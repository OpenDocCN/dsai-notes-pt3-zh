- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P38ï¼šL7.2- åœ¨Kerasï¼Tensorflow2.0ä¸­ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç”Ÿæˆäººè„¸
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P38ï¼šL7.2- åœ¨Kerasï¼Tensorflow2.0ä¸­ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç”Ÿæˆäººè„¸
    - ShowMeAI - BV15f4y1w7b8
- en: Generative adversarial neural networksï¼Œ these faces you see here are not realã€‚
    They were created by a Gã€‚This type of neural network can be used to create data
    that is not realã€‚ Nowï¼Œ I am realï¼Œ or at least I thinkã€‚But these neural networks
    can be used to create this kind of faceã€‚ Nowï¼Œ I'm going to start by not showing
    you how to create these very high resolution faces that you see that were created
    with software that Nvidia makes for youã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¯¹æŠ—ç¥ç»ç½‘ç»œï¼Œè¿™äº›ä½ çœ‹åˆ°çš„é¢å­”éƒ½ä¸çœŸå®ã€‚å®ƒä»¬æ˜¯ç”±ä¸€ä¸ªGåˆ›å»ºçš„ã€‚è¿™ç§ç±»å‹çš„ç¥ç»ç½‘ç»œå¯ä»¥ç”¨äºåˆ›å»ºä¸çœŸå®çš„æ•°æ®ã€‚ç°åœ¨ï¼Œæˆ‘æ˜¯çœŸå®çš„ï¼Œè‡³å°‘æˆ‘è¿™ä¹ˆè®¤ä¸ºã€‚ä½†è¿™äº›ç¥ç»ç½‘ç»œå¯ä»¥ç”¨æ¥åˆ›å»ºè¿™ç§é¢å­”ã€‚ç°åœ¨ï¼Œæˆ‘å°†å¼€å§‹ï¼Œä¸å‘ä½ å±•ç¤ºå¦‚ä½•åˆ›å»ºè¿™äº›ç”±Nvidiaè½¯ä»¶ä¸ºä½ ç”Ÿæˆçš„é«˜åˆ†è¾¨ç‡é¢å­”ã€‚
- en: This is styleganï¼Œ which we'll see in the next videoã€‚ But in this video we're
    gonna to see how to actually build this sort of thing from scratchã€‚ You'll create
    faces that look more like thisï¼Œ but this is somethingã€‚ this is the beginningã€‚
    This is the stepping stone for you to get code up and running that can create
    this kind of dataã€‚Hiã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯styleganï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­çœ‹åˆ°ã€‚ä½†åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å®é™…ä»å¤´å¼€å§‹æ„å»ºè¿™ç§ä¸œè¥¿ã€‚ä½ å°†åˆ›å»ºæ›´åƒè¿™æ ·çš„é¢å­”ï¼Œä½†è¿™åªæ˜¯ä¸ªå¼€å§‹ã€‚è¿™æ˜¯ä½ è·å¾—ä»£ç å¹¶è¿è¡Œä»¥ç”Ÿæˆè¿™ç§æ•°æ®çš„å«è„šçŸ³ã€‚å—¨ã€‚
- en: my name is Jeff Heatonã€‚ Welcome to applications of deep neural networks with
    Washington University to see all my videos about Cagel neural networks and other
    AI topicsã€‚ click the subscribe button and the bell next to it and select al to
    be notified of every new videoã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å«Jeff Heatonã€‚æ¬¢è¿æ¥åˆ°ä¸åç››é¡¿å¤§å­¦åˆä½œçš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ï¼ŒæŸ¥çœ‹æˆ‘å…³äºCagelç¥ç»ç½‘ç»œå’Œå…¶ä»–AIä¸»é¢˜çš„æ‰€æœ‰è§†é¢‘ã€‚ç‚¹å‡»è®¢é˜…æŒ‰é’®å’Œæ—è¾¹çš„é“ƒé“›ï¼Œé€‰æ‹©å…¨éƒ¨ï¼Œä»¥ä¾¿æ¥æ”¶åˆ°æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚
- en: I do provide complete source code for thisã€‚ I recommend that you open it in
    Google coab like I have up here in my Github linkã€‚ I have a link to this Github
    repository with all my code hereã€‚ I just upgraded all of my G code to Tensorflow
    2ã€‚0ã€‚ So this should work fully well with that latest version of Tensorflow through
    Ksã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç¡®å®æä¾›äº†å®Œæ•´çš„æºä»£ç ã€‚æˆ‘å»ºè®®ä½ åƒæˆ‘åœ¨æˆ‘çš„Githubé“¾æ¥ä¸­é‚£æ ·åœ¨Google Coabä¸­æ‰“å¼€å®ƒã€‚æˆ‘è¿™é‡Œæœ‰ä¸€ä¸ªæŒ‡å‘è¿™ä¸ªGithubä»£ç åº“çš„é“¾æ¥ï¼Œé‡Œé¢åŒ…å«æˆ‘æ‰€æœ‰çš„ä»£ç ã€‚æˆ‘åˆšåˆšå°†æˆ‘çš„Gä»£ç å‡çº§åˆ°Tensorflow
    2.0ã€‚å› æ­¤ï¼Œè¿™åº”è¯¥èƒ½å¤Ÿå¾ˆå¥½åœ°ä¸æœ€æ–°ç‰ˆæœ¬çš„Tensorflowé€šè¿‡Ksé…åˆä½¿ç”¨ã€‚
- en: before we get into the codeï¼Œ let's just conceptually look at what we're trying
    to doã€‚ So for a Gã€‚ you have two neural networksã€‚ and you're training each of these
    two neural networks completely differentlyã€‚ And it's important to understand this
    distinctionã€‚ if you really want to understand how this code worksã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬è¿›å…¥ä»£ç ä¹‹å‰ï¼Œå…ˆä»æ¦‚å¿µä¸Šçœ‹ä¸€ä¸‹æˆ‘ä»¬æƒ³è¦åšçš„äº‹æƒ…ã€‚å¯¹äºä¸€ä¸ªGï¼Œä½ æœ‰ä¸¤ä¸ªç¥ç»ç½‘ç»œï¼Œè€Œä½ ä»¥å®Œå…¨ä¸åŒçš„æ–¹å¼è®­ç»ƒè¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œã€‚ç†è§£è¿™ç§åŒºåˆ«å¾ˆé‡è¦ï¼Œå¦‚æœä½ çœŸçš„æƒ³ç†è§£è¿™æ®µä»£ç æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
- en: That is really the goal of this video to show you literally how you can create
    your own GN fromã€‚ğŸ˜Šã€‚![](img/618ec4df027e5ab5cc37e5905fefc1e4_1.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯è¿™ä¸ªè§†é¢‘çš„ç›®æ ‡ï¼Œå‘ä½ å±•ç¤ºå¦‚ä½•ä»å¤´å¼€å§‹åˆ›å»ºè‡ªå·±çš„GNã€‚ğŸ˜Šã€‚![](img/618ec4df027e5ab5cc37e5905fefc1e4_1.png)
- en: '![](img/618ec4df027e5ab5cc37e5905fefc1e4_2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/618ec4df027e5ab5cc37e5905fefc1e4_2.png)'
- en: 2 neural networksã€‚ It's really not that complicatedã€‚ If you take it piece by
    pieceã€‚ So you have two neural networksã€‚ you have a discriminator and you have
    a generatorã€‚ The inputs and outputs to these two neural networks are completely
    differentã€‚ This is how I always think about learning a new technology when I see
    a neural networkã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªç¥ç»ç½‘ç»œã€‚å…¶å®å¹¶æ²¡æœ‰é‚£ä¹ˆå¤æ‚ã€‚å¦‚æœä½ é€æ­¥æ¥çœ‹ã€‚ä½ æœ‰ä¸¤ä¸ªç¥ç»ç½‘ç»œï¼Œä¸€ä¸ªæ˜¯é‰´åˆ«å™¨ï¼Œå¦ä¸€ä¸ªæ˜¯ç”Ÿæˆå™¨ã€‚è¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œçš„è¾“å…¥å’Œè¾“å‡ºæ˜¯å®Œå…¨ä¸åŒçš„ã€‚è¿™å°±æ˜¯æˆ‘åœ¨çœ‹åˆ°ç¥ç»ç½‘ç»œæ—¶ï¼Œå¦‚ä½•æ€è€ƒå­¦ä¹ æ–°æŠ€æœ¯çš„æ–¹å¼ã€‚
- en: I want to know what the input isã€‚ I want to know what the output is so that
    I can really see what this thing is actually doing for the discriminatorã€‚ this
    neural network has only one job in the worldã€‚ It is used to tell if the input
    to it is real or not real Here we have a image coming into itã€‚ I'm using this
    as though it's a real imageï¼Œ but this is actually something I created with style
    ga just so that I'm not using anybody's random face in my videoã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³çŸ¥é“è¾“å…¥æ˜¯ä»€ä¹ˆã€‚æˆ‘æƒ³çŸ¥é“è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Œä»¥ä¾¿æˆ‘èƒ½çœŸæ­£äº†è§£è¿™ä¸ªä¸œè¥¿åœ¨é‰´åˆ«å™¨ä¸­å®é™…ä¸Šåœ¨åšä»€ä¹ˆã€‚è¿™ä¸ªç¥ç»ç½‘ç»œåœ¨è¿™ä¸ªä¸–ç•Œä¸Šåªæœ‰ä¸€ä¸ªå·¥ä½œã€‚å®ƒç”¨æ¥åˆ¤æ–­è¾“å…¥æ˜¯çœŸå®çš„è¿˜æ˜¯ä¸çœŸå®çš„ã€‚è¿™é‡Œæœ‰ä¸€å¼ å›¾åƒè¿›å…¥å®ƒã€‚æˆ‘æŠŠè¿™ä¸ªå½“ä½œçœŸå®çš„å›¾åƒæ¥ä½¿ç”¨ï¼Œä½†å®é™…ä¸Šè¿™æ˜¯æˆ‘ç”¨stylegaåˆ›å»ºçš„ï¼Œä»¥ä¾¿æˆ‘ä¸åœ¨è§†é¢‘ä¸­ä½¿ç”¨ä»»ä½•éšæœºçš„é¢å­”ã€‚
- en: So image comes into the neural networkã€‚ Now this is what is awesome about neural
    networks compared to other types of modelsã€‚ the input can be almost anythingã€‚
    the output can be almost anythingã€‚ So here the input isã€‚Image this is a 3D tensorã€‚
    So it's the height and the width and then the color gapã€‚ The output is a single
    numberã€‚ This is a predictionã€‚ So 0ã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å›¾åƒè¿›å…¥ç¥ç»ç½‘ç»œã€‚ç°åœ¨è¿™å°±æ˜¯ç¥ç»ç½‘ç»œä¸å…¶ä»–ç±»å‹æ¨¡å‹ç›¸æ¯”çš„ç²¾å½©ä¹‹å¤„ã€‚è¾“å…¥å‡ ä¹å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿ï¼Œè¾“å‡ºå‡ ä¹å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿ã€‚æ‰€ä»¥è¿™é‡Œè¾“å…¥æ˜¯å›¾åƒï¼Œè¿™æ˜¯ä¸€ä¸ª3Då¼ é‡ã€‚æ‰€ä»¥å®ƒæ˜¯é«˜åº¦ã€å®½åº¦å’Œé¢œè‰²é€šé“ã€‚è¾“å‡ºæ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—ã€‚è¿™æ˜¯ä¸€ä¸ªé¢„æµ‹ã€‚æ‰€ä»¥0ã€‚
- en: 97 means that the discriminator is saying that there is a 97% probability that
    this isï¼Œ in factã€‚ a real faceã€‚ Just think of him as a real face and not something
    that came from my own personal matrixã€‚ All rightï¼Œ now the generatorï¼Œ this is the
    part that is going to be really useful when you build a face generating neural
    network or some other sort of generating neural networkã€‚ Often you throw the discriminator
    away once you once you've trained itã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 97æ„å‘³ç€åˆ¤åˆ«å™¨åœ¨è¯´ï¼Œè¿™å®é™…ä¸Šæœ‰97%çš„æ¦‚ç‡æ˜¯ä¸€ä¸ªçœŸå®çš„é¢å­”ã€‚åªè¦æŠŠå®ƒå½“ä½œä¸€ä¸ªçœŸå®çš„é¢å­”ï¼Œè€Œä¸æ˜¯ä»æˆ‘ä¸ªäººçš„çŸ©é˜µä¸­æ¥çš„ä¸œè¥¿ã€‚å¥½å§ï¼Œç°åœ¨ç”Ÿæˆå™¨ï¼Œè¿™éƒ¨åˆ†åœ¨ä½ æ„å»ºé¢å­”ç”Ÿæˆç¥ç»ç½‘ç»œæˆ–å…¶ä»–ç±»å‹çš„ç”Ÿæˆç¥ç»ç½‘ç»œæ—¶ä¼šéå¸¸æœ‰ç”¨ã€‚é€šå¸¸ä½ åœ¨è®­ç»ƒå®Œæˆåä¼šæ‰”æ‰åˆ¤åˆ«å™¨ã€‚
- en: but the discriminator does have use and we'll see this later in later videos
    when you deal a semi superervised learning where maybe you don't have labels for
    everythingã€‚ So both of these two can be usefulï¼Œ But if you just want a face generator
    or car generator or a cat or an avocado generatorã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åˆ¤åˆ«å™¨ç¡®å®æ˜¯æœ‰ç”¨çš„ï¼Œæˆ‘ä»¬å°†åœ¨åé¢çš„åç»­è§†é¢‘ä¸­çœ‹åˆ°ï¼Œå½“ä½ å¤„ç†åŠç›‘ç£å­¦ä¹ æ—¶ï¼Œå¯èƒ½ä½ å¹¶æ²¡æœ‰æ‰€æœ‰å†…å®¹çš„æ ‡ç­¾ã€‚æ‰€ä»¥è¿™ä¸¤ä¸ªéƒ½å¯ä»¥æœ‰ç”¨ï¼Œä½†å¦‚æœä½ åªæƒ³è¦ä¸€ä¸ªé¢å­”ç”Ÿæˆå™¨ã€æ±½è½¦ç”Ÿæˆå™¨ã€çŒ«æˆ–ç‰›æ²¹æœç”Ÿæˆå™¨ã€‚
- en: this is all you really needing and generate anything Here we basicallyã€‚ğŸ˜Šï¼Œin
    random seedsã€‚ So the random seedsã€‚ you might have seen these in video games like
    Minecraftï¼Œ I know does thisã€‚ You put in a random seedã€‚ and essentially a whole
    world is created for youã€‚ That is what this isã€‚ So in Minecraftï¼Œ it's not like
    some seeds are bad and some seeds are goodã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä½ çœŸæ­£éœ€è¦çš„ï¼Œç”Ÿæˆä»»ä½•ä¸œè¥¿åœ¨è¿™é‡ŒåŸºæœ¬ä¸Šã€‚ğŸ˜Šï¼Œåœ¨éšæœºç§å­ä¸­ã€‚æ‰€ä»¥éšæœºç§å­ã€‚ä½ å¯èƒ½åœ¨åƒMinecraftè¿™æ ·çš„ç”µå­æ¸¸æˆä¸­è§è¿‡è¿™äº›ï¼Œæˆ‘çŸ¥é“è¿™æ ·åšã€‚ä½ è¾“å…¥ä¸€ä¸ªéšæœºç§å­ï¼ŒåŸºæœ¬ä¸Šä¼šä¸ºä½ åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ä¸–ç•Œã€‚è¿™å°±æ˜¯è¿™ä¸ªæ¦‚å¿µã€‚å› æ­¤ï¼Œåœ¨Minecraftä¸­ï¼Œå¹¶ä¸æ˜¯è¯´æŸäº›ç§å­æ˜¯åçš„ï¼Œè€ŒæŸäº›ç§å­æ˜¯å¥½çš„ã€‚
- en: They all give you random worldsã€‚ Each of these random seeds gives you a random
    face Since the neural network was trained toã€‚ Now what you have to keep in mind
    is this is not just a single numberã€‚ This is a vectorã€‚ So it is a array of numberã€‚
    often it will be100 or some higher dimension array of these numbersã€‚ You can also
    do really interesting experiments and very just one number of the vector and try
    to see what different parts of the vector are actually for in stylegan you can
    do some of that you can make hair longerã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬éƒ½ä¼šç»™ä½ éšæœºçš„ä¸–ç•Œã€‚æ¯ä¸€ä¸ªéšæœºç§å­éƒ½ä¼šç»™ä½ ä¸€ä¸ªéšæœºçš„é¢å­”ã€‚ç”±äºç¥ç»ç½‘ç»œè¢«è®­ç»ƒå‡ºæ¥çš„ã€‚æ‰€ä»¥ä½ è¦è®°ä½çš„å°±æ˜¯ï¼Œè¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªæ•°å­—ã€‚è¿™æ˜¯ä¸€ä¸ªå‘é‡ã€‚æ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªæ•°å­—çš„æ•°ç»„ã€‚é€šå¸¸æ˜¯100æˆ–è€…æ›´é«˜ç»´åº¦çš„è¿™äº›æ•°å­—çš„æ•°ç»„ã€‚ä½ ä¹Ÿå¯ä»¥åšä¸€äº›éå¸¸æœ‰è¶£çš„å®éªŒï¼Œæ”¹å˜å‘é‡ä¸­çš„æŸä¸ªæ•°å­—ï¼Œçœ‹çœ‹å‘é‡çš„ä¸åŒéƒ¨åˆ†å®é™…ä¸Šæ˜¯ç”¨äºä»€ä¹ˆï¼Œåœ¨styleganä¸­ä½ å¯ä»¥åšä¸€äº›è¿™æ ·çš„å®éªŒï¼Œä½ å¯ä»¥è®©å¤´å‘å˜é•¿ã€‚
- en: you can change the color of the eyes and leave everything else aloneã€‚ but that's
    more for the next video when we talk about styleganã€‚ This is creating your own
    from scratchã€‚ So you give it this random seed that you generateã€‚ğŸ˜Šã€‚Then you give
    itã€‚ It gives you an output imageã€‚ Nowã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ”¹å˜çœ¼ç›çš„é¢œè‰²ï¼Œè€Œä¸æ”¹å˜å…¶ä»–æ‰€æœ‰ä¸œè¥¿ï¼Œä½†è¿™æ›´å¤šæ˜¯é’ˆå¯¹ä¸‹ä¸€ä¸ªè§†é¢‘ï¼Œæˆ‘ä»¬è®¨è®ºstyleganã€‚è¿™æ˜¯ä»é›¶å¼€å§‹åˆ›å»ºè‡ªå·±çš„ä¸œè¥¿ã€‚æ‰€ä»¥ä½ ç»™å®ƒè¿™ä¸ªä½ ç”Ÿæˆçš„éšæœºç§å­ã€‚ğŸ˜Šç„¶åä½ ç»™å®ƒï¼Œå®ƒä¼šç»™ä½ ä¸€ä¸ªè¾“å‡ºå›¾åƒã€‚ç°åœ¨ã€‚
- en: a question I got in some of the other videos was what ranges should these numbers
    be inã€‚ Wellã€‚ it doesn't matterã€‚ but they have to be the same range that you trained
    it onã€‚ So when you are training itï¼Œ you were giving it some random range and distributionã€‚
    Make sure that stays the sameã€‚ Don't train it on numbers that are in the range
    is 0 to sayï¼Œ100ã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨å…¶ä»–è§†é¢‘ä¸­æ”¶åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯è¿™äº›æ•°å­—åº”è¯¥åœ¨ä»€ä¹ˆèŒƒå›´å†…ã€‚å¥½å§ã€‚æ²¡å…³ç³»ï¼Œä½†å®ƒä»¬å¿…é¡»åœ¨ä½ è®­ç»ƒæ—¶ç›¸åŒçš„èŒƒå›´å†…ã€‚æ‰€ä»¥å½“ä½ è®­ç»ƒå®ƒæ—¶ï¼Œä½ ç»™å®ƒä¸€äº›éšæœºçš„èŒƒå›´å’Œåˆ†å¸ƒã€‚ç¡®ä¿ä¿æŒä¸€è‡´ã€‚ä¸è¦åœ¨èŒƒå›´æ˜¯0åˆ°100çš„æ•°å­—ä¸Šè®­ç»ƒã€‚
- en: And then all of a sudden throw a million in thereã€‚ That's not going to work
    wellã€‚ So this is what these two neural networks look like just in their general
    usageã€‚ The trick is how do we train theseã€‚ It's an adversarial neural networksã€‚
    So they're working against each otherã€‚ It's a generative neural networkã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åçªç„¶é—´æ”¾å…¥ä¸€ç™¾ä¸‡ï¼Œè¿™æ ·åšæ˜¯ä¸ä¼šå¥½çš„ã€‚æ‰€ä»¥è¿™å°±æ˜¯è¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œåœ¨å…¶ä¸€èˆ¬ä½¿ç”¨ä¸­çš„æ ·å­ã€‚è¯€çªæ˜¯æˆ‘ä»¬å¦‚ä½•è®­ç»ƒè¿™äº›ã€‚è¿™æ˜¯å¯¹æŠ—ç¥ç»ç½‘ç»œã€‚æ‰€ä»¥å®ƒä»¬æ˜¯äº’ç›¸å¯¹æŠ—çš„ã€‚è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå¼ç¥ç»ç½‘ç»œã€‚
- en: That just means it's generating thingsã€‚ It's generating facesã€‚ Firstã€‚ let's
    look at how we train the generatorã€‚ because it's a little bit more simple than
    the discriminatorã€‚ What is important about training both of these is noticeã€‚I
    show weights trained weights staticã€‚ Both of the neural networks need to be in
    place to train either oneã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯æ„å‘³ç€å®ƒåœ¨ç”Ÿæˆä¸œè¥¿ã€‚å®ƒåœ¨ç”Ÿæˆé¢å­”ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¦‚ä½•è®­ç»ƒç”Ÿæˆå™¨ï¼Œå› ä¸ºè¿™æ¯”è®­ç»ƒåˆ¤åˆ«å™¨è¦ç®€å•ä¸€äº›ã€‚è®­ç»ƒè¿™ä¸¤ä¸ªçš„é‡è¦æ€§åœ¨äºï¼Œæ³¨æ„åˆ°æˆ‘å±•ç¤ºçš„æƒé‡æ˜¯é™æ€çš„ã€‚ä¸¤ä¸ªç¥ç»ç½‘ç»œéƒ½éœ€è¦åˆ°ä½ï¼Œæ‰èƒ½è®­ç»ƒä»»æ„ä¸€ä¸ªã€‚
- en: but you cannot update the weights on both that that would not work well at all
    here we are training the generatorã€‚ So if we were to allow the weights on the
    discriminator to be modified while we're training the generator that would be
    cheatingã€‚ That's the generator is basically trying to get its weights better and
    better and better so that we can fool the discriminatorã€‚ the whole overall objective
    is to fool the generator while we're training thisã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ ä¸èƒ½åŒæ—¶æ›´æ–°è¿™ä¸¤ä¸ªçš„æƒé‡ï¼Œè¿™æ ·æ ¹æœ¬è¡Œä¸é€šï¼Œè¿™é‡Œæˆ‘ä»¬æ˜¯åœ¨è®­ç»ƒç”Ÿæˆå™¨ã€‚æ‰€ä»¥å¦‚æœåœ¨è®­ç»ƒç”Ÿæˆå™¨çš„åŒæ—¶å…è®¸ä¿®æ”¹åˆ¤åˆ«å™¨çš„æƒé‡ï¼Œé‚£å°±æ˜¯ä½œå¼Šã€‚ç”Ÿæˆå™¨åŸºæœ¬ä¸Šæ˜¯åœ¨ä¸æ–­ä¼˜åŒ–å®ƒçš„æƒé‡ï¼Œä»¥ä¾¿èƒ½å¤Ÿæ¬ºéª—åˆ¤åˆ«å™¨ã€‚æ•´ä½“ç›®æ ‡æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¬ºéª—ç”Ÿæˆå™¨ã€‚
- en: So if we allow the weights to be trained on both of these it happen is back
    propagation would sayã€‚ okay let' let's move the weights so the generator is betterã€‚
    Oh let's affect the discriminator so that the weights are also better at producing
    this result of fooling the discriminator you don't want to modify the discriminator
    to foolã€‚SoThats that's like training one runner on the track and letting him get
    better and betterã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘ä»¬å…è®¸å¯¹è¿™ä¸¤ä¸ªè¿›è¡Œæƒé‡è®­ç»ƒï¼Œé‚£ä¹ˆåå‘ä¼ æ’­ä¼šè¯´ï¼Œå¥½çš„ï¼Œè®©æˆ‘ä»¬ç§»åŠ¨æƒé‡ï¼Œä½¿ç”Ÿæˆå™¨å˜å¾—æ›´å¥½ã€‚å“¦ï¼Œè®©æˆ‘ä»¬å½±å“åˆ¤åˆ«å™¨ï¼Œä½¿å¾—æƒé‡åœ¨æ¬ºéª—åˆ¤åˆ«å™¨çš„ç»“æœä¸Šä¹Ÿæ›´å¥½ï¼Œä½ ä¸æƒ³ä¿®æ”¹åˆ¤åˆ«å™¨æ¥è¿›è¡Œæ¬ºéª—ã€‚è¿™å°±åƒæ˜¯åœ¨è·‘é“ä¸Šè®­ç»ƒä¸€åè¿åŠ¨å‘˜ï¼Œè®©ä»–å˜å¾—è¶Šæ¥è¶Šå¥½ã€‚
- en: but then seeing the other runner that he's gonna train against someday and tripping
    that guyã€‚ So only one of these guys needs to be trained at a time Otherwise you're
    going to end up with weaker resultã€‚ You need that competition goingã€‚ So when you're
    dealing with trainingã€‚ Like every other neural network that we've seen in this
    courseï¼Œ you have your X and you have your Yã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åˆçœ‹åˆ°å…¶ä»–è¿åŠ¨å‘˜ï¼Œæœ‰ä¸€å¤©ä»–ä¼šå¯¹æŠ—é‚£ä¸ªäººï¼Œå¹¶ä¸”ä¼šç»Šå€’é‚£å®¶ä¼™ã€‚æ‰€ä»¥è¿™äº›è¿åŠ¨å‘˜ä¸­åªèƒ½æœ‰ä¸€ä¸ªåœ¨è®­ç»ƒï¼Œå¦åˆ™ä½ æœ€ç»ˆä¼šå¾—åˆ°è¾ƒå¼±çš„ç»“æœã€‚ä½ éœ€è¦æœ‰ç«äº‰åœ¨è¿›è¡Œã€‚å› æ­¤ï¼Œå½“ä½ è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåƒæˆ‘ä»¬åœ¨æœ¬è¯¾ç¨‹ä¸­çœ‹åˆ°çš„æ¯ä¸ªç¥ç»ç½‘ç»œä¸€æ ·ï¼Œä½ æœ‰Xå’ŒYã€‚
- en: The X is what goes into the neural network to produce the Y that you expectedã€‚
    What your neural network actually gives you is called Y hatã€‚ It's the Y with a
    little triangle type thing above itã€‚ So the X in this case is random seedsã€‚ We're
    going to create a bunch of random seedsã€‚ In this caseï¼Œ I'm just showing threeã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Xæ˜¯è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­ä»¥ç”Ÿæˆé¢„æœŸçš„Yã€‚ä½ çš„ç¥ç»ç½‘ç»œå®é™…ç»™ä½ çš„è¢«ç§°ä¸ºYå¸½ã€‚å®ƒæ˜¯å¸¦æœ‰å°ä¸‰è§’çš„Yã€‚å› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒXæ˜¯éšæœºç§å­ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€å †éšæœºç§å­ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘åªæ˜¯å±•ç¤ºä¸‰ä¸ªã€‚
- en: but we're going to send those into the generatorã€‚ The generator is going to
    create three random facesã€‚ Now the generator may not be very good at first and
    it's going to get better and betterã€‚the discriminator is going to get better and
    better at sayingï¼Œ aha these facesã€‚ they're not realã€‚ The discriminator is going
    to take these inï¼Œ and it's going to give predictionsã€‚ It's going to sayã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ä¼šå°†è¿™äº›è¾“å…¥åˆ°ç”Ÿæˆå™¨ä¸­ã€‚ç”Ÿæˆå™¨ä¼šåˆ›å»ºä¸‰ä¸ªéšæœºçš„é¢å­”ã€‚ç°åœ¨ç”Ÿæˆå™¨å¯èƒ½èµ·åˆä¸å¤ªå¥½ï¼Œä½†å®ƒä¼šè¶Šæ¥è¶Šå¥½ã€‚åˆ¤åˆ«å™¨ä¹Ÿä¼šè¶Šæ¥è¶Šå¥½ï¼Œå®ƒä¼šè¯´ï¼Œå•Šï¼Œè¿™äº›é¢å­”ï¼Œå®ƒä»¬ä¸æ˜¯çœŸçš„ã€‚åˆ¤åˆ«å™¨ä¼šæ¥å—è¿™äº›è¾“å…¥ï¼Œå¹¶ç»™å‡ºé¢„æµ‹ã€‚å®ƒä¼šè¯´ã€‚
- en: okayï¼Œ that face 45%ã€‚ This face 55%ã€‚ The last oneï¼Œ that looks a little betterï¼Œ65%ã€‚
    These are the y hatsã€‚ These were the actual predictions at this point in training
    for the discriminatorã€‚ Nowï¼Œ the why is what we really wanted it to beã€‚ This is
    the expected outputã€‚ This is what normally comes from your training dataã€‚ But
    look at the interesting thing hereã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™å¼ è„¸45%ã€‚è¿™å¼ è„¸55%ã€‚æœ€åé‚£å¼ ï¼Œçœ‹èµ·æ¥å¥½ä¸€ç‚¹ï¼Œ65%ã€‚è¿™äº›æ˜¯yå¸½ã€‚è¿™äº›æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåˆ¤åˆ«å™¨æ­¤æ—¶çš„å®é™…é¢„æµ‹ã€‚ç°åœ¨ï¼Œyæ˜¯æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„ã€‚è¿™æ˜¯é¢„æœŸçš„è¾“å‡ºã€‚è¿™æ˜¯é€šå¸¸æ¥è‡ªä½ çš„è®­ç»ƒæ•°æ®çš„ã€‚ä½†çœ‹çœ‹è¿™é‡Œæœ‰è¶£çš„åœ°æ–¹ã€‚
- en: This is training the generatorã€‚ We're not using any of our training dataã€‚ Our
    training data is a bunch of real faces that you downloadã€‚ I give you some sample
    places that you can go to get these actual facesã€‚ But when we're training the
    generatorã€‚ We're not using any real faces at allã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è®­ç»ƒç”Ÿæˆå™¨ã€‚æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ä»»ä½•è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®æ˜¯ä¸€å †ä½ ä¸‹è½½çš„çœŸå®é¢å­”ã€‚æˆ‘ç»™ä½ ä¸€äº›ç¤ºä¾‹ç½‘å€ï¼Œä½ å¯ä»¥å»è·å–è¿™äº›çœŸå®çš„é¢å­”ã€‚ä½†åœ¨è®­ç»ƒç”Ÿæˆå™¨æ—¶ï¼Œæˆ‘ä»¬æ ¹æœ¬ä¸ä½¿ç”¨ä»»ä½•çœŸå®é¢å­”ã€‚
- en: The generator never gets to see the real facesã€‚ It is just learning slowlyã€‚
    slowly slowly to generate faces that are better andã€‚Or at fooling the discriminatorã€‚
    So that that might seem a little bit strangeã€‚ And the Ysã€‚ these y's normally come
    from the training dataã€‚ The Ys are always oneã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå™¨ä»æœªè§è¿‡çœŸå®é¢å­”ã€‚å®ƒåªæ˜¯æ…¢æ…¢åœ°å­¦ä¹ ï¼Œæ…¢æ…¢åœ°ç”Ÿæˆæ›´å¥½çš„é¢å­”ï¼Œæˆ–è€…åœ¨æ¬ºéª—é‰´åˆ«å™¨æ–¹é¢å˜å¾—æ›´å¥½ã€‚æ‰€ä»¥è¿™å¯èƒ½çœ‹èµ·æ¥æœ‰ç‚¹å¥‡æ€ªã€‚Ysã€‚è¿™äº›yé€šå¸¸æ¥è‡ªè®­ç»ƒæ•°æ®ã€‚Yså§‹ç»ˆä¸º1ã€‚
- en: This is completely unbalanced dataã€‚ This is the worst of unbalanced dataã€‚ You
    don't have any zerosã€‚ So you're not training the generator on any false casesã€‚
    But it has this discriminator in the way that it has to foolã€‚ If you didn't have
    thisã€‚ The generator just learnï¼Œ ohï¼Œ you always want a1ã€‚ Okayï¼Œ that's fineï¼Œ I'll
    always give you a oneã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å®Œå…¨ä¸å¹³è¡¡çš„æ•°æ®ã€‚è¿™æ˜¯æœ€ç³Ÿç³•çš„ä¸å¹³è¡¡æ•°æ®ã€‚ä½ æ²¡æœ‰ä»»ä½•é›¶ã€‚å› æ­¤ä½ å¹¶æ²¡æœ‰åœ¨ä»»ä½•è™šå‡æ¡ˆä¾‹ä¸Šè®­ç»ƒç”Ÿæˆå™¨ã€‚ä½†å®ƒæœ‰è¿™ä¸ªé‰´åˆ«å™¨éœ€è¦å»æ¬ºéª—ã€‚å¦‚æœæ²¡æœ‰è¿™ä¸ªï¼Œç”Ÿæˆå™¨å°±ä¼šå­¦ä¹ åˆ°â€œå“¦ï¼Œä½ æ€»æ˜¯æƒ³è¦1â€ã€‚å¥½çš„ï¼Œé‚£æˆ‘å°±æ€»æ˜¯ç»™ä½ 1ã€‚
- en: But the generator's output is being fed right into the discriminator for the
    training loopã€‚ This is a little more complicated of a neural networkã€‚ than we
    than we've had beforeã€‚ You can almost think of this whole region that I'm drawing
    my mouse circle around over here as the objective functionã€‚ The objective is to
    fool the discriminatorã€‚ So it doesn't matter that this is unbalancedã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ç”Ÿæˆå™¨çš„è¾“å‡ºè¢«ç›´æ¥è¾“å…¥åˆ°é‰´åˆ«å™¨è¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚è¿™æ˜¯ä¸€ä¸ªæ¯”æˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œã€‚ä½ å‡ ä¹å¯ä»¥å°†æˆ‘ç”¨é¼ æ ‡åœˆä½çš„æ•´ä¸ªåŒºåŸŸè§†ä¸ºç›®æ ‡å‡½æ•°ã€‚ç›®æ ‡æ˜¯æ¬ºéª—é‰´åˆ«å™¨ã€‚æ‰€ä»¥è¿™å¹¶ä¸é‡è¦ï¼Œå®ƒæ˜¯ä¸å¹³è¡¡çš„ã€‚
- en: It's not really unbalancedã€‚ It's just because we want this to alwaysã€‚Give as
    close to a one as as we canã€‚ And the only way the generator can do that is by
    getting better and better images to actually fool that discriminatorã€‚ So you'll
    see in the code when we look at that in a momentã€‚ We are literally creating for
    the loss function for the objective functionã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¹¶ä¸æ˜¯çœŸæ­£çš„ä¸å¹³è¡¡ã€‚è¿™åªæ˜¯å› ä¸ºæˆ‘ä»¬å¸Œæœ›å®ƒæ€»æ˜¯å°½å¯èƒ½æ¥è¿‘1ã€‚ç”Ÿæˆå™¨èƒ½åšåˆ°è¿™ä¸€ç‚¹çš„å”¯ä¸€æ–¹æ³•æ˜¯ç”Ÿæˆæ›´å¥½æ›´å¥½çš„å›¾åƒæ¥æ¬ºéª—é‰´åˆ«å™¨ã€‚å› æ­¤ä½ ä¼šåœ¨ä»£ç ä¸­çœ‹åˆ°ï¼Œå½“æˆ‘ä»¬ç¨åæŸ¥çœ‹æ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨ä¸ºç›®æ ‡å‡½æ•°åˆ›å»ºæŸå¤±å‡½æ•°ã€‚
- en: data sets where we choose whatever the batch sizesï¼Œ whatever we're training
    for the current stepã€‚ Howeverï¼Œ many of these we wantï¼Œ and that's set is a configuration
    parameterã€‚ We generate that many random seedsï¼Œ we generate the random facesã€‚ and
    then we send those to the discri discriminatorã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†æˆ‘ä»¬é€‰æ‹©æ— è®ºæ‰¹é‡å¤§å°ï¼Œæ— è®ºæˆ‘ä»¬å½“å‰æ­¥éª¤è®­ç»ƒä»€ä¹ˆã€‚è¿™äº›æ•°é‡ç”±é…ç½®å‚æ•°è®¾ç½®ã€‚æˆ‘ä»¬ç”Ÿæˆé‚£ä¹ˆå¤šéšæœºç§å­ï¼Œç”Ÿæˆéšæœºé¢å­”ã€‚ç„¶åå°†è¿™äº›å‘é€ç»™é‰´åˆ«å™¨ã€‚
- en: get the Y hats calculate the back propagation gradients apply thatï¼Œ and then
    you apply the chainã€‚ So you do that for one stepã€‚ They'll be multiple stepã€‚ So
    whatever your batch sizesï¼Œ That's a stepã€‚ And then we do enough of these so that
    we cross the entire training set for the entire epochã€‚ So the things to notice
    here that might seem a little strangeã€‚ğŸ˜Šã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è·å–Yå¸½ï¼Œè®¡ç®—åå‘ä¼ æ’­æ¢¯åº¦ï¼Œåº”ç”¨å®ƒï¼Œç„¶åä½ åº”ç”¨é“¾å¼æ³•åˆ™ã€‚æ‰€ä»¥ä½ å¯¹ä¸€æ­¥è¿›è¡Œè¿™æ ·çš„æ“ä½œã€‚ä¼šæœ‰å¤šä¸ªæ­¥éª¤ã€‚æ‰€ä»¥æ— è®ºä½ çš„æ‰¹é‡å¤§å°æ˜¯ä»€ä¹ˆï¼Œé‚£å°±æ˜¯ä¸€æ­¥ã€‚ç„¶åæˆ‘ä»¬åšè¶³å¤Ÿå¤šçš„è¿™äº›ï¼Œä»¥è¦†ç›–æ•´ä¸ªè®­ç»ƒé›†ï¼Œç›´åˆ°æ•´ä¸ªå‘¨æœŸã€‚æ‰€ä»¥è¿™é‡Œéœ€è¦æ³¨æ„çš„äº‹æƒ…å¯èƒ½çœ‹èµ·æ¥æœ‰ç‚¹å¥‡æ€ªã€‚ğŸ˜Š
- en: The generator never sees the training set and the Ys are always one for this
    because weã€‚ we aspire to be perfectã€‚1ã€‚0ã€‚ There's really nothing we could train
    the generatorã€‚ we don't want to train the generator to produce zerosã€‚ So that's
    why the training set looks in balanceï¼Œ but the fact that this whole piece over
    here is working togetherã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå™¨ä»æœªè§è¿‡è®­ç»ƒé›†ï¼ŒYså§‹ç»ˆä¸º1ï¼Œå› ä¸ºæˆ‘ä»¬æ¸´æœ›å®Œç¾ã€‚1.0ã€‚å®é™…ä¸Šæˆ‘ä»¬æ— æ³•è®­ç»ƒç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›ç”Ÿæˆå™¨ç”Ÿæˆé›¶ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè®­ç»ƒé›†çœ‹èµ·æ¥ä¸å¹³è¡¡ï¼Œä½†å®é™…ä¸Šè¿™ä¸€æ•´å—åœ¨ä¸€èµ·å·¥ä½œã€‚
- en: The generator is the real loss function hereã€‚ That worksã€‚ All rightï¼Œ let's see
    how theã€‚Discriminator is trained a little bit more going on hereï¼Œ but not muchã€‚
    Notice here it is balancedã€‚ We have zeros and we have onesã€‚ So that isã€‚That's
    a little differenceã€‚ We'll get into thatã€‚ Notice alsoï¼Œ the training data is actually
    being used hereã€‚ These three imagesã€‚ Againã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå™¨æ˜¯çœŸæ­£çš„æŸå¤±å‡½æ•°ã€‚å¥½çš„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹é‰´åˆ«å™¨æ˜¯å¦‚ä½•è¢«è®­ç»ƒçš„ï¼Œè¿™é‡Œæœ‰æ›´å¤šçš„å†…å®¹ï¼Œä½†ä¸å¤šã€‚æ³¨æ„è¿™é‡Œæ˜¯å¹³è¡¡çš„ã€‚æˆ‘ä»¬æœ‰é›¶å’Œä¸€ã€‚è¿™å°±æ˜¯ä¸€ç‚¹ä¸åŒã€‚æˆ‘ä»¬ä¼šæ·±å…¥è®¨è®ºè¿™ä¸€ç‚¹ã€‚è¿˜è¦æ³¨æ„ï¼Œè®­ç»ƒæ•°æ®å®é™…ä¸Šåœ¨è¿™é‡Œè¢«ä½¿ç”¨ã€‚è¿™ä¸‰å¼ å›¾åƒã€‚å†æ¬¡ã€‚
- en: these are not real peopleï¼Œ but pretend that they areã€‚ I don't want to pay licensing
    rights to use real real people just for my diagram Nvidia stylegan is good enoughã€‚
    These are ones that were generated by my generatorã€‚ So this is what the X and
    y looks like for thisã€‚ First of allï¼Œ we need to generate a enough of the fake
    images to fill the batch sizeã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ä¸æ˜¯ç°å®ä¸­çš„äººï¼Œä½†å‡è£…å®ƒä»¬æ˜¯ã€‚æˆ‘ä¸æƒ³ä¸ºäº†æˆ‘çš„å›¾è¡¨æ”¯ä»˜ä½¿ç”¨çœŸå®äººç‰©çš„è®¸å¯æƒï¼ŒNvidiaçš„StyleGANå·²ç»è¶³å¤Ÿäº†ã€‚è¿™äº›æ˜¯ç”±æˆ‘çš„ç”Ÿæˆå™¨ç”Ÿæˆçš„ã€‚è¿™å°±æ˜¯Xå’ŒYåœ¨è¿™é‡Œçš„æ ·å­ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆè¶³å¤Ÿçš„å‡å›¾åƒä»¥å¡«å……æ‰¹å¤„ç†å¤§å°ã€‚
- en: And then we need to put in enough of the real images from the training set to
    also fill out that step sizeã€‚ So really half and half for the batch would be would
    be perfectã€‚ We have now these fake imagesã€‚ real imagesã€‚ All six of theseã€‚ Now
    it'll be bigger for the mini batchã€‚ Not a lot biggerã€‚ Go into the discriminator
    and the discriminator picks these probabilities for these Probabilities for theseã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬éœ€è¦ä»è®­ç»ƒé›†ä¸­æ”¾å…¥è¶³å¤Ÿçš„çœŸå®å›¾åƒï¼Œä»¥å¡«å……è¯¥æ­¥éª¤å¤§å°ã€‚å› æ­¤ï¼Œå¯¹äºæ‰¹å¤„ç†æ¥è¯´ï¼ŒçœŸæ­£çš„å›¾åƒå’Œå‡å›¾åƒå„å ä¸€åŠæ˜¯å®Œç¾çš„ã€‚ç°åœ¨æˆ‘ä»¬æœ‰è¿™äº›å‡å›¾åƒå’ŒçœŸå®å›¾åƒã€‚è¿™å…­ä¸ªç°åœ¨ä¼šæ›´å¤§ï¼Œä»¥é€‚åº”å°æ‰¹å¤„ç†ï¼Œä¸ä¼šå¤§å¾ˆå¤šã€‚è¿›å…¥é‰´åˆ«å™¨ï¼Œé‰´åˆ«å™¨ä¸ºè¿™äº›æ¦‚ç‡è¿›è¡Œé€‰æ‹©ã€‚
- en: you'll see lower and lower probabilities for the generated higher for the other
    as the discriminator gets betterã€‚ But this is where you can't really look at the
    two lossesã€‚ The program that I wroteã€‚ it shows you the loss for the generator
    and the loss for the discriminatorã€‚ It is really essentially an arms raceã€‚ as
    one gets betterï¼Œ the other gets betterã€‚ So ideallyã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€é‰´åˆ«å™¨å˜å¾—æ›´å¥½ï¼Œä½ ä¼šçœ‹åˆ°ç”Ÿæˆçš„æ¦‚ç‡è¶Šæ¥è¶Šä½ï¼Œè€Œå¦ä¸€ä¸ªçš„æ¦‚ç‡è¶Šæ¥è¶Šé«˜ã€‚ä½†è¿™æ—¶ä½ æ— æ³•çœŸæ­£æŸ¥çœ‹è¿™ä¸¤ä¸ªæŸå¤±ã€‚æˆ‘ç¼–å†™çš„ç¨‹åºæ˜¾ç¤ºç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„æŸå¤±ï¼Œè¿™æœ¬è´¨ä¸Šæ˜¯ä¸€åœºå†›å¤‡ç«èµ›ï¼›ä¸€ä¸ªå˜å¾—æ›´å¥½ï¼Œå¦ä¸€ä¸ªä¹Ÿä¼šå˜å¾—æ›´å¥½ã€‚
- en: you'll see those both stay right at around 0ã€‚5 or so if both of those are really
    growing with each otherã€‚ And the ideal would be eventually if the generator is
    so good at generating these that the discriminator just really can't tell the
    differenceer in is getting about a 5050ã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šçœ‹åˆ°è¿™ä¸¤ä¸ªå€¼éƒ½ä¿æŒåœ¨å¤§çº¦0.5å·¦å³ï¼Œå¦‚æœå®ƒä»¬ç¡®å®æ˜¯ç›¸äº’å¢é•¿çš„ã€‚ç†æƒ³çš„æƒ…å†µæ˜¯ï¼Œå¦‚æœç”Ÿæˆå™¨èƒ½å¤Ÿå¦‚æ­¤æœ‰æ•ˆåœ°ç”Ÿæˆè¿™äº›ï¼Œä»¥è‡³äºé‰´åˆ«å™¨æ ¹æœ¬æ— æ³•åˆ†è¾¨ï¼Œå®ƒçš„ç»“æœå°†æ˜¯å¤§çº¦5050ã€‚
- en: So that would be the idealã€‚ So in this caseï¼Œ the X is all of these images concateated
    together real and fakeã€‚ The Y hat is going to be the probabilities that were assigned
    to each of theseã€‚ And then the actual y is going to be the false for the ones
    that we know are not realã€‚ and true for the ones thatã€‚Noï¼Œ in factï¼Œ are real and
    that's how a again is trained that is that technique can be used for just about
    anythingã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°†æ˜¯ç†æƒ³çš„æƒ…å†µã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒXæ˜¯æ‰€æœ‰è¿™äº›å›¾åƒæ‹¼æ¥åœ¨ä¸€èµ·çš„çœŸå®å’Œå‡å›¾åƒã€‚Y hatå°†æ˜¯åˆ†é…ç»™æ¯ä¸ªå›¾åƒçš„æ¦‚ç‡ï¼Œè€Œå®é™…çš„yå°†æ˜¯æˆ‘ä»¬çŸ¥é“ä¸æ˜¯ç°å®çš„å›¾åƒçš„å‡å€¼ï¼Œä»¥åŠå¯¹äºé‚£äº›å®é™…ä¸Šæ˜¯ç°å®çš„å›¾åƒçš„çœŸå€¼ï¼Œè¿™å°±æ˜¯è¯¥æŠ€æœ¯çš„è®­ç»ƒæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºå‡ ä¹ä»»ä½•äº‹æƒ…ã€‚
- en: You create a neural network that takes in seeds and generates random data based
    on those seeds now it helps to use convolution neural networks if you're dealing
    with images possibly helps to use LSTms or even CNNs as well for time series depending
    on what you're trying to generateã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åˆ›å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œè¾“å…¥ç§å­å¹¶åŸºäºè¿™äº›ç§å­ç”Ÿæˆéšæœºæ•°æ®ã€‚å¦‚æœå¤„ç†å›¾åƒï¼Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æœ‰å¸®åŠ©çš„ï¼›è€Œå¯¹äºæ—¶é—´åºåˆ—ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨LSTMæˆ–CNNï¼Œå…·ä½“å–å†³äºä½ æƒ³ç”Ÿæˆä»€ä¹ˆã€‚
- en: and then you use your training dataï¼Œ examples of real data to co-train the discriminator
    with and graduallyã€‚ gradually gradually the neural network learns to generate
    these kind of images and better yetã€‚ the distributions of certain things within
    the data are going to match the original data For exampleã€‚ it's going to learn
    that if part of somebody's face is one particular skin toneã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ ä½¿ç”¨ä½ çš„è®­ç»ƒæ•°æ®ï¼Œå³çœŸå®æ•°æ®çš„ç¤ºä¾‹ï¼Œä¸é‰´åˆ«å™¨è¿›è¡Œå…±åŒè®­ç»ƒï¼Œé€æ¸åœ°ï¼Œç¥ç»ç½‘ç»œå­¦ä¼šç”Ÿæˆè¿™äº›å›¾åƒï¼Œæ›´å¥½çš„æ˜¯ï¼Œæ•°æ®ä¸­æŸäº›ä¸œè¥¿çš„åˆ†å¸ƒå°†ä¸åŸå§‹æ•°æ®åŒ¹é…ã€‚ä¾‹å¦‚ï¼Œå®ƒä¼šå­¦ä¹ åˆ°ï¼Œå¦‚æœæŸäººçš„è„¸éƒ¨æœ‰ç‰¹å®šçš„è‚¤è‰²ã€‚
- en: the other half is probably not going to be a different skin toneã€‚Just likeã€‚If
    we gave itã€‚ say population dataï¼Œ it would learn that as people wereã€‚Olderã€‚ they
    might have different names than younger people because different naming styles
    change differentlyã€‚ or health characteristics might be differentã€‚Allrightã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€åŠå¯èƒ½ä¸ä¼šæœ‰ä¸åŒçš„è‚¤è‰²ã€‚å°±åƒï¼Œå¦‚æœæˆ‘ä»¬æä¾›äººå£æ•°æ®ï¼Œå®ƒä¼šå­¦ä¹ åˆ°ï¼Œéšç€äººä»¬å˜è€ï¼Œä»–ä»¬å¯èƒ½ä¼šæœ‰ä¸åŒäºå¹´è½»äººçš„åå­—ï¼Œå› ä¸ºä¸åŒçš„å‘½åé£æ ¼å˜åŒ–ä¸åŒï¼Œæˆ–å¥åº·ç‰¹å¾å¯èƒ½ä¸åŒã€‚
- en: let's look at the code and see how this actually runsã€‚ So these are the loss
    functions Here we can see we're using cross entropy to train these because its
    logistic primarily The discriminator loss here we create the real and fakeã€‚ just
    like I showed you in the diagramã€‚ Not we're using ones and zerosã€‚ Then the total
    loss is going to be both of these added together because you have to do good on
    the reelã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ä»£ç ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦‚ä½•è¿è¡Œçš„ã€‚è¿™äº›æ˜¯æŸå¤±å‡½æ•°ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä½¿ç”¨äº¤å‰ç†µè¿›è¡Œè®­ç»ƒï¼Œå› ä¸ºä¸»è¦æ˜¯ logisticã€‚è¿™é‡Œçš„åˆ¤åˆ«å™¨æŸå¤±æˆ‘ä»¬åˆ›å»ºäº†çœŸå®å’Œè™šå‡çš„æ ·æœ¬ï¼Œå°±åƒæˆ‘åœ¨å›¾è¡¨ä¸­å±•ç¤ºçš„é‚£æ ·ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ä¸€å’Œé›¶ã€‚ç„¶åæ€»æŸå¤±å°†æ˜¯è¿™ä¸¤ä¸ªåŠ åœ¨ä¸€èµ·ï¼Œå› ä¸ºä½ å¿…é¡»åœ¨çœŸå®æ ·æœ¬ä¸Šè¡¨ç°è‰¯å¥½ã€‚
- en: So you have to do good on the fakesã€‚ And that's essentially all there is to
    itã€‚ we're adding the ones and the zeros for the reels and the fakesã€‚ and that
    is going to be your lossã€‚ That is what the training is going to attempt to minimizeã€‚
    Nowï¼Œ the generator loss is even easierã€‚ It's just cross entropyã€‚ And notice we
    do it just on onesï¼Œ because like I saidï¼Œ it's unbalancedã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¿…é¡»åœ¨è™šå‡æ ·æœ¬ä¸Šè¡¨ç°è‰¯å¥½ã€‚è¿™å°±æ˜¯ä¸€åˆ‡çš„è¦ç‚¹ã€‚æˆ‘ä»¬å°†çœŸå®å’Œè™šå‡çš„ä¸€ä¸é›¶ç›¸åŠ ï¼Œè¿™å°†æ˜¯ä½ çš„æŸå¤±ã€‚è®­ç»ƒå°†å°è¯•æœ€å°åŒ–è¿™ä¸ªæŸå¤±ã€‚ç°åœ¨ï¼Œç”Ÿæˆå™¨çš„æŸå¤±æ›´ç®€å•ã€‚å®ƒåªæ˜¯äº¤å‰ç†µã€‚æ³¨æ„æˆ‘ä»¬åªåœ¨ä¸€ä¸Šè¿›è¡Œï¼Œå› ä¸ºæ­£å¦‚æˆ‘æ‰€è¯´ï¼Œè¿™æ˜¯ä¸å¹³è¡¡çš„ã€‚
- en: but that's okayã€‚ works just fineã€‚ And we are training a just that we would like
    for ones on the fake outputã€‚ this is backwardsã€‚ these are fakeï¼Œ but these are
    onesï¼Œ but that is what weã€‚ğŸ˜Šã€‚![](img/618ec4df027e5ab5cc37e5905fefc1e4_4.png)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ²¡å…³ç³»ï¼Œæ•ˆæœå¾ˆå¥½ã€‚æˆ‘ä»¬è®­ç»ƒçš„æ˜¯å¸Œæœ›åœ¨è™šå‡è¾“å‡ºä¸Šå¾—åˆ°ä¸€ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯åå‘çš„ã€‚è¿™äº›æ˜¯è™šå‡çš„ï¼Œä½†è¿™äº›æ˜¯ä¸€ï¼Œä½†è¿™å°±æ˜¯æˆ‘ä»¬æ‰€è¦çš„ã€‚ğŸ˜Š![](img/618ec4df027e5ab5cc37e5905fefc1e4_4.png)
- en: Aspire to we want to fool the discriminatorã€‚ We use atom on both of theseã€‚ Nowã€‚
    one question that I got a lot on the previous version of this people try to increase
    the resolutionã€‚ do other things as you increase resolution on these or do other
    changesã€‚ you're you're going have to retune I have these primarily tuned for the
    different resolutions that I have indicated up higher in the code on the symbolic
    constant for for the magnification factorã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¬ºéª—åˆ¤åˆ«å™¨ã€‚æˆ‘ä»¬åœ¨è¿™ä¸¤ä¸ªç½‘ç»œä¸Šéƒ½ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ã€‚ç°åœ¨ï¼Œæˆ‘åœ¨ä¹‹å‰çš„ç‰ˆæœ¬ä¸­å¾—åˆ°äº†å¾ˆå¤šé—®é¢˜ï¼Œäººä»¬è¯•å›¾æé«˜åˆ†è¾¨ç‡ã€‚å½“ä½ æé«˜è¿™äº›çš„åˆ†è¾¨ç‡æˆ–è¿›è¡Œå…¶ä»–æ›´æ”¹æ—¶ï¼Œä½ å°†ä¸å¾—ä¸é‡æ–°è°ƒæ•´ã€‚æˆ‘ä¸»è¦é’ˆå¯¹æˆ‘åœ¨ä»£ç ä¸­ä¸Šæ–¹çš„ç¬¦å·å¸¸é‡æ‰€æŒ‡ç¤ºçš„ä¸åŒåˆ†è¾¨ç‡è¿›è¡Œäº†è°ƒæ•´ã€‚
- en: but you'll probably have to change these if you make the resolution higher in
    particularã€‚ you're going to probably have to make these smaller learning ratesã€‚
    This is what an individual training step looks like and I want to show you how
    we're training here because this is very different than how we did this in previous
    neural networks that we've trained The reason we're going through these extra
    steps and dealing directly with the gradients is because we don't want to modify
    the weights of the wrong neural networksã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¦‚æœä½ æé«˜åˆ†è¾¨ç‡ï¼Œç‰¹åˆ«æ˜¯ï¼Œä½ å¯èƒ½éœ€è¦å°†è¿™äº›å­¦ä¹ ç‡è°ƒæ•´å¾—æ›´å°ã€‚è¿™æ˜¯å•ä¸ªè®­ç»ƒæ­¥éª¤çš„æ ·å­ï¼Œæˆ‘æƒ³å‘ä½ å±•ç¤ºæˆ‘ä»¬åœ¨è¿™é‡Œå¦‚ä½•è®­ç»ƒï¼Œå› ä¸ºè¿™ä¸æˆ‘ä»¬ä¹‹å‰è®­ç»ƒçš„ç¥ç»ç½‘ç»œæœ‰å¾ˆå¤§ä¸åŒã€‚æˆ‘ä»¬ç»è¿‡è¿™äº›é¢å¤–æ­¥éª¤å¹¶ç›´æ¥å¤„ç†æ¢¯åº¦ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬ä¸æƒ³ä¿®æ”¹é”™è¯¯ç¥ç»ç½‘ç»œçš„æƒé‡ã€‚
- en: We've got two neural networks at play in both of these training operationsã€‚
    We do we train both of these completely separatelyï¼Œ but we do not want crossoverã€‚
    we do not want we want to be only modifying one of these neural network weights
    at a timeã€‚ And we use for this the gradient tapeã€‚ And I talk about this a little
    bit during one of the in-class meetingsã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸¤ä¸ªè®­ç»ƒæ“ä½œä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªç¥ç»ç½‘ç»œåœ¨å‘æŒ¥ä½œç”¨ã€‚æˆ‘ä»¬å®Œå…¨åˆ†å¼€è®­ç»ƒè¿™ä¸¤ä¸ªç½‘ç»œï¼Œä½†æˆ‘ä»¬ä¸å¸Œæœ›äº¤å‰ã€‚æˆ‘ä»¬åªå¸Œæœ›ä¸€æ¬¡ä¿®æ”¹ä¸€ä¸ªç¥ç»ç½‘ç»œçš„æƒé‡ã€‚ä¸ºæ­¤æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦å¸¦ã€‚åœ¨è¯¾å ‚ä¼šè®®ä¸­æˆ‘è°ˆåˆ°è¿‡è¿™ä¸ªé—®é¢˜ã€‚
- en: but this is essentially how Tensorflow does automatic differentiationã€‚ So it
    is calculating the derivatives for you for your neural network forever complicated
    you end up making it And I have other videos talking about thisã€‚ Like how do you
    create how do you take a derivativeã€‚ and I'll put a link to that video as well
    in the description to this oneã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™æœ¬è´¨ä¸Šå°±æ˜¯ Tensorflow å¦‚ä½•è¿›è¡Œè‡ªåŠ¨å¾®åˆ†ã€‚æ‰€ä»¥å®ƒä¸ºä½ çš„ç¥ç»ç½‘ç»œè®¡ç®—å¯¼æ•°ï¼Œè¿™ä¸ªè¿‡ç¨‹å¤æ‚æ— æ¯”ï¼Œæœ€ç»ˆä½ ä¼šä½¿å…¶å˜å¾—å¦‚æ­¤ã€‚æˆ‘è¿˜æœ‰å…¶ä»–è§†é¢‘è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚æ¯”å¦‚ï¼Œå¦‚ä½•åˆ›å»ºå¯¼æ•°ï¼Œä»¥åŠæˆ‘ä¼šåœ¨è¿™ä¸ªè§†é¢‘çš„æè¿°ä¸­æä¾›è¯¥è§†é¢‘çš„é“¾æ¥ã€‚
- en: But this shows you basically how how to do thisã€‚ So we'rere creating two tapes
    The reason they're called tapes is it's almost like it's recording all of the
    mathematical functions going through andã€‚Neural networks and then it unwinds it
    backwards to figure out what the derivative isã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™åŸºæœ¬ä¸Šå±•ç¤ºäº†ä½ å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥æˆ‘ä»¬æ­£åœ¨åˆ›å»ºä¸¤ä¸ªæ¢¯åº¦å¸¦ã€‚ä¹‹æ‰€ä»¥ç§°å…¶ä¸ºå¸¦ï¼Œæ˜¯å› ä¸ºå®ƒå‡ ä¹åƒæ˜¯åœ¨è®°å½•æ‰€æœ‰é€šè¿‡çš„æ•°å­¦å‡½æ•°ï¼Œç„¶åå‘åå±•å¼€ä»¥æ‰¾å‡ºå¯¼æ•°æ˜¯ä»€ä¹ˆã€‚
- en: Then we basically createï¼Œ we're dealing with the discriminatorã€‚ The discriminator
    has the two sidesã€‚ so it has the real output in the fake output that you are giving
    itã€‚ So we need to know what the output was for the real imagesã€‚ We need to know
    what the output was for the fake images and then that lets us essentially take
    the loss for the generatorã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åŸºæœ¬ä¸Šåˆ›å»ºï¼Œå¤„ç†é‰´åˆ«å™¨ã€‚é‰´åˆ«å™¨æœ‰ä¸¤ä¸ªæ–¹é¢ã€‚æ‰€ä»¥å®ƒæœ‰çœŸå®è¾“å‡ºå’Œä½ æä¾›çš„è™šå‡è¾“å‡ºã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦çŸ¥é“çœŸå®å›¾åƒçš„è¾“å‡ºæ˜¯ä»€ä¹ˆã€‚æˆ‘ä»¬éœ€è¦çŸ¥é“è™šå‡å›¾åƒçš„è¾“å‡ºæ˜¯ä»€ä¹ˆï¼Œç„¶åè¿™è®©æˆ‘ä»¬èƒ½å¤Ÿä¸ºç”Ÿæˆå™¨è®¡ç®—æŸå¤±ã€‚
- en: the generator because it's only dealing with fakeã€‚ The generator can't generate
    real imagesã€‚ it can only generate fake onesã€‚ We're calculating the loss on thatã€‚
    we're calculating the loss on both types of outputs for the discriminator because
    it sees both typesã€‚ We cal the gradients of the generatorã€‚ We calculate the gradients
    of the discriminator so that we're not crossing those over and then we apply the
    gradientsã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå™¨å› ä¸ºåªå¤„ç†è™šå‡ã€‚ç”Ÿæˆå™¨æ— æ³•ç”ŸæˆçœŸå®å›¾åƒã€‚å®ƒåªèƒ½ç”Ÿæˆè™šå‡å›¾åƒã€‚æˆ‘ä»¬åœ¨æ­¤è®¡ç®—æŸå¤±ã€‚æˆ‘ä»¬ä¸ºé‰´åˆ«å™¨çš„ä¸¤ç§è¾“å‡ºç±»å‹è®¡ç®—æŸå¤±ï¼Œå› ä¸ºå®ƒçœ‹åˆ°äº†è¿™ä¸¤ç§ç±»å‹ã€‚æˆ‘ä»¬è®¡ç®—ç”Ÿæˆå™¨çš„æ¢¯åº¦ã€‚æˆ‘ä»¬è®¡ç®—é‰´åˆ«å™¨çš„æ¢¯åº¦ï¼Œä»¥ä¾¿ä¸äº¤å‰è¿™äº›ï¼Œç„¶åæˆ‘ä»¬åº”ç”¨æ¢¯åº¦ã€‚
- en: and this is essentially one step of trainã€‚ We're getting a little more manual
    hereã€‚ We're not letting Tensorflow and Keraã€‚Actually apply the gradients for usã€‚
    We're actually doing thisã€‚ So this is a little bit behind the scenes of how you
    actually modify the weights based on theseã€‚ These apply gradientsã€‚ that is what
    is is happeningã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬è´¨ä¸Šæ˜¯è®­ç»ƒçš„ä¸€ä¸ªæ­¥éª¤ã€‚æˆ‘ä»¬å˜å¾—æ›´åŠ æ‰‹åŠ¨ã€‚æˆ‘ä»¬ä¸è®©TensorFlowå’ŒKerasä¸ºæˆ‘ä»¬åº”ç”¨æ¢¯åº¦ã€‚å®é™…ä¸Šæˆ‘ä»¬æ˜¯åœ¨è‡ªå·±åšè¿™ä»¶äº‹ã€‚è¿™æœ‰ç‚¹å¹•åæ­ç§˜ï¼Œå±•ç¤ºäº†å¦‚ä½•æ ¹æ®è¿™äº›åº”ç”¨æ¢¯åº¦æ¥ä¿®æ”¹æƒé‡ã€‚è¿™å°±æ˜¯æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…ã€‚
- en: Then training it is relatively simple compared to thatã€‚ We do create a number
    of fixed seedsã€‚ So this lets us track the same facesã€‚ You you see this video that
    I have playing over top of this oneã€‚ This is showing you how these faces are evolving
    as it actually trainsã€‚ So I created these fixed seeds so that these images that
    you see here evolvingã€‚ are consistentã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè®­ç»ƒç›¸å¯¹ç®€å•ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€äº›å›ºå®šç§å­ã€‚è¿™è®©æˆ‘ä»¬èƒ½å¤Ÿè·Ÿè¸ªç›¸åŒçš„é¢å­”ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªè§†é¢‘åœ¨æ’­æ”¾ã€‚è¿™ä¸ªè§†é¢‘å±•ç¤ºäº†è¿™äº›é¢å­”åœ¨å®é™…è®­ç»ƒä¸­æ˜¯å¦‚ä½•æ¼”å˜çš„ã€‚æ‰€ä»¥æˆ‘åˆ›å»ºäº†è¿™äº›å›ºå®šç§å­ï¼Œä»¥ä¾¿ä½ çœ‹åˆ°çš„è¿™äº›æ¼”å˜å›¾åƒæ˜¯ä¸€è‡´çš„ã€‚
- en: Otherwiseï¼Œ we just see a random mess of different facesã€‚ but this shows you
    how individual seeds are actually evolving over timeã€‚ We go through the requested
    number of epochsã€‚ We are keeping track of how much time is spent on oneã€‚ Def use
    a GPU use Googlego coabab for thisã€‚ If you don't have a GPU on your local computerã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¦åˆ™ï¼Œæˆ‘ä»¬åªä¼šçœ‹åˆ°ä¸åŒé¢å­”çš„éšæœºæ··ä¹±ã€‚ä½†è¿™å±•ç¤ºäº†ä¸ªåˆ«ç§å­æ˜¯å¦‚ä½•éšæ—¶é—´æ¼”å˜çš„ã€‚æˆ‘ä»¬ç»å†äº†è¯·æ±‚çš„epochæ•°é‡ã€‚æˆ‘ä»¬è®°å½•äº†åœ¨ä¸€ä¸ªepochä¸ŠèŠ±è´¹çš„æ—¶é—´ã€‚ç¡®å®ä½¿ç”¨GPUï¼Œä½¿ç”¨Google
    Colabæ¥åšè¿™ä»¶äº‹ã€‚å¦‚æœä½ åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šæ²¡æœ‰GPUã€‚
- en: It will run so much fasterã€‚ and then weã€‚ğŸ˜Šã€‚![](img/618ec4df027e5ab5cc37e5905fefc1e4_6.png)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿è¡Œå¾—æ›´å¿«ã€‚ç„¶åæˆ‘ä»¬ã€‚ğŸ˜Šã€‚![](img/618ec4df027e5ab5cc37e5905fefc1e4_6.png)
- en: Loop through for each epochã€‚ we loop through each batch that we divided up earlierã€‚
    We divided the images into batches because each epoch is a complete set of batches
    that takes us over the entire training set We calculate the loss for the generator
    and the discriminator and we keep displaying this as we goã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ¯ä¸ªepochè¿›è¡Œå¾ªç¯ã€‚æˆ‘ä»¬éå†ä¹‹å‰åˆ’åˆ†çš„æ¯ä¸ªæ‰¹æ¬¡ã€‚æˆ‘ä»¬å°†å›¾åƒåˆ’åˆ†ä¸ºæ‰¹æ¬¡ï¼Œå› ä¸ºæ¯ä¸ªepochæ˜¯è¦†ç›–æ•´ä¸ªè®­ç»ƒé›†çš„å®Œæ•´æ‰¹æ¬¡é›†åˆã€‚æˆ‘ä»¬è®¡ç®—ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„æŸå¤±ï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­æŒç»­æ˜¾ç¤ºã€‚
- en: So you can see here you have the losses on each of these Now these are not accuracy
    lossesã€‚ So I said earlier you aspire to maybe a 5050 on each of these this is
    more of a log loss that you're seeing here but you could calculate accuracy loss
    if you wanted to as wellã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œçš„æ¯ä¸ªæŸå¤±ã€‚è¿™äº›ä¸æ˜¯å‡†ç¡®ç‡æŸå¤±ã€‚æˆ‘ä¹‹å‰æåˆ°è¿‡ï¼Œä½ å¯èƒ½å¸Œæœ›åœ¨è¿™äº›ä¸Šè¾¾åˆ°50å¯¹50ï¼Œè¿™æ›´å¤šçš„æ˜¯ä½ çœ‹åˆ°çš„å¯¹æ•°æŸå¤±ï¼Œä½†å¦‚æœä½ æƒ³çš„è¯ï¼Œä¹Ÿå¯ä»¥è®¡ç®—å‡†ç¡®ç‡æŸå¤±ã€‚
- en: but you're going to optimize on on the log loss log loss and cross entropy are
    essentially the same rangeã€‚ and it goes through hereã€‚ you never really get to
    these to sort of these two being even and that's because really like like I said
    earlierã€‚ you're going to get to faces about like this which which is pretty amazing
    that it isã€‚trainining up a neural network that never sees the training set to
    actually be able to create this degree more or less of realism in the faces now
    to actually tune it and get the right faces there's a lot of steps in that and
    I have some papers linked to that would help you if you really really really want
    to find tune this and go deep on creating GNs that are realistic you're going
    definitely need to buy some cloud time to get enough processing going or you can
    simply pull in the Google stylegan weights I'm sorry Nvidia stylegan weights so
    that you can just transfer and all of a sudden have a neural network that has
    had considerable high end training done on it to produce very realistic looking
    faces I might do a video in the future about how to really eke out and get the
    really high resolutiongan built completely from scratch that would be that would
    be beyond the boundã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ å°†ä¼˜åŒ–æ—¥å¿—æŸå¤±ï¼Œæ—¥å¿—æŸå¤±å’Œäº¤å‰ç†µæœ¬è´¨ä¸Šæ˜¯ç›¸åŒçš„èŒƒå›´ã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨è¿™é‡Œè¿›è¡Œã€‚ä½ å®é™…ä¸Šå¹¶ä¸èƒ½è®©è¿™ä¸¤ä¸ªå®Œå…¨ä¸€è‡´ï¼Œè¿™å°±æ˜¯æˆ‘ä¹‹å‰æ‰€è¯´çš„ã€‚ä½ æœ€ç»ˆä¼šå¾—åˆ°åƒè¿™æ ·çš„é¢å­”ï¼Œè¿™å®åœ¨æ˜¯å¤ªä»¤äººæƒŠè®¶äº†ã€‚è®­ç»ƒä¸€ä¸ªä»æœªè§è¿‡è®­ç»ƒé›†çš„ç¥ç»ç½‘ç»œï¼Œå®é™…ä¸Šèƒ½å¤Ÿåˆ›é€ å‡ºè¿™ç§ç¨‹åº¦çš„é€¼çœŸé¢å­”ã€‚è¦çœŸæ­£è°ƒæ•´å¹¶è·å¾—æ­£ç¡®çš„é¢å­”ï¼Œè¿™é‡Œé¢æœ‰å¾ˆå¤šæ­¥éª¤ã€‚æˆ‘æœ‰ä¸€äº›ç›¸å…³è®ºæ–‡é“¾æ¥ï¼Œå¦‚æœä½ çœŸçš„éå¸¸æƒ³è¦å¾®è°ƒå¹¶æ·±å…¥ç ”ç©¶åˆ›å»ºé€¼çœŸGANï¼Œè‚¯å®šéœ€è¦è´­ä¹°ä¸€äº›äº‘è®¡ç®—æ—¶é—´ï¼Œä»¥ä¾¿è·å¾—è¶³å¤Ÿçš„å¤„ç†èƒ½åŠ›ï¼Œæˆ–è€…ä½ å¯ä»¥ç®€å•åœ°å¼•å…¥è°·æ­Œçš„StyleGANæƒé‡ï¼ŒæŠ±æ­‰ï¼Œæ˜¯NVIDIAçš„StyleGANæƒé‡ï¼Œè¿™æ ·ä½ å°±å¯ä»¥è½¬ç§»ï¼Œå¹¶çªç„¶æ‹¥æœ‰ä¸€ä¸ªç»è¿‡é«˜ç«¯è®­ç»ƒçš„ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿç”Ÿæˆéå¸¸é€¼çœŸçš„é¢å­”ã€‚æœªæ¥æˆ‘å¯èƒ½ä¼šåšä¸€ä¸ªå…³äºå¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºé«˜åˆ†è¾¨ç‡GANçš„è§†é¢‘ï¼Œè¿™å°†è¶…å‡ºç•Œé™ã€‚
- en: Of what my class gets into itã€‚ if this is something you're interested in maybe
    seen as a side videoã€‚ definitely click the likeï¼Œ I pay attention to those so that
    I get an idea of what you're interested inã€‚ Thanks for watching this video in
    the next videoï¼Œ we're going to see how to use transfer learning and take really
    cool software created by NviDdia stylegan and just immediately transfer those
    weights into your neural network so that you're able to create very realistic
    looking faces like theseã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è¯¾ç¨‹å°†æ¢è®¨ä»€ä¹ˆã€‚å¦‚æœä½ å¯¹æ­¤æ„Ÿå…´è¶£ï¼Œå¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ªé™„åŠ è§†é¢‘ã€‚è¯·ä¸€å®šç‚¹èµï¼Œæˆ‘ä¼šå…³æ³¨è¿™äº›ï¼Œä»¥äº†è§£ä½ ä»¬çš„å…´è¶£ã€‚æ„Ÿè°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨è¿ç§»å­¦ä¹ ï¼Œåˆ©ç”¨NVIDIAçš„StyleGANè½¯ä»¶ï¼Œå°†è¿™äº›æƒé‡ç«‹å³è½¬ç§»åˆ°ä½ çš„ç¥ç»ç½‘ç»œä¸­ï¼Œä»¥ä¾¿ä½ èƒ½å¤Ÿåˆ›å»ºå¦‚è¿™äº›ä¸€æ ·éå¸¸é€¼çœŸçš„é¢å­”ã€‚
- en: ğŸ˜Šï¼ŒThank you for watching the videoã€‚ And if you want to see more of thisã€‚ please
    subscribe to my channelã€‚ Thank you muchã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šæ„Ÿè°¢è§‚çœ‹è§†é¢‘ã€‚å¦‚æœä½ æƒ³çœ‹åˆ°æ›´å¤šå†…å®¹ï¼Œè¯·è®¢é˜…æˆ‘çš„é¢‘é“ã€‚éå¸¸æ„Ÿè°¢ã€‚
