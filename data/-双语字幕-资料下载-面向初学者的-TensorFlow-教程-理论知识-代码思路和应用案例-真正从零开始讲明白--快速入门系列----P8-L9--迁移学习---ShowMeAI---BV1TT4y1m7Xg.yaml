- en: 【双语字幕+资料下载】面向初学者的 TensorFlow 教程，理论知识、代码思路和应用案例，真正从零开始讲明白！＜快速入门系列＞ - P8：L9- 迁移学习
    - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】面向初学者的 TensorFlow 教程，理论知识、代码思路和应用案例，真正从零开始讲明白！＜快速入门系列＞ - P8：L9- 迁移学习
    - ShowMeAI - BV1TT4y1m7Xg
- en: '![](img/61fab98aab26950654922e0fb57a2416_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_0.png)'
- en: 🎼，Hey， guys， and welcome to a new Tensorflowlow tutorial。 Today。 we will continue
    where we left off last time and applied transfer learning together get a model
    with a good performance。😊，So I highly recommend that you watch the last tutorial
    first if you haven't already。 And as a quick recap。 So we used a dataset set from
    Kegle with Lego Star Wars Minfi。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 🎼，大家好，欢迎来到新的 Tensorflowlow 教程。今天，我们将继续上次的内容，一起应用迁移学习，获得一个良好表现的模型。😊，所以如果你还没有看过上一个教程，我强烈推荐你先去看一下。作为快速回顾，我们使用了来自
    Kegle 的一个数据集，包含乐高星球大战 Minfi。
- en: and we applied our own convolutional neural net。 and then we had the problem
    that for the training。 we got a very good accuracy。 So this was close to a 100%。
    but it didn't perform well on our validation data set and also for the final evaluation
    with the test data set。 We only got an accuracy of 40%。 So this is not very good。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了自己的卷积神经网络。然后我们遇到的问题是，在训练中，我们得到了非常好的准确率。接近 100%。但在验证数据集上的表现不好，在最终测试数据集的评估中，我们的准确率只有
    40%。这不是很好。
- en: So now what we want to do is we want to apply transfer learning to improve our
    model。😊。And transfer learning is a very nice， simple but very powerful technique。So
    the concept is that we use a model that has been already trained and this is probably
    a very good model that with a lot of features and that also has been trained on
    a lot of data and now what we do here is so we we take this model and then we
    only modify the last layers so we cut them out and then apply our own classification
    layers at the end and train only these layers at the end so with this our training
    can be very quick but we can also get the power of the rest of the neural network
    that is already pretrained So this is the whole concept behind transfer learning
    and now I show you how we do that with Ks so the first thing。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们要做的是应用迁移学习来改善我们的模型。😊。迁移学习是一种非常好的，简单但非常强大的技术。其概念是，我们使用一个已经训练好的模型，这个模型可能是一个具有许多特征并且在大量数据上训练的非常好的模型。现在我们所做的就是，取这个模型，然后只修改最后的层，剪掉它们，然后在最后应用我们自己的分类层，并只训练这些层。这样，我们的训练可以非常快速，同时也能利用已经预训练的神经网络的其他部分。所以这就是迁移学习的整个概念，接下来我将向你展示如何使用
    Keras 实现这一点，所以第一步。
- en: We want to do is to load a pretrain model。 So there are already some models
    available in Ks。 For example， the popular Vg G16 model。 So you get this by saying
    Tensorflow kas applications and then the name of our model。 So if we download
    the if we call this， then it's downloading this model and saves it in your folder。
    So let's run this and print this summary。 And here we have the。Archiecture。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的是加载一个预训练模型。Keras 中已经有一些模型可用。例如，流行的 Vgg16 模型。通过说 Tensorflow keras applications
    和我们的模型名称，你可以获取这个。如果我们调用它，系统会下载该模型并将其保存在你的文件夹中。让我们运行它并打印摘要。这里是。架构。
- en: So you can have a look at that。And now what we want to do here is， as I said，
    we want to。![](img/61fab98aab26950654922e0fb57a2416_2.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以看看这个。现在我们要做的是，如我所说，我们想要。![](img/61fab98aab26950654922e0fb57a2416_2.png)
- en: '![](img/61fab98aab26950654922e0fb57a2416_3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_3.png)'
- en: Delette the last layer。 so you can delete only the very last layer。 or you can
    also delete more and then apply your own。 So in this example， we only take out
    the last。Layer， so this dense layer and then apply our own dense layer with five
    different outputs。 because in our example， we have five different classes。 And
    right now。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 删除最后一层。你可以只删除最后一层，或者也可以删除更多层，然后应用你自己的。所以在这个例子中，我们只删除最后一层，密集层，然后应用我们自己的具有五个不同输出的密集层，因为在我们的例子中，我们有五个不同的类别。现在。
- en: this is a Kaas functional model。 So I already talked about the functional API。
    And if you haven't。 then I also recommend to watch this one first and I will put
    the link in the description。 But I also said that we can easily convert this to
    a sequential model。 So we can do this by setting up a new model and say this is
    a sequential model。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 Keras 功能模型。我已经谈到了功能 API。如果你还没有看过，我也建议你先看这个，我会把链接放在描述中。但我也说过，我们可以轻松地将其转换为序贯模型。我们可以通过设置一个新模型并说这是一个序贯模型来做到这一点。
- en: and then we iterate over all the layers except the last one。 So this is not
    included and say model and layer。 So now let's run this and print the summary。
    and then。It should be the same， except that you don't see this layer， so。Oh sorry。
    So here。 this is the original summary。 and here we have this as last layer with10
    outputs。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们遍历所有层，除了最后一层。因此最后一层不包括在内，称为模型和层。现在让我们运行这个并打印摘要。然后，它应该是相同的，除了你看不到这一层。哦，对不起。所以这里，这是原始摘要。这里我们有作为最后一层的10个输出。
- en: And now in our case， this should be the last layer。 So let's have a look。 And
    yes， here this。 This is the last layer。 And now what we want to do here is we
    want to set all of those layers to trainable equals falses。 because we don't have
    to retrain these again。 we only have to train our new classification layer。 So
    we loop over all layers and say layer trainable equals false。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在我们的案例中，这应该是最后一层。那么我们来看一下。是的，这就是最后一层。现在我们要做的是将所有这些层的可训练属性设置为`false`。因为我们不需要重新训练它们。我们只需要训练我们的新分类层。所以我们遍历所有层，并将层的可训练属性设置为`false`。
- en: '![](img/61fab98aab26950654922e0fb57a2416_5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_5.png)'
- en: '![](img/61fab98aab26950654922e0fb57a2416_6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_6.png)'
- en: And for example， here， you see the trainable parameters and the nontrainable
    parameters。 And now if we do this and print the summary again。 then we see that
    now all of our parameters are non trainable。 and now we add a last dense layer。
    And by default。 Now this is trainable again。 And then again。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里你可以看到可训练参数和不可训练参数。现在如果我们这样做并再次打印摘要，我们会发现现在所有的参数都是不可训练的。现在我们添加最后一个密集层。默认情况下，这又是可训练的。然后再一次。
- en: we set up a loss and a optimizer and compile our model。And then so last time
    I told you how we can use this。Image data generator and then call this dot flow
    from directory function。 And this very easily loads the images from a directory。
    and we can also apply preprocessing and rescaling and even image augmentation
    here。 So last time we applied this rescaling here。And now this time， what we want
    to do。 we want to apply the same pre processingcessing function as in our base
    model。 So in this weci G net。So， and we also get this by saying this is available
    in tensor flowcaras applications than the name of our model and then dot pre process
    input。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置损失函数和优化器并编译我们的模型。上次我告诉你们如何使用这个图像数据生成器，然后调用这个`flow from directory`函数。这很简单地从目录加载图像。我们也可以在这里应用预处理、重缩放，甚至图像增强。所以上次我们在这里应用了重缩放。这次我们想做的是，应用与基础模型相同的预处理函数。在这个`weci
    G net`中。因此，我们也可以通过说这个在`tensorflow.keras`应用程序中可用，后面接我们模型的名称和`preprocess_input`来获取。
- en: So this is our pre processing function， and then we can give this to our image
    data generator for with the argument pre processinging function。 So this is the
    same for our training validation and test set。And then we call this flow from
    directory for each one。 And this is。 these are the same arguments as last time。
    And now this is loading them the images from the different models。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的预处理函数，然后我们可以将其提供给我们的图像数据生成器，作为预处理函数的参数。这对于我们的训练、验证和测试集都是一样的。然后我们为每个数据集调用`flow
    from directory`。这些参数与上次相同。现在我们正在从不同的模型加载图像。
- en: I didn't run this cell。 So let's run this and this again。 And now we have it。
    And now， again。 this is the same as last time。 So we fitted our model。 and we
    apply this early stopping call back。 So if our validation loss does not increase
    for or improve for5 epos。 Then it does an early stopping。 So let's apply this
    again here。 And now let's fit our data。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有运行这个单元。所以我们来运行这个和这个。现在我们完成了。再一次。这和上次是一样的。所以我们训练了我们的模型，并应用了提前停止的回调。如果我们的验证损失在5个周期内没有增加或改善，那么就会提前停止。所以我们再在这里应用一次。现在让我们来拟合我们的数据。
- en: So this is giving an error。 You must compile your model before training and
    testing。 So I think I already did this in this cell。 So let's run this again。
    and run this and this and now our training。 So now it's working。 I guess I didn't
    run the cell the first time。 So now let's see how our transfer learning model
    is doing。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这出现了一个错误。你必须在训练和测试之前编译你的模型。我想我在这个单元中已经做过了。所以我们再运行一次。运行这个和这个，现在是我们的训练。现在它工作了。我想我第一次没有运行这个单元。现在让我们看看我们的迁移学习模型表现如何。
- en: All right。 And now our training is done。 And again， we had an early stopping。
    So we see that our accuracy on the test data set is 100 per。 so perfect。And the
    validation accuracy is almost 94%。 So yeah， I think this is now very good。 And
    it's a lot better than last time。 And now we specified 30 epochs。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。现在我们的训练完成了。我们再次进行了早期停止。所以我们看到测试数据集上的准确率是 100%。完美。而验证准确率几乎是 94%。所以，我认为这现在非常好。这比上次好多了。现在我们设置了
    30 个周期。
- en: but then our validation loss had the lowest value here。 And then it didn't get
    better over the next five epoch。 So we set patients is 5。 And that's why that
    the early stopping。 So we already had a validation accuracy of 100% in the second
    epoch。 But this might be the case because we don't have so many images available
    in our validation data set。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们的验证损失在这里是最低的值。然后在接下来的五个周期内没有改善。所以我们设置了患者值为 5。这就是早期停止的原因。因此我们在第二个周期时已经获得了
    100% 的验证准确率。但这可能是因为我们的验证数据集中可用的图像不多。
- en: So I think this result is not very reliable。 But yeah。 I think we can see how
    powerful this transfer learning is。 because last time we had problem with overfitting
    so that we had a。Good accuracy on the test。 on the training data， but not on the
    validation data and not on the test data。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我认为这个结果不是很可靠。但我认为我们可以看到迁移学习是多么强大。因为上次我们遇到了过拟合的问题，以至于我们在训练数据上有良好的准确率，但在验证数据和测试数据上却没有。
- en: And now with a transfer learning technique， we can get this after only two epochs
    And even in this example where we don't have so many images available。 and this
    is very good。 So now let's evaluate our model on the test data set。 And we see
    in this case， we got 100 percent on accuracy on the test data。 So I guess I' am
    a little bit lucky this time。 But yeah。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过迁移学习技术，我们在仅仅两个周期后就得到了这个结果，即使在这个例子中我们没有那么多可用的图像。这是非常好的。那么现在让我们在测试数据集上评估我们的模型。我们看到在这种情况下，测试数据的准确率为
    100%。所以我想这次我有点幸运。但也确实如此。
- en: we see how powerful this technique is again and how simple it is。 So you load
    a pretrained model。😊。And。So。So this one。 and then we converted it in this case，
    to a sequential model。 So you don't have to do this。 but this makes it a little
    bit simpler for you because I know the sequential API is easier to understand。And
    then we excluded the last layer and added our own dense layer。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次看到这种技术是多么强大，以及它是多么简单。所以你加载一个预训练的模型。😊。然后，我们在这种情况下将其转换为顺序模型。所以你不必这样做，但这样对你来说会简单一些，因为我知道顺序
    API 更容易理解。然后我们排除了最后一层，添加了我们自己的密集层。
- en: and then we also set layers trainable to false except for our last dense layer。
    And then we did a new training。And as a homework， you can try out other pretrain
    nets。 So。 for example， the mobile net version 2 is another very popular net。 so
    you can go to this link And then here you have all the different available net。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们还将层的可训练性设置为 false，除了最后的密集层。然后我们进行了新的训练。作为家庭作业，你可以尝试其他预训练的网络。所以，比如说，移动网络版本
    2 是另一个非常受欢迎的网络。你可以访问这个链接，在这里你可以找到所有不同的可用网络。
- en: So here's our V G16， you also have reachi G19。 you have the mobile net and the
    mobile net version 2 and the resnet。 So yeah， try them out for itself。 and I can
    tell you that you might run into a problem when you try to convert your model
    to a sequential model because this only works if the architecture of your model
    is linear。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是我们的 V G16，你也可以使用 G19。你有移动网络和移动网络版本 2 以及 ResNet。所以，试试它们。我可以告诉你，当你尝试将模型转换为顺序模型时，可能会遇到问题，因为这仅在模型架构是线性时有效。
- en: and if you don't know how you do this， if your architecture is not linear。 then
    you can watch my tutorial about the functional API because there I gave you a
    tip at the end and showed you how you can still。Do transfer learning with a functional
    model。 So yeah check it out and let me know if you can also get a accuracy of
    100% and I hope to see you in the next video then。 And if you enjoy this video，
    please hit the like button and consider subscribing to the channel bye。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道如何操作，如果你的架构不是线性的，那么你可以观看我关于功能 API 的教程，因为我在最后给了你一个提示，并展示了如何在功能模型中进行迁移学习。所以，看看这个，如果你也能获得
    100% 的准确率，请告诉我，然后希望在下一个视频中见到你。如果你喜欢这个视频，请点击赞，并考虑订阅频道，再见。
- en: '![](img/61fab98aab26950654922e0fb57a2416_8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_8.png)'
