- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P8ï¼šL9- è¿ç§»å­¦ä¹ 
    - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P8ï¼šL9- è¿ç§»å­¦ä¹ 
    - ShowMeAI - BV1TT4y1m7Xg
- en: '![](img/61fab98aab26950654922e0fb57a2416_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_0.png)'
- en: ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ and welcome to a new Tensorflowlow tutorialã€‚ Todayã€‚ we will continue
    where we left off last time and applied transfer learning together get a model
    with a good performanceã€‚ğŸ˜Šï¼ŒSo I highly recommend that you watch the last tutorial
    first if you haven't alreadyã€‚ And as a quick recapã€‚ So we used a dataset set from
    Kegle with Lego Star Wars Minfiã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æ–°çš„ Tensorflowlow æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä¸Šæ¬¡çš„å†…å®¹ï¼Œä¸€èµ·åº”ç”¨è¿ç§»å­¦ä¹ ï¼Œè·å¾—ä¸€ä¸ªè‰¯å¥½è¡¨ç°çš„æ¨¡å‹ã€‚ğŸ˜Šï¼Œæ‰€ä»¥å¦‚æœä½ è¿˜æ²¡æœ‰çœ‹è¿‡ä¸Šä¸€ä¸ªæ•™ç¨‹ï¼Œæˆ‘å¼ºçƒˆæ¨èä½ å…ˆå»çœ‹ä¸€ä¸‹ã€‚ä½œä¸ºå¿«é€Ÿå›é¡¾ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ª
    Kegle çš„ä¸€ä¸ªæ•°æ®é›†ï¼ŒåŒ…å«ä¹é«˜æ˜Ÿçƒå¤§æˆ˜ Minfiã€‚
- en: and we applied our own convolutional neural netã€‚ and then we had the problem
    that for the trainingã€‚ we got a very good accuracyã€‚ So this was close to a 100%ã€‚
    but it didn't perform well on our validation data set and also for the final evaluation
    with the test data setã€‚ We only got an accuracy of 40%ã€‚ So this is not very goodã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”ç”¨äº†è‡ªå·±çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚ç„¶åæˆ‘ä»¬é‡åˆ°çš„é—®é¢˜æ˜¯ï¼Œåœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°äº†éå¸¸å¥½çš„å‡†ç¡®ç‡ã€‚æ¥è¿‘ 100%ã€‚ä½†åœ¨éªŒè¯æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¸å¥½ï¼Œåœ¨æœ€ç»ˆæµ‹è¯•æ•°æ®é›†çš„è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„å‡†ç¡®ç‡åªæœ‰
    40%ã€‚è¿™ä¸æ˜¯å¾ˆå¥½ã€‚
- en: So now what we want to do is we want to apply transfer learning to improve our
    modelã€‚ğŸ˜Šã€‚And transfer learning is a very niceï¼Œ simple but very powerful techniqueã€‚So
    the concept is that we use a model that has been already trained and this is probably
    a very good model that with a lot of features and that also has been trained on
    a lot of data and now what we do here is so we we take this model and then we
    only modify the last layers so we cut them out and then apply our own classification
    layers at the end and train only these layers at the end so with this our training
    can be very quick but we can also get the power of the rest of the neural network
    that is already pretrained So this is the whole concept behind transfer learning
    and now I show you how we do that with Ks so the first thingã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯åº”ç”¨è¿ç§»å­¦ä¹ æ¥æ”¹å–„æˆ‘ä»¬çš„æ¨¡å‹ã€‚ğŸ˜Šã€‚è¿ç§»å­¦ä¹ æ˜¯ä¸€ç§éå¸¸å¥½çš„ï¼Œç®€å•ä½†éå¸¸å¼ºå¤§çš„æŠ€æœ¯ã€‚å…¶æ¦‚å¿µæ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å¯èƒ½æ˜¯ä¸€ä¸ªå…·æœ‰è®¸å¤šç‰¹å¾å¹¶ä¸”åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒçš„éå¸¸å¥½çš„æ¨¡å‹ã€‚ç°åœ¨æˆ‘ä»¬æ‰€åšçš„å°±æ˜¯ï¼Œå–è¿™ä¸ªæ¨¡å‹ï¼Œç„¶ååªä¿®æ”¹æœ€åçš„å±‚ï¼Œå‰ªæ‰å®ƒä»¬ï¼Œç„¶ååœ¨æœ€ååº”ç”¨æˆ‘ä»¬è‡ªå·±çš„åˆ†ç±»å±‚ï¼Œå¹¶åªè®­ç»ƒè¿™äº›å±‚ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬çš„è®­ç»ƒå¯ä»¥éå¸¸å¿«é€Ÿï¼ŒåŒæ—¶ä¹Ÿèƒ½åˆ©ç”¨å·²ç»é¢„è®­ç»ƒçš„ç¥ç»ç½‘ç»œçš„å…¶ä»–éƒ¨åˆ†ã€‚æ‰€ä»¥è¿™å°±æ˜¯è¿ç§»å­¦ä¹ çš„æ•´ä¸ªæ¦‚å¿µï¼Œæ¥ä¸‹æ¥æˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨
    Keras å®ç°è¿™ä¸€ç‚¹ï¼Œæ‰€ä»¥ç¬¬ä¸€æ­¥ã€‚
- en: We want to do is to load a pretrain modelã€‚ So there are already some models
    available in Ksã€‚ For exampleï¼Œ the popular Vg G16 modelã€‚ So you get this by saying
    Tensorflow kas applications and then the name of our modelã€‚ So if we download
    the if we call thisï¼Œ then it's downloading this model and saves it in your folderã€‚
    So let's run this and print this summaryã€‚ And here we have theã€‚Archiectureã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦åšçš„æ˜¯åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚Keras ä¸­å·²ç»æœ‰ä¸€äº›æ¨¡å‹å¯ç”¨ã€‚ä¾‹å¦‚ï¼Œæµè¡Œçš„ Vgg16 æ¨¡å‹ã€‚é€šè¿‡è¯´ Tensorflow keras applications
    å’Œæˆ‘ä»¬çš„æ¨¡å‹åç§°ï¼Œä½ å¯ä»¥è·å–è¿™ä¸ªã€‚å¦‚æœæˆ‘ä»¬è°ƒç”¨å®ƒï¼Œç³»ç»Ÿä¼šä¸‹è½½è¯¥æ¨¡å‹å¹¶å°†å…¶ä¿å­˜åœ¨ä½ çš„æ–‡ä»¶å¤¹ä¸­ã€‚è®©æˆ‘ä»¬è¿è¡Œå®ƒå¹¶æ‰“å°æ‘˜è¦ã€‚è¿™é‡Œæ˜¯ã€‚æ¶æ„ã€‚
- en: So you can have a look at thatã€‚And now what we want to do here isï¼Œ as I saidï¼Œ
    we want toã€‚![](img/61fab98aab26950654922e0fb57a2416_2.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯ä»¥çœ‹çœ‹è¿™ä¸ªã€‚ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯ï¼Œå¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬æƒ³è¦ã€‚![](img/61fab98aab26950654922e0fb57a2416_2.png)
- en: '![](img/61fab98aab26950654922e0fb57a2416_3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_3.png)'
- en: Delette the last layerã€‚ so you can delete only the very last layerã€‚ or you can
    also delete more and then apply your ownã€‚ So in this exampleï¼Œ we only take out
    the lastã€‚Layerï¼Œ so this dense layer and then apply our own dense layer with five
    different outputsã€‚ because in our exampleï¼Œ we have five different classesã€‚ And
    right nowã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ é™¤æœ€åä¸€å±‚ã€‚ä½ å¯ä»¥åªåˆ é™¤æœ€åä¸€å±‚ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥åˆ é™¤æ›´å¤šå±‚ï¼Œç„¶ååº”ç”¨ä½ è‡ªå·±çš„ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªåˆ é™¤æœ€åä¸€å±‚ï¼Œå¯†é›†å±‚ï¼Œç„¶ååº”ç”¨æˆ‘ä»¬è‡ªå·±çš„å…·æœ‰äº”ä¸ªä¸åŒè¾“å‡ºçš„å¯†é›†å±‚ï¼Œå› ä¸ºåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰äº”ä¸ªä¸åŒçš„ç±»åˆ«ã€‚ç°åœ¨ã€‚
- en: this is a Kaas functional modelã€‚ So I already talked about the functional APIã€‚
    And if you haven'tã€‚ then I also recommend to watch this one first and I will put
    the link in the descriptionã€‚ But I also said that we can easily convert this to
    a sequential modelã€‚ So we can do this by setting up a new model and say this is
    a sequential modelã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ª Keras åŠŸèƒ½æ¨¡å‹ã€‚æˆ‘å·²ç»è°ˆåˆ°äº†åŠŸèƒ½ APIã€‚å¦‚æœä½ è¿˜æ²¡æœ‰çœ‹è¿‡ï¼Œæˆ‘ä¹Ÿå»ºè®®ä½ å…ˆçœ‹è¿™ä¸ªï¼Œæˆ‘ä¼šæŠŠé“¾æ¥æ”¾åœ¨æè¿°ä¸­ã€‚ä½†æˆ‘ä¹Ÿè¯´è¿‡ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†å…¶è½¬æ¢ä¸ºåºè´¯æ¨¡å‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½®ä¸€ä¸ªæ–°æ¨¡å‹å¹¶è¯´è¿™æ˜¯ä¸€ä¸ªåºè´¯æ¨¡å‹æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: and then we iterate over all the layers except the last oneã€‚ So this is not
    included and say model and layerã€‚ So now let's run this and print the summaryã€‚
    and thenã€‚It should be the sameï¼Œ except that you don't see this layerï¼Œ soã€‚Oh sorryã€‚
    So hereã€‚ this is the original summaryã€‚ and here we have this as last layer with10
    outputsã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬éå†æ‰€æœ‰å±‚ï¼Œé™¤äº†æœ€åä¸€å±‚ã€‚å› æ­¤æœ€åä¸€å±‚ä¸åŒ…æ‹¬åœ¨å†…ï¼Œç§°ä¸ºæ¨¡å‹å’Œå±‚ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå¹¶æ‰“å°æ‘˜è¦ã€‚ç„¶åï¼Œå®ƒåº”è¯¥æ˜¯ç›¸åŒçš„ï¼Œé™¤äº†ä½ çœ‹ä¸åˆ°è¿™ä¸€å±‚ã€‚å“¦ï¼Œå¯¹ä¸èµ·ã€‚æ‰€ä»¥è¿™é‡Œï¼Œè¿™æ˜¯åŸå§‹æ‘˜è¦ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰ä½œä¸ºæœ€åä¸€å±‚çš„10ä¸ªè¾“å‡ºã€‚
- en: And now in our caseï¼Œ this should be the last layerã€‚ So let's have a lookã€‚ And
    yesï¼Œ here thisã€‚ This is the last layerã€‚ And now what we want to do here is we
    want to set all of those layers to trainable equals falsesã€‚ because we don't have
    to retrain these againã€‚ we only have to train our new classification layerã€‚ So
    we loop over all layers and say layer trainable equals falseã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œè¿™åº”è¯¥æ˜¯æœ€åä¸€å±‚ã€‚é‚£ä¹ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯æœ€åä¸€å±‚ã€‚ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯å°†æ‰€æœ‰è¿™äº›å±‚çš„å¯è®­ç»ƒå±æ€§è®¾ç½®ä¸º`false`ã€‚å› ä¸ºæˆ‘ä»¬ä¸éœ€è¦é‡æ–°è®­ç»ƒå®ƒä»¬ã€‚æˆ‘ä»¬åªéœ€è¦è®­ç»ƒæˆ‘ä»¬çš„æ–°åˆ†ç±»å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬éå†æ‰€æœ‰å±‚ï¼Œå¹¶å°†å±‚çš„å¯è®­ç»ƒå±æ€§è®¾ç½®ä¸º`false`ã€‚
- en: '![](img/61fab98aab26950654922e0fb57a2416_5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_5.png)'
- en: '![](img/61fab98aab26950654922e0fb57a2416_6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_6.png)'
- en: And for exampleï¼Œ hereï¼Œ you see the trainable parameters and the nontrainable
    parametersã€‚ And now if we do this and print the summary againã€‚ then we see that
    now all of our parameters are non trainableã€‚ and now we add a last dense layerã€‚
    And by defaultã€‚ Now this is trainable againã€‚ And then againã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè¿™é‡Œä½ å¯ä»¥çœ‹åˆ°å¯è®­ç»ƒå‚æ•°å’Œä¸å¯è®­ç»ƒå‚æ•°ã€‚ç°åœ¨å¦‚æœæˆ‘ä»¬è¿™æ ·åšå¹¶å†æ¬¡æ‰“å°æ‘˜è¦ï¼Œæˆ‘ä»¬ä¼šå‘ç°ç°åœ¨æ‰€æœ‰çš„å‚æ•°éƒ½æ˜¯ä¸å¯è®­ç»ƒçš„ã€‚ç°åœ¨æˆ‘ä»¬æ·»åŠ æœ€åä¸€ä¸ªå¯†é›†å±‚ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™åˆæ˜¯å¯è®­ç»ƒçš„ã€‚ç„¶åå†ä¸€æ¬¡ã€‚
- en: we set up a loss and a optimizer and compile our modelã€‚And then so last time
    I told you how we can use thisã€‚Image data generator and then call this dot flow
    from directory functionã€‚ And this very easily loads the images from a directoryã€‚
    and we can also apply preprocessing and rescaling and even image augmentation
    hereã€‚ So last time we applied this rescaling hereã€‚And now this timeï¼Œ what we want
    to doã€‚ we want to apply the same pre processingcessing function as in our base
    modelã€‚ So in this weci G netã€‚Soï¼Œ and we also get this by saying this is available
    in tensor flowcaras applications than the name of our model and then dot pre process
    inputã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾ç½®æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨å¹¶ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¸Šæ¬¡æˆ‘å‘Šè¯‰ä½ ä»¬å¦‚ä½•ä½¿ç”¨è¿™ä¸ªå›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œç„¶åè°ƒç”¨è¿™ä¸ª`flow from directory`å‡½æ•°ã€‚è¿™å¾ˆç®€å•åœ°ä»ç›®å½•åŠ è½½å›¾åƒã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œåº”ç”¨é¢„å¤„ç†ã€é‡ç¼©æ”¾ï¼Œç”šè‡³å›¾åƒå¢å¼ºã€‚æ‰€ä»¥ä¸Šæ¬¡æˆ‘ä»¬åœ¨è¿™é‡Œåº”ç”¨äº†é‡ç¼©æ”¾ã€‚è¿™æ¬¡æˆ‘ä»¬æƒ³åšçš„æ˜¯ï¼Œåº”ç”¨ä¸åŸºç¡€æ¨¡å‹ç›¸åŒçš„é¢„å¤„ç†å‡½æ•°ã€‚åœ¨è¿™ä¸ª`weci
    G net`ä¸­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡è¯´è¿™ä¸ªåœ¨`tensorflow.keras`åº”ç”¨ç¨‹åºä¸­å¯ç”¨ï¼Œåé¢æ¥æˆ‘ä»¬æ¨¡å‹çš„åç§°å’Œ`preprocess_input`æ¥è·å–ã€‚
- en: So this is our pre processing functionï¼Œ and then we can give this to our image
    data generator for with the argument pre processinging functionã€‚ So this is the
    same for our training validation and test setã€‚And then we call this flow from
    directory for each oneã€‚ And this isã€‚ these are the same arguments as last timeã€‚
    And now this is loading them the images from the different modelsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬çš„é¢„å¤„ç†å‡½æ•°ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°†å…¶æä¾›ç»™æˆ‘ä»¬çš„å›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œä½œä¸ºé¢„å¤„ç†å‡½æ•°çš„å‚æ•°ã€‚è¿™å¯¹äºæˆ‘ä»¬çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†éƒ½æ˜¯ä¸€æ ·çš„ã€‚ç„¶åæˆ‘ä»¬ä¸ºæ¯ä¸ªæ•°æ®é›†è°ƒç”¨`flow
    from directory`ã€‚è¿™äº›å‚æ•°ä¸ä¸Šæ¬¡ç›¸åŒã€‚ç°åœ¨æˆ‘ä»¬æ­£åœ¨ä»ä¸åŒçš„æ¨¡å‹åŠ è½½å›¾åƒã€‚
- en: I didn't run this cellã€‚ So let's run this and this againã€‚ And now we have itã€‚
    And nowï¼Œ againã€‚ this is the same as last timeã€‚ So we fitted our modelã€‚ and we
    apply this early stopping call backã€‚ So if our validation loss does not increase
    for or improve for5 eposã€‚ Then it does an early stoppingã€‚ So let's apply this
    again hereã€‚ And now let's fit our dataã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ²¡æœ‰è¿è¡Œè¿™ä¸ªå•å…ƒã€‚æ‰€ä»¥æˆ‘ä»¬æ¥è¿è¡Œè¿™ä¸ªå’Œè¿™ä¸ªã€‚ç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚å†ä¸€æ¬¡ã€‚è¿™å’Œä¸Šæ¬¡æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥æˆ‘ä»¬è®­ç»ƒäº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶åº”ç”¨äº†æå‰åœæ­¢çš„å›è°ƒã€‚å¦‚æœæˆ‘ä»¬çš„éªŒè¯æŸå¤±åœ¨5ä¸ªå‘¨æœŸå†…æ²¡æœ‰å¢åŠ æˆ–æ”¹å–„ï¼Œé‚£ä¹ˆå°±ä¼šæå‰åœæ­¢ã€‚æ‰€ä»¥æˆ‘ä»¬å†åœ¨è¿™é‡Œåº”ç”¨ä¸€æ¬¡ã€‚ç°åœ¨è®©æˆ‘ä»¬æ¥æ‹Ÿåˆæˆ‘ä»¬çš„æ•°æ®ã€‚
- en: So this is giving an errorã€‚ You must compile your model before training and
    testingã€‚ So I think I already did this in this cellã€‚ So let's run this againã€‚
    and run this and this and now our trainingã€‚ So now it's workingã€‚ I guess I didn't
    run the cell the first timeã€‚ So now let's see how our transfer learning model
    is doingã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å‡ºç°äº†ä¸€ä¸ªé”™è¯¯ã€‚ä½ å¿…é¡»åœ¨è®­ç»ƒå’Œæµ‹è¯•ä¹‹å‰ç¼–è¯‘ä½ çš„æ¨¡å‹ã€‚æˆ‘æƒ³æˆ‘åœ¨è¿™ä¸ªå•å…ƒä¸­å·²ç»åšè¿‡äº†ã€‚æ‰€ä»¥æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚è¿è¡Œè¿™ä¸ªå’Œè¿™ä¸ªï¼Œç°åœ¨æ˜¯æˆ‘ä»¬çš„è®­ç»ƒã€‚ç°åœ¨å®ƒå·¥ä½œäº†ã€‚æˆ‘æƒ³æˆ‘ç¬¬ä¸€æ¬¡æ²¡æœ‰è¿è¡Œè¿™ä¸ªå•å…ƒã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„è¿ç§»å­¦ä¹ æ¨¡å‹è¡¨ç°å¦‚ä½•ã€‚
- en: All rightã€‚ And now our training is doneã€‚ And againï¼Œ we had an early stoppingã€‚
    So we see that our accuracy on the test data set is 100 perã€‚ so perfectã€‚And the
    validation accuracy is almost 94%ã€‚ So yeahï¼Œ I think this is now very goodã€‚ And
    it's a lot better than last timeã€‚ And now we specified 30 epochsã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ã€‚ç°åœ¨æˆ‘ä»¬çš„è®­ç»ƒå®Œæˆäº†ã€‚æˆ‘ä»¬å†æ¬¡è¿›è¡Œäº†æ—©æœŸåœæ­¢ã€‚æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°æµ‹è¯•æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æ˜¯ 100%ã€‚å®Œç¾ã€‚è€ŒéªŒè¯å‡†ç¡®ç‡å‡ ä¹æ˜¯ 94%ã€‚æ‰€ä»¥ï¼Œæˆ‘è®¤ä¸ºè¿™ç°åœ¨éå¸¸å¥½ã€‚è¿™æ¯”ä¸Šæ¬¡å¥½å¤šäº†ã€‚ç°åœ¨æˆ‘ä»¬è®¾ç½®äº†
    30 ä¸ªå‘¨æœŸã€‚
- en: but then our validation loss had the lowest value hereã€‚ And then it didn't get
    better over the next five epochã€‚ So we set patients is 5ã€‚ And that's why that
    the early stoppingã€‚ So we already had a validation accuracy of 100% in the second
    epochã€‚ But this might be the case because we don't have so many images available
    in our validation data setã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æˆ‘ä»¬çš„éªŒè¯æŸå¤±åœ¨è¿™é‡Œæ˜¯æœ€ä½çš„å€¼ã€‚ç„¶ååœ¨æ¥ä¸‹æ¥çš„äº”ä¸ªå‘¨æœŸå†…æ²¡æœ‰æ”¹å–„ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾ç½®äº†æ‚£è€…å€¼ä¸º 5ã€‚è¿™å°±æ˜¯æ—©æœŸåœæ­¢çš„åŸå› ã€‚å› æ­¤æˆ‘ä»¬åœ¨ç¬¬äºŒä¸ªå‘¨æœŸæ—¶å·²ç»è·å¾—äº†
    100% çš„éªŒè¯å‡†ç¡®ç‡ã€‚ä½†è¿™å¯èƒ½æ˜¯å› ä¸ºæˆ‘ä»¬çš„éªŒè¯æ•°æ®é›†ä¸­å¯ç”¨çš„å›¾åƒä¸å¤šã€‚
- en: So I think this result is not very reliableã€‚ But yeahã€‚ I think we can see how
    powerful this transfer learning isã€‚ because last time we had problem with overfitting
    so that we had aã€‚Good accuracy on the testã€‚ on the training dataï¼Œ but not on the
    validation data and not on the test dataã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™ä¸ªç»“æœä¸æ˜¯å¾ˆå¯é ã€‚ä½†æˆ‘è®¤ä¸ºæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿ç§»å­¦ä¹ æ˜¯å¤šä¹ˆå¼ºå¤§ã€‚å› ä¸ºä¸Šæ¬¡æˆ‘ä»¬é‡åˆ°äº†è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œä»¥è‡³äºæˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®ä¸Šæœ‰è‰¯å¥½çš„å‡†ç¡®ç‡ï¼Œä½†åœ¨éªŒè¯æ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸Šå´æ²¡æœ‰ã€‚
- en: And now with a transfer learning techniqueï¼Œ we can get this after only two epochs
    And even in this example where we don't have so many images availableã€‚ and this
    is very goodã€‚ So now let's evaluate our model on the test data setã€‚ And we see
    in this caseï¼Œ we got 100 percent on accuracy on the test dataã€‚ So I guess I' am
    a little bit lucky this timeã€‚ But yeahã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œé€šè¿‡è¿ç§»å­¦ä¹ æŠ€æœ¯ï¼Œæˆ‘ä»¬åœ¨ä»…ä»…ä¸¤ä¸ªå‘¨æœŸåå°±å¾—åˆ°äº†è¿™ä¸ªç»“æœï¼Œå³ä½¿åœ¨è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬æ²¡æœ‰é‚£ä¹ˆå¤šå¯ç”¨çš„å›¾åƒã€‚è¿™æ˜¯éå¸¸å¥½çš„ã€‚é‚£ä¹ˆç°åœ¨è®©æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬çœ‹åˆ°åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæµ‹è¯•æ•°æ®çš„å‡†ç¡®ç‡ä¸º
    100%ã€‚æ‰€ä»¥æˆ‘æƒ³è¿™æ¬¡æˆ‘æœ‰ç‚¹å¹¸è¿ã€‚ä½†ä¹Ÿç¡®å®å¦‚æ­¤ã€‚
- en: we see how powerful this technique is again and how simple it isã€‚ So you load
    a pretrained modelã€‚ğŸ˜Šã€‚Andã€‚Soã€‚So this oneã€‚ and then we converted it in this caseï¼Œ
    to a sequential modelã€‚ So you don't have to do thisã€‚ but this makes it a little
    bit simpler for you because I know the sequential API is easier to understandã€‚And
    then we excluded the last layer and added our own dense layerã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å†æ¬¡çœ‹åˆ°è¿™ç§æŠ€æœ¯æ˜¯å¤šä¹ˆå¼ºå¤§ï¼Œä»¥åŠå®ƒæ˜¯å¤šä¹ˆç®€å•ã€‚æ‰€ä»¥ä½ åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹ã€‚ğŸ˜Šã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨è¿™ç§æƒ…å†µä¸‹å°†å…¶è½¬æ¢ä¸ºé¡ºåºæ¨¡å‹ã€‚æ‰€ä»¥ä½ ä¸å¿…è¿™æ ·åšï¼Œä½†è¿™æ ·å¯¹ä½ æ¥è¯´ä¼šç®€å•ä¸€äº›ï¼Œå› ä¸ºæˆ‘çŸ¥é“é¡ºåº
    API æ›´å®¹æ˜“ç†è§£ã€‚ç„¶åæˆ‘ä»¬æ’é™¤äº†æœ€åä¸€å±‚ï¼Œæ·»åŠ äº†æˆ‘ä»¬è‡ªå·±çš„å¯†é›†å±‚ã€‚
- en: and then we also set layers trainable to false except for our last dense layerã€‚
    And then we did a new trainingã€‚And as a homeworkï¼Œ you can try out other pretrain
    netsã€‚ Soã€‚ for exampleï¼Œ the mobile net version 2 is another very popular netã€‚ so
    you can go to this link And then here you have all the different available netã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜å°†å±‚çš„å¯è®­ç»ƒæ€§è®¾ç½®ä¸º falseï¼Œé™¤äº†æœ€åçš„å¯†é›†å±‚ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œäº†æ–°çš„è®­ç»ƒã€‚ä½œä¸ºå®¶åº­ä½œä¸šï¼Œä½ å¯ä»¥å°è¯•å…¶ä»–é¢„è®­ç»ƒçš„ç½‘ç»œã€‚æ‰€ä»¥ï¼Œæ¯”å¦‚è¯´ï¼Œç§»åŠ¨ç½‘ç»œç‰ˆæœ¬
    2 æ˜¯å¦ä¸€ä¸ªéå¸¸å—æ¬¢è¿çš„ç½‘ç»œã€‚ä½ å¯ä»¥è®¿é—®è¿™ä¸ªé“¾æ¥ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥æ‰¾åˆ°æ‰€æœ‰ä¸åŒçš„å¯ç”¨ç½‘ç»œã€‚
- en: So here's our V G16ï¼Œ you also have reachi G19ã€‚ you have the mobile net and the
    mobile net version 2 and the resnetã€‚ So yeahï¼Œ try them out for itselfã€‚ and I can
    tell you that you might run into a problem when you try to convert your model
    to a sequential model because this only works if the architecture of your model
    is linearã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬çš„ V G16ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ G19ã€‚ä½ æœ‰ç§»åŠ¨ç½‘ç»œå’Œç§»åŠ¨ç½‘ç»œç‰ˆæœ¬ 2 ä»¥åŠ ResNetã€‚æ‰€ä»¥ï¼Œè¯•è¯•å®ƒä»¬ã€‚æˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œå½“ä½ å°è¯•å°†æ¨¡å‹è½¬æ¢ä¸ºé¡ºåºæ¨¡å‹æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°é—®é¢˜ï¼Œå› ä¸ºè¿™ä»…åœ¨æ¨¡å‹æ¶æ„æ˜¯çº¿æ€§æ—¶æœ‰æ•ˆã€‚
- en: and if you don't know how you do thisï¼Œ if your architecture is not linearã€‚ then
    you can watch my tutorial about the functional API because there I gave you a
    tip at the end and showed you how you can stillã€‚Do transfer learning with a functional
    modelã€‚ So yeah check it out and let me know if you can also get a accuracy of
    100% and I hope to see you in the next video thenã€‚ And if you enjoy this videoï¼Œ
    please hit the like button and consider subscribing to the channel byeã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸çŸ¥é“å¦‚ä½•æ“ä½œï¼Œå¦‚æœä½ çš„æ¶æ„ä¸æ˜¯çº¿æ€§çš„ï¼Œé‚£ä¹ˆä½ å¯ä»¥è§‚çœ‹æˆ‘å…³äºåŠŸèƒ½ API çš„æ•™ç¨‹ï¼Œå› ä¸ºæˆ‘åœ¨æœ€åç»™äº†ä½ ä¸€ä¸ªæç¤ºï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åœ¨åŠŸèƒ½æ¨¡å‹ä¸­è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚æ‰€ä»¥ï¼Œçœ‹çœ‹è¿™ä¸ªï¼Œå¦‚æœä½ ä¹Ÿèƒ½è·å¾—
    100% çš„å‡†ç¡®ç‡ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œç„¶åå¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªè§†é¢‘ï¼Œè¯·ç‚¹å‡»èµï¼Œå¹¶è€ƒè™‘è®¢é˜…é¢‘é“ï¼Œå†è§ã€‚
- en: '![](img/61fab98aab26950654922e0fb57a2416_8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61fab98aab26950654922e0fb57a2416_8.png)'
