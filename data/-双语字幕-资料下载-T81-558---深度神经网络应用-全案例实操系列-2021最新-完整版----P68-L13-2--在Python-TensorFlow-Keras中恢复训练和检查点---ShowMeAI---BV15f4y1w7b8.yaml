- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P68ï¼šL13.2- åœ¨Python TensorFlow
    Kerasä¸­æ¢å¤è®­ç»ƒå’Œæ£€æŸ¥ç‚¹ - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P68ï¼šL13.2- åœ¨Python TensorFlow
    Kerasä¸­æ¢å¤è®­ç»ƒå’Œæ£€æŸ¥ç‚¹ - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heaton welcome to applications of Deep neural Networks with
    Washington University In this presentation I'm going to show you how to checkpoint
    and continue a model in Kisã€‚![](img/b54dc4281b74dae55dd425a171fc90c8_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ã€‚åœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•åœ¨Kisä¸­è¿›è¡Œæ£€æŸ¥ç‚¹å’Œç»§ç»­æ¨¡å‹ã€‚![](img/b54dc4281b74dae55dd425a171fc90c8_1.png)
- en: ğŸ¼Theã€‚So the first thing I'm going to do for the class notes for this and this
    is just on my Github repositoryã€‚ I have a link in the description so you can go
    right to itã€‚ I'm going to click open and collab Now when you're training big complicated
    models you'll frequently want to stop and restart training because they may go
    on for several days you'll invariably get interrupted not necessarily intentionally
    but you need a way to continue and that's what I'm going to show you in this presentation
    go ahead and zoom this a little bit so we're now running and collab I'm going
    to go ahead and copy it to my G drive even though I'm not really going to use
    actual files on the G driveri I'm going make sure that the runtime type has a
    GPU which it does you don't need collab Pro for this even though you'll see that
    I'm running coEpro I'll run this introductory code here that just gets you started
    this also defines a little function that shows you how much time something elapsed
    in a human readable form This code that Iã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼æ‰€ä»¥ï¼Œæˆ‘è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯ä¸ºè¿™ä¸ªè¯¾ç¨‹ç¬”è®°å‡†å¤‡ï¼Œè¿™åªæ˜¯åœ¨æˆ‘çš„Githubä»“åº“ä¸­ã€‚æˆ‘åœ¨æè¿°ä¸­æœ‰ä¸€ä¸ªé“¾æ¥ï¼Œä½ å¯ä»¥ç›´æ¥è®¿é—®å®ƒã€‚æˆ‘å°†ç‚¹å‡»æ‰“å¼€å’Œcollabã€‚ç°åœ¨ï¼Œå½“ä½ è®­ç»ƒå¤§å‹å¤æ‚æ¨¡å‹æ—¶ï¼Œä½ é€šå¸¸ä¼šæƒ³è¦åœæ­¢å¹¶é‡æ–°å¼€å§‹è®­ç»ƒï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šæŒç»­å‡ å¤©ã€‚ä½ ä¸å¯é¿å…åœ°ä¼šè¢«æ‰“æ–­ï¼Œä¸ä¸€å®šæ˜¯æ•…æ„çš„ï¼Œä½†ä½ éœ€è¦ä¸€ç§ç»§ç»­çš„æ–¹å¼ï¼Œè¿™å°±æ˜¯æˆ‘å°†åœ¨æœ¬æ¼”ç¤ºä¸­å±•ç¤ºçš„ã€‚ç»§ç»­æ”¾å¤§ä¸€ä¸‹ï¼Œç°åœ¨æˆ‘ä»¬åœ¨collabä¸­è¿è¡Œï¼Œæˆ‘ä¼šå°†å…¶å¤åˆ¶åˆ°æˆ‘çš„Gé©±åŠ¨å™¨ï¼Œå°½ç®¡æˆ‘å¹¶ä¸æ‰“ç®—çœŸæ­£ä½¿ç”¨Gé©±åŠ¨å™¨ä¸Šçš„å®é™…æ–‡ä»¶ã€‚æˆ‘ä¼šç¡®ä¿è¿è¡Œæ—¶ç±»å‹æ˜¯GPUï¼Œç¡®å®å¦‚æ­¤ï¼Œå³ä½¿ä½ ä¼šçœ‹åˆ°æˆ‘åœ¨è¿è¡ŒcoEproï¼Œæˆ‘ä¼šè¿è¡Œè¿™ä¸ªä»‹ç»æ€§ä»£ç ï¼Œå®ƒåªæ˜¯è®©ä½ å…¥é—¨ï¼Œè¿™ä¹Ÿå®šä¹‰äº†ä¸€ä¸ªå°å‡½æ•°ï¼Œå‘Šè¯‰ä½ æŸäº‹ç»è¿‡çš„æ—¶é—´ä»¥äººç±»å¯è¯»çš„å½¢å¼ã€‚è¿™ä¸ªä»£ç æˆ‘ã€‚
- en: '![](img/b54dc4281b74dae55dd425a171fc90c8_3.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b54dc4281b74dae55dd425a171fc90c8_3.png)'
- en: '![](img/b54dc4281b74dae55dd425a171fc90c8_4.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b54dc4281b74dae55dd425a171fc90c8_4.png)'
- en: I have here is code that I make use of when I'm running a bigger complicated
    project actually base this code on NviDdia styleganN2 ADA they had some really
    nice code there to create output directories that were labeled ever incrementing
    and also captured the standard out to a log file So if you worked with style GN2
    you will have seen some of this code here before basically the way it works is
    there's this logger function and actually a logger classã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘åœ¨è¿è¡Œæ›´å¤§å¤æ‚é¡¹ç›®æ—¶ä½¿ç”¨çš„ä»£ç ï¼Œå®é™…ä¸Šè¿™ä¸ªä»£ç åŸºäºNviDdiaçš„styleganN2 ADAï¼Œä»–ä»¬æœ‰ä¸€äº›å¾ˆå¥½çš„ä»£ç æ¥åˆ›å»ºæ ‡ç­¾é€æ­¥é€’å¢çš„è¾“å‡ºç›®å½•ï¼Œå¹¶ä¸”è¿˜å°†æ ‡å‡†è¾“å‡ºæ•è·åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ã€‚å› æ­¤ï¼Œå¦‚æœä½ ä½¿ç”¨è¿‡style
    GAN2ï¼Œä½ ä¹‹å‰å¯èƒ½è§è¿‡ä¸€äº›è¿™ä¸ªä»£ç ï¼ŒåŸºæœ¬ä¸Šå®ƒçš„å·¥ä½œæ–¹å¼æ˜¯æœ‰è¿™ä¸ªloggerå‡½æ•°ï¼Œå®é™…ä¸Šæ˜¯ä¸€ä¸ªloggerç±»ã€‚
- en: And that is used to wrap your code so that anything going to standard out goes
    to the log file as well as to standard outã€‚ So it's a convenient kind of low grade
    loggingã€‚ If you want something more production levelã€‚ you'll probably want to
    use log for Python or other libraries that are available for thatã€‚ but I'm going
    to run this so that it's definedã€‚ Okayï¼Œ let's go to the next partã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç”¨äºåŒ…è£…ä½ çš„ä»£ç ï¼Œä»¥ä¾¿ä»»ä½•è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºçš„å†…å®¹ä¹Ÿä¼šè®°å½•åˆ°æ—¥å¿—æ–‡ä»¶ä¸­ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ç§æ–¹ä¾¿çš„ä½çº§æ—¥å¿—è®°å½•æ–¹å¼ã€‚å¦‚æœä½ æƒ³è¦æ›´é«˜çš„ç”Ÿäº§çº§åˆ«ï¼Œä½ å¯èƒ½ä¼šæƒ³ä½¿ç”¨Pythonçš„logæˆ–å…¶ä»–å¯ç”¨çš„åº“ã€‚ä½†æˆ‘ä¼šè¿è¡Œè¿™ä¸ªä»¥ä¾¿å®šä¹‰ã€‚å¥½çš„ï¼Œæˆ‘ä»¬è¿›å…¥ä¸‹ä¸€éƒ¨åˆ†ã€‚
- en: this is where I am going to store the checkpoint filesã€‚ So I'm putting a call
    back on Kis that is going to wait every so manyã€‚Steps at the end of each epoch
    actually it is going to save a complete copy of your neural network as well as
    the training state so that you can resume training because if you don't capture
    the training state as well as the neural network then your training resume is
    going to be inefficient think of it like you're in the middle of a college semester
    and you I don't know life gets in the way you have to drop out but you're going
    to come back when you come back do you want to start at the beginning of your
    deep degree program or do you want to start where you left off that's like your
    training object your training object is like the university you want to you don't
    want to have to repeat those semesters because it's not going to do you any good
    you still have all the knowledge up in your brain like the neural network so that's
    why you want to save the state of both the training which is like your transcript
    in collegeã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘å°†å­˜å‚¨æ£€æŸ¥ç‚¹æ–‡ä»¶çš„åœ°æ–¹ã€‚æ‰€ä»¥æˆ‘åœ¨Kisä¸Šæ”¾ç½®äº†ä¸€ä¸ªå›è°ƒï¼Œå®ƒå°†åœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ç­‰å¾…ä¸€å®šçš„æ­¥éª¤ï¼Œå®é™…ä¸Šï¼Œå®ƒå°†ä¿å­˜ä½ çš„ç¥ç»ç½‘ç»œçš„å®Œæ•´å‰¯æœ¬ä»¥åŠè®­ç»ƒçŠ¶æ€ï¼Œä»¥ä¾¿ä½ å¯ä»¥æ¢å¤è®­ç»ƒï¼Œå› ä¸ºå¦‚æœä½ ä¸æ•è·è®­ç»ƒçŠ¶æ€ä»¥åŠç¥ç»ç½‘ç»œï¼Œé‚£ä¹ˆä½ çš„è®­ç»ƒæ¢å¤å°†æ˜¯ä½æ•ˆçš„ï¼Œæƒ³è±¡ä¸€ä¸‹ä½ åœ¨å¤§å­¦å­¦æœŸä¸­é—´ï¼Œè€Œç”Ÿæ´»å‘ç”Ÿäº†ä¸€äº›äº‹æƒ…ï¼Œä½ ä¸å¾—ä¸é€€å­¦ï¼Œä½†ä½ ä¼šå›æ¥ï¼Œå›æ¥æ—¶ä½ æ˜¯æƒ³ä»æ·±é€ è¯¾ç¨‹çš„å¼€å§‹å¼€å§‹ï¼Œè¿˜æ˜¯æƒ³ä»ä½ åœæ­¢çš„åœ°æ–¹å¼€å§‹ï¼Œè¿™å°±åƒä½ çš„è®­ç»ƒç›®æ ‡ï¼Œä½ çš„è®­ç»ƒç›®æ ‡å°±åƒå¤§å­¦ï¼Œä½ ä¸æƒ³é‡å¤é‚£äº›å­¦æœŸï¼Œå› ä¸ºè¿™å¯¹ä½ æ²¡æœ‰ä»»ä½•å¥½å¤„ï¼Œä½ çš„è„‘æµ·ä¸­ä»ç„¶æœ‰æ‰€æœ‰çš„çŸ¥è¯†ï¼Œå°±åƒç¥ç»ç½‘ç»œä¸€æ ·ï¼Œæ‰€ä»¥è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ æƒ³ä¿å­˜è®­ç»ƒçŠ¶æ€çš„åŸå› ï¼Œè¿™å°±åƒä½ åœ¨å¤§å­¦çš„æˆç»©å•ã€‚
- en: And the neural networkï¼Œ which is your smarts that it's learned Nowï¼Œ just like
    a transcriptã€‚ you're only going to capture those courses back to the semesterã€‚
    so the semester is like the Epoch at the end of the epochï¼Œ it is going to save
    the state ofã€‚The training and also the neural network you're going to lose whatever
    happens in the middle of the Epoch until the other oneã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯å®ƒæ‰€å­¦ä¹ çš„æ™ºæ…§ï¼Œå°±åƒæˆç»©å•ä¸€æ ·ã€‚ä½ åªä¼šæ•è·é‚£äº›è¯¾ç¨‹åˆ°å­¦æœŸã€‚å› æ­¤ï¼Œå­¦æœŸå°±åƒå‘¨æœŸï¼Œåœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ï¼Œå®ƒå°†ä¿å­˜è®­ç»ƒçŠ¶æ€å’Œç¥ç»ç½‘ç»œçš„çŠ¶æ€ï¼Œä½ å°†å¤±å»åœ¨å‘¨æœŸä¸­é—´å‘ç”Ÿçš„ä»»ä½•äº‹æƒ…ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªå‘¨æœŸã€‚
- en: so that's that's a little differentï¼Œ but that's basically how that worksã€‚ I
    am going to run this code and it is going to store it in this data directoryã€‚
    which is just a locationã€‚On my coabab instance that'll go away as soon as I reboot
    it but this is just for an exampleã€‚ you would probably move this elsewhereã€‚ this
    is just going to be the batch sizeã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰ç‚¹ä¸åŒï¼Œä½†åŸºæœ¬ä¸Šå°±æ˜¯è¿™æ ·ã€‚æˆ‘å°†è¿è¡Œè¿™æ®µä»£ç ï¼Œå®ƒå°†å­˜å‚¨åœ¨è¿™ä¸ªæ•°æ®ç›®å½•ä¸­ï¼Œè¿™åªæ˜¯ä¸€ä¸ªä½ç½®ã€‚åœ¨æˆ‘çš„coababå®ä¾‹ä¸Šï¼Œé‡å¯åå®ƒå°±ä¼šæ¶ˆå¤±ï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ã€‚ä½ å¯èƒ½ä¼šå°†å…¶ç§»åŠ¨åˆ°å…¶ä»–åœ°æ–¹ï¼Œè¿™åªæ˜¯æ‰¹é‡å¤§å°ã€‚
- en: the number of classes we're doing a classification we're doing the classic minsed
    digits so we're teaching it to classify these handwritten digits there's 10 digits
    so that's why there's 10 classes the results are going to be saved this is 001
    test train that's the name of the experiment that I was running and this is just
    an ever- increasingcreas number that keeps these separate so that way you can
    quickly go back to previous runs and since we're saving the state of the training
    in a JSON file you'll be able to look at that and see how these individual runs
    were this is very useful in a research type project so we're going to define this
    class called my model checkpoint This is going to work as your checkpoint this
    will be called at the end of each epoch and it's going to store your neural network
    and the training parameters so on the EpoC endã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿›è¡Œçš„æ˜¯åˆ†ç±»ï¼Œæ­£åœ¨åšç»å…¸çš„æ‰‹å†™æ•°å­—åˆ†ç±»ï¼Œå› æ­¤æˆ‘ä»¬æ•™å®ƒå¯¹è¿™äº›æ‰‹å†™æ•°å­—è¿›è¡Œåˆ†ç±»ï¼Œæœ‰10ä¸ªæ•°å­—ï¼Œæ‰€ä»¥æœ‰10ä¸ªç±»åˆ«ï¼Œç»“æœå°†è¢«ä¿å­˜ï¼Œè¿™å°±æ˜¯æˆ‘è¿è¡Œçš„å®éªŒçš„åç§°001æµ‹è¯•è®­ç»ƒï¼Œè¿™åªæ˜¯ä¸€ä¸ªä¸æ–­å¢åŠ çš„æ•°å­—ï¼Œç”¨äºå°†å®ƒä»¬åŒºåˆ†å¼€ï¼Œè¿™æ ·ä½ å¯ä»¥å¿«é€Ÿå›åˆ°ä»¥å‰çš„è¿è¡Œï¼Œç”±äºæˆ‘ä»¬å°†è®­ç»ƒçŠ¶æ€ä¿å­˜åœ¨JSONæ–‡ä»¶ä¸­ï¼Œä½ å°†èƒ½å¤ŸæŸ¥çœ‹è¿™äº›ä¸ªåˆ«è¿è¡Œï¼Œè¿™åœ¨ç ”ç©¶ç±»å‹çš„é¡¹ç›®ä¸­éå¸¸æœ‰ç”¨ï¼Œå› æ­¤æˆ‘ä»¬å°†å®šä¹‰è¿™ä¸ªåä¸ºmy
    model checkpointçš„ç±»ï¼Œè¿™å°†ä½œä¸ºä½ çš„æ£€æŸ¥ç‚¹ï¼Œåœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶è°ƒç”¨å®ƒï¼Œå¹¶å°†å­˜å‚¨ä½ çš„ç¥ç»ç½‘ç»œå’Œè®­ç»ƒå‚æ•°ã€‚
- en: We want this to be called when each epoC is endedï¼Œ we are going to first of
    all call the previous class that we're basing this onã€‚ which is the model checkpointï¼Œ
    which is provided by Kiris so you want to make sure that the built-in stuff is
    still called that's what actually saves your model state We're going to just do
    the extra work that we want to do beyond what Curris has built in and that extra
    work is we're going to save the optimizer state so I'm going to get the file path
    that so that I have the name of the HD5 I think it is that it stores the model
    to it's a binary format that the model is stored to but I want the training state
    to have the same name as the model just a different extension it'll be a PKL file
    because we're going to pickle it that I open up the pickle file and I essentially
    write to the pickle file a dictionaryã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›åœ¨æ¯ä¸ªepoCç»“æŸæ—¶è°ƒç”¨è¿™ä¸ªï¼Œæˆ‘ä»¬é¦–å…ˆè¦è°ƒç”¨æˆ‘ä»¬æ‰€åŸºäºçš„å‰ä¸€ä¸ªç±»ã€‚é‚£å°±æ˜¯æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œç”±Kirisæä¾›ï¼Œæ‰€ä»¥ä½ è¦ç¡®ä¿å†…ç½®çš„å†…å®¹ä»ç„¶è¢«è°ƒç”¨ï¼Œè¿™å®é™…ä¸Šä¿å­˜äº†ä½ çš„æ¨¡å‹çŠ¶æ€ã€‚æˆ‘ä»¬è¦åšçš„é¢å¤–å·¥ä½œæ˜¯ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ‰€ä»¥æˆ‘ä¼šè·å–æ–‡ä»¶è·¯å¾„ï¼Œä»¥ä¾¿æˆ‘çŸ¥é“å­˜å‚¨æ¨¡å‹çš„HD5åç§°ï¼Œå®ƒæ˜¯ä»¥äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨çš„ï¼Œä½†æˆ‘å¸Œæœ›è®­ç»ƒçŠ¶æ€ä¸æ¨¡å‹åŒåï¼Œåªæ˜¯æ‰©å±•åä¸åŒï¼Œå°†æ˜¯PKLæ–‡ä»¶ï¼Œå› ä¸ºæˆ‘ä»¬è¦å°†å…¶åºåˆ—åŒ–ï¼Œæˆ‘ä¼šæ‰“å¼€pickleæ–‡ä»¶ï¼Œæœ¬è´¨ä¸Šå‘pickleæ–‡ä»¶å†™å…¥ä¸€ä¸ªå­—å…¸ã€‚
- en: That has all of this information in here So the optimizer that is basically
    I'm going to call whatever optimizer the model is using that's something like
    atom or gradient other forms of gradient boosted based algorithms that is just
    how it is being optimized stochastic gradient descent is also another possibility
    We have to save what epoch we're on because we're going to also do a learning
    rate decay on this so the learning rate is gradually going down as you train you
    don't want that to change just because you're going to restart training and this
    is stored as a pickle file let's go ahead and run this so that it's defined This
    is the decay scheduler This is a fairly standard decay scheduler so as this is
    your initial learning rate one times 10 to the negative third we're decaying by
    75% and the step size is 10 and it's just going to gradually decay that rateã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œé¢åŒ…å«äº†æ‰€æœ‰ä¿¡æ¯ï¼Œæ‰€ä»¥ä¼˜åŒ–å™¨åŸºæœ¬ä¸Šæ˜¯æˆ‘å°†è°ƒç”¨æ¨¡å‹æ­£åœ¨ä½¿ç”¨çš„ä»»ä½•ä¼˜åŒ–å™¨ï¼Œåƒæ˜¯atomæˆ–å…¶ä»–å½¢å¼çš„æ¢¯åº¦æå‡ç®—æ³•ï¼Œè¿™å°±æ˜¯å®ƒçš„ä¼˜åŒ–æ–¹å¼ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ä¹Ÿæ˜¯å¦ä¸€ç§å¯èƒ½æ€§ã€‚æˆ‘ä»¬å¿…é¡»ä¿å­˜æˆ‘ä»¬æ‰€å¤„çš„epochï¼Œå› ä¸ºæˆ‘ä»¬ä¹Ÿå°†è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ï¼Œå› æ­¤éšç€è®­ç»ƒï¼Œå­¦ä¹ ç‡é€æ¸ä¸‹é™ã€‚ä½ ä¸å¸Œæœ›åœ¨é‡æ–°å¯åŠ¨è®­ç»ƒæ—¶æ”¹å˜è¿™ä¸ªï¼Œå¹¶ä¸”è¿™æ˜¯å­˜å‚¨ä¸ºpickleæ–‡ä»¶çš„ã€‚è®©æˆ‘ä»¬ç»§ç»­è¿è¡Œï¼Œè¿™æ ·å®ƒå°±è¢«å®šä¹‰äº†ã€‚è¿™æ˜¯è¡°å‡è°ƒåº¦å™¨ï¼Œè¿™æ˜¯ä¸€ä¸ªç›¸å½“æ ‡å‡†çš„è¡°å‡è°ƒåº¦å™¨ï¼Œå› æ­¤è¿™æ˜¯ä½ çš„åˆå§‹å­¦ä¹ ç‡1ä¹˜ä»¥10çš„è´Ÿä¸‰æ¬¡æ–¹ï¼Œæˆ‘ä»¬ä»¥75%çš„æ¯”ä¾‹è¡°å‡ï¼Œæ­¥é•¿ä¸º10ï¼Œå®ƒå°†é€æ¸è¡°å‡è¿™ä¸ªé€Ÿç‡ã€‚
- en: downã€‚Exponentialallyï¼Œ we'll go ahead and run that so that it's definedã€‚ This
    is the code to build a modelã€‚ and this is very similar to what you've seen previously
    in this courseã€‚ It's just a convolution neural networkã€‚ The model format is not
    really that important to this exampleã€‚ We're mostly interested in how we're going
    to continue trainingã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ä¸‹å‘ˆæŒ‡æ•°çº§ï¼Œæˆ‘ä»¬ä¼šç»§ç»­è¿è¡Œï¼Œè¿™æ ·å®ƒå°±è¢«å®šä¹‰äº†ã€‚è¿™æ˜¯æ„å»ºæ¨¡å‹çš„ä»£ç ï¼Œè¿™ä¸ä½ åœ¨æœ¬è¯¾ç¨‹ä¸­ä¹‹å‰çœ‹åˆ°çš„éå¸¸ç›¸ä¼¼ã€‚è¿™åªæ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œã€‚æ¨¡å‹æ ¼å¼å¯¹è¿™ä¸ªä¾‹å­å¹¶ä¸é‡è¦ã€‚æˆ‘ä»¬ä¸»è¦å…³å¿ƒçš„æ˜¯å¦‚ä½•ç»§ç»­è®­ç»ƒã€‚
- en: We're going to now call it also this train modelã€‚ This is a little more complicatedã€‚
    because we're going to potentially resume trainingã€‚ We'll pass in the modelã€‚ The
    initial epoch when you first start is going to always be zeroï¼Œ because you should
    start at zeroã€‚ and then Max Epos is going to be how far you want it to trainã€‚
    So when you first train itã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ä¹Ÿè¦è°ƒç”¨è¿™ä¸ªè®­ç»ƒæ¨¡å‹ã€‚è¿™æœ‰ç‚¹å¤æ‚ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šæ¢å¤è®­ç»ƒã€‚æˆ‘ä»¬å°†ä¼ å…¥æ¨¡å‹ã€‚ç¬¬ä¸€æ¬¡å¯åŠ¨æ—¶çš„åˆå§‹epochå°†å§‹ç»ˆä¸ºé›¶ï¼Œå› ä¸ºä½ åº”è¯¥ä»é›¶å¼€å§‹ã€‚ç„¶åMax
    Eposå°†æ˜¯ä½ å¸Œæœ›è®­ç»ƒçš„ç¨‹åº¦ã€‚æ‰€ä»¥å½“ä½ ç¬¬ä¸€æ¬¡è®­ç»ƒæ—¶ã€‚
- en: we're going to train it for just three epochsã€‚ but you could also hard interrupt
    it as wellã€‚ The computer could lose powerã€‚ The dog could trip over your power
    cableã€‚ Whatever that could cause you to failã€‚ You can also buy spot instances
    on AWSï¼Œ which are muchã€‚Cheaper than normal cloud instancesã€‚ But the trick is Amazon
    can interrupt you when a higher paying customer comes alongã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è®­ç»ƒä¸‰ä¸ªepochã€‚ä½†ä½ ä¹Ÿå¯ä»¥éšæ—¶ä¸­æ–­ã€‚è®¡ç®—æœºå¯èƒ½ä¼šæ–­ç”µã€‚ç‹—å¯èƒ½ä¼šç»Šå€’ä½ çš„ç”µæºçº¿ã€‚ä»»ä½•å¯èƒ½å¯¼è‡´ä½ å¤±è´¥çš„æƒ…å†µã€‚ä½ è¿˜å¯ä»¥åœ¨AWSä¸Šè´­ä¹°ç°è´§å®ä¾‹ï¼Œè¿™æ¯”æ­£å¸¸çš„äº‘å®ä¾‹ä¾¿å®œå¾—å¤šã€‚ä½†è¯€çªæ˜¯ï¼Œå½“æœ‰æ›´é«˜æ”¯ä»˜çš„å®¢æˆ·å‡ºç°æ—¶ï¼Œäºšé©¬é€Šå¯ä»¥ä¸­æ–­ä½ ã€‚
- en: So this is all cases where this checkpointing is really very important in a
    production type situationã€‚ So we create the checkpointã€‚It's going to have this
    name so the model Epoch will be embedded in there and also our loss just so we
    can keep track of how effective each of these are we're going to create a learning
    rate schedule that we have up thereã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨ç”Ÿäº§ç±»å‹çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ£€æŸ¥ç‚¹æ˜¯éå¸¸é‡è¦çš„ã€‚æ‰€ä»¥æˆ‘ä»¬åˆ›å»ºæ£€æŸ¥ç‚¹ã€‚å®ƒä¼šæœ‰è¿™ä¸ªåç§°ï¼Œå› æ­¤æ¨¡å‹çºªå…ƒä¼šåµŒå…¥å…¶ä¸­ï¼Œè¿˜æœ‰æˆ‘ä»¬çš„æŸå¤±ï¼Œä»¥ä¾¿æˆ‘ä»¬è·Ÿè¸ªæ¯ä¸ªçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå­¦ä¹ ç‡è®¡åˆ’ã€‚
- en: These are our two callbacksï¼Œ the checkpoint and the schedulerã€‚ and we're going
    to call fit just like we would doã€‚On any other training operation at the end we're
    going to evaluate it and print out the resultsã€‚ we're also going to track how
    much time this took and print that out so let's run this stuff so that it's available
    This is where we're going to actually run it so I'm going to go ahead and kick
    this off because this takes a little bit of time not muchã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬çš„ä¸¤ä¸ªå›è°ƒï¼Œæ£€æŸ¥ç‚¹å’Œè°ƒåº¦ç¨‹åºã€‚æˆ‘ä»¬å°†åƒå¯¹å¾…å…¶ä»–è®­ç»ƒæ“ä½œé‚£æ ·è°ƒç”¨ fitã€‚åœ¨æœ€åï¼Œæˆ‘ä»¬å°†å¯¹å…¶è¿›è¡Œè¯„ä¼°å¹¶æ‰“å°å‡ºç»“æœã€‚æˆ‘ä»¬è¿˜å°†è·Ÿè¸ªè¿™èŠ±äº†å¤šå°‘æ—¶é—´å¹¶æ‰“å°å‡ºæ¥ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬è¿è¡Œè¿™äº›ä¸œè¥¿ï¼Œä»¥ä¾¿å®ƒå¯ç”¨ã€‚è¿™æ˜¯æˆ‘ä»¬å°†å®é™…è¿è¡Œçš„åœ°æ–¹ï¼Œæ‰€ä»¥æˆ‘å°†ç»§ç»­å¯åŠ¨å®ƒï¼Œå› ä¸ºè¿™éœ€è¦ä¸€ç‚¹æ—¶é—´ï¼Œä¸è¿‡ä¸ä¹…ã€‚
- en: We are going to train it for three epochsï¼Œ which is not very muchã€‚ I just want
    to get an initial train in hereã€‚ I could force interrupt it in some wayã€‚ but this
    works just fine and it's continuing and you can see we're on Epoch one of three
    This is all pretty standard stuff for what we've had before except you will see
    now that it's saying saving model to here and it's also saying that it's saving
    the optimizerã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è®­ç»ƒä¸‰æ¬¡çºªå…ƒï¼Œè¿™å¹¶ä¸ç®—å¾ˆå¤šã€‚æˆ‘åªæ˜¯æƒ³åœ¨è¿™é‡Œè¿›è¡Œä¸€æ¬¡åˆæ­¥è®­ç»ƒã€‚æˆ‘å¯ä»¥ä»¥æŸç§æ–¹å¼å¼ºåˆ¶ä¸­æ–­ï¼Œä½†è¿™æ ·åšæ²¡é—®é¢˜ï¼Œå®ƒåœ¨ç»§ç»­ï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¤„äºä¸‰æ¬¡çºªå…ƒä¸­çš„ç¬¬ä¸€çºªå…ƒã€‚è¿™å¯¹äºæˆ‘ä»¬ä¹‹å‰çš„å†…å®¹æ¥è¯´éƒ½æ˜¯æ ‡å‡†æ“ä½œï¼Œåªæ˜¯ä½ ç°åœ¨ä¼šçœ‹åˆ°å®ƒåœ¨è¯´å°†æ¨¡å‹ä¿å­˜åˆ°è¿™é‡Œï¼Œå¹¶ä¸”å®ƒè¿˜åœ¨è¯´æ­£åœ¨ä¿å­˜ä¼˜åŒ–å™¨ã€‚
- en: If I could spell optimizerï¼Œ that'd be nice to the pickle file and the two filesã€‚
    you're going to want those file names and you also want to make sure you're running
    GPU acceleration or this little training bit here will take considerably longer
    It's done already so you've got these two file names here you'll want those you'll
    copy those and these are the two files that you have there I don't know why it's
    been smart and hyperlinking them it doesn't go to anywhere those will give you
    a 404 if you try to click those but if we list the directory you will see basically
    that's the directory it created if we actually look into that directory you're
    going to see all the files there's the log Txt file which is exactly the same
    as your console up here but that way you have a record of it and all of these
    various checkpoints those last three those last two from the third epoch are the
    ones that you will want to continue from and by the way that getconfig thatã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘èƒ½æ‹¼å†™ä¼˜åŒ–å™¨ï¼Œé‚£å¯¹ pickle æ–‡ä»¶å’Œè¿™ä¸¤ä¸ªæ–‡ä»¶ä¼šå¾ˆå¥½ã€‚ä½ ä¼šæƒ³è¦è¿™äº›æ–‡ä»¶åï¼Œå¹¶ç¡®ä¿ä½ æ­£åœ¨è¿è¡Œ GPU åŠ é€Ÿï¼Œå¦åˆ™è¿™ä¸ªè®­ç»ƒè¿‡ç¨‹ä¼šèŠ±è´¹ç›¸å½“é•¿çš„æ—¶é—´ã€‚å®ƒå·²ç»å®Œæˆäº†ï¼Œæ‰€ä»¥ä½ æœ‰è¿™ä¸¤ä¸ªæ–‡ä»¶åï¼Œä½ ä¼šæƒ³è¦è¿™äº›ï¼Œä½ ä¼šå¤åˆ¶å®ƒä»¬ï¼Œè¿™å°±æ˜¯ä½ æ‹¥æœ‰çš„ä¸¤ä¸ªæ–‡ä»¶ã€‚æˆ‘ä¸çŸ¥é“ä¸ºä»€ä¹ˆå®ƒä¼šæ™ºèƒ½åœ°è¶…é“¾æ¥å®ƒä»¬ï¼Œç‚¹å‡»æ—¶ä¼šå‡ºç°404é”™è¯¯ï¼Œä½†å¦‚æœæˆ‘ä»¬åˆ—å‡ºç›®å½•ï¼Œä½ å°†çœ‹åˆ°åŸºæœ¬ä¸Šè¿™æ˜¯å®ƒåˆ›å»ºçš„ç›®å½•ã€‚å¦‚æœæˆ‘ä»¬å®é™…æŸ¥çœ‹é‚£ä¸ªç›®å½•ï¼Œä½ ä¼šçœ‹åˆ°æ‰€æœ‰æ–‡ä»¶ï¼ŒåŒ…æ‹¬
    log Txt æ–‡ä»¶ï¼Œå®ƒå’Œä½ ä¸Šé¢çš„æ§åˆ¶å°æ˜¯ä¸€æ ·çš„ï¼Œè¿™æ ·ä½ å°±æœ‰äº†è®°å½•ï¼Œè¿˜æœ‰è¿™äº›å„ç§æ£€æŸ¥ç‚¹ï¼Œæœ€åä¸‰ä¸ªæ£€æŸ¥ç‚¹ä¸­ï¼Œç¬¬ä¸‰ä¸ªçºªå…ƒçš„æœ€åä¸¤ä¸ªæ˜¯ä½ æƒ³è¦ç»§ç»­çš„ï¼Œè€Œé¡ºä¾¿æä¸€ä¸‹ï¼Œé‚£å°±æ˜¯
    getconfigã€‚
- en: Were calling on the optimizer that we are saving so that we are able to continue
    with the optimizer as well you can see basically what it is printing out here
    so now let's continue the training These names are potentially different than
    what I had up there so I copied them let me go up here and copy the last two names
    I'm just going copy and paste on so I decrease the odds of me making some sort
    of a dumb mistake there we goã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è°ƒç”¨æ­£åœ¨ä¿å­˜çš„ä¼˜åŒ–å™¨ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½ç»§ç»­ä½¿ç”¨ä¼˜åŒ–å™¨ã€‚ä½ åŸºæœ¬ä¸Šå¯ä»¥çœ‹åˆ°å®ƒæ‰“å°å‡ºçš„å†…å®¹ã€‚ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­è®­ç»ƒã€‚è¿™äº›åç§°å¯èƒ½ä¸æˆ‘ä¹‹å‰çš„ä¸åŒï¼Œæ‰€ä»¥æˆ‘å¤åˆ¶äº†å®ƒä»¬ï¼Œè®©æˆ‘ä¸Šå»å¤åˆ¶æœ€åä¸¤ä¸ªåç§°ï¼Œæˆ‘åªæ˜¯å¤åˆ¶ç²˜è´´ï¼Œè¿™æ ·å°±å‡å°‘äº†æˆ‘çŠ¯ä¸€äº›æ„šè ¢é”™è¯¯çš„å¯èƒ½æ€§ã€‚
- en: And I'll delete this and we'll just go ahead and define those two and now we're
    going to run this codeã€‚ you'll notice I have the load model dataï¼Œ this is loading
    those two pathsã€‚ you pass those two paths to there it loads the model with a very
    simple load model command and then it opens up the pickle file and extracts from
    itã€‚ the number of epos and the training optionsã€‚You'll want to add to this if
    you're doing something more complicated where you need to store additional things
    beyond just that learning rateã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åˆ é™¤è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ç»§ç»­å®šä¹‰è¿™ä¸¤ä¸ªï¼Œç°åœ¨æˆ‘ä»¬è¦è¿è¡Œè¿™æ®µä»£ç ã€‚ä½ ä¼šæ³¨æ„åˆ°æˆ‘æœ‰åŠ è½½æ¨¡å‹æ•°æ®ï¼Œè¿™æ­£åœ¨åŠ è½½è¿™ä¸¤ä¸ªè·¯å¾„ã€‚ä½ å°†è¿™ä¸¤ä¸ªè·¯å¾„ä¼ é€’ç»™å®ƒï¼Œå®ƒç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„åŠ è½½æ¨¡å‹å‘½ä»¤åŠ è½½æ¨¡å‹ï¼Œç„¶åæ‰“å¼€pickleæ–‡ä»¶å¹¶æå–å…¶ä¸­çš„å‘¨æœŸæ•°é‡å’Œè®­ç»ƒé€‰é¡¹ã€‚å¦‚æœä½ è¦åšæ›´å¤æ‚çš„äº‹æƒ…ï¼Œéœ€è¦å­˜å‚¨çš„ä¸ä»…ä»…æ˜¯å­¦ä¹ ç‡ï¼Œä½ ä¼šæƒ³è¦åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ·»åŠ ã€‚
- en: the learning rate that I have is entirely driven by the epochã€‚ So it so long
    as the epoch is saved It's it's good to goã€‚ Notice how we compile itï¼Œ thoughã€‚
    this is a little differentã€‚ the optimizerï¼Œ I am creating a new optimizer fromã€‚Aomã€‚
    so I am potentially changing the optimizer that was there when we call build modelã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ‰€ä½¿ç”¨çš„å­¦ä¹ ç‡å®Œå…¨ç”±å‘¨æœŸé©±åŠ¨ã€‚æ‰€ä»¥åªè¦å‘¨æœŸè¢«ä¿å­˜ï¼Œå°±å¯ä»¥ç»§ç»­è¿›è¡Œã€‚æ³¨æ„æˆ‘ä»¬æ˜¯å¦‚ä½•ç¼–è¯‘å®ƒçš„ï¼Œè¿™æœ‰ç‚¹ä¸åŒã€‚æˆ‘æ­£åœ¨ä»Aomåˆ›å»ºä¸€ä¸ªæ–°çš„ä¼˜åŒ–å™¨ï¼Œå› æ­¤æˆ‘å¯èƒ½æ­£åœ¨æ›´æ”¹åœ¨è°ƒç”¨æ„å»ºæ¨¡å‹æ—¶å­˜åœ¨çš„ä¼˜åŒ–å™¨ã€‚
- en: which builds a blank untrained modelã€‚ So I'm changing the optimizer out and
    reading its config from those options that we savedã€‚ that will have some ramifications
    that we'll see here in a secondã€‚ mainly I'm going to have to recompil itã€‚ So if
    I run this code just so that it's going because I think that yeahã€‚ that's the
    last stepã€‚ you'll notice hereï¼Œ I call this in I train the modelã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å»ºäº†ä¸€ä¸ªç©ºçš„æœªè®­ç»ƒæ¨¡å‹ã€‚æ‰€ä»¥æˆ‘åœ¨æ›´æ¢ä¼˜åŒ–å™¨ï¼Œå¹¶ä»æˆ‘ä»¬ä¿å­˜çš„é‚£äº›é€‰é¡¹ä¸­è¯»å–å…¶é…ç½®ã€‚è¿™å°†äº§ç”Ÿä¸€äº›å½±å“ï¼Œæˆ‘ä»¬ç¨åä¼šçœ‹åˆ°ã€‚ä¸»è¦æ˜¯æˆ‘å°†ä¸å¾—ä¸é‡æ–°ç¼–è¯‘å®ƒã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™æ®µä»£ç ï¼Œç¡®ä¿å®ƒæ­£åœ¨è¿›è¡Œï¼Œå› ä¸ºæˆ‘æƒ³è¿™æ˜¯æœ€åä¸€æ­¥ã€‚ä½ ä¼šæ³¨æ„åˆ°ï¼Œæˆ‘åœ¨è¿™é‡Œè°ƒç”¨å®ƒï¼Œè®­ç»ƒæ¨¡å‹ã€‚
- en: I pass in the initial epoch is the one that I loaded and the max epos at 6ã€‚
    So we're saving some moreã€‚ And againï¼Œ the compile step that I head hereï¼Œ that's
    recompilingã€‚The model with the new optimizer might not be necessary depending
    on the optimizer that you haveã€‚ but compiling the model does not erase your weights
    that is justã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¼ å…¥çš„åˆå§‹å‘¨æœŸæ˜¯æˆ‘åŠ è½½çš„é‚£ä¸ªï¼Œæœ€å¤§å‘¨æœŸæ˜¯6ã€‚æ‰€ä»¥æˆ‘ä»¬ä¿å­˜äº†ä¸€äº›æ›´å¤šçš„å†…å®¹ã€‚å†è¯´ä¸€æ¬¡ï¼Œæˆ‘åœ¨è¿™é‡Œçš„ç¼–è¯‘æ­¥éª¤ï¼Œæ˜¯ç”¨æ–°çš„ä¼˜åŒ–å™¨é‡æ–°ç¼–è¯‘æ¨¡å‹ï¼Œè¿™å¯èƒ½ä¸æ˜¯å¿…è¦çš„ï¼Œå…·ä½“å–å†³äºä½ æ‰€ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼Œä½†ç¼–è¯‘æ¨¡å‹å¹¶ä¸ä¼šåˆ é™¤ä½ çš„æƒé‡ã€‚
- en: Really defining the optimizer and building that whole graph that's going to
    be executedã€‚ and you can see that it's doneã€‚ So notice the key things Epoch started
    at four and it ended at sixã€‚Notice the accuracy when it started it was 98 so that
    was the starting accuracy right out of the gate whereas the earlier one had 94%
    accuracy so it didn't have to start over you can see that it really kind of continued
    right from right from here so this is how you continue training or maybe you decide
    that you want to send your neural network back for a master's degree additional
    training this is how you do it all right thank you for watching this video if
    you're interested in artificial intelligence and more on this course other things
    please subscribe to the channelã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šæ˜¯å®šä¹‰ä¼˜åŒ–å™¨å¹¶æ„å»ºå°†è¦æ‰§è¡Œçš„æ•´ä¸ªå›¾ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™å·²ç»å®Œæˆã€‚æ‰€ä»¥æ³¨æ„å…³é”®ç‚¹ï¼Œå‘¨æœŸä»å››å¼€å§‹ï¼Œç»“æŸäºå…­ã€‚æ³¨æ„å‡†ç¡®åº¦ï¼Œå¼€å§‹æ—¶æ˜¯98ï¼Œæ‰€ä»¥è¿™æ˜¯å¯åŠ¨æ—¶çš„å‡†ç¡®åº¦ï¼Œè€Œä¹‹å‰çš„æ˜¯94%å‡†ç¡®åº¦ï¼Œå› æ­¤ä¸éœ€è¦ä»å¤´å¼€å§‹ï¼Œä½ å¯ä»¥çœ‹åˆ°å®ƒå®é™…ä¸Šæ˜¯ä»è¿™é‡Œç»§ç»­çš„ã€‚è¿™å°±æ˜¯ä½ å¦‚ä½•ç»§ç»­è®­ç»ƒï¼Œæˆ–è€…ä¹Ÿè®¸ä½ å†³å®šå°†ç¥ç»ç½‘ç»œé€å›è¿›è¡Œé¢å¤–çš„è®­ç»ƒï¼Œè¿™å°±æ˜¯ä½ è¯¥æ€ä¹ˆåšã€‚è°¢è°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œå¦‚æœä½ å¯¹äººå·¥æ™ºèƒ½ä»¥åŠè¿™ä¸ªè¯¾ç¨‹çš„æ›´å¤šå†…å®¹æ„Ÿå…´è¶£ï¼Œè¯·è®¢é˜…é¢‘é“ã€‚
- en: '![](img/b54dc4281b74dae55dd425a171fc90c8_6.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b54dc4281b74dae55dd425a171fc90c8_6.png)'
- en: And thank you for watchingã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹ã€‚
