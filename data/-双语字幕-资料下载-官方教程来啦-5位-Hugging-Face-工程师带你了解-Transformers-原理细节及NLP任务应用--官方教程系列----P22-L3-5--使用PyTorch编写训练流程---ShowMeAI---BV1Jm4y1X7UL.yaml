- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠNLPä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P22ï¼šL3.5- ä½¿ç”¨PyTorchç¼–å†™è®­ç»ƒæµç¨‹ - ShowMeAI - BV1Jm4y1X7UL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠ NLP ä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P22ï¼šL3.5- ä½¿ç”¨ PyTorch ç¼–å†™è®­ç»ƒæµç¨‹ - ShowMeAI - BV1Jm4y1X7UL
- en: Write your own training loop bit by dochã€‚In this videoã€‚ along Kaar we can do
    the same functioning as in the train video but without relying on web classã€‚ this
    wayï¼Œ you'll be able to easily customize each type to of the training loop to your
    needsã€‚This is also very useful to manually debug something things that went along
    with the train APIã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰éƒ¨å°±ç­åœ°ç¼–å†™ä½ è‡ªå·±çš„è®­ç»ƒå¾ªç¯ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæ²¿ç€ Kaar çš„æ€è·¯ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ä¸è®­ç»ƒè§†é¢‘ä¸­ç›¸åŒçš„åŠŸèƒ½ï¼Œä½†ä¸ä¾èµ–äºç½‘ç»œè¯¾å ‚ã€‚è¿™æ ·ï¼Œä½ å°†èƒ½å¤Ÿè½»æ¾å®šåˆ¶æ¯ç§ç±»å‹çš„è®­ç»ƒå¾ªç¯ï¼Œä»¥æ»¡è¶³ä½ çš„éœ€æ±‚ã€‚è¿™å¯¹äºæ‰‹åŠ¨è°ƒè¯•è®­ç»ƒ
    API ä¸­å‡ºç°çš„é—®é¢˜ä¹Ÿéå¸¸æœ‰ç”¨ã€‚
- en: Before we dive into the codeï¼Œ here is a sketch of a training loopã€‚We take a
    batch of training data and feed it to the modelã€‚With the labelsï¼Œ we can get computer
    lessã€‚That number is not useful in turnï¼Œ but is used to compute the gradient of
    our model weightsï¼›
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬æ·±å…¥ä»£ç ä¹‹å‰ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªè®­ç»ƒå¾ªç¯çš„è‰å›¾ã€‚æˆ‘ä»¬å–ä¸€æ‰¹è®­ç»ƒæ•°æ®å¹¶å°†å…¶é¦ˆé€ç»™æ¨¡å‹ã€‚é€šè¿‡æ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºè¾ƒå°‘çš„å€¼ã€‚è¿™ä¸ªæ•°å­—æœ¬èº«å¹¶æ²¡æœ‰ç”¨å¤„ï¼Œä½†ç”¨äºè®¡ç®—æˆ‘ä»¬æ¨¡å‹æƒé‡çš„æ¢¯åº¦ï¼›
- en: that is the derivative of thes with respect to each model weightã€‚Those gradients
    are then used by the optimizer to update the model ways and make them a little
    bit betterã€‚We then repeated the process with a new batch of training dataã€‚If any
    of this isn'tã€‚ don't hesitate to take a refresher on your fabric deep learning
    courseã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³äºæ¯ä¸ªæ¨¡å‹æƒé‡çš„å¯¼æ•°ã€‚è¿™äº›æ¢¯åº¦éšåè¢«ä¼˜åŒ–å™¨ç”¨æ¥æ›´æ–°æ¨¡å‹æƒé‡ï¼Œä½¿å…¶å˜å¾—æ›´å¥½ã€‚ç„¶åæˆ‘ä»¬ç”¨ä¸€æ‰¹æ–°çš„è®­ç»ƒæ•°æ®é‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚å¦‚æœå…¶ä¸­ä»»ä½•ä¸€é¡¹å‡ºç°é—®é¢˜ï¼Œè¯·ä¸è¦çŠ¹è±«ï¼Œé‡æ–°å¤ä¹ ä½ çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ã€‚
- en: We'll use the G MRRPC dataset set here againï¼Œ and we're seen to propose head
    the data using the data sets library with dynamicy Pddingã€‚Check out the videos
    link below if you haven't seen them alreadyã€‚With this doneã€‚ we only have to define
    Pytorrch data loadorsï¼Œ which will be responsible to convert the elements of a
    dataset set into patchesã€‚We use our data coulator for padding as a correct function
    and sh for the training set to make sure we don't go through the samples in the
    same order as a cheaperã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨è¿™é‡Œå†æ¬¡ä½¿ç”¨ G MRRPC æ•°æ®é›†ï¼Œå¹¶å»ºè®®ä½¿ç”¨åŠ¨æ€å¡«å……çš„æ•°æ®é›†åº“æ¥å¤„ç†æ•°æ®ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰çœ‹è¿‡ï¼Œè¯·æŸ¥çœ‹ä¸‹é¢çš„è§†é¢‘é“¾æ¥ã€‚å®Œæˆè¿™äº›åï¼Œæˆ‘ä»¬åªéœ€è¦å®šä¹‰
    PyTorch æ•°æ®åŠ è½½å™¨ï¼Œå®ƒå°†è´Ÿè´£å°†æ•°æ®é›†çš„å…ƒç´ è½¬æ¢ä¸ºè¡¥ä¸ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®å¡«å……å™¨ä½œä¸ºæ­£ç¡®å‡½æ•°ï¼Œå¹¶å¯¹è®­ç»ƒé›†è¿›è¡Œå¤„ç†ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šæŒ‰ç…§ä¾¿å®œçš„é¡ºåºéå†æ ·æœ¬ã€‚
- en: To check that everything works as intendedï¼Œ we try to grab a batch of data and
    inspect itã€‚Like how that asset set elementsï¼Œ it's a dictionaryã€‚ but this time
    the values are not a single list of integersã€‚ but the tonso of shapepa sizes by
    sequence lengthã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ£€æŸ¥ä¸€åˆ‡æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œï¼Œæˆ‘ä»¬å°è¯•æŠ“å–ä¸€æ‰¹æ•°æ®å¹¶è¿›è¡Œæ£€æŸ¥ã€‚å°±åƒè¯¥èµ„äº§é›†å…ƒç´ ä¸€æ ·ï¼Œå®ƒæ˜¯ä¸€ä¸ªå­—å…¸ã€‚ä½†è¿™æ¬¡å€¼ä¸æ˜¯å•ä¸€çš„æ•´æ•°åˆ—è¡¨ï¼Œè€Œæ˜¯æŒ‰åºåˆ—é•¿åº¦åˆ’åˆ†çš„å½¢çŠ¶å¤§å°ã€‚
- en: The next step is to send the training data in our modelã€‚Now that will need to
    actually create a modelã€‚As seen in the model API videoã€‚ we use the front pretrained
    method and adjust the number of labels to the number of classes we have on this
    dataset set here tooã€‚Againï¼Œ to be sure everything is going wellï¼Œ we pass the batch
    we to our model and check there is no errorã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥æ˜¯å°†è®­ç»ƒæ•°æ®å‘é€åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚ç°åœ¨éœ€è¦å®é™…åˆ›å»ºä¸€ä¸ªæ¨¡å‹ã€‚æ­£å¦‚åœ¨æ¨¡å‹ API è§†é¢‘ä¸­æ‰€è§ï¼Œæˆ‘ä»¬ä½¿ç”¨å‰è®­ç»ƒçš„æ–¹æ³•ï¼Œå¹¶å°†æ ‡ç­¾çš„æ•°é‡è°ƒæ•´ä¸ºè¯¥æ•°æ®é›†ä¸­çš„ç±»åˆ«æ•°é‡ã€‚åŒæ ·ï¼Œä¸ºäº†ç¡®ä¿ä¸€åˆ‡é¡ºåˆ©ï¼Œæˆ‘ä»¬å°†æ‰¹æ¬¡ä¼ é€’ç»™æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦æ²¡æœ‰é”™è¯¯ã€‚
- en: I the labels are providedï¼Œ the models of the Transence library always returns
    the list directlyã€‚We'll be able to do less step backward to compute all the gradientã€‚
    and we'll then need the Optr to do the training stepã€‚We use the Adam W optimizer
    hereã€‚ which is the variant of Adam with proper weight decayã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæä¾›äº†æ ‡ç­¾ï¼ŒTransence åº“çš„æ¨¡å‹æ€»æ˜¯ä¼šç›´æ¥è¿”å›åˆ—è¡¨ã€‚æˆ‘ä»¬å°†èƒ½å¤Ÿè¿›è¡Œæ›´å°‘çš„æ­¥éª¤æ¥è®¡ç®—æ‰€æœ‰çš„æ¢¯åº¦ã€‚ç„¶åæˆ‘ä»¬éœ€è¦ä¼˜åŒ–å™¨æ¥è¿›è¡Œè®­ç»ƒæ­¥éª¤ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨
    Adam W ä¼˜åŒ–å™¨ï¼Œå®ƒæ˜¯å…·æœ‰é€‚å½“æƒé‡è¡°å‡çš„ Adam å˜ä½“ã€‚
- en: but you can pick any by doch optimizer you likeã€‚Using the previous loss and
    computing the gradients we've listeded backwardã€‚ we check that we can do the optimizer
    step without an errorã€‚Don't forget to zero your gradient afterwardï¼Œ or the next
    step from get added to the gradient you computedã€‚We got already white or training
    loopï¼Œ but we add two more things to make it as good as it can beã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ å¯ä»¥é€‰æ‹©ä»»ä½•ä½ å–œæ¬¢çš„ä¼˜åŒ–å™¨ã€‚åˆ©ç”¨ä¹‹å‰çš„æŸå¤±å¹¶è®¡ç®—æˆ‘ä»¬æ‰€åˆ—å‡ºçš„æ¢¯åº¦åå‘ä¼ æ’­ï¼Œæˆ‘ä»¬æ£€æŸ¥èƒ½å¦åœ¨æ²¡æœ‰é”™è¯¯çš„æƒ…å†µä¸‹æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤ã€‚ä¸è¦å¿˜è®°åœ¨ä¹‹åå°†æ¢¯åº¦å½’é›¶ï¼Œå¦åˆ™ä¸‹ä¸€æ­¥å°†ä¼šåŠ åˆ°ä½ è®¡ç®—çš„æ¢¯åº¦ä¸Šã€‚æˆ‘ä»¬å·²ç»æœ‰äº†åŸºæœ¬çš„è®­ç»ƒå¾ªç¯ï¼Œä½†æˆ‘ä»¬æ·»åŠ äº†ä¸¤é¡¹å†…å®¹ï¼Œä½¿å…¶å°½å¯èƒ½å®Œå–„ã€‚
- en: The first one is a learning rate scheduler to progressively decay a learning
    rate to0ã€‚The GtSched function from the Transformer library is just a convenience
    function to easily build searcher Schã€‚You can again use any Pythto learning weight
    scheduler insteadã€‚Finallyã€‚ if we want our training to take a couple of minutes
    instead of a few hours we'll need to use a GPU the first step is to get one for
    instance by using a collaborative bookã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæ˜¯å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œç”¨äºé€æ­¥é™ä½å­¦ä¹ ç‡åˆ°0ã€‚Transformeråº“ä¸­çš„GtSchedå‡½æ•°åªæ˜¯ä¸€ä¸ªä¾¿åˆ©å‡½æ•°ï¼Œç”¨äºè½»æ¾æ„å»ºæœç´¢å™¨Schã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ä»»ä½•Pythtoå­¦ä¹ æƒé‡è°ƒåº¦å™¨ã€‚æœ€åï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›è®­ç»ƒæŒç»­å‡ åˆ†é’Ÿè€Œä¸æ˜¯å‡ ä¸ªå°æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨GPUï¼Œç¬¬ä¸€æ­¥æ˜¯é€šè¿‡ä½¿ç”¨åä½œä¹¦ç±æ¥è·å–ä¸€ä¸ªå®ä¾‹ã€‚
- en: Then you need to actually send your model and training that on it by using a
    dashch deviceã€‚Do will check the following lines point your good databases for
    you or be prepared for your training to last more than an hourã€‚We cannot put everything
    togetherã€‚Firstï¼Œ we put our model in training modeã€‚ which will activate the training
    behavior for some layers like dropoutã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ éœ€è¦å®é™…å‘é€ä½ çš„æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªdashchè®¾å¤‡è¿›è¡Œè®­ç»ƒã€‚è¯·æ£€æŸ¥ä»¥ä¸‹å‡ è¡Œï¼Œä»¥ç¡®ä¿ä½ æœ‰å¥½çš„æ•°æ®åº“ï¼Œæˆ–è€…å‡†å¤‡å¥½ä½ çš„è®­ç»ƒæ—¶é—´è¶…è¿‡ä¸€ä¸ªå°æ—¶ã€‚æˆ‘ä»¬æ— æ³•å°†æ‰€æœ‰å†…å®¹ç»„åˆåœ¨ä¸€èµ·ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ¨¡å‹ç½®äºè®­ç»ƒæ¨¡å¼ã€‚è¿™å°†æ¿€æ´»ä¸€äº›å±‚çš„è®­ç»ƒè¡Œä¸ºï¼Œæ¯”å¦‚dropoutã€‚
- en: Then we go through the number of reports books we picked and all the data in
    our training dataã€‚Then we go through all the steps we've seen alreadyï¼Œ send the
    data to the GPUã€‚ compute the model outputsï¼Œ and in particular the lessã€‚Use the
    list to compute gradientsã€‚ then make a training step with the optimizerã€‚Updates
    are earn rate and our schedule error for the next detereration and the gradient
    of the optimizerã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡æ‰€é€‰æ‹©çš„æŠ¥å‘Šä¹¦æ•°é‡å’Œè®­ç»ƒæ•°æ®ä¸­çš„æ‰€æœ‰æ•°æ®ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å›é¡¾æˆ‘ä»¬å·²ç»çœ‹åˆ°çš„æ‰€æœ‰æ­¥éª¤ï¼Œå°†æ•°æ®å‘é€åˆ°GPUï¼Œè®¡ç®—æ¨¡å‹è¾“å‡ºï¼Œç‰¹åˆ«æ˜¯æŸå¤±ã€‚ä½¿ç”¨åˆ—è¡¨æ¥è®¡ç®—æ¢¯åº¦ï¼Œç„¶åä½¿ç”¨ä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒæ­¥éª¤ã€‚æ›´æ–°åŒ…æ‹¬å­¦ä¹ ç‡å’Œæˆ‘ä»¬ä¸‹ä¸€ä¸ªè¿­ä»£çš„è°ƒåº¦è¯¯å·®ï¼Œä»¥åŠä¼˜åŒ–å™¨çš„æ¢¯åº¦ã€‚
- en: Once this is finishedï¼Œ we can evaluate our model very easily with a metric from
    the dataset sets libraryã€‚ğŸ˜Šï¼ŒFirstï¼Œ we put our model in the evaluation mode to deactivate
    layers like dropoutã€‚Then goes through all the des the evaluation theã€‚As we' seen
    in the trainer videoã€‚ the model outputs logggets and we need to apply the Agm
    function to convert them into predictionsã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦å®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨æ•°æ®é›†åº“ä¸­çš„metricæ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚ğŸ˜Šé¦–å…ˆï¼Œæˆ‘ä»¬å°†æ¨¡å‹ç½®äºè¯„ä¼°æ¨¡å¼ï¼Œä»¥åœç”¨åƒdropoutè¿™æ ·çš„å±‚ã€‚ç„¶åè¿›è¡Œæ‰€æœ‰è¯„ä¼°æ­¥éª¤ã€‚å¦‚æˆ‘ä»¬åœ¨è®­ç»ƒè§†é¢‘ä¸­çœ‹åˆ°çš„ï¼Œæ¨¡å‹è¾“å‡ºçš„æ˜¯logggetsï¼Œæˆ‘ä»¬éœ€è¦åº”ç”¨Agmå‡½æ•°å°†å…¶è½¬æ¢ä¸ºé¢„æµ‹ã€‚
- en: The metric object then has a net batch method we can use to send it for intermediate
    predictionsã€‚Once the evaluation loop is finishedï¼Œ you just have to call the compute
    method to get the final resultsã€‚Congratulationsï¼Œ you have no find model all by
    yourselfã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œmetricå¯¹è±¡æœ‰ä¸€ä¸ªnet batchæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ¥å‘é€ä¸­é—´é¢„æµ‹ã€‚ä¸€æ—¦è¯„ä¼°å¾ªç¯ç»“æŸï¼Œä½ åªéœ€è°ƒç”¨computeæ–¹æ³•ä»¥è·å–æœ€ç»ˆç»“æœã€‚æ­å–œä½ ï¼Œä½ å·²ç»ç‹¬ç«‹æ‰¾åˆ°æ¨¡å‹ã€‚
- en: '![](img/e8f7bf95fa7a3fb25fc811f317b88cfb_1.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8f7bf95fa7a3fb25fc811f317b88cfb_1.png)'
- en: ã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ã€‚
- en: '![](img/e8f7bf95fa7a3fb25fc811f317b88cfb_3.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8f7bf95fa7a3fb25fc811f317b88cfb_3.png)'
