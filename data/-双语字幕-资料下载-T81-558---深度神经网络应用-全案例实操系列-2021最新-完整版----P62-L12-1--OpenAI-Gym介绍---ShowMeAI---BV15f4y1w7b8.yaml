- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P62ï¼šL12.1- OpenAI Gymä»‹ç»
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P62ï¼šL12.1- OpenAI Gymä»‹ç»
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeffyã€‚ Wecome to applications of deep neural networks with Washington
    Universityã€‚ In this moduleï¼Œ we're going to look at AI gymã€‚ So AI gym is aã€‚ğŸ˜Šã€‚Benchmark
    platform that lets you in Python evaluate your reinforcement learning programs
    against wellknown gamesã€‚ Atari games and other things like thatã€‚ So we're going
    to see how you can actually interface into this and use this to even watch the
    games play on the screen or to train them in an offline way to see all my videos
    about kgel neural networks and other AI topicsã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯Jeffyã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨æ¨¡å—ã€‚åœ¨è¿™ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹AI Gymã€‚æ‰€ä»¥AI Gymæ˜¯ä¸€ä¸ªğŸ˜ŠåŸºå‡†å¹³å°ï¼Œè®©ä½ åœ¨Pythonä¸­è¯„ä¼°ä½ çš„å¼ºåŒ–å­¦ä¹ ç¨‹åºï¼Œä¸è‘—åæ¸¸æˆå¦‚Atariæ¸¸æˆç­‰è¿›è¡Œå¯¹æ¯”ã€‚æ‰€ä»¥æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å®é™…ä¸è¿™ä¸ªæ¥å£ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥è§‚çœ‹æ¸¸æˆåœ¨å±å¹•ä¸Šæ’­æ”¾ï¼Œæˆ–è€…ä»¥ç¦»çº¿æ–¹å¼è®­ç»ƒï¼Œçœ‹çœ‹æˆ‘å…³äºkgelç¥ç»ç½‘ç»œå’Œå…¶ä»–AIä¸»é¢˜çš„æ‰€æœ‰è§†é¢‘ã€‚
- en: click the subscribe button and the bell next to it and select all to be notified
    of every new video So let's take a look at open AI gym So reinforcement learning
    is what we're dealing with for this module and the next five parts So reinforcement
    learning it's not like supervised learning or unsupervised learning it is really
    sometimes referred to a selfupervised It's going to happen is you're going to
    give the computer some sort of a gameã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹å‡»è®¢é˜…æŒ‰é’®å’Œæ—è¾¹çš„é“ƒé“›ï¼Œå¹¶é€‰æ‹©å…¨éƒ¨ä»¥æ¥æ”¶æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬æ¥çœ‹çœ‹OpenAI Gymã€‚åœ¨è¿™ä¸ªæ¨¡å—å’Œæ¥ä¸‹æ¥çš„äº”ä¸ªéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¼ºåŒ–å­¦ä¹ ã€‚å¼ºåŒ–å­¦ä¹ ä¸ç›‘ç£å­¦ä¹ æˆ–æ— ç›‘ç£å­¦ä¹ ä¸åŒï¼Œå®ƒæœ‰æ—¶è¢«ç§°ä¸ºè‡ªæˆ‘ç›‘ç£ã€‚ä½ å°†ç»™è®¡ç®—æœºæä¾›æŸç§æ¸¸æˆã€‚
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_1.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_1.png)'
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_2.png)'
- en: And it doesn't have to be gameã€‚ It could beï¼Œ it's really anything that has well
    defined rules and can be completely simulated in the computerã€‚ So basically a
    gameï¼Œ butã€‚To use this for other types of learningã€‚ you really need to express
    your problem in such a way so that the rules are well definedfined so that there's
    kind of an increment as you go through episode So each play of the game so to
    speak is an episode you go through a series of steps at each step the computer
    can take a given action and then at the endã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”è¿™ä¸ä¸€å®šæ˜¯æ¸¸æˆã€‚å®ƒå¯ä»¥æ˜¯ä»»ä½•æœ‰æ˜ç¡®è§„åˆ™ä¸”å¯ä»¥åœ¨è®¡ç®—æœºä¸­å®Œå…¨æ¨¡æ‹Ÿçš„ä¸œè¥¿ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªæ¸¸æˆï¼Œä½†è¦å°†å…¶ç”¨äºå…¶ä»–ç±»å‹çš„å­¦ä¹ ï¼Œä½ éœ€è¦ä»¥æŸç§æ–¹å¼è¡¨è¾¾ä½ çš„é—®é¢˜ï¼Œä½¿è§„åˆ™æ˜ç¡®ï¼Œä»¥ä¾¿åœ¨è¿›è¡Œè¿‡ç¨‹ä¸­æœ‰ä¸€ç§å¢é‡çš„è¿›å±•ã€‚æ¯å±€æ¸¸æˆå¯ä»¥ç§°ä¸ºä¸€ä¸ªå›åˆï¼Œä½ ç»å†ä¸€ç³»åˆ—æ­¥éª¤ï¼Œåœ¨æ¯ä¸€æ­¥ï¼Œè®¡ç®—æœºå¯ä»¥é‡‡å–ç‰¹å®šçš„åŠ¨ä½œï¼Œç„¶ååœ¨ç»“æŸæ—¶ã€‚
- en: its performance is evaluatedï¼Œ did it succeed or did it notï¼Œ and at each stepã€‚
    it is given a reward based on how well it did And the machine plays it over and
    over and over again and it's able to learn and get very good at playing this This
    was used and go and chess to develop extraordinarily powerful computers that can
    play better than the humans who ever taught it how to do this and it does this
    basically by playing chess essentially with itself because the rules are well
    well definedã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒçš„æ€§èƒ½è¢«è¯„ä¼°ï¼ŒæˆåŠŸäº†è¿˜æ˜¯å¤±è´¥äº†ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰æ‰€è¯„ä¼°ã€‚æ ¹æ®è¡¨ç°ç»™äºˆå¥–åŠ±ï¼Œæœºå™¨é‡å¤è¿›è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿå­¦ä¹ å¹¶å˜å¾—éå¸¸æ“…é•¿ã€‚è¿™åœ¨å›´æ£‹å’Œå›½é™…è±¡æ£‹ä¸­è¢«ç”¨æ¥å¼€å‘å‡ºè¶…å¼ºçš„è®¡ç®—æœºï¼Œèƒ½å¤Ÿä¸‹å¾—æ¯”æ•™å®ƒçš„ä»»ä½•äººéƒ½è¦å¥½ï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯é€šè¿‡ä¸è‡ªå·±ä¸‹æ£‹æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œå› ä¸ºè§„åˆ™éå¸¸æ˜ç¡®ã€‚
- en: It gets better and better and betterã€‚ And what's amazing about it is it needs
    no prior knowledge of chessã€‚ So all those chess books that talk about famous openings
    and whatnotã€‚ it's almost like an alien came from another parallel Earth that develop
    chess on their ownã€‚ but the two planets did not share any techniques on chessã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå˜å¾—è¶Šæ¥è¶Šå¥½ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå®ƒä¸éœ€è¦ä»»ä½•å…³äºå›½é™…è±¡æ£‹çš„å…ˆå‰çŸ¥è¯†ã€‚æ‰€ä»¥é‚£äº›è°ˆè®ºè‘—åå¼€å±€çš„å›½é™…è±¡æ£‹ä¹¦ç±ï¼Œå‡ ä¹å°±åƒæ˜¯ä¸€ä¸ªæ¥è‡ªå¦ä¸€ä¸ªå¹³è¡Œåœ°çƒçš„å¤–æ˜Ÿäººï¼Œè‡ªä¸»å‘å±•äº†å›½é™…è±¡æ£‹ï¼Œä½†è¿™ä¸¤ä¸ªæ˜Ÿçƒæ²¡æœ‰åˆ†äº«ä»»ä½•å›½é™…è±¡æ£‹çš„æŠ€å·§ã€‚
- en: So these extremely advanced chess players from the parallel world came to Earth
    to play and they're playing chess from a whole different rule bookã€‚ So I think
    that was part of the complexity too for the goplay as well to beat these highly
    optimized machinesã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™äº›æ¥è‡ªå¹³è¡Œä¸–ç•Œçš„æé«˜çº§æ£‹æ‰‹æ¥åˆ°åœ°çƒä¸‹æ£‹ï¼Œä»–ä»¬éµå¾ªå®Œå…¨ä¸åŒçš„è§„åˆ™ã€‚æˆ‘è®¤ä¸ºè¿™ä¹Ÿæ˜¯å‡»è´¥è¿™äº›é«˜åº¦ä¼˜åŒ–æœºå™¨çš„å¤æ‚æ€§çš„ä¸€éƒ¨åˆ†ã€‚
- en: So let's see open AI labã€‚ So open AI lab Jim is basically a bunch of gamesã€‚
    even the Atari games all set up so that you can have your program compete against
    themã€‚ So this is open AI gymã€‚ you can see that they have Atari gamesã€‚ these are
    running through an Atariã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹OpenAIå®éªŒå®¤ã€‚OpenAIå®éªŒå®¤åŸºæœ¬ä¸Šæ˜¯ä¸€å †æ¸¸æˆã€‚ç”šè‡³æ˜¯Atariæ¸¸æˆéƒ½è®¾ç½®å¥½ï¼Œè®©ä½ çš„ç¨‹åºå¯ä»¥ä¸å®ƒä»¬ç«äº‰ã€‚è¿™å°±æ˜¯OpenAI Gymã€‚ä½ å¯ä»¥çœ‹åˆ°ä»–ä»¬æœ‰Atariæ¸¸æˆï¼Œè¿™äº›æ¸¸æˆæ˜¯é€šè¿‡Atariè¿è¡Œçš„ã€‚
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_4.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_4.png)'
- en: LaterThat works really well on Mac and on Linux on Windowsã€‚ you can make it
    workã€‚ There is some complexities to getting the Atari emulator working on Windowsã€‚
    the classic games like you see here that is the pole cart that's the pendulumã€‚
    Those work just fine and we'll start off using pole cart and using mountain carã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåœ¨Macå’ŒLinuxä¸Šæ•ˆæœå¾ˆå¥½ï¼Œåœ¨Windowsä¸Šï¼Œä½ å¯ä»¥è®©å®ƒå·¥ä½œã€‚ä½†åœ¨Windowsä¸Šè®©Atariæ¨¡æ‹Ÿå™¨å·¥ä½œæœ‰ä¸€äº›å¤æ‚æ€§ã€‚ä½ çœ‹åˆ°çš„ç»å…¸æ¸¸æˆï¼Œæ¯”å¦‚è¿™ä¸ªæ†è½¦å’Œæ‘†é”¤ï¼Œè¿è¡Œå¾—å¾ˆå¥½ï¼Œæˆ‘ä»¬å°†å¼€å§‹ä½¿ç”¨æ†è½¦å’Œå±±åœ°è½¦ã€‚
- en: which are some fairly classic games for exampleï¼Œ let me show you what those
    look likeã€‚ if you click on the environmentsï¼Œ you can see these are the classic
    control gamesã€‚ The ones that we're going to work on in particular are cartpo and
    mountain carã€‚ There's two versions of mountain car and this becomes important
    when we see how to actually interact with theseã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›éƒ½æ˜¯ä¸€äº›ç›¸å½“ç»å…¸çš„æ¸¸æˆï¼Œä¾‹å¦‚ï¼Œè®©æˆ‘ç»™ä½ å±•ç¤ºä¸€ä¸‹å®ƒä»¬çš„æ ·å­ã€‚å¦‚æœä½ ç‚¹å‡»ç¯å¢ƒï¼Œä½ ä¼šçœ‹åˆ°è¿™äº›æ˜¯ç»å…¸çš„æ§åˆ¶æ¸¸æˆã€‚æˆ‘ä»¬ç‰¹åˆ«è¦å¤„ç†çš„æ¸¸æˆæ˜¯cartpoå’Œå±±åœ°è½¦ã€‚å±±åœ°è½¦æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼Œè¿™åœ¨æˆ‘ä»¬çœ‹åˆ°å¦‚ä½•å®é™…ä¸è¿™äº›äº’åŠ¨æ—¶å˜å¾—å¾ˆé‡è¦ã€‚
- en: there is this is mountain car that basically has a Boolean throttleã€‚ Either
    you've got your foot on the brake all the way down or you've got your foot on
    the gas all the way downã€‚ the idea of mountain cart mountain car is to try to
    get up here to this flagã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€è¾†å±±åœ°è½¦ï¼Œå®ƒåŸºæœ¬ä¸Šæœ‰ä¸€ä¸ªå¸ƒå°”æ²¹é—¨ã€‚è¦ä¹ˆä½ æŠŠè„šè¸©åœ¨åˆ¹è½¦ä¸Šåˆ°åº•ï¼Œè¦ä¹ˆè¸©åœ¨æ²¹é—¨ä¸Šåˆ°åº•ã€‚å±±åœ°è½¦çš„ç›®çš„æ˜¯å°½é‡åˆ°è¾¾è¿™ä¸ªæ——å¸œã€‚
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_6.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_6.png)'
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_7.png)'
- en: Car's engine is simply not powerful enough to do itã€‚ It is going to even if
    you floor itã€‚ So we pretty much have toã€‚ you've got three controls on this one
    forward backward and breakã€‚ So pushing it upï¼Œ it's going get to about here and
    then just roll back downã€‚ It just does not have enough momentum So what it needs
    to do is go as fast as it can roll back back back up hereã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è½¦çš„å‘åŠ¨æœºæ ¹æœ¬æ²¡æœ‰è¶³å¤Ÿçš„åŠ¨åŠ›å»åšåˆ°è¿™ä¸€ç‚¹ã€‚å³ä½¿ä½ å…¨åŠ›è¸©ä¸‹å»ï¼Œå®ƒä¹Ÿæ˜¯å¦‚æ­¤ã€‚å› æ­¤æˆ‘ä»¬åŸºæœ¬ä¸Šå¿…é¡»â€¦â€¦ä½ åœ¨è¿™ä¸ªæ¸¸æˆä¸­æœ‰ä¸‰ä¸ªæ§åˆ¶ï¼šå‘å‰ã€å‘åå’Œåˆ¹è½¦ã€‚æ‰€ä»¥æ¨ä¸Šå»ï¼Œå®ƒå¤§æ¦‚èƒ½åˆ°è¿™é‡Œï¼Œç„¶åå°±ä¼šæ»‘å›å»ã€‚å®ƒçš„åŠ¨é‡ä¸è¶³ã€‚å› æ­¤ï¼Œå®ƒéœ€è¦å°½å¯èƒ½å¿«åœ°å‘åæ»‘å›åˆ°è¿™é‡Œã€‚
- en: push it hard to go up here and then push it hard to go up here and eventually
    just by rocking back and forthã€‚ you get enough momentum that you make it up the
    hill So it takes a little AI to learn to do thatã€‚ I also show you an algorithm
    that I write that is just if statements that is able to solve it to basically
    just whichever direction you're going if you're going upã€‚ always force the throttle
    full speed the way up the hill you're going the continuous oneã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨åŠ›æ¨ä¸Šå»ï¼Œç„¶åç”¨åŠ›æ¨ä¸Šå»ï¼Œæœ€ç»ˆé€šè¿‡å‰åæ‘‡æ‘†ï¼Œä½ ä¼šè·å¾—è¶³å¤Ÿçš„åŠ¨é‡è®©å®ƒä¸Šå¡ã€‚å› æ­¤ï¼Œè¿™éœ€è¦ä¸€ç‚¹AIæ¥å­¦ä¹ å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘è¿˜ä¼šç»™ä½ å±•ç¤ºä¸€ä¸ªæˆ‘å†™çš„ç®—æ³•ï¼ŒåŸºæœ¬ä¸Šæ˜¯ä¸€äº›ifè¯­å¥ï¼Œèƒ½å¤Ÿè§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ— è®ºä½ å¾€å“ªä¸ªæ–¹å‘èµ°ï¼Œå¦‚æœä½ åœ¨ä¸Šå¡ï¼Œå°±å§‹ç»ˆè®©æ²¹é—¨å…¨åŠ›ä»¥èµ´å‘ä¸Šèµ°ã€‚
- en: you can push the pedal partially down or partially upã€‚ I don't think that really
    helpsã€‚ I think you pretty much need to floor it to make it up up the hillã€‚ This
    one's just trying to balance So you've got this pullã€‚I meanã€‚ think of it like
    if you took a meter rod or a yardstick and you tried to balance it on top of your
    hand and now walk across the room and have that not fall offã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥éƒ¨åˆ†è¸©ä¸‹æ²¹é—¨æˆ–éƒ¨åˆ†æ¾å¼€ã€‚æˆ‘è®¤ä¸ºè¿™å¹¶æ²¡æœ‰ä»€ä¹ˆå¸®åŠ©ã€‚æˆ‘è§‰å¾—ä½ å‡ ä¹éœ€è¦å…¨åŠ›è¸©ä¸‹å»æ‰èƒ½ä¸Šå¡ã€‚è¿™åªæ˜¯è¯•å›¾ä¿æŒå¹³è¡¡ï¼Œæ‰€ä»¥ä½ æœ‰è¿™ç§æ‹‰åŠ›ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ æ‹¿ä¸€æ ¹ç±³å°ºæˆ–ä¸€æ ¹ç å°ºï¼Œè¯•å›¾åœ¨æ‰‹ä¸Šå¹³è¡¡ï¼Œç„¶ååœ¨æˆ¿é—´é‡Œèµ°åŠ¨ï¼Œè€Œä¸è®©å®ƒæ‰ä¸‹æ¥ã€‚
- en: That's basically what it's trying to doã€‚So let's go back here to the notes for
    this section for this part in Google Collab in GitHub actually now we're opening
    it in Collabã€‚ so it's opened hereã€‚ Let's look at how to actually make use of AI
    gym I've got some basic information here but the first thing we're going to do
    is we're going to import AI gym and each of those games that I showed you is basically
    called an environment and this function that I just defined here essentially queries
    and environment you need to open up the environment and then you need to open
    up the specification for that environmentã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šæ˜¯å®ƒè¯•å›¾åšçš„äº‹æƒ…ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å›åˆ°è¿™é‡Œï¼Œåˆ°è¿™ä¸€éƒ¨åˆ†çš„æ³¨é‡Šä¸­ï¼Œåœ¨Google Collabä¸­å®é™…ä¸Šç°åœ¨æˆ‘ä»¬æ­£åœ¨æ‰“å¼€å®ƒåœ¨Collabä¸­æ‰“å¼€å®ƒã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å®é™…åˆ©ç”¨AI
    gymã€‚æˆ‘è¿™é‡Œæœ‰ä¸€äº›åŸºæœ¬ä¿¡æ¯ï¼Œä½†æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å¯¼å…¥AI gymå’Œæˆ‘å‘ä½ å±•ç¤ºçš„æ¯ä¸ªæ¸¸æˆåŸºæœ¬ä¸Šéƒ½ç§°ä¸ºä¸€ä¸ªç¯å¢ƒï¼Œè€Œæˆ‘åˆšåˆšå®šä¹‰çš„è¿™ä¸ªå‡½æ•°æœ¬è´¨ä¸Šæ˜¯æŸ¥è¯¢ç¯å¢ƒï¼Œä½ éœ€è¦æ‰“å¼€ç¯å¢ƒï¼Œç„¶åä½ éœ€è¦æ‰“å¼€è¯¥ç¯å¢ƒçš„è§„èŒƒã€‚
- en: What I'm doing here is you can run this for each of the environments that we're
    going to be dealing with and I'll show you it for a couple of Atari games as well
    If you run it for mountain car It tells you the action space The action space
    of this type is discrete So that means you can be doing three discrete things
    to run that mountain carã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œæ‰€åšçš„æ˜¯ä½ å¯ä»¥ä¸ºæˆ‘ä»¬å°†è¦å¤„ç†çš„æ¯ä¸ªç¯å¢ƒè¿è¡Œå®ƒï¼Œå¹¶ä¸”æˆ‘è¿˜å°†å‘æ‚¨å±•ç¤ºå®ƒé€‚ç”¨äºå‡ ä¸ªAtariæ¸¸æˆã€‚å¦‚æœä½ ä¸ºmountain carè¿è¡Œå®ƒï¼Œå®ƒå‘Šè¯‰ä½ åŠ¨ä½œç©ºé—´ï¼Œè¿™ç§ç±»å‹çš„åŠ¨ä½œç©ºé—´æ˜¯ç¦»æ•£çš„ã€‚è¿™æ„å‘³ç€ä½ å¯ä»¥åšä¸‰ç§ç¦»æ•£çš„äº‹æƒ…æ¥è¿è¡Œé‚£è¾†å±±è½¦ã€‚
- en: You can be going backwardsï¼Œ you can be applying the brakesã€‚ I think you're applying
    the brakesã€‚ It might be running idle I forget exactly and you can be going forwardã€‚
    I'll tell you on dealing with just about any of these environments I usually look
    at the source code and Github for that environment to really truly understand
    how they work Now the observation space So you've got the action spaceã€‚ these
    are things that you can do and then the observation space is basically how the
    world has changed Now there's two box values box basically means continuous so
    there's two continuous variables that come back and those two are basically telling
    you the location of that car left and right so how far up the hill essentially
    is it and in which side so it's essentially the X on that screen that was on and
    then the other value is how fast is it going and that's a plus or minus depending
    on which which direction it is moving it and that's the wholeã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å€’ç€èµ°ï¼Œä½ å¯ä»¥è¸©åˆ¹è½¦ã€‚æˆ‘è§‰å¾—ä½ åœ¨è¸©åˆ¹è½¦ã€‚å®ƒå¯èƒ½åœ¨ç©ºè½¬ï¼Œæˆ‘ä¸ç¡®å®šï¼Œä½ å¯ä»¥å‘å‰èµ°ã€‚æˆ‘å‘Šè¯‰ä½ ï¼Œæˆ‘å¤„ç†å‡ ä¹æ‰€æœ‰è¿™äº›ç¯å¢ƒæ—¶ï¼Œæˆ‘é€šå¸¸ä¼šæŸ¥çœ‹è¯¥ç¯å¢ƒçš„æºä»£ç å’ŒGithubï¼Œä»¥çœŸæ­£ç†è§£å®ƒä»¬æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ç°åœ¨æ˜¯è§‚å¯Ÿç©ºé—´ã€‚æ‰€ä»¥ä½ æœ‰åŠ¨ä½œç©ºé—´ã€‚è¿™äº›éƒ½æ˜¯ä½ å¯ä»¥åšçš„äº‹æƒ…ï¼Œç„¶åè§‚å¯Ÿç©ºé—´åŸºæœ¬ä¸Šæ˜¯ä¸–ç•Œå¦‚ä½•æ”¹å˜çš„ã€‚ç°åœ¨æœ‰ä¸¤ä¸ªæ¡†å€¼æ¡†åŸºæœ¬ä¸Šæ„å‘³ç€è¿ç»­çš„ï¼Œæ‰€ä»¥æœ‰ä¸¤ä¸ªè¿ç»­çš„å˜é‡è¿”å›ï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªåŸºæœ¬ä¸Šå‘Šè¯‰ä½ æ±½è½¦çš„ä½ç½®å·¦å³ï¼Œæ‰€ä»¥å®ƒåœ¨å±±ä¸Šä¸Šå‡åˆ°å“ªé‡Œï¼Œä»¥åŠåœ¨å“ªä¸€è¾¹ï¼Œæ‰€ä»¥æœ¬è´¨ä¸Šæ˜¯å±å¹•ä¸Šçš„Xï¼Œç„¶åå¦ä¸€ä¸ªå€¼æ˜¯å®ƒçš„é€Ÿåº¦æ˜¯å¤šå¿«ï¼Œè¿™å–å†³äºå®ƒç§»åŠ¨çš„æ–¹å‘ï¼Œè¿™å°±æ˜¯æ•´ä¸ªã€‚
- en: Unniverse those are the only two values that it needs Max episode stepsã€‚ So
    each episode is a play of this game and that's how long the episode is gonna last
    if the car is not figured it out by 200 stepsã€‚ we give up Think of a step like
    a frame think of you're playing a video game you know a video game your render
    engine is shooting for maybe 30 frames a second which is what a movie is each
    of those steps is a frame so it's going to go for a max of of 200 of those nondeterministic
    I don't really like the naming of this one in particular Most of these episodes
    or environments are random somewhat So your cart it's not like the physics calculation
    on that cart is completely predictable now you can seed it and you can put a seed
    into here and that's what the nondeterministic means if you seed it then that
    means it will be deterministic but if you don't seed it's it's somewhat random
    So that isã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Unniverseåªéœ€è¦è¿™ä¸¤ä¸ªå€¼æœ€å¤§çš„æƒ…èŠ‚æ­¥éª¤ã€‚æ‰€ä»¥æ¯ä¸€é›†éƒ½æ˜¯è¿™åœºæ¯”èµ›çš„ä¸€åœºæ¯”èµ›ï¼Œå¦‚æœæ±½è½¦æ²¡æœ‰åœ¨200æ­¥ä¹‹å†…è§£å†³é—®é¢˜ï¼Œé‚£ä¹ˆè¿™ä¸€é›†å°±ä¼šç»“æŸã€‚æˆ‘ä»¬æ”¾å¼ƒäº†ã€‚æƒ³è±¡ä¸€ä¸‹ä¸€æ­¥åƒä¸€å¸§ï¼Œæƒ³è±¡ä½ åœ¨ç©ä¸€ä¸ªè§†é¢‘æ¸¸æˆï¼Œä½ çŸ¥é“ä¸€ä¸ªè§†é¢‘æ¸¸æˆï¼Œä½ çš„æ¸²æŸ“å¼•æ“å¯èƒ½æ¯ç§’é’Ÿå‘å°„30å¸§ï¼Œè¿™å°±æ˜¯ç”µå½±çš„æƒ…å†µï¼Œæ¯ä¸€æ­¥éƒ½æ˜¯ä¸€å¸§ï¼Œæ‰€ä»¥å®ƒæœ€å¤šä¼šæœ‰200ä¸ªé‚£äº›ä¸ç¡®å®šçš„æ­¥éª¤ã€‚æˆ‘ç‰¹åˆ«ä¸å–œæ¬¢è¿™ä¸ªå‘½åã€‚è¿™äº›å¤§å¤šæ•°æƒ…èŠ‚æˆ–ç¯å¢ƒéƒ½æ˜¯éšæœºçš„ã€‚æ‰€ä»¥ä½ çš„è½¦ä¸åƒé‚£è¾†è½¦çš„ç‰©ç†è®¡ç®—å®Œå…¨å¯é¢„æµ‹ã€‚ç°åœ¨ä½ å¯ä»¥ç§å­ï¼Œä½ å¯ä»¥æŠŠä¸€ä¸ªç§å­æ”¾è¿›å»ï¼Œè¿™å°±æ˜¯ä¸ç¡®å®šæ€§çš„æ„æ€ï¼Œå¦‚æœä½ ç§å­ï¼Œé‚£æ„å‘³ç€å®ƒå°†æ˜¯ç¡®å®šæ€§çš„ï¼Œä½†å¦‚æœä½ ä¸ç§å­ï¼Œå®ƒå°±æœ‰äº›éšæœºã€‚æ‰€ä»¥è¿™å°±æ˜¯ã€‚
- en: Essentially what this means most of the environments that I've worked with are
    nondeterministic so if you seed themã€‚ then they're going to be the sameã€‚ So this
    is important to understand if you've trained a neural network to play mountain
    cart and you have it play it with a different seed it might lose because it's
    facing random situations it's learned some basic ideas about how to how to play
    the gameã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è´¨ä¸Šï¼Œè¿™æ„å‘³ç€æˆ‘æ‰€å¤„ç†çš„å¤§å¤šæ•°ç¯å¢ƒéƒ½æ˜¯éç¡®å®šæ€§çš„ï¼Œå› æ­¤å¦‚æœä½ ç»™å®ƒè®¾å®šç§å­ï¼Œå®ƒä»¬å°±ä¼šæ˜¯ç›¸åŒçš„ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå¦‚æœä½ è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥ç©å±±åœ°è½¦ï¼Œè€Œä½ ç”¨ä¸åŒçš„ç§å­è®©å®ƒç©ï¼Œå®ƒå¯èƒ½ä¼šè¾“ï¼Œå› ä¸ºå®ƒé¢ä¸´éšæœºæƒ…å†µã€‚å®ƒå·²ç»å­¦ä¹ äº†ä¸€äº›å…³äºå¦‚ä½•ç©æ¸¸æˆçš„åŸºæœ¬ç†å¿µã€‚
- en: but if I don't know if you look at the world's best race car driverã€‚ there's
    no guarantee that they're going they're going to win every time because there's
    a lot of random and random are just things outside of their control outside of
    each game and they may not win It's the same thing now for each of those stepsã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœæˆ‘ä¸çŸ¥é“ï¼Œä½ çœ‹ä¸–ç•Œä¸Šæœ€å¥½çš„èµ›è½¦æ‰‹ï¼Œæ²¡æœ‰ä¿è¯ä»–ä»¬æ¯æ¬¡éƒ½ä¼šèµ¢ï¼Œå› ä¸ºæœ‰å¾ˆå¤šéšæœºå› ç´ ï¼Œè¿™äº›éšæœºå› ç´ åªæ˜¯ä»–ä»¬æ— æ³•æ§åˆ¶çš„äº‹æƒ…ï¼Œè¶…å‡ºæ¯åœºæ¯”èµ›çš„èŒƒå›´ï¼Œä»–ä»¬å¯èƒ½ä¸ä¼šèµ¢ã€‚ç°åœ¨æ¯ä¸€æ­¥éƒ½æ˜¯åŒæ ·çš„é“ç†ã€‚
- en: you're going to get a reward So you essentially give it the actionã€‚ it gives
    you back the observation so what does the world now look like for the next step
    and then you give it another action and tells you what the world looks like the
    reward threshold is essentiallys what that's your basic reward so if you get the
    negativeã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šå¾—åˆ°ä¸€ä¸ªå¥–åŠ±ï¼Œæ‰€ä»¥ä½ æœ¬è´¨ä¸Šç»™å®ƒä¸€ä¸ªåŠ¨ä½œï¼Œå®ƒä¼šç»™ä½ åé¦ˆè§‚å¯Ÿç»“æœï¼Œé‚£ä¹ˆä¸‹ä¸€æ­¥çš„ä¸–ç•Œçœ‹èµ·æ¥æ˜¯æ€æ ·çš„ï¼Œç„¶åä½ å†ç»™å®ƒå¦ä¸€ä¸ªåŠ¨ä½œï¼Œå®ƒä¼šå‘Šè¯‰ä½ ä¸–ç•Œçš„æ ·å­ã€‚å¥–åŠ±é˜ˆå€¼æœ¬è´¨ä¸Šå°±æ˜¯ä½ çš„åŸºæœ¬å¥–åŠ±ï¼Œæ‰€ä»¥å¦‚æœä½ å¾—åˆ°è´Ÿå¥–åŠ±ã€‚
- en: 110 you didn't do so goodã€‚ Now mountain car is very stingy on rewardsã€‚ you only
    get a reward when you win which makes it a little difficult to train for because
    it's I meanã€‚ imagine if you had to build this building and you don't get any feedback
    at each stepã€‚ you build the entire building and they tell you if it was good at
    the endã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 110ä½ æ²¡æœ‰åšå¾—å¾ˆå¥½ã€‚ç°åœ¨å±±åœ°è½¦åœ¨å¥–åŠ±ä¸Šéå¸¸åå•¬ã€‚ä½ åªæœ‰åœ¨è·èƒœæ—¶æ‰èƒ½è·å¾—å¥–åŠ±ï¼Œè¿™ä½¿å¾—è®­ç»ƒæœ‰äº›å›°éš¾ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ è¦å»ºé€ è¿™åº§å»ºç­‘ï¼Œè€Œåœ¨æ¯ä¸€æ­¥éƒ½æ²¡æœ‰ä»»ä½•åé¦ˆã€‚ä½ å»ºé€ å®Œæ•´ä¸ªå»ºç­‘ï¼Œç„¶åå‘Šè¯‰ä½ å®ƒçš„å¥½åã€‚
- en: that's very frustrating but the neural network can actually optimize something
    that does win mountain car and we'll see an example of that in in the next class
    Now I can also query the environment for cart poleã€‚ So that's the one where you're
    trying to balance the pole and a cart the accent space for this one is discreteã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸ä»¤äººæ²®ä¸§ï¼Œä½†ç¥ç»ç½‘ç»œå®é™…ä¸Šå¯ä»¥ä¼˜åŒ–ä¸€äº›å¯ä»¥èµ¢å¾—å±±åœ°è½¦çš„ç­–ç•¥ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹èŠ‚è¯¾ä¸­çœ‹åˆ°ä¸€ä¸ªä¾‹å­ã€‚ç°åœ¨æˆ‘ä¹Ÿå¯ä»¥æŸ¥è¯¢ç¯å¢ƒä»¥è·å–å°è½¦å¹³è¡¡çš„æƒ…å†µã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªè¯•å›¾å¹³è¡¡æ†å­å’Œå°è½¦çš„æƒ…å†µï¼Œè¯¥åŠ¨ä½œç©ºé—´æ˜¯ç¦»æ•£çš„ã€‚
- en: So you can't stop you are moving in one direction or another and your observation
    space is for values I had to go look at the code to figure out what those areã€‚
    but essentially it's the cart positionï¼Œ you're moving the cart only in two dimensions
    the cart velocity how fast is it going because as you apply greater force from
    those two discreteã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ ä¸èƒ½åœæ­¢ï¼Œä½ åœ¨ä¸€ä¸ªæ–¹å‘ä¸Šç§»åŠ¨ï¼Œæˆ–è€…å¦ä¸€ä¸ªæ–¹å‘ï¼Œè€Œä½ çš„è§‚å¯Ÿç©ºé—´æœ‰å››ä¸ªå€¼ã€‚æˆ‘ä¸å¾—ä¸æŸ¥çœ‹ä»£ç æ‰èƒ½å¼„æ¸…æ¥šè¿™äº›æ˜¯ä»€ä¹ˆï¼Œä½†æœ¬è´¨ä¸Šæ˜¯å°è½¦çš„ä½ç½®ï¼Œä½ åªåœ¨ä¸¤ä¸ªç»´åº¦ä¸Šç§»åŠ¨å°è½¦ï¼Œå°è½¦çš„é€Ÿåº¦æœ‰å¤šå¿«ï¼Œå› ä¸ºå½“ä½ ä»è¿™ä¸¤ä¸ªç¦»æ•£å€¼ä¸­æ–½åŠ æ›´å¤§çš„åŠ›é‡æ—¶ã€‚
- en: Dires you accelerate what is the angle of the pole and what is the pole velocity
    at tip so that's kind of the physics usually you think of the velocity of a pendulum
    or a pendulum I means it's it's essentially an inverted pendulumã€‚And what is the
    velocity at the tip of thatã€‚ And you can push the car to the left or the rightã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: é©¾é©¶æ—¶ï¼Œä½ åŠ é€Ÿï¼Œæ†å­çš„è§’åº¦æ˜¯å¤šå°‘ï¼Œæ†å­çš„æœ«ç«¯é€Ÿåº¦æ˜¯å¤šå°‘ï¼Œè¿™å°±æ˜¯ç‰©ç†ã€‚é€šå¸¸ä½ ä¼šæƒ³åˆ°æ‘†çš„é€Ÿåº¦ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå€’ç«‹æ‘†ã€‚æœ«ç«¯çš„é€Ÿåº¦æ˜¯å¤šå°‘ã€‚ä½ å¯ä»¥æŠŠå°è½¦æ¨å‘å·¦è¾¹æˆ–å³è¾¹ã€‚
- en: So the only two of these values that we're dealing with are discreteã€‚ meaning
    there's only two So it's one variableï¼Œ two possible settings or continuousï¼Œ which
    is boxã€‚ So there's four continuous valuesã€‚ And if you're dealing with the mountain
    car continuous varietyã€‚ they're both boxesã€‚ So the action space is just the acceleratorã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¤„ç†çš„è¿™ä¸¤ä¸ªå€¼æ˜¯ç¦»æ•£çš„ï¼Œæ„å‘³ç€åªæœ‰ä¸¤ä¸ªè®¾ç½®ã€‚è¿˜æœ‰ä¸€ä¸ªå˜é‡ï¼Œä¸¤ä¸ªå¯èƒ½çš„è®¾ç½®æˆ–è€…è¿ç»­çš„ï¼Œè¿™å°±æ˜¯ç®±å­ã€‚æ‰€ä»¥æœ‰å››ä¸ªè¿ç»­å€¼ã€‚å¦‚æœä½ åœ¨å¤„ç†å±±åœ°è½¦çš„è¿ç»­ç±»å‹ï¼Œå®ƒä»¬éƒ½æ˜¯ç®±å­ã€‚æ‰€ä»¥åŠ¨ä½œç©ºé—´åªæ˜¯åŠ é€Ÿå™¨ã€‚
- en: you can give it positive or negative acceleration and a continuous range or
    zeroï¼Œ meaning nothingã€‚ The maximum episode steps for some reason is 999ã€‚ and it
    it's a double negative nondeterministicã€‚ So it is not deterministic soã€‚And then
    the reward range can go from negative to to positive and the reward threshold
    is 90ã€‚ Don't worry about this warningã€‚ I think that's a bug actually in open AI
    gym Open AI gym is not maintained a lot there's a lot of issues posted on itã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ç»™å®ƒæ­£åŠ é€Ÿåº¦æˆ–è´ŸåŠ é€Ÿåº¦ï¼Œä»¥åŠè¿ç»­èŒƒå›´æˆ–é›¶ï¼Œæ„å‘³ç€ä»€ä¹ˆéƒ½æ²¡æœ‰ã€‚å‡ºäºæŸç§åŸå› ï¼Œæœ€å¤§å‰§é›†æ­¥æ•°æ˜¯ 999ã€‚è€Œä¸”è¿™æ˜¯ä¸€ä¸ªåŒé‡è´Ÿé¢éç¡®å®šæ€§ã€‚å› æ­¤ï¼Œå®ƒä¸æ˜¯ç¡®å®šæ€§çš„ã€‚ç„¶åå¥–åŠ±èŒƒå›´å¯ä»¥ä»è´Ÿæ•°åˆ°æ­£æ•°ï¼Œå¥–åŠ±é˜ˆå€¼æ˜¯
    90ã€‚åˆ«æ‹…å¿ƒè¿™ä¸ªè­¦å‘Šã€‚æˆ‘è®¤ä¸ºè¿™å®é™…ä¸Šæ˜¯ OpenAI Gym ä¸­çš„ä¸€ä¸ªé”™è¯¯ã€‚OpenAI Gym ç»´æŠ¤å¾—ä¸å¤šï¼Œä¸Šé¢æœ‰å¾ˆå¤šé—®é¢˜è¢«å‘å¸ƒã€‚
- en: but it's a great toolkit still to use for this Now breakout This is an Atari
    game and I want to show you what they do for some of these Atari games which is
    just kind of fascinating So the observation spaces it's essentially an image 210
    by 160 by three So''s essentially a red green blue image and what you're doing
    here is using the image so what is the user looking at it's looking at the screen
    just like a user that is cool that it is just looking at that image and learning
    how to play the game episode steps can go on for quite a while you know 1000 of
    them Nodeterministic is almost always false on these and the reward range can
    be anything Re threshold they don't even give you one typically I don't use the
    range in the thresholdã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä»ç„¶æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„å·¥å…·åŒ…ï¼Œç”¨äºçªç ´ã€‚è¿™æ˜¯ä¸€ä¸ª Atari æ¸¸æˆï¼Œæˆ‘æƒ³å±•ç¤ºä»–ä»¬ä¸ºä¸€äº› Atari æ¸¸æˆæ‰€åšçš„äº‹æƒ…ï¼Œè¿™çœŸçš„å¾ˆè¿·äººã€‚æ‰€ä»¥è§‚å¯Ÿç©ºé—´æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª
    210 ä¹˜ä»¥ 160 ä¹˜ä»¥ 3 çš„å›¾åƒã€‚å› æ­¤æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªçº¢ç»¿è“å›¾åƒï¼Œä½ åœ¨è¿™é‡Œåšçš„æ˜¯ä½¿ç”¨å›¾åƒï¼Œé‚£ä¹ˆç”¨æˆ·åœ¨çœ‹ä»€ä¹ˆå‘¢ï¼Ÿä»–æ­£åœ¨çœ‹å±å¹•ï¼Œå°±åƒä¸€ä¸ªç”¨æˆ·ä¸€æ ·ï¼Œè¿™å¾ˆé…·ï¼Œå®ƒåªæ˜¯çœ‹ç€é‚£ä¸ªå›¾åƒå¹¶å­¦ä¹ å¦‚ä½•ç©æ¸¸æˆï¼Œå‰§é›†æ­¥æ•°å¯ä»¥æŒç»­å¾ˆä¹…ï¼Œä½ çŸ¥é“çš„ï¼Œ1000
    æ¬¡ã€‚éç¡®å®šæ€§å‡ ä¹æ€»æ˜¯ä¸ºå‡ï¼Œå¥–åŠ±èŒƒå›´å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿ï¼Œé˜ˆå€¼ä»–ä»¬é€šå¸¸ç”šè‡³ä¸ç»™ä½ ä¸€ä¸ªï¼Œæˆ‘é€šå¸¸ä¸ä½¿ç”¨èŒƒå›´å’Œé˜ˆå€¼ã€‚
- en: Kd FYs Nowï¼Œ thisï¼Œ I thinkï¼Œ is really fascinatingã€‚ They also give you breakout
    Ramã€‚ You're looking at the Ram of the Atari 2600ã€‚ The Atari 2600 has 128 bys of
    Ram bys not K not meg and certainly not gigã€‚ So this is not that much memoryã€‚
    I meanï¼Œ heck the image size is bigger than the Ram that it took for that gameã€‚
    I meanï¼Œ one row is 210 times three bysã€‚ So that's a lot of that's not a lot of
    memoryã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kd FYs ç°åœ¨ï¼Œæˆ‘è®¤ä¸ºè¿™çœŸçš„å¾ˆæœ‰è¶£ã€‚ä»–ä»¬è¿˜ç»™ä½ æä¾›äº†çªç ´æ€§å†…å­˜ã€‚ä½ çœ‹åˆ°çš„æ˜¯ Atari 2600 çš„å†…å­˜ã€‚Atari 2600 çš„å†…å­˜æ˜¯ 128 å­—èŠ‚ï¼Œä¸æ˜¯
    K ä¸æ˜¯ MBï¼Œå½“ç„¶ä¹Ÿä¸æ˜¯ GBã€‚å› æ­¤ï¼Œè¿™å¹¶ä¸æ˜¯å¾ˆå¤šå†…å­˜ã€‚æˆ‘æ˜¯è¯´ï¼Œå¤©å“ªï¼Œå›¾åƒå¤§å°æ¯”è¿™ä¸ªæ¸¸æˆæ‰€éœ€çš„å†…å­˜è¿˜è¦å¤§ã€‚æˆ‘æ˜¯è¯´ï¼Œä¸€è¡Œæ˜¯ 210 ä¹˜ä»¥ 3 å­—èŠ‚ã€‚æ‰€ä»¥ï¼Œè¿™ä¸ç®—æ˜¯å¾ˆå¤šå†…å­˜ã€‚
- en: but by looking at the memory for this gameï¼Œ you can kind of tell what's going
    onã€‚ And who what are those 128 bys for in the old schoolã€‚ they call that a memory
    map and who knows only the Atari developers knowã€‚ they're probably not even using
    all 128 of themã€‚ And just by looking at the memory manipulate as as you play the
    gameã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯é€šè¿‡æŸ¥çœ‹è¿™ä¸ªæ¸¸æˆçš„å†…å­˜ï¼Œä½ å¯ä»¥å¤§æ¦‚çŸ¥é“å‘ç”Ÿäº†ä»€ä¹ˆã€‚è€Œé‚£äº› 128 å­—èŠ‚åœ¨è€å¼æ¸¸æˆä¸­æ˜¯ç”¨æ¥åšä»€ä¹ˆçš„ã€‚ä»–ä»¬ç§°ä¹‹ä¸ºå†…å­˜æ˜ å°„ï¼Œè°çŸ¥é“ï¼Œåªæœ‰ Atari å¼€å‘è€…çŸ¥é“ã€‚ä»–ä»¬å¯èƒ½ç”šè‡³æ²¡æœ‰ä½¿ç”¨å…¨éƒ¨çš„
    128 ä¸ªå­—èŠ‚ã€‚ä»…ä»…é€šè¿‡æŸ¥çœ‹å†…å­˜æ¥æ“æ§ï¼Œä½ å¯ä»¥åœ¨ç©æ¸¸æˆæ—¶è·å¾—ä¿¡æ¯ã€‚
- en: you're able to to play the gameã€‚ Now both of theseï¼Œ the action spaceã€‚ So the
    input is4ã€‚ That's your joystickã€‚Four positions up down left right because you're
    moving that little square around trying to bat the ball and you don't need to
    give a bat the ball commandã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ èƒ½å¤Ÿç©è¿™ä¸ªæ¸¸æˆã€‚ç°åœ¨è¿™ä¸¤è€…ï¼ŒåŠ¨ä½œç©ºé—´ã€‚æ‰€ä»¥è¾“å…¥æ˜¯ 4ã€‚è¿™æ˜¯ä½ çš„æ‘‡æ†ã€‚å››ä¸ªæ–¹å‘ï¼šä¸Šã€ä¸‹ã€å·¦ã€å³ï¼Œå› ä¸ºä½ åœ¨ç§»åŠ¨é‚£ä¸ªå°æ–¹å—ï¼Œè¯•å›¾å‡»æ‰“çƒï¼Œè€Œä½ ä¸éœ€è¦ç»™çƒä¸€ä¸ªå‡»æ‰“å‘½ä»¤ã€‚
- en: just the fact that it hits your player causes it to bounce out and what's fascinating
    and we'll see how to do this we develop a agent that is able to learn to play
    these Atari games this I also want to show you because we're doing coab if you
    were running this on your actual local computer what would happen when you try
    to render and play these games as a window would pop up and you would actually
    see the Atari game So if you want to actually play the Atari game on your computer
    in coabab since coab's a virtual environment I'll show you how you can do this
    So we're gonna to run this part here it does a Pip install we're installing Python
    virtual display which is great for something like coab I use it also to generate
    some of the videos that I attach in to show you kind of things playing it gives
    you a Python virtualã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä»…ä»…å› ä¸ºå®ƒå‡»ä¸­äº†ä½ çš„è§’è‰²å°±ä¼šå¯¼è‡´å®ƒå¼¹å‡ºï¼Œè€Œä»¤äººç€è¿·çš„æ˜¯ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å¼€å‘ä¸€ä¸ªä»£ç†ï¼Œå®ƒèƒ½å¤Ÿå­¦ä¹ ç©è¿™äº›é›…è¾¾åˆ©æ¸¸æˆã€‚æˆ‘è¿˜æƒ³ç»™ä½ å±•ç¤ºï¼Œå› ä¸ºæˆ‘ä»¬åœ¨CoLabä¸­ï¼Œå¦‚æœä½ åœ¨è‡ªå·±çš„æœ¬åœ°è®¡ç®—æœºä¸Šè¿è¡Œï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Œå½“ä½ å°è¯•æ¸²æŸ“å’Œæ’­æ”¾è¿™äº›æ¸¸æˆæ—¶ï¼Œçª—å£ä¼šå¼¹å‡ºï¼Œä½ å°†å®é™…çœ‹åˆ°é›…è¾¾åˆ©æ¸¸æˆã€‚æ‰€ä»¥å¦‚æœä½ æƒ³åœ¨CoLabä¸­å®é™…ç©é›…è¾¾åˆ©æ¸¸æˆï¼Œå› ä¸ºCoLabæ˜¯ä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å°†è¿è¡Œè¿™éƒ¨åˆ†ï¼Œå®ƒä¼šè¿›è¡Œpipå®‰è£…ï¼Œæˆ‘ä»¬æ­£åœ¨å®‰è£…Pythonè™šæ‹Ÿæ˜¾ç¤ºï¼Œè¿™å¯¹CoLabå¾ˆæœ‰ç”¨ï¼Œæˆ‘è¿˜ç”¨å®ƒç”Ÿæˆä¸€äº›æˆ‘é™„åŠ çš„å±•ç¤ºè§†é¢‘ï¼Œç»™ä½ å±•ç¤ºä¸€äº›æ’­æ”¾çš„ä¸œè¥¿ï¼Œç»™ä½ ä¸€ä¸ªPythonè™šæ‹Ÿç¯å¢ƒã€‚
- en: Environment and it essentially is going to render it to a file that we can then
    turn into a videoã€‚ let's go ahead and run these So essentially you're going to
    have it play the guitar game and record a video of it playing and you can potentially
    download the video or just watch watch it in coab so you don't get to watch it
    play in real time you kind of see it after the fact but that's just as good and
    it's all you can really do in collab Now this part here and I do provide a link
    because I got these functions from a very handy write up that somebody did on
    how to use this in coab so'm going to run these just define it that shows the
    video and sets it up for you we're gonna play atlantis Atlantis version zero so
    I'm going go ahead and run this what's basically going on here is wild true it's
    not using any AI at all it's essentially doing a it's sampling from the action
    space so it's basically taking random acts and look there's the game This is not
    playã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒåŸºæœ¬ä¸Šä¼šå°†å…¶æ¸²æŸ“ä¸ºæ–‡ä»¶ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°†å…¶è½¬æ¢ä¸ºè§†é¢‘ã€‚è®©æˆ‘ä»¬ç»§ç»­è¿è¡Œè¿™äº›ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œä½ å°†ç©å‰ä»–æ¸¸æˆå¹¶å½•åˆ¶è§†é¢‘ï¼Œä½ å¯ä»¥ä¸‹è½½è§†é¢‘æˆ–åœ¨CoLabä¸­è§‚çœ‹ï¼Œæ‰€ä»¥ä½ ä¸èƒ½å®æ—¶è§‚çœ‹ï¼Œåªèƒ½äº‹åçœ‹åˆ°ï¼Œä½†è¿™ä¹Ÿå¾ˆå¥½ï¼Œè¿™å°±æ˜¯ä½ åœ¨CoLabä¸­èƒ½åšçš„ã€‚è¿™é‡Œçš„éƒ¨åˆ†æˆ‘æä¾›äº†é“¾æ¥ï¼Œå› ä¸ºæˆ‘ä»ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å†™ä½œä¸­è·å¾—äº†è¿™äº›åŠŸèƒ½ï¼Œè¯¥å†™ä½œä»‹ç»äº†å¦‚ä½•åœ¨CoLabä¸­ä½¿ç”¨å®ƒï¼Œæ‰€ä»¥æˆ‘å°†è¿è¡Œè¿™äº›ï¼Œåªéœ€å®šä¹‰å®ƒï¼Œä»¥æ˜¾ç¤ºè§†é¢‘å¹¶ä¸ºä½ è®¾ç½®ï¼Œæˆ‘ä»¬å°†æ’­æ”¾ã€Šäºšç‰¹å…°è’‚æ–¯ã€‹ç‰ˆæœ¬é›¶ï¼Œæ‰€ä»¥æˆ‘å°†ç»§ç»­è¿è¡Œã€‚è¿™é‡Œçš„åŸºæœ¬æƒ…å†µæ˜¯ï¼Œå®ƒæ²¡æœ‰ä½¿ç”¨ä»»ä½•AIï¼Œè€Œæ˜¯ä»åŠ¨ä½œç©ºé—´è¿›è¡Œé‡‡æ ·ï¼ŒåŸºæœ¬ä¸Šåœ¨éšæœºè¡Œä¸ºä¸­å–æ ·ï¼Œçœ‹ï¼Œè¿™å°±æ˜¯æ¸¸æˆï¼Œè¿™å¹¶æ²¡æœ‰çœŸæ­£è¿›è¡Œã€‚
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_9.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_9.png)'
- en: In real timeï¼Œ this is a video that had been recorded briefly while that cell
    was runningã€‚ but now you can watch it play over and over again it's about a minute
    and 16 you can see the players getting beat badly you've got a gun hereã€‚ you've
    got a gun and you've got a gun and it is shooting some of the some of the spaceships
    but the spaceships start to eventually take it out as as we play further and further
    the idea here is got to love 1980s graphics this is a underwater city this is
    water and oops just tuck out the main cannon so it's as you lose your lives but
    this is just an overview of AIG will be using it more in the next to really every
    every module in this every part of this moduleã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå®æ—¶è§†é¢‘ï¼Œè®°å½•äº†é‚£ä¸ªç»†èƒè¿è¡Œæ—¶çš„ç®€çŸ­ç‰‡æ®µã€‚ç°åœ¨ä½ å¯ä»¥åå¤è§‚çœ‹ï¼Œæ—¶é•¿çº¦ä¸ºä¸€åˆ†é’Ÿ16ç§’ï¼Œä½ å¯ä»¥çœ‹åˆ°ç©å®¶è¢«å‡»è´¥å¾—å¾ˆæƒ¨ã€‚è¿™é‡Œæœ‰ä¸€æŠŠæªï¼Œä½ å¯ä»¥å‘å°„ä¸€äº›å®‡å®™é£èˆ¹ï¼Œä½†éšç€æ¸¸æˆçš„è¿›è¡Œï¼Œå®‡å®™é£èˆ¹æœ€ç»ˆä¼šå°†å…¶æ‘§æ¯ã€‚è¿™é‡Œçš„æƒ³æ³•æ˜¯ï¼Œè¦çƒ­çˆ±1980å¹´ä»£çš„å›¾å½¢ï¼Œè¿™æ˜¯ä¸€ä¸ªæ°´ä¸‹åŸå¸‚ï¼Œè¿™é‡Œæ˜¯æ°´ï¼Œå“¦ï¼Œä¸»ç‚®è¢«å‡»æ¯äº†ï¼Œæ‰€ä»¥å½“ä½ å¤±å»ç”Ÿå‘½æ—¶ï¼Œè¿™æ˜¯å¯¹AIGçš„æ¦‚è¿°ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„æ¯ä¸ªæ¨¡å—ä¸­æ›´å¤šåœ°ä½¿ç”¨å®ƒã€‚
- en: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_11.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e05a69d9ca1dbcb4403e08d1b85b5a4e_11.png)'
- en: Thank you for watching this video and if you're interested in more things about
    reinforcement learning and training it for gamesã€‚ please subscribe to my YouTube
    channelï¼Œ thank you very muchã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œå¦‚æœä½ å¯¹å¼ºåŒ–å­¦ä¹ å’Œä¸ºæ¸¸æˆè®­ç»ƒçš„æ›´å¤šå†…å®¹æ„Ÿå…´è¶£ï¼Œè¯·è®¢é˜…æˆ‘çš„YouTubeé¢‘é“ï¼Œéå¸¸æ„Ÿè°¢ã€‚
