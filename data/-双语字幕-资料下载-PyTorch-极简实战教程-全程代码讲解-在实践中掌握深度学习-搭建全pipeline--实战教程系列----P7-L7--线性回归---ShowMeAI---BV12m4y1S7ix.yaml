- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- çº¿æ€§å›å½’
    - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- çº¿æ€§å›å½’
    - ShowMeAI - BV12m4y1S7ix
- en: Hiï¼Œ everybodyã€‚ Welcome back to a new Pytarch tutorialã€‚ This timeï¼Œ we implement
    linear regressionã€‚ So we already implemented this step by step in the last couple
    of tutorialsã€‚ and this should be a repetition where we can apply all the learned
    concepts and quickly implement our algorithm againã€‚ğŸ˜Šï¼ŒSo as I've shown you beforeï¼Œ
    our typical pieytorch pipeline consists of those three stepsã€‚Firstã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ã€‚æ¬¢è¿å›åˆ°æ–°çš„Pytarchæ•™ç¨‹ã€‚è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å®ç°çº¿æ€§å›å½’ã€‚æ‰€ä»¥æˆ‘ä»¬å·²ç»åœ¨å‰å‡ ä¸ªæ•™ç¨‹ä¸­é€æ­¥å®ç°äº†è¿™ä¸ªã€‚è¿™åº”è¯¥æ˜¯ä¸€ä¸ªé‡å¤çš„è¿‡ç¨‹ï¼Œè®©æˆ‘ä»¬å¯ä»¥åº”ç”¨æ‰€æœ‰å­¦åˆ°çš„æ¦‚å¿µï¼Œå¹¶è¿…é€Ÿå†æ¬¡å®ç°æˆ‘ä»¬çš„ç®—æ³•ã€‚ğŸ˜Šå¦‚æˆ‘ä¹‹å‰æ‰€ç¤ºï¼Œæˆ‘ä»¬å…¸å‹çš„pyytorchç®¡é“ç”±è¿™ä¸‰ä¸ªæ­¥éª¤ç»„æˆã€‚é¦–å…ˆã€‚
- en: we design our modelã€‚ So we define the input and the output sizeï¼Œ and then the
    forward passã€‚ Then we create our loss and optimizer functionsã€‚ And then we do
    the actual training loop with the forward passã€‚ the backward pass and the weight
    updatesã€‚ So let's do thisã€‚And first of allã€‚ we import a couple of things that
    we needã€‚ So let's import torchã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾è®¡æˆ‘ä»¬çš„æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘ä»¬å®šä¹‰è¾“å…¥å’Œè¾“å‡ºå¤§å°ï¼Œç„¶åè¿›è¡Œå‰å‘ä¼ æ’­ã€‚æ¥ç€æˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„æŸå¤±å’Œä¼˜åŒ–å™¨å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬æ‰§è¡Œå®é™…çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°ã€‚è®©æˆ‘ä»¬æ¥åšè¿™ä¸ªã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥ä¸€äº›éœ€è¦çš„å†…å®¹ã€‚æ‰€ä»¥æˆ‘ä»¬å¯¼å…¥torchã€‚
- en: Then we import torch dot and N S and Nã€‚ So the neural network moduleã€‚ Then we
    import nuy S and P just to make some data transformationsã€‚ and then from S K learnã€‚
    we import data setã€‚ So we want to generate a regression data setã€‚And then we also
    want to plot this laterã€‚ So I say import matplot clip the pie plot as P LTã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯¼å…¥torchç‚¹å’ŒN Så’ŒNã€‚ä¹Ÿå°±æ˜¯ç¥ç»ç½‘ç»œæ¨¡å—ã€‚ç„¶åæˆ‘ä»¬å¯¼å…¥nuy Så’ŒPä»¥è¿›è¡Œä¸€äº›æ•°æ®è½¬æ¢ã€‚ç„¶åä»S K learnä¸­å¯¼å…¥æ•°æ®é›†ã€‚æˆ‘ä»¬æƒ³ç”Ÿæˆä¸€ä¸ªå›å½’æ•°æ®é›†ã€‚ç„¶åæˆ‘ä»¬ç¨åä¹Ÿæƒ³ç»˜åˆ¶è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘è¯´å¯¼å…¥matplot
    clipçš„pie plotä½œä¸ºP LTã€‚
- en: And then we do our three stepsã€‚ So we design the modelï¼Œ step number oneã€‚Then
    step number twoã€‚ we define the loss and the optimizerã€‚And then step number 3ï¼Œ
    our training loopã€‚ So let's do thisã€‚ And first of allï¼Œ let's do a step 0 where
    we prepare our dataã€‚ So prepare dataã€‚ So let's generate a regression data setã€‚
    and we can do this by saying let's call this x nuy and y nuy equalsã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿›è¡Œæˆ‘ä»¬çš„ä¸‰ä¸ªæ­¥éª¤ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾è®¡æ¨¡å‹ï¼Œç¬¬ä¸€æ­¥ã€‚ç„¶åç¬¬äºŒæ­¥ï¼Œæˆ‘ä»¬å®šä¹‰æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚æœ€åç¬¬ä¸‰æ­¥ï¼Œæˆ‘ä»¬çš„è®­ç»ƒå¾ªç¯ã€‚è®©æˆ‘ä»¬æ¥åšè¿™ä¸ªã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åšä¸€ä¸ªæ­¥éª¤0ï¼Œå‡†å¤‡æˆ‘ä»¬çš„æ•°æ®ã€‚æ‰€ä»¥å‡†å¤‡æ•°æ®ã€‚è®©æˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªå›å½’æ•°æ®é›†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´è®©æˆ‘ä»¬ç§°è¿™ä¸ªä¸ºx
    nuyå’Œy nuyæ¥å®ç°ã€‚
- en: and then we can use data sets dot make regressionã€‚ which getsï¼Œ let's say 100
    samplesã€‚ So n samples equals 100ã€‚ and only one feature in this exampleã€‚ So n features
    equals  oneã€‚ Then we add some noiseã€‚ and let's also at a random stateã€‚ Let's say
    this is oneã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ•°æ®é›†ç‚¹make regressionã€‚è·å–ï¼Œå‡è®¾100ä¸ªæ ·æœ¬ã€‚æ‰€ä»¥n samplesç­‰äº100ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­åªéœ€è¦ä¸€ä¸ªç‰¹å¾ã€‚æ‰€ä»¥n featuresç­‰äº1ã€‚ç„¶åæˆ‘ä»¬æ·»åŠ ä¸€äº›å™ªå£°ã€‚æˆ‘ä»¬è¿˜è¦è®¾ç½®ä¸€ä¸ªéšæœºçŠ¶æ€ã€‚å‡è®¾è¿™ä¸ªæ˜¯1ã€‚
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_1.png)'
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_2.png)'
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_3.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_3.png)'
- en: And then we want to convert this to a torch tenzoaã€‚ So we say x equalsã€‚ and
    then we can use the function torch dot from numyã€‚ and then we say x dotã€‚X underscore
    nuyã€‚But we want to convert this to aã€‚A float 32 data data type beforeã€‚ So right
    now this is a double data typeã€‚ So if we use a double hereã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³æŠŠè¿™ä¸ªè½¬æ¢ä¸ºä¸€ä¸ªtorchå¼ é‡ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´xç­‰äºã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‡½æ•°torchä»numyä¸­æå–ã€‚ç„¶åæˆ‘ä»¬è¯´xç‚¹ã€‚Xä¸‹åˆ’çº¿nuyã€‚ä½†æˆ‘ä»¬æƒ³åœ¨æ­¤ä¹‹å‰å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªfloat
    32æ•°æ®ç±»å‹ã€‚æ‰€ä»¥ç°åœ¨è¿™æ˜¯ä¸€ä¸ªåŒç²¾åº¦æ•°æ®ç±»å‹ã€‚å¦‚æœæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨åŒç²¾åº¦ã€‚
- en: then we will run into some arrows laterã€‚ So let's just convert this by saying
    S type and then say nuy dot float 32 and we do the same thing for our yã€‚ So we
    say y equals the torch tenzo from our nuy arrayã€‚And now let's also reshape our
    yã€‚ because right now this is a has only one rowï¼Œ and we want to make it a column
    vectorã€‚ So we want to put each value in one rowï¼Œ and the whole shape has only
    one columnï¼Œ soã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ç¨åä¼šé‡åˆ°ä¸€äº›é”™è¯¯ã€‚æ‰€ä»¥æˆ‘ä»¬åªéœ€é€šè¿‡è¯´Sç±»å‹ï¼Œç„¶åè¯´nuyç‚¹float 32æ¥è½¬æ¢ï¼Œå¹¶ä¸”å¯¹æˆ‘ä»¬çš„yåšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´yç­‰äºä»æˆ‘ä»¬çš„nuyæ•°ç»„è½¬æ¢çš„torchå¼ é‡ã€‚ç°åœ¨æˆ‘ä»¬è¿˜è¦é‡å¡‘æˆ‘ä»¬çš„yã€‚å› ä¸ºç°åœ¨å®ƒåªæœ‰ä¸€è¡Œï¼Œæˆ‘ä»¬æƒ³æŠŠå®ƒå˜æˆåˆ—å‘é‡ã€‚æˆ‘ä»¬å¸Œæœ›å°†æ¯ä¸ªå€¼æ”¾åœ¨ä¸€è¡Œä¸­ï¼Œæ•´ä¸ªå½¢çŠ¶åªæœ‰ä¸€åˆ—ã€‚
- en: Let's say y equals y dot viewã€‚ And here we put in the new size So y dot shape0ã€‚
    So the number of of valuesã€‚ and then only one columnã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_5.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¯´yç­‰äºyç‚¹viewã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æ”¾å…¥æ–°çš„å¤§å°ï¼Œæ‰€ä»¥yç‚¹shape0ã€‚æ‰€ä»¥å€¼çš„æ•°é‡ã€‚ç„¶ååªéœ€è¦ä¸€åˆ—ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_5.png)
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_6.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_6.png)'
- en: So the few method is a built in pi torch methodï¼Œ which will reshape our tenoneã€‚And
    then let's get the number of samples and the number of features by saying this
    is x dot shapeã€‚ So we can use this in a secondã€‚ And now let's do our three stepsã€‚
    So now we have the dataã€‚ Now we define the modelã€‚And in the linear regression
    caseï¼Œ this is just one layerã€‚ So ourã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¸ªæ–¹æ³•æ˜¯ä¸€ä¸ªå†…ç½®çš„PyTorchæ–¹æ³•ï¼Œå°†é‡æ–°è°ƒæ•´æˆ‘ä»¬çš„`tensor`ã€‚ç„¶åé€šè¿‡è¯´`x.shape`æ¥è·å–æ ·æœ¬æ•°é‡å’Œç‰¹å¾æ•°é‡ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨ç¨åä½¿ç”¨ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œä¸‰æ­¥æ“ä½œã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†æ•°æ®ã€‚ç°åœ¨æˆ‘ä»¬å®šä¹‰æ¨¡å‹ã€‚åœ¨çº¿æ€§å›å½’çš„æƒ…å†µä¸‹ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå±‚ã€‚æˆ‘ä»¬çš„ã€‚
- en: so we can use to build in linear modelã€‚ So we say model equals N N dot linearã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_8.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å†…ç½®çš„çº¿æ€§æ¨¡å‹ã€‚æˆ‘ä»¬è¯´`model = NN.Linear`ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_8.png)
- en: This is the linear layerï¼Œ which needs a input size of our features and a output
    sizeã€‚ So let's say input size equalsã€‚ This is the number of features we haveã€‚
    So this is just one in our exampleã€‚ and the output size equals oneã€‚ So we only
    want to have one value for each sample that we want to put inã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯çº¿æ€§å±‚ï¼Œå®ƒéœ€è¦æˆ‘ä»¬ç‰¹å¾çš„è¾“å…¥å¤§å°å’Œè¾“å‡ºå¤§å°ã€‚æ‰€ä»¥å‡è®¾è¾“å…¥å¤§å°ç­‰äºã€‚è¿™æ˜¯æˆ‘ä»¬æ‹¥æœ‰çš„ç‰¹å¾æ•°é‡ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œè¿™ä»…ä¸º1ã€‚è¾“å‡ºå¤§å°ç­‰äº1ã€‚æ‰€ä»¥æˆ‘ä»¬åªæƒ³ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆä¸€ä¸ªå€¼ã€‚
- en: So our model gets now the input and the output size So input size and output
    sizeã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_10.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„æ¨¡å‹å¾—åˆ°äº†è¾“å…¥å’Œè¾“å‡ºçš„å¤§å°ï¼Œè¾“å…¥å¤§å°å’Œè¾“å‡ºå¤§å°ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_10.png)
- en: And this is all we have to do to set up the modelã€‚And now let's continue with
    the loss and the optimizerã€‚ So let's call this criterionã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_12.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬è®¾ç½®æ¨¡å‹æ‰€éœ€åšçš„å…¨éƒ¨ã€‚ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­å¤„ç†æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚æ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸º`criterion`ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_12.png)
- en: And here we can use a built in loss function from Pytorchã€‚ And in the case of
    linear regressionã€‚ this is the mean squared errorã€‚ So we can say this is N N dot
    M S E lossã€‚ So will calculate the mean squared errorã€‚ So this is a callable functionã€‚And
    then we also set up the optimizersã€‚ So we sayã€‚Opttimizer equalsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Pytorchå†…ç½®çš„æŸå¤±å‡½æ•°ã€‚åœ¨çº¿æ€§å›å½’çš„æƒ…å†µä¸‹ï¼Œè¿™å°±æ˜¯å‡æ–¹è¯¯å·®ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´è¿™æ˜¯`NN.MSELoss`ã€‚è¿™æ ·å°±ä¼šè®¡ç®—å‡æ–¹è¯¯å·®ã€‚è¿™æ˜¯ä¸€ä¸ªå¯è°ƒç”¨çš„å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬è¿˜è®¾ç½®ä¼˜åŒ–å™¨ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ï¼Œ`optimizer
    = ...`ã€‚
- en: And let's say torch dot optim dot S G Dã€‚ So this is stochastic gradient descentã€‚
    and our optr needs the parameters that it should optimizeã€‚ So here we can simply
    say this is model dot parametersã€‚ And then it needs a learning rateã€‚ So let's
    define this here as a variableã€‚ So let's say learning rate equalsã€‚ let's say 001ã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬ä½¿ç”¨`torch.optim.SGD`ã€‚è¿™å°±æ˜¯éšæœºæ¢¯åº¦ä¸‹é™ã€‚æˆ‘ä»¬çš„ä¼˜åŒ–å™¨éœ€è¦ä¼˜åŒ–çš„å‚æ•°ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´è¿™æ˜¯`model.parameters`ã€‚ç„¶åå®ƒéœ€è¦ä¸€ä¸ªå­¦ä¹ ç‡ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰ä¸ºä¸€ä¸ªå˜é‡ã€‚å‡è®¾å­¦ä¹ ç‡ç­‰äº`0.01`ã€‚
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_14.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_14.png)'
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_15.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_15.png)'
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_16.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_16.png)'
- en: And then Lr equals learning rateã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_18.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶å`lr = learning rate`ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_18.png)
- en: So this is step number 2ã€‚ And now let's do our training loopã€‚ Soï¼Œ first of allã€‚
    let's define the number of epochsã€‚Let's say we want to do 100 training iterationsã€‚
    and now forã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_20.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç¬¬äºŒæ­¥ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚é¦–å…ˆï¼Œå®šä¹‰ä¸€ä¸‹è¿­ä»£çš„æ¬¡æ•°ã€‚å‡è®¾æˆ‘ä»¬æƒ³è¿›è¡Œ100æ¬¡è®­ç»ƒè¿­ä»£ã€‚ç„¶åï¼Œ![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_20.png)
- en: Epoch in range epochsã€‚ And now here we do our steps in the training loopï¼Œ the
    forward passã€‚ the backward pass and the update and the weight updatesã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_22.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨`range(epochs)`ä¸­è¿›è¡Œå¾ªç¯ã€‚ç°åœ¨åœ¨è®­ç»ƒå¾ªç¯ä¸­æ‰§è¡Œæˆ‘ä»¬çš„æ­¥éª¤ï¼Œå‰å‘ä¼ æ’­ï¼Œåå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_22.png)
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_23.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_23.png)'
- en: So let'sï¼Œ first of allï¼Œ do the forward pass and also the loss hereã€‚Thenï¼Œ the
    backward passã€‚And then the updateã€‚ So the forward pass and the loss hereï¼Œ we can
    sayï¼Œ why predict itã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_25.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥é¦–å…ˆæˆ‘ä»¬åšå‰å‘ä¼ æ’­ä»¥åŠè¿™é‡Œçš„æŸå¤±ã€‚ç„¶åæ˜¯åå‘ä¼ æ’­ã€‚ç„¶åæ˜¯æ›´æ–°ã€‚å‰å‘ä¼ æ’­å’Œè¿™é‡Œçš„æŸå¤±ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ï¼Œä¸ºä»€ä¹ˆé¢„æµ‹å®ƒã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_25.png)
- en: Equalsï¼Œ and here we call our modelã€‚ And as a dataï¼Œ it gets xã€‚ So this is the
    forward passã€‚ And then we compute the loss by saying loss equalsã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_27.png)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰äºï¼Œç„¶åæˆ‘ä»¬è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä½œä¸ºæ•°æ®ï¼Œå®ƒè·å–`x`ã€‚è¿™å°±æ˜¯å‰å‘ä¼ æ’­ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡è¯´`loss = ...`æ¥è®¡ç®—æŸå¤±ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_27.png)
- en: This is our cr we call this criterionã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_29.png)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬çš„`criterion`ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_29.png)
- en: And this needs the actual labels and the predicted valuesã€‚ So why predict and
    whyã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_31.png)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éœ€è¦å®é™…æ ‡ç­¾å’Œé¢„æµ‹å€¼ã€‚é‚£ä¹ˆä¸ºä»€ä¹ˆè¦é¢„æµ‹å‘¢ï¼Ÿ![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_31.png)
- en: And nowï¼Œ in the backward pass to calculate the gradientsï¼Œ we just say lost dot
    backwardã€‚ So this will do the back propagation and calculate the gradients for
    usã€‚And then our update hereã€‚ we simply say optimizer dot stepã€‚ So this will update
    the weightsã€‚And then before the next iterationï¼Œ we have to be carefulã€‚ So we have
    to empty our gradients nowã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åå‘ä¼ æ’­ä¸­è®¡ç®—æ¢¯åº¦æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¯´ lost dot backwardã€‚è¿™å°†è¿›è¡Œåå‘ä¼ æ’­å¹¶ä¸ºæˆ‘ä»¬è®¡ç®—æ¢¯åº¦ã€‚ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œçš„æ›´æ–°ï¼Œåªéœ€è¯´ optimizer
    dot stepã€‚è¿™å°†æ›´æ–°æƒé‡ã€‚åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»å°å¿ƒï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»ç°åœ¨æ¸…ç©ºæ¢¯åº¦ã€‚
- en: because whenever we call the backward functionï¼Œ this will sum up the gradients
    into the dot Gr attributeã€‚ So now we want to empty this againã€‚ And we simply say
    optimizer dot0 graã€‚ So you should never forget thisã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_33.png)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæ¯å½“æˆ‘ä»¬è°ƒç”¨ backward å‡½æ•°æ—¶ï¼Œè¿™å°†æŠŠæ¢¯åº¦ç´¯åŠ åˆ° dot Gr å±æ€§ä¸­ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æƒ³å†æ¬¡æ¸…ç©ºè¿™ä¸ªã€‚æˆ‘ä»¬ç®€å•åœ°è¯´ optimizer dot
    0 graã€‚æ‰€ä»¥ä½ æ°¸è¿œä¸è¦å¿˜è®°è¿™ä¸ªã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_33.png)
- en: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_34.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_34.png)'
- en: And then we are done with the draining loopã€‚ Let's also print some informationã€‚
    So let's say ifã€‚Epoch plus 1 modular1s equals equals 0ã€‚ So every 10th stepï¼Œ we
    want to print some informationã€‚ So let's print the epochã€‚ And here we say epoch
    plus oneã€‚ and let's also print the lossã€‚ the loss equalsã€‚ And here we can can
    say loss dot itemã€‚ and let's format thisã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å®Œæˆäº†è®­ç»ƒå¾ªç¯ã€‚è®©æˆ‘ä»¬æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚å‡è®¾å¦‚æœ Epoch plus 1 modular1s ç­‰äº 0ã€‚æ¯ç¬¬ 10 æ­¥ï¼Œæˆ‘ä»¬æƒ³æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ‰“å°
    epochã€‚è¿™é‡Œæˆ‘ä»¬è¯´ epoch plus oneã€‚è®©æˆ‘ä»¬ä¹Ÿæ‰“å°æŸå¤±ï¼ŒæŸå¤±ç­‰äºã€‚æˆ‘ä»¬å¯ä»¥è¯´ loss dot itemã€‚ç„¶åè®©æˆ‘ä»¬æ ¼å¼åŒ–è¿™ä¸ªã€‚
- en: So let's plot or print only for decimal valuesã€‚ğŸ¤¢ï¼ŒSo now we are doneã€‚ and now
    let's also plot thisã€‚ soã€‚Let's sayï¼Œ let's get all the predicted values by saying
    predicted equals hereã€‚ we call our final model nowï¼Œ model Xã€‚And with all the dataã€‚And
    now we want to convert this to nu pipe back againï¼Œ but before we do thatã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬åªç»˜åˆ¶æˆ–æ‰“å°å°æ•°å€¼ã€‚ğŸ¤¢ï¼Œç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚ç°åœ¨æˆ‘ä»¬ä¹Ÿæ¥ç»˜åˆ¶è¿™ä¸ªã€‚æˆ‘ä»¬æ¥è¯´ï¼Œè·å–æ‰€æœ‰çš„é¢„æµ‹å€¼ï¼Œç§°ä¸º predictedã€‚ç°åœ¨æˆ‘ä»¬è°ƒç”¨æˆ‘ä»¬çš„æœ€ç»ˆæ¨¡å‹ï¼Œmodel
    Xã€‚å¸¦ç€æ‰€æœ‰çš„æ•°æ®ã€‚ç°åœ¨æˆ‘ä»¬æƒ³æŠŠå®ƒè½¬æ¢å› nu pipeï¼Œä½†åœ¨æ­¤ä¹‹å‰ã€‚
- en: we want to detach our tenzoorï¼Œ so we want to prevent this operation from being
    tracked in our graph and our computational graphã€‚Because right nowï¼Œ this tenorã€‚Here
    I have a typo predictedã€‚ So this tenor has the required gradients argument set
    to trueã€‚ But now we want this to fall to be falseã€‚ So this will generate a new
    tenzor where our gradient calculation attribute is falseã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¦åˆ†ç¦»æˆ‘ä»¬çš„ tenzoï¼Œä»¥é˜²æ­¢æ­¤æ“ä½œè¢«è·Ÿè¸ªåœ¨æˆ‘ä»¬çš„å›¾å½¢å’Œè®¡ç®—å›¾ä¸­ã€‚å› ä¸ºç°åœ¨ï¼Œè¿™ä¸ª tenzoã€‚è¿™é‡Œæˆ‘æœ‰ä¸ªé”™åˆ«å­—é¢„æµ‹äº†ã€‚æ‰€ä»¥è¿™ä¸ª tenzo éœ€è¦æ¢¯åº¦å‚æ•°è®¾ç½®ä¸º
    trueã€‚ä½†ç°åœ¨æˆ‘ä»¬å¸Œæœ›å®ƒå˜ä¸º falseã€‚è¿™æ ·å°†ç”Ÿæˆä¸€ä¸ªæ–°çš„ tenzoï¼Œå…¶ä¸­æˆ‘ä»¬çš„æ¢¯åº¦è®¡ç®—å±æ€§ä¸º falseã€‚
- en: So this is our new tenzoã€‚ And then we just call the numpy functionã€‚ Now we convert
    it to numpy and now plot thisã€‚ So let's say first plot all our dataã€‚Soã€‚ x nuy
    and y nuyã€‚And we want to plot this asï¼Œ let's say red dotsã€‚ And then we want to
    plot our generated or approximated functionã€‚ So let's say Pï¼Œ L T dot plotã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬çš„æ–° tenzoã€‚ç„¶åæˆ‘ä»¬è°ƒç”¨ numpy å‡½æ•°ã€‚ç°åœ¨æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º numpyï¼Œå¹¶ç»˜åˆ¶è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬å…ˆç»˜åˆ¶æ‰€æœ‰çš„æ•°æ®ã€‚æ‰€ä»¥ï¼Œx nuy å’Œ y
    nuyã€‚æˆ‘ä»¬å¸Œæœ›å°†å…¶ç»˜åˆ¶ä¸ºçº¢ç‚¹ã€‚ç„¶åæˆ‘ä»¬å¸Œæœ›ç»˜åˆ¶æˆ‘ä»¬çš„ç”Ÿæˆæˆ–è¿‘ä¼¼å‡½æ•°ã€‚æ‰€ä»¥è¯´ Pï¼ŒL T dot plotã€‚
- en: X nuy on the X axis and our predicted labels on the Y axisã€‚And let's plot this
    in blueã€‚ And then we say P L T dot showã€‚ And now let's run this and hope that
    everything is correctã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_36.png)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ X è½´ä¸Šæ˜¯ X nuyï¼ŒY è½´ä¸Šæ˜¯æˆ‘ä»¬çš„é¢„æµ‹æ ‡ç­¾ã€‚è®©æˆ‘ä»¬ç”¨è“è‰²ç»˜åˆ¶è¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬è¯´ P L T dot showã€‚ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå¸Œæœ›ä¸€åˆ‡éƒ½æ˜¯æ­£ç¡®çš„ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_36.png)
- en: And now this plot appears hereã€‚ So now we see that we have a pretty good approximation
    of our data with this lineã€‚ and we see that this is workingã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_38.png)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿™ä¸ªå›¾å‡ºç°äº†ã€‚æˆ‘ä»¬çœ‹åˆ°è¿™æ¡çº¿å¾ˆå¥½åœ°è¿‘ä¼¼äº†æˆ‘ä»¬çš„æ•°æ®ï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™ä¸ªæ˜¯æœ‰æ•ˆçš„ã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_38.png)
- en: And yeahï¼Œ now were doneã€‚ I hope you enjoyed thisã€‚ If you like thisã€‚ please subscribe
    to the channel and see you next timeï¼Œ byeã€‚ğŸ˜Šã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_40.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªã€‚å¦‚æœä½ å–œæ¬¢ï¼Œè¯·è®¢é˜…é¢‘é“ï¼Œä¸‹æ¬¡è§ï¼Œå†è§ã€‚ğŸ˜Šã€‚![](img/ad2afccfb99dbe5b3a127586f9ddc4a3_40.png)
