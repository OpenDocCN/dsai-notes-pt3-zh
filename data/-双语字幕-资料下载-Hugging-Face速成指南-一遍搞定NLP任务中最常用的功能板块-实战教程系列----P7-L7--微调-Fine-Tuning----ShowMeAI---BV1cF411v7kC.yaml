- en: 【双语字幕+资料下载】Hugging Face速成指南！一遍搞定NLP任务中最常用的功能板块＜实战教程系列＞ - P7：L7- 微调(Fine Tuning)
    - ShowMeAI - BV1cF411v7kC
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】Hugging Face速成指南！一遍搞定NLP任务中最常用的功能板块＜实战教程系列＞ - P7：L7- 微调(Fine Tuning)
    - ShowMeAI - BV1cF411v7kC
- en: Another a look at how we can finet tune our own models。 So this is very important。
    and I already prepared some code here， and I will go over this very roughly。 but
    there's also a very great documentation about this。 So we can go to this documentation
    page here。 and you can also open this in colo。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们如何微调自己模型的看法。这非常重要，我已经准备了一些代码，我会大致介绍，但还有很好的文档可以参考。因此，我们可以访问这个文档页面，你也可以在colab中打开它。
- en: So either with Pytorch or tens of flow code。 So this is really helpful。 So I
    encourage you to check this out。 But now let's go over this briefly。 So basically
    there are five steps you have to do。 So in this example， it's for Pytorch。 So
    we have to prepare our data set， for example， load it from a Cv file or whatever。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是使用Pytorch还是TensorFlow代码，这真的很有帮助。因此，我鼓励你查看一下。但现在让我们快速浏览一下。基本上，你需要做五个步骤。在这个例子中，适用于Pytorch。我们必须准备我们的数据集，例如，从Cv文件或其他地方加载。
- en: Then we have to load a pretrained tokenizer and then call it with our dataset
    set。 So then we get the encodings or the token Is。😊。![](img/4ee3097c7f433d913bfc9e33552e43f7_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们必须加载一个预训练的分词器，然后用我们的数据集调用它。然后我们得到编码或tokens。😊。![](img/4ee3097c7f433d913bfc9e33552e43f7_1.png)
- en: '![](img/4ee3097c7f433d913bfc9e33552e43f7_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ee3097c7f433d913bfc9e33552e43f7_2.png)'
- en: Then we have to build a pytorch dataset set out of this with these encoding。
    So if you don't know what a pytorch dataset is， then I will have a link for you
    here where I explain this。 Then we also load a pretrain model and then we can
    either load a hugging face trainer and train it。 So this abstracts away a lot
    of things， or we can just use a native or normal pytorch training pipeline like
    in our other pytorch code。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们必须根据这些编码构建一个pytorch数据集。如果你不知道什么是pytorch数据集，我这里会有一个链接来解释这个。然后我们加载一个预训练模型，然后可以加载Hugging
    Face训练器并进行训练。这抽象了很多事情，或者我们可以使用一个本地的或普通的pytorch训练管道，就像我们其他pytorch代码中一样。
- en: So yeah， this is what we have to do。 So let's go over this very quickly。 So
    in this case。 we define our base model name。 So we want to start with a thistilbert
    face uncased version。 So in this case， for example， not the fine tuned one。 So
    just this one。 then step 1。 we prepare the data。 So we write a helpful function
    to create text and。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这就是我们必须做的。让我们很快浏览一下。在这个案例中，我们定义我们的基础模型名称。因此我们想从这个distilbert面部uncased版本开始。例如，在这个案例中，不是微调的那个。所以仅仅是这个。然后步骤1。我们准备数据。我们写一个有用的函数来创建文本和标签。
- en: Labels out of the actual text and here we downloaded some data set and put it
    in our folder。 so I already did this here and yeah this is available at this website
    and this contains movie reviews so we want to find you in our models on movie
    reviews for sentiment classification So here we create training text and the training
    labels with our helper function and we also do a train test split to get validation
    text and labels and yeah then as a next step we create or we define a Pytorrch
    data set。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际文本中，这里我们下载了一些数据集并放入我们的文件夹。因此，我已经在这里做了，是的，这可以在这个网站上获得，包含电影评论，因此我们希望在电影评论上微调我们的模型，以进行情感分类。因此，在这里我们使用我们的助手函数创建训练文本和训练标签，我们还进行训练测试拆分，以获得验证文本和标签，然后下一步我们创建或定义一个Pytorch数据集。
- en: So this inherits from pitorrch data set so torch U data we import data and then
    we define this here So again I have a tutorial where I explain how this works
    but basically it needs the encodecodings and。![](img/4ee3097c7f433d913bfc9e33552e43f7_4.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这继承自pytorch数据集，因此torch U数据我们导入数据，然后在这里定义它。因此，我有一个教程来解释这个是如何工作的，但基本上它需要编码。![](img/4ee3097c7f433d913bfc9e33552e43f7_4.png)
- en: '![](img/4ee3097c7f433d913bfc9e33552e43f7_5.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ee3097c7f433d913bfc9e33552e43f7_5.png)'
- en: The labels and it stores them in here。 So yeah， this needs the encodings。 So
    for the encodings。 we need a tokenizer。 So again， we use this from pretrain function
    with the model name And in this case。 since we know we use the distill bird one，
    we can use this class。 So remember before we used a generic tokenizer， this auto
    tokenizer class。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 标签将被存储在这里。所以，是的，这需要编码。因此，对于编码，我们需要一个分词器。再一次，我们使用这个来自预训练函数的模型名称，在这个案例中，由于我们知道使用的是distill
    bird模型，我们可以使用这个类。所以记住，我们之前使用的是一个通用分词器，这个自动分词器类。
- en: And here we used a more concrete one So we use the distal bird tokenizer fast
    then we apply it to training validation and test set and get the encodings。 then
    we put them in our data set and create the Pytorch data set and then we import
    a trainer and the training argument。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了一个更具体的示例。因此，我们使用了远程鸟分词器快速处理，然后将其应用于训练、验证和测试集，并获取编码。然后，我们将它们放入数据集中，并创建
    Pytorch 数据集，接着导入一个训练器和训练参数。
- en: So this is an available in Trans us library and then we can set this up so we
    can。Create the arguments。 So here， for example， we specify the number of training
    epochs。 the output directory， the learning rate and other parameters we want and
    then we create our model again from a concrete model class and then with this
    dot from pretrained function and then we set up this trainer and give it the model
    and the training arguments and then the training set and the validation set and
    then we simply have to call trainer the train and this will do all the training
    for us and afterwards you can test it on your test data set and then you have
    a fine tune model。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 Trans us 库中是可用的，我们可以设置它来创建参数。例如，在这里，我们指定训练纪元的数量、输出目录、学习率和其他参数，然后再次从具体模型类创建我们的模型，使用这个
    dot from pretrained 函数，然后设置这个训练器，提供模型、训练参数、训练集和验证集，然后我们只需调用训练器的 train，这将为我们完成所有训练，之后你可以在测试数据集上测试它，然后你就拥有一个微调的模型。
- en: So yeah， this is basically all you know it and then I also want to show you
    that instead of using this trainer if you want to do it manually and have even
    more flexibility you can just use a normal Pytht training loop。For this， we use
    a data loader and we need an optimization。 So in this case。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这基本上就是你所知道的，然后我还想告诉你，如果你想手动操作并获得更多灵活性，可以使用普通的 Pytht 训练循环。为此，我们使用数据加载器并需要一个优化器。在这种情况下。
- en: we use an optimizer from the Transformers library。 and then here we specify
    our device then again we create this model。 We push it to the device and set it
    to training mode then we create a data loader and the optimizer and then we do
    the typical training loop So we say for epoch in nu epos and for batch in our
    training loader and then we do the stuff we always do。 we say optimizer zero grad，
    we also push it to the device if necessary。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了来自 Transformers 库的优化器。然后在这里我们指定了设备，再次创建这个模型。我们将其推送到设备并设置为训练模式，然后创建数据加载器和优化器，接着进行典型的训练循环。我们说，对于每个纪元和训练加载器中的每个批次，我们执行我们通常做的事情。我们说优化器零梯度，如果需要也将其推送到设备。
- en: then we call the model and we calculate the loss with this and in this case
    this is already contained in the output so we can just access the loss like this
    then we call loss the backward and optimizer step and iterate and afterwards we
    can set our model to。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们调用模型，使用这个计算损失，在这种情况下，它已经包含在输出中，因此我们可以这样访问损失。然后我们调用损失的反向传播和优化器步骤，进行迭代，之后我们可以将模型设置为。
- en: Evaluation mode again。 and yeah， this is how we do it in native Pythtorch code。
    and yeah so this is basically how we do a fine tuning and then can fine tune our
    own models And then afterwards you can also upload them to the hugging face model
    hub if you want So yeah I think that's pretty cool and yeah that's all that I
    wanted to show you for now I think that's enough to get started with hugging face
    and I hope you enjoyed this tutorial and then I hope to see in the next video。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模式再次启用。是的，这就是我们在原生 Pythtorch 代码中执行的方式。这基本上就是我们如何进行微调，然后可以微调我们自己的模型。之后，如果需要，你还可以将它们上传到
    Hugging Face 模型中心。所以我觉得这非常酷，今天我想展示的就是这些，希望你喜欢这个教程，也期待在下一个视频中见到你。
- en: 😊。![](img/4ee3097c7f433d913bfc9e33552e43f7_7.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 😊。![](img/4ee3097c7f433d913bfc9e33552e43f7_7.png)
