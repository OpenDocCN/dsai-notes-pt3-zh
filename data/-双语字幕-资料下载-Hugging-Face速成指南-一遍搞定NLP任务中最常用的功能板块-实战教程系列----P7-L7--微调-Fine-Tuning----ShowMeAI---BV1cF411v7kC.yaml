- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- å¾®è°ƒ(Fine Tuning)
    - ShowMeAI - BV1cF411v7kC
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- å¾®è°ƒ(Fine Tuning)
    - ShowMeAI - BV1cF411v7kC
- en: Another a look at how we can finet tune our own modelsã€‚ So this is very importantã€‚
    and I already prepared some code hereï¼Œ and I will go over this very roughlyã€‚ but
    there's also a very great documentation about thisã€‚ So we can go to this documentation
    page hereã€‚ and you can also open this in coloã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæˆ‘ä»¬å¦‚ä½•å¾®è°ƒè‡ªå·±æ¨¡å‹çš„çœ‹æ³•ã€‚è¿™éå¸¸é‡è¦ï¼Œæˆ‘å·²ç»å‡†å¤‡äº†ä¸€äº›ä»£ç ï¼Œæˆ‘ä¼šå¤§è‡´ä»‹ç»ï¼Œä½†è¿˜æœ‰å¾ˆå¥½çš„æ–‡æ¡£å¯ä»¥å‚è€ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®è¿™ä¸ªæ–‡æ¡£é¡µé¢ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨colabä¸­æ‰“å¼€å®ƒã€‚
- en: So either with Pytorch or tens of flow codeã€‚ So this is really helpfulã€‚ So I
    encourage you to check this outã€‚ But now let's go over this brieflyã€‚ So basically
    there are five steps you have to doã€‚ So in this exampleï¼Œ it's for Pytorchã€‚ So
    we have to prepare our data setï¼Œ for exampleï¼Œ load it from a Cv file or whateverã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ˜¯ä½¿ç”¨Pytorchè¿˜æ˜¯TensorFlowä»£ç ï¼Œè¿™çœŸçš„å¾ˆæœ‰å¸®åŠ©ã€‚å› æ­¤ï¼Œæˆ‘é¼“åŠ±ä½ æŸ¥çœ‹ä¸€ä¸‹ã€‚ä½†ç°åœ¨è®©æˆ‘ä»¬å¿«é€Ÿæµè§ˆä¸€ä¸‹ã€‚åŸºæœ¬ä¸Šï¼Œä½ éœ€è¦åšäº”ä¸ªæ­¥éª¤ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œé€‚ç”¨äºPytorchã€‚æˆ‘ä»¬å¿…é¡»å‡†å¤‡æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œä¾‹å¦‚ï¼Œä»Cvæ–‡ä»¶æˆ–å…¶ä»–åœ°æ–¹åŠ è½½ã€‚
- en: Then we have to load a pretrained tokenizer and then call it with our dataset
    setã€‚ So then we get the encodings or the token Isã€‚ğŸ˜Šã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¿…é¡»åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„åˆ†è¯å™¨ï¼Œç„¶åç”¨æˆ‘ä»¬çš„æ•°æ®é›†è°ƒç”¨å®ƒã€‚ç„¶åæˆ‘ä»¬å¾—åˆ°ç¼–ç æˆ–tokensã€‚ğŸ˜Šã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_1.png)
- en: '![](img/4ee3097c7f433d913bfc9e33552e43f7_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ee3097c7f433d913bfc9e33552e43f7_2.png)'
- en: Then we have to build a pytorch dataset set out of this with these encodingã€‚
    So if you don't know what a pytorch dataset isï¼Œ then I will have a link for you
    here where I explain thisã€‚ Then we also load a pretrain model and then we can
    either load a hugging face trainer and train itã€‚ So this abstracts away a lot
    of thingsï¼Œ or we can just use a native or normal pytorch training pipeline like
    in our other pytorch codeã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¿…é¡»æ ¹æ®è¿™äº›ç¼–ç æ„å»ºä¸€ä¸ªpytorchæ•°æ®é›†ã€‚å¦‚æœä½ ä¸çŸ¥é“ä»€ä¹ˆæ˜¯pytorchæ•°æ®é›†ï¼Œæˆ‘è¿™é‡Œä¼šæœ‰ä¸€ä¸ªé“¾æ¥æ¥è§£é‡Šè¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¯ä»¥åŠ è½½Hugging
    Faceè®­ç»ƒå™¨å¹¶è¿›è¡Œè®­ç»ƒã€‚è¿™æŠ½è±¡äº†å¾ˆå¤šäº‹æƒ…ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªæœ¬åœ°çš„æˆ–æ™®é€šçš„pytorchè®­ç»ƒç®¡é“ï¼Œå°±åƒæˆ‘ä»¬å…¶ä»–pytorchä»£ç ä¸­ä¸€æ ·ã€‚
- en: So yeahï¼Œ this is what we have to doã€‚ So let's go over this very quicklyã€‚ So
    in this caseã€‚ we define our base model nameã€‚ So we want to start with a thistilbert
    face uncased versionã€‚ So in this caseï¼Œ for exampleï¼Œ not the fine tuned oneã€‚ So
    just this oneã€‚ then step 1ã€‚ we prepare the dataã€‚ So we write a helpful function
    to create text andã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¿…é¡»åšçš„ã€‚è®©æˆ‘ä»¬å¾ˆå¿«æµè§ˆä¸€ä¸‹ã€‚åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„åŸºç¡€æ¨¡å‹åç§°ã€‚å› æ­¤æˆ‘ä»¬æƒ³ä»è¿™ä¸ªdistilberté¢éƒ¨uncasedç‰ˆæœ¬å¼€å§‹ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œä¸æ˜¯å¾®è°ƒçš„é‚£ä¸ªã€‚æ‰€ä»¥ä»…ä»…æ˜¯è¿™ä¸ªã€‚ç„¶åæ­¥éª¤1ã€‚æˆ‘ä»¬å‡†å¤‡æ•°æ®ã€‚æˆ‘ä»¬å†™ä¸€ä¸ªæœ‰ç”¨çš„å‡½æ•°æ¥åˆ›å»ºæ–‡æœ¬å’Œæ ‡ç­¾ã€‚
- en: Labels out of the actual text and here we downloaded some data set and put it
    in our folderã€‚ so I already did this here and yeah this is available at this website
    and this contains movie reviews so we want to find you in our models on movie
    reviews for sentiment classification So here we create training text and the training
    labels with our helper function and we also do a train test split to get validation
    text and labels and yeah then as a next step we create or we define a Pytorrch
    data setã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å®é™…æ–‡æœ¬ä¸­ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸‹è½½äº†ä¸€äº›æ•°æ®é›†å¹¶æ”¾å…¥æˆ‘ä»¬çš„æ–‡ä»¶å¤¹ã€‚å› æ­¤ï¼Œæˆ‘å·²ç»åœ¨è¿™é‡Œåšäº†ï¼Œæ˜¯çš„ï¼Œè¿™å¯ä»¥åœ¨è¿™ä¸ªç½‘ç«™ä¸Šè·å¾—ï¼ŒåŒ…å«ç”µå½±è¯„è®ºï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›åœ¨ç”µå½±è¯„è®ºä¸Šå¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œä»¥è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„åŠ©æ‰‹å‡½æ•°åˆ›å»ºè®­ç»ƒæ–‡æœ¬å’Œè®­ç»ƒæ ‡ç­¾ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œè®­ç»ƒæµ‹è¯•æ‹†åˆ†ï¼Œä»¥è·å¾—éªŒè¯æ–‡æœ¬å’Œæ ‡ç­¾ï¼Œç„¶åä¸‹ä¸€æ­¥æˆ‘ä»¬åˆ›å»ºæˆ–å®šä¹‰ä¸€ä¸ªPytorchæ•°æ®é›†ã€‚
- en: So this inherits from pitorrch data set so torch U data we import data and then
    we define this here So again I have a tutorial where I explain how this works
    but basically it needs the encodecodings andã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_4.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»§æ‰¿è‡ªpytorchæ•°æ®é›†ï¼Œå› æ­¤torch Uæ•°æ®æˆ‘ä»¬å¯¼å…¥æ•°æ®ï¼Œç„¶ååœ¨è¿™é‡Œå®šä¹‰å®ƒã€‚å› æ­¤ï¼Œæˆ‘æœ‰ä¸€ä¸ªæ•™ç¨‹æ¥è§£é‡Šè¿™ä¸ªæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä½†åŸºæœ¬ä¸Šå®ƒéœ€è¦ç¼–ç ã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_4.png)
- en: '![](img/4ee3097c7f433d913bfc9e33552e43f7_5.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ee3097c7f433d913bfc9e33552e43f7_5.png)'
- en: The labels and it stores them in hereã€‚ So yeahï¼Œ this needs the encodingsã€‚ So
    for the encodingsã€‚ we need a tokenizerã€‚ So againï¼Œ we use this from pretrain function
    with the model name And in this caseã€‚ since we know we use the distill bird oneï¼Œ
    we can use this classã€‚ So remember before we used a generic tokenizerï¼Œ this auto
    tokenizer classã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡ç­¾å°†è¢«å­˜å‚¨åœ¨è¿™é‡Œã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™éœ€è¦ç¼–ç ã€‚å› æ­¤ï¼Œå¯¹äºç¼–ç ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåˆ†è¯å™¨ã€‚å†ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ¥è‡ªé¢„è®­ç»ƒå‡½æ•°çš„æ¨¡å‹åç§°ï¼Œåœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œç”±äºæˆ‘ä»¬çŸ¥é“ä½¿ç”¨çš„æ˜¯distill
    birdæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªç±»ã€‚æ‰€ä»¥è®°ä½ï¼Œæˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªé€šç”¨åˆ†è¯å™¨ï¼Œè¿™ä¸ªè‡ªåŠ¨åˆ†è¯å™¨ç±»ã€‚
- en: And here we used a more concrete one So we use the distal bird tokenizer fast
    then we apply it to training validation and test set and get the encodingsã€‚ then
    we put them in our data set and create the Pytorch data set and then we import
    a trainer and the training argumentã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªæ›´å…·ä½“çš„ç¤ºä¾‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¿œç¨‹é¸Ÿåˆ†è¯å™¨å¿«é€Ÿå¤„ç†ï¼Œç„¶åå°†å…¶åº”ç”¨äºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ï¼Œå¹¶è·å–ç¼–ç ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å®ƒä»¬æ”¾å…¥æ•°æ®é›†ä¸­ï¼Œå¹¶åˆ›å»º
    Pytorch æ•°æ®é›†ï¼Œæ¥ç€å¯¼å…¥ä¸€ä¸ªè®­ç»ƒå™¨å’Œè®­ç»ƒå‚æ•°ã€‚
- en: So this is an available in Trans us library and then we can set this up so we
    canã€‚Create the argumentsã€‚ So hereï¼Œ for exampleï¼Œ we specify the number of training
    epochsã€‚ the output directoryï¼Œ the learning rate and other parameters we want and
    then we create our model again from a concrete model class and then with this
    dot from pretrained function and then we set up this trainer and give it the model
    and the training arguments and then the training set and the validation set and
    then we simply have to call trainer the train and this will do all the training
    for us and afterwards you can test it on your test data set and then you have
    a fine tune modelã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨ Trans us åº“ä¸­æ˜¯å¯ç”¨çš„ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®å®ƒæ¥åˆ›å»ºå‚æ•°ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®šè®­ç»ƒçºªå…ƒçš„æ•°é‡ã€è¾“å‡ºç›®å½•ã€å­¦ä¹ ç‡å’Œå…¶ä»–å‚æ•°ï¼Œç„¶åå†æ¬¡ä»å…·ä½“æ¨¡å‹ç±»åˆ›å»ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œä½¿ç”¨è¿™ä¸ª
    dot from pretrained å‡½æ•°ï¼Œç„¶åè®¾ç½®è¿™ä¸ªè®­ç»ƒå™¨ï¼Œæä¾›æ¨¡å‹ã€è®­ç»ƒå‚æ•°ã€è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œç„¶åæˆ‘ä»¬åªéœ€è°ƒç”¨è®­ç»ƒå™¨çš„ trainï¼Œè¿™å°†ä¸ºæˆ‘ä»¬å®Œæˆæ‰€æœ‰è®­ç»ƒï¼Œä¹‹åä½ å¯ä»¥åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šæµ‹è¯•å®ƒï¼Œç„¶åä½ å°±æ‹¥æœ‰ä¸€ä¸ªå¾®è°ƒçš„æ¨¡å‹ã€‚
- en: So yeahï¼Œ this is basically all you know it and then I also want to show you
    that instead of using this trainer if you want to do it manually and have even
    more flexibility you can just use a normal Pytht training loopã€‚For thisï¼Œ we use
    a data loader and we need an optimizationã€‚ So in this caseã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œè¿™åŸºæœ¬ä¸Šå°±æ˜¯ä½ æ‰€çŸ¥é“çš„ï¼Œç„¶åæˆ‘è¿˜æƒ³å‘Šè¯‰ä½ ï¼Œå¦‚æœä½ æƒ³æ‰‹åŠ¨æ“ä½œå¹¶è·å¾—æ›´å¤šçµæ´»æ€§ï¼Œå¯ä»¥ä½¿ç”¨æ™®é€šçš„ Pytht è®­ç»ƒå¾ªç¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®åŠ è½½å™¨å¹¶éœ€è¦ä¸€ä¸ªä¼˜åŒ–å™¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ã€‚
- en: we use an optimizer from the Transformers libraryã€‚ and then here we specify
    our device then again we create this modelã€‚ We push it to the device and set it
    to training mode then we create a data loader and the optimizer and then we do
    the typical training loop So we say for epoch in nu epos and for batch in our
    training loader and then we do the stuff we always doã€‚ we say optimizer zero gradï¼Œ
    we also push it to the device if necessaryã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ª Transformers åº“çš„ä¼˜åŒ–å™¨ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬æŒ‡å®šäº†è®¾å¤‡ï¼Œå†æ¬¡åˆ›å»ºè¿™ä¸ªæ¨¡å‹ã€‚æˆ‘ä»¬å°†å…¶æ¨é€åˆ°è®¾å¤‡å¹¶è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œç„¶ååˆ›å»ºæ•°æ®åŠ è½½å™¨å’Œä¼˜åŒ–å™¨ï¼Œæ¥ç€è¿›è¡Œå…¸å‹çš„è®­ç»ƒå¾ªç¯ã€‚æˆ‘ä»¬è¯´ï¼Œå¯¹äºæ¯ä¸ªçºªå…ƒå’Œè®­ç»ƒåŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡ï¼Œæˆ‘ä»¬æ‰§è¡Œæˆ‘ä»¬é€šå¸¸åšçš„äº‹æƒ…ã€‚æˆ‘ä»¬è¯´ä¼˜åŒ–å™¨é›¶æ¢¯åº¦ï¼Œå¦‚æœéœ€è¦ä¹Ÿå°†å…¶æ¨é€åˆ°è®¾å¤‡ã€‚
- en: then we call the model and we calculate the loss with this and in this case
    this is already contained in the output so we can just access the loss like this
    then we call loss the backward and optimizer step and iterate and afterwards we
    can set our model toã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è°ƒç”¨æ¨¡å‹ï¼Œä½¿ç”¨è¿™ä¸ªè®¡ç®—æŸå¤±ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå·²ç»åŒ…å«åœ¨è¾“å‡ºä¸­ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è¿™æ ·è®¿é—®æŸå¤±ã€‚ç„¶åæˆ‘ä»¬è°ƒç”¨æŸå¤±çš„åå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ­¥éª¤ï¼Œè¿›è¡Œè¿­ä»£ï¼Œä¹‹åæˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹è®¾ç½®ä¸ºã€‚
- en: Evaluation mode againã€‚ and yeahï¼Œ this is how we do it in native Pythtorch codeã€‚
    and yeah so this is basically how we do a fine tuning and then can fine tune our
    own models And then afterwards you can also upload them to the hugging face model
    hub if you want So yeah I think that's pretty cool and yeah that's all that I
    wanted to show you for now I think that's enough to get started with hugging face
    and I hope you enjoyed this tutorial and then I hope to see in the next videoã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ¨¡å¼å†æ¬¡å¯ç”¨ã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨åŸç”Ÿ Pythtorch ä»£ç ä¸­æ‰§è¡Œçš„æ–¹å¼ã€‚è¿™åŸºæœ¬ä¸Šå°±æ˜¯æˆ‘ä»¬å¦‚ä½•è¿›è¡Œå¾®è°ƒï¼Œç„¶åå¯ä»¥å¾®è°ƒæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ã€‚ä¹‹åï¼Œå¦‚æœéœ€è¦ï¼Œä½ è¿˜å¯ä»¥å°†å®ƒä»¬ä¸Šä¼ åˆ°
    Hugging Face æ¨¡å‹ä¸­å¿ƒã€‚æ‰€ä»¥æˆ‘è§‰å¾—è¿™éå¸¸é…·ï¼Œä»Šå¤©æˆ‘æƒ³å±•ç¤ºçš„å°±æ˜¯è¿™äº›ï¼Œå¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œä¹ŸæœŸå¾…åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚
- en: ğŸ˜Šã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_7.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šã€‚![](img/4ee3097c7f433d913bfc9e33552e43f7_7.png)
