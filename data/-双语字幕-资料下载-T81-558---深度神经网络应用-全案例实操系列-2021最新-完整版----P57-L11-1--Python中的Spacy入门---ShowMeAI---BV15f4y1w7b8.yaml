- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P57ï¼šL11.1- Pythonä¸­çš„Spacyå…¥é—¨
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P57ï¼šL11.1- Pythonä¸­çš„Spacyå…¥é—¨
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heaton welcome to applications of deep neural networkss with
    Washington University Now we're going to start a look at natural language processing
    with Cars in particular we're going to begin by looking at some tools that help
    us preproces the data to the neural network we're going to talk about Space for
    the latest on AI course and bell notified of are primary deal natural language
    processing neural is dealing characterrate stories Tsure Island basically LS of
    it reproduces that the second way that you can deal with it is on the word level
    and we dealt with it on the word level for the captioning really you can make
    both techniques any type of problem Word level NLP can be good becauseã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚ç°åœ¨æˆ‘ä»¬å°†å¼€å§‹æ¢è®¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œç‰¹åˆ«æ˜¯æ±½è½¦ç›¸å…³çš„å†…å®¹ã€‚æˆ‘ä»¬å°†é¦–å…ˆçœ‹çœ‹ä¸€äº›å·¥å…·ï¼Œè¿™äº›å·¥å…·å¸®åŠ©æˆ‘ä»¬åœ¨å°†æ•°æ®é¢„å¤„ç†åˆ°ç¥ç»ç½‘ç»œä¹‹å‰è¿›è¡Œå¤„ç†ã€‚æˆ‘ä»¬å°†è®¨è®ºSpacyï¼Œè¿™æ˜¯å…³äºAIè¯¾ç¨‹çš„æœ€æ–°å†…å®¹ï¼Œå¹¶æé†’ä½ æ³¨æ„æˆ‘ä»¬ä¸»è¦å¤„ç†è‡ªç„¶è¯­è¨€çš„å†…å®¹ï¼Œå®ƒæ¶‰åŠå­—ç¬¦ã€ç‡ã€æ•…äº‹ï¼ŒåŸºæœ¬ä¸Šæ˜¯å¯¹å…¶çš„å†ç°ã€‚å¤„ç†å®ƒçš„ç¬¬äºŒç§æ–¹æ³•æ˜¯æŒ‰è¯çº§è¿›è¡Œï¼Œè€Œæˆ‘ä»¬ç¡®å®åœ¨å­—å¹•ä¸­æŒ‰è¯çº§å¤„ç†è¿‡ï¼Œå®é™…ä¸Šä½ å¯ä»¥å°†è¿™ä¸¤ç§æŠ€æœ¯åº”ç”¨äºä»»ä½•ç±»å‹çš„é—®é¢˜ï¼Œè¯çº§NLPå¯ä»¥å¾ˆå¥½åœ°å¤„ç†ã€‚
- en: '![](img/ff26651c6e28d6ee53469ef48ed52d86_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ff26651c6e28d6ee53469ef48ed52d86_1.png)'
- en: You can use additional libraries available to you in Python to actually process
    those words before they go into the actual neural networkã€‚ characteract level
    has its advantages because you're not doing that because you're letting the neural
    network actually figure out all of the things about English suffixes prefixes
    all these grammatical type expressionã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨Pythonä¸­å¯ç”¨çš„é¢å¤–åº“ï¼Œåœ¨å°†è¿™äº›å•è¯é€å…¥å®é™…çš„ç¥ç»ç½‘ç»œä¹‹å‰å¯¹å…¶è¿›è¡Œå¤„ç†ã€‚å­—ç¬¦çº§åˆ«æœ‰å…¶ä¼˜ç‚¹ï¼Œå› ä¸ºä½ å¹¶ä¸åœ¨å¤„ç†è¿™äº›é—®é¢˜ï¼Œå› ä¸ºä½ è®©ç¥ç»ç½‘ç»œè‡ªå·±å»å¼„æ¸…æ¥šè‹±è¯­åç¼€ã€å‰ç¼€ä»¥åŠæ‰€æœ‰è¿™äº›è¯­æ³•ç±»å‹çš„è¡¨è¾¾ã€‚
- en: Some techniques are better for othersã€‚ The more historic method for natural
    language processing was heavy grammatical analysisã€‚ The more modern and newer
    techniques are pretty much end to end where the neural networks operate on the
    raw text directlyã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›æŠ€æœ¯å¯¹äºå…¶ä»–æŠ€æœ¯æ¥è¯´æ›´å¥½ã€‚è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¼ ç»Ÿæ–¹æ³•æ˜¯è¿›è¡Œå¤§é‡çš„è¯­æ³•åˆ†æã€‚è€Œç°ä»£çš„æ–°æŠ€æœ¯å‡ ä¹æ˜¯ç«¯åˆ°ç«¯çš„ï¼Œç¥ç»ç½‘ç»œç›´æ¥åœ¨åŸå§‹æ–‡æœ¬ä¸Šæ“ä½œã€‚
- en: Howeverï¼Œ you still will sometimes do some processing at the word levelã€‚ So we're
    going to see how to use some of the python packages to work with the actual words
    that are in your text before you actually send them on the neural networkã€‚ As
    far as natural language processing libraries available for Python I mean other
    than Tensorflow there are several butã€‚Two of the ones that I've seen particularly
    stand out in Caagle competitions and related literature to this are NLTK and Spaceyã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä½ æœ‰æ—¶ä»ç„¶ä¼šåœ¨è¯çº§ä¸Šè¿›è¡Œä¸€äº›å¤„ç†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ä¸€äº›PythonåŒ…æ¥å¤„ç†æ–‡æœ¬ä¸­çš„å®é™…å•è¯ï¼Œåœ¨å°†å®ƒä»¬å‘é€åˆ°ç¥ç»ç½‘ç»œä¹‹å‰ã€‚å…³äºå¯ç”¨äºPythonçš„è‡ªç„¶è¯­è¨€å¤„ç†åº“ï¼Œé™¤äº†Tensorflowï¼Œè¿˜æœ‰å‡ ä¸ªï¼Œä½†æ˜¯æˆ‘çœ‹åˆ°çš„ä¸¤ä¸ªç‰¹åˆ«çªå‡ºçš„æ˜¯NLTKå’ŒSpaceyï¼Œè¿™åœ¨Kaggleæ¯”èµ›åŠç›¸å…³æ–‡çŒ®ä¸­å¾—åˆ°äº†ä½“ç°ã€‚
- en: NLTK was around for longer than Spaceyã€‚ It's been used for quite some timeã€‚
    I've used both of these at this pointï¼Œ I prefer spaceyã€‚ and that's the one that
    we will be using for the classã€‚ It's a little more object oriented and object
    oriented in a good wayã€‚ believe meã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: NLTKçš„å‡ºç°æ—¶é—´æ¯”Spaceyæ›´æ—©ï¼Œå·²ç»ä½¿ç”¨äº†ä¸€æ®µæ—¶é—´ã€‚ç›®å‰æˆ‘éƒ½ä½¿ç”¨è¿‡è¿™ä¸¤è€…ï¼Œæˆ‘æ›´å–œæ¬¢Spaceyã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨è¯¾å ‚ä¸Šå°†ä½¿ç”¨çš„å·¥å…·ã€‚å®ƒæ›´é¢å‘å¯¹è±¡ï¼Œè€Œä¸”è¿™ç§é¢å‘å¯¹è±¡çš„æ–¹å¼å¾ˆå¥½ï¼Œç›¸ä¿¡æˆ‘ã€‚
- en: there can be objectoriented in a bad wayï¼Œ meaning that it literally transforms
    the words into individual objects that give you a fair amount of information about
    these individual wordsã€‚ Nowï¼Œ installing spaceyï¼Œ it should have already been installed
    when you went through in module1 and did all the Pip installs that I gave you
    for this classã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½ä¼šä»¥ä¸€ç§ç³Ÿç³•çš„é¢å‘å¯¹è±¡æ–¹å¼å®ç°ï¼Œæ„å‘³ç€å®ƒå®é™…ä¸Šå°†å•è¯è½¬æ¢ä¸ºä¸ªä½“å¯¹è±¡ï¼Œä»è€Œæä¾›å…³äºè¿™äº›å•è¯ç›¸å½“å¤šçš„ä¿¡æ¯ã€‚ç°åœ¨ï¼Œå®‰è£…Spaceyæ—¶ï¼Œå®ƒåº”è¯¥åœ¨ä½ é€šè¿‡æ¨¡å—1å¹¶å®Œæˆæˆ‘ç»™ä½ çš„æ‰€æœ‰Pipå®‰è£…æ—¶å·²ç»å®‰è£…è¿‡ã€‚
- en: Spacey was one of the packages that I specify that you should installã€‚ Howeverã€‚
    if you just install Spaceyï¼Œ it won't workã€‚ It needs a lexicon dictionaryã€‚ And
    I'll suggest that you install the English one for this class because that's what
    we're usingã€‚ if you haven'tã€‚Stall the dictionaryã€‚ most likely you haven't when
    you try to run the code in this moduleã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Spaceyæ˜¯æˆ‘æŒ‡å®šçš„ä½ åº”è¯¥å®‰è£…çš„åŒ…ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œå¦‚æœä½ åªæ˜¯å®‰è£…Spaceyï¼Œå®ƒæ˜¯æ— æ³•å·¥ä½œçš„ã€‚å®ƒéœ€è¦ä¸€ä¸ªè¯å…¸ã€‚æˆ‘å»ºè®®ä½ ä¸ºè¿™é—¨è¯¾å®‰è£…è‹±è¯­è¯å…¸ï¼Œå› ä¸ºè¿™æ­£æ˜¯æˆ‘ä»¬è¦ä½¿ç”¨çš„ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…è¯å…¸ï¼Œå¯èƒ½åœ¨è¿è¡Œè¿™ä¸ªæ¨¡å—ä¸­çš„ä»£ç æ—¶ä½ æ²¡æœ‰ã€‚
- en: you're going to get an error such as this to install spacey dictionaryã€‚ This
    is the command that I found works about the best if you run into problemsã€‚ you
    may want to Google them or post something in in the class piazza or Sla and I'll
    see what I can do as far as if you're getting a specific error and also post something
    in the commentsã€‚ I've run into just about every error imaginableã€‚ well that's
    not trueã€‚ somebody always surprises meã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šé‡åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œæ¯”å¦‚è¦å®‰è£… spacey å­—å…¸ã€‚è¿™æ˜¯æˆ‘å‘ç°çš„æœ€ä½³å‘½ä»¤ï¼Œå¦‚æœä½ é‡åˆ°é—®é¢˜ï¼Œä½ å¯èƒ½æƒ³è¦è°·æ­Œæœç´¢å®ƒä»¬ï¼Œæˆ–è€…åœ¨è¯¾å ‚çš„ Piazza æˆ– Sla
    ä¸Šå‘å¸–ï¼Œæˆ‘ä¼šçœ‹çœ‹å¦‚æœä½ é‡åˆ°ç‰¹å®šé”™è¯¯æˆ‘èƒ½åšäº›ä»€ä¹ˆï¼ŒåŒæ—¶åœ¨è¯„è®ºä¸­å‘å¸–ã€‚æˆ‘é‡åˆ°è¿‡å‡ ä¹æ‰€æœ‰å¯ä»¥æƒ³è±¡çš„é”™è¯¯ã€‚å—¯ï¼Œè¿™ä¸æ˜¯äº‹å®ï¼Œæ€»æ˜¯ä¼šæœ‰äººè®©æˆ‘æ„Ÿåˆ°æƒŠè®¶ã€‚
- en: but I can't necessarily always debug everything because I have to have it physically
    on my computer giving you problemã€‚ So believe me if you get an errorã€‚ Google is
    your friend just copy and paste this and put it into Google and you'll probably
    be taken prompt to stack overflow Some of the terms that you will hear with this
    tokenization is a big one And tokenization is where you take sentences and you
    break them into the individual workã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘å¹¶ä¸æ€»èƒ½è°ƒè¯•æ‰€æœ‰å†…å®¹ï¼Œå› ä¸ºæˆ‘éœ€è¦åœ¨æˆ‘çš„è®¡ç®—æœºä¸Šå®é™…è¿è¡Œå®ƒç»™ä½ å¸¦æ¥é—®é¢˜ã€‚æ‰€ä»¥ç›¸ä¿¡æˆ‘ï¼Œå¦‚æœä½ é‡åˆ°é”™è¯¯ï¼Œè°·æ­Œæ˜¯ä½ çš„æœ‹å‹ï¼Œåªéœ€å¤åˆ¶å¹¶ç²˜è´´è¿™æ®µå†…å®¹åˆ°è°·æ­Œï¼Œä½ å¯èƒ½ä¼šè¢«å¼•å¯¼åˆ°
    Stack Overflowã€‚ä½ å°†ä¼šå¬åˆ°çš„ä¸€äº›æœ¯è¯­ï¼Œåƒè¿™ç§**åˆ†è¯**æ˜¯ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µï¼Œåˆ†è¯å°±æ˜¯å°†å¥å­æ‹†åˆ†æˆå•ä¸ªå•è¯ã€‚
- en: More difficultifficult than it soundã€‚ Let me just put a cell above hereã€‚ Consider
    some of these sentencesã€‚ If I just gave you the sentenceã€‚ this is a test period
    that'd be easy to token the words are this is and a testã€‚ So's four words in thereã€‚
    you will then get more complicated sentences like okay but what about thisã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¯”å¬èµ·æ¥æ›´å›°éš¾ã€‚è®©æˆ‘åœ¨è¿™é‡Œæ”¾ä¸€ä¸ªå•å…ƒæ ¼ã€‚è€ƒè™‘ä¸€ä¸‹è¿™äº›å¥å­ã€‚å¦‚æœæˆ‘ç»™ä½ è¿™ä¸ªå¥å­ï¼šè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ï¼Œé‚£å°†å¾ˆå®¹æ˜“è¿›è¡Œåˆ†è¯ï¼Œå•è¯æ˜¯â€œè¿™â€ã€â€œæ˜¯â€å’Œâ€œä¸€ä¸ªæµ‹è¯•â€ã€‚æ‰€ä»¥é‡Œé¢æœ‰å››ä¸ªå•è¯ã€‚ç„¶åä½ ä¼šå¾—åˆ°æ›´å¤æ‚çš„å¥å­ï¼Œæ¯”å¦‚â€œå¥½çš„ï¼Œä½†è¿™æ€ä¹ˆæ ·ï¼Ÿâ€
- en: Now you need to decide how are you going to tokenize thisã€‚ You may not want
    to lose that commaã€‚ that comma might be useful or maybe you want the comma to
    go awayã€‚ So if you're breaking this into a list of wordã€‚ it might be okay comma
    but what about thisã€‚ So you have to decide if you're breaking on white space or
    notã€‚ then you have things like thisã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ éœ€è¦å†³å®šå¦‚ä½•è¿›è¡Œåˆ†è¯ã€‚ä½ å¯èƒ½ä¸æƒ³å¤±å»é‚£ä¸ªé€—å·ã€‚é‚£ä¸ªé€—å·å¯èƒ½æ˜¯æœ‰ç”¨çš„ï¼Œæˆ–è€…ä½ å¯èƒ½å¸Œæœ›é€—å·æ¶ˆå¤±ã€‚æ‰€ä»¥å¦‚æœä½ æŠŠå®ƒæ‹†åˆ†æˆä¸€ä¸ªå•è¯åˆ—è¡¨ï¼Œå¯èƒ½ä¼šå˜æˆâ€œå¥½çš„ï¼Œä½†è¿™æ€ä¹ˆæ ·ï¼Ÿâ€æ‰€ä»¥ä½ å¿…é¡»å†³å®šæ˜¯åŸºäºç©ºæ ¼è¿›è¡Œæ‹†åˆ†è¿˜æ˜¯å…¶ä»–ã€‚ç„¶åä½ ä¼šé‡åˆ°åƒè¿™æ ·çš„ä¸œè¥¿ã€‚
- en: if you're breaking on punctuationï¼Œ now it's going to be u is a word S is a word
    and a is a word you would like to keep that togetherã€‚ but unless you have some
    knowledge of the languageï¼Œ you won't really know what is going on hereã€‚ these
    will just seem like three sort of disjoã€‚Letters and that's why you have to install
    the dictionary for thisã€‚ You also have to deal with things likeï¼Œ okayï¼Œ I don't
    typically hyphenate dataã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ˜¯åŸºäºæ ‡ç‚¹ç¬¦å·è¿›è¡Œåˆ†è¯ï¼Œç°åœ¨å°†ä¼šæ˜¯ u æ˜¯ä¸€ä¸ªå•è¯ï¼ŒS æ˜¯ä¸€ä¸ªå•è¯ï¼Œa æ˜¯ä¸€ä¸ªå•è¯ï¼Œä½ å¸Œæœ›æŠŠå®ƒä»¬æ”¾åœ¨ä¸€èµ·ã€‚ä½†æ˜¯ï¼Œé™¤éä½ å¯¹è¯­è¨€æœ‰ä¸€äº›çŸ¥è¯†ï¼Œå¦åˆ™ä½ çœŸçš„ä¸çŸ¥é“è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™äº›çœ‹èµ·æ¥åªä¼šåƒæ˜¯ä¸‰ä¸ªæœ‰ç‚¹ä¸è¿è´¯çš„å­—æ¯ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ éœ€è¦ä¸ºæ­¤å®‰è£…å­—å…¸ã€‚ä½ è¿˜éœ€è¦å¤„ç†åƒè¿™æ ·çš„äº‹æƒ…ï¼Œå¥½çš„ï¼Œæˆ‘é€šå¸¸ä¸ä¼šå¯¹æ•°æ®ä½¿ç”¨è¿å­—ç¬¦ã€‚
- en: but you may not want to break those into two wordsã€‚ So if deal hyphens like
    thatã€‚ But sometimes hyps do like if you're going to do an dash or something like
    that where you do a rapid shiftã€‚ you wouldn't want to combine that into this noã€‚
    it's doing a abrupt change in the sentenceã€‚ I think I will do thisã€‚ Noï¼Œ waitï¼Œ
    I will do this or maybe that sounds good So these are some of the issues that
    you will run into when you're trying to tokenize sentences and look at the example
    one that I have hereã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ å¯èƒ½ä¸æƒ³æŠŠå®ƒä»¬åˆ†æˆä¸¤ä¸ªå•è¯ã€‚æ‰€ä»¥å¦‚æœå¤„ç†å¸¦æœ‰è¿å­—ç¬¦çš„æƒ…å†µã€‚ä½†æ˜¯æœ‰æ—¶è¿å­—ç¬¦ç¡®å®ä¼šï¼Œæ¯”å¦‚å¦‚æœä½ è¦åšä¸€ä¸ªçŸ­ç ´æŠ˜å·æˆ–ç±»ä¼¼çš„ä¸œè¥¿ï¼Œä½ ä¸ä¼šæƒ³æŠŠå®ƒåˆå¹¶ä¸ºè¿™ä¸ªï¼Œå› ä¸ºå®ƒåœ¨å¥å­ä¸­è¿›è¡Œäº†ä¸€æ¬¡çªå˜ã€‚æˆ‘è§‰å¾—æˆ‘ä¼šè¿™æ ·åšã€‚ç­‰ä¸€ä¸‹ï¼Œæˆ‘ä¼šè¿™æ ·åšï¼Œæˆ–è€…ä¹Ÿè®¸é‚£å¬èµ·æ¥ä¸é”™ã€‚è¿™äº›æ˜¯åœ¨å°è¯•åˆ†è¯å¥å­æ—¶ä½ ä¼šé‡åˆ°çš„ä¸€äº›é—®é¢˜ï¼Œçœ‹çœ‹æˆ‘åœ¨è¿™é‡Œçš„ç¤ºä¾‹ã€‚
- en: There's the U period K periodã€‚ So you don't you want that to stay togetherã€‚
    and the dollar signã€‚ you might be tempted to strip that offã€‚ but that does give
    you information about that oneã€‚ So we can run this and I will show you how spacey
    tokenize tokenizing is probably one of the most common things that you will do
    with word levelã€‚Natural language processã€‚ Another common one that you'll do is
    it will strip the words to the root formã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ U. K.ã€‚æ‰€ä»¥ä½ æƒ³è®©å®ƒä¿æŒåœ¨ä¸€èµ·ã€‚è€Œç¾å…ƒç¬¦å·ã€‚ä½ å¯èƒ½ä¼šæƒ³å»æ‰å®ƒï¼Œä½†å®ƒç¡®å®ç»™ä½ æä¾›äº†æœ‰å…³é‚£ä¸ªè¯çš„ä¿¡æ¯ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä¼šå‘Šè¯‰ä½  spacey
    çš„åˆ†è¯æ˜¯ä½ åœ¨è¯çº§åˆ«çš„è‡ªç„¶è¯­è¨€å¤„ç†è¿‡ç¨‹ä¸­æœ€å¸¸åšçš„äº‹æƒ…ä¹‹ä¸€ã€‚å¦ä¸€ä¸ªå¸¸è§çš„æ“ä½œæ˜¯å°†å•è¯ç®€åŒ–ä¸ºå…¶æ ¹å½¢å¼ã€‚
- en: So buying would become byã€‚ Now you're losing some information thereã€‚ But that
    wayã€‚ if you're doing simple lookupï¼Œ look would become look rest of these are all
    in their base formã€‚ but this breaks it up into a nice set of words for youã€‚ So
    you don't have to parse it and do the tokenization yourselfã€‚ believe meã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥â€œbuyingâ€ä¼šå˜æˆâ€œbyâ€ã€‚è¿™æ ·ä½ å°±ä¼šå¤±å»ä¸€äº›ä¿¡æ¯ã€‚ä½†å¦‚æœä½ è¿›è¡Œç®€å•æŸ¥æ‰¾ï¼Œâ€œlookâ€ä¼šå˜æˆâ€œlookâ€ï¼Œå…¶ä½™çš„éƒ½æ˜¯å®ƒä»¬çš„åŸºæœ¬å½¢å¼ã€‚ä½†è¿™å°†å…¶åˆ†è§£æˆä¸€ä¸ªæ¼‚äº®çš„è¯ç»„ï¼Œè¿™æ ·ä½ å°±ä¸å¿…è‡ªå·±è§£æå’Œè¿›è¡Œæ ‡è®°åŒ–ã€‚ç›¸ä¿¡æˆ‘ã€‚
- en: never look for spaces and use regular expressions and do tokenization yourselfã€‚
    It's actually a pretty hard problem that requires a dictionary to be loadedã€‚ that
    way you can keep things like UK togetherã€‚ This is also kind of neatã€‚ I don't use
    this as muchã€‚ I prefer the end to end where I'm not dealing with English grammatical
    forms like verbs and adjectives and things like thisã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ«æ‰¾ç©ºæ ¼ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¹¶è‡ªå·±è¿›è¡Œæ ‡è®°åŒ–ã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªç›¸å½“å›°éš¾çš„é—®é¢˜ï¼Œéœ€è¦åŠ è½½å­—å…¸ã€‚è¿™æ ·ä½ å°±å¯ä»¥å°†â€œUKâ€è¿™æ ·çš„è¯æ”¾åœ¨ä¸€èµ·ã€‚è¿™ä¹ŸæŒºæœ‰è¶£çš„ã€‚æˆ‘ä¸å¸¸ç”¨è¿™ä¸ªã€‚æˆ‘æ›´å–œæ¬¢ç«¯åˆ°ç«¯çš„æ–¹æ³•ï¼Œä¸ç”¨å¤„ç†è‹±è¯­çš„è¯­æ³•å½¢å¼ï¼Œæ¯”å¦‚åŠ¨è¯ã€å½¢å®¹è¯ç­‰ç­‰ã€‚
- en: This gives you space these best guess at what these words areã€‚ Now the problem
    thoughã€‚ is it's contextualã€‚ So word can operate sometimes as either a noun or
    a verbã€‚ It just depends on how the words being usedã€‚ So this can be very difficultã€‚
    It's not just a simple lookupã€‚ This can also be useful because this can let you
    very quickly figure out whatã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™äº†ä½ ç©ºé—´ï¼Œå¯ä»¥å¯¹è¿™äº›è¯åšå‡ºæœ€ä½³çŒœæµ‹ã€‚ä½†é—®é¢˜åœ¨äºï¼Œå®ƒæ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„ã€‚å› æ­¤ï¼Œè¯è¯­æœ‰æ—¶å¯ä»¥ä½œä¸ºåè¯æˆ–åŠ¨è¯ä½¿ç”¨ã€‚è¿™å®Œå…¨å–å†³äºè¯è¯­çš„ä½¿ç”¨æ–¹å¼ï¼Œæ‰€ä»¥è¿™å¯èƒ½éå¸¸å›°éš¾ã€‚è¿™ä¸ä»…ä»…æ˜¯ç®€å•çš„æŸ¥æ‰¾ã€‚è¿™ä¹Ÿå¾ˆæœ‰ç”¨ï¼Œå› ä¸ºè¿™å¯ä»¥è®©ä½ å¿«é€Ÿå¼„æ¸…æ¥šã€‚
- en: Different words are as far as that their're numbersã€‚ There's other ones in here
    tooã€‚ you can like noneã€‚ There's a few other likesã€‚ I can't think of another one
    offhandã€‚ but it lets you know if the word is like something so trueã€‚ The one in
    the dollar sign1 is like a number Also billion is even though it's a word is like
    a number of root if you want to go more hardcore on grammar you can even get them
    the sentences diagram for youã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒçš„è¯åœ¨æ•°é‡ä¸Šæ˜¯æœ‰å·®å¼‚çš„ã€‚è¿™å„¿è¿˜æœ‰å…¶ä»–ä¸€äº›ï¼Œæ¯”å¦‚â€œnoneâ€ã€‚è¿˜æœ‰å‡ ä¸ªæˆ‘ä¸€æ—¶æƒ³ä¸èµ·çš„ï¼Œä½†å®ƒè®©ä½ çŸ¥é“è¿™ä¸ªè¯æ˜¯å¦åƒæŸäº›ä¸œè¥¿ã€‚æ‰€ä»¥â€œ$1â€å°±åƒä¸€ä¸ªæ•°å­—ã€‚è™½ç„¶â€œbillionâ€æ˜¯ä¸€ä¸ªè¯ï¼Œä½†åœ¨è¯­æ³•ä¸Šä¹Ÿåƒæ˜¯æ•°å­—çš„æ ¹ã€‚å¦‚æœä½ æƒ³æ›´æ·±å…¥åœ°ç ”ç©¶è¯­æ³•ï¼Œç”šè‡³å¯ä»¥è®©å®ƒä¸ºä½ å›¾ç¤ºå¥å­ã€‚
- en: So if you run this I want a laptop an iPad laptop and a dog So I was trying
    to see if it could figure out that list of words there sort of does and it gives
    you a English sentence diagram and you get this actually as a traversible tree
    that you can use in your code as wellã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœä½ è¿è¡Œè¿™ä¸ªï¼Œæˆ‘æƒ³è¦ä¸€ä¸ªç¬”è®°æœ¬ç”µè„‘ã€ä¸€ä¸ªiPadå’Œä¸€åªç‹—ã€‚æˆ‘æƒ³çœ‹çœ‹å®ƒæ˜¯å¦èƒ½ææ¸…æ¥šé‚£ä¸ªè¯ç»„ï¼Œç»“æœæœ‰ç‚¹æˆåŠŸäº†ï¼Œå®ƒç»™äº†ä½ ä¸€ä¸ªè‹±è¯­å¥å­çš„å›¾ç¤ºï¼Œä½ å®é™…ä¸Šå¯ä»¥å°†å…¶ç”¨ä½œå¯éå†çš„æ ‘ï¼Œè¿™æ ·ä½ å¯ä»¥åœ¨ä»£ç ä¸­ä½¿ç”¨ã€‚
- en: I usually don't use theseï¼Œ but it can be kind of interesting sometimes to see
    the diagram of a sentence really complicated sentences automatic diagrams tend
    to tend to fail often enough by the wayã€‚ one thing that is easy to run into as
    a problem when you run this diagramã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é€šå¸¸ä¸ä½¿ç”¨è¿™äº›ï¼Œä½†æœ‰æ—¶çœ‹åˆ°å¥å­çš„å›¾ç¤ºï¼Œå°¤å…¶æ˜¯å¤æ‚å¥å­çš„è‡ªåŠ¨å›¾ç¤ºï¼Œè¿˜æ˜¯æŒºæœ‰è¶£çš„ã€‚é¡ºä¾¿æä¸€ä¸‹ï¼Œè¿™äº›å›¾ç¤ºå¾€å¾€ä¼šå¤±è´¥ï¼Œè¿è¡Œè¿™ä¸ªå›¾ç¤ºæ—¶ï¼Œæœ‰ä¸€ä¸ªå¸¸è§çš„é—®é¢˜ã€‚
- en: Notice that star is still thereã€‚ So if you try to run this next thingï¼Œ print
    out the sentenceã€‚ you tend to think why is my print taking so longã€‚ Wellã€‚ it's
    because this guy up here is still running because it has to start a web server
    to actually display that to you and you can see that is evident by that So it's
    good to just break that and now you can run these other thing This is what I was
    telling you before where you take the words back to their root levelã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„â€œstarâ€ä»ç„¶åœ¨è¿™é‡Œã€‚æ‰€ä»¥å¦‚æœä½ å°è¯•è¿è¡Œä¸‹ä¸€ä¸ªæ­¥éª¤ï¼Œæ‰“å°å‡ºå¥å­ï¼Œä½ å¯èƒ½ä¼šæƒ³ï¼Œä¸ºä»€ä¹ˆæˆ‘çš„æ‰“å°è¿™ä¹ˆæ…¢ã€‚å—¯ï¼Œæ˜¯å› ä¸ºä¸Šé¢è¿™ä¸ªå®¶ä¼™ä»åœ¨è¿è¡Œï¼Œå› ä¸ºå®ƒéœ€è¦å¯åŠ¨ä¸€ä¸ªç½‘ç»œæœåŠ¡å™¨æ¥å®é™…æ˜¾ç¤ºç»™ä½ ï¼Œä½ å¯ä»¥ä»ä¸­çœ‹å‡ºã€‚æ‰€ä»¥æœ€å¥½å°†å…¶æ–­å¼€ï¼Œç°åœ¨ä½ å¯ä»¥è¿è¡Œå…¶ä»–çš„ã€‚è¿™å°±æ˜¯æˆ‘ä¹‹å‰å‘Šè¯‰ä½ çš„ï¼Œä½ å¯ä»¥å°†è¯è¯­è¿˜åŸåˆ°å®ƒä»¬çš„æ ¹å±‚æ¬¡ã€‚
- en: this is very usefulã€‚ I will use this often because then you don't have to worry
    about like hanging hanging All those would go to hang and this is just a list
    you can iterate over that and handle those as you want stop words This is a very
    common term in natural language processing you can see all the stop words hereã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸æœ‰ç”¨ã€‚æˆ‘ä¼šç»å¸¸ä½¿ç”¨è¿™ä¸ªï¼Œå› ä¸ºè¿™æ ·ä½ å°±ä¸å¿…æ‹…å¿ƒåƒâ€œhangingâ€è¿™æ ·çš„é—®é¢˜ã€‚æ‰€æœ‰è¿™äº›éƒ½ä¼šå˜æˆâ€œhangâ€ï¼Œè€Œè¿™åªæ˜¯ä¸€ä¸ªä½ å¯ä»¥éå†çš„åˆ—è¡¨ï¼Œå¯ä»¥æ ¹æ®éœ€è¦å¤„ç†é‚£äº›åœç”¨è¯ã€‚åœç”¨è¯æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€ä¸ªéå¸¸å¸¸è§çš„æœ¯è¯­ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°æ‰€æœ‰çš„åœç”¨è¯ã€‚
- en: these are words that are very common in English but have usually and I emphasize
    usually very little value So the stop words are often removed or deemphasize and
    this is just a list of the stop words So very common thing that you would do as
    you would loop overã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯è‹±è¯­ä¸­éå¸¸å¸¸è§çš„è¯ï¼Œä½†é€šå¸¸ï¼ˆæˆ‘å¼ºè°ƒé€šå¸¸ï¼‰ä»·å€¼å¾ˆä½ã€‚æ‰€ä»¥åœç”¨è¯é€šå¸¸è¢«ç§»é™¤æˆ–é™é‡ï¼Œè¿™åªæ˜¯åœç”¨è¯çš„ä¸€ä¸ªåˆ—è¡¨ã€‚å› æ­¤ï¼Œä½ é€šå¸¸ä¼šåšçš„äº‹æƒ…æ˜¯éå†è¿™äº›ã€‚
- en: Sentence like this and remove the stop wordsã€‚ You're using relatively simple
    word counts and statistical analysis for your natural language processing probably
    need to remove the stop wordsã€‚ An exampleï¼Œ though I ran into this when I was competing
    in a natural language processing on Cale I was printing out the sentences that
    my program was not parsing correctly And one sentence in particular it was kind
    of interestingã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åƒè¿™æ ·çš„å¥å­å¹¶ç§»é™¤åœç”¨è¯ã€‚ä½ åœ¨è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†æ—¶ä½¿ç”¨ç›¸å¯¹ç®€å•çš„è¯é¢‘ç»Ÿè®¡å’Œç»Ÿè®¡åˆ†æï¼Œå¯èƒ½éœ€è¦ç§»é™¤åœç”¨è¯ã€‚ä¸è¿‡ï¼Œæˆ‘åœ¨å‚åŠ Caleçš„è‡ªç„¶è¯­è¨€å¤„ç†ç«èµ›æ—¶é‡åˆ°è¿‡ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘æ‰“å°å‡ºäº†æˆ‘çš„ç¨‹åºæ²¡æœ‰æ­£ç¡®è§£æçš„å¥å­ã€‚å…¶ä¸­æœ‰ä¸€ä¸ªå¥å­ç‰¹åˆ«æœ‰è¶£ã€‚
- en: It was what is I Wellï¼Œ what is Iï¼Œ It's the part of the company that handles
    the computer and data systems for the corporationã€‚ Wellï¼Œ the first thing that
    my program was doing putting everything to lowercaseã€‚ What is it Okayã€‚ that's
    a whole different question That is like I don't know if you brought something
    to show me at class a new electronic device and laid it on my desk I'd be like
    what is it So just dripping everything to lowercase can get you in trouble And
    then when I converted that sentence toã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿå—¯ï¼Œæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿè¿™æ˜¯å…¬å¸ä¸­è´Ÿè´£è®¡ç®—æœºå’Œæ•°æ®ç³»ç»Ÿçš„éƒ¨åˆ†ã€‚å—¯ï¼Œæˆ‘ç¨‹åºåšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å°†æ‰€æœ‰å†…å®¹è½¬æ¢ä¸ºå°å†™ã€‚é‚£æ˜¯ä»€ä¹ˆï¼Ÿå¥½å§ï¼Œé‚£æ˜¯ä¸€ä¸ªå®Œå…¨ä¸åŒçš„é—®é¢˜ã€‚å°±åƒæˆ‘ä¸çŸ¥é“ä½ åœ¨è¯¾å ‚ä¸Šå¸¦æ¥äº†ä»€ä¹ˆæ–°çš„ç”µå­è®¾å¤‡æ”¾åœ¨æˆ‘æ¡Œå­ä¸Šï¼Œæˆ‘ä¼šé—®é‚£æ˜¯ä»€ä¹ˆã€‚æ‰€ä»¥ä»…ä»…æŠŠæ‰€æœ‰å†…å®¹è½¬æ¢ä¸ºå°å†™å¯èƒ½ä¼šè®©ä½ é™·å…¥éº»çƒ¦ã€‚ç„¶åå½“æˆ‘å°†é‚£ä¸ªå¥å­è½¬æ¢æ—¶ã€‚
- en: Remove the stop wordssï¼Œ it became thisã€‚A blank line because all three of those
    words were removed because they're all stop wordsã€‚ So this is a legitimate question
    that's asking somethingã€‚ what is what is itã€‚ but you have to realize these common
    acronyms and not just strip it or you're going to lose every time you make a transformation
    and remove junk or clean up every time you clean something you're losing information
    and maybe that information is not valuableã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç§»é™¤åœç”¨è¯åï¼Œå®ƒå˜æˆäº†è¿™æ ·ã€‚ç”±äºè¿™ä¸‰ä¸ªè¯éƒ½æ˜¯åœç”¨è¯ï¼Œå› æ­¤äº§ç”Ÿäº†ä¸€ä¸ªç©ºè¡Œã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªåˆæ³•çš„é—®é¢˜ï¼Œè¯¢é—®çš„æ˜¯æŸä»¶äº‹æƒ…ã€‚é‚£æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿä½†ä½ å¿…é¡»æ„è¯†åˆ°è¿™äº›å¸¸è§çš„ç¼©ç•¥è¯­ï¼Œè€Œä¸ä»…ä»…æ˜¯å»é™¤å®ƒä»¬ï¼Œå¦åˆ™æ¯æ¬¡è¿›è¡Œè½¬æ¢å’Œæ¸…ç†æ—¶éƒ½ä¼šä¸¢å¤±ä¿¡æ¯ï¼Œä¹Ÿè®¸é‚£äº›ä¿¡æ¯å¹¶ä¸é‡è¦ã€‚
- en: but you have to you have to be aware of these things in natural language processã€‚![](img/ff26651c6e28d6ee53469ef48ed52d86_3.png)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ å¿…é¡»å¯¹è¿™äº›è‡ªç„¶è¯­è¨€å¤„ç†çš„äº‹é¡¹ä¿æŒè­¦è§‰ã€‚![](img/ff26651c6e28d6ee53469ef48ed52d86_3.png)
- en: Thank you for watching this videoã€‚ In the next videoã€‚ we're going to talk about
    more natural language processing toolsï¼Œ particularly word to Vecã€‚ This content
    changes oftenã€‚ so subscribe to the channel to stay up to date on this course and
    other topics in artificial intelligenceã€‚ğŸ˜Šã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢ä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘ã€‚åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ›´å¤šè‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·ï¼Œç‰¹åˆ«æ˜¯Word2Vecã€‚è¿™ä¸ªå†…å®¹ç»å¸¸å˜åŒ–ï¼Œå› æ­¤è¯·è®¢é˜…é¢‘é“ä»¥ä¿æŒæ›´æ–°ï¼Œäº†è§£æœ¬è¯¾ç¨‹å’Œå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜ã€‚ğŸ˜Š
