- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Pandas è¿›è¡Œæ•°æ®å¤„ç†ä¸åˆ†æï¼çœŸå®æ•°æ®&å®æ—¶è®²è§£ï¼Œå­¦å®Œå°±èƒ½ä¸Šæ‰‹åšæ•°æ®åˆ†æäº†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P9ï¼š9ï¼‰æ•°æ®æ¸…æ´— -
    è½¬æ¢æ•°æ®ç±»å‹å’Œå¤„ç†ç¼ºå¤±å€¼ - ShowMeAI - BV1M64y187bz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Pandas è¿›è¡Œæ•°æ®å¤„ç†ä¸åˆ†æï¼çœŸå®æ•°æ®&å®æ—¶è®²è§£ï¼Œå­¦å®Œå°±èƒ½ä¸Šæ‰‹åšæ•°æ®åˆ†æäº†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P9ï¼š9ï¼‰æ•°æ®æ¸…æ´— -
    è½¬æ¢æ•°æ®ç±»å‹å’Œå¤„ç†ç¼ºå¤±å€¼ - ShowMeAI - BV1M64y187bz
- en: Hey thereã€‚ How's it goingï¼Œ everybodyã€‚ In this videoã€‚ we're gonna be learning
    how to handle missing values and also how to clean up our data a bitã€‚ Nowã€‚ almost
    every data set that you're gonna to be working with is likely going to have some
    missing data or data that we'd like to clean up or convert to a different data
    typeã€‚ So we'll learn how to do all of that hereã€‚ Nowï¼Œ towards the end of the videoã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œä½ ä»¬è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿåœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Œä»¥åŠå¦‚ä½•ç¨å¾®æ¸…ç†ä¸€ä¸‹æˆ‘ä»¬çš„æ•°æ®ã€‚å‡ ä¹æ¯ä¸€ä¸ªä½ è¦å¤„ç†çš„æ•°æ®é›†éƒ½æœ‰å¯èƒ½åŒ…å«ä¸€äº›ç¼ºå¤±æ•°æ®ï¼Œæˆ–è€…æ˜¯æˆ‘ä»¬å¸Œæœ›æ¸…ç†æˆ–è½¬æ¢ä¸ºä¸åŒæ•°æ®ç±»å‹çš„æ•°æ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œå­¦ä¹ å¦‚ä½•åšåˆ°è¿™ä¸€åˆ‡ã€‚ç°åœ¨ï¼Œè§†é¢‘æ¥è¿‘å°¾å£°æ—¶ã€‚
- en: We'll combine what we learned here to be able to look at our stack overflow
    survey dataã€‚ And calculate the average years of experiences of developers who
    answered the surveyã€‚ So be sure to stay around for thatã€‚ And it's going to be
    great practice for what we learned hereã€‚ Nowï¼Œ I would like to mention that we
    do have a sponsor for this series of videosã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»“åˆåœ¨è¿™é‡Œå­¦åˆ°çš„å†…å®¹ï¼Œèƒ½å¤ŸæŸ¥çœ‹æˆ‘ä»¬çš„ Stack Overflow è°ƒæŸ¥æ•°æ®ï¼Œå¹¶è®¡ç®—å›ç­”è°ƒæŸ¥çš„å¼€å‘è€…çš„å¹³å‡å·¥ä½œå¹´é™ã€‚æ‰€ä»¥ä¸€å®šè¦ä¿æŒå…³æ³¨ï¼Œè¿™å°†æ˜¯å¯¹æˆ‘ä»¬åœ¨è¿™é‡Œæ‰€å­¦å†…å®¹çš„æä½³å®è·µã€‚ç°åœ¨ï¼Œæˆ‘æƒ³æåˆ°çš„æ˜¯ï¼Œæˆ‘ä»¬ç¡®å®æœ‰è¿™ç³»åˆ—è§†é¢‘çš„èµåŠ©å•†ã€‚
- en: And that is brilliantã€‚ So I really want to thank brilliant for sponsoring the
    seriesã€‚ and it'll be great if you all can check them out using the link in the
    description section below and support the sponsorsã€‚ And I'll talk more about their
    services in just a bitã€‚ So with that saidã€‚ let's go ahead and get startedã€‚ Okayï¼Œ
    so firstï¼Œ let's talk about how to drop missing valuesã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœŸæ˜¯å¤ªæ£’äº†ã€‚å› æ­¤ï¼Œæˆ‘éå¸¸æ„Ÿè°¢ Brilliant èµåŠ©äº†è¿™ä¸ªç³»åˆ—ã€‚å¦‚æœä½ ä»¬èƒ½é€šè¿‡ä¸‹é¢æè¿°éƒ¨åˆ†çš„é“¾æ¥å»äº†è§£ä»–ä»¬ï¼Œé‚£å°†æ˜¯æå¥½çš„ï¼Œå¹¶æ”¯æŒæˆ‘ä»¬çš„èµåŠ©å•†ã€‚æˆ‘ä¼šåœ¨ç¨åè¯¦ç»†è°ˆè°ˆä»–ä»¬çš„æœåŠ¡ã€‚é‚£ä¹ˆï¼Œå°±è®©æˆ‘ä»¬å¼€å§‹å§ã€‚å¥½çš„ï¼Œé¦–å…ˆï¼Œè®©æˆ‘ä»¬è°ˆè°ˆå¦‚ä½•åˆ é™¤ç¼ºå¤±å€¼ã€‚
- en: So I have my snippets file open hereã€‚ And we've seen this in previous videosã€‚
    And againã€‚ if anyone wants to follow alongã€‚ğŸ˜Šï¼ŒThen I'll have a link to all of these
    notebooks and the data in the description section belowã€‚ And as we've seen in
    previous videosï¼Œ we'll learn how to do some of this in our smaller snippets data
    frame first And then we'll see how to do some interesting stuff on our larger
    stack overflow data set to get this working on some real worldorld dataã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿™é‡Œæ‰“å¼€äº†æˆ‘çš„ä»£ç ç‰‡æ®µæ–‡ä»¶ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­çœ‹åˆ°è¿‡è¿™ä¸ªã€‚å¦‚æœæœ‰äººæƒ³è·Ÿç€ä¸€èµ·åšã€‚ğŸ˜Šï¼Œæˆ‘ä¼šåœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†æä¾›æ‰€æœ‰è¿™äº›ç¬”è®°æœ¬å’Œæ•°æ®çš„é“¾æ¥ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å°†é¦–å…ˆåœ¨è¾ƒå°çš„ä»£ç ç‰‡æ®µæ•°æ®æ¡†ä¸­å­¦ä¹ å¦‚ä½•åšå…¶ä¸­çš„ä¸€äº›æ“ä½œï¼Œç„¶åå†çœ‹çœ‹å¦‚ä½•åœ¨æ›´å¤§çš„
    Stack Overflow æ•°æ®é›†ä¸Šåšä¸€äº›æœ‰è¶£çš„äº‹æƒ…ï¼Œä»¥ä¾¿åœ¨ä¸€äº›çœŸå®ä¸–ç•Œçš„æ•°æ®ä¸Šè¿›è¡Œå·¥ä½œã€‚
- en: So for this video I've added some null values here into our snippets data frame
    that we didn't have beforeã€‚ So I added some extra first names hereã€‚ And we can
    see that I just have one that is a nu do Nã€‚ which is a not a number valueã€‚ I also
    imported nu up here at the topã€‚ this one here is just a nuvalueã€‚ And then I also
    have some custom missing values as wellã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘åœ¨æˆ‘ä»¬çš„ä»£ç ç‰‡æ®µæ•°æ®æ¡†ä¸­æ·»åŠ äº†ä¸€äº›ä¹‹å‰æ²¡æœ‰çš„ç©ºå€¼ã€‚æˆ‘æ·»åŠ äº†ä¸€äº›é¢å¤–çš„åå­—ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘è¿™é‡Œåªæœ‰ä¸€ä¸ªæ˜¯ nu do Nï¼Œä¹Ÿå°±æ˜¯ä¸æ˜¯æ•°å­—çš„å€¼ã€‚æˆ‘åœ¨é¡¶éƒ¨ä¹Ÿå¯¼å…¥äº†
    nuï¼Œè¿™é‡Œåªæ˜¯ä¸€ä¸ª nu å€¼ã€‚æˆ‘è¿˜æ·»åŠ äº†ä¸€äº›è‡ªå®šä¹‰ç¼ºå¤±å€¼ã€‚
- en: This one is just a string of NA and this one is just a string of missingã€‚ So
    I have some Ns some nuns and stuff like that thrown throughout this data so that
    we have some missing valuesã€‚ So you're gonna to see this a lot that when we work
    with pandasã€‚ğŸ˜Šã€‚We're going to have some missing data And depending on what it is
    you're trying to doã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåªæ˜¯ä¸€ä¸ª NA å­—ç¬¦ä¸²ï¼Œè€Œè¿™ä¸ªåªæ˜¯ä¸€ä¸ªç¼ºå¤±çš„å­—ç¬¦ä¸²ã€‚å› æ­¤ï¼Œæˆ‘åœ¨æ•°æ®ä¸­éšæ„æ”¾äº†ä¸€äº› Nã€ä¸€äº› nuns ç­‰ç­‰ï¼Œä»¥ä¾¿æˆ‘ä»¬æœ‰ä¸€äº›ç¼ºå¤±å€¼ã€‚æ‰€ä»¥ä½ ä¼šçœ‹åˆ°ï¼Œå½“æˆ‘ä»¬ä½¿ç”¨
    pandas æ—¶ï¼Œè¿™ç§æƒ…å†µä¼šç»å¸¸å‡ºç°ã€‚ğŸ˜Šæˆ‘ä»¬ä¼šæœ‰ä¸€äº›ç¼ºå¤±æ•°æ®ï¼Œå…·ä½“å–å†³äºä½ æƒ³åšä»€ä¹ˆã€‚
- en: you might want to handle this in different waysã€‚ So one thing you might want
    to do with missing data is to simply remove itã€‚ So for our small data frame hereã€‚
    let's say that we're going to do some analysis with these people in the data frameã€‚
    but if they don't have their first name last name and email address then we can't
    do what we're trying to do So we'll just remove the rows that don't have those
    valuesã€‚ So in order to do thisï¼Œ we can use the drop in a methodã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æƒ³ç”¨ä¸åŒçš„æ–¹æ³•å¤„ç†ç¼ºå¤±æ•°æ®ã€‚æ‰€ä»¥ï¼Œä½ å¯èƒ½æƒ³åšçš„ä¸€ä»¶äº‹å°±æ˜¯ç®€å•åœ°åˆ é™¤å®ƒã€‚å¯¹äºæˆ‘ä»¬è¿™é‡Œçš„å°æ•°æ®æ¡†æ¥è¯´ï¼Œå‡è®¾æˆ‘ä»¬è¦å¯¹æ•°æ®æ¡†ä¸­çš„è¿™äº›äººè¿›è¡Œä¸€äº›åˆ†æï¼Œä½†å¦‚æœä»–ä»¬æ²¡æœ‰åå­—ã€å§“æ°å’Œç”µå­é‚®ä»¶åœ°å€ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±æ— æ³•è¿›è¡Œæ‰€éœ€çš„æ“ä½œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åˆ é™¤é‚£äº›ç¼ºå°‘è¿™äº›å€¼çš„è¡Œã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`drop`æ–¹æ³•ã€‚
- en: So let's do this and then I'll explain the results and go over those So all
    I'm going to do down here with my data frame is I'm gonna to say Df drop in a
    and we're gonna to run that without any arguments right now So when we run this
    we can see that now we only get four rows of data here And up here we had let's
    see45ã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬è¿™æ ·åšï¼Œç„¶åæˆ‘ä¼šè§£é‡Šç»“æœå¹¶è®¨è®ºè¿™äº›ã€‚å› æ­¤ï¼Œæˆ‘åœ¨è¿™é‡Œå¯¹æˆ‘çš„æ•°æ®æ¡†æ‰€åšçš„åªæ˜¯è¯´Df drop in aï¼Œæˆ‘ä»¬ç°åœ¨å°†ä¸å¸¦ä»»ä½•å‚æ•°è¿è¡Œå®ƒã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬è¿è¡Œæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°åœ¨æˆ‘ä»¬åªå¾—åˆ°å››è¡Œæ•°æ®ï¼Œè€Œåœ¨ä¸Šé¢æˆ‘ä»¬æœ‰45è¡Œã€‚
- en: 67ã€‚ So we got these four rows here because they didn't have any missing valuesã€‚
    Now we do still have our bottom row hereã€‚Which has some of our custom missing
    valuesã€‚ But we'll see how to deal with these in just a secondã€‚ But for nowã€‚ let's
    go over what drop in a is actually doing hereã€‚ Nowã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¾—åˆ°äº†è¿™å››è¡Œï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰ç¼ºå¤±å€¼ã€‚ç°åœ¨æˆ‘ä»¬åº•éƒ¨çš„è¿™ä¸€è¡Œä»ç„¶å­˜åœ¨ï¼Œè¿™é‡Œæœ‰ä¸€äº›è‡ªå®šä¹‰ç¼ºå¤±å€¼ã€‚ä½†æˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•å¤„ç†è¿™äº›ã€‚ä¸è¿‡ç°åœ¨ï¼Œè®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹drop
    in aå®é™…ä¸Šåœ¨è¿™é‡Œåšäº†ä»€ä¹ˆã€‚
- en: what's going on in the background is that drop in a is using some default argumentsã€‚
    So I'm going to manually fill in these default argumentsã€‚ And it might make more
    sense why we got this specific resultsã€‚ So by defaultã€‚ I'll leave that one hereã€‚
    And now I'm going to fill in drop in a againã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„èƒŒæ™¯æ˜¯drop in aæ­£åœ¨ä½¿ç”¨ä¸€äº›é»˜è®¤å‚æ•°ã€‚æ‰€ä»¥æˆ‘å°†æ‰‹åŠ¨å¡«å†™è¿™äº›é»˜è®¤å‚æ•°ã€‚è¿™æ ·å¯èƒ½ä¼šæ›´æ¸…æ¥šæˆ‘ä»¬ä¸ºä»€ä¹ˆå¾—åˆ°è¿™ä¸ªå…·ä½“çš„ç»“æœã€‚å› æ­¤é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘å°†ç•™é‚£ä¸ªå‚æ•°åœ¨è¿™é‡Œã€‚ç°åœ¨æˆ‘å†æ¬¡å¡«å†™drop
    in aã€‚
- en: but I'm going to put the default arguments that it already hasã€‚ and the default
    arguments of what this is doing in the background is it has an axis set to indexã€‚
    and it has a how variable set to anyã€‚ So since this is what the method was using
    by default anywayã€‚ we should go ahead and get the same results here and we can
    see that we doã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘å°†æ”¾å…¥å®ƒå·²ç»æ‹¥æœ‰çš„é»˜è®¤å‚æ•°ã€‚è¿™ä¸ªåœ¨åå°çš„é»˜è®¤å‚æ•°æ˜¯å®ƒå°†è½´è®¾ç½®ä¸ºç´¢å¼•ï¼Œå¹¶å°†howå˜é‡è®¾ç½®ä¸ºä»»ä½•ã€‚æ‰€ä»¥ç”±äºè¿™æ­£æ˜¯è¯¥æ–¹æ³•é»˜è®¤ä½¿ç”¨çš„ï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ç›¸åŒçš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç¡®å®å¦‚æ­¤ã€‚
- en: we get the same results as we did when we ran this up hereã€‚ But now let me actually
    explain these arguments hereã€‚ So firstï¼Œ we have the axis argumentsã€‚ So this can
    either be set to indexã€‚Were set to columnsã€‚ That is going to tell pandas that
    we want to drop in values when our rows are missing values when it's set here
    to indexã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°çš„ç»“æœä¸æˆ‘ä»¬åœ¨ä¸Šé¢è¿è¡Œæ—¶æ˜¯ä¸€æ ·çš„ã€‚ä½†ç°åœ¨è®©æˆ‘è§£é‡Šä¸€ä¸‹è¿™äº›å‚æ•°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æœ‰è½´å‚æ•°ã€‚è¿™ä¸ªå¯ä»¥è®¾ç½®ä¸ºç´¢å¼•æˆ–åˆ—ã€‚è¿™å°†å‘Šè¯‰pandasæˆ‘ä»¬å¸Œæœ›åœ¨è¡Œç¼ºå¤±å€¼æ—¶ä¸¢å¼ƒå€¼ï¼Œå½“è¿™é‡Œè®¾ç½®ä¸ºç´¢å¼•æ—¶ã€‚
- en: If we set this to columnsï¼Œ then it would instead drop columns if they had missing
    valuesã€‚ And we'll look at that in just a secondã€‚ Nowï¼Œ the second argument here
    is how we want to drop theseã€‚ or I guess a better way to frame that is this is
    the criteria that it uses for dropping a row or a columnã€‚ So by defaultï¼Œ this
    is set to anyã€‚ So we're looking over our rows since this is set to indexã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†æ­¤è®¾ç½®ä¸ºåˆ—ï¼Œé‚£ä¹ˆå¦‚æœåˆ—ä¸­æœ‰ç¼ºå¤±å€¼ï¼Œå®ƒå°†ä¼šä¸¢å¼ƒåˆ—ã€‚æˆ‘ä»¬é©¬ä¸Šä¼šè®¨è®ºè¿™ä¸ªã€‚ç°åœ¨ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯æˆ‘ä»¬æƒ³å¦‚ä½•ä¸¢å¼ƒè¿™äº›ã€‚æˆ–è€…æˆ‘æƒ³è¯´ä¸€ä¸ªæ›´å¥½çš„æ–¹å¼æ˜¯ï¼Œè¿™æ˜¯å®ƒç”¨æ¥ä¸¢å¼ƒè¡Œæˆ–åˆ—çš„æ ‡å‡†ã€‚å› æ­¤é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™è¢«è®¾ç½®ä¸ºä»»ä½•ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨æŸ¥çœ‹è¡Œï¼Œå› ä¸ºè¿™è¢«è®¾ç½®ä¸ºç´¢å¼•ã€‚
- en: And this is set to any hereã€‚ So it will drop rows with any missing valuesã€‚ But
    this might not be what you wantã€‚ Maybe with this kind of an analysis that we're
    doingã€‚ It's okay to have you know missing email or last name or something like
    thatã€‚ But there just has to be somethingã€‚ It can't just be an entire row of missing
    valuesã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œä¹Ÿè¢«è®¾ç½®ä¸ºä»»ä½•ã€‚å› æ­¤å®ƒå°†ä¸¢å¼ƒä»»ä½•æœ‰ç¼ºå¤±å€¼çš„è¡Œã€‚ä½†è¿™å¯èƒ½ä¸æ˜¯ä½ æƒ³è¦çš„ã€‚ä¹Ÿè®¸åœ¨æˆ‘ä»¬è¿›è¡Œçš„è¿™ç§åˆ†æä¸­ï¼Œæœ‰ç¼ºå¤±çš„ç”µå­é‚®ä»¶æˆ–å§“æ°æ˜¯å¯ä»¥çš„ã€‚ä½†å¿…é¡»æœ‰æŸäº›å†…å®¹ã€‚ä¸èƒ½æ•´è¡Œéƒ½æ˜¯ç¼ºå¤±å€¼ã€‚
- en: So if that's the caseï¼Œ then we can instead change thisï¼Œ how argument toã€‚Allã€‚And
    this will then only drop rows when all of the values in that row are missingã€‚
    So now if I run thisï¼Œ then we can see that now we get back more rows than we did
    beforeã€‚ because it kept the rows that had some missing valuesã€‚ but not all missing
    valuesã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªhowå‚æ•°æ”¹ä¸ºAllã€‚è¿™æ ·åªæœ‰å½“è¯¥è¡Œä¸­çš„æ‰€æœ‰å€¼éƒ½ç¼ºå¤±æ—¶ï¼Œæ‰ä¼šä¸¢å¼ƒè¡Œã€‚å› æ­¤ç°åœ¨å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¾—åˆ°äº†æ¯”ä¹‹å‰æ›´å¤šçš„è¡Œï¼Œå› ä¸ºå®ƒä¿ç•™äº†é‚£äº›æœ‰ä¸€äº›ç¼ºå¤±å€¼ï¼Œä½†ä¸æ˜¯å…¨éƒ¨ç¼ºå¤±å€¼çš„è¡Œã€‚
- en: So we can see here we have an email missingï¼Œ but there were some other columns
    filled inã€‚ and we can see that everything was missing hereï¼Œ but they did have
    an emailã€‚ So all of the values have to be missing in order for this to actually
    drop thoseã€‚ So it looks like we are missing index of fourã€‚ if I go up to a my
    original data frame hereã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œç¼ºå¤±äº†ç”µå­é‚®ä»¶ï¼Œä½†è¿˜æœ‰å…¶ä»–ä¸€äº›åˆ—æ˜¯å¡«å¥½çš„ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œæ‰€æœ‰å†…å®¹éƒ½ç¼ºå¤±ï¼Œä½†ä»–ä»¬æœ‰ç”µå­é‚®ä»¶ã€‚å› æ­¤ï¼Œæ‰€æœ‰çš„å€¼å¿…é¡»ç¼ºå¤±ï¼Œæ‰èƒ½çœŸæ­£ä¸¢å¼ƒå®ƒä»¬ã€‚å› æ­¤çœ‹èµ·æ¥æˆ‘ä»¬ç¼ºå¤±ç´¢å¼•4ã€‚å¦‚æœæˆ‘å›åˆ°æˆ‘çš„åŸå§‹æ•°æ®æ¡†è¿™é‡Œã€‚
- en: we can see that that index had all missing values thereã€‚ Okayã€‚ now if I instead
    change this axis to columns instead of indexã€‚ then it will drop columns that have
    all missing valuesã€‚ we don't have any columns that have missing values all the
    way downã€‚ So it should just return our original data frameã€‚ So if I say columns
    here and run thisã€‚ Then we can seeã€‚That's what we get because none of these columns
    have missing values all the way down Nowã€‚ if I set this back to the default and
    drop columns with any missing valuesã€‚ then we'll actually get an empty data frame
    returned because we have one row that is completely empty that we saw here this
    index of four So for that row each column is going to have at least one missing
    value and if we set this to any then any column which is even a single missing
    value will be dropped which in this case is all of them So if I change this to
    any then since we have all missing values in one of these rows that's just going
    to give us an empty data frame now at this point you might be wondering okay well
    my data is a bit more complicated than this and I'm doing some of analysis where
    I want to drop some missing values but I only want to drop rows that are missing
    values in a specific column so for exampleã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç´¢å¼•ä¸­æœ‰æ‰€æœ‰ç¼ºå¤±å€¼ã€‚å¥½çš„ã€‚å¦‚æœæˆ‘å°†è¿™ä¸ªè½´æ”¹ä¸ºåˆ—è€Œä¸æ˜¯ç´¢å¼•ï¼Œé‚£ä¹ˆå®ƒå°†åˆ é™¤æ‰€æœ‰ç¼ºå¤±å€¼çš„åˆ—ã€‚æˆ‘ä»¬æ²¡æœ‰ä»»ä½•åˆ—æ˜¯å®Œå…¨ç¼ºå¤±å€¼çš„ã€‚å› æ­¤ï¼Œå®ƒåº”è¯¥åªè¿”å›æˆ‘ä»¬çš„åŸå§‹æ•°æ®æ¡†ã€‚å¦‚æœæˆ‘åœ¨è¿™é‡Œè¯´åˆ—å¹¶è¿è¡Œè¿™ä¸ªã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å¾—åˆ°çš„ï¼Œå› ä¸ºè¿™äº›åˆ—æ²¡æœ‰å®Œå…¨ç¼ºå¤±å€¼ã€‚ç°åœ¨ã€‚å¦‚æœæˆ‘å°†å…¶è®¾ç½®å›é»˜è®¤å€¼å¹¶åˆ é™¤ä»»ä½•ç¼ºå¤±å€¼çš„åˆ—ã€‚é‚£ä¹ˆæˆ‘ä»¬å®é™…ä¸Šä¼šå¾—åˆ°ä¸€ä¸ªç©ºçš„æ•°æ®æ¡†ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ä¸€è¡Œæ˜¯å®Œå…¨ç©ºçš„ï¼Œè¿™ä¸ªç´¢å¼•ä¸ºå››ã€‚å› æ­¤å¯¹äºé‚£ä¸€è¡Œï¼Œæ¯ä¸€åˆ—è‡³å°‘ä¼šæœ‰ä¸€ä¸ªç¼ºå¤±å€¼ã€‚å¦‚æœæˆ‘ä»¬å°†æ­¤è®¾ç½®ä¸ºä»»ä½•ï¼Œåˆ™ä»»ä½•å…·æœ‰å•ä¸ªç¼ºå¤±å€¼çš„åˆ—éƒ½ä¼šè¢«åˆ é™¤ï¼Œè€Œåœ¨è¿™ç§æƒ…å†µä¸‹æ‰€æœ‰åˆ—éƒ½æ˜¯è¿™æ ·çš„ã€‚å¦‚æœæˆ‘å°†æ­¤æ”¹ä¸ºä»»ä½•ï¼Œé‚£ä¹ˆç”±äºå…¶ä¸­ä¸€è¡Œçš„æ‰€æœ‰å€¼éƒ½æ˜¯ç¼ºå¤±çš„ï¼Œè¿™å°†ç»™æˆ‘ä»¬ä¸€ä¸ªç©ºçš„æ•°æ®æ¡†ã€‚æ­¤æ—¶ä½ å¯èƒ½ä¼šæƒ³ï¼Œå¥½çš„ï¼Œæˆ‘çš„æ•°æ®æ¯”è¿™å¤æ‚ä¸€äº›ï¼Œæˆ‘æ­£åœ¨è¿›è¡Œä¸€äº›åˆ†æï¼Œæˆ‘æƒ³åˆ é™¤ä¸€äº›ç¼ºå¤±å€¼ï¼Œä½†æˆ‘åªæƒ³åˆ é™¤åœ¨ç‰¹å®šåˆ—ä¸­ç¼ºå¤±å€¼çš„è¡Œï¼Œæ‰€ä»¥ä¾‹å¦‚ã€‚
- en: Let's say that we're doing some analysis on our data and it's fine if they don't
    have a first name or a last nameã€‚ but we really need the email address and if
    they don't have an email addressã€‚ then we need to just drop those rowsã€‚ So in
    order to do this we can pass in a subset argumentã€‚ So first I'm going to set our
    our access here back to index so that we're dropping rows and now we want to pass
    in a subset argument and this subset will be the column names that we're checking
    for missing valuesã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æ­£åœ¨å¯¹æ•°æ®è¿›è¡Œä¸€äº›åˆ†æï¼Œå¦‚æœä»–ä»¬æ²¡æœ‰åå­—æˆ–å§“æ°ä¹Ÿæ²¡å…³ç³»ï¼Œä½†æˆ‘ä»¬ç¡®å®éœ€è¦ç”µå­é‚®ä»¶åœ°å€ã€‚å¦‚æœä»–ä»¬æ²¡æœ‰ç”µå­é‚®ä»¶åœ°å€ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦åˆ é™¤è¿™äº›è¡Œã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€ä¸ªå­é›†å‚æ•°ã€‚æ‰€ä»¥é¦–å…ˆæˆ‘å°†æˆ‘ä»¬çš„è®¿é—®è®¾ç½®å›ç´¢å¼•ï¼Œä»¥ä¾¿åˆ é™¤è¡Œï¼Œç°åœ¨æˆ‘ä»¬æƒ³ä¼ å…¥ä¸€ä¸ªå­é›†å‚æ•°ï¼Œè¿™ä¸ªå­é›†å°†æ˜¯æˆ‘ä»¬æ£€æŸ¥ç¼ºå¤±å€¼çš„åˆ—åã€‚
- en: So in this case it's just going to be a single column So I'm going to say subset
    is equal to and I'm still going to pass in a list even though this is just a single
    column and I'll say email So if I run this then we can see that the data frame
    that we get back is full of rows that have at least their email address filled
    in and again this one down here with these in values that is our custom missing
    values and I'll show you how to treat thoseã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒåªä¼šæ˜¯ä¸€ä¸ªå•åˆ—ã€‚å› æ­¤ï¼Œæˆ‘å°†è¯´å­é›†ç­‰äºï¼Œæˆ‘ä»ç„¶ä¼šä¼ å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œå³ä½¿è¿™åªæ˜¯å•ä¸ªåˆ—ï¼Œæˆ‘ä¼šè¯´ç”µå­é‚®ä»¶ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿”å›çš„æ•°æ®æ¡†å……æ»¡äº†è‡³å°‘å¡«å…¥ç”µå­é‚®ä»¶åœ°å€çš„è¡Œã€‚è€Œä¸”å†æ¬¡æåˆ°ä¸‹é¢è¿™ä¸ªå¸¦æœ‰è¿™äº›ç©ºå€¼çš„è¡Œæ˜¯æˆ‘ä»¬è‡ªå®šä¹‰çš„ç¼ºå¤±å€¼ï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ å¦‚ä½•å¤„ç†è¿™äº›ã€‚
- en: Mising values in just a bitã€‚ Nowï¼Œ in this case hereã€‚ since we're only passing
    in a single column for our subsetã€‚ our how argument here isn't really doing much
    because it's only going to look at the email address for missing valuesã€‚ So if
    an email address isn't filled in then passing in either any or all for our argument
    here would trigger that row to be removed So even if I put this as all it should
    give us the same results because we're only checking one valueã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼ç¨åå†è®¨è®ºã€‚ç°åœ¨ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºæˆ‘ä»¬åªä¼ å…¥ä¸€ä¸ªå•åˆ—ä½œä¸ºæˆ‘ä»¬çš„å­é›†ï¼Œæˆ‘ä»¬çš„å¦‚ä½•å‚æ•°å¹¶æ²¡æœ‰çœŸæ­£å‘æŒ¥ä½œç”¨ï¼Œå› ä¸ºå®ƒåªä¼šæŸ¥çœ‹ç”µå­é‚®ä»¶åœ°å€çš„ç¼ºå¤±å€¼ã€‚å› æ­¤ï¼Œå¦‚æœç”µå­é‚®ä»¶åœ°å€æ²¡æœ‰å¡«å†™ï¼Œåˆ™åœ¨æ­¤å¤„ä¼ å…¥ä»»ä½•æˆ–æ‰€æœ‰å‚æ•°éƒ½ä¼šè§¦å‘è¯¥è¡Œè¢«ç§»é™¤ã€‚æ‰€ä»¥å³ä½¿æˆ‘å°†å…¶è®¾ç½®ä¸ºæ‰€æœ‰ï¼Œå®ƒä¹Ÿåº”è¯¥ç»™æˆ‘ä»¬ç›¸åŒçš„ç»“æœï¼Œå› ä¸ºæˆ‘ä»¬åªåœ¨æ£€æŸ¥ä¸€ä¸ªå€¼ã€‚
- en: but we can also pass in multiple columns to our subsetã€‚ So what if we saidï¼Œ
    okayï¼Œ wellã€‚ in order for my data to be useful I need either their last name or
    their email addressã€‚ but I don't need bothã€‚ So in order to do this we could just
    say okay they need all of theã€‚Values in last name and an emailã€‚ or I'm sorry there
    that I got that reversedã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†å¤šä¸ªåˆ—ä¼ å…¥æˆ‘ä»¬çš„å­é›†ã€‚é‚£ä¹ˆå¦‚æœæˆ‘ä»¬è¯´ï¼Œå¥½å§ï¼Œä¸ºäº†ä½¿æˆ‘çš„æ•°æ®æœ‰ç”¨ï¼Œæˆ‘éœ€è¦ä»–ä»¬çš„å§“æ°æˆ–ç”µå­é‚®ä»¶åœ°å€ï¼Œä½†ä¸éœ€è¦ä¸¤ä¸ªéƒ½æä¾›ã€‚é‚£ä¹ˆä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ï¼Œä»–ä»¬éœ€è¦å§“æ°å’Œç”µå­é‚®ä»¶çš„æ‰€æœ‰å€¼ã€‚æŠ±æ­‰ï¼Œæˆ‘æŠŠè¿™ä¸ªè¯´åäº†ã€‚
- en: they don't need their last name in the emailã€‚ It just can't be that all of those
    values are missingã€‚ So as long as the last name or the email is thereã€‚ Then it
    shouldn't drop those rowsã€‚ So if I run thisã€‚ Then we can see that we get some
    values that don't have an emailã€‚ but they did have a last nameã€‚ And also we would
    get back some values that didn't have a last nameã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ä¸éœ€è¦å§“æ°å’Œç”µå­é‚®ä»¶ã€‚åªæ˜¯ä¸èƒ½æ‰€æœ‰è¿™äº›å€¼éƒ½ç¼ºå¤±ã€‚æ‰€ä»¥åªè¦å§“æ°æˆ–ç”µå­é‚®ä»¶å­˜åœ¨ï¼Œå°±ä¸åº”è¯¥åˆ é™¤é‚£äº›è¡Œã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›æ²¡æœ‰ç”µå­é‚®ä»¶çš„å€¼ï¼Œä½†å®ƒä»¬æœ‰å§“æ°ã€‚æˆ‘ä»¬è¿˜ä¼šå¾—åˆ°ä¸€äº›æ²¡æœ‰å§“æ°çš„å€¼ã€‚
- en: but do have an email just like this a nonin spun hereï¼Œ it has an emailã€‚ but
    it doesn't have a last nameã€‚ And againï¼Œ that's because we passed in all for our
    how argumentã€‚ which means for a row to be droppedï¼Œ both of the subset columns
    needed to be missingã€‚ Nowã€‚ like we've seen in previous videosï¼Œ This isn't permanently
    changing our data frame valuesã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç¡®å®æœ‰ä¸€ä¸ªç”µå­é‚®ä»¶ï¼Œå°±åƒè¿™é‡Œçš„ä¸€ä¸ªéå†…è”å…ƒç´ ï¼Œå®ƒæœ‰ä¸€ä¸ªç”µå­é‚®ä»¶ã€‚ä½†å®ƒæ²¡æœ‰å§“æ°ã€‚è€Œä¸”ï¼Œå†æ¬¡è¯´æ˜ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨æ‰€æœ‰å‚æ•°ä¸­ä¼ å…¥äº†`how`ã€‚è¿™æ„å‘³ç€è¦åˆ é™¤ä¸€è¡Œï¼Œä¸¤ä¸ªå­é›†åˆ—éƒ½éœ€è¦ç¼ºå¤±ã€‚ç°åœ¨ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­çœ‹åˆ°çš„ï¼Œè¿™å¹¶æ²¡æœ‰æ°¸ä¹…æ”¹å˜æˆ‘ä»¬çš„æ•°æ®æ¡†å€¼ã€‚
- en: If we want to permanently change our data frameï¼Œ then we'd have to add the inplace
    argument and set that equal to true here within this methodã€‚ But we've seen that
    a bunch throughout the series so farã€‚I don't think I'll go over that again hereã€‚
    Okayï¼Œ so now let's get to these custom missing valuesã€‚ We can see down here that
    we have a row here that has some customized missing valuesã€‚ Soã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³æ°¸ä¹…æ”¹å˜æˆ‘ä»¬çš„æ•°æ®æ¡†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¿…é¡»æ·»åŠ `inplace`å‚æ•°å¹¶åœ¨è¿™ä¸ªæ–¹æ³•ä¸­å°†å…¶è®¾ç½®ä¸º`true`ã€‚ä½†åœ¨è¿™ä¸€ç³»åˆ—ä¸­æˆ‘ä»¬å·²ç»çœ‹è¿‡å¾ˆå¤šæ¬¡ã€‚æˆ‘è§‰å¾—åœ¨è¿™é‡Œä¸éœ€è¦å†é‡å¤ã€‚å¥½çš„ï¼Œç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™äº›è‡ªå®šä¹‰ç¼ºå¤±å€¼ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸€è¡ŒåŒ…å«ä¸€äº›è‡ªå®šä¹‰çš„ç¼ºå¤±å€¼ã€‚
- en: for exampleï¼Œ maybe the people who got our data from I didn't know what to do
    with missing valuesã€‚ So insteadï¼Œ they just passed in a string of N or they passed
    in you know a string of missing like we have hereã€‚ So how would we actually handle
    theseã€‚ Wellï¼Œ it depends on how we load in our dataã€‚ In this caseã€‚ we've created
    our data frame from scratch by creating a dictionary and then creating our data
    frame hereã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¯èƒ½è·å–æˆ‘ä»¬æ•°æ®çš„äººä¸çŸ¥é“å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ã€‚æ‰€ä»¥ï¼Œä»–ä»¬åªæ˜¯ä¼ å…¥äº†ä¸€ä¸ªå­—ç¬¦ä¸²â€œNâ€æˆ–è€…ä¼ å…¥äº†ä¸€ä¸ªåƒæˆ‘ä»¬è¿™é‡Œçš„â€œç¼ºå¤±â€å­—ç¬¦ä¸²ã€‚é‚£ä¹ˆæˆ‘ä»¬è¯¥å¦‚ä½•å¤„ç†è¿™äº›å‘¢ï¼Ÿè¿™å–å†³äºæˆ‘ä»¬å¦‚ä½•åŠ è½½æ•°æ®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ˜¯é€šè¿‡åˆ›å»ºä¸€ä¸ªå­—å…¸å¹¶åœ¨è¿™é‡Œåˆ›å»ºæ•°æ®æ¡†æ¥ä»å¤´å¼€å§‹åˆ›å»ºæˆ‘ä»¬çš„æ•°æ®æ¡†ã€‚
- en: So what we can do here is just simply replace those values with an NN valueã€‚
    Nowã€‚ if we instead loaded in our data from a CV fileã€‚ then we could do something
    differentã€‚ But firstã€‚ I'll show this and then we'll take a look at the CV file
    later whenever I go over to the stack overflow dataã€‚ So right here at the top
    where we created our data frameã€‚ I'm going to replace these valuesã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œç®€å•åœ°å°†è¿™äº›å€¼æ›¿æ¢ä¸º`NaN`å€¼ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬ä»ä¸€ä¸ªCSVæ–‡ä»¶åŠ è½½æ•°æ®ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥åšä¸åŒçš„äº‹æƒ…ã€‚ä½†é¦–å…ˆï¼Œæˆ‘å°†å±•ç¤ºè¿™ä¸ªï¼Œç„¶ååœ¨æˆ‘æŸ¥çœ‹Stack
    Overflowæ•°æ®æ—¶å†çœ‹çœ‹CSVæ–‡ä»¶ã€‚æ‰€ä»¥åœ¨æˆ‘ä»¬åˆ›å»ºæ•°æ®æ¡†çš„é¡¶éƒ¨ï¼Œæˆ‘å°†æ›¿æ¢è¿™äº›å€¼ã€‚
- en: With a proper nuy NAN valueã€‚ So to do this'm just going to go a couple lines
    down here and we've seen this in previous videosã€‚ but we can use this replace
    here and I'm replacing all the values in the entire data frameã€‚ So anytime we
    see a string of NA I'm going to replace that with nuy NA and again I am importing
    nuy up here asmpã€‚ so that's where I'm getting I'm able to use nuy and then I want
    to say in place equal to true because we actually want to modify that data frame
    so if I run that then that would replace those values but I'm also going to place
    replace this string of missing as well withmp do NAN values and I want to do that
    in place as wellã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åˆé€‚çš„`NaN`å€¼ã€‚å› æ­¤ï¼Œä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘å°†å¾€ä¸‹èµ°å‡ è¡Œï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­çœ‹åˆ°è¿‡è¿™ä¸ªï¼Œä½†æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œä½¿ç”¨`replace`ï¼Œæˆ‘å°†æ›¿æ¢æ•´ä¸ªæ•°æ®æ¡†ä¸­çš„æ‰€æœ‰å€¼ã€‚æ‰€ä»¥æ¯å½“æˆ‘ä»¬çœ‹åˆ°ä¸€ä¸ªâ€œNAâ€å­—ç¬¦ä¸²æ—¶ï¼Œæˆ‘å°†å…¶æ›¿æ¢ä¸º`NaN`ï¼Œè€Œä¸”æˆ‘åœ¨è¿™é‡Œå¯¼å…¥äº†`numpy`ï¼Œæ‰€ä»¥æˆ‘èƒ½å¤Ÿä½¿ç”¨`numpy`ï¼Œç„¶åæˆ‘æƒ³è¯´`inplace`ç­‰äº`true`ï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šæƒ³è¦ä¿®æ”¹é‚£ä¸ªæ•°æ®æ¡†ï¼Œæ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œå®ƒï¼Œé‚£ä¹ˆè¿™å°†æ›¿æ¢é‚£äº›å€¼ï¼Œä½†æˆ‘è¿˜å°†æŠŠè¿™ä¸ªç¼ºå¤±å­—ç¬¦ä¸²ä¹Ÿæ›¿æ¢ä¸º`NaN`å€¼ï¼Œæˆ‘ä¹Ÿæƒ³è¿™æ ·åšã€‚
- en: So let's go ahead and run this that should replace those valuesã€‚ And now if
    I look at our data frame hereã€‚ then we can see that we no longer haveã€‚That string
    of missing or Nã€‚ these are now all N N valuesã€‚ And now if we go back through and
    we run ourselves where we dropped N valuesã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ç»§ç»­æ‰§è¡Œè¿™ä¸ªæ“ä½œï¼Œè¿™åº”è¯¥æ›¿æ¢é‚£äº›å€¼ã€‚ç°åœ¨å¦‚æœæˆ‘æŸ¥çœ‹æˆ‘ä»¬çš„æ•°æ®æ¡†ï¼Œå¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä¸å†æœ‰é‚£ä¸²ç¼ºå¤±æˆ– N çš„å€¼ã€‚è¿™äº›ç°åœ¨éƒ½æ˜¯ N N å€¼ã€‚å¦‚æœæˆ‘ä»¬å›è¿‡å¤´æ¥ï¼Œè¿è¡Œåˆ é™¤
    N å€¼çš„æ“ä½œã€‚
- en: then these custom values should have been replaced and it should treat those
    as missing valuesã€‚ So right here we can see what our previous result was where
    we got this index of 6 with those custom values if I rerun this nowã€‚ we can see
    that that's gone and the same with here if I rerun thisï¼Œ then that is gone as
    wellã€‚ Nowã€‚ if you don't actually want to make any changesï¼Œ and we just want to
    see if certain values would or wouldn't be treated as NA valuesã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè¿™äº›è‡ªå®šä¹‰å€¼åº”è¯¥è¢«æ›¿æ¢ï¼Œå¹¶ä¸”å®ƒåº”è¯¥å°†è¿™äº›è§†ä¸ºç¼ºå¤±å€¼ã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¹‹å‰çš„ç»“æœï¼Œå…¶ä¸­è‡ªå®šä¹‰å€¼çš„ç´¢å¼•ä¸º 6ï¼Œå¦‚æœæˆ‘ç°åœ¨é‡æ–°è¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæ¶ˆå¤±äº†ï¼ŒåŒæ ·åœ¨è¿™é‡Œå¦‚æœæˆ‘é‡æ–°è¿è¡Œï¼Œé‚£ä¹ˆå®ƒä¹Ÿæ¶ˆå¤±äº†ã€‚ç°åœ¨ï¼Œå¦‚æœä½ ä¸æƒ³åšä»»ä½•æ›´æ”¹ï¼Œåªæƒ³æŸ¥çœ‹æŸäº›å€¼æ˜¯å¦ä¼šè¢«è§†ä¸º
    NA å€¼ã€‚
- en: then we could just run the NA or is in a method and get a mask of values as
    to whether or not these classified as NA or notã€‚ So let me just show you what
    I mean hereã€‚ So I could say Df dot is NA And this is just going to give us a mask
    here of values that whether or not they are classified as an N valuesã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥è¿è¡Œ NA or is in a æ–¹æ³•ï¼Œå¾—åˆ°ä¸€ä¸ªå€¼çš„æ©ç ï¼Œä»¥åˆ¤æ–­è¿™äº›å€¼æ˜¯å¦è¢«åˆ†ç±»ä¸º NAã€‚è®©æˆ‘å‘ä½ å±•ç¤ºæˆ‘åœ¨è¿™é‡Œçš„æ„æ€ã€‚æˆ‘å¯ä»¥è¯´ Df dot
    is NAï¼Œè¿™å°†ç»™æˆ‘ä»¬ä¸€ä¸ªå€¼çš„æ©ç ï¼Œè¡¨ç¤ºå®ƒä»¬æ˜¯å¦è¢«åˆ†ç±»ä¸º N å€¼ã€‚
- en: so we can seeã€‚That our row4 here was all NA values and so same thing with our
    row6 and we can see some other missing values throughout here as wellã€‚ Now sometimes
    especially when we're working with numerical data we might want to fill our NA
    values with a particular value Now I'm working with string data here but sometimes
    it make might make sense to fill your NA values with certain values with these
    as wellã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œrow4 è¿™é‡Œå…¨æ˜¯ NA å€¼ï¼Œrow6 ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°å…¶ä»–ä¸€äº›ç¼ºå¤±å€¼ã€‚ç°åœ¨ï¼Œæœ‰æ—¶ç‰¹åˆ«æ˜¯å¤„ç†æ•°å€¼æ•°æ®æ—¶ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³ç”¨ç‰¹å®šå€¼å¡«å…… NA
    å€¼ã€‚ç°åœ¨æˆ‘æ­£åœ¨å¤„ç†å­—ç¬¦ä¸²æ•°æ®ï¼Œä½†æœ‰æ—¶ç”¨ç‰¹å®šå€¼å¡«å…… NA å€¼ä¹Ÿæ˜¯æœ‰æ„ä¹‰çš„ã€‚
- en: So for exampleï¼Œ let's assume that we were calculating grades for assignments
    or something like that and you had some assignments that were NA because the student
    never turned in the assignment Well at that point you could just decide if you
    wanted to score all missing assignments as zeros so that you could probably calculate
    up the grades so to do something like this we can use the fill NA method so for
    example I could say something like this if I do a Df do fill NA and then pass
    in a valueã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬åœ¨ä¸ºä½œä¸šè®¡ç®—åˆ†æ•°ï¼Œæˆ–è€…ç±»ä¼¼çš„äº‹æƒ…ï¼Œè€Œä½ æœ‰ä¸€äº›ä½œä¸šçš„å€¼ä¸º NAï¼Œå› ä¸ºå­¦ç”Ÿä»æœªæäº¤ä½œä¸šã€‚é‚£ä¹ˆåœ¨é‚£æ—¶ä½ å¯ä»¥å†³å®šæ˜¯å¦å°†æ‰€æœ‰ç¼ºå¤±çš„ä½œä¸šè®°ä¸ºé›¶ï¼Œä»¥ä¾¿ä½ å¯ä»¥è®¡ç®—æ€»åˆ†ã€‚å› æ­¤ï¼Œè¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨
    fill NA æ–¹æ³•ï¼Œä¾‹å¦‚æˆ‘å¯ä»¥è¿™æ ·è¯´ï¼Œå¦‚æœæˆ‘åš Df do fill NAï¼Œç„¶åä¼ å…¥ä¸€ä¸ªå€¼ã€‚
- en: Just to show you exactly what this is doingï¼Œ I'm going to fill all of our missing
    values with this capitalized missing string hereã€‚ and if I run thisï¼Œ then we can
    see that all of those missing or all of those in values We're filled with this
    string capitalized as missingã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¡®åˆ‡å±•ç¤ºè¿™åœ¨åšä»€ä¹ˆï¼Œæˆ‘å°†ç”¨è¿™ä¸ªå¤§å†™çš„ç¼ºå¤±å­—ç¬¦ä¸²å¡«å……æˆ‘ä»¬æ‰€æœ‰çš„ç¼ºå¤±å€¼ã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰ç¼ºå¤±çš„å€¼ï¼Œæˆ–æ‰€æœ‰çš„ N å€¼éƒ½è¢«å¡«å……ä¸ºè¿™ä¸ªå¤§å†™çš„ç¼ºå¤±å­—ç¬¦ä¸²ã€‚
- en: Nowï¼Œ like I said beforeï¼Œ I don't do this a lot with certain stringsã€‚ I found
    this to be most useful for numerical data depending on how you're doing your calculationsã€‚
    but you might want to give in values a value of0 or negative1 or something like
    thatã€‚ So if it would make sense with your dataï¼Œ and you had numerical data to
    replace your missing values with a0ã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä¹‹å‰æ‰€è¯´ï¼Œæˆ‘å¹¶ä¸å¸¸ç”¨æŸäº›å­—ç¬¦ä¸²ã€‚æˆ‘å‘ç°è¿™å¯¹äºæ•°å€¼æ•°æ®æœ€æœ‰ç”¨ï¼Œå…·ä½“å–å†³äºä½ å¦‚ä½•è¿›è¡Œè®¡ç®—ã€‚ä½†æ˜¯ä½ å¯èƒ½æƒ³ç»™ NA å€¼ä¸€ä¸ªå€¼ï¼Œä¾‹å¦‚ 0 æˆ– -1 ç­‰ã€‚å¦‚æœè¿™ä¸æ•°æ®ç›¸ç¬¦ï¼Œå¹¶ä¸”ä½ æœ‰æ•°å€¼æ•°æ®ï¼Œå¯ä»¥ç”¨
    0 æ›¿æ¢ç¼ºå¤±å€¼ã€‚
- en: then you can just run Df fill in0ã€‚ And if I go ahead and run thisã€‚ then we can
    see that that works on our data frame as wellã€‚ And againã€‚ just like with our other
    methodsã€‚ if you want those changes to your data frame to be permanent and carry
    over into other cellsã€‚ then simply just add that inplace argument and set that
    to true toã€‚that change permanentã€‚ Okayã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥è¿è¡Œ Df fill in0ã€‚å¦‚æœæˆ‘ç»§ç»­è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™åœ¨æˆ‘ä»¬çš„æ•°æ®æ¡†ä¸­ä¹Ÿæœ‰æ•ˆã€‚åŒæ ·ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰çš„æ–¹æ³•ä¸€æ ·ï¼Œå¦‚æœä½ å¸Œæœ›å¯¹æ•°æ®æ¡†çš„æ›´æ”¹æ˜¯æ°¸ä¹…çš„ï¼Œå¹¶ä¸”èƒ½åœ¨å…¶ä»–å•å…ƒæ ¼ä¸­ä¿ç•™ï¼Œåªéœ€æ·»åŠ 
    inplace å‚æ•°å¹¶å°†å…¶è®¾ç½®ä¸º trueï¼Œä½¿æ›´æ”¹æ°¸ä¹…åŒ–ã€‚å¥½çš„ã€‚
- en: so now let's look at another common thing that we're likely going to need to
    do with a lot of our dataã€‚ And that is casting data typesã€‚ So I have another column
    in my snippets here that I didn't have in previous videosã€‚ And I have up hereï¼Œ
    if we lookï¼Œ this is this age columnã€‚ So let's say that we wanted to get the average
    age of all the people in this sample data frameã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¯èƒ½éœ€è¦å¤„ç†çš„å¦ä¸€ä»¶å¸¸è§äº‹æƒ…ã€‚é‚£å°±æ˜¯è½¬æ¢æ•°æ®ç±»å‹ã€‚å› æ­¤æˆ‘åœ¨è¿™é‡Œæœ‰å¦ä¸€åˆ—ï¼Œè¿™æ˜¯æˆ‘åœ¨ä¹‹å‰è§†é¢‘ä¸­æ²¡æœ‰æåˆ°çš„ã€‚å¦‚æœæˆ‘ä»¬æŸ¥çœ‹ï¼Œè¿™å°±æ˜¯è¿™ä¸ªå¹´é¾„åˆ—ã€‚æ‰€ä»¥å‡è®¾æˆ‘ä»¬æƒ³è¦è·å–è¿™ä¸ªæ ·æœ¬æ•°æ®æ¡†ä¸­æ‰€æœ‰äººçš„å¹³å‡å¹´é¾„ã€‚
- en: Wellï¼Œ right nowï¼Œ these might look like numbers when we print them out in our
    data frame down hereã€‚ these are actually stringsã€‚ And we can see this if we look
    at our data frame data typesã€‚ So to do thisï¼Œ we can say Df do D typesã€‚ and that's
    not a methodã€‚ it's just an attributeã€‚ So if I run this hereã€‚ And we can see that
    it says all of these columns are objectsã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨è¿™äº›åœ¨æˆ‘ä»¬çš„æ•°æ®æ¡†ä¸­æ‰“å°å‡ºæ¥æ—¶å¯èƒ½çœ‹èµ·æ¥åƒæ•°å­—ã€‚å®é™…ä¸Šå®ƒä»¬æ˜¯å­—ç¬¦ä¸²ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥çœ‹æ•°æ®æ¡†çš„æ•°æ®ç±»å‹æ¥éªŒè¯è¿™ä¸€ç‚¹ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ Df
    çš„æ•°æ®ç±»å‹ï¼ˆD typesï¼‰ã€‚è¿™ä¸æ˜¯ä¸€ä¸ªæ–¹æ³•ï¼Œè€Œåªæ˜¯ä¸€ä¸ªå±æ€§ã€‚æ‰€ä»¥å¦‚æœæˆ‘åœ¨è¿™é‡Œè¿è¡Œå®ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰è¿™äº›åˆ—éƒ½æ˜¯å¯¹è±¡ã€‚
- en: And when it says it's an objectï¼Œ it likely means it's a string or a mix of different
    thingsã€‚ So in the latest version of Python or pandasï¼Œ I'm sorryï¼Œ they actually
    updated itã€‚ so that there's actually a string data typeã€‚Now but I'll do a video
    on those pandas version updates at the end of this series since they actually
    released that updated version as I was writing this courseã€‚ but don't worryï¼Œ there's
    not a lot that's changed to where what you learn here will be outdated or anything
    like that it's still mostly the same but we can see here that our age column is
    a string because it's this object data typeã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å®ƒè¯´è¿™æ˜¯ä¸€ä¸ªå¯¹è±¡æ—¶ï¼Œå¯èƒ½æ„å‘³ç€å®ƒæ˜¯å­—ç¬¦ä¸²æˆ–ä¸åŒäº‹ç‰©çš„æ··åˆã€‚æ‰€ä»¥åœ¨ Python æˆ– pandas çš„æœ€æ–°ç‰ˆæœ¬ä¸­ï¼ŒæŠ±æ­‰ï¼Œå®ƒä»¬å®é™…ä¸Šè¿›è¡Œäº†æ›´æ–°ï¼Œç°åœ¨æœ‰ä¸€ä¸ªå­—ç¬¦ä¸²æ•°æ®ç±»å‹ã€‚ä½†æˆ‘ä¼šåœ¨è¿™ä¸€ç³»åˆ—çš„æœ€ååšä¸€ä¸ªå…³äº
    pandas ç‰ˆæœ¬æ›´æ–°çš„è§†é¢‘ï¼Œå› ä¸ºåœ¨æˆ‘ç¼–å†™è¿™é—¨è¯¾ç¨‹æ—¶å®ƒä»¬å®é™…ä¸Šå‘å¸ƒäº†é‚£ä¸ªæ›´æ–°ç‰ˆæœ¬ã€‚ä½†ä¸ç”¨æ‹…å¿ƒï¼Œè¿™é‡Œå­¦åˆ°çš„å†…å®¹ä¸ä¼šè¿‡æ—¶ï¼ŒåŸºæœ¬ä¸Šè¿˜æ˜¯å¤§åŒå°å¼‚ï¼Œä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å¹´é¾„åˆ—æ˜¯å­—ç¬¦ä¸²ï¼Œå› ä¸ºå®ƒæ˜¯è¿™ä¸ªå¯¹è±¡æ•°æ®ç±»å‹ã€‚
- en: So if we wanted the average age then it wouldn't work as it is nowã€‚ So let's
    just see what this error looks likeã€‚ So I'm going to grab the mean of that age
    column and if I run this then we can see that right now we get an error and if
    I scroll down to see what this error wasã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘ä»¬æƒ³è¦å¹³å‡å¹´é¾„ï¼Œç°åœ¨è¿™æ ·åšæ˜¯è¡Œä¸é€šçš„ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªé”™è¯¯æ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚æˆ‘å°†è·å–é‚£ä¸ªå¹´é¾„åˆ—çš„å¹³å‡å€¼ï¼Œå¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°åœ¨æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œå¦‚æœæˆ‘å‘ä¸‹æ»šåŠ¨çœ‹çœ‹è¿™ä¸ªé”™è¯¯æ˜¯ä»€ä¹ˆã€‚
- en: it says can only concatenate STR not int to string Now that might not be the
    most easy to understand error right there but basically it's telling us that because
    that column is strings and not integers So we need to convert that column to numbers
    instead of a stringã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¾ç¤ºâ€œåªèƒ½å°† STR è¿æ¥åˆ°å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ intâ€ã€‚è¿™å¯èƒ½ä¸æ˜¯æœ€å®¹æ˜“ç†è§£çš„é”™è¯¯ï¼Œä½†åŸºæœ¬ä¸Šå®ƒå‘Šè¯‰æˆ‘ä»¬ï¼Œå› ä¸ºé‚£ä¸€åˆ—æ˜¯å­—ç¬¦ä¸²è€Œä¸æ˜¯æ•´æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å°†è¯¥åˆ—è½¬æ¢ä¸ºæ•°å­—ï¼Œè€Œä¸æ˜¯å­—ç¬¦ä¸²ã€‚
- en: Now there's a caveat when doing thisã€‚ and this might throw some people offã€‚
    So when we have NAN values in a column that we're trying to convert the numbersã€‚
    then you need to use the float data typeã€‚ And that's because the NN value is actually
    a float under the hoodã€‚ let me go ahead and show this just to show you what this
    looks likeã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨åœ¨åšè¿™ä»¶äº‹æ—¶æœ‰ä¸€ä¸ªæ³¨æ„äº‹é¡¹ï¼Œè¿™å¯èƒ½ä¼šè®©ä¸€äº›äººå›°æƒ‘ã€‚æ‰€ä»¥å½“æˆ‘ä»¬åœ¨å°è¯•å°†åˆ—ä¸­çš„ NAN å€¼è½¬æ¢ä¸ºæ•°å­—æ—¶ï¼Œä½ éœ€è¦ä½¿ç”¨æµ®ç‚¹æ•°æ®ç±»å‹ã€‚è¿™æ˜¯å› ä¸º NAN å€¼å®é™…ä¸Šæ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚è®©æˆ‘ç»§ç»­æ¼”ç¤ºä¸€ä¸‹ï¼Œä»¥ä¾¿è®©ä½ çœ‹çœ‹è¿™æ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚
- en: So I'm going to look up the type of N dot NAã€‚ And we can see that that is a
    floatã€‚ So if we try to convert this column to integersï¼Œ then it's going to throw
    an error when it runs into those NAN values because it can't convert thoseã€‚ So
    if I was to say Df andã€‚Of age is equal toã€‚ And now let's try to convert these
    to integersã€‚ So the way that you cast data types here is we can just sayï¼Œ okayï¼Œ
    I want the age column as typeã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æŸ¥æ‰¾ N dot NA çš„ç±»å‹ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚å¦‚æœæˆ‘ä»¬å°è¯•å°†è¿™ä¸€åˆ—è½¬æ¢ä¸ºæ•´æ•°ï¼Œå½“é‡åˆ° NAN å€¼æ—¶å°±ä¼šæŠ›å‡ºé”™è¯¯ï¼Œå› ä¸ºå®ƒæ— æ³•è¿›è¡Œè½¬æ¢ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘è¯´
    Df çš„å¹´é¾„ï¼ˆOf ageï¼‰ç­‰äºï¼Œç„¶åæˆ‘ä»¬å°è¯•å°†è¿™äº›è½¬æ¢ä¸ºæ•´æ•°ã€‚è¿™é‡Œè½¬æ¢æ•°æ®ç±»å‹çš„æ–¹å¼æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´ï¼Œæˆ‘æƒ³å°†å¹´é¾„åˆ—çš„ç±»å‹è®¾ç½®ä¸ºã€‚
- en: and now we want to pass in the type that we wantã€‚ If I tried to convert these
    to integersã€‚ Then this is going to give us an errorã€‚ because we have some N in
    valuesï¼Œ So we can see hereã€‚ int argument must be a string not none typeã€‚ So when
    you're trying to convert these the numbers and you have those Nn valuesã€‚ you basically
    have two options hereã€‚ If your column didn't have any missing valuesã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æƒ³ä¼ å…¥æˆ‘ä»¬æƒ³è¦çš„ç±»å‹ã€‚å¦‚æœæˆ‘å°è¯•å°†è¿™äº›è½¬æ¢ä¸ºæ•´æ•°ï¼Œé‚£ä¹ˆè¿™ä¼šç»™æˆ‘ä»¬ä¸€ä¸ªé”™è¯¯ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ä¸€äº›naNå€¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œintå‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯noneç±»å‹ã€‚å› æ­¤ï¼Œå½“ä½ è¯•å›¾å°†è¿™äº›æ•°å­—è½¬æ¢æ—¶ï¼Œå¦‚æœæœ‰naNå€¼ï¼Œä½ åŸºæœ¬ä¸Šæœ‰ä¸¤ä¸ªé€‰æ‹©ã€‚å¦‚æœä½ çš„åˆ—æ²¡æœ‰ä»»ä½•ç¼ºå¤±å€¼ã€‚
- en: then this would just work fineã€‚ We wouldn't even run into this errorã€‚ But if
    it does have missing valuesã€‚ Then you can either convert those missing values
    to something else like a0 using the feel N method that we saw beforeã€‚ or you can
    just cast that column to a float insteadã€‚ Nowã€‚ I think this would be a bad idea
    to convert those missing values to a0 or some other numberã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·å°±å¯ä»¥æ­£å¸¸å·¥ä½œã€‚æˆ‘ä»¬ç”šè‡³ä¸ä¼šé‡åˆ°è¿™ä¸ªé”™è¯¯ã€‚ä½†å¦‚æœç¡®å®æœ‰ç¼ºå¤±å€¼ï¼Œä½ å¯ä»¥å°†é‚£äº›ç¼ºå¤±å€¼è½¬æ¢ä¸ºå…¶ä»–å€¼ï¼Œæ¯”å¦‚ç”¨æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„feel Næ–¹æ³•å°†å…¶è½¬æ¢ä¸º0ï¼Œæˆ–è€…ä½ ä¹Ÿå¯ä»¥ç›´æ¥å°†è¯¥åˆ—è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚ç°åœ¨ï¼Œæˆ‘è®¤ä¸ºå°†é‚£äº›ç¼ºå¤±å€¼è½¬æ¢ä¸º0æˆ–å…¶ä»–æ•°å­—æ˜¯ä¸ªåä¸»æ„ã€‚
- en: Because we're trying to compute the average in this caseã€‚ But depending on your
    dataã€‚ that might be what you want to doã€‚ But I'm going to go ahead and just convert
    these to floatsã€‚ So those naN values stay missing valuesã€‚ So instead of an nt
    hereã€‚ I'm just going to convert this to a floatã€‚ And if I run thisï¼Œ then that
    seem to have workedã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬è¯•å›¾è®¡ç®—è¿™ä¸ªæ¡ˆä¾‹ä¸­çš„å¹³å‡å€¼ã€‚ä½†æ ¹æ®ä½ çš„æ•°æ®ï¼Œè¿™å¯èƒ½æ­£æ˜¯ä½ æƒ³è¦åšçš„ã€‚ä¸è¿‡æˆ‘ä¼šç»§ç»­å°†è¿™äº›è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚æ‰€ä»¥é‚£äº›naNå€¼ä¿æŒä¸ºç¼ºå¤±å€¼ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘ä¸å†ä½¿ç”¨ntï¼Œè€Œæ˜¯å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆçœ‹èµ·æ¥æ˜¯æœ‰æ•ˆçš„ã€‚
- en: So now we can look at the data types againã€‚ So I'll say Df whoopsã€‚ sorry I wouldn't
    typing in that cellã€‚ I can say Df do D typesã€‚ And if we look at thisã€‚ then we
    can see that now our age is a float object hereã€‚ So now let's see what happens
    when we try to take the average of that columnã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å†æ¬¡æŸ¥çœ‹æ•°æ®ç±»å‹ã€‚æˆ‘å¯ä»¥è¯´Dfï¼Œå“å‘€ï¼Œå¯¹ä¸èµ·ï¼Œæˆ‘åœ¨é‚£ä¸ªå•å…ƒæ ¼é‡Œæ‰“é”™äº†ã€‚æˆ‘å¯ä»¥è¯´Dfçš„dtypesã€‚å¦‚æœæˆ‘ä»¬æŸ¥çœ‹è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°åœ¨æˆ‘ä»¬çš„å¹´é¾„æ˜¯ä¸€ä¸ªæµ®ç‚¹å¯¹è±¡ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬å°è¯•è®¡ç®—è¯¥åˆ—çš„å¹³å‡å€¼æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚
- en: So I'll say Df do meanã€‚ And if I run thatï¼Œ then we can see that we get the average
    value for those agesã€‚ Now if you have an entire data frame of numbers or something
    like that that you're trying to convert all at onceã€‚ then the data frame object
    has an as type method as wellã€‚ So you could just say Df do as typeã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¼šè¯´Dfçš„meanã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¾—åˆ°äº†è¿™äº›å¹´é¾„çš„å¹³å‡å€¼ã€‚ç°åœ¨ï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªåŒ…å«æ•°å­—çš„æ•´ä¸ªæ•°æ®æ¡†æˆ–è€…ç±»ä¼¼çš„ä¸œè¥¿ï¼Œæƒ³è¦ä¸€æ¬¡æ€§è½¬æ¢ï¼Œé‚£ä¹ˆæ•°æ®æ¡†å¯¹è±¡ä¹Ÿæœ‰ä¸€ä¸ªas
    typeæ–¹æ³•ã€‚æ‰€ä»¥ä½ å¯ä»¥ç›´æ¥è¯´Dfçš„as typeã€‚
- en: '![](img/f3f6adee5351ab52b6113da712018c15_1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_1.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_2.png)'
- en: Then passs in whatever data type you're trying to cast everything to and just
    convert everything in the data frame at onceã€‚ But we have some mixed columns hereã€‚
    so we don't want to do thatã€‚ Okay so we've been looking at our small data set
    right now to test this stuff outã€‚ But now let's take what we learned here and
    learn how this applies to real worldorld data and do some analysis on our stack
    overflow survey data so first of allã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä¼ å…¥ä½ æƒ³è¦è½¬æ¢ä¸ºçš„ä»»ä½•æ•°æ®ç±»å‹ï¼Œå¹¶ä¸€æ¬¡æ€§è½¬æ¢æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰å†…å®¹ã€‚ä½†è¿™é‡Œæœ‰ä¸€äº›æ··åˆåˆ—ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸æƒ³è¿™ä¹ˆåšã€‚å¥½çš„ï¼Œæˆ‘ä»¬ç°åœ¨ä¸€ç›´åœ¨æŸ¥çœ‹æˆ‘ä»¬çš„å°æ•°æ®é›†ä»¥æµ‹è¯•è¿™äº›å†…å®¹ã€‚ä½†ç°åœ¨è®©æˆ‘ä»¬æŠŠåœ¨è¿™é‡Œå­¦åˆ°çš„çŸ¥è¯†åº”ç”¨åˆ°ç°å®ä¸–ç•Œæ•°æ®ä¸Šï¼Œå¹¶å¯¹æˆ‘ä»¬çš„Stack
    Overflowè°ƒæŸ¥æ•°æ®è¿›è¡Œä¸€äº›åˆ†æï¼Œæ‰€ä»¥é¦–å…ˆã€‚
- en: I mentioned earlier that if we had custom values for missing data then it's
    a little bit easier to handle these when loading in a cv and what I'm talking
    about up here is up here at the top where we replaced these custom missing values
    let me show you how we would do this same thing but loading in a cv instead So
    I'm gonna switch over here to my stack overflow survey dataã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰æåˆ°è¿‡ï¼Œå¦‚æœæˆ‘ä»¬æœ‰è‡ªå®šä¹‰çš„ç¼ºå¤±æ•°æ®å€¼ï¼Œé‚£ä¹ˆåœ¨åŠ è½½cvæ—¶å¤„ç†è¿™äº›ä¼šç®€å•ä¸€äº›ã€‚æˆ‘æ‰€è¯´çš„åœ¨è¿™é‡Œæ˜¯æˆ‘ä»¬åœ¨é¡¶éƒ¨æ›¿æ¢è¿™äº›è‡ªå®šä¹‰ç¼ºå¤±å€¼ã€‚è®©æˆ‘ç»™ä½ å±•ç¤ºå¦‚ä½•åœ¨åŠ è½½cvæ—¶åšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘å°†åˆ‡æ¢åˆ°æˆ‘çš„Stack
    Overflowè°ƒæŸ¥æ•°æ®ã€‚
- en: let me go ahead and rerun this just to make sure that all of this stuff is running
    so this notebook still running that's good and again this isã€‚Stack overflow data
    that we have been using throughout the seriesã€‚ And if you'd like to follow alongã€‚
    then I do have a download link for this in the description section belowã€‚ Okayã€‚
    so if I wanted to ignore those custom values when loading in a CSVã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘é‡æ–°è¿è¡Œè¿™ä¸€åˆ‡ï¼Œä»¥ç¡®ä¿æ‰€æœ‰è¿™äº›å†…å®¹éƒ½åœ¨æ­£å¸¸è¿è¡Œï¼Œæ‰€ä»¥è¿™ä¸ªç¬”è®°æœ¬ä»åœ¨è¿è¡Œï¼Œè¿™å¾ˆå¥½ï¼Œè€Œä¸”è¿™ä»ç„¶æ˜¯æˆ‘ä»¬åœ¨æ•´ä¸ªç³»åˆ—ä¸­ä½¿ç”¨çš„ Stack Overflow æ•°æ®ã€‚å¦‚æœä½ æƒ³è·Ÿç€æ“ä½œï¼Œæˆ‘åœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†æœ‰ä¸€ä¸ªä¸‹è½½é“¾æ¥ã€‚å¥½çš„ï¼Œå¦‚æœæˆ‘æƒ³åœ¨åŠ è½½
    CSV æ—¶å¿½ç•¥è¿™äº›è‡ªå®šä¹‰å€¼ã€‚
- en: then we can simply pass in an argument of a list of values that we want to be
    treated as missingã€‚ So here's how we would do thisã€‚ if we had some custom missing
    values here in this CSB fileã€‚ then I could simply create a list here of those
    missing values andã€‚I will just call this in a vowsã€‚ And now I'll pass in a list
    of thoseã€‚ So let's say that we have some values that are a string of N a and a
    string of missingã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ä¼ å…¥ä¸€ä¸ªæˆ‘ä»¬å¸Œæœ›è§†ä¸ºç¼ºå¤±çš„å€¼åˆ—è¡¨ä½œä¸ºå‚æ•°ã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¿™æ ·åšã€‚å¦‚æœåœ¨è¿™ä¸ª CSV æ–‡ä»¶ä¸­æœ‰ä¸€äº›è‡ªå®šä¹‰ç¼ºå¤±å€¼ï¼Œæˆ‘å¯ä»¥ç®€å•åœ°åˆ›å»ºä¸€ä¸ªç¼ºå¤±å€¼çš„åˆ—è¡¨ï¼Œå¹¶ç§°ä¹‹ä¸ºâ€œç¼ºå¤±å€¼â€ã€‚ç„¶åæˆ‘å°†ä¼ å…¥è¿™ä¸ªåˆ—è¡¨ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›å€¼æ˜¯å­—ç¬¦ä¸²â€œNaâ€å’Œä¸€ä¸ªè¡¨ç¤ºç¼ºå¤±çš„å­—ç¬¦ä¸²ã€‚
- en: So now what we could do here is just add in an argument and say in a values
    is equal toã€‚ and then that list that we just createdã€‚ And if we run thatï¼Œ then
    we shouldn't get any errorsã€‚ And when it reads in that CVï¼Œ then it will treat
    that list of valuesã€‚ as missing values and give them an in a in resultã€‚ Nowï¼Œ in
    this survey hereã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸€ä¸ªå‚æ•°ï¼Œå¹¶è¯´ Na å€¼ç­‰äºæˆ‘ä»¬åˆšåˆšåˆ›å»ºçš„é‚£ä¸ªåˆ—è¡¨ã€‚å¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå°±ä¸åº”è¯¥å‡ºç°ä»»ä½•é”™è¯¯ã€‚å½“å®ƒè¯»å–è¿™ä¸ª CSV æ—¶ï¼Œå®ƒä¼šå°†é‚£ä¸ªå€¼åˆ—è¡¨è§†ä¸ºç¼ºå¤±å€¼ï¼Œå¹¶ç»™å‡º
    NaN ç»“æœã€‚ç°åœ¨ï¼Œåœ¨è¿™ä¸ªè°ƒæŸ¥ä¸­ã€‚
- en: they did a good job of not having any weird occurrences like thatã€‚ So that actually
    shouldn't change anythingã€‚ Okayï¼Œ so now let's look at an interesting problem with
    casting some valuesã€‚ So let's say that for the developers who answered this surveyã€‚
    we wanted to calculate the average number of years of coding experience among
    all of themã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬åšå¾—å¾ˆå¥½ï¼Œæ²¡æœ‰å‡ºç°ä»»ä½•å¥‡æ€ªçš„æƒ…å†µã€‚å› æ­¤ï¼Œè¿™å®é™…ä¸Šä¸åº”è¯¥æ”¹å˜ä»»ä½•å†…å®¹ã€‚å¥½å§ï¼Œç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼Œå³å¦‚ä½•è½¬æ¢ä¸€äº›å€¼ã€‚å‡è®¾å¯¹äºå›ç­”äº†è¿™é¡¹è°ƒæŸ¥çš„å¼€å‘è€…ï¼Œæˆ‘ä»¬æƒ³è®¡ç®—ä»–ä»¬çš„å¹³å‡ç¼–ç¨‹ç»éªŒå¹´æ•°ã€‚
- en: Now that might be a good thing to know to compare your experience against the
    averageã€‚But let's look at what this or why this might be difficult to calculate
    with this data setã€‚ and us calculating this solution is actually going to apply
    several concepts that we've learned so far throughout this seriesã€‚ So the column
    to view the answer for this question in the survey is called years codeã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨äº†è§£è¿™ä¸€ç‚¹å¯èƒ½å¯¹æ¯”è¾ƒä½ çš„ç»éªŒä¸å¹³å‡æ°´å¹³æ˜¯æœ‰å¸®åŠ©çš„ã€‚ä½†è®©æˆ‘ä»¬çœ‹çœ‹ä¸ºä»€ä¹ˆä½¿ç”¨è¿™ä¸ªæ•°æ®é›†æ¥è®¡ç®—å¯èƒ½ä¼šæ¯”è¾ƒå›°éš¾ã€‚æˆ‘ä»¬è®¡ç®—è¿™ä¸ªè§£å†³æ–¹æ¡ˆå®é™…ä¸Šä¼šåº”ç”¨åˆ°æˆ‘ä»¬åœ¨è¿™ä¸€ç³»åˆ—ä¸­å­¦åˆ°çš„å‡ ä¸ªæ¦‚å¿µã€‚æ‰€ä»¥åœ¨è°ƒæŸ¥ä¸­æŸ¥çœ‹è¿™ä¸ªé—®é¢˜ç­”æ¡ˆçš„åˆ—ç§°ä¸ºâ€œç¼–ç¨‹å¹´é™â€ã€‚
- en: So let's look at some of these answersã€‚ So I'm just going to look at the top
    10 answers for years codeã€‚So I will do a dot headã€‚ and let's look at the top 10ã€‚
    So if I run thisã€‚ then at first glanceã€‚ this doesn't really look like it'll be
    a problemã€‚ We just have a bunch of integers and the number of years that different
    respondents have been codingã€‚ So you might think that we can just grab the mean
    of this column simply by sayingï¼Œ okayã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹è¿™äº›ç­”æ¡ˆã€‚æˆ‘å°†æŸ¥çœ‹â€œç¼–ç¨‹å¹´é™â€çš„å‰ 10 ä¸ªç­”æ¡ˆã€‚æ‰€ä»¥æˆ‘ä¼šä½¿ç”¨ `.head()`ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å‰ 10 ä¸ªç»“æœã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œä¹ä¸€çœ‹ï¼Œè¿™ä¼¼ä¹å¹¶ä¸ä¼šæˆä¸ºé—®é¢˜ã€‚æˆ‘ä»¬åªæœ‰ä¸€å †æ•´æ•°ï¼Œè¡¨ç¤ºä¸åŒå—è®¿è€…ç¼–ç¨‹çš„å¹´æ•°ã€‚æ‰€ä»¥ä½ å¯èƒ½ä¼šè®¤ä¸ºæˆ‘ä»¬å¯ä»¥ç®€å•åœ°é€šè¿‡è¯´â€œå¥½å§â€æ¥è·å–è¿™ä¸€åˆ—çš„å‡å€¼ã€‚
- en: if we just have a bunch of integers here and some Nn valuesï¼Œ that's fineã€‚ let's
    just grab the mean of that columnã€‚ But if I run thisï¼Œ then we get an errorã€‚ And
    if I scroll down hereã€‚ Then it says can only concatenate string to stringã€‚ And
    we saw the same error in our smaller data set where the column was actually being
    loaded in as a string instead of numerical dataã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬è¿™é‡Œåªæœ‰ä¸€å †æ•´æ•°å’Œä¸€äº› NaN å€¼ï¼Œé‚£ä¹Ÿæ²¡é—®é¢˜ã€‚è®©æˆ‘ä»¬ç›´æ¥è®¡ç®—è¿™ä¸€åˆ—çš„å‡å€¼ã€‚ä½†å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œå°±ä¼šå‡ºç°é”™è¯¯ã€‚å¦‚æœæˆ‘å‘ä¸‹æ»šåŠ¨ï¼Œè¿™é‡Œæ˜¾ç¤ºåªèƒ½å°†å­—ç¬¦ä¸²ä¸å­—ç¬¦ä¸²è¿æ¥ã€‚æˆ‘ä»¬åœ¨è¾ƒå°çš„æ•°æ®é›†ä¸­ä¹Ÿçœ‹åˆ°äº†åŒæ ·çš„é”™è¯¯ï¼Œé‚£æ—¶åˆ—å®é™…ä¸Šè¢«åŠ è½½ä¸ºå­—ç¬¦ä¸²è€Œä¸æ˜¯æ•°å€¼æ•°æ®ã€‚
- en: And we should know how to handle this by nowï¼Œ since we did it in the smaller
    data setã€‚ So let's try thatã€‚ So let's try to convert this to floats and then take
    the averageã€‚ So let me go back up here to the top where weã€‚ğŸ˜Šï¼ŒAnd instead of running
    the mean hereã€‚ I'm going to sayï¼Œ okayï¼Œ wellï¼Œ let's convert this to a float so
    that we can grab that averageã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”è¯¥çŸ¥é“å¦‚ä½•å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨å°æ•°æ®é›†ä¸­å·²ç»å¤„ç†è¿‡äº†ã€‚è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹ã€‚è®©æˆ‘ä»¬å°è¯•å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œç„¶åå–å¹³å‡å€¼ã€‚æ‰€ä»¥è®©æˆ‘å›åˆ°é¡¶éƒ¨ã€‚ğŸ˜Šè€Œä¸æ˜¯åœ¨è¿™é‡Œè¿è¡Œ
    meanã€‚æˆ‘å°†è¯´ï¼Œå¥½å§ï¼Œè®©æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œä»¥ä¾¿å¯ä»¥è·å–å¹³å‡å€¼ã€‚
- en: So I will say as typeã€‚And we want to convert this to a float since there are
    N N valuesã€‚ So if I run thisã€‚ then we still get an errorã€‚ So we didn't get an
    error in our smaller data set hereã€‚ So if I scroll downï¼Œ then it says could not
    convert string to floatã€‚ And the string that it couldn't convert was less than
    one yearã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¼šè¯´ä½œä¸ºç±»å‹ã€‚æˆ‘ä»¬æƒ³å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå› ä¸ºæœ‰ N N å€¼ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬ä»ç„¶ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ã€‚æ‰€ä»¥åœ¨æˆ‘ä»¬çš„å°æ•°æ®é›†ä¸­æ²¡æœ‰å‡ºç°é”™è¯¯ã€‚å¦‚æœæˆ‘å‘ä¸‹æ»šåŠ¨ï¼Œå®ƒè¯´æ— æ³•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚æ— æ³•è½¬æ¢çš„å­—ç¬¦ä¸²æ˜¯å°äºä¸€å¹´ã€‚
- en: So this might be something that we didn't expect hereã€‚ So obviouslyã€‚ we don't
    just have numbers and N N values in this columnã€‚ There is actually a string value
    that respondents could select that is equal to this string of less than one year
    for coding experienceã€‚ So let's look at all the unique values of of this column
    so that we can see exactly what's in here in case there are more strings like
    thisã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½æ˜¯æˆ‘ä»¬æ²¡æœ‰é¢„æ–™åˆ°çš„äº‹æƒ…ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸€åˆ—ä¸ä»…ä»…æœ‰æ•°å­—å’Œ N N å€¼ã€‚å®é™…ä¸Šï¼Œæœ‰ä¸€ä¸ªå­—ç¬¦ä¸²å€¼ï¼Œå—è®¿è€…å¯ä»¥é€‰æ‹©ï¼Œè¯¥å€¼ç­‰äºå°äºä¸€å¹´ç¼–ç¨‹ç»éªŒçš„å­—ç¬¦ä¸²ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æŸ¥çœ‹è¯¥åˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼ï¼Œä»¥ä¾¿çœ‹åˆ°å…¶ä¸­åˆ°åº•æœ‰ä»€ä¹ˆï¼Œä»¥é˜²æœ‰æ›´å¤šç±»ä¼¼çš„å­—ç¬¦ä¸²ã€‚
- en: And I don't believe we've actually seen this in the series yetã€‚ maybe we haveã€‚
    I can't really rememberã€‚ But if we want to view unique values of a seriesã€‚ then
    we can simply use the unique methodã€‚ So we could also use the value counts method
    that we've seen several times beforeã€‚If we want to count all the unique valuesï¼Œ
    but we don't really want to count themã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ç›¸ä¿¡æˆ‘ä»¬åœ¨åºåˆ—ä¸­å®é™…ä¸Šè§è¿‡è¿™ä¸ªã€‚ä¹Ÿè®¸æˆ‘ä»¬è§è¿‡ã€‚æˆ‘è®°ä¸å¤ªæ¸…æ¥šã€‚ä½†å¦‚æœæˆ‘ä»¬æƒ³æŸ¥çœ‹åºåˆ—çš„å”¯ä¸€å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç®€å•ä½¿ç”¨ unique æ–¹æ³•ã€‚æ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰è§è¿‡çš„
    value counts æ–¹æ³•ã€‚å¦‚æœæˆ‘ä»¬æƒ³è®¡ç®—æ‰€æœ‰å”¯ä¸€å€¼ï¼Œä½†æˆ‘ä»¬å…¶å®å¹¶ä¸æƒ³ç»Ÿè®¡å®ƒä»¬ã€‚
- en: we just want to see all the unique values in this columnã€‚ So to do thisï¼Œ I'm
    going to sayã€‚DF and then access that years code column dot uniqueã€‚Dot uniqueã€‚
    That is a methodã€‚ So if I run thisã€‚ whoopsï¼Œ and I spelled this wrongã€‚ Sorry having
    a hard time typing todayã€‚ Okayï¼Œ so if I run thisã€‚ then this gives us all of the
    unique values of that columnã€‚ And as we'd expectã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªæƒ³æŸ¥çœ‹è¯¥åˆ—ä¸­çš„æ‰€æœ‰å”¯ä¸€å€¼ã€‚ä¸ºæ­¤ï¼Œæˆ‘å°†è¯´ã€‚DF ç„¶åè®¿é—®è¯¥ years code åˆ—çš„ uniqueã€‚é‚£æ˜¯ä¸€ä¸ªæ–¹æ³•ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªã€‚å“å‘€ï¼Œæˆ‘æ‹¼å†™é”™äº†ã€‚æŠ±æ­‰ï¼Œä»Šå¤©æ‰“å­—æœ‰ç‚¹å›°éš¾ã€‚å¥½çš„ï¼Œå¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªã€‚é‚£ä¹ˆè¿™å°†ç»™æˆ‘ä»¬è¯¥åˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€æœŸå¾…çš„ã€‚
- en: there are a lot of numbersã€‚ But we see that we also have some strings that are
    mixed throughout these numbersã€‚ Now we also have in A N values hereã€‚ but we're
    not going to worry about thoseã€‚ we just want to ignore the N A N valuesï¼Œ because
    that's just people who didn't answer the questionã€‚ But we can see that the strings
    that we have throughout here are less than one yearã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å¾ˆå¤šæ•°å­—ã€‚ä½†æˆ‘ä»¬çœ‹åˆ°è¿™äº›æ•°å­—ä¸­ä¹Ÿæ··æ‚äº†ä¸€äº›å­—ç¬¦ä¸²ã€‚ç°åœ¨æˆ‘ä»¬åœ¨è¿™é‡Œä¹Ÿæœ‰ N A N å€¼ï¼Œä½†æˆ‘ä»¬ä¸éœ€è¦æ‹…å¿ƒè¿™äº›ã€‚æˆ‘ä»¬åªæƒ³å¿½ç•¥ N A N å€¼ï¼Œå› ä¸ºè¿™åªæ˜¯æ²¡æœ‰å›ç­”é—®é¢˜çš„äººã€‚ä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œçš„å­—ç¬¦ä¸²éƒ½æ˜¯å°äºä¸€å¹´ã€‚
- en: and more than 50 years of coding experienceã€‚ Okayï¼Œ so those are our only string
    valuesã€‚ So I'm going to replace those with numbers so that we can get an idea
    of the average yearsã€‚ people have been codingã€‚ So let's go ahead and replace less
    than one year here with a0 since that's basically the same thingã€‚ If somebody
    has been coding for less than a year than they've been coding forã€‚Basically zero
    yearsã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¶…è¿‡ 50 å¹´çš„ç¼–ç¨‹ç»éªŒã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å”¯ä¸€çš„å­—ç¬¦ä¸²å€¼ã€‚æ‰€ä»¥æˆ‘å°†ç”¨æ•°å­—æ›¿æ¢è¿™äº›ï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿäº†è§£äººä»¬ç¼–ç¨‹çš„å¹³å‡å¹´é™ã€‚æ‰€ä»¥æˆ‘ä»¬ç»§ç»­å°†å°äºä¸€å¹´æ›¿æ¢ä¸º a0ï¼Œå› ä¸ºè¿™åŸºæœ¬ä¸Šæ˜¯åŒæ ·çš„æ„æ€ã€‚å¦‚æœæŸäººç¼–ç¨‹å°‘äºä¸€å¹´ï¼Œé‚£ä»–ä»¬å®é™…ä¸Šç¼–ç¨‹çš„å¹´é™å°±æ˜¯é›¶å¹´ã€‚
- en: so to do thisã€‚I can say D F dot years code and access that columnã€‚ and then
    we can just replaceã€‚That value of less than one yearã€‚And let's replace that with
    a0ã€‚ And we also want these to be in place equal to true because we actually want
    to modify that data frameã€‚ So if I run thatï¼Œ then it should make that replacementã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¦åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘å¯ä»¥è¯´ D F ç‚¹ years code å¹¶è®¿é—®è¯¥åˆ—ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ç›´æ¥æ›¿æ¢ã€‚å°†å°äºä¸€å¹´çš„å€¼æ›¿æ¢ä¸º a0ã€‚æˆ‘ä»¬è¿˜å¸Œæœ›è¿™äº›å€¼çš„ in place
    ç­‰äº trueï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šæƒ³ä¿®æ”¹è¿™ä¸ªæ•°æ®æ¡†ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œåº”è¯¥èƒ½è¿›è¡Œæ›¿æ¢ã€‚
- en: And now I'm also going to replace the value for more than 50 years hereã€‚ And
    this is going to rescue skew our results a bitï¼Œ depending on how we want to do
    thisã€‚ I'm simply going to replace this with the value of 51ã€‚ there may be some
    people who have several more more years of coding experience than 51 yearsã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘è¿˜è¦æ›¿æ¢è¿™é‡Œè¶…è¿‡50å¹´çš„å€¼ã€‚è¿™å°†ç¨å¾®å½±å“æˆ‘ä»¬çš„ç»“æœï¼Œå…·ä½“å–å†³äºæˆ‘ä»¬æƒ³æ€ä¹ˆåšã€‚æˆ‘åªæ˜¯ç®€å•åœ°ç”¨51çš„å€¼æ¥æ›¿æ¢å®ƒã€‚å¯èƒ½æœ‰äº›äººæ¯”51å¹´æœ‰æ›´å¤šçš„ç¼–ç ç»éªŒã€‚
- en: But I can't imagine that would be that many people who haveï¼Œ you knowã€‚ coded
    many years greater than 50ã€‚ So I'm going to just going to fill this in with 51ã€‚
    But like I saidï¼Œ depending on what we pick hereï¼Œ it could affect our results slightlyã€‚
    but not by a lot in this caseã€‚ So I'm just going to grab this same replace value
    hereã€‚ And insteadã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘æ— æ³•æƒ³è±¡ä¼šæœ‰é‚£ä¹ˆå¤šäººï¼Œæ‚¨çŸ¥é“ã€‚ç¼–ç è¶…è¿‡50å¹´çš„ã€‚æ‰€ä»¥æˆ‘åªä¼šç”¨51æ¥å¡«å……è¿™ä¸ªã€‚ä½†æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œå…·ä½“å–å†³äºæˆ‘ä»¬åœ¨è¿™é‡Œé€‰æ‹©çš„å†…å®¹ï¼Œå®ƒå¯èƒ½ä¼šç¨å¾®å½±å“æˆ‘ä»¬çš„ç»“æœã€‚ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ä¸ä¼šå½±å“å¾ˆå¤šã€‚æ‰€ä»¥æˆ‘åªæ˜¯ä¼šæŠ“å–è¿™ä¸ªç›¸åŒçš„æ›¿æ¢å€¼ã€‚ç„¶åã€‚
- en: I want to replace more than 50 yearsã€‚And I'm going to replace that with a value
    of 51ã€‚ So nowã€‚ let me go ahead and run thisã€‚ And if we want to look at these unique
    values againã€‚ then we could look at theseã€‚ And now it doesn't look like we have
    any strings in hereã€‚ But we can see here that this is still a D type of objectã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æ›¿æ¢è¶…è¿‡50å¹´çš„æ•°æ®ã€‚æˆ‘å°†ç”¨51çš„å€¼æ¥æ›¿æ¢å®ƒã€‚é‚£ä¹ˆç°åœ¨ã€‚è®©æˆ‘ç»§ç»­è¿è¡Œè¿™ä¸ªã€‚å¦‚æœæˆ‘ä»¬æƒ³å†æ¬¡æŸ¥çœ‹è¿™äº›å”¯ä¸€å€¼ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹è¿™äº›ã€‚ç°åœ¨çœ‹èµ·æ¥è¿™é‡Œæ²¡æœ‰ä»»ä½•å­—ç¬¦ä¸²ã€‚ä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªDç±»å‹çš„å¯¹è±¡ã€‚
- en: which means that it's not actually reading this in as floatsã€‚ So if we scroll
    back up here a bitã€‚ Ohï¼Œ actuallyï¼Œ I think Iã€‚Overwrote that lineã€‚ Yesï¼Œ I didã€‚ So
    let's just try that againï¼Œ soã€‚What I want to do here is I want to convert this
    to a floatã€‚ And this is what gave us an error before because we had these strings
    in hereã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€å®é™…ä¸Šå¹¶æ²¡æœ‰å°†å…¶ä½œä¸ºæµ®ç‚¹æ•°è¯»å–ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬å‘ä¸Šæ»šåŠ¨ä¸€ä¸‹ã€‚å“¦ï¼Œå®é™…ä¸Šï¼Œæˆ‘æƒ³æˆ‘ã€‚è¦†ç›–äº†é‚£ä¸€è¡Œã€‚æ˜¯çš„ï¼Œæˆ‘ç¡®å®è¿™æ ·åšäº†ã€‚é‚£æˆ‘ä»¬å†è¯•ä¸€æ¬¡ï¼Œæ‰€ä»¥ã€‚æˆ‘è¦åšçš„æ˜¯å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚è¿™å°±æ˜¯ä¹‹å‰ç»™æˆ‘ä»¬å¸¦æ¥é”™è¯¯çš„åŸå› ï¼Œå› ä¸ºæˆ‘ä»¬è¿™é‡Œæœ‰è¿™äº›å­—ç¬¦ä¸²ã€‚
- en: and it didn't know how to convert these to a floatã€‚ But now we should just be
    able to see sayï¼Œ okayã€‚ I want to convert thatã€‚ as type set that to a floatã€‚ So
    let's run thatã€‚ And we didn't get an error this timeã€‚ So that's goodã€‚ And now
    we should be able to view the average numbers of or average number of years of
    coding experience of the developers who filled out this surveyã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸çŸ¥é“å¦‚ä½•å°†è¿™äº›è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚ä½†ç°åœ¨æˆ‘ä»¬åº”è¯¥åªéœ€è¦è¯´ï¼Œå¥½å§ã€‚æˆ‘æƒ³å°†å…¶è½¬æ¢ã€‚å°†ç±»å‹è®¾ç½®ä¸ºæµ®ç‚¹æ•°ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬è¿è¡Œä¸€ä¸‹ã€‚æˆ‘ä»¬è¿™æ¬¡æ²¡æœ‰å¾—åˆ°é”™è¯¯ã€‚è¿™å¾ˆå¥½ã€‚ç°åœ¨æˆ‘ä»¬åº”è¯¥èƒ½å¤ŸæŸ¥çœ‹å¡«å†™äº†æ­¤è°ƒæŸ¥çš„å¼€å‘è€…çš„ç¼–ç ç»éªŒå¹´æ•°çš„å¹³å‡å€¼ã€‚
- en: So to do thisã€‚ I'm just going to sayï¼Œ okayï¼Œ D F data frameã€‚Access that column
    and grab the mean of that columnã€‚ So if I run thisã€‚ then we can see that now we
    get that average backã€‚ So the average that we got here was about 11 and a half
    years of coding experienceã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘å°†è¯´ï¼Œå¥½å§ï¼ŒD Fæ•°æ®æ¡†ã€‚è®¿é—®è¯¥åˆ—å¹¶è·å–è¯¥åˆ—çš„å‡å€¼ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†é‚£ä¸ªå¹³å‡å€¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¾—åˆ°çš„å¹³å‡å€¼å¤§çº¦æ˜¯11å¹´åŠçš„ç¼–ç ç»éªŒã€‚
- en: as the average years for developers who answered this surveyã€‚ And now you can
    do other analysis on this as wellã€‚ Soï¼Œ for exampleï¼Œ if we wanted to see the medianã€‚
    Then I could run thatã€‚ And the median comes back as nine years of coding experienceã€‚
    So hopefully that real world example helped explain why it's important to know
    how to cast these values and understand what's going on thereã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºå›ç­”æ­¤è°ƒæŸ¥çš„å¼€å‘è€…çš„å¹³å‡å¹´æ•°ã€‚ç°åœ¨ä½ ä¹Ÿå¯ä»¥å¯¹æ­¤è¿›è¡Œå…¶ä»–åˆ†æã€‚æ‰€ä»¥ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³æŸ¥çœ‹ä¸­ä½æ•°ã€‚é‚£ä¹ˆæˆ‘å¯ä»¥è¿è¡Œè¿™ä¸ªã€‚ä¸­ä½æ•°è¿”å›ä¸º9å¹´çš„ç¼–ç ç»éªŒã€‚æ‰€ä»¥å¸Œæœ›è¿™ä¸ªç°å®ä¸–ç•Œçš„ä¾‹å­æœ‰åŠ©äºè§£é‡Šä¸ºä»€ä¹ˆäº†è§£å¦‚ä½•è½¬æ¢è¿™äº›å€¼ä»¥åŠç†è§£å…¶ä¸­å‘ç”Ÿçš„äº‹æƒ…æ˜¯é‡è¦çš„ã€‚
- en: there's always going to be data that is messy or not in the format that we wanted
    inã€‚ So knowing how to handle these missing values and cast these values to different
    data types is really going to be essential when working with pandasã€‚ Okayï¼Œ so
    before we end hereï¼Œ I'd like to thank the sponsor of this video and mention why
    I really enjoy their tutorialsã€‚ And that is brilliantã€‚ So in this seriesï¼Œ we've
    been learning about pandas and how toã€‚ğŸ˜Šã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä¼šæœ‰ä¸€äº›æ•°æ®æ˜¯æ‚ä¹±çš„æˆ–ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ ¼å¼ã€‚æ‰€ä»¥çŸ¥é“å¦‚ä½•å¤„ç†è¿™äº›ç¼ºå¤±å€¼å¹¶å°†è¿™äº›å€¼è½¬æ¢ä¸ºä¸åŒçš„æ•°æ®ç±»å‹åœ¨ä½¿ç”¨pandasæ—¶çœŸçš„å¾ˆé‡è¦ã€‚å¥½çš„ï¼Œæ‰€ä»¥åœ¨ç»“æŸä¹‹å‰ï¼Œæˆ‘æƒ³æ„Ÿè°¢æœ¬è§†é¢‘çš„èµåŠ©å•†ï¼Œå¹¶æåˆ°æˆ‘ä¸ºä»€ä¹ˆéå¸¸å–œæ¬¢ä»–ä»¬çš„æ•™ç¨‹ã€‚é‚£å°±æ˜¯brilliantã€‚åœ¨è¿™ä¸€ç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨å­¦ä¹ å…³äºpandasçš„å†…å®¹ä»¥åŠå¦‚ä½•ã€‚ğŸ˜Šã€‚
- en: '![](img/f3f6adee5351ab52b6113da712018c15_4.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_4.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_5.png)'
- en: Analyze data in Python and brilliant would be an excellent way to supplement
    what you learn here with their handson coursesã€‚ They have some excellent courses
    and lessons that do a deep dive on how to think about and analyze data correctlyã€‚
    for data analysis fundamentalsã€‚ I would really recommend checking out their statistics
    courseã€‚ which shows you how to analyze graphs and determine significance in the
    dataã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­åˆ†ææ•°æ®ï¼Œbrilliant å°†æ˜¯è¡¥å……ä½ åœ¨è¿™é‡Œæ‰€å­¦å†…å®¹çš„ç»ä½³æ–¹å¼ï¼Œä»–ä»¬æä¾›äº†ä¸€äº›ä¼˜ç§€çš„åŠ¨æ‰‹è¯¾ç¨‹ã€‚è¿™é‡Œæœ‰ä¸€äº›å‡ºè‰²çš„è¯¾ç¨‹å’Œæ•™ç¨‹ï¼Œæ·±å…¥è®²è§£å¦‚ä½•æ­£ç¡®æ€è€ƒå’Œåˆ†ææ•°æ®ã€‚å¯¹äºæ•°æ®åˆ†æåŸºç¡€ï¼Œæˆ‘çœŸçš„æ¨èä½ æŸ¥çœ‹ä»–ä»¬çš„ç»Ÿè®¡è¯¾ç¨‹ï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•åˆ†æå›¾è¡¨å¹¶ç¡®å®šæ•°æ®çš„æ˜¾è‘—æ€§ã€‚
- en: And I would also recommend their machine learning course which takes data analysis
    to a new level while you' about the techniques being used that allow machines
    to make decisions where there's just too many variables for a human to considerã€‚
    So to support my channel and learn more about brilliantã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜å»ºè®®ä»–ä»¬çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œè¯¥è¯¾ç¨‹å°†æ•°æ®åˆ†ææå‡åˆ°ä¸€ä¸ªæ–°æ°´å¹³ï¼Œè®²è¿°äº†å…è®¸æœºå™¨åœ¨å˜é‡è¿‡å¤šæ—¶åšå‡ºå†³ç­–çš„æŠ€æœ¯ã€‚ä¸ºäº†æ”¯æŒæˆ‘çš„é¢‘é“å¹¶äº†è§£æ›´å¤šå…³äº brilliant
    çš„ä¿¡æ¯ã€‚
- en: you can go to brilliant org to sign up for freeã€‚ And also the first 200 people
    that go to that link will get 20% off the annual premium subscriptionã€‚ and you
    can find that link in the description section belowã€‚ againã€‚ that's brilliant org
    for so I think that's going to do it for this pandas video I hope you feel like
    you got a good idea for how to handle these missing values and cast our data to
    differentã€‚ğŸ˜Šã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è®¿é—® brilliant.org å…è´¹æ³¨å†Œã€‚è€Œä¸”å‰ 200 ä½è®¿é—®è¯¥é“¾æ¥çš„äººå¯ä»¥äº«å—å¹´åº¦é«˜çº§è®¢é˜…çš„ 20% æŠ˜æ‰£ã€‚ä½ å¯ä»¥åœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†æ‰¾åˆ°è¯¥é“¾æ¥ã€‚å†è¯´ä¸€æ¬¡ï¼Œè®¿é—®
    brilliant.orgã€‚æˆ‘æƒ³è¿™å°±æ˜¯è¿™æ®µ pandas è§†é¢‘çš„å†…å®¹äº†ï¼Œå¸Œæœ›ä½ å¯¹å¦‚ä½•å¤„ç†è¿™äº›ç¼ºå¤±å€¼å’Œå°†æ•°æ®è½¬æ¢æœ‰äº†ä¸€ä¸ªè‰¯å¥½çš„ç†è§£ã€‚ğŸ˜Šã€‚
- en: '![](img/f3f6adee5351ab52b6113da712018c15_7.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_7.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_8.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_8.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_9.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_9.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_10.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_10.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_11.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_11.png)'
- en: Data typess so that we can do exactly what we want to do in terms of analyzing
    our dataã€‚ Nowã€‚ in the next videoï¼Œ we're gonna to be learning how to work with
    dates and time series dataã€‚ Now I've been using the stack overflow survey data
    for this entire series because I love being able to show you all realword examples
    of how these concepts applyã€‚ But our stack overflow survey data doesn't have any
    time series data that we can actually work withã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç±»å‹ä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿç²¾ç¡®åœ°åˆ†ææˆ‘ä»¬çš„æ•°æ®ã€‚ç°åœ¨ï¼Œåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•å¤„ç†æ—¥æœŸå’Œæ—¶é—´åºåˆ—æ•°æ®ã€‚æ­¤ç³»åˆ—çš„æ•´ä¸ªè¿‡ç¨‹æˆ‘ä¸€ç›´åœ¨ä½¿ç”¨ Stack Overflow
    è°ƒæŸ¥æ•°æ®ï¼Œå› ä¸ºæˆ‘å–œæ¬¢å‘å¤§å®¶å±•ç¤ºè¿™äº›æ¦‚å¿µå¦‚ä½•åœ¨ç°å®ä¸–ç•Œä¸­åº”ç”¨ã€‚ä½†æˆ‘ä»¬çš„ Stack Overflow è°ƒæŸ¥æ•°æ®æ²¡æœ‰ä»»ä½•æˆ‘ä»¬å¯ä»¥å®é™…å¤„ç†çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚
- en: So I'm gonna to be using a different data set for the next videoã€‚ and I still
    haven't narrowed down exactly what I'll be usingã€‚ but I'll be sure that it allows
    us to do some analysis on some real worldor data like we've been doingã€‚ So maybe
    we'll use time series data to analyze cryptocurrency rates over time or something
    like thatã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ä½¿ç”¨ä¸€ä¸ªä¸åŒçš„æ•°æ®é›†ã€‚æˆ‘è¿˜æ²¡æœ‰ç¡®å®šå…·ä½“ä½¿ç”¨ä»€ä¹ˆï¼Œä½†æˆ‘ä¼šç¡®ä¿å®ƒèƒ½è®©æˆ‘ä»¬å¯¹ä¸€äº›ç°å®ä¸–ç•Œçš„æ•°æ®è¿›è¡Œåˆ†æï¼Œå°±åƒæˆ‘ä»¬ä¸€ç›´åœ¨åšçš„é‚£æ ·ã€‚ä¹Ÿè®¸æˆ‘ä»¬ä¼šä½¿ç”¨æ—¶é—´åºåˆ—æ•°æ®æ¥åˆ†æåŠ å¯†è´§å¸çš„æ±‡ç‡å˜åŒ–ï¼Œæˆ–è€…å…¶ä»–ç±»ä¼¼çš„å†…å®¹ã€‚
- en: But if anyone has any questions about what be covered in this video then feel
    free to ask in the comment section below and I'll do my best to answer thoseã€‚
    And if you enjoy these tutorials and would like to support themã€‚ then there are
    sub ways you can do thatã€‚ The easiest ways to simply like the video and give it
    a thumbs upã€‚ and also it's a hugeã€‚ğŸ˜Šï¼ŒTo share these videos with anyone who you
    think would find them usefulã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœä»»ä½•äººå¯¹æœ¬è§†é¢‘ä¸­çš„å†…å®¹æœ‰ç–‘é—®ï¼Œè¯·éšæ—¶åœ¨ä¸‹é¢çš„è¯„è®ºéƒ¨åˆ†æé—®ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ã€‚å¦‚æœä½ å–œæ¬¢è¿™äº›æ•™ç¨‹å¹¶å¸Œæœ›æ”¯æŒå®ƒä»¬ï¼Œè¿˜æœ‰å…¶ä»–æ–¹å¼å¯ä»¥åšåˆ°ã€‚æœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯ç‚¹èµå¹¶ç»™è§†é¢‘ä¸€ä¸ªå¥½è¯„ã€‚æ­¤å¤–ï¼Œåˆ†äº«è¿™äº›è§†é¢‘ç»™ä»»ä½•ä½ è®¤ä¸ºä¼šè§‰å¾—æœ‰ç”¨çš„äººä¹Ÿéå¸¸é‡è¦ã€‚ğŸ˜Šã€‚
- en: And if you have the meansï¼Œ you can contribute through Patreonã€‚ And there's a
    link to that page and in the description section belowã€‚ Be sure to subscribe for
    future videosã€‚ And thank you all for watchingã€‚ğŸ˜Šã€‚![](img/f3f6adee5351ab52b6113da712018c15_13.png)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æœ‰èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡ Patreon è¿›è¡Œæ”¯æŒã€‚é“¾æ¥åœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†ã€‚è¯·åŠ¡å¿…è®¢é˜…ä»¥è·å–æœªæ¥çš„è§†é¢‘ã€‚æ„Ÿè°¢å¤§å®¶çš„è§‚çœ‹ã€‚ğŸ˜Šã€‚![](img/f3f6adee5351ab52b6113da712018c15_13.png)
