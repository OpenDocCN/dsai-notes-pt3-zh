- en: 【双语字幕+资料下载】用 Pandas 进行数据处理与分析！真实数据&实时讲解，学完就能上手做数据分析了！＜实战教程系列＞ - P9：9）数据清洗 -
    转换数据类型和处理缺失值 - ShowMeAI - BV1M64y187bz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】用 Pandas 进行数据处理与分析！真实数据&实时讲解，学完就能上手做数据分析了！＜实战教程系列＞ - P9：9）数据清洗 -
    转换数据类型和处理缺失值 - ShowMeAI - BV1M64y187bz
- en: Hey there。 How's it going， everybody。 In this video。 we're gonna be learning
    how to handle missing values and also how to clean up our data a bit。 Now。 almost
    every data set that you're gonna to be working with is likely going to have some
    missing data or data that we'd like to clean up or convert to a different data
    type。 So we'll learn how to do all of that here。 Now， towards the end of the video。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大家好，你们过得怎么样？在这个视频中，我们将学习如何处理缺失值，以及如何稍微清理一下我们的数据。几乎每一个你要处理的数据集都有可能包含一些缺失数据，或者是我们希望清理或转换为不同数据类型的数据。因此，我们将在这里学习如何做到这一切。现在，视频接近尾声时。
- en: We'll combine what we learned here to be able to look at our stack overflow
    survey data。 And calculate the average years of experiences of developers who
    answered the survey。 So be sure to stay around for that。 And it's going to be
    great practice for what we learned here。 Now， I would like to mention that we
    do have a sponsor for this series of videos。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将结合在这里学到的内容，能够查看我们的 Stack Overflow 调查数据，并计算回答调查的开发者的平均工作年限。所以一定要保持关注，这将是对我们在这里所学内容的极佳实践。现在，我想提到的是，我们确实有这系列视频的赞助商。
- en: And that is brilliant。 So I really want to thank brilliant for sponsoring the
    series。 and it'll be great if you all can check them out using the link in the
    description section below and support the sponsors。 And I'll talk more about their
    services in just a bit。 So with that said。 let's go ahead and get started。 Okay，
    so first， let's talk about how to drop missing values。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是太棒了。因此，我非常感谢 Brilliant 赞助了这个系列。如果你们能通过下面描述部分的链接去了解他们，那将是极好的，并支持我们的赞助商。我会在稍后详细谈谈他们的服务。那么，就让我们开始吧。好的，首先，让我们谈谈如何删除缺失值。
- en: So I have my snippets file open here。 And we've seen this in previous videos。
    And again。 if anyone wants to follow along。😊，Then I'll have a link to all of these
    notebooks and the data in the description section below。 And as we've seen in
    previous videos， we'll learn how to do some of this in our smaller snippets data
    frame first And then we'll see how to do some interesting stuff on our larger
    stack overflow data set to get this working on some real worldorld data。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我这里打开了我的代码片段文件，我们在之前的视频中看到过这个。如果有人想跟着一起做。😊，我会在下面的描述部分提供所有这些笔记本和数据的链接。正如我们在之前的视频中看到的，我们将首先在较小的代码片段数据框中学习如何做其中的一些操作，然后再看看如何在更大的
    Stack Overflow 数据集上做一些有趣的事情，以便在一些真实世界的数据上进行工作。
- en: So for this video I've added some null values here into our snippets data frame
    that we didn't have before。 So I added some extra first names here。 And we can
    see that I just have one that is a nu do N。 which is a not a number value。 I also
    imported nu up here at the top。 this one here is just a nuvalue。 And then I also
    have some custom missing values as well。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个视频中，我在我们的代码片段数据框中添加了一些之前没有的空值。我添加了一些额外的名字，我们可以看到我这里只有一个是 nu do N，也就是不是数字的值。我在顶部也导入了
    nu，这里只是一个 nu 值。我还添加了一些自定义缺失值。
- en: This one is just a string of NA and this one is just a string of missing。 So
    I have some Ns some nuns and stuff like that thrown throughout this data so that
    we have some missing values。 So you're gonna to see this a lot that when we work
    with pandas。😊。We're going to have some missing data And depending on what it is
    you're trying to do。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这个只是一个 NA 字符串，而这个只是一个缺失的字符串。因此，我在数据中随意放了一些 N、一些 nuns 等等，以便我们有一些缺失值。所以你会看到，当我们使用
    pandas 时，这种情况会经常出现。😊我们会有一些缺失数据，具体取决于你想做什么。
- en: you might want to handle this in different ways。 So one thing you might want
    to do with missing data is to simply remove it。 So for our small data frame here。
    let's say that we're going to do some analysis with these people in the data frame。
    but if they don't have their first name last name and email address then we can't
    do what we're trying to do So we'll just remove the rows that don't have those
    values。 So in order to do this， we can use the drop in a method。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想用不同的方法处理缺失数据。所以，你可能想做的一件事就是简单地删除它。对于我们这里的小数据框来说，假设我们要对数据框中的这些人进行一些分析，但如果他们没有名字、姓氏和电子邮件地址，那么我们就无法进行所需的操作。因此，我们将删除那些缺少这些值的行。为了做到这一点，我们可以使用`drop`方法。
- en: So let's do this and then I'll explain the results and go over those So all
    I'm going to do down here with my data frame is I'm gonna to say Df drop in a
    and we're gonna to run that without any arguments right now So when we run this
    we can see that now we only get four rows of data here And up here we had let's
    see45。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们这样做，然后我会解释结果并讨论这些。因此，我在这里对我的数据框所做的只是说Df drop in a，我们现在将不带任何参数运行它。因此，当我们运行时，我们可以看到现在我们只得到四行数据，而在上面我们有45行。
- en: 67。 So we got these four rows here because they didn't have any missing values。
    Now we do still have our bottom row here。Which has some of our custom missing
    values。 But we'll see how to deal with these in just a second。 But for now。 let's
    go over what drop in a is actually doing here。 Now。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们得到了这四行，因为它们没有缺失值。现在我们底部的这一行仍然存在，这里有一些自定义缺失值。但我们将看看如何处理这些。不过现在，让我们讨论一下drop
    in a实际上在这里做了什么。
- en: what's going on in the background is that drop in a is using some default arguments。
    So I'm going to manually fill in these default arguments。 And it might make more
    sense why we got this specific results。 So by default。 I'll leave that one here。
    And now I'm going to fill in drop in a again。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的背景是drop in a正在使用一些默认参数。所以我将手动填写这些默认参数。这样可能会更清楚我们为什么得到这个具体的结果。因此默认情况下，我将留那个参数在这里。现在我再次填写drop
    in a。
- en: but I'm going to put the default arguments that it already has。 and the default
    arguments of what this is doing in the background is it has an axis set to index。
    and it has a how variable set to any。 So since this is what the method was using
    by default anyway。 we should go ahead and get the same results here and we can
    see that we do。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但我将放入它已经拥有的默认参数。这个在后台的默认参数是它将轴设置为索引，并将how变量设置为任何。所以由于这正是该方法默认使用的，我们应该得到相同的结果，我们可以看到确实如此。
- en: we get the same results as we did when we ran this up here。 But now let me actually
    explain these arguments here。 So first， we have the axis arguments。 So this can
    either be set to index。Were set to columns。 That is going to tell pandas that
    we want to drop in values when our rows are missing values when it's set here
    to index。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的结果与我们在上面运行时是一样的。但现在让我解释一下这些参数。首先，我们有轴参数。这个可以设置为索引或列。这将告诉pandas我们希望在行缺失值时丢弃值，当这里设置为索引时。
- en: If we set this to columns， then it would instead drop columns if they had missing
    values。 And we'll look at that in just a second。 Now， the second argument here
    is how we want to drop these。 or I guess a better way to frame that is this is
    the criteria that it uses for dropping a row or a column。 So by default， this
    is set to any。 So we're looking over our rows since this is set to index。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将此设置为列，那么如果列中有缺失值，它将会丢弃列。我们马上会讨论这个。现在，第二个参数是我们想如何丢弃这些。或者我想说一个更好的方式是，这是它用来丢弃行或列的标准。因此默认情况下，这被设置为任何。所以我们在查看行，因为这被设置为索引。
- en: And this is set to any here。 So it will drop rows with any missing values。 But
    this might not be what you want。 Maybe with this kind of an analysis that we're
    doing。 It's okay to have you know missing email or last name or something like
    that。 But there just has to be something。 It can't just be an entire row of missing
    values。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里也被设置为任何。因此它将丢弃任何有缺失值的行。但这可能不是你想要的。也许在我们进行的这种分析中，有缺失的电子邮件或姓氏是可以的。但必须有某些内容。不能整行都是缺失值。
- en: So if that's the case， then we can instead change this， how argument to。All。And
    this will then only drop rows when all of the values in that row are missing。
    So now if I run this， then we can see that now we get back more rows than we did
    before。 because it kept the rows that had some missing values。 but not all missing
    values。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果是这样的话，我们可以将这个how参数改为All。这样只有当该行中的所有值都缺失时，才会丢弃行。因此现在如果我运行这个，我们可以看到我们得到了比之前更多的行，因为它保留了那些有一些缺失值，但不是全部缺失值的行。
- en: So we can see here we have an email missing， but there were some other columns
    filled in。 and we can see that everything was missing here， but they did have
    an email。 So all of the values have to be missing in order for this to actually
    drop those。 So it looks like we are missing index of four。 if I go up to a my
    original data frame here。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以看到这里缺失了电子邮件，但还有其他一些列是填好的。我们可以看到这里所有内容都缺失，但他们有电子邮件。因此，所有的值必须缺失，才能真正丢弃它们。因此看起来我们缺失索引4。如果我回到我的原始数据框这里。
- en: we can see that that index had all missing values there。 Okay。 now if I instead
    change this axis to columns instead of index。 then it will drop columns that have
    all missing values。 we don't have any columns that have missing values all the
    way down。 So it should just return our original data frame。 So if I say columns
    here and run this。 Then we can see。That's what we get because none of these columns
    have missing values all the way down Now。 if I set this back to the default and
    drop columns with any missing values。 then we'll actually get an empty data frame
    returned because we have one row that is completely empty that we saw here this
    index of four So for that row each column is going to have at least one missing
    value and if we set this to any then any column which is even a single missing
    value will be dropped which in this case is all of them So if I change this to
    any then since we have all missing values in one of these rows that's just going
    to give us an empty data frame now at this point you might be wondering okay well
    my data is a bit more complicated than this and I'm doing some of analysis where
    I want to drop some missing values but I only want to drop rows that are missing
    values in a specific column so for example。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到索引中有所有缺失值。好的。如果我将这个轴改为列而不是索引，那么它将删除所有缺失值的列。我们没有任何列是完全缺失值的。因此，它应该只返回我们的原始数据框。如果我在这里说列并运行这个。那么我们可以看到。这就是我们得到的，因为这些列没有完全缺失值。现在。如果我将其设置回默认值并删除任何缺失值的列。那么我们实际上会得到一个空的数据框，因为我们有一行是完全空的，这个索引为四。因此对于那一行，每一列至少会有一个缺失值。如果我们将此设置为任何，则任何具有单个缺失值的列都会被删除，而在这种情况下所有列都是这样的。如果我将此改为任何，那么由于其中一行的所有值都是缺失的，这将给我们一个空的数据框。此时你可能会想，好的，我的数据比这复杂一些，我正在进行一些分析，我想删除一些缺失值，但我只想删除在特定列中缺失值的行，所以例如。
- en: Let's say that we're doing some analysis on our data and it's fine if they don't
    have a first name or a last name。 but we really need the email address and if
    they don't have an email address。 then we need to just drop those rows。 So in
    order to do this we can pass in a subset argument。 So first I'm going to set our
    our access here back to index so that we're dropping rows and now we want to pass
    in a subset argument and this subset will be the column names that we're checking
    for missing values。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在对数据进行一些分析，如果他们没有名字或姓氏也没关系，但我们确实需要电子邮件地址。如果他们没有电子邮件地址，那么我们需要删除这些行。为了做到这一点，我们可以传入一个子集参数。所以首先我将我们的访问设置回索引，以便删除行，现在我们想传入一个子集参数，这个子集将是我们检查缺失值的列名。
- en: So in this case it's just going to be a single column So I'm going to say subset
    is equal to and I'm still going to pass in a list even though this is just a single
    column and I'll say email So if I run this then we can see that the data frame
    that we get back is full of rows that have at least their email address filled
    in and again this one down here with these in values that is our custom missing
    values and I'll show you how to treat those。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，它只会是一个单列。因此，我将说子集等于，我仍然会传入一个列表，即使这只是单个列，我会说电子邮件。所以如果我运行这个，我们可以看到返回的数据框充满了至少填入电子邮件地址的行。而且再次提到下面这个带有这些空值的行是我们自定义的缺失值，我会告诉你如何处理这些。
- en: Mising values in just a bit。 Now， in this case here。 since we're only passing
    in a single column for our subset。 our how argument here isn't really doing much
    because it's only going to look at the email address for missing values。 So if
    an email address isn't filled in then passing in either any or all for our argument
    here would trigger that row to be removed So even if I put this as all it should
    give us the same results because we're only checking one value。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值稍后再讨论。现在，在这种情况下，由于我们只传入一个单列作为我们的子集，我们的如何参数并没有真正发挥作用，因为它只会查看电子邮件地址的缺失值。因此，如果电子邮件地址没有填写，则在此处传入任何或所有参数都会触发该行被移除。所以即使我将其设置为所有，它也应该给我们相同的结果，因为我们只在检查一个值。
- en: but we can also pass in multiple columns to our subset。 So what if we said，
    okay， well。 in order for my data to be useful I need either their last name or
    their email address。 but I don't need both。 So in order to do this we could just
    say okay they need all of the。Values in last name and an email。 or I'm sorry there
    that I got that reversed。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们也可以将多个列传入我们的子集。那么如果我们说，好吧，为了使我的数据有用，我需要他们的姓氏或电子邮件地址，但不需要两个都提供。那么为了做到这一点，我们可以说，他们需要姓氏和电子邮件的所有值。抱歉，我把这个说反了。
- en: they don't need their last name in the email。 It just can't be that all of those
    values are missing。 So as long as the last name or the email is there。 Then it
    shouldn't drop those rows。 So if I run this。 Then we can see that we get some
    values that don't have an email。 but they did have a last name。 And also we would
    get back some values that didn't have a last name。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 他们不需要姓氏和电子邮件。只是不能所有这些值都缺失。所以只要姓氏或电子邮件存在，就不应该删除那些行。如果我运行这个，那么我们可以看到一些没有电子邮件的值，但它们有姓氏。我们还会得到一些没有姓氏的值。
- en: but do have an email just like this a nonin spun here， it has an email。 but
    it doesn't have a last name。 And again， that's because we passed in all for our
    how argument。 which means for a row to be dropped， both of the subset columns
    needed to be missing。 Now。 like we've seen in previous videos， This isn't permanently
    changing our data frame values。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但确实有一个电子邮件，就像这里的一个非内联元素，它有一个电子邮件。但它没有姓氏。而且，再次说明，这是因为我们在所有参数中传入了`how`。这意味着要删除一行，两个子集列都需要缺失。现在，正如我们在之前的视频中看到的，这并没有永久改变我们的数据框值。
- en: If we want to permanently change our data frame， then we'd have to add the inplace
    argument and set that equal to true here within this method。 But we've seen that
    a bunch throughout the series so far。I don't think I'll go over that again here。
    Okay， so now let's get to these custom missing values。 We can see down here that
    we have a row here that has some customized missing values。 So。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想永久改变我们的数据框，那么我们必须添加`inplace`参数并在这个方法中将其设置为`true`。但在这一系列中我们已经看过很多次。我觉得在这里不需要再重复。好的，现在让我们来看看这些自定义缺失值。我们可以看到这里有一行包含一些自定义的缺失值。
- en: for example， maybe the people who got our data from I didn't know what to do
    with missing values。 So instead， they just passed in a string of N or they passed
    in you know a string of missing like we have here。 So how would we actually handle
    these。 Well， it depends on how we load in our data。 In this case。 we've created
    our data frame from scratch by creating a dictionary and then creating our data
    frame here。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可能获取我们数据的人不知道如何处理缺失值。所以，他们只是传入了一个字符串“N”或者传入了一个像我们这里的“缺失”字符串。那么我们该如何处理这些呢？这取决于我们如何加载数据。在这种情况下，我们是通过创建一个字典并在这里创建数据框来从头开始创建我们的数据框。
- en: So what we can do here is just simply replace those values with an NN value。
    Now。 if we instead loaded in our data from a CV file。 then we could do something
    different。 But first。 I'll show this and then we'll take a look at the CV file
    later whenever I go over to the stack overflow data。 So right here at the top
    where we created our data frame。 I'm going to replace these values。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以在这里简单地将这些值替换为`NaN`值。现在，如果我们从一个CSV文件加载数据，那么我们可以做不同的事情。但首先，我将展示这个，然后在我查看Stack
    Overflow数据时再看看CSV文件。所以在我们创建数据框的顶部，我将替换这些值。
- en: With a proper nuy NAN value。 So to do this'm just going to go a couple lines
    down here and we've seen this in previous videos。 but we can use this replace
    here and I'm replacing all the values in the entire data frame。 So anytime we
    see a string of NA I'm going to replace that with nuy NA and again I am importing
    nuy up here asmp。 so that's where I'm getting I'm able to use nuy and then I want
    to say in place equal to true because we actually want to modify that data frame
    so if I run that then that would replace those values but I'm also going to place
    replace this string of missing as well withmp do NAN values and I want to do that
    in place as well。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合适的`NaN`值。因此，为了做到这一点，我将往下走几行，我们在之前的视频中看到过这个，但我们可以在这里使用`replace`，我将替换整个数据框中的所有值。所以每当我们看到一个“NA”字符串时，我将其替换为`NaN`，而且我在这里导入了`numpy`，所以我能够使用`numpy`，然后我想说`inplace`等于`true`，因为我们实际上想要修改那个数据框，所以如果我运行它，那么这将替换那些值，但我还将把这个缺失字符串也替换为`NaN`值，我也想这样做。
- en: So let's go ahead and run this that should replace those values。 And now if
    I look at our data frame here。 then we can see that we no longer have。That string
    of missing or N。 these are now all N N values。 And now if we go back through and
    we run ourselves where we dropped N values。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们继续执行这个操作，这应该替换那些值。现在如果我查看我们的数据框，可以看到我们不再有那串缺失或 N 的值。这些现在都是 N N 值。如果我们回过头来，运行删除
    N 值的操作。
- en: then these custom values should have been replaced and it should treat those
    as missing values。 So right here we can see what our previous result was where
    we got this index of 6 with those custom values if I rerun this now。 we can see
    that that's gone and the same with here if I rerun this， then that is gone as
    well。 Now。 if you don't actually want to make any changes， and we just want to
    see if certain values would or wouldn't be treated as NA values。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这些自定义值应该被替换，并且它应该将这些视为缺失值。所以在这里，我们可以看到之前的结果，其中自定义值的索引为 6，如果我现在重新运行，我们可以看到它消失了，同样在这里如果我重新运行，那么它也消失了。现在，如果你不想做任何更改，只想查看某些值是否会被视为
    NA 值。
- en: then we could just run the NA or is in a method and get a mask of values as
    to whether or not these classified as NA or not。 So let me just show you what
    I mean here。 So I could say Df dot is NA And this is just going to give us a mask
    here of values that whether or not they are classified as an N values。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以运行 NA or is in a 方法，得到一个值的掩码，以判断这些值是否被分类为 NA。让我向你展示我在这里的意思。我可以说 Df dot
    is NA，这将给我们一个值的掩码，表示它们是否被分类为 N 值。
- en: so we can see。That our row4 here was all NA values and so same thing with our
    row6 and we can see some other missing values throughout here as well。 Now sometimes
    especially when we're working with numerical data we might want to fill our NA
    values with a particular value Now I'm working with string data here but sometimes
    it make might make sense to fill your NA values with certain values with these
    as well。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，row4 这里全是 NA 值，row6 也是如此，我们还可以看到其他一些缺失值。现在，有时特别是处理数值数据时，我们可能想用特定值填充 NA
    值。现在我正在处理字符串数据，但有时用特定值填充 NA 值也是有意义的。
- en: So for example， let's assume that we were calculating grades for assignments
    or something like that and you had some assignments that were NA because the student
    never turned in the assignment Well at that point you could just decide if you
    wanted to score all missing assignments as zeros so that you could probably calculate
    up the grades so to do something like this we can use the fill NA method so for
    example I could say something like this if I do a Df do fill NA and then pass
    in a value。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们在为作业计算分数，或者类似的事情，而你有一些作业的值为 NA，因为学生从未提交作业。那么在那时你可以决定是否将所有缺失的作业记为零，以便你可以计算总分。因此，要做到这一点，我们可以使用
    fill NA 方法，例如我可以这样说，如果我做 Df do fill NA，然后传入一个值。
- en: Just to show you exactly what this is doing， I'm going to fill all of our missing
    values with this capitalized missing string here。 and if I run this， then we can
    see that all of those missing or all of those in values We're filled with this
    string capitalized as missing。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确切展示这在做什么，我将用这个大写的缺失字符串填充我们所有的缺失值。如果我运行这个，那么我们可以看到所有缺失的值，或所有的 N 值都被填充为这个大写的缺失字符串。
- en: Now， like I said before， I don't do this a lot with certain strings。 I found
    this to be most useful for numerical data depending on how you're doing your calculations。
    but you might want to give in values a value of0 or negative1 or something like
    that。 So if it would make sense with your data， and you had numerical data to
    replace your missing values with a0。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前所说，我并不常用某些字符串。我发现这对于数值数据最有用，具体取决于你如何进行计算。但是你可能想给 NA 值一个值，例如 0 或 -1 等。如果这与数据相符，并且你有数值数据，可以用
    0 替换缺失值。
- en: then you can just run Df fill in0。 And if I go ahead and run this。 then we can
    see that that works on our data frame as well。 And again。 just like with our other
    methods。 if you want those changes to your data frame to be permanent and carry
    over into other cells。 then simply just add that inplace argument and set that
    to true to。that change permanent。 Okay。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以运行 Df fill in0。如果我继续运行这个，我们可以看到这在我们的数据框中也有效。同样，就像我们之前的方法一样，如果你希望对数据框的更改是永久的，并且能在其他单元格中保留，只需添加
    inplace 参数并将其设置为 true，使更改永久化。好的。
- en: so now let's look at another common thing that we're likely going to need to
    do with a lot of our data。 And that is casting data types。 So I have another column
    in my snippets here that I didn't have in previous videos。 And I have up here，
    if we look， this is this age column。 So let's say that we wanted to get the average
    age of all the people in this sample data frame。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看我们可能需要处理的另一件常见事情。那就是转换数据类型。因此我在这里有另一列，这是我在之前视频中没有提到的。如果我们查看，这就是这个年龄列。所以假设我们想要获取这个样本数据框中所有人的平均年龄。
- en: Well， right now， these might look like numbers when we print them out in our
    data frame down here。 these are actually strings。 And we can see this if we look
    at our data frame data types。 So to do this， we can say Df do D types。 and that's
    not a method。 it's just an attribute。 So if I run this here。 And we can see that
    it says all of these columns are objects。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在这些在我们的数据框中打印出来时可能看起来像数字。实际上它们是字符串。我们可以通过查看数据框的数据类型来验证这一点。要做到这一点，我们可以说 Df
    的数据类型（D types）。这不是一个方法，而只是一个属性。所以如果我在这里运行它，我们可以看到所有这些列都是对象。
- en: And when it says it's an object， it likely means it's a string or a mix of different
    things。 So in the latest version of Python or pandas， I'm sorry， they actually
    updated it。 so that there's actually a string data type。Now but I'll do a video
    on those pandas version updates at the end of this series since they actually
    released that updated version as I was writing this course。 but don't worry， there's
    not a lot that's changed to where what you learn here will be outdated or anything
    like that it's still mostly the same but we can see here that our age column is
    a string because it's this object data type。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当它说这是一个对象时，可能意味着它是字符串或不同事物的混合。所以在 Python 或 pandas 的最新版本中，抱歉，它们实际上进行了更新，现在有一个字符串数据类型。但我会在这一系列的最后做一个关于
    pandas 版本更新的视频，因为在我编写这门课程时它们实际上发布了那个更新版本。但不用担心，这里学到的内容不会过时，基本上还是大同小异，但我们可以看到我们的年龄列是字符串，因为它是这个对象数据类型。
- en: So if we wanted the average age then it wouldn't work as it is now。 So let's
    just see what this error looks like。 So I'm going to grab the mean of that age
    column and if I run this then we can see that right now we get an error and if
    I scroll down to see what this error was。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们想要平均年龄，现在这样做是行不通的。那么让我们看看这个错误是什么样子的。我将获取那个年龄列的平均值，如果我运行这个，那么我们可以看到现在我们得到一个错误，如果我向下滚动看看这个错误是什么。
- en: it says can only concatenate STR not int to string Now that might not be the
    most easy to understand error right there but basically it's telling us that because
    that column is strings and not integers So we need to convert that column to numbers
    instead of a string。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示“只能将 STR 连接到字符串，而不是 int”。这可能不是最容易理解的错误，但基本上它告诉我们，因为那一列是字符串而不是整数，所以我们需要将该列转换为数字，而不是字符串。
- en: Now there's a caveat when doing this。 and this might throw some people off。
    So when we have NAN values in a column that we're trying to convert the numbers。
    then you need to use the float data type。 And that's because the NN value is actually
    a float under the hood。 let me go ahead and show this just to show you what this
    looks like。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在做这件事时有一个注意事项，这可能会让一些人困惑。所以当我们在尝试将列中的 NAN 值转换为数字时，你需要使用浮点数据类型。这是因为 NAN 值实际上是一个浮点数。让我继续演示一下，以便让你看看这是什么样子的。
- en: So I'm going to look up the type of N dot NA。 And we can see that that is a
    float。 So if we try to convert this column to integers， then it's going to throw
    an error when it runs into those NAN values because it can't convert those。 So
    if I was to say Df and。Of age is equal to。 And now let's try to convert these
    to integers。 So the way that you cast data types here is we can just say， okay，
    I want the age column as type。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我将查找 N dot NA 的类型。我们可以看到这是一个浮点数。如果我们尝试将这一列转换为整数，当遇到 NAN 值时就会抛出错误，因为它无法进行转换。因此，如果我说
    Df 的年龄（Of age）等于，然后我们尝试将这些转换为整数。这里转换数据类型的方式是，我们可以简单地说，我想将年龄列的类型设置为。
- en: and now we want to pass in the type that we want。 If I tried to convert these
    to integers。 Then this is going to give us an error。 because we have some N in
    values， So we can see here。 int argument must be a string not none type。 So when
    you're trying to convert these the numbers and you have those Nn values。 you basically
    have two options here。 If your column didn't have any missing values。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想传入我们想要的类型。如果我尝试将这些转换为整数，那么这会给我们一个错误，因为我们有一些naN值。所以我们可以看到，int参数必须是字符串，而不是none类型。因此，当你试图将这些数字转换时，如果有naN值，你基本上有两个选择。如果你的列没有任何缺失值。
- en: then this would just work fine。 We wouldn't even run into this error。 But if
    it does have missing values。 Then you can either convert those missing values
    to something else like a0 using the feel N method that we saw before。 or you can
    just cast that column to a float instead。 Now。 I think this would be a bad idea
    to convert those missing values to a0 or some other number。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就可以正常工作。我们甚至不会遇到这个错误。但如果确实有缺失值，你可以将那些缺失值转换为其他值，比如用我们之前看到的feel N方法将其转换为0，或者你也可以直接将该列转换为浮点数。现在，我认为将那些缺失值转换为0或其他数字是个坏主意。
- en: Because we're trying to compute the average in this case。 But depending on your
    data。 that might be what you want to do。 But I'm going to go ahead and just convert
    these to floats。 So those naN values stay missing values。 So instead of an nt
    here。 I'm just going to convert this to a float。 And if I run this， then that
    seem to have worked。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们试图计算这个案例中的平均值。但根据你的数据，这可能正是你想要做的。不过我会继续将这些转换为浮点数。所以那些naN值保持为缺失值。因此，在这里我不再使用nt，而是将其转换为浮点数。如果我运行这个，那么看起来是有效的。
- en: So now we can look at the data types again。 So I'll say Df whoops。 sorry I wouldn't
    typing in that cell。 I can say Df do D types。 And if we look at this。 then we
    can see that now our age is a float object here。 So now let's see what happens
    when we try to take the average of that column。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以再次查看数据类型。我可以说Df，哎呀，对不起，我在那个单元格里打错了。我可以说Df的dtypes。如果我们查看这个，我们可以看到现在我们的年龄是一个浮点对象。那么让我们看看当我们尝试计算该列的平均值时会发生什么。
- en: So I'll say Df do mean。 And if I run that， then we can see that we get the average
    value for those ages。 Now if you have an entire data frame of numbers or something
    like that that you're trying to convert all at once。 then the data frame object
    has an as type method as well。 So you could just say Df do as type。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我会说Df的mean。如果我运行这个，那么我们可以看到我们得到了这些年龄的平均值。现在，如果你有一个包含数字的整个数据框或者类似的东西，想要一次性转换，那么数据框对象也有一个as
    type方法。所以你可以直接说Df的as type。
- en: '![](img/f3f6adee5351ab52b6113da712018c15_1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_1.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_2.png)'
- en: Then passs in whatever data type you're trying to cast everything to and just
    convert everything in the data frame at once。 But we have some mixed columns here。
    so we don't want to do that。 Okay so we've been looking at our small data set
    right now to test this stuff out。 But now let's take what we learned here and
    learn how this applies to real worldorld data and do some analysis on our stack
    overflow survey data so first of all。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后传入你想要转换为的任何数据类型，并一次性转换数据框中的所有内容。但这里有一些混合列，所以我们不想这么做。好的，我们现在一直在查看我们的小数据集以测试这些内容。但现在让我们把在这里学到的知识应用到现实世界数据上，并对我们的Stack
    Overflow调查数据进行一些分析，所以首先。
- en: I mentioned earlier that if we had custom values for missing data then it's
    a little bit easier to handle these when loading in a cv and what I'm talking
    about up here is up here at the top where we replaced these custom missing values
    let me show you how we would do this same thing but loading in a cv instead So
    I'm gonna switch over here to my stack overflow survey data。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前提到过，如果我们有自定义的缺失数据值，那么在加载cv时处理这些会简单一些。我所说的在这里是我们在顶部替换这些自定义缺失值。让我给你展示如何在加载cv时做同样的事情。所以我将切换到我的Stack
    Overflow调查数据。
- en: let me go ahead and rerun this just to make sure that all of this stuff is running
    so this notebook still running that's good and again this is。Stack overflow data
    that we have been using throughout the series。 And if you'd like to follow along。
    then I do have a download link for this in the description section below。 Okay。
    so if I wanted to ignore those custom values when loading in a CSV。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我重新运行这一切，以确保所有这些内容都在正常运行，所以这个笔记本仍在运行，这很好，而且这仍然是我们在整个系列中使用的 Stack Overflow 数据。如果你想跟着操作，我在下面的描述部分有一个下载链接。好的，如果我想在加载
    CSV 时忽略这些自定义值。
- en: then we can simply pass in an argument of a list of values that we want to be
    treated as missing。 So here's how we would do this。 if we had some custom missing
    values here in this CSB file。 then I could simply create a list here of those
    missing values and。I will just call this in a vows。 And now I'll pass in a list
    of those。 So let's say that we have some values that are a string of N a and a
    string of missing。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以简单地传入一个我们希望视为缺失的值列表作为参数。那么我们可以这样做。如果在这个 CSV 文件中有一些自定义缺失值，我可以简单地创建一个缺失值的列表，并称之为“缺失值”。然后我将传入这个列表。假设我们有一些值是字符串“Na”和一个表示缺失的字符串。
- en: So now what we could do here is just add in an argument and say in a values
    is equal to。 and then that list that we just created。 And if we run that， then
    we shouldn't get any errors。 And when it reads in that CV， then it will treat
    that list of values。 as missing values and give them an in a in result。 Now， in
    this survey here。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们可以在这里添加一个参数，并说 Na 值等于我们刚刚创建的那个列表。如果我们运行这个，就不应该出现任何错误。当它读取这个 CSV 时，它会将那个值列表视为缺失值，并给出
    NaN 结果。现在，在这个调查中。
- en: they did a good job of not having any weird occurrences like that。 So that actually
    shouldn't change anything。 Okay， so now let's look at an interesting problem with
    casting some values。 So let's say that for the developers who answered this survey。
    we wanted to calculate the average number of years of coding experience among
    all of them。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 他们做得很好，没有出现任何奇怪的情况。因此，这实际上不应该改变任何内容。好吧，现在让我们看看一个有趣的问题，即如何转换一些值。假设对于回答了这项调查的开发者，我们想计算他们的平均编程经验年数。
- en: Now that might be a good thing to know to compare your experience against the
    average。But let's look at what this or why this might be difficult to calculate
    with this data set。 and us calculating this solution is actually going to apply
    several concepts that we've learned so far throughout this series。 So the column
    to view the answer for this question in the survey is called years code。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在了解这一点可能对比较你的经验与平均水平是有帮助的。但让我们看看为什么使用这个数据集来计算可能会比较困难。我们计算这个解决方案实际上会应用到我们在这一系列中学到的几个概念。所以在调查中查看这个问题答案的列称为“编程年限”。
- en: So let's look at some of these answers。 So I'm just going to look at the top
    10 answers for years code。So I will do a dot head。 and let's look at the top 10。
    So if I run this。 then at first glance。 this doesn't really look like it'll be
    a problem。 We just have a bunch of integers and the number of years that different
    respondents have been coding。 So you might think that we can just grab the mean
    of this column simply by saying， okay。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们看看这些答案。我将查看“编程年限”的前 10 个答案。所以我会使用 `.head()`，让我们看一下前 10 个结果。如果我运行这个，乍一看，这似乎并不会成为问题。我们只有一堆整数，表示不同受访者编程的年数。所以你可能会认为我们可以简单地通过说“好吧”来获取这一列的均值。
- en: if we just have a bunch of integers here and some Nn values， that's fine。 let's
    just grab the mean of that column。 But if I run this， then we get an error。 And
    if I scroll down here。 Then it says can only concatenate string to string。 And
    we saw the same error in our smaller data set where the column was actually being
    loaded in as a string instead of numerical data。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们这里只有一堆整数和一些 NaN 值，那也没问题。让我们直接计算这一列的均值。但如果我运行这个，就会出现错误。如果我向下滚动，这里显示只能将字符串与字符串连接。我们在较小的数据集中也看到了同样的错误，那时列实际上被加载为字符串而不是数值数据。
- en: And we should know how to handle this by now， since we did it in the smaller
    data set。 So let's try that。 So let's try to convert this to floats and then take
    the average。 So let me go back up here to the top where we。😊，And instead of running
    the mean here。 I'm going to say， okay， well， let's convert this to a float so
    that we can grab that average。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该知道如何处理这个问题，因为我们在小数据集中已经处理过了。让我们尝试一下。让我们尝试将其转换为浮点数，然后取平均值。所以让我回到顶部。😊而不是在这里运行
    mean。我将说，好吧，让我们将其转换为浮点数，以便可以获取平均值。
- en: So I will say as type。And we want to convert this to a float since there are
    N N values。 So if I run this。 then we still get an error。 So we didn't get an
    error in our smaller data set here。 So if I scroll down， then it says could not
    convert string to float。 And the string that it couldn't convert was less than
    one year。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我会说作为类型。我们想将其转换为浮点数，因为有 N N 值。所以如果我运行这个，我们仍然会得到一个错误。所以在我们的小数据集中没有出现错误。如果我向下滚动，它说无法将字符串转换为浮点数。无法转换的字符串是小于一年。
- en: So this might be something that we didn't expect here。 So obviously。 we don't
    just have numbers and N N values in this column。 There is actually a string value
    that respondents could select that is equal to this string of less than one year
    for coding experience。 So let's look at all the unique values of of this column
    so that we can see exactly what's in here in case there are more strings like
    this。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我们没有预料到的事情。显然，这一列不仅仅有数字和 N N 值。实际上，有一个字符串值，受访者可以选择，该值等于小于一年编程经验的字符串。所以让我们查看该列的所有唯一值，以便看到其中到底有什么，以防有更多类似的字符串。
- en: And I don't believe we've actually seen this in the series yet。 maybe we have。
    I can't really remember。 But if we want to view unique values of a series。 then
    we can simply use the unique method。 So we could also use the value counts method
    that we've seen several times before。If we want to count all the unique values，
    but we don't really want to count them。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我不相信我们在序列中实际上见过这个。也许我们见过。我记不太清楚。但如果我们想查看序列的唯一值，那么我们可以简单使用 unique 方法。所以我们也可以使用我们之前见过的
    value counts 方法。如果我们想计算所有唯一值，但我们其实并不想统计它们。
- en: we just want to see all the unique values in this column。 So to do this， I'm
    going to say。DF and then access that years code column dot unique。Dot unique。
    That is a method。 So if I run this。 whoops， and I spelled this wrong。 Sorry having
    a hard time typing today。 Okay， so if I run this。 then this gives us all of the
    unique values of that column。 And as we'd expect。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只想查看该列中的所有唯一值。为此，我将说。DF 然后访问该 years code 列的 unique。那是一个方法。所以如果我运行这个。哎呀，我拼写错了。抱歉，今天打字有点困难。好的，如果我运行这个。那么这将给我们该列的所有唯一值。正如我们所期待的。
- en: there are a lot of numbers。 But we see that we also have some strings that are
    mixed throughout these numbers。 Now we also have in A N values here。 but we're
    not going to worry about those。 we just want to ignore the N A N values， because
    that's just people who didn't answer the question。 But we can see that the strings
    that we have throughout here are less than one year。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多数字。但我们看到这些数字中也混杂了一些字符串。现在我们在这里也有 N A N 值，但我们不需要担心这些。我们只想忽略 N A N 值，因为这只是没有回答问题的人。但我们可以看到这里的字符串都是小于一年。
- en: and more than 50 years of coding experience。 Okay， so those are our only string
    values。 So I'm going to replace those with numbers so that we can get an idea
    of the average years。 people have been coding。 So let's go ahead and replace less
    than one year here with a0 since that's basically the same thing。 If somebody
    has been coding for less than a year than they've been coding for。Basically zero
    years。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 超过 50 年的编程经验。好的，这就是我们唯一的字符串值。所以我将用数字替换这些，以便我们能够了解人们编程的平均年限。所以我们继续将小于一年替换为 a0，因为这基本上是同样的意思。如果某人编程少于一年，那他们实际上编程的年限就是零年。
- en: so to do this。I can say D F dot years code and access that column。 and then
    we can just replace。That value of less than one year。And let's replace that with
    a0。 And we also want these to be in place equal to true because we actually want
    to modify that data frame。 So if I run that， then it should make that replacement。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 所以要做到这一点。我可以说 D F 点 years code 并访问该列。然后我们可以直接替换。将小于一年的值替换为 a0。我们还希望这些值的 in place
    等于 true，因为我们实际上想修改这个数据框。所以如果我运行这个，应该能进行替换。
- en: And now I'm also going to replace the value for more than 50 years here。 And
    this is going to rescue skew our results a bit， depending on how we want to do
    this。 I'm simply going to replace this with the value of 51。 there may be some
    people who have several more more years of coding experience than 51 years。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我还要替换这里超过50年的值。这将稍微影响我们的结果，具体取决于我们想怎么做。我只是简单地用51的值来替换它。可能有些人比51年有更多的编码经验。
- en: But I can't imagine that would be that many people who have， you know。 coded
    many years greater than 50。 So I'm going to just going to fill this in with 51。
    But like I said， depending on what we pick here， it could affect our results slightly。
    but not by a lot in this case。 So I'm just going to grab this same replace value
    here。 And instead。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但我无法想象会有那么多人，您知道。编码超过50年的。所以我只会用51来填充这个。但正如我所说，具体取决于我们在这里选择的内容，它可能会稍微影响我们的结果。但在这种情况下不会影响很多。所以我只是会抓取这个相同的替换值。然后。
- en: I want to replace more than 50 years。And I'm going to replace that with a value
    of 51。 So now。 let me go ahead and run this。 And if we want to look at these unique
    values again。 then we could look at these。 And now it doesn't look like we have
    any strings in here。 But we can see here that this is still a D type of object。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我想替换超过50年的数据。我将用51的值来替换它。那么现在。让我继续运行这个。如果我们想再次查看这些唯一值。然后我们可以查看这些。现在看起来这里没有任何字符串。但我们可以看到，这仍然是一个D类型的对象。
- en: which means that it's not actually reading this in as floats。 So if we scroll
    back up here a bit。 Oh， actually， I think I。Overwrote that line。 Yes， I did。 So
    let's just try that again， so。What I want to do here is I want to convert this
    to a float。 And this is what gave us an error before because we had these strings
    in here。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着实际上并没有将其作为浮点数读取。所以如果我们向上滚动一下。哦，实际上，我想我。覆盖了那一行。是的，我确实这样做了。那我们再试一次，所以。我要做的是将其转换为浮点数。这就是之前给我们带来错误的原因，因为我们这里有这些字符串。
- en: and it didn't know how to convert these to a float。 But now we should just be
    able to see say， okay。 I want to convert that。 as type set that to a float。 So
    let's run that。 And we didn't get an error this time。 So that's good。 And now
    we should be able to view the average numbers of or average number of years of
    coding experience of the developers who filled out this survey。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 它不知道如何将这些转换为浮点数。但现在我们应该只需要说，好吧。我想将其转换。将类型设置为浮点数。那么让我们运行一下。我们这次没有得到错误。这很好。现在我们应该能够查看填写了此调查的开发者的编码经验年数的平均值。
- en: So to do this。 I'm just going to say， okay， D F data frame。Access that column
    and grab the mean of that column。 So if I run this。 then we can see that now we
    get that average back。 So the average that we got here was about 11 and a half
    years of coding experience。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所以为了做到这一点。我将说，好吧，D F数据框。访问该列并获取该列的均值。所以如果我运行这个。然后我们可以看到现在我们得到了那个平均值。所以我们得到的平均值大约是11年半的编码经验。
- en: as the average years for developers who answered this survey。 And now you can
    do other analysis on this as well。 So， for example， if we wanted to see the median。
    Then I could run that。 And the median comes back as nine years of coding experience。
    So hopefully that real world example helped explain why it's important to know
    how to cast these values and understand what's going on there。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 作为回答此调查的开发者的平均年数。现在你也可以对此进行其他分析。所以，例如，如果我们想查看中位数。那么我可以运行这个。中位数返回为9年的编码经验。所以希望这个现实世界的例子有助于解释为什么了解如何转换这些值以及理解其中发生的事情是重要的。
- en: there's always going to be data that is messy or not in the format that we wanted
    in。 So knowing how to handle these missing values and cast these values to different
    data types is really going to be essential when working with pandas。 Okay， so
    before we end here， I'd like to thank the sponsor of this video and mention why
    I really enjoy their tutorials。 And that is brilliant。 So in this series， we've
    been learning about pandas and how to。😊。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 总会有一些数据是杂乱的或不是我们想要的格式。所以知道如何处理这些缺失值并将这些值转换为不同的数据类型在使用pandas时真的很重要。好的，所以在结束之前，我想感谢本视频的赞助商，并提到我为什么非常喜欢他们的教程。那就是brilliant。在这一系列中，我们一直在学习关于pandas的内容以及如何。😊。
- en: '![](img/f3f6adee5351ab52b6113da712018c15_4.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_4.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_5.png)'
- en: Analyze data in Python and brilliant would be an excellent way to supplement
    what you learn here with their handson courses。 They have some excellent courses
    and lessons that do a deep dive on how to think about and analyze data correctly。
    for data analysis fundamentals。 I would really recommend checking out their statistics
    course。 which shows you how to analyze graphs and determine significance in the
    data。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中分析数据，brilliant 将是补充你在这里所学内容的绝佳方式，他们提供了一些优秀的动手课程。这里有一些出色的课程和教程，深入讲解如何正确思考和分析数据。对于数据分析基础，我真的推荐你查看他们的统计课程，它展示了如何分析图表并确定数据的显著性。
- en: And I would also recommend their machine learning course which takes data analysis
    to a new level while you' about the techniques being used that allow machines
    to make decisions where there's just too many variables for a human to consider。
    So to support my channel and learn more about brilliant。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我还建议他们的机器学习课程，该课程将数据分析提升到一个新水平，讲述了允许机器在变量过多时做出决策的技术。为了支持我的频道并了解更多关于 brilliant
    的信息。
- en: you can go to brilliant org to sign up for free。 And also the first 200 people
    that go to that link will get 20% off the annual premium subscription。 and you
    can find that link in the description section below。 again。 that's brilliant org
    for so I think that's going to do it for this pandas video I hope you feel like
    you got a good idea for how to handle these missing values and cast our data to
    different。😊。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以访问 brilliant.org 免费注册。而且前 200 位访问该链接的人可以享受年度高级订阅的 20% 折扣。你可以在下面的描述部分找到该链接。再说一次，访问
    brilliant.org。我想这就是这段 pandas 视频的内容了，希望你对如何处理这些缺失值和将数据转换有了一个良好的理解。😊。
- en: '![](img/f3f6adee5351ab52b6113da712018c15_7.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_7.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_8.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_8.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_9.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_9.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_10.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_10.png)'
- en: '![](img/f3f6adee5351ab52b6113da712018c15_11.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3f6adee5351ab52b6113da712018c15_11.png)'
- en: Data typess so that we can do exactly what we want to do in terms of analyzing
    our data。 Now。 in the next video， we're gonna to be learning how to work with
    dates and time series data。 Now I've been using the stack overflow survey data
    for this entire series because I love being able to show you all realword examples
    of how these concepts apply。 But our stack overflow survey data doesn't have any
    time series data that we can actually work with。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型以便我们能够精确地分析我们的数据。现在，在下一个视频中，我们将学习如何处理日期和时间序列数据。此系列的整个过程我一直在使用 Stack Overflow
    调查数据，因为我喜欢向大家展示这些概念如何在现实世界中应用。但我们的 Stack Overflow 调查数据没有任何我们可以实际处理的时间序列数据。
- en: So I'm gonna to be using a different data set for the next video。 and I still
    haven't narrowed down exactly what I'll be using。 but I'll be sure that it allows
    us to do some analysis on some real worldor data like we've been doing。 So maybe
    we'll use time series data to analyze cryptocurrency rates over time or something
    like that。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我将在下一个视频中使用一个不同的数据集。我还没有确定具体使用什么，但我会确保它能让我们对一些现实世界的数据进行分析，就像我们一直在做的那样。也许我们会使用时间序列数据来分析加密货币的汇率变化，或者其他类似的内容。
- en: But if anyone has any questions about what be covered in this video then feel
    free to ask in the comment section below and I'll do my best to answer those。
    And if you enjoy these tutorials and would like to support them。 then there are
    sub ways you can do that。 The easiest ways to simply like the video and give it
    a thumbs up。 and also it's a huge。😊，To share these videos with anyone who you
    think would find them useful。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果任何人对本视频中的内容有疑问，请随时在下面的评论部分提问，我会尽力回答。如果你喜欢这些教程并希望支持它们，还有其他方式可以做到。最简单的方法就是点赞并给视频一个好评。此外，分享这些视频给任何你认为会觉得有用的人也非常重要。😊。
- en: And if you have the means， you can contribute through Patreon。 And there's a
    link to that page and in the description section below。 Be sure to subscribe for
    future videos。 And thank you all for watching。😊。![](img/f3f6adee5351ab52b6113da712018c15_13.png)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有能力，可以通过 Patreon 进行支持。链接在下面的描述部分。请务必订阅以获取未来的视频。感谢大家的观看。😊。![](img/f3f6adee5351ab52b6113da712018c15_13.png)
