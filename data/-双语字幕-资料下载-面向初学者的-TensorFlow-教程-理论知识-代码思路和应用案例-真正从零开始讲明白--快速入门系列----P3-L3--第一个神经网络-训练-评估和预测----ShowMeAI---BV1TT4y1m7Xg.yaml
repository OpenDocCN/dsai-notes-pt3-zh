- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P3ï¼šL3- ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ(è®­ç»ƒã€è¯„ä¼°å’Œé¢„æµ‹)
    - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P3ï¼šL3- ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œ(è®­ç»ƒã€è¯„ä¼°å’Œé¢„æµ‹)
    - ShowMeAI - BV1TT4y1m7Xg
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_0.png)'
- en: ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ welcomee to the third Tens offlow tutorialã€‚ Todayã€‚ we're going
    to build our first neural networkã€‚ I will not explain the theory here and instead
    focus on the implementationã€‚ but I will provide some links in the descriptionã€‚
    If you want to learn more about thisã€‚ And I will also provide the slidesï¼Œ as well
    as the code in my Github reportpoã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ï¼Œå˜¿ï¼Œå¤§å®¶ï¼Œæ¬¢è¿æ¥åˆ°ç¬¬ä¸‰ä¸ª Tensorflow æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ„å»ºæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œã€‚æˆ‘ä¸ä¼šåœ¨è¿™é‡Œè§£é‡Šç†è®ºï¼Œè€Œæ˜¯ä¸“æ³¨äºå®ç°ï¼Œä½†æˆ‘ä¼šåœ¨æè¿°ä¸­æä¾›ä¸€äº›é“¾æ¥ï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå†…å®¹ã€‚æˆ‘ä¹Ÿä¼šæä¾›å¹»ç¯ç‰‡ä»¥åŠæˆ‘çš„
    GitHub é¡¹ç›®ä¸­çš„ä»£ç ã€‚
- en: So we implement a neural network that will look like thisã€‚ Our neural network
    has multiple layersã€‚ and it gets an input imageï¼Œ and then it processes this imageï¼Œ
    and at the endã€‚ it produces a probability for each classã€‚ğŸ˜Šï¼ŒSo we have a multi
    class classification problem hereã€‚ And this means that at the endï¼Œ we use a soft
    max layer to get the probabilitiesã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®ç°çš„ç¥ç»ç½‘ç»œçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ã€‚æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæœ‰å¤šä¸ªå±‚ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªè¾“å…¥å›¾åƒï¼Œç„¶åå¤„ç†è¿™ä¸ªå›¾åƒï¼Œæœ€åäº§ç”Ÿæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚ğŸ˜Šï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™é‡Œæœ‰ä¸€ä¸ªå¤šç±»åˆ†ç±»é—®é¢˜ã€‚è¿™æ„å‘³ç€æœ€åæˆ‘ä»¬ä½¿ç”¨
    soft max å±‚æ¥è·å–æ¦‚ç‡ã€‚
- en: So this is what we are going to codeã€‚ And I promise that the final code will
    look relatively easy because Tensorflow takes care of a lot of things for usã€‚
    So even beginners should be able to build a neural network like thisã€‚ and Tensorflow
    provides two different kind of APIsï¼Œ the Kaas sequential API and the subclassing
    APIã€‚ The Kaas API abstracts away a lot of things and makes implementing the algorithms
    much easierã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬è¦ç¼–ç çš„å†…å®¹ã€‚æˆ‘ä¿è¯æœ€ç»ˆçš„ä»£ç çœ‹èµ·æ¥ç›¸å¯¹ç®€å•ï¼Œå› ä¸º Tensorflow ä¸ºæˆ‘ä»¬å¤„ç†äº†å¾ˆå¤šäº‹æƒ…ã€‚å› æ­¤å³ä½¿æ˜¯åˆå­¦è€…ä¹Ÿåº”è¯¥èƒ½å¤Ÿæ„å»ºè¿™æ ·çš„ç¥ç»ç½‘ç»œã€‚Tensorflow
    æä¾›ä¸¤ç§ä¸åŒç±»å‹çš„ APIï¼ŒKaas é¡ºåº API å’Œå­ç±»åŒ– APIã€‚Kaas API æŠ½è±¡äº†å¾ˆå¤šä¸œè¥¿ï¼Œä½¿å®ç°ç®—æ³•å˜å¾—æ›´åŠ å®¹æ˜“ã€‚
- en: So they say here that this one is for beginners and the other one is for expertsã€‚
    So I don't think that this is a good descriptionï¼Œ because I think that Kaas is
    good not just for beginnersã€‚ but it's also a good fit for experience programmersã€‚
    So this is a great API here and you can implement a lot of thingsã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä»–ä»¬è¯´è¿™ä¸ªé€‚åˆåˆå­¦è€…ï¼Œè€Œå¦ä¸€ä¸ªé€‚åˆä¸“å®¶ã€‚æˆ‘è®¤ä¸ºè¿™ä¸æ˜¯ä¸€ä¸ªå¥½çš„æè¿°ï¼Œå› ä¸ºæˆ‘è®¤ä¸º Kaas ä¸ä»…é€‚åˆåˆå­¦è€…ï¼Œä¹ŸåŒæ ·é€‚åˆæœ‰ç»éªŒçš„ç¨‹åºå‘˜ã€‚å› æ­¤è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„
    APIï¼Œä½ å¯ä»¥å®ç°å¾ˆå¤šä¸œè¥¿ã€‚
- en: And then only when you need more flexibility you can or should switch over to
    the subclassing APIã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_2.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åªæœ‰åœ¨ä½ éœ€è¦æ›´å¤šçµæ´»æ€§æ—¶ï¼Œä½ æ‰å¯ä»¥æˆ–åº”è¯¥åˆ‡æ¢åˆ°å­ç±»åŒ– APIã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_2.png)
- en: So in this beginner courseï¼Œ we concentrate on the Kaa sequential APIã€‚ but I
    will also cover the subclassing API in later episodesã€‚ So for now let's use the
    sequential API and let's jump to the codeã€‚ So I already imported Tenofflow and
    I silenced some warnings like in the last episode so you don't need to worry about
    thisã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªåˆå­¦è€…è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬é›†ä¸­åœ¨ Kaa é¡ºåº APIï¼Œä½†æˆ‘ä¼šåœ¨åé¢çš„å‰§é›†ä¸­æ¶µç›–å­ç±»åŒ– APIã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨é¡ºåº APIï¼Œè·³è½¬åˆ°ä»£ç ã€‚æˆ‘å·²ç»å¯¼å…¥äº†
    Tenofflowï¼Œå¹¶åƒä¸Šä¸€ä¸ªå‰§é›†é‚£æ ·å±è”½äº†ä¸€äº›è­¦å‘Šï¼Œæ‰€ä»¥ä½ ä¸ç”¨æ‹…å¿ƒã€‚
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_4.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_4.png)'
- en: And now let's start implementing our network with the Kaas APIã€‚ So we also say
    from Tensflowã€‚ we want to import Kaasã€‚ And since Tensorflowlow 2ï¼Œ this is includedã€‚
    So before it was a separate APIã€‚ But now it is fully integratedã€‚So then we also
    import nuy S N P and we import matplot Li do pi plot S PLT because I want to show
    you a plotã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å¼€å§‹ä½¿ç”¨ Kaas API å®ç°æˆ‘ä»¬çš„ç½‘ç»œã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿä» Tensorflow å¯¼å…¥ Kaasã€‚ç”±äº Tensorflow 2ï¼Œå·²ç»åŒ…å«è¿™ä¸ªå†…å®¹ã€‚å› æ­¤åœ¨æ­¤ä¹‹å‰ï¼Œå®ƒæ˜¯ä¸€ä¸ªå•ç‹¬çš„
    APIã€‚ä½†ç°åœ¨å®ƒå·²å®Œå…¨é›†æˆã€‚æ‰€ä»¥æˆ‘ä»¬è¿˜å¯¼å…¥ nuy S N Pï¼Œå¦å¤–å¯¼å…¥ matplot Li do pi plot S PLTï¼Œå› ä¸ºæˆ‘æƒ³ç»™ä½ å±•ç¤ºä¸€ä¸ªå›¾ã€‚
- en: And now let's get our data set firstã€‚ And in this tutorialï¼Œ we use the Mnis
    data setã€‚ So the famous data set for handwritten diit classificationã€‚ And this
    is included in Kas do data sets do Mniã€‚ And then we get training and testing sets
    by saying x train and Y trainã€‚ and then comma and then another tuple and then
    x test and y testã€‚ And this is Mist dot load dataã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å…ˆè·å–æ•°æ®é›†ã€‚åœ¨è¿™ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ Mnis æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªè‘—åçš„æ‰‹å†™æ•°å­—åˆ†ç±»æ•°æ®é›†ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«åœ¨ Kas do æ•°æ®é›†ä¸­ã€‚æ¥ç€æˆ‘ä»¬é€šè¿‡å£°æ˜
    x train å’Œ Y train è·å–è®­ç»ƒå’Œæµ‹è¯•é›†ï¼Œç„¶åæ˜¯é€—å·ï¼Œå†æ˜¯å¦ä¸€ä¸ªå…ƒç»„ï¼Œç„¶åæ˜¯ x test å’Œ y testã€‚è¿™æ˜¯ Mist.dot.load
    dataã€‚
- en: So we have to use two tuples here because this is what the load data returnsã€‚And
    thenï¼Œ for exampleã€‚ let's print X train dot shapeã€‚And let's also print Y train
    dot shapeã€‚ So now let's open our terminalã€‚ And here I' am already inside the virtual
    environment with Tensorflow installedã€‚ So let's run this fileã€‚So this is this
    file hereã€‚ And let's have a look at the shapeã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»åœ¨è¿™é‡Œä½¿ç”¨ä¸¤ä¸ªå…ƒç»„ï¼Œå› ä¸ºè¿™æ˜¯load dataè¿”å›çš„å†…å®¹ã€‚ç„¶åï¼Œä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬æ‰“å°X train.shapeã€‚è¿˜è®©æˆ‘ä»¬æ‰“å°Y train.shapeã€‚ç°åœ¨è®©æˆ‘ä»¬æ‰“å¼€ç»ˆç«¯ã€‚æˆ‘å·²ç»åœ¨å®‰è£…äº†Tensorflowçš„è™šæ‹Ÿç¯å¢ƒä¸­ã€‚æ‰€ä»¥è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªæ–‡ä»¶ã€‚è¿™æ˜¯è¿™ä¸ªæ–‡ä»¶ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å½¢çŠ¶ã€‚
- en: So we see our xtrain has this shapeï¼Œ so we have 60000 training imagesã€‚ and each
    image has the size 28 by 28ï¼Œ and then we have 60000 labels corresponding to the
    data here and by the wayã€‚ this is a nuy and D right nowï¼Œ so this is not a tens
    of load tensorã€‚ but we can still use it for our model thenã€‚ So the first thing
    I want to do is I want to normalize the data because right nowã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„xè®­ç»ƒæœ‰è¿™ä¸ªå½¢çŠ¶ï¼Œå› æ­¤æˆ‘ä»¬æœ‰60000ä¸ªè®­ç»ƒå›¾åƒã€‚æ¯ä¸ªå›¾åƒçš„å¤§å°ä¸º28Ã—28ï¼Œç„¶åæˆ‘ä»¬æœ‰60000ä¸ªä¸æ•°æ®å¯¹åº”çš„æ ‡ç­¾ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œè¿™ç°åœ¨æ˜¯NumPyæ•°ç»„ï¼Œå› æ­¤è¿™ä¸æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œä½†æˆ‘ä»¬ä»ç„¶å¯ä»¥å°†å…¶ç”¨äºæˆ‘ä»¬çš„æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘æƒ³åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å½’ä¸€åŒ–æ•°æ®ï¼Œå› ä¸ºç°åœ¨ã€‚
- en: the images have values between0 and 20055ã€‚ and we want to normalize this so
    that the values are between 0 and1ã€‚ So we say x strain and x test equals and then
    we say x strain divided by 255 as floatã€‚And the second one X tests divided by
    255ã€‚ So we can do this in one line for both data setsã€‚And now let me copy and
    paste some code in hereã€‚ So I want to plot the dataã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒçš„å€¼åœ¨0åˆ°20055ä¹‹é—´ã€‚æˆ‘ä»¬æƒ³è¦å°†å…¶å½’ä¸€åŒ–ï¼Œä½¿å€¼åœ¨0åˆ°1ä¹‹é—´ã€‚å› æ­¤æˆ‘ä»¬è¯´xè®­ç»ƒå’Œxæµ‹è¯•ç­‰äºï¼Œç„¶åæˆ‘ä»¬è¯´xè®­ç»ƒé™¤ä»¥255ä½œä¸ºæµ®ç‚¹æ•°ã€‚ç¬¬äºŒä¸ªæ˜¯xæµ‹è¯•é™¤ä»¥255ã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä¸­å¤„ç†è¿™ä¸¤ä¸ªæ•°æ®é›†ã€‚ç°åœ¨è®©æˆ‘åœ¨è¿™é‡Œå¤åˆ¶ç²˜è´´ä¸€äº›ä»£ç ã€‚æˆ‘æƒ³ç»˜åˆ¶æ•°æ®ã€‚
- en: So we just say P T I to plot6 different imagesã€‚ So the first six digitsã€‚ So
    let's run this and have a look at the plotã€‚ Allrightï¼Œ so this is what the plot
    looks likeã€‚ So here we see the handwritten diitsã€‚ So very simpleã€‚ And this is
    what we are going to classifyã€‚ So let's remove thisã€‚ and let's build our modelã€‚
    So let's build our modelã€‚ And as I saidã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åªè¯´PTIæ¥ç»˜åˆ¶6ä¸ªä¸åŒçš„å›¾åƒã€‚å‰å…­ä¸ªæ•°å­—ã€‚è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œçœ‹çœ‹å›¾çš„æ ·å­ã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯å›¾çš„æ ·å­ã€‚è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æ‰‹å†™æ•°å­—ï¼Œéå¸¸ç®€å•ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦åˆ†ç±»çš„å†…å®¹ã€‚è®©æˆ‘ä»¬å»æ‰è¿™ä¸ªï¼Œæ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚è®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚æ­£å¦‚æˆ‘æ‰€è¯´çš„ã€‚
- en: we are using the sequential APIã€‚ So we set model equalsã€‚ And this is a ks dot
    model dot sequentialã€‚ And here we pass in a list with all the different layersã€‚
    So similar like hereã€‚ we want to have different fully connected layersã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_6.png)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨é¡ºåºAPIã€‚æ‰€ä»¥æˆ‘ä»¬è®¾ç½®modelç­‰äºã€‚è¿™æ˜¯ks.model.sequentialã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä¼ å…¥ä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¸åŒå±‚çš„åˆ—è¡¨ã€‚ä¸è¿™é‡Œç±»ä¼¼ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰ä¸åŒçš„å…¨è¿æ¥å±‚ã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_6.png)
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_7.png)'
- en: So let's start with ks dot layers dot flattenã€‚ So this just flattens our image
    to be to reduce one dimension of this 28 times 28ã€‚And then we are going to use
    our first real fully connected layerã€‚ So we say ks dot layers dot denseã€‚ So the
    dense layer is the fully connected layer in the Kaas APIã€‚ And here we have to
    specify the outputã€‚ So this is a hidden size that we can specifyã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ä»ks.layers.flattenå¼€å§‹ã€‚è¿™å°†æˆ‘ä»¬çš„å›¾åƒå±•å¹³ï¼Œä»¥å‡å°‘è¿™ä¸€ç»´åº¦ï¼Œä»28Ã—28å˜ä¸º1ç»´ã€‚ç„¶åæˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªçœŸæ­£çš„å…¨è¿æ¥å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ks.layers.denseã€‚è¿™ä¸ªç¨ å¯†å±‚æ˜¯åœ¨Keras
    APIä¸­çš„å…¨è¿æ¥å±‚ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¿…é¡»æŒ‡å®šè¾“å‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥æŒ‡å®šçš„éšè—å¤§å°ã€‚
- en: So I am going to use 128ï¼Œ but you can use a different one hereã€‚ğŸ˜Šã€‚And then we
    also say activation equals reusã€‚ So we're going to use the reou activation functionã€‚
    So if you have a look againï¼Œ at this plotï¼Œ then usually all these layers are followed
    by activation functionsã€‚ So I have a full tutorial about activation functions
    in the pytorch beginner courseã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†ä½¿ç”¨128ï¼Œä½†ä½ å¯ä»¥åœ¨è¿™é‡Œä½¿ç”¨ä¸åŒçš„å€¼ã€‚ğŸ˜Šã€‚ç„¶åæˆ‘ä»¬è¿˜è¯´activationç­‰äºreluã€‚æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨reluæ¿€æ´»å‡½æ•°ã€‚å¦‚æœä½ å†çœ‹ä¸€ä¸‹è¿™ä¸ªå›¾ï¼Œé€šå¸¸è¿™äº›å±‚åé¢éƒ½æœ‰æ¿€æ´»å‡½æ•°ã€‚æˆ‘æœ‰ä¸€ä¸ªå…³äºæ¿€æ´»å‡½æ•°çš„å®Œæ•´æ•™ç¨‹åœ¨PyTorchåˆå­¦è€…è¯¾ç¨‹ä¸­ã€‚
- en: but the same concept applies here tooã€‚ So I will put the link in the descriptionã€‚
    and you can check it outã€‚ But basically what you should know is that it introduces
    nonlineityã€‚ and it improves the trainingã€‚ So it makes our model betterã€‚ So we
    should use a activation function after each of these layersã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ç›¸åŒçš„æ¦‚å¿µä¹Ÿé€‚ç”¨äºè¿™é‡Œã€‚æ‰€ä»¥æˆ‘ä¼šåœ¨æè¿°ä¸­æ”¾å…¥é“¾æ¥ï¼Œä½ å¯ä»¥æŸ¥çœ‹ã€‚ä½†åŸºæœ¬ä¸Šä½ åº”è¯¥çŸ¥é“çš„æ˜¯ï¼Œå®ƒå¼•å…¥äº†éçº¿æ€§ï¼Œå¹¶æ”¹å–„äº†è®­ç»ƒã€‚å®ƒä½¿æˆ‘ä»¬çš„æ¨¡å‹æ›´å¥½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨æ¯ä¸€å±‚åä½¿ç”¨æ¿€æ´»å‡½æ•°ã€‚
- en: and then so let's use just one in the middleã€‚ and then let's use our final layersã€‚
    So this is againã€‚ a dense layerã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_9.png)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°±ç”¨ä¸€ä¸ªåœ¨ä¸­é—´ã€‚ç„¶åä½¿ç”¨æˆ‘ä»¬çš„æœ€ç»ˆå±‚ã€‚è¿™åˆæ˜¯ä¸€ä¸ªç¨ å¯†å±‚ã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_9.png)
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_10.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_10.png)'
- en: And now we need to specify 10 outputsã€‚ So we want to haveã€‚ so we do have 10
    different classesã€‚ And for each classï¼Œ we need one outputã€‚ So So in this simple
    exampleã€‚ we only have two different classes doc and catã€‚ And that's why we only
    need two output layersã€‚ but in our exampleï¼Œ we have 10 classesã€‚ So that's why
    this must be 10ã€‚ So this has to be 10ã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬éœ€è¦æŒ‡å®š10ä¸ªè¾“å‡ºã€‚æ‰€ä»¥æˆ‘ä»¬å¸Œæœ›æœ‰ã€‚æˆ‘ä»¬ç¡®å®æœ‰10ä¸ªä¸åŒçš„ç±»åˆ«ã€‚æ¯ä¸ªç±»åˆ«æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¾“å‡ºã€‚åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªæœ‰ä¸¤ç§ä¸åŒçš„ç±»åˆ«ï¼šç‹—å’ŒçŒ«ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬åªéœ€è¦ä¸¤ä¸ªè¾“å‡ºå±‚ã€‚ä½†åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰10ä¸ªç±»åˆ«ã€‚æ‰€ä»¥è¿™å¿…é¡»æ˜¯10ã€‚è¿™å¿…é¡»æ˜¯10ã€‚
- en: but you can play around with this sizeã€‚ And then as I saidï¼Œ we want to get the
    probabilitiesã€‚ So that's why we need a soft marks layerã€‚ So we couldã€‚ we could
    include this here by saying ks dot layers dot soft marksã€‚ But actually in the
    tens of load docsï¼Œ they say that this is not recommend itã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ å¯ä»¥è°ƒæ•´è¿™ä¸ªå¤§å°ã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬æƒ³è¦å¾—åˆ°æ¦‚ç‡ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªsoft markså±‚ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´ks dot layers dot
    soft marksæ¥åŒ…å«å®ƒã€‚ä½†å®é™…ä¸Šåœ¨æ–‡æ¡£ä¸­ï¼Œä»–ä»¬è¯´è¿™ä¸æ¨èã€‚
- en: but instead you shouldã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_12.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç›¸åä½ åº”è¯¥ã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_12.png)
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_13.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_13.png)'
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_14.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_14.png)'
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_15.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_15.png)'
- en: Included in your loss function laterã€‚ So we leave this out for nowã€‚ So now this
    is all that we need for our model and our model can automatically determine the
    correct input sizesã€‚ we only need to specify the output sizesã€‚ but let's say after
    we create thisã€‚ we want to call model dot summary and we want to print thisã€‚ So
    right now this doesn't workã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„æŸå¤±å‡½æ•°ä¸­ç¨ååŒ…å«ã€‚å› æ­¤æˆ‘ä»¬æš‚æ—¶ä¸è€ƒè™‘è¿™ä¸€ç‚¹ã€‚ç°åœ¨è¿™å°±æ˜¯æˆ‘ä»¬æ¨¡å‹æ‰€éœ€çš„ä¸€åˆ‡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥è‡ªåŠ¨ç¡®å®šæ­£ç¡®çš„è¾“å…¥å¤§å°ã€‚æˆ‘ä»¬åªéœ€æŒ‡å®šè¾“å‡ºå¤§å°ã€‚ä½†å‡è®¾åœ¨åˆ›å»ºåï¼Œæˆ‘ä»¬æƒ³è°ƒç”¨model
    dot summaryå¹¶æ‰“å°å‡ºæ¥ã€‚ç›®å‰è¿™ä¸èµ·ä½œç”¨ã€‚
- en: But if we specify the first input sizeã€‚ So here we can say input shape equals
    and then 28 by 28ã€‚Then this worksã€‚ But you don't have to do thisã€‚ You can alsoã€‚
    it can also figure this out when you fit it to the training data laterã€‚ but then
    you can only print this after you compile your modelã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœæˆ‘ä»¬æŒ‡å®šç¬¬ä¸€ä¸ªè¾“å…¥å¤§å°ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥è¯´input shapeç­‰äº28ä¹˜28ã€‚é‚£ä¹ˆè¿™æ ·å°±æœ‰æ•ˆã€‚ä½†ä½ ä¸å¿…è¿™æ ·åšã€‚ä½ ä¹Ÿå¯ä»¥åœ¨åé¢å°†å…¶é€‚é…åˆ°è®­ç»ƒæ•°æ®æ—¶è®©å®ƒè‡ªåŠ¨è®¡ç®—ï¼Œä½†é‚£æ ·ä½ åªèƒ½åœ¨ç¼–è¯‘æ¨¡å‹åæ‰“å°ã€‚
- en: So it's a good practice to include this hereã€‚ So now let's save this and run
    this againã€‚ and then we will print the model summaryã€‚ And here I forgot to include
    an Sã€‚ So it's called Kara dot model dot sequentialã€‚Alrightï¼Œ so here this is the
    printed summariesã€‚ So it prints all the different layersã€‚ So here we see our first
    flattening layerã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡ŒåŒ…å«è¿™ä¸€ç‚¹æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚ç°åœ¨æˆ‘ä»¬ä¿å­˜å¹¶å†æ¬¡è¿è¡Œï¼Œç„¶åæˆ‘ä»¬å°†æ‰“å°æ¨¡å‹æ‘˜è¦ã€‚åœ¨è¿™é‡Œæˆ‘å¿˜äº†åŠ ä¸€ä¸ªSã€‚æ‰€ä»¥å®ƒå«Kara dot model dot sequentialã€‚å¥½çš„ï¼Œè¿™é‡Œæ˜¯æ‰“å°çš„æ‘˜è¦ã€‚æ‰€ä»¥å®ƒæ‰“å°å‡ºæ‰€æœ‰ä¸åŒçš„å±‚ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°ç¬¬ä¸€ä¸ªå±•å¹³å±‚ã€‚
- en: and this is the shape 784ã€‚ So this is 28 times 28ã€‚ It reduces it to one dimensionã€‚
    And this is not an actual layer that we have to trainã€‚ So it doesn't have parametersã€‚
    And we have our first dense layer with 128 output shapeã€‚ And this is the number
    of parametersã€‚ and then our second dense layer with 10 outputsã€‚ And hereï¼Œ the
    first one is just noneã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å½¢çŠ¶784ã€‚æ‰€ä»¥è¿™æ˜¯28ä¹˜28ã€‚å®ƒå°†å…¶å‡å°‘åˆ°ä¸€ç»´ã€‚è¿™ä¸æ˜¯æˆ‘ä»¬éœ€è¦è®­ç»ƒçš„å®é™…å±‚ã€‚æ‰€ä»¥å®ƒæ²¡æœ‰å‚æ•°ã€‚æˆ‘ä»¬æœ‰ç¬¬ä¸€ä¸ªè¾“å‡ºå½¢çŠ¶ä¸º128çš„ç¨ å¯†å±‚ã€‚ç„¶åæ˜¯ç¬¬äºŒä¸ªè¾“å‡º10çš„ç¨ å¯†å±‚ã€‚åœ¨è¿™é‡Œï¼Œç¬¬ä¸€ä¸ªåªæ˜¯noneã€‚
- en: So this is the number of samples that we don't know yetã€‚ğŸ˜Šã€‚And then we also see
    the total parameterss and the trainable parameterssã€‚Soï¼Œ yeahã€‚ so now we already
    have our modelã€‚ And by the wayï¼Œ so I think you can already see how simple it is
    with this sequential APIã€‚ And there's also a second way to do it with the sequential
    API so you can set up your model like thisã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬è¿˜ä¸çŸ¥é“çš„æ ·æœ¬æ•°é‡ã€‚ğŸ˜Šã€‚ç„¶åæˆ‘ä»¬ä¹Ÿçœ‹åˆ°äº†æ€»å‚æ•°å’Œå¯è®­ç»ƒå‚æ•°ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†æ¨¡å‹ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œæˆ‘æƒ³ä½ å¯ä»¥çœ‹åˆ°ä½¿ç”¨è¿™ä¸ªé¡ºåºAPIæ˜¯å¤šä¹ˆç®€å•ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ç¬¬äºŒç§ä½¿ç”¨é¡ºåºAPIçš„æ–¹æ³•ï¼Œå¯ä»¥åƒè¿™æ ·è®¾ç½®ä½ çš„æ¨¡å‹ã€‚
- en: And then at each layer separatelyã€‚ So you can call model dot atã€‚ And then you
    use this layerã€‚ and then you seeï¼Œ sayï¼Œ model dot atã€‚ And then you use this layerã€‚ğŸ˜Šã€‚Model
    dot at and the second layer and then model dot atã€‚ and the last layerã€‚ So this
    is doing the same thingã€‚ But this is the advantage that now you could print model
    summary after each operation and figure out how your training looksã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æ¯ä¸€å±‚åˆ†åˆ«è¿›è¡Œã€‚æ‰€ä»¥ä½ å¯ä»¥è°ƒç”¨ model dot atã€‚ç„¶åä½¿ç”¨è¿™ä¸€å±‚ã€‚ç„¶åä½ çœ‹åˆ°ï¼Œæ¯”å¦‚è¯´ï¼Œmodel dot atã€‚ç„¶åä½ ä½¿ç”¨è¿™ä¸€å±‚ã€‚ğŸ˜Šã€‚Model
    dot at ç¬¬äºŒå±‚ï¼Œç„¶å model dot atã€‚æœ€åä¸€å±‚ã€‚æ‰€ä»¥è¿™åœ¨åšåŒæ ·çš„äº‹æƒ…ã€‚ä½†è¿™å°±æ˜¯ç°åœ¨çš„ä¼˜åŠ¿ï¼Œä½ å¯ä»¥åœ¨æ¯ä¸ªæ“ä½œåæ‰“å°æ¨¡å‹æ‘˜è¦ï¼Œå¼„æ¸…æ¥šä½ çš„è®­ç»ƒæƒ…å†µã€‚
- en: Soï¼Œ yeahï¼Œ keep that in mind that you can do it like this as wellã€‚ So we're just
    going to use the first oneã€‚And comment this out againã€‚ So now we have our model
    and now the next thing we need is we need the loss and optimizerã€‚ So in a multiclass
    classification problemã€‚ typicallyy we use the categorical cross entropyã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå—¯ï¼Œè¯·è®°ä½ä½ ä¹Ÿå¯ä»¥è¿™æ ·åšã€‚æ‰€ä»¥æˆ‘ä»¬åªä¼šä½¿ç”¨ç¬¬ä¸€ä¸ªã€‚ç„¶åå†æ¬¡æ³¨é‡Šæ‰è¿™ä¸ªã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦çš„æ˜¯æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚åœ¨å¤šç±»åˆ†ç±»é—®é¢˜ä¸­ï¼Œé€šå¸¸æˆ‘ä»¬ä½¿ç”¨ç±»åˆ«äº¤å‰ç†µã€‚
- en: So we say loss equals and then we say ks dot lossesã€‚ And then here this is actually
    called sparse categorical cross entropyã€‚ And this is because our y is an integer
    class labelã€‚ So it's 0ï¼Œ1ï¼Œ2ï¼Œ3 or something like thatã€‚ And that's why we use this
    sometimes the label is also encoded as one hotã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´æŸå¤±ç­‰äºï¼Œç„¶åæˆ‘ä»¬è¯´ ks dot lossesã€‚ç„¶åè¿™é‡Œå®é™…ä¸Šå«åšç¨€ç–ç±»åˆ«äº¤å‰ç†µã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬çš„ y æ˜¯ä¸€ä¸ªæ•´æ•°ç±»æ ‡ç­¾ã€‚æ‰€ä»¥æ˜¯ 0ã€1ã€2ã€3
    æˆ–ç±»ä¼¼çš„ã€‚å› æ­¤æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªï¼Œæœ‰æ—¶æ ‡ç­¾ä¹Ÿç¼–ç ä¸º one hotã€‚
- en: So a one for the class 0 and then90s for theã€‚Other classesã€‚ So in this caseã€‚
    we just use the categorical cross entropyï¼Œ but in our caseï¼Œ we use this oneã€‚ And
    we also say from logics equals trueã€‚ And this is because here at the endã€‚ we didn't
    include the soft marksã€‚ So we still have the raw numbersï¼Œ the raw lasã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¯¹äºç±» 0 æ˜¯ 1ï¼Œç„¶åå¯¹äºå…¶ä»–ç±»æ˜¯ 90sã€‚æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªæ˜¯ä½¿ç”¨ç±»åˆ«äº¤å‰ç†µï¼Œä½†åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªã€‚è€Œä¸”æˆ‘ä»¬ä¹Ÿè¯´ from logics
    ç­‰äº trueã€‚è¿™æ˜¯å› ä¸ºåœ¨æœ€åï¼Œæˆ‘ä»¬æ²¡æœ‰åŒ…å« soft marksã€‚æ‰€ä»¥æˆ‘ä»¬ä»ç„¶æœ‰åŸå§‹æ•°å­—ï¼ŒåŸå§‹ lasã€‚
- en: So we have to use thisï¼Œ Otherwise it won't train very wellã€‚And then we need
    to create an optimizerã€‚ So we say Kas dot optimizersã€‚ And then hereï¼Œ let's use
    the Adamom optimizerã€‚ a very popular optimizerã€‚ and we need to give it a learning
    rateã€‚ So we say this is 0001ã€‚ So this is the one of the most important socalled
    hyperpar that you should tweak in the beginning to get a good resultã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¿…é¡»ä½¿ç”¨è¿™ä¸ªï¼Œå¦åˆ™è®­ç»ƒæ•ˆæœä¸ä¼šå¾ˆå¥½ã€‚ç„¶åæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªä¼˜åŒ–å™¨ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ Kas dot optimizersã€‚ç„¶åè¿™é‡Œï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ Adamom
    ä¼˜åŒ–å™¨ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„ä¼˜åŒ–å™¨ã€‚æˆ‘ä»¬éœ€è¦ç»™å®ƒä¸€ä¸ªå­¦ä¹ ç‡ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¿™æ˜¯ 0.0001ã€‚è¿™æ˜¯ä½ åœ¨å¼€å§‹æ—¶åº”è¯¥è°ƒæ•´ä»¥è·å¾—å¥½ç»“æœçš„æœ€é‡è¦çš„è¶…å‚æ•°ä¹‹ä¸€ã€‚
- en: So play around with thisã€‚ And then we also define some metrics that we want
    to trackã€‚ So in this caseï¼Œ and this should be a listã€‚ And here we only want to
    track the accuracy metricã€‚So when we have thisï¼Œ then we call model dot compileã€‚
    So this is what we do with the Tensorflow frameworkã€‚ And then we say our loss
    equals the lossã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥éšæ„å°è¯•ä¸€ä¸‹ã€‚ç„¶åæˆ‘ä»¬ä¹Ÿå®šä¹‰äº†ä¸€äº›æˆ‘ä»¬æƒ³è¦è·Ÿè¸ªçš„æŒ‡æ ‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™åº”è¯¥æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚æˆ‘ä»¬è¿™é‡Œåªæƒ³è·Ÿè¸ªå‡†ç¡®åº¦æŒ‡æ ‡ã€‚å› æ­¤å½“æˆ‘ä»¬æœ‰è¿™ä¸ªæ—¶ï¼Œæˆ‘ä»¬è°ƒç”¨ model
    dot compileã€‚è¿™æ˜¯æˆ‘ä»¬åœ¨ Tensorflow æ¡†æ¶ä¸­æ‰€åšçš„ã€‚ç„¶åæˆ‘ä»¬è¯´æˆ‘ä»¬çš„æŸå¤±ç­‰äºæŸå¤±ã€‚
- en: our optimizer equals the optimizer and the metrics equals the metricsã€‚ So this
    will configure the model for training and after that we can start the trainingã€‚
    So let's define the batch size and set this to 64 and set the number of epochs
    for our trainingã€‚ So here I only use5 epochs and then we can simply call model
    dot fit and we want to fit the x train and the Y trainã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ä¼˜åŒ–å™¨ç­‰äºä¼˜åŒ–å™¨ï¼ŒæŒ‡æ ‡ç­‰äºæŒ‡æ ‡ã€‚æ‰€ä»¥è¿™å°†ä¸ºè®­ç»ƒé…ç½®æ¨¡å‹ï¼Œä¹‹åæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒã€‚æ‰€ä»¥è®©æˆ‘ä»¬å®šä¹‰æ‰¹é‡å¤§å°å¹¶å°†å…¶è®¾ç½®ä¸º 64ï¼Œè®¾ç½®æˆ‘ä»¬è®­ç»ƒçš„ epochs
    æ•°é‡ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘åªä½¿ç”¨ 5 ä¸ª epochsï¼Œç„¶åæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è°ƒç”¨ model dot fitï¼Œæˆ‘ä»¬æƒ³è¦æ‹Ÿåˆ x train å’Œ y trainã€‚
- en: So our training data and we specify the batch size equalã€‚The batch sizeã€‚And
    the epoch equals the epochã€‚And then we said shuffle equals trueã€‚ So this is the
    defaultã€‚ but I want to stress this that you should always do this during trainingã€‚
    And then let's set ver equals 2ã€‚ So this is just for logging0 means no output
    1 means a progress bar and two means normal loggingã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬æŒ‡å®šæ‰¹é‡å¤§å°ç­‰äºã€‚æ‰¹é‡å¤§å°ã€‚ç„¶å epoch ç­‰äº epochã€‚ç„¶åæˆ‘ä»¬è¯´ shuffle ç­‰äº trueã€‚è¿™æ˜¯é»˜è®¤å€¼ã€‚ä½†æˆ‘æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œåœ¨è®­ç»ƒæœŸé—´ä½ åº”è¯¥å§‹ç»ˆè¿™æ ·åšã€‚ç„¶åè®©æˆ‘ä»¬å°†
    ver è®¾ç½®ä¸º 2ã€‚è¿™åªæ˜¯ç”¨äºæ—¥å¿—è®°å½•ï¼Œ0 è¡¨ç¤ºæ²¡æœ‰è¾“å‡ºï¼Œ1 è¡¨ç¤ºè¿›åº¦æ¡ï¼Œ2 è¡¨ç¤ºæ­£å¸¸æ—¥å¿—è®°å½•ã€‚
- en: So this is all that we have to do to train our modelã€‚ So againã€‚ we build our
    model with the sequential APIã€‚ Then we define the loss and the optr and optional
    sum metricsã€‚ So we don't have to use this hereã€‚ but we canã€‚ And then start the
    training with model dot fitã€‚ And now we can already start training thisã€‚Soï¼Œ let's
    run thisã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬è®­ç»ƒæ¨¡å‹æ‰€éœ€åšçš„ä¸€åˆ‡ã€‚å†è¯´ä¸€æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨é¡ºåº API æ¥æ„å»ºæ¨¡å‹ã€‚ç„¶åå®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œå¯é€‰çš„æ±‡æ€»æŒ‡æ ‡ã€‚æ‰€ä»¥è¿™é‡Œä¸ä¸€å®šéœ€è¦ä½¿ç”¨å®ƒï¼Œä½†æˆ‘ä»¬å¯ä»¥ã€‚ç„¶åå¼€å§‹è®­ç»ƒï¼Œä½¿ç”¨
    `model.fit`ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªã€‚
- en: So now we see that it's starting the training and after each epochï¼Œ it prints
    the somesymmetricã€‚ so it prints the loss and the accuracy because we specified
    thisã€‚And we see that after five epochsã€‚ we already have a very low lossã€‚ So this
    decreased and our accuracy is 98 per centã€‚ So our simple neural network is already
    very good for this taskã€‚Soï¼Œ nowã€‚That we trained itã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çœ‹åˆ°å®ƒå¼€å§‹è®­ç»ƒï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªçºªå…ƒä¹‹åï¼Œå®ƒæ‰“å°å‡ºä¸€äº›ä¿¡æ¯ã€‚å› æ­¤ï¼Œå®ƒæ‰“å°å‡ºæŸå¤±å’Œå‡†ç¡®ç‡ï¼Œå› ä¸ºæˆ‘ä»¬æŒ‡å®šäº†è¿™äº›ã€‚æˆ‘ä»¬çœ‹åˆ°ï¼Œåœ¨äº”ä¸ªçºªå…ƒä¹‹åï¼Œæˆ‘ä»¬å·²ç»å¾—åˆ°äº†ä¸€ä¸ªå¾ˆä½çš„æŸå¤±ã€‚å› æ­¤ï¼Œå®ƒé™ä½äº†ï¼Œæˆ‘ä»¬çš„å‡†ç¡®ç‡æ˜¯
    98%ã€‚æ‰€ä»¥æˆ‘ä»¬çš„ç®€å•ç¥ç»ç½‘ç»œå¯¹äºè¿™ä¸ªä»»åŠ¡å·²ç»éå¸¸å¥½äº†ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒå¥½äº†å®ƒã€‚
- en: What we want to do then is want to evaluate our modelã€‚ and we can also very
    simply do this with by saying model equal model dot evaluate and then we use our
    test dataã€‚ So we use X test and y testã€‚ And againï¼Œ here we use the or can use
    the batch size and set this to our batch sizeã€‚ and I also set ver both equals
    true equals2 for some loggingã€‚ So this is how we evaluate itã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æˆ‘ä»¬æƒ³è¦è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥éå¸¸ç®€å•åœ°é€šè¿‡è¯´ `model = model.evaluate` æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œç„¶åä½¿ç”¨æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨
    `X_test` å’Œ `y_test`ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ‰¹å¤§å°å¹¶å°†å…¶è®¾ç½®ä¸ºæˆ‘ä»¬çš„æ‰¹å¤§å°ã€‚æˆ‘è¿˜è®¾ç½®äº† `verbose = 2` ç”¨äºä¸€äº›æ—¥å¿—è®°å½•ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¯„ä¼°çš„æ–¹å¼ã€‚
- en: and so the batch size means that it takes some batches and performs the computations
    on the batchesã€‚ So this can make the training and evaluation faster and even and
    also improve the trainingã€‚ So let'sã€‚Let's run this againã€‚ So for nowï¼Œ I didn't
    save the modelã€‚ So now I have to train it again and then evaluate itã€‚ So let's
    run itã€‚ And in later episodesã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹å¤§å°æ„å‘³ç€å®ƒå¤„ç†ä¸€äº›æ‰¹æ¬¡å¹¶åœ¨è¿™äº›æ‰¹æ¬¡ä¸Šè¿›è¡Œè®¡ç®—ã€‚è¿™å¯ä»¥åŠ å¿«è®­ç»ƒå’Œè¯„ä¼°çš„é€Ÿåº¦ï¼Œç”šè‡³æ”¹å–„è®­ç»ƒã€‚æ‰€ä»¥è®©æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚ç°åœ¨æˆ‘æ²¡æœ‰ä¿å­˜æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘éœ€è¦å†æ¬¡è®­ç»ƒå®ƒï¼Œç„¶åè¿›è¡Œè¯„ä¼°ã€‚è®©æˆ‘ä»¬è¿è¡Œå®ƒã€‚åœ¨ä»¥åçš„ç« èŠ‚ä¸­ã€‚
- en: we learn how we save our model after the trainingã€‚ Alrightï¼Œ so training a done
    So againã€‚ we see the five different epochsã€‚ and then we have one print statement
    for the evaluationã€‚ So we see that it'sã€‚Slightly lowered the accuracy for the
    test setï¼Œ but it's still very goodã€‚ So now we already have a very good training
    to classify the amnes digitsã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•åœ¨è®­ç»ƒåä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ã€‚å¥½çš„ï¼Œè®­ç»ƒå®Œæˆäº†ã€‚å†è¯´ä¸€æ¬¡ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†äº”ä¸ªä¸åŒçš„çºªå…ƒï¼Œç„¶åæˆ‘ä»¬æœ‰ä¸€ä¸ªç”¨äºè¯„ä¼°çš„æ‰“å°è¯­å¥ã€‚æˆ‘ä»¬çœ‹åˆ°ï¼Œæµ‹è¯•é›†çš„å‡†ç¡®ç‡ç¨å¾®é™ä½äº†ï¼Œä½†ä»ç„¶éå¸¸å¥½ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªå¾ˆå¥½çš„è®­ç»ƒæ¨¡å‹æ¥åˆ†ç±»æ‰‹å†™æ•°å­—ã€‚
- en: And now let's see how we can do some predictions with our modelã€‚ So there we
    have several different optionsã€‚ and againã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_17.png)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œä¸€äº›é¢„æµ‹ã€‚æˆ‘ä»¬æœ‰å‡ ä¸ªä¸åŒçš„é€‰é¡¹ã€‚å†ä¸€æ¬¡ï¼[](img/3f9d346b7c507e285fe99bf4d69f54ed_17.png)
- en: For the predictionsï¼Œ we need the soft max layer to call the probabilitiesã€‚ So
    we didn'tã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_19.png)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºé¢„æµ‹ï¼Œæˆ‘ä»¬éœ€è¦è½¯æœ€å¤§å±‚æ¥è°ƒç”¨æ¦‚ç‡ã€‚æ‰€ä»¥æˆ‘ä»¬æ²¡æœ‰ï¼[](img/3f9d346b7c507e285fe99bf4d69f54ed_19.png)
- en: Put this in here as the last layerï¼Œ but it was automatically included here during
    the trainingã€‚ but now we need itã€‚ So our first option is to create a new new modelã€‚
    So let's call this probability modelã€‚ And this is also a Kaas dot model dot C
    sequential modelã€‚ And here this is one new thing that I want to show youã€‚ we can
    pass a whole model into thisã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å…¶æ”¾åœ¨è¿™é‡Œä½œä¸ºæœ€åä¸€å±‚ï¼Œä½†å®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å·²è‡ªåŠ¨åŒ…å«åœ¨å†…ã€‚ä¸è¿‡ç°åœ¨æˆ‘ä»¬éœ€è¦å®ƒã€‚æ‰€ä»¥æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªé€‰æ‹©æ˜¯åˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†å…¶ç§°ä¸ºæ¦‚ç‡æ¨¡å‹ã€‚è¿™ä¹Ÿæ˜¯ä¸€ä¸ª
    `keras.models.Sequential` æ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æƒ³ç»™ä½ å±•ç¤ºä¸€ä»¶æ–°äº‹ç‰©ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•´ä¸ªæ¨¡å‹ä¼ å…¥å…¶ä¸­ã€‚
- en: So we can put in our original modelã€‚ So now it has all of the layers of this
    modelã€‚ And now we use the kra dot layers dot softms layerã€‚ And now we that we
    have this we can call this probability modelã€‚ So we say predictions equals probability
    model and then passã€‚In the X test dataï¼Œ soã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬åŸæ¥çš„æ¨¡å‹ã€‚ç°åœ¨å®ƒæ‹¥æœ‰è¿™ä¸ªæ¨¡å‹çš„æ‰€æœ‰å±‚ã€‚ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ `kra.layers.softmax` å±‚ã€‚æ—¢ç„¶æˆ‘ä»¬æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨è¿™ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´
    `predictions = probability_model`ï¼Œç„¶åä¼ å…¥æµ‹è¯•æ•°æ® `X_test`ã€‚
- en: Now we have thisã€‚ we canï¼Œ for exampleï¼Œ get the first prediction by saying this
    is the predictions index0ã€‚ And let's print this hereã€‚ So print prediction 0ã€‚ And
    then this is the probabilityã€‚ So now we want to choose the class with the highest
    probabilityã€‚ So we can do this by calling the arc max functionã€‚ So we say label
    0 equals nuy dot arc maxã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´è¿™æ˜¯é¢„æµ‹ç´¢å¼•0æ¥è·å–ç¬¬ä¸€ä¸ªé¢„æµ‹ã€‚è®©æˆ‘ä»¬åœ¨è¿™é‡Œæ‰“å°è¿™ä¸ªã€‚æ‰€ä»¥æ‰“å°é¢„æµ‹0ã€‚è¿™æ˜¯æ¦‚ç‡ã€‚å› æ­¤ç°åœ¨æˆ‘ä»¬æƒ³é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨arc
    maxå‡½æ•°æ¥å®ç°è¿™ä¸€ç‚¹ã€‚å› æ­¤æˆ‘ä»¬è¯´æ ‡ç­¾0ç­‰äºnuy.dot arc maxã€‚
- en: and then of this prediction pre 0 and then print the label 0ã€‚ So now let's save
    thisã€‚ And now I run the training and evaluation again and then print this for
    youã€‚ Allrightï¼Œ so it's doneã€‚ And here it it prints the prediction 0ã€‚ So forã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_21.png)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ˜¯è¿™ä¸ªé¢„æµ‹pre 0ï¼Œç„¶åæ‰“å°æ ‡ç­¾0ã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªã€‚ç°åœ¨æˆ‘å†æ¬¡è¿è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œç„¶åä¸ºä½ æ‰“å°è¿™ä¸ªã€‚å¥½å§ï¼Œå®Œæˆäº†ã€‚åœ¨è¿™é‡Œå®ƒæ‰“å°å‡ºé¢„æµ‹0ã€‚æ‰€ä»¥å¯¹äºã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_21.png)
- en: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_22.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f9d346b7c507e285fe99bf4d69f54ed_22.png)'
- en: Each classï¼Œ it has a probabilityã€‚ and then we take the label or the index with
    the highest probabilitiesã€‚ This is index 7 in this caseã€‚ So I think it'sã€‚This
    oneã€‚ So 9ã€‚49ã€‚ This is the highest oneã€‚ So yeahã€‚ this worksã€‚ So this is the first
    way to do itã€‚ The second way is to use our original model plus the soft marks
    separatelyã€‚ So we can say the same as we are doing here predictions equalsã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªç±»åˆ«éƒ½æœ‰ä¸€ä¸ªæ¦‚ç‡ã€‚ç„¶åæˆ‘ä»¬è·å–å…·æœ‰æœ€é«˜æ¦‚ç‡çš„æ ‡ç­¾æˆ–ç´¢å¼•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ç´¢å¼•7ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºæ˜¯è¿™ä¸ªã€‚9.49ã€‚è¿™æ˜¯æœ€é«˜çš„ã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼Œè¿™å¯ä»¥å·¥ä½œã€‚è¿™æ˜¯å®ç°å®ƒçš„ç¬¬ä¸€ç§æ–¹æ³•ã€‚ç¬¬äºŒç§æ–¹æ³•æ˜¯åˆ†åˆ«ä½¿ç”¨æˆ‘ä»¬çš„åŸå§‹æ¨¡å‹åŠ ä¸Šsoft
    marksã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥è¯´å’Œæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„ä¸€æ ·ï¼Œé¢„æµ‹ç­‰äºã€‚
- en: And then we call the original model and pass an x testã€‚ And then we apply the
    soft marks for ourselvesã€‚ So we say predictions equals Tens offlow dot N N dot
    soft maxsã€‚ And then here we put in the predictionsã€‚ And now we have the same as
    we have hereã€‚ So let's print this oneã€‚ğŸ˜Šï¼ŒAnd then when we run this and print thisã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è°ƒç”¨åŸå§‹æ¨¡å‹å¹¶ä¼ å…¥xæµ‹è¯•ã€‚æ¥ç€æˆ‘ä»¬ä¸ºè‡ªå·±åº”ç”¨soft marksã€‚å› æ­¤æˆ‘ä»¬è¯´é¢„æµ‹ç­‰äºTens offlow.dot N N.dot soft maxsã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æ”¾å…¥é¢„æµ‹ã€‚ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†å’Œè¿™é‡Œç›¸åŒçš„ç»“æœã€‚è®©æˆ‘ä»¬æ‰“å°è¿™ä¸ªã€‚ğŸ˜Šï¼Œç„¶åå½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå¹¶æ‰“å°æ—¶ã€‚
- en: then we should see the exact exact same numbersã€‚Ohï¼Œ sorryï¼Œ I stopped this for
    nowã€‚ So here I forgot to get the prediction 0 so that we see this is the same
    hereã€‚So let's clear this and run it againã€‚ Alrightï¼Œ so againï¼Œ our training is
    doneã€‚ And here you can see that it prints the exact same numbers and the same
    class labelã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥çœ‹åˆ°å®Œå…¨ç›¸åŒçš„æ•°å­—ã€‚å“¦ï¼ŒæŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶åœæ­¢äº†è¿™ä¸ªã€‚å› æ­¤æˆ‘åœ¨è¿™é‡Œå¿˜è®°è·å–é¢„æµ‹0ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°è¿™é‡Œæ˜¯ç›¸åŒçš„ã€‚è®©æˆ‘ä»¬æ¸…é™¤è¿™ä¸ªå¹¶å†è¿è¡Œä¸€æ¬¡ã€‚å¥½å§ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„è®­ç»ƒå®Œæˆäº†ã€‚åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°å®ƒæ‰“å°å‡ºå®Œå…¨ç›¸åŒçš„æ•°å­—å’Œç›¸åŒçš„ç±»åˆ«æ ‡ç­¾ã€‚
- en: So you can do it like thisã€‚ And then as a third option instead of calling model
    and model like thisã€‚ you can also call model dot predictã€‚ and then the dataã€‚ And
    here you can also specify the batch size equals the batch sizeã€‚ then it computes
    it for each each batchã€‚ So this is also what you can doã€‚ and againã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è¿™æ ·åšã€‚ç„¶åä½œä¸ºç¬¬ä¸‰ç§é€‰æ‹©ï¼Œè€Œä¸æ˜¯åƒè¿™æ ·è°ƒç”¨æ¨¡å‹å’Œæ¨¡å‹ã€‚ä½ ä¹Ÿå¯ä»¥è°ƒç”¨model.dot predictã€‚ç„¶åæ˜¯æ•°æ®ã€‚åœ¨è¿™é‡Œä½ ä¹Ÿå¯ä»¥æŒ‡å®šæ‰¹å¤§å°ç­‰äºæ‰¹å¤§å°ã€‚ç„¶åå®ƒä¼šä¸ºæ¯ä¸ªæ‰¹æ¬¡è®¡ç®—ã€‚è¿™ä¹Ÿæ˜¯ä½ å¯ä»¥åšçš„ã€‚å†ä¸€æ¬¡ã€‚
- en: the numbers should be the sameã€‚And now let's not only get one single predictionã€‚
    So let's say we have two or five different predictionsã€‚ So let's call the 0ï¼Œ5sã€‚
    And then we get this by saying predictions and use slicing from index 0 to index
    5ã€‚And now let's print the pre0ï¼Œ5 dot shape first for youã€‚ And now if we call the
    arc max for thisã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°å­—åº”è¯¥æ˜¯ç›¸åŒçš„ã€‚ç°åœ¨æˆ‘ä»¬ä¸ä»…ä»…è¦å¾—åˆ°ä¸€ä¸ªé¢„æµ‹ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªæˆ–äº”ä¸ªä¸åŒçš„é¢„æµ‹ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸º0ï¼Œ5sã€‚ç„¶åæˆ‘ä»¬é€šè¿‡é¢„æµ‹å¹¶ä½¿ç”¨ä»ç´¢å¼•0åˆ°ç´¢å¼•5çš„åˆ‡ç‰‡æ¥å¾—åˆ°è¿™ä¸ªç»“æœã€‚ç°åœ¨æˆ‘ä»¬å…ˆä¸ºä½ æ‰“å°pre0ï¼Œ5çš„å½¢çŠ¶ã€‚ç°åœ¨å¦‚æœæˆ‘ä»¬å¯¹è¿™ä¸ªè°ƒç”¨arc
    maxã€‚
- en: So now let's say our label 0ï¼Œ5s equalsï¼Œ and then if we get the predictionsã€‚
    if we call the nuy dot arc maxï¼Œ with this5 predictionsã€‚ then we also have to specify
    the xã€‚ and in this caseï¼Œ we want to compute it along xs 1ã€‚And now we should get
    five different labelsã€‚ So print label 50sã€‚And now let's clear this and run it
    one more time and hope that this worksã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å‡è®¾æˆ‘ä»¬çš„æ ‡ç­¾0ï¼Œ5sç­‰äºï¼Œç„¶åå¦‚æœæˆ‘ä»¬è·å–é¢„æµ‹ã€‚å¦‚æœæˆ‘ä»¬è°ƒç”¨nuy.dot arc maxï¼Œå¹¶ä½¿ç”¨è¿™5ä¸ªé¢„æµ‹ã€‚ç„¶åæˆ‘ä»¬è¿˜å¿…é¡»æŒ‡å®šxã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æƒ³æ²¿ç€xs
    1è¿›è¡Œè®¡ç®—ã€‚ç°åœ¨æˆ‘ä»¬åº”è¯¥å¾—åˆ°äº”ä¸ªä¸åŒçš„æ ‡ç­¾ã€‚æ‰“å°æ ‡ç­¾50sã€‚ç°åœ¨è®©æˆ‘ä»¬æ¸…é™¤è¿™ä¸ªï¼Œå†è¿è¡Œä¸€æ¬¡ï¼Œå¸Œæœ›è¿™èƒ½æˆåŠŸã€‚
- en: Alrightï¼Œ so againï¼Œ this is doneã€‚ we see that againï¼Œ with this model predictã€‚
    We get the same numbersã€‚ And then this is our shapeã€‚ So 5 by 10 So  five different
    samples and or predictionsã€‚ and for each prediction10 different probabilities
    like hereã€‚ And if we call the arcms along X 1ã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæ‰€ä»¥è¿™å°±å®Œæˆäº†ã€‚æˆ‘ä»¬çœ‹åˆ°ï¼Œå†æ¬¡é€šè¿‡è¿™ä¸ªæ¨¡å‹é¢„æµ‹ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ç›¸åŒçš„æ•°å­—ã€‚ç„¶åè¿™æ˜¯æˆ‘ä»¬çš„å½¢çŠ¶ã€‚æ‰€ä»¥æ˜¯5ä¹˜10ï¼Œå³äº”ä¸ªä¸åŒçš„æ ·æœ¬å’Œé¢„æµ‹ã€‚å¯¹äºæ¯ä¸ªé¢„æµ‹ï¼Œæœ‰10ç§ä¸åŒçš„æ¦‚ç‡ï¼Œå¦‚è¿™é‡Œæ‰€ç¤ºã€‚å¦‚æœæˆ‘ä»¬æ²¿X
    1è°ƒç”¨arcmsã€‚
- en: then we get five different labelsã€‚ So againï¼Œ the first label is label 7 like
    hereã€‚ And these are the next predictionsã€‚ Yeahï¼Œ so this is how you can predict
    itã€‚ And I think this is all you should know to build your first neural networkã€‚
    So againã€‚ you build your sequential modelï¼Œ then you set up loss and optimizerï¼Œ
    Then you compile the modelã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¾—åˆ°äº†äº”ä¸ªä¸åŒçš„æ ‡ç­¾ã€‚å› æ­¤ï¼Œç¬¬ä¸€æ¬¡æ ‡ç­¾æ˜¯è¿™é‡Œçš„æ ‡ç­¾7ã€‚è¿™äº›æ˜¯æ¥ä¸‹æ¥çš„é¢„æµ‹ã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯ä½ å¦‚ä½•è¿›è¡Œé¢„æµ‹ã€‚æˆ‘è®¤ä¸ºè¿™å°±æ˜¯ä½ éœ€è¦çŸ¥é“çš„ï¼Œä»¥æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œã€‚å› æ­¤ï¼Œå†æ¬¡å¼ºè°ƒï¼Œä½ æ„å»ºä½ çš„é¡ºåºæ¨¡å‹ï¼Œç„¶åè®¾ç½®æŸå¤±å’Œä¼˜åŒ–å™¨ï¼Œç„¶åç¼–è¯‘æ¨¡å‹ã€‚
- en: Then you call model fit and model evaluateã€‚ And then when you want to predictã€‚
    you can call model predictã€‚ But yeahï¼Œ don't forget to call the soft marks if you
    want the actual probabilitiesã€‚ And yeahï¼Œ I think that's all for nowã€‚ And I hope
    you enjoyed this tutorialã€‚ Please hit the like button and consider subscribing
    to the channelã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ è°ƒç”¨æ¨¡å‹æ‹Ÿåˆå’Œæ¨¡å‹è¯„ä¼°ã€‚ç„¶åå½“ä½ æƒ³è¿›è¡Œé¢„æµ‹æ—¶ï¼Œå¯ä»¥è°ƒç”¨æ¨¡å‹é¢„æµ‹ã€‚ä¸è¿‡ï¼Œåˆ«å¿˜äº†å¦‚æœä½ æƒ³è¦å®é™…çš„æ¦‚ç‡ï¼Œè®°å¾—è°ƒç”¨è½¯æ ‡è®°ã€‚æ˜¯çš„ï¼Œæˆ‘æƒ³ç›®å‰å°±è¿™äº›ã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ã€‚è¯·ç‚¹å‡»å–œæ¬¢æŒ‰é’®ï¼Œå¹¶è€ƒè™‘è®¢é˜…é¢‘é“ã€‚
- en: And I hope to see you in the next video byã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_24.png)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚ğŸ˜Šã€‚![](img/3f9d346b7c507e285fe99bf4d69f54ed_24.png)
