- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘140åˆ†é’Ÿå…¥é—¨ PyTorchï¼Œå®˜æ–¹æ•™ç¨‹æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒç¬¬ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- ä½¿ç”¨ Captum
    è¿›è¡Œæ¨¡å‹ç†è§£ - ShowMeAI - BV19L4y1t7tu
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘140åˆ†é’Ÿå…¥é—¨PyTorchï¼Œå®˜æ–¹æ•™ç¨‹æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒç¬¬ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7- ä½¿ç”¨Captumè¿›è¡Œæ¨¡å‹ç†è§£
    - ShowMeAI - BV19L4y1t7tu
- en: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_0.png)'
- en: Welcome to the next video in the Pytorrch Tra seriesã€‚ This video gives an overview
    of Cap Pytorrch's tool set for model interpretabilityã€‚ğŸ˜Šï¼ŒIn this videoã€‚ we'll discussã€‚The
    basic concepts of captain that we'll be covering attributionsã€‚ attribution algorithms
    and visualizationsã€‚We'll demonstrate how to perform and visualize feature attributions
    for a computer vision classifierã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°PyTorch Traç³»åˆ—çš„ä¸‹ä¸€ä¸ªè§†é¢‘ã€‚è¿™ä¸ªè§†é¢‘æ¦‚è¿°äº†Captum PyTorchçš„æ¨¡å‹å¯è§£é‡Šæ€§å·¥å…·é›†ã€‚ğŸ˜Šåœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºCaptumçš„åŸºæœ¬æ¦‚å¿µï¼ŒåŒ…æ‹¬å½’å› ã€å½’å› ç®—æ³•å’Œå¯è§†åŒ–ã€‚æˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•ä¸ºè®¡ç®—æœºè§†è§‰åˆ†ç±»å™¨æ‰§è¡Œå’Œå¯è§†åŒ–ç‰¹å¾å½’å› ã€‚
- en: Will apply layer attribution to the same classifier to examine the activity
    of a model's hidden layersã€‚And finallyï¼Œ we'll look at captive insights and API
    for creating visualization widgets for imagesã€‚ text and other featuresã€‚![](img/2fb9bd9df95d3221c8b5a298fc267de0_2.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å¯¹åŒä¸€åˆ†ç±»å™¨åº”ç”¨å±‚å½’å› ï¼Œä»¥æ£€æŸ¥æ¨¡å‹éšè—å±‚çš„æ´»åŠ¨ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹Captumçš„è§è§£å’ŒAPIï¼Œä»¥åˆ›å»ºç”¨äºå›¾åƒã€æ–‡æœ¬å’Œå…¶ä»–ç‰¹å¾çš„å¯è§†åŒ–å°éƒ¨ä»¶ã€‚![](img/2fb9bd9df95d3221c8b5a298fc267de0_2.png)
- en: Captain provides a deep set of tools for explaining the behavior of your pietorrch
    modelsã€‚ This video and the accompanying interactive notebook provide only an overview
    of core featuresã€‚ The website at Captain AI contains more in depth tutorialsï¼Œ
    documentation and an API referenceã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Captumæä¾›äº†ä¸€å¥—æ·±å±‚å·¥å…·ï¼Œç”¨äºè§£é‡Šä½ çš„PyTorchæ¨¡å‹çš„è¡Œä¸ºã€‚è¿™ä¸ªè§†é¢‘å’Œé™„å¸¦çš„äº¤äº’å¼ç¬”è®°æœ¬ä»…æä¾›æ ¸å¿ƒåŠŸèƒ½çš„æ¦‚è¿°ã€‚Captum AIç½‘ç«™åŒ…å«æ›´æ·±å…¥çš„æ•™ç¨‹ã€æ–‡æ¡£å’ŒAPIå‚è€ƒã€‚
- en: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_4.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_4.png)'
- en: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_5.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_5.png)'
- en: To run the interactive notebook associated with this videoï¼Œ you'll want to install
    Python version 3ã€‚6 or higherã€‚Flaask 1ã€‚1 or higherï¼Œ and the latest versions of
    piey torchï¼Œ torch visionion and captainã€‚Captain can be easily installed with Pip
    or with Ananaconda by specifying the Pytorr channelã€‚To start withï¼Œ we're going
    to take a pre trained image classifierã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¿è¡Œä¸æ­¤è§†é¢‘ç›¸å…³çš„äº¤äº’å¼ç¬”è®°æœ¬ï¼Œä½ éœ€è¦å®‰è£…Python 3.6æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ŒFlask 1.1æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œä»¥åŠæœ€æ–°ç‰ˆæœ¬çš„PyTorchã€TorchVisionå’ŒCaptumã€‚Captumå¯ä»¥é€šè¿‡Pipæˆ–æŒ‡å®šPyTorché¢‘é“çš„Anacondaè½»æ¾å®‰è£…ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„å›¾åƒåˆ†ç±»å™¨ã€‚
- en: Resnet trained against the imagenet data setï¼Œ and we're going to use the tools
    within cap to gain insight into how the model responds to a particular input image
    to give its predictionã€‚This first sells a bunch of importsï¼Œ including attribution
    methods and visualization tools from captainã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ResNetåœ¨ImageNetæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Captumä¸­çš„å·¥å…·æ¥æ·±å…¥äº†è§£æ¨¡å‹å¦‚ä½•å“åº”ç‰¹å®šè¾“å…¥å›¾åƒä»¥ç»™å‡ºé¢„æµ‹ã€‚è¿™ä¸ªéƒ¨åˆ†åŒ…å«äº†ä¸€ç³»åˆ—å¯¼å…¥ï¼ŒåŒ…æ‹¬æ¥è‡ªCaptumçš„å½’å› æ–¹æ³•å’Œå¯è§†åŒ–å·¥å…·ã€‚
- en: which we'll examine shortlyã€‚Nextï¼Œ we'll get our pretrain modelã€‚Then we'll pull
    up an image to work with whereverver you got this video in the interactive notebook
    should also include a folder of images for use in this tutorialã€‚ In our caseï¼Œ
    it's going to be a catã€‚Next we'll define some image transforms to prepare the
    image for consumption by the modelã€‚And bring in the human readable labels of the
    thousand imagenet classesã€‚Nowã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¨åå°†å¯¹æ­¤è¿›è¡Œæ£€æŸ¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è·å–æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¼šè°ƒå‡ºä¸€å¼ å›¾åƒæ¥è¿›è¡Œå¤„ç†ï¼Œæ— è®ºä½ åœ¨äº¤äº’å¼ç¬”è®°æœ¬ä¸­è·å¾—äº†è¿™ä¸ªè§†é¢‘çš„å“ªä¸€éƒ¨åˆ†ï¼Œåº”è¯¥ä¹ŸåŒ…æ‹¬ç”¨äºæœ¬æ•™ç¨‹çš„å›¾åƒæ–‡ä»¶å¤¹ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå®ƒå°†æ˜¯ä¸€åªçŒ«ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€äº›å›¾åƒè½¬æ¢ï¼Œä»¥ä¾¿ä¸ºæ¨¡å‹çš„å¤„ç†åšå¥½å‡†å¤‡ï¼Œå¹¶å¼•å…¥åƒä¸ªImageNetç±»åˆ«çš„äººç±»å¯è¯»æ ‡ç­¾ã€‚ç°åœ¨ã€‚
- en: let's see what the model thinks this isã€‚And thinks our cat is a catã€‚But why
    does the model think this is a picture of a catã€‚![](img/2fb9bd9df95d3221c8b5a298fc267de0_7.png)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹è®¤ä¸ºè¿™æ˜¯ä»€ä¹ˆã€‚å®ƒè®¤ä¸ºæˆ‘ä»¬çš„çŒ«æ˜¯ä¸€åªçŒ«ã€‚ä½†ä¸ºä»€ä¹ˆæ¨¡å‹è®¤ä¸ºè¿™æ˜¯çŒ«çš„å›¾ç‰‡å‘¢ï¼Ÿ![](img/2fb9bd9df95d3221c8b5a298fc267de0_7.png)
- en: For the answer to thatï¼Œ we can look under the hood of the model of capã€‚The core
    abstraction in cap is the attributionã€‚ and that is a quantitative method of attributing
    a particular output or activity of a model with its inputã€‚The first kind of attribution
    is feature attributionã€‚This lets us ask which parts of the input were most important
    in determining a model's predictionã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹Captumæ¨¡å‹çš„åº•å±‚å®ç°ã€‚Captumçš„æ ¸å¿ƒæŠ½è±¡æ˜¯å½’å› ï¼ˆattributionï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å®šé‡æ–¹æ³•ï¼Œç”¨äºå°†æ¨¡å‹çš„ç‰¹å®šè¾“å‡ºæˆ–æ´»åŠ¨ä¸å…¶è¾“å…¥ç›¸å…³è”ã€‚ç¬¬ä¸€ç§å½’å› æ˜¯ç‰¹å¾å½’å› ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè¯¢é—®è¾“å…¥çš„å“ªäº›éƒ¨åˆ†åœ¨ç¡®å®šæ¨¡å‹çš„é¢„æµ‹ä¸­æœ€ä¸ºé‡è¦ã€‚
- en: It lets us find answers to questions likeã€‚Which words in this input question
    were most significant in deciding the answerã€‚Which pixels in this input image
    drove the model's classification of the imageã€‚Which features of the input data
    were most significant to my regression model's predictionã€‚Feature attribution
    just covers inputs and outputsï¼Œ thoughã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè®©æˆ‘ä»¬æ‰¾åˆ°ä¸€äº›é—®é¢˜çš„ç­”æ¡ˆï¼Œæ¯”å¦‚ï¼šåœ¨è¿™ä¸ªè¾“å…¥é—®é¢˜ä¸­ï¼Œå“ªäº›è¯åœ¨å†³å®šç­”æ¡ˆæ—¶æœ€é‡è¦ï¼Ÿåœ¨è¿™ä¸ªè¾“å…¥å›¾åƒä¸­ï¼Œå“ªäº›åƒç´ æ¨åŠ¨äº†æ¨¡å‹å¯¹å›¾åƒçš„åˆ†ç±»ï¼Ÿè¾“å…¥æ•°æ®çš„å“ªäº›ç‰¹å¾å¯¹æˆ‘çš„å›å½’æ¨¡å‹çš„é¢„æµ‹æœ€é‡è¦ï¼Ÿä¸è¿‡ï¼Œç‰¹å¾å½’å› ä»…æ¶µç›–è¾“å…¥å’Œè¾“å‡ºã€‚
- en: What if we want to see what's happening inside the modelã€‚For thatï¼Œ we have layer
    attributionã€‚This attributes the activity of a hidden layer of a model to the model's
    inputã€‚It lets us answer questionsï¼Œ likeã€‚Which neurons in this layer were most
    activeï¼Œ given this inputã€‚Which neurons in this layer were most important to how
    the input influenced a particular output neuroã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³çœ‹çœ‹æ¨¡å‹å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æœ‰å±‚å½’å› ã€‚è¿™å°†æ¨¡å‹éšè—å±‚çš„æ´»åŠ¨å½’å› äºæ¨¡å‹çš„è¾“å…¥ã€‚å®ƒè®©æˆ‘ä»¬å›ç­”ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚ï¼šåœ¨ç»™å®šè¾“å…¥çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸€å±‚ä¸­å“ªäº›ç¥ç»å…ƒæœ€æ´»è·ƒï¼Ÿè¿™ä¸€å±‚ä¸­å“ªäº›ç¥ç»å…ƒå¯¹è¾“å…¥å¦‚ä½•å½±å“ç‰¹å®šè¾“å‡ºç¥ç»å…ƒæœ€é‡è¦ï¼Ÿ
- en: How is the activation map output by this convolutional layer correlated to my
    input imageã€‚Finallyã€‚ there's neuron attributionã€‚ This is similar to layer attributionã€‚
    but goes down to the level of individual neurons in the modelã€‚In this tutorialã€‚
    we're going to look at feature attribution and layer attributionã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å·ç§¯å±‚è¾“å‡ºçš„æ¿€æ´»å›¾ä¸æˆ‘çš„è¾“å…¥å›¾åƒä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿæœ€åï¼Œè¿˜æœ‰ç¥ç»å…ƒå½’å› ã€‚è¿™ä¸å±‚å½’å› ç±»ä¼¼ï¼Œä½†æ·±å…¥åˆ°æ¨¡å‹ä¸­å•ä¸ªç¥ç»å…ƒçš„å±‚é¢ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ç ”ç©¶ç‰¹å¾å½’å› å’Œå±‚å½’å› ã€‚
- en: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_9.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_9.png)'
- en: Firstï¼Œ feature attributionã€‚Attributions are realized by an attribution algorithmã€‚![](img/2fb9bd9df95d3221c8b5a298fc267de0_11.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œç‰¹å¾å½’å› ã€‚å½’å› æ˜¯é€šè¿‡å½’å› ç®—æ³•å®ç°çš„ã€‚![](img/2fb9bd9df95d3221c8b5a298fc267de0_11.png)
- en: A particular method of mapping model activity to inputsã€‚The first feature attribution
    algorithm we'll look at is called integrated gradientsã€‚This algorithm numerically
    approximates the integral of the gradients of the model's output with respect
    to its inputsã€‚ essentially finding the most important paths through the model
    for a given input output pairã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§å°†æ¨¡å‹æ´»åŠ¨æ˜ å°„åˆ°è¾“å…¥çš„ç‰¹å®šæ–¹æ³•ã€‚æˆ‘ä»¬å°†è¦æŸ¥çœ‹çš„ç¬¬ä¸€ä¸ªç‰¹å¾å½’å› ç®—æ³•ç§°ä¸ºæ•´åˆæ¢¯åº¦ã€‚è¯¥ç®—æ³•æ•°å€¼ä¸Šè¿‘ä¼¼æ¨¡å‹è¾“å‡ºç›¸å¯¹äºå…¶è¾“å…¥çš„æ¢¯åº¦ç§¯åˆ†ï¼Œå®è´¨ä¸Šæ˜¯ä¸ºç»™å®šçš„è¾“å…¥è¾“å‡ºå¯¹æ‰¾åˆ°é€šè¿‡æ¨¡å‹çš„æœ€é‡è¦è·¯å¾„ã€‚
- en: We'll go ahead and create an integrated gradient objectï¼Œ initializing it with
    our modelã€‚Then we'll call the attribute method on itã€‚We'll feed it our inputã€‚
    our output label and an optional number of steps to runã€‚Note that running the
    cell can take a couple of minutesã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»§ç»­åˆ›å»ºä¸€ä¸ªæ•´åˆæ¢¯åº¦å¯¹è±¡ï¼Œå¹¶ç”¨æˆ‘ä»¬çš„æ¨¡å‹åˆå§‹åŒ–å®ƒã€‚ç„¶åæˆ‘ä»¬å°†è°ƒç”¨å®ƒçš„å½’å› æ–¹æ³•ã€‚æˆ‘ä»¬å°†è¾“å…¥ã€è¾“å‡ºæ ‡ç­¾ä»¥åŠä¸€ä¸ªå¯é€‰çš„è¿è¡Œæ­¥éª¤æ•°ä¼ å…¥ã€‚è¯·æ³¨æ„ï¼Œè¿è¡Œè¯¥å•å…ƒå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿã€‚
- en: The process of integrating the gradients is computationally intensiveã€‚Once that
    cell finishes runningï¼Œ we have a sort of numerical importance map of the cat image
    with respect to the cat label generated by the modelã€‚For a simple regression model
    with few output categoriesï¼Œ we might just print that out as a tableã€‚ but for a
    more complicated C model with a larger input like an imageã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ•´åˆæ¢¯åº¦çš„è¿‡ç¨‹è®¡ç®—é‡å¾ˆå¤§ã€‚ä¸€æ—¦è¯¥å•å…ƒå®Œæˆè¿è¡Œï¼Œæˆ‘ä»¬å°±ä¼šç”Ÿæˆä¸€ä¸ªå…³äºçŒ«å›¾åƒå’Œæ¨¡å‹ç”Ÿæˆçš„çŒ«æ ‡ç­¾çš„æ•°å€¼é‡è¦æ€§å›¾ã€‚å¯¹äºä¸€ä¸ªè¾“å‡ºç±»åˆ«è¾ƒå°‘çš„ç®€å•å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬å¯èƒ½åªéœ€å°†å…¶æ‰“å°ä¸ºè¡¨æ ¼ã€‚ä½†å¯¹äºä¸€ä¸ªæ›´å¤æ‚çš„
    C æ¨¡å‹ï¼Œè¾“å…¥æ›´å¤§ï¼Œå¦‚å›¾åƒã€‚
- en: it would help to be able to relate the importance map to the image visuallyã€‚Captain's
    got you coveredã€‚Visualization module gives you tools for exactly thatã€‚Hereã€‚ we're
    going to make two calls to visualize image atã€‚The first displays the original
    imageã€‚Firstã€‚ we need to make some adjustments to the imageã€‚ We call a squeeze
    to remove the batch dimension on the imageã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è§†è§‰ä¸Šå°†é‡è¦æ€§å›¾ä¸å›¾åƒå…³è”å°†ä¼šæœ‰æ‰€å¸®åŠ©ã€‚Captain å·²ç»ä¸ºä½ å‡†å¤‡å¥½äº†ã€‚å¯è§†åŒ–æ¨¡å—æ­£å¥½æä¾›äº†è¿™æ–¹é¢çš„å·¥å…·ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¿›è¡Œä¸¤æ¬¡è°ƒç”¨æ¥å¯è§†åŒ–å›¾åƒã€‚ç¬¬ä¸€æ¬¡æ˜¾ç¤ºåŸå§‹å›¾åƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¹å›¾åƒè¿›è¡Œä¸€äº›è°ƒæ•´ã€‚æˆ‘ä»¬è°ƒç”¨
    squeeze æ¥ç§»é™¤å›¾åƒä¸Šçš„æ‰¹é‡ç»´åº¦ã€‚
- en: We make sure we're running on CPUã€‚ We detach the image tensor from computation
    historyã€‚ Otherwiseã€‚ the image tensor will keep tracking its computation history
    unnecessarilyã€‚And finallyã€‚ we make it a numpy array and switch the dimensions
    around and put the color channels lastã€‚The first argument of this method would
    normally be the attributionsã€‚ But for this callã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¡®ä¿åœ¨ CPU ä¸Šè¿è¡Œã€‚æˆ‘ä»¬å°†å›¾åƒå¼ é‡ä»è®¡ç®—å†å²ä¸­åˆ†ç¦»å‡ºæ¥ã€‚å¦åˆ™ï¼Œå›¾åƒå¼ é‡ä¼šä¸å¿…è¦åœ°ç»§ç»­è·Ÿè¸ªå…¶è®¡ç®—å†å²ã€‚æœ€åï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œè°ƒæ•´ç»´åº¦ï¼Œå¹¶å°†é¢œè‰²é€šé“æ”¾åœ¨æœ€åã€‚è¯¥æ–¹æ³•çš„ç¬¬ä¸€ä¸ªå‚æ•°é€šå¸¸æ˜¯å½’å› ã€‚ä½†å¯¹äºè¿™ä¸ªè°ƒç”¨ã€‚
- en: we're going to make that noneã€‚ We're just displaying the original imageã€‚The
    second argument is our transformed imageã€‚Third argument is a visualization methodã€‚
    a string that indicates how you want the visualization to workã€‚Hereï¼Œ we told Captainã€‚
    we just want to display the aboginal imageã€‚Finallyï¼Œ we give our visualization
    an instructive titleã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŠŠå…¶è®¾ç½®ä¸ºæ— ã€‚æˆ‘ä»¬åªæ˜¾ç¤ºåŸå§‹å›¾åƒã€‚ç¬¬äºŒä¸ªå‚æ•°æ˜¯æˆ‘ä»¬çš„å˜æ¢å›¾åƒã€‚ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯å¯è§†åŒ–æ–¹æ³•ï¼Œä¸€ä¸ªæŒ‡ç¤ºä½ å¸Œæœ›å¯è§†åŒ–å¦‚ä½•å·¥ä½œçš„å­—ç¬¦ä¸²ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å‘Šè¯‰Captainï¼Œæˆ‘ä»¬åªæƒ³æ˜¾ç¤ºåŸå§‹å›¾åƒã€‚æœ€åï¼Œæˆ‘ä»¬ç»™æˆ‘ä»¬çš„å¯è§†åŒ–ä¸€ä¸ªè¯´æ˜æ€§çš„æ ‡é¢˜ã€‚
- en: The second call will make a visual mapping of the important regions of our imageã€‚The
    first argument is the attributions we got from integrated gradientsã€‚ And the second
    is our transformative imageã€‚For a method will specify heat napã€‚Where color intensity
    maps to the importance of an image regionã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªè°ƒç”¨å°†å¯¹æˆ‘ä»¬å›¾åƒçš„é‡è¦åŒºåŸŸè¿›è¡Œå¯è§†åŒ–æ˜ å°„ã€‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æˆ‘ä»¬ä»ç§¯åˆ†æ¢¯åº¦ä¸­è·å¾—çš„å½’å› ã€‚ç¬¬äºŒä¸ªæ˜¯æˆ‘ä»¬çš„å˜æ¢å›¾åƒã€‚å¯¹äºè¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å°†æŒ‡å®šçƒ­å›¾ã€‚é¢œè‰²å¼ºåº¦ä¸å›¾åƒåŒºåŸŸçš„é‡è¦æ€§ç›¸å¯¹åº”ã€‚
- en: Capize you to use custom color maps from map plotlibã€‚ And we've made one here
    that will slightly enhance the contrast of our heat mapã€‚We specify s as positiveã€‚
    We're only looking at positive attributionsã€‚Running a cellã€‚ we can see that the
    model is paying attention to the outline of the catã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Capizeä½ å¯ä»¥ä½¿ç”¨æ¥è‡ªmap plotlibçš„è‡ªå®šä¹‰é¢œè‰²å›¾ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œåˆ›å»ºäº†ä¸€ä¸ªï¼Œå¯ä»¥ç¨å¾®å¢å¼ºçƒ­å›¾çš„å¯¹æ¯”åº¦ã€‚æˆ‘ä»¬å°†sæŒ‡å®šä¸ºæ­£é¢ã€‚æˆ‘ä»¬åªå…³æ³¨æ­£é¢å½’å› ã€‚è¿è¡Œä¸€ä¸ªå•å…ƒã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹å…³æ³¨çš„æ˜¯çŒ«çš„è½®å»“ã€‚
- en: as well as the region around the centre of the cat's faceã€‚Let's try another
    feature attribution algorithmã€‚ Nextï¼Œ we'll try occlusionã€‚Integrated gradients
    was a gradient based attribution algorithmã€‚ Occlusion is differentã€‚ It's a perturbation
    based method that involves screening out portions of the image and seeing how
    that affects the outputã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠçŒ«è„¸ä¸­å¿ƒå‘¨å›´çš„åŒºåŸŸã€‚è®©æˆ‘ä»¬å°è¯•å¦ä¸€ç§ç‰¹å¾å½’å› ç®—æ³•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å°è¯•é®æŒ¡ã€‚ç§¯åˆ†æ¢¯åº¦æ˜¯ä¸€ç§åŸºäºæ¢¯åº¦çš„å½’å› ç®—æ³•ã€‚é®æŒ¡åˆ™æœ‰æ‰€ä¸åŒã€‚å®ƒæ˜¯ä¸€ç§åŸºäºæ‰°åŠ¨çš„æ–¹æ³•ï¼Œæ¶‰åŠé®è”½å›¾åƒçš„éƒ¨åˆ†åŒºåŸŸï¼Œå¹¶æŸ¥çœ‹è¿™å¦‚ä½•å½±å“è¾“å‡ºã€‚
- en: As beforeï¼Œ we're going to specify our input image and our output labeled to
    the attribution algorithmã€‚For occlusionï¼Œ we're going to specify a few more itemsã€‚
    The first are the sliding window and the stride lengthã€‚ And these are analogous
    to similar configuration options in a convolutional neural networkã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å°†æŒ‡å®šæˆ‘ä»¬çš„è¾“å…¥å›¾åƒå’Œè¾“å‡ºæ ‡ç­¾ç»™å½’å› ç®—æ³•ã€‚å¯¹äºé®æŒ¡ï¼Œæˆ‘ä»¬å°†æŒ‡å®šå‡ ä¸ªæ›´å¤šçš„é¡¹ç›®ã€‚ç¬¬ä¸€ä¸ªæ˜¯æ»‘åŠ¨çª—å£å’Œæ­¥å¹…é•¿åº¦ã€‚è¿™äº›ç±»ä¼¼äºå·ç§¯ç¥ç»ç½‘ç»œä¸­çš„ç±»ä¼¼é…ç½®é€‰é¡¹ã€‚
- en: We're also going to set our baselineã€‚That isï¼Œ our representation of an occluded
    image cellï¼Œ 0ã€‚Depending on how your data are normalizedï¼Œ you may wish to specify
    a different baselineã€‚ but for zero centered dataï¼Œ it makes sense to use 0ã€‚We'll
    run the attribute call and give it a minuteã€‚And in the next cellï¼Œ we're doing
    something newã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†è®¾ç½®æˆ‘ä»¬çš„åŸºçº¿ã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬å¯¹ä¸€ä¸ªè¢«é®æŒ¡çš„å›¾åƒå•å…ƒçš„è¡¨ç¤ºï¼Œè®¾ç½®ä¸º0ã€‚æ ¹æ®ä½ çš„æ•°æ®å¦‚ä½•å½’ä¸€åŒ–ï¼Œä½ å¯èƒ½å¸Œæœ›æŒ‡å®šä¸€ä¸ªä¸åŒçš„åŸºçº¿ã€‚ä½†å¯¹äºä»¥é›¶ä¸ºä¸­å¿ƒçš„æ•°æ®ï¼Œä½¿ç”¨0æ˜¯æœ‰æ„ä¹‰çš„ã€‚æˆ‘ä»¬å°†è¿è¡Œå½’å› è°ƒç”¨ï¼Œç»™å®ƒä¸€ç‚¹æ—¶é—´ã€‚åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­ï¼Œæˆ‘ä»¬å°†è¿›è¡Œä¸€äº›æ–°çš„æ“ä½œã€‚
- en: We're calling visualized image Adder multipleã€‚To show multiple visualizations
    of the occlusion attributionã€‚Besides the original imageï¼Œ we'll show three visualizationsã€‚
    The first two are heat maps of both positive and negative attributionsã€‚ You can
    see that we're providing a list of methods with heat map being the second and
    thirdã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨è°ƒç”¨å¯è§†åŒ–å›¾åƒå åŠ å¤šæ¬¡ã€‚ä¸ºäº†æ˜¾ç¤ºé®æŒ¡å½’å› çš„å¤šä¸ªå¯è§†åŒ–ç»“æœã€‚é™¤äº†åŸå§‹å›¾åƒï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸‰ä¸ªå¯è§†åŒ–ç»“æœã€‚å‰ä¸¤ä¸ªæ˜¯æ­£é¢å’Œè´Ÿé¢çš„å½’å› çƒ­å›¾ã€‚ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæ–¹æ³•åˆ—è¡¨ï¼Œå…¶ä¸­çƒ­å›¾æ˜¯ç¬¬äºŒå’Œç¬¬ä¸‰ä¸ªã€‚
- en: We're also specifying a sign for each visualizationã€‚ And here you can see that
    we've askedtra positive attributions on one heat map and negative on the otherã€‚
    These indicate whichã€‚For our final visualizationï¼Œ we'll use the mask methodã€‚ This
    uses positive attributions to selectively screen the original imageã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜ä¸ºæ¯ä¸ªå¯è§†åŒ–æŒ‡å®šäº†ä¸€ä¸ªæ ‡å¿—ã€‚åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬åœ¨ä¸€ä¸ªçƒ­å›¾ä¸Šè¯·æ±‚äº†æ­£é¢å½’å› ï¼Œè€Œåœ¨å¦ä¸€ä¸ªä¸Šè¯·æ±‚äº†è´Ÿé¢å½’å› ã€‚è¿™äº›æŒ‡ç¤ºäº†å“ªä¸€ä¸ªã€‚å¯¹äºæˆ‘ä»¬çš„æœ€ç»ˆå¯è§†åŒ–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ©è†œæ–¹æ³•ã€‚è¿™ä½¿ç”¨æ­£é¢å½’å› æ¥é€‰æ‹©æ€§åœ°é®è”½åŸå§‹å›¾åƒã€‚
- en: giving a striking visual representation of the areas of the image the model
    paid most attention to for this input output pairã€‚Running the cellï¼Œ you can see
    that this maps well to what we learn from integrated gradientsã€‚ Most of the activities
    are on the cat's outlined in the center of its faceã€‚What about what the model
    is doing under the hoodã€‚Let's use a layer attribution algorithm to check the activity
    of one of the hidden layersã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºè¯¥è¾“å…¥è¾“å‡ºå¯¹æä¾›äº†å›¾åƒä¸­æ¨¡å‹æœ€å…³æ³¨åŒºåŸŸçš„æ˜¾è‘—è§†è§‰è¡¨ç¤ºã€‚è¿è¡Œå•å…ƒï¼Œä½ å¯ä»¥çœ‹åˆ°è¿™ä¸æˆ‘ä»¬ä»ç§¯åˆ†æ¢¯åº¦ä¸­å­¦åˆ°çš„å†…å®¹å¾ˆå¥½åœ°å¯¹åº”ã€‚å¤§å¤šæ•°æ´»åŠ¨é›†ä¸­åœ¨çŒ«è„¸ä¸­å¿ƒçš„è½®å»“ä¸Šã€‚æ¨¡å‹åœ¨åå°æ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿè®©æˆ‘ä»¬ä½¿ç”¨å±‚å½’å› ç®—æ³•æ£€æŸ¥å…¶ä¸­ä¸€ä¸ªéšè—å±‚çš„æ´»åŠ¨ã€‚
- en: Gradcam is another gradient based attribution algorithm designed for convesã€‚It
    computes the gradients of the output with respect to the specified model layerã€‚
    averagevers the gradients for each channel and multiplies this average by the
    layer activationsã€‚And uses this as a measure of the importance of a layer's outputã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GradCAMæ˜¯å¦ä¸€ç§åŸºäºæ¢¯åº¦çš„å½’å› ç®—æ³•ï¼Œä¸“ä¸ºå·ç§¯è®¾è®¡ã€‚å®ƒè®¡ç®—è¾“å‡ºç›¸å¯¹äºæŒ‡å®šæ¨¡å‹å±‚çš„æ¢¯åº¦ï¼Œå¯¹æ¯ä¸ªé€šé“çš„æ¢¯åº¦è¿›è¡Œå¹³å‡ï¼Œå¹¶å°†æ­¤å¹³å‡å€¼ä¸å±‚æ¿€æ´»ç›¸ä¹˜ï¼Œå¹¶å°†å…¶ä½œä¸ºå±‚è¾“å‡ºé‡è¦æ€§çš„åº¦é‡ã€‚
- en: To get started with layer attributionï¼Œ we'll create a layer gradcam object and
    initialize it with our model and the layer we wish to examineã€‚Then we'll give
    it the input output pair and ask it to do attributionã€‚We can visualize this with
    a heat mapï¼Œ as we did beforeã€‚ in this wayã€‚ you can visually examine which areas
    of a confidencein activation map were like to your outputã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¼€å§‹å±‚å½’å› ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå±‚GradCAMå¯¹è±¡ï¼Œå¹¶ç”¨æˆ‘ä»¬çš„æ¨¡å‹å’Œæˆ‘ä»¬å¸Œæœ›æ£€æŸ¥çš„å±‚è¿›è¡Œåˆå§‹åŒ–ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¾“å…¥è¾“å‡ºå¯¹ä¼ å…¥ï¼Œå¹¶è¯·æ±‚è¿›è¡Œå½’å› ã€‚æˆ‘ä»¬å¯ä»¥åƒä¹‹å‰é‚£æ ·ç”¨çƒ­å›¾å¯è§†åŒ–ã€‚è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥ç›´è§‚åœ°æ£€æŸ¥æ¿€æ´»å›¾çš„å“ªäº›åŒºåŸŸä¸è¾“å‡ºç›¸å…³ã€‚
- en: We can do better than thisï¼Œ thoughã€‚Since the output of a convolutional layer
    is usually spatially correlated to the inputã€‚ we can take advantage of that by
    up sampling that activation map and comparing it directly with the inputã€‚The layer
    attribution parent class has a convenience method for up samplingling the lower
    resolution convenant activation map up to the input sizeã€‚We'll do that with the
    interpolate method hereã€‚And asked the visualizer for a blended heat mapã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œæˆ‘ä»¬å¯ä»¥åšå¾—æ›´å¥½ã€‚ç”±äºå·ç§¯å±‚çš„è¾“å‡ºé€šå¸¸ä¸è¾“å…¥åœ¨ç©ºé—´ä¸Šç›¸å…³ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œé€šè¿‡ä¸Šé‡‡æ ·æ¿€æ´»å›¾å¹¶ç›´æ¥ä¸è¾“å…¥è¿›è¡Œæ¯”è¾ƒã€‚å±‚å½’å› çˆ¶ç±»æœ‰ä¸€ä¸ªæ–¹ä¾¿çš„æ–¹æ³•ï¼Œå¯ä»¥å°†ä½åˆ†è¾¨ç‡çš„å·ç§¯æ¿€æ´»å›¾ä¸Šé‡‡æ ·åˆ°è¾“å…¥å¤§å°ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨æ’å€¼æ–¹æ³•ã€‚å¹¶è¯·æ±‚å¯è§†åŒ–å·¥å…·ç”Ÿæˆä¸€ä¸ªæ··åˆçƒ­å›¾ã€‚
- en: showing the original image with a heat map superimposed and a masked imageã€‚Visualizations
    like this can give you insight into how hidden layers contribute to a particular
    output from your modelã€‚Captain comes with an advanced visualization tool called
    Cap Insightsã€‚ which lets you put together multiple visualizations in an in browserrowsed
    widget that lets you configure the attribution algorithm and its parametersã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç¤ºåŸå§‹å›¾åƒåŠå…¶å åŠ çš„çƒ­å›¾å’Œæ©æ¨¡å›¾åƒã€‚è¿™æ ·çš„å¯è§†åŒ–å¯ä»¥è®©ä½ æ·±å…¥äº†è§£éšè—å±‚å¦‚ä½•å½±å“æ¨¡å‹çš„ç‰¹å®šè¾“å‡ºã€‚Captainé…å¤‡äº†ä¸€ä¸ªåä¸ºCap Insightsçš„é«˜çº§å¯è§†åŒ–å·¥å…·ï¼Œå®ƒå…è®¸ä½ åœ¨æµè§ˆå™¨ä¸­ç»„åˆå¤šä¸ªå¯è§†åŒ–ï¼Œé…ç½®å½’å› ç®—æ³•åŠå…¶å‚æ•°ã€‚
- en: Captain Inights lets you visualize textï¼Œ image and arbitrary dataã€‚We're going
    to try three images nowï¼Œ the catï¼Œ a teapot and a trilaite fossilã€‚Againã€‚ these
    images should be available wherever you got the interactive notebook that goes
    with its videoã€‚Firstï¼Œ we'll query the model to see what it thinks each of these
    areã€‚And it seems to be really okayã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Captain Inightsè®©ä½ å¯è§†åŒ–æ–‡æœ¬ã€å›¾åƒå’Œä»»æ„æ•°æ®ã€‚æˆ‘ä»¬ç°åœ¨å°†å°è¯•ä¸‰å¼ å›¾åƒï¼Œåˆ†åˆ«æ˜¯çŒ«ã€ä¸€å£¶èŒ¶å’Œä¸‰å¶è™«åŒ–çŸ³ã€‚å†æ¬¡å¼ºè°ƒï¼Œè¿™äº›å›¾åƒåº”è¯¥å¯ä»¥åœ¨ä½ è·å–äº’åŠ¨ç¬”è®°æœ¬åŠå…¶è§†é¢‘çš„åœ°æ–¹æ‰¾åˆ°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æŸ¥è¯¢æ¨¡å‹ï¼Œçœ‹çœ‹å®ƒå¯¹è¿™äº›å†…å®¹çš„ç†è§£å¦‚ä½•ã€‚ä¼¼ä¹æ•ˆæœè¿˜ä¸é”™ã€‚
- en: Nowï¼Œ let's set up cap Insã€‚We're going to use the attribution visualizer objectã€‚
    and we'll configure it with our modelã€‚A scoring function for the model's outputs
    hereï¼Œ softmã€‚A list of the classes the model recognizes here I am stripping out
    an ordered list of the image net class namesã€‚We'll tell it that we're looking
    at image featuresã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬è®¾ç½®Cap Insightsã€‚æˆ‘ä»¬å°†ä½¿ç”¨å½’å› å¯è§†åŒ–å¯¹è±¡ï¼Œå¹¶ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œé…ç½®ã€‚æ¨¡å‹è¾“å‡ºçš„è¯„åˆ†å‡½æ•°åœ¨è¿™é‡Œæ˜¯softmã€‚æ¨¡å‹è¯†åˆ«çš„ç±»åˆ—è¡¨åœ¨è¿™é‡Œï¼Œæˆ‘å°†æŒ‰é¡ºåºåˆ—å‡ºImageNetçš„ç±»åã€‚æˆ‘ä»¬ä¼šå‘Šè¯‰å®ƒï¼Œæˆ‘ä»¬åœ¨æŸ¥çœ‹å›¾åƒç‰¹å¾ã€‚
- en: Captive Insights also handles text and arbitrary dataï¼Œ as wellã€‚And it'll give
    it a data setã€‚ which is just an iterable that returns a batch of images and labelsã€‚Note
    that we haven't specified an algorithm or a visualization methodã€‚These are things
    that you set up in the in browserrower widgetã€‚Nowï¼Œ we ask the visualizer to renderã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Captive InsightsåŒæ ·å¤„ç†æ–‡æœ¬å’Œä»»æ„æ•°æ®ï¼Œå®ƒä¼šç»™å‡ºä¸€ä¸ªæ•°æ®é›†ï¼Œå³ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œè¿”å›ä¸€æ‰¹å›¾åƒå’Œæ ‡ç­¾ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬å°šæœªæŒ‡å®šç®—æ³•æˆ–å¯è§†åŒ–æ–¹æ³•ã€‚è¿™äº›æ˜¯åœ¨æµè§ˆå™¨å°éƒ¨ä»¶ä¸­è®¾ç½®çš„å†…å®¹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¯·æ±‚å¯è§†åŒ–å·¥å…·è¿›è¡Œæ¸²æŸ“ã€‚
- en: It starts off emptyï¼Œ but we can set up configuration parameters and ask it to
    fetch our visualized attributions with the fetch buttonã€‚I'm going to leave things
    at the default setting for integrated gradientsã€‚ Captain needs a few minutes to
    generate the attributionsã€‚But now we can see that it ranks the first few predictions
    for each image with their probabilities and provides heat map attribution for
    the important regions of the imageã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæœ€åˆæ˜¯ç©ºçš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥è®¾ç½®é…ç½®å‚æ•°ï¼Œå¹¶é€šè¿‡æå–æŒ‰é’®è¯·æ±‚å®ƒè·å–æˆ‘ä»¬å¯è§†åŒ–çš„å½’å› ã€‚æˆ‘å°†ä¿æŒé›†æˆæ¢¯åº¦çš„é»˜è®¤è®¾ç½®ã€‚Captainéœ€è¦å‡ åˆ†é’Ÿç”Ÿæˆå½’å› ã€‚ä½†ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒä¸ºæ¯ä¸ªå›¾åƒæ’åå‰å‡ çš„é¢„æµ‹åŠå…¶æ¦‚ç‡ï¼Œå¹¶æä¾›é‡è¦åŒºåŸŸçš„çƒ­å›¾å½’å› ã€‚
- en: In this wayï¼Œ Captain insightights lets you experiment with attribution methods
    and understand the activity that LED to your model's predictionsã€‚ both correct
    and incorrect and lets you do it visually with minimal codeã€‚Finallyã€‚ don't forget
    to look at Captain AI for documentationã€‚ tutorials and API reference and access
    to the source on Gitthubã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒCaptain insightightsè®©ä½ å®éªŒå½’å› æ–¹æ³•ï¼Œç†è§£å¯¼è‡´æ¨¡å‹é¢„æµ‹çš„æ´»åŠ¨ï¼Œæ— è®ºæ˜¯æ­£ç¡®çš„è¿˜æ˜¯é”™è¯¯çš„ï¼Œå¹¶ä¸”ä»¥æœ€å°‘çš„ä»£ç è¿›è¡Œå¯è§†åŒ–ã€‚æœ€åï¼Œåˆ«å¿˜äº†æŸ¥çœ‹Captain
    AIä»¥è·å–æ–‡æ¡£ã€æ•™ç¨‹å’ŒAPIå‚è€ƒï¼Œä»¥åŠåœ¨GitHubä¸Šçš„æºä»£ç è®¿é—®ã€‚
- en: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_13.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2fb9bd9df95d3221c8b5a298fc267de0_13.png)'
