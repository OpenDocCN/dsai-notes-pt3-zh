- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7-
    TorchText - ShowMeAI - BV1ZZ4y1U7dg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P7ï¼šL7-
    TorchText - ShowMeAI - BV1ZZ4y1U7dg
- en: ğŸ¼ã€‚![](img/aaa011e1dc72912baa590f68c0c043cd_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ã€‚![](img/aaa011e1dc72912baa590f68c0c043cd_1.png)
- en: Hello everyoneï¼Œ welcome to PyTchDeveloper Day for 2020ã€‚My name is Georgeã€‚ I'm
    a software engineer at Facebookï¼Œ I work for the text domain in Pytotã€‚My job at
    Facebook is to support the PyToch userï¼Œ especially in the text domain for research
    to productionã€‚ so in this talk I will go over some major update in 2020 and help
    you understand how our work can facilitate your research and production for the
    PyTochã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œæ¬¢è¿å‚åŠ 2020å¹´çš„PyTchå¼€å‘è€…æ—¥ã€‚æˆ‘å«ä¹”æ²»ã€‚æˆ‘æ˜¯Facebookçš„ä¸€ä¸ªè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œå·¥ä½œäºPytotçš„æ–‡æœ¬é¢†åŸŸã€‚æˆ‘åœ¨Facebookçš„å·¥ä½œæ˜¯æ”¯æŒPyTochç”¨æˆ·ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–‡æœ¬é¢†åŸŸï¼Œä»ç ”ç©¶åˆ°ç”Ÿäº§ã€‚å› æ­¤ï¼Œåœ¨è¿™æ¬¡æ¼”è®²ä¸­ï¼Œæˆ‘å°†è®²è§£2020å¹´çš„ä¸€äº›ä¸»è¦æ›´æ–°ï¼Œå¹¶å¸®åŠ©ä½ äº†è§£æˆ‘ä»¬çš„å·¥ä½œå¦‚ä½•ä¿ƒè¿›ä½ çš„ç ”ç©¶å’ŒPyTochçš„ç”Ÿäº§ã€‚
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_3.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_3.png)'
- en: So why we want to have a text domain in addition to Pythã€‚Firstã€‚We want to accelerate
    NLP research and provide some reusful orthogonal and correct building block for
    cutting edge researchã€‚Based on our knowledge for the text domain and the research
    communityã€‚We want to work with the both internal team and external open source
    community to build a pipeline like can better supportã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬å¸Œæœ›åœ¨Pythä¹‹å¤–æœ‰ä¸€ä¸ªæ–‡æœ¬é¢†åŸŸå‘¢ï¼Ÿé¦–å…ˆã€‚æˆ‘ä»¬å¸Œæœ›åŠ é€ŸNLPç ”ç©¶ï¼Œå¹¶ä¸ºå‰æ²¿ç ”ç©¶æä¾›ä¸€äº›å¯é‡ç”¨çš„æ­£äº¤å’Œæ­£ç¡®çš„æ„å»ºå—ã€‚åŸºäºæˆ‘ä»¬å¯¹æ–‡æœ¬é¢†åŸŸå’Œç ”ç©¶ç¤¾åŒºçš„äº†è§£ã€‚æˆ‘ä»¬å¸Œæœ›ä¸å†…éƒ¨å›¢é˜Ÿå’Œå¤–éƒ¨å¼€æºç¤¾åŒºåˆä½œï¼Œå»ºç«‹ä¸€ä¸ªæ›´å¥½æ”¯æŒçš„ç®¡é“ã€‚
- en: Both the Facebook products and external researchã€‚Secondã€‚ğŸ˜Šã€‚We want to provide
    a solution to transfer from research to productionã€‚What we mean here is we integrate
    those pipeline and module with a wide range of py capabilities such as touchscript
    quantizationã€‚ distribute data parallel and mobile with this goal we want to have
    a better support for research to production transition for most end an NLP pipeline
    thirdly we want to engage with the community and Disc novel technologyã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ—¶æ”¯æŒFacebookçš„äº§å“å’Œå¤–éƒ¨ç ”ç©¶ã€‚å…¶æ¬¡ã€‚ğŸ˜Šã€‚æˆ‘ä»¬å¸Œæœ›æä¾›ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œå°†ç ”ç©¶è½¬åŒ–ä¸ºç”Ÿäº§ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œçš„æ„æ€æ˜¯å°†è¿™äº›ç®¡é“å’Œæ¨¡å—ä¸å¹¿æ³›çš„pyèƒ½åŠ›é›†æˆï¼Œå¦‚touchscripté‡åŒ–ã€åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œå’Œç§»åŠ¨ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¸ºå¤§å¤šæ•°NLPç®¡é“çš„ç ”ç©¶åˆ°ç”Ÿäº§è¿‡æ¸¡æä¾›æ›´å¥½çš„æ”¯æŒï¼Œç¬¬ä¸‰ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ç¤¾åŒºäº’åŠ¨ï¼Œæ¢ç´¢æ–°æŠ€æœ¯ã€‚
- en: As people notesï¼Œ the NRP domainã€‚Move very fastã€‚ So the text domain in Pyth team
    want to develop a good technology understandingã€‚In the NLP area and build a new
    research collaborationã€‚For the future communityã€‚With those go in mindï¼Œ we provide
    those easy access to data setsã€‚Text processing pipelineã€‚And some NLP related moduleã€‚So
    if you have timeï¼Œ please go over those one by oneã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚äººä»¬æ‰€æ³¨æ„åˆ°çš„ï¼ŒNRPé¢†åŸŸå‘å±•éå¸¸è¿…é€Ÿã€‚æ‰€ä»¥Pythå›¢é˜Ÿå¸Œæœ›åœ¨NLPé¢†åŸŸå‘å±•è‰¯å¥½çš„æŠ€æœ¯ç†è§£ï¼Œå¹¶å»ºç«‹æ–°çš„ç ”ç©¶åˆä½œã€‚ä¸ºäº†æœªæ¥çš„ç¤¾åŒºã€‚è€ƒè™‘åˆ°è¿™äº›ï¼Œæˆ‘ä»¬æä¾›äº†å¯¹æ•°æ®é›†çš„ä¾¿æ·è®¿é—®ã€æ–‡æœ¬å¤„ç†ç®¡é“å’Œä¸€äº›ä¸NLPç›¸å…³çš„æ¨¡å—ã€‚æ‰€ä»¥å¦‚æœä½ æœ‰æ—¶é—´ï¼Œè¯·é€ä¸€æŸ¥çœ‹è¿™äº›å†…å®¹ã€‚
- en: our row text data setï¼Œ the transformã€‚And our more some NP related moduleï¼Œ I
    will goã€‚ go over this one by one with youã€‚![](img/aaa011e1dc72912baa590f68c0c043cd_5.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è¡Œæ–‡æœ¬æ•°æ®é›†å’Œè½¬æ¢ã€‚è¿˜æœ‰ä¸€äº›ä¸NPç›¸å…³çš„æ¨¡å—ï¼Œæˆ‘ä¼šé€ä¸€å’Œä½ è®²è§£ã€‚![](img/aaa011e1dc72912baa590f68c0c043cd_5.png)
- en: Okayï¼Œ so the new data set in To textã€‚We have also rewrite a few existing data
    set in To text nightly releaseã€‚So hereã€‚For the nightly releaseï¼Œ we consider those
    new stuff as a prototypeã€‚ So we will release those new data sets with ourã€‚ğŸ˜Šï¼ŒBetter
    release very soonã€‚So the new data set show here are fully compatible with data
    loader in Pyã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ‰€ä»¥æ–°çš„æ•°æ®é›†åœ¨æ–‡æœ¬ä¸­ã€‚æˆ‘ä»¬ä¹Ÿé‡å†™äº†ä¸€äº›ç°æœ‰çš„æ•°æ®é›†ï¼Œåœ¨æ–‡æœ¬å¤œé—´å‘å¸ƒä¸­ã€‚æ‰€ä»¥åœ¨è¿™é‡Œã€‚å¯¹äºå¤œé—´å‘å¸ƒï¼Œæˆ‘ä»¬å°†è¿™äº›æ–°å†…å®¹è§†ä¸ºåŸå‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å¾ˆå¿«å‘å¸ƒè¿™äº›æ–°çš„æ•°æ®é›†ã€‚ğŸ˜Šï¼Œå¾ˆå¿«å°±ä¼šå‘å¸ƒã€‚æ‰€ä»¥è¿™é‡Œå±•ç¤ºçš„æ–°æ•°æ®é›†ä¸Pyä¸­çš„æ•°æ®åŠ è½½å™¨å®Œå…¨å…¼å®¹ã€‚
- en: User will have the flexibility to build the data processing pipeline with some
    standard tokenizer and vocabulary blocksã€‚Okayï¼Œ here I list all the new data set
    available to our user in our beta releaseã€‚ at sameã€‚ you may wonderingï¼Œ once I
    have those raw dataï¼Œ what should I do to convert this raw data intoã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·å°†èƒ½å¤Ÿçµæ´»æ„å»ºæ•°æ®å¤„ç†ç®¡é“ï¼Œå¹¶ä½¿ç”¨ä¸€äº›æ ‡å‡†çš„åˆ†è¯å™¨å’Œè¯æ±‡å—ã€‚å¥½çš„ï¼Œåœ¨è¿™é‡Œæˆ‘åˆ—å‡ºäº†æˆ‘ä»¬betaå‘å¸ƒä¸­å¯ç”¨çš„æ–°æ•°æ®é›†ã€‚ä¸æ­¤åŒæ—¶ï¼Œä½ å¯èƒ½ä¼šæƒ³ï¼Œä¸€æ—¦æˆ‘æœ‰äº†è¿™äº›åŸå§‹æ•°æ®ï¼Œæˆ‘è¯¥å¦‚ä½•å°†å…¶è½¬æ¢ã€‚
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_7.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_7.png)'
- en: A tensor like can be used to train a model okayï¼Œ so here we provide some improved
    performance we provide some data pipeline with improved performanceã€‚With some
    C+ plus extensionã€‚So the goal here is we want to have an easy transfer to productionã€‚Here's
    the overview of some end to end pipeline with Ptoch and Torch textã€‚The row data
    string read and send to a field transform here here you can see like tokenizerã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åƒå¼ é‡å¯ä»¥ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬æä¾›äº†ä¸€äº›æ”¹è¿›çš„æ€§èƒ½ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€äº›å…·æœ‰æ”¹è¿›æ€§èƒ½çš„æ•°æ®ç®¡é“ã€‚ä½¿ç”¨ä¸€äº› C++ æ‰©å±•ã€‚å› æ­¤ï¼Œè¿™é‡Œçš„ç›®æ ‡æ˜¯æˆ‘ä»¬å¸Œæœ›èƒ½è½»æ¾è½¬ç§»åˆ°ç”Ÿäº§ç¯å¢ƒã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨
    PyTorch å’Œ Torch Text çš„ä¸€äº›ç«¯åˆ°ç«¯ç®¡é“çš„æ¦‚è¿°ã€‚åŸå§‹æ•°æ®å­—ç¬¦ä¸²è¢«è¯»å–å¹¶å‘é€åˆ°å­—æ®µè½¬æ¢ï¼Œè¿™é‡Œæ‚¨å¯ä»¥çœ‹åˆ°åˆ†è¯å™¨ã€‚
- en: vocabularyï¼Œ vector took up and convertive cancerï¼Œ rightï¼Ÿ
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¯æ±‡ï¼Œå‘é‡å ç”¨å’Œè½¬æ¢ç™Œç—‡ï¼Œå¯¹å§ï¼Ÿ
- en: So currently we are rewriting this data processing transform as an orthogonal
    building block with the G portã€‚So after this after this stepï¼Œ we call this a pre
    processingã€‚ The data are sent to data loader and samplerï¼Œ where we generateã€‚They
    have bachelorã€‚Then the data are ready for the modelã€‚So we are do our best to write
    those a building blockã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰æˆ‘ä»¬æ­£åœ¨å°†æ­¤æ•°æ®å¤„ç†è½¬æ¢é‡å†™ä¸ºä¸€ä¸ªæ­£äº¤æ„å»ºæ¨¡å—ï¼Œå¹¶ä¸ G ç«¯å£ç»“åˆã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸€æ­¥ä¹‹åï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºé¢„å¤„ç†ã€‚æ•°æ®è¢«å‘é€åˆ°æ•°æ®åŠ è½½å™¨å’Œé‡‡æ ·å™¨ï¼Œåœ¨é‚£é‡Œæˆ‘ä»¬ç”Ÿæˆã€‚å®ƒä»¬æœ‰å­¦å£«å­¦ä½ã€‚ç„¶åæ•°æ®å°±å‡†å¤‡å¥½ä¾›æ¨¡å‹ä½¿ç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°½åŠ›å°†è¿™äº›å†™æˆä¸€ä¸ªæ„å»ºæ¨¡å—ã€‚
- en: individual building blockï¼Œ like so you will have the full flexibility to combine
    them togetherã€‚And with the C++ extensionï¼Œ we are able to support the Gt for all
    this transformã€‚And we believe that's a better support for the productionã€‚Okayï¼Œ
    so now we go to theã€‚The NLP related moduleï¼Œ so we released a new multiha attention
    module in Tor textã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å•ç‹¬çš„æ„å»ºæ¨¡å—ï¼Œè¿™æ ·æ‚¨å°†æ‹¥æœ‰å®Œå…¨çš„çµæ´»æ€§æ¥å°†å®ƒä»¬ç»„åˆåœ¨ä¸€èµ·ã€‚é€šè¿‡ C++ æ‰©å±•ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ”¯æŒæ‰€æœ‰è¿™äº›è½¬æ¢çš„ Gtã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™å¯¹ç”Ÿäº§ç¯å¢ƒæä¾›äº†æ›´å¥½çš„æ”¯æŒã€‚å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬è¿›å…¥ä¸
    NLP ç›¸å…³çš„æ¨¡å—ï¼Œæˆ‘ä»¬åœ¨ Torch Text ä¸­å‘å¸ƒäº†æ–°çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ã€‚
- en: so in addition to the dropping replacementï¼Œ if you are using the multiha attention
    in Pytoch co libraryã€‚ we support the dropping replacement so you can easily switch
    from a Pytoch multiha attention to To text multiha attentionã€‚In additionã€‚The new
    multi attention container also for touch scriptã€‚Based on the feedback from our
    userï¼Œ we add the incremental decoding and the broadcasting supportã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†ä¸¢å¼ƒæ›¿æ¢ä¹‹å¤–ï¼Œå¦‚æœæ‚¨åœ¨ PyTorch åº“ä¸­ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼Œæˆ‘ä»¬æ”¯æŒä¸¢å¼ƒæ›¿æ¢ï¼Œå› æ­¤æ‚¨å¯ä»¥è½»æ¾åœ°ä» PyTorch çš„å¤šå¤´æ³¨æ„åŠ›åˆ‡æ¢åˆ°æ–‡æœ¬çš„å¤šå¤´æ³¨æ„åŠ›ã€‚æ­¤å¤–ï¼Œæ–°çš„å¤šå¤´æ³¨æ„åŠ›å®¹å™¨ä¹Ÿé€‚ç”¨äº
    Touch è„šæœ¬ã€‚æ ¹æ®ç”¨æˆ·çš„åé¦ˆï¼Œæˆ‘ä»¬æ·»åŠ äº†å¢é‡è§£ç å’Œå¹¿æ’­æ”¯æŒã€‚
- en: The idea for this new multi high attention container is to facilitate user with
    some novel research idea under the transformer architectureã€‚Right nowï¼Œ the transformer
    architecture is very popular across the textï¼Œ audio and vision domainã€‚We hope
    here like we can provide a very flexible multiha attention module so our user
    can apply this with different idea here I give you an example like how you switch
    from the Pych multiha attention to our Tosh text multiha attention containerã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–°å¤šå¤´æ³¨æ„åŠ›å®¹å™¨çš„æƒ³æ³•æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€äº›åœ¨å˜æ¢å™¨æ¶æ„ä¸‹çš„æ–°é¢–ç ”ç©¶ç†å¿µã€‚ç°åœ¨ï¼Œå˜æ¢å™¨æ¶æ„åœ¨æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†è§‰é¢†åŸŸéå¸¸æµè¡Œã€‚æˆ‘ä»¬å¸Œæœ›èƒ½æä¾›ä¸€ä¸ªéå¸¸çµæ´»çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œä»¥ä¾¿ç”¨æˆ·å¯ä»¥åœ¨ä¸åŒçš„æƒ³æ³•ä¸­åº”ç”¨å®ƒã€‚è¿™é‡Œæˆ‘ç»™æ‚¨ä¸€ä¸ªä¾‹å­ï¼Œå±•ç¤ºå¦‚ä½•å°†
    PyTorch çš„å¤šå¤´æ³¨æ„åŠ›åˆ‡æ¢åˆ°æˆ‘ä»¬çš„ Torch Text å¤šå¤´æ³¨æ„åŠ›å®¹å™¨ã€‚
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_9.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_9.png)'
- en: Just with this a few linesã€‚User has more flexibility to try different custom
    component with the concept multi attentionã€‚You can putã€‚Custom in projection containerï¼Œ
    multihaitation containerã€‚O skilled dog productsã€‚ you can apply different idea
    with this multi hair attention containerã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»…é€šè¿‡è¿™å‡ è¡Œï¼Œç”¨æˆ·å¯ä»¥æ›´çµæ´»åœ°å°è¯•ä¸åŒçš„è‡ªå®šä¹‰ç»„ä»¶ï¼Œä¸å¤šå¤´æ³¨æ„åŠ›çš„æ¦‚å¿µç›¸ç»“åˆã€‚æ‚¨å¯ä»¥æ”¾ç½®è‡ªå®šä¹‰çš„æŠ•å½±å®¹å™¨ã€å¤šå¤´æ³¨æ„åŠ›å®¹å™¨ã€‚O æŠ€èƒ½ç‹—äº§å“ã€‚æ‚¨å¯ä»¥åœ¨è¿™ä¸ªå¤šå¤´æ³¨æ„åŠ›å®¹å™¨ä¸­åº”ç”¨ä¸åŒçš„æƒ³æ³•ã€‚
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_11.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_11.png)'
- en: Okayï¼Œ lastï¼Œ but not leastã€‚On our websiteï¼Œ we have several text related tutorialsã€‚Including
    the one to show how to use the new data set for text classification analysisã€‚Please
    check out those tutorial and have some idea about how to write those into an NLP
    pipelineã€‚Keep in mindï¼Œ like we will also update this tutorial and to show how
    to build the N to N pipeline with theã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ã€‚åœ¨æˆ‘ä»¬çš„ç½‘ç«™ä¸Šï¼Œæˆ‘ä»¬æœ‰å‡ ä¸ªä¸æ–‡æœ¬ç›¸å…³çš„æ•™ç¨‹ï¼ŒåŒ…æ‹¬ä¸€ä¸ªå±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ•°æ®é›†è¿›è¡Œæ–‡æœ¬åˆ†ç±»åˆ†æçš„æ•™ç¨‹ã€‚è¯·æŸ¥çœ‹è¿™äº›æ•™ç¨‹ï¼Œäº†è§£å¦‚ä½•å°†å…¶å†™å…¥
    NLP ç®¡é“ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬ä¹Ÿä¼šæ›´æ–°è¿™ä¸ªæ•™ç¨‹ï¼Œä»¥å±•ç¤ºå¦‚ä½•æ„å»º N åˆ° N ç®¡é“ã€‚
- en: With the new Tosht library for different NLP task at the endï¼Œ thank you for
    watching this videoã€‚ and I hope you enjoy the Pytor Develop day for this yearï¼Œ
    and I will see you aroundã€‚![](img/aaa011e1dc72912baa590f68c0c043cd_13.png)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è§†é¢‘çš„æœ€åï¼Œæ„Ÿè°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œå¹¶å¸Œæœ›ä½ äº«å—ä»Šå¹´çš„**Pytorå¼€å‘æ—¥**ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§ï¼![](img/aaa011e1dc72912baa590f68c0c043cd_13.png)
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_14.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_14.png)'
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_15.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaa011e1dc72912baa590f68c0c043cd_15.png)'
