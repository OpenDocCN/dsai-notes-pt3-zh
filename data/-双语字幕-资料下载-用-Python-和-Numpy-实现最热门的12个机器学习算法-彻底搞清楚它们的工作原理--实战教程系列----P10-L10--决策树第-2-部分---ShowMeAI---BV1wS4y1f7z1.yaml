- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Python å’Œ Numpy å®ç°æœ€çƒ­é—¨çš„12ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå½»åº•ææ¸…æ¥šå®ƒä»¬çš„å·¥ä½œåŸç†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P10ï¼šL10-
    å†³ç­–æ ‘ç¬¬ 2 éƒ¨åˆ† - ShowMeAI - BV1wS4y1f7z1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Python å’Œ Numpy å®ç°æœ€çƒ­é—¨çš„12ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå½»åº•ææ¸…æ¥šå®ƒä»¬çš„å·¥ä½œåŸç†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P10ï¼šL10-
    å†³ç­–æ ‘ç¬¬ 2 éƒ¨åˆ† - ShowMeAI - BV1wS4y1f7z1
- en: Hiï¼Œ everybodyã€‚ Welcome to the second part of the decision tree tutorialã€‚ If
    you haven't watched the first partï¼Œ then please do soï¼Œ because thereï¼Œ I will explain
    the theoryã€‚ So here we continue with the implementationï¼Œ and we can start right
    awayã€‚ So we say import numpy S and Pã€‚ and thenã€‚Before we implement the decision
    tree classï¼Œ we will firstã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ã€‚æ¬¢è¿æ¥åˆ°å†³ç­–æ ‘æ•™ç¨‹çš„ç¬¬äºŒéƒ¨åˆ†ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰è§‚çœ‹ç¬¬ä¸€éƒ¨åˆ†ï¼Œè¯·åŠ¡å¿…è§‚çœ‹ï¼Œå› ä¸ºåœ¨é‚£é‡Œæˆ‘ä¼šè§£é‡Šç†è®ºã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬ç»§ç»­å®ç°ï¼Œæˆ‘ä»¬å¯ä»¥ç«‹å³å¼€å§‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å¯¼å…¥numpy
    Så’ŒPã€‚ç„¶åï¼Œåœ¨å®ç°å†³ç­–æ ‘ç±»ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆã€‚
- en: Create our entropy method to calculate the entropyã€‚ and we implement this as
    global functionsã€‚ So we say define entropyã€‚ and this will get a vector y of all
    our class labelsã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_1.png)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºæˆ‘ä»¬çš„ç†µæ–¹æ³•æ¥è®¡ç®—ç†µã€‚æˆ‘ä»¬å°†å…¶å®ç°ä¸ºå…¨å±€å‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å®šä¹‰ç†µã€‚å®ƒå°†è·å–ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç±»åˆ«æ ‡ç­¾çš„å‘é‡yã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_1.png)
- en: And let's have a look at the formulaã€‚ So we have to calculate the number of
    occurrencesï¼Œ and we canã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_3.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå…¬å¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»è®¡ç®—å‡ºç°æ¬¡æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_3.png)
- en: Do this with a functionã€‚ And we call this hist or histogramã€‚ And we can use
    nuy bin countã€‚Of yã€‚ So this will calculate the number of occurrences of all class
    labelsã€‚ and then we divide them by the number of total samplesã€‚ So we say P equals
    hist divided by length of yã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨ä¸€ä¸ªå‡½æ•°æ¥å®Œæˆè¿™é¡¹å·¥ä½œã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºhistæˆ–ç›´æ–¹å›¾ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨nuy bin countã€‚å¯¹yè¿›è¡Œè®¡æ•°ã€‚æ‰€ä»¥è¿™å°†è®¡ç®—æ‰€æœ‰ç±»åˆ«æ ‡ç­¾çš„å‡ºç°æ¬¡æ•°ã€‚ç„¶åæˆ‘ä»¬å°†å®ƒä»¬é™¤ä»¥æ€»æ ·æœ¬æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´Pç­‰äºhisté™¤ä»¥yçš„é•¿åº¦ã€‚
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_5.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_5.png)'
- en: And then we apply the actual formulaã€‚ So we say minus the sum of p of x times
    the log of p of xã€‚ So we can do this in one line and say return minus nu pi sumã€‚
    And here we use less comprehensionã€‚ So we can say P times nupy log2 of P for all
    P in P P and we also have to use a condition if P is greater than 0 because the
    lock is not defined for negative numbersã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åº”ç”¨å®é™…çš„å…¬å¼ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å‡å»pçš„xä¹˜ä»¥logçš„pçš„xçš„æ€»å’Œã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä¸­å®Œæˆè¿™ä¸ªå¹¶è¯´è¿”å›å‡å»nu piçš„æ€»å’Œã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨åˆ—è¡¨æ¨å¯¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´Pä¹˜ä»¥nupy
    log2çš„Pï¼Œé€‚ç”¨äºPä¸­çš„æ‰€æœ‰Pï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜å¿…é¡»ä½¿ç”¨ä¸€ä¸ªæ¡ä»¶ï¼Œå¦‚æœPå¤§äº0ï¼Œå› ä¸ºå¯¹è´Ÿæ•°ä¸å®šä¹‰å¯¹æ•°ã€‚
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_7.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_7.png)'
- en: So this is the entropyã€‚And now we also implement a helper class and call this
    noteã€‚ So here we will store the information for our noteã€‚ So this will get an
    in itã€‚Which gets selfã€‚ And then let's have a look at thisï¼Œ soã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_9.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯ç†µã€‚ç°åœ¨æˆ‘ä»¬è¿˜å®ç°ä¸€ä¸ªè¾…åŠ©ç±»ï¼Œç§°ä¹‹ä¸ºnoteã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å°†å­˜å‚¨æˆ‘ä»¬çš„noteçš„ä¿¡æ¯ã€‚æ‰€ä»¥è¿™å°†è·å–ä¸€ä¸ªåˆå§‹åŒ–ã€‚å®ƒå°†è·å–è‡ªæˆ‘ã€‚ç„¶åæˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªï¼Œã€‚
- en: If we are in the middleï¼Œ then we want to store the best split feature and the
    best split thresholdã€‚And we also want to store the left and the right child treesï¼Œ
    because we need them later andã€‚If we and nowï¼Œ if we are at a leaf noteï¼Œ then we
    also want to store the actual value hereã€‚ So the most common class labelã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å¤„äºä¸­é—´çŠ¶æ€ï¼Œé‚£ä¹ˆæˆ‘ä»¬æƒ³å­˜å‚¨æœ€ä½³åˆ†è£‚ç‰¹å¾å’Œæœ€ä½³åˆ†è£‚é˜ˆå€¼ã€‚æˆ‘ä»¬è¿˜æƒ³å­˜å‚¨å·¦å³å­æ ‘ï¼Œå› ä¸ºæˆ‘ä»¬ç¨åéœ€è¦å®ƒä»¬ã€‚å¦‚æœæˆ‘ä»¬ç°åœ¨å¤„äºå¶èŠ‚ç‚¹ï¼Œæˆ‘ä»¬è¿˜æƒ³åœ¨è¿™é‡Œå­˜å‚¨å®é™…å€¼ã€‚æ‰€ä»¥æœ€å¸¸è§çš„ç±»åˆ«æ ‡ç­¾ã€‚
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_11.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_11.png)'
- en: Soï¼Œ we sayï¼Œ featureã€‚Equals noneã€‚Threshold equals none left equals none right
    equals noneã€‚ And then we use a little trickierã€‚ So we use an asterisk and a commaã€‚
    and then we say value equals noneã€‚ So now if we want to use this value parameterã€‚
    we have to use it as aã€‚Key word only parameterã€‚ So later when we create our leaf
    nodeã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæˆ‘ä»¬è¯´ç‰¹å¾ç­‰äºæ— ã€‚é˜ˆå€¼ç­‰äºæ— ï¼Œå·¦ç­‰äºæ— ï¼Œå³ç­‰äºæ— ã€‚ç„¶åæˆ‘ä»¬ç”¨ä¸€ä¸ªå°æŠ€å·§ã€‚æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ˜Ÿå·å’Œä¸€ä¸ªé€—å·ã€‚ç„¶åæˆ‘ä»¬è¯´å€¼ç­‰äºæ— ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨è¿™ä¸ªå€¼å‚æ•°ï¼Œæˆ‘ä»¬å¿…é¡»å°†å…¶ä½œä¸ºå…³é”®å­—å‚æ•°ä½¿ç”¨ã€‚æ‰€ä»¥ç¨åå½“æˆ‘ä»¬åˆ›å»ºå¶èŠ‚ç‚¹æ—¶ã€‚
- en: which only gets the valueï¼Œ then we also have to write value equals somethingã€‚
    So then it's clearer that this is a leaf nodeã€‚ And here we simply store themã€‚
    So we say self feature equals feature self threshold equals thresholdã€‚Self left
    equals leftã€‚Selfã€‚ right equals rightã€‚And self value equals valueã€‚ And now we also
    create a little help a function to determine if we are at a leaf nodeã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªè·å–å€¼ï¼Œç„¶åæˆ‘ä»¬è¿˜éœ€è¦å†™å€¼ç­‰äºæŸä¸ªä¸œè¥¿ã€‚æ‰€ä»¥è¿™æ ·æ›´æ¸…æ¥šè¿™æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°å­˜å‚¨å®ƒä»¬ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è‡ªæˆ‘ç‰¹å¾ç­‰äºç‰¹å¾ï¼Œè‡ªæˆ‘é˜ˆå€¼ç­‰äºé˜ˆå€¼ã€‚è‡ªæˆ‘å·¦ç­‰äºå·¦ã€‚è‡ªæˆ‘å³ç­‰äºå³ã€‚è‡ªæˆ‘å€¼ç­‰äºå€¼ã€‚ç°åœ¨æˆ‘ä»¬è¿˜åˆ›å»ºä¸€ä¸ªå°è¾…åŠ©å‡½æ•°æ¥ç¡®å®šæˆ‘ä»¬æ˜¯å¦å¤„äºå¶èŠ‚ç‚¹ã€‚
- en: So define fine is leaf nodeã€‚Which gets selfã€‚ And here we simply say ifï¼Œ if we
    areã€‚ if we have a valueï¼Œ then we are at a leaf node and otherwise notã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_13.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰åˆ¤æ–­æ˜¯å¦ä¸ºå¶èŠ‚ç‚¹ã€‚å®ƒè·å–è‡ªç‚¹ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°è¯´ï¼Œå¦‚æœï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¤„äºå¶èŠ‚ç‚¹ï¼Œå¦åˆ™ä¸åœ¨ï¼[](img/84741cb53cd03bf1f8d55692e7a39444_13.png)
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_14.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_14.png)'
- en: So we return self that value is not noneã€‚So if we have a valueï¼Œ then we return
    trueã€‚And this is our helper class for the notesã€‚ And now we can start with the
    actual decision3 classã€‚ So this also gets an in itã€‚Which gets selfã€‚ And then it
    will get some stopping criteriaã€‚ So we call this min samples splitã€‚ And by defaultï¼Œ
    let's say this is2ã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¿”å›è‡ªç‚¹ï¼Œè¯¥å€¼ä¸ä¸ºNoneã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿”å›trueã€‚è¿™æ˜¯æˆ‘ä»¬ä¸ºæ³¨é‡Šå‡†å¤‡çš„è¾…åŠ©ç±»ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹å®é™…çš„decision3ç±»ã€‚å› æ­¤è¿™ä¹Ÿè·å–ä¸€ä¸ªinitã€‚å®ƒè·å–è‡ªç‚¹ã€‚ç„¶åå®ƒä¼šè·å–ä¸€äº›åœæ­¢æ ‡å‡†ã€‚å› æ­¤æˆ‘ä»¬ç§°ä¹‹ä¸ºæœ€å°æ ·æœ¬åˆ†å‰²ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå‡è®¾è¿™æ˜¯2ã€‚
- en: So the minimum samples required to further split our  treeï¼Œ Then the max depthã€‚
    And by defaultã€‚ this is 100ã€‚And then alsoï¼Œ it gets a parameter that we call the
    number of features or n Fesã€‚ And this is noneã€‚ So we don't need thisï¼Œ but we can
    specify itã€‚ So as I saidã€‚ we do a greedy search over all the featuresï¼Œ but we
    can also only loop over a subset of number of featuresã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿›ä¸€æ­¥åˆ†å‰²æˆ‘ä»¬æ ‘æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°ï¼Œç„¶åæ˜¯æœ€å¤§æ·±åº¦ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™æ˜¯100ã€‚ç„¶åå®ƒè¿˜è·å–ä¸€ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç‰¹å¾æ•°é‡æˆ–nFesã€‚è¿™æ˜¯Noneã€‚æ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦è¿™ä¸ªï¼Œä½†æˆ‘ä»¬å¯ä»¥æŒ‡å®šå®ƒã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬å¯¹æ‰€æœ‰ç‰¹å¾è¿›è¡Œè´ªå©ªæœç´¢ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ä»…å¾ªç¯éå†ç‰¹å¾å­é›†ã€‚
- en: And then we randomly select this subsetï¼Œ So this is one of the random factorsã€‚And
    that's also one of the reasons why it's called random forestã€‚ If we extend our
    decision trees to a random forestã€‚ So this is one random factorã€‚And now we simply
    store themã€‚ So we say self dot min samples split equals min samplesã€‚Sorryã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬éšæœºé€‰æ‹©è¿™ä¸ªå­é›†ã€‚è¿™æ˜¯éšæœºå› ç´ ä¹‹ä¸€ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå®ƒè¢«ç§°ä¸ºéšæœºæ£®æ—çš„åŸå› ä¹‹ä¸€ã€‚å¦‚æœæˆ‘ä»¬å°†å†³ç­–æ ‘æ‰©å±•ä¸ºéšæœºæ£®æ—ã€‚é‚£ä¹ˆè¿™å°±æ˜¯ä¸€ä¸ªéšæœºå› ç´ ã€‚ç°åœ¨æˆ‘ä»¬ç®€å•åœ°å­˜å‚¨å®ƒä»¬ã€‚å› æ­¤æˆ‘ä»¬è¯´è‡ªç‚¹æœ€å°æ ·æœ¬åˆ†å‰²ç­‰äºæœ€å°æ ·æœ¬ã€‚æŠ±æ­‰ã€‚
- en: min sample split self dot max step equals maxã€‚Deepã€‚Self dot n features equals
    and featuresã€‚ And we also create a rootã€‚ And by in the beginningï¼Œ this is noneã€‚
    So we later need to know our root so that we know where we should start traversing
    our treeã€‚And now we implement the fit methodã€‚Which gets the training data and
    training labelsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: minæ ·æœ¬åˆ†å‰²è‡ªç‚¹æœ€å¤§æ­¥é•¿ç­‰äºæœ€å¤§ã€‚æ·±åº¦ã€‚è‡ªç‚¹nç‰¹å¾ç­‰äºå’Œç‰¹å¾ã€‚æˆ‘ä»¬è¿˜åˆ›å»ºä¸€ä¸ªæ ¹èŠ‚ç‚¹ã€‚æœ€å¼€å§‹æ—¶ï¼Œè¿™ä¸ªå€¼ä¸ºNoneã€‚å› æ­¤æˆ‘ä»¬åæ¥éœ€è¦çŸ¥é“æˆ‘ä»¬çš„æ ¹èŠ‚ç‚¹ï¼Œä»¥ä¾¿çŸ¥é“ä»å“ªé‡Œå¼€å§‹éå†æˆ‘ä»¬çš„æ ‘ã€‚ç°åœ¨æˆ‘ä»¬å®ç°fitæ–¹æ³•ã€‚è¯¥æ–¹æ³•è·å–è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæ ‡ç­¾ã€‚
- en: So here we want to grow our treeã€‚And then it gets the predict methodã€‚With the
    test labelsã€‚ So here we want to traverse our treeã€‚So let's start with growing
    our treeã€‚ So we say self dot root equalsã€‚ And now we call and create a help a
    function self dot grow3ã€‚ which gets X and yã€‚And we also apply a safety checkã€‚
    So we say self dot and features fits equalsã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬å¸Œæœ›ç”Ÿé•¿æˆ‘ä»¬çš„æ ‘ã€‚ç„¶åå®ƒè·å–é¢„æµ‹æ–¹æ³•ã€‚å¸¦æœ‰æµ‹è¯•æ ‡ç­¾ã€‚å› æ­¤åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³éå†æˆ‘ä»¬çš„æ ‘ã€‚è®©æˆ‘ä»¬å¼€å§‹ç”Ÿé•¿æˆ‘ä»¬çš„æ ‘ã€‚æˆ‘ä»¬è¯´è‡ªç‚¹æ ¹èŠ‚ç‚¹ç­‰äºã€‚ç°åœ¨æˆ‘ä»¬è°ƒç”¨å¹¶åˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°è‡ªç‚¹grow3ã€‚å®ƒè·å–Xå’Œyã€‚æˆ‘ä»¬è¿˜åº”ç”¨ä¸€ä¸ªå®‰å…¨æ£€æŸ¥ã€‚å› æ­¤æˆ‘ä»¬è¯´è‡ªç‚¹å’Œç‰¹å¾æ‹Ÿåˆç­‰äºã€‚
- en: X dot shapeã€‚offã€‚1ï¼Œ so this is a nuy and DRAã€‚ And the second dimension is the
    number of featuresã€‚If not self dot and feedã€‚ So if this is not specifiedï¼Œ if this
    is noneã€‚ then we simply take the maximum number of featuresã€‚And otherwiseï¼Œ we
    take the minimum of selfã€‚And feets and X dot shape 1ã€‚So this just makes sure that
    it can never be greater than the actual number of featuresã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: X.dot.shapeã€‚ofã€‚1ï¼Œæ‰€ä»¥è¿™æ˜¯nuyå’ŒDRAã€‚ç¬¬äºŒä¸ªç»´åº¦æ˜¯ç‰¹å¾æ•°é‡ã€‚å¦‚æœä¸æ˜¯è‡ªç‚¹å’Œå–‚å…»ã€‚å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œå¦‚æœä¸ºNoneã€‚é‚£ä¹ˆæˆ‘ä»¬ç®€å•åœ°å–æœ€å¤§ç‰¹å¾æ•°é‡ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬å–è‡ªç‚¹å’Œç‰¹å¾ä¸X.dot.shape
    1çš„æœ€å°å€¼ã€‚è¿™åªæ˜¯ç¡®ä¿å®ƒæ°¸è¿œä¸ä¼šå¤§äºå®é™…ç‰¹å¾æ•°é‡ã€‚
- en: And now we implement theã€‚Grow treeã€‚Methodï¼Œ which gets selfã€‚ and then it gets
    X and yã€‚ And also also a depthã€‚ And this is 0 in the beginningã€‚ So we need to
    keep track of the depthã€‚And now let's do thisã€‚ So firstï¼Œ let's get the number
    of samples and the number of featuresã€‚ This is x dot shapeã€‚And then we also want
    to get the number of different labelsã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å®ç°ã€‚ç”Ÿé•¿æ ‘ã€‚æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è·å–è‡ªç‚¹ï¼Œç„¶åè·å–Xå’Œyã€‚åŒæ—¶è¿˜æœ‰ä¸€ä¸ªæ·±åº¦ã€‚æœ€å¼€å§‹æ—¶ä¸º0ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦è·Ÿè¸ªæ·±åº¦ã€‚ç°åœ¨è®©æˆ‘ä»¬å¼€å§‹å§ã€‚é¦–å…ˆï¼Œè·å–æ ·æœ¬æ•°é‡å’Œç‰¹å¾æ•°é‡ã€‚è¿™æ˜¯x.dot.shapeã€‚ç„¶åæˆ‘ä»¬è¿˜æƒ³è·å–ä¸åŒæ ‡ç­¾çš„æ•°é‡ã€‚
- en: So this is the length of nuyã€‚Uniqueã€‚Of yã€‚ So all the different labelsã€‚And nowï¼Œ
    firstã€‚What we do here is firstï¼Œ we apply our stopping criteriaã€‚Tiaã€‚So we say ifã€‚
    and now let's again have a look what we saidã€‚ So we want to check for the maximum
    depthã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_16.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ nuy çš„é•¿åº¦ã€‚y çš„å”¯ä¸€å€¼ã€‚æ‰€ä»¥æ‰€æœ‰ä¸åŒçš„æ ‡ç­¾ã€‚ç°åœ¨ï¼Œé¦–å…ˆæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„æ˜¯ï¼Œé¦–å…ˆåº”ç”¨æˆ‘ä»¬çš„åœæ­¢æ ‡å‡† Tiaã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å¦‚æœã€‚ç°åœ¨å†çœ‹çœ‹æˆ‘ä»¬æ‰€è¯´çš„å†…å®¹ã€‚æˆ‘ä»¬æƒ³æ£€æŸ¥æœ€å¤§æ·±åº¦ã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_16.png)
- en: Then the minimum samples required and if we have no more class distributionï¼Œ
    so we say ifã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_18.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ˜¯æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°ï¼Œå¦‚æœæˆ‘ä»¬æ²¡æœ‰æ›´å¤šçš„ç±»åˆ«åˆ†å¸ƒï¼Œæˆ‘ä»¬è¯´å¦‚æœã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_18.png)
- en: And we say depth is greater or equal than self max depthã€‚Orã€‚Ifã€‚The number of
    different labelsã€‚Equals oneã€‚ So if we have only one class at this nodeï¼Œ or if
    we have number of samplesã€‚Is smaller than the minimum samples requiredã€‚Soã€‚If this
    is trueï¼Œ then we are at the leaf nodeã€‚ So we says let leaf value equals self dot
    mostã€‚Common labelã€‚Of this yã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¯´æ·±åº¦å¤§äºæˆ–ç­‰äºè‡ªèº«çš„æœ€å¤§æ·±åº¦ã€‚æˆ–è€…ï¼Œå¦‚æœä¸åŒæ ‡ç­¾çš„æ•°é‡ç­‰äºä¸€ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬åœ¨è¿™ä¸ªèŠ‚ç‚¹åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œæˆ–è€…æ ·æœ¬æ•°é‡å°äºæ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°ã€‚é‚£ä¹ˆï¼Œå¦‚æœè¿™ä¸€åˆ‡éƒ½æˆç«‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±åœ¨å¶å­èŠ‚ç‚¹ã€‚å› æ­¤æˆ‘ä»¬è¯´è®©å¶å­å€¼ç­‰äºè‡ªèº«çš„æœ€å¸¸è§æ ‡ç­¾ã€‚
- en: And now we create and return our leaf nodeã€‚ So we say return nodeã€‚ And then
    we have to say value equals leaf valueã€‚ And now it gets clear why I use just ask
    the riskã€‚ So here I have to use the value as keywordã€‚ And now it's clear that
    this is a leaf nodeã€‚And now we also need this help a function to say to get the
    most common labelã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬åˆ›å»ºå¹¶è¿”å›æˆ‘ä»¬çš„å¶å­èŠ‚ç‚¹ã€‚å› æ­¤æˆ‘ä»¬è¯´è¿”å›èŠ‚ç‚¹ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»è¯´å€¼ç­‰äºå¶å­å€¼ã€‚ç°åœ¨å¯ä»¥æ¸…æ¥šä¸ºä»€ä¹ˆæˆ‘åªç”¨é—®é£é™©ã€‚åœ¨è¿™é‡Œæˆ‘å¿…é¡»ä½¿ç”¨å€¼ä½œä¸ºå…³é”®å­—ã€‚ç°åœ¨å¾ˆæ¸…æ¥šè¿™æ˜¯ä¸€ä¸ªå¶å­èŠ‚ç‚¹ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªå¸®åŠ©å‡½æ•°æ¥è·å–æœ€å¸¸è§çš„æ ‡ç­¾ã€‚
- en: So let's write this down hereã€‚ So define most common labelï¼Œ which gets selfã€‚And
    then it gets a vector of the glass labelsã€‚ And for thisï¼Œ we use a Python moduleã€‚
    the counter moduleã€‚ So we say from collections import counterã€‚ So I talked about
    this in previous videos alreadyã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŠŠè¿™ä¸ªå†™ä¸‹æ¥ã€‚æ‰€ä»¥å®šä¹‰æœ€å¸¸è§æ ‡ç­¾ï¼Œå®ƒè·å–è‡ªèº«ã€‚ç„¶åè·å–ä¸€ä¸ªç±»åˆ«æ ‡ç­¾çš„å‘é‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª Python æ¨¡å—ï¼Œè®¡æ•°å™¨æ¨¡å—ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ä» collections
    å¯¼å…¥è®¡æ•°å™¨ã€‚æˆ‘åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­å·²ç»è°ˆåˆ°è¿‡è¿™ä¸ªã€‚
- en: please check that out if you're not familiar with the counter moduleã€‚So here
    we can create a counter objectã€‚ Count equals counter of yã€‚ So this willã€‚å—¯ã€‚Calculate
    all the the number of occurrences for all the ysï¼Œ similar to the nu pin countã€‚
    and then we have a most common functionã€‚ So we say most common equals counter
    dot most common of oneã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹è®¡æ•°å™¨æ¨¡å—ä¸ç†Ÿæ‚‰ï¼Œè¯·æŸ¥çœ‹ä¸€ä¸‹ã€‚å› æ­¤åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªè®¡æ•°å™¨å¯¹è±¡ã€‚è®¡æ•°ç­‰äº y çš„è®¡æ•°å™¨ã€‚è¿™å°†ã€‚å—¯ã€‚è®¡ç®—æ‰€æœ‰ y çš„å‡ºç°æ¬¡æ•°ï¼Œç±»ä¼¼äº nu pin
    è®¡æ•°ã€‚ç„¶åæˆ‘ä»¬æœ‰ä¸€ä¸ªæœ€å¸¸è§çš„å‡½æ•°ã€‚å› æ­¤æˆ‘ä»¬è¯´æœ€å¸¸è§ç­‰äºè®¡æ•°å™¨çš„æœ€å¸¸è§å€¼ã€‚
- en: So we only need the very most common labelã€‚ and this will return a lists of
    tusã€‚ So we want to have the first element of the listã€‚ So this is the very most
    common tupleã€‚ and in the tupleï¼Œ there is the value stored and also the number
    of occurrencesã€‚ So we only need the valueã€‚ So we again say index 0ã€‚ So please
    double check it for yourselfã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦æœ€å¸¸è§çš„æ ‡ç­¾ã€‚è¿™å°†è¿”å›ä¸€ä¸ªåˆ—è¡¨ã€‚å› æ­¤æˆ‘ä»¬æƒ³è¦åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ ã€‚è¿™æ˜¯æœ€å¸¸è§çš„å…ƒç»„ã€‚åœ¨å…ƒç»„ä¸­ï¼Œå­˜å‚¨äº†å€¼å’Œå‡ºç°æ¬¡æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦å€¼ã€‚å› æ­¤æˆ‘ä»¬å†æ¬¡è¯´ç´¢å¼•
    0ã€‚æ‰€ä»¥è¯·è‡ªå·±å†ç¡®è®¤ä¸€ä¸‹ã€‚
- en: and then we return thisã€‚This will determine the most common labelã€‚ So now we
    have the tier andã€‚Nowã€‚ if we didn't meet the stopping criteriaï¼Œ then we continueã€‚
    So firstï¼Œ we select the feature indicesã€‚ So feature indices equals nuy random
    choiceã€‚And this will get the number of featuresã€‚ So it will select random numbers
    from between 0 and the number of featuresã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿”å›è¿™ä¸ªã€‚è¿™å°†ç¡®å®šæœ€å¸¸è§çš„æ ‡ç­¾ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº†å±‚çº§ã€‚å¦‚æœæˆ‘ä»¬æ²¡æœ‰æ»¡è¶³åœæ­¢æ ‡å‡†ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç»§ç»­ã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘ä»¬é€‰æ‹©ç‰¹å¾ç´¢å¼•ã€‚å› æ­¤ç‰¹å¾ç´¢å¼•ç­‰äº nuy
    éšæœºé€‰æ‹©ã€‚è¿™å°†è·å–ç‰¹å¾çš„æ•°é‡ã€‚å› æ­¤å®ƒä¼šåœ¨ 0 å’Œç‰¹å¾æ•°é‡ä¹‹é—´é€‰æ‹©éšæœºæ•°ã€‚
- en: And the array should be of sizeï¼Œ self dot and fes that we specifiedã€‚ And we
    also say replace equals false because we don't haveã€‚ don't want to have the same
    indices multiple timesã€‚And nowï¼Œ we do our greedy searchã€‚Soï¼Œ we sayã€‚ best threshã€‚And
    bestï¼Œ all let's do it the other way aroundã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°ç»„çš„å¤§å°åº”è¯¥æ˜¯æˆ‘ä»¬æŒ‡å®šçš„è‡ªèº«çš„å’Œ fesã€‚æˆ‘ä»¬è¿˜è¯´æ›¿æ¢ç­‰äºå‡ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æƒ³å¤šæ¬¡å‡ºç°ç›¸åŒçš„ç´¢å¼•ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¿›è¡Œè´ªå¿ƒæœç´¢ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è¯´æœ€ä½³é˜ˆå€¼ã€‚è¿˜æœ‰æœ€ä½³ï¼Œè®©æˆ‘ä»¬åè¿‡æ¥åšã€‚
- en: best feature and best thrash equals self dotã€‚Best criteriaã€‚ And this will get
    X and y and all the feature indicesã€‚ So this is another helper methodã€‚ So let's
    define it hereã€‚ define itself bestã€‚Criiteterriaã€‚ which gets self and X and y and
    the featureã€‚Inice seesã€‚Soï¼Œ hereã€‚We do our greedy searchã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ä½³ç‰¹å¾å’Œæœ€ä½³é˜ˆå€¼ç­‰äº self.dotã€‚æœ€ä½³æ ‡å‡†ã€‚è¿™å°†è·å– X å’Œ y ä»¥åŠæ‰€æœ‰ç‰¹å¾ç´¢å¼•ã€‚æ‰€ä»¥è¿™æ˜¯å¦ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ã€‚ç°åœ¨è®©æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰å®ƒã€‚å®šä¹‰ self.bestã€‚æ ‡å‡†ã€‚å®ƒè·å–
    self å’Œ X ä»¥åŠ y å’Œç‰¹å¾ã€‚ç´¢å¼•ã€‚æ‰€ä»¥ï¼Œåœ¨è¿™é‡Œã€‚æˆ‘ä»¬è¿›è¡Œè´ªå©ªæœç´¢ã€‚
- en: So we say best gain equals -1ã€‚ So we want to go over all the features and all
    the feature values and calculate the information gainã€‚Soã€‚Nowï¼Œ let's say split
    index andã€‚ğŸ¼Split threshold equals noneã€‚ So both of them are noneã€‚ And then we
    have our first loopã€‚ So4 featureã€‚Index inã€‚Feature indicesã€‚ And now we only want
    to selectã€‚The column vector of this xã€‚ So we say xã€‚X column equalsã€‚X ofã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´æœ€ä½³å¢ç›Šç­‰äº -1ã€‚æˆ‘ä»¬æƒ³è¦éå†æ‰€æœ‰ç‰¹å¾å’Œæ‰€æœ‰ç‰¹å¾å€¼ï¼Œå¹¶è®¡ç®—ä¿¡æ¯å¢ç›Šã€‚æ‰€ä»¥ã€‚ç°åœ¨ï¼Œå‡è®¾æ‹†åˆ†ç´¢å¼•å’Œã€‚ğŸ¼æ‹†åˆ†é˜ˆå€¼ç­‰äºæ— ã€‚æ‰€ä»¥å®ƒä»¬éƒ½æ˜¯æ— çš„ã€‚ç„¶åæˆ‘ä»¬æœ‰æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå¾ªç¯ã€‚å¯¹äºç‰¹å¾ã€‚ç´¢å¼•åœ¨ã€‚ç‰¹å¾ç´¢å¼•ä¸­ã€‚ç°åœ¨æˆ‘ä»¬åªæƒ³é€‰æ‹©ã€‚è¿™ä¸ª
    x çš„åˆ—å‘é‡ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ xã€‚X åˆ—ç­‰äºã€‚X çš„ã€‚
- en: And we want to have all samplesã€‚ but only at this indexã€‚And then we want to
    go over all the possible thresholdsï¼Œ So we sayã€‚Thresholds equals Nyï¼Œ uniqueã€‚Ofã€‚å—¯ã€‚X
    columnã€‚ So we don't want to check the same value twiceã€‚ So like in this example
    hereã€‚ we would check for 30ï¼Œ15ï¼Œ5ï¼Œ10ã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¦æ‰€æœ‰æ ·æœ¬ã€‚ ä½†ä»…åœ¨è¿™ä¸ªç´¢å¼•ä¸Šã€‚ç„¶åæˆ‘ä»¬æƒ³è¦éå†æ‰€æœ‰å¯èƒ½çš„é˜ˆå€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´ã€‚é˜ˆå€¼ç­‰äº Nyï¼Œå”¯ä¸€ã€‚çš„ã€‚å—¯ã€‚X åˆ—ã€‚æ‰€ä»¥æˆ‘ä»¬ä¸æƒ³æ£€æŸ¥ç›¸åŒçš„å€¼ä¸¤æ¬¡ã€‚å°±åƒåœ¨è¿™ä¸ªä¾‹å­ä¸­ã€‚æˆ‘ä»¬ä¼šæ£€æŸ¥
    30ï¼Œ15ï¼Œ5ï¼Œ10ã€‚
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_20.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_20.png)'
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_21.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_21.png)'
- en: 20 and 25ã€‚And now we go over all the possible thresholdsã€‚ So we say for thã€‚Old
    in thresholdsã€‚And now we calculate the information gainï¼Œ we say gain equals self
    dotã€‚In formation gainã€‚Which gets y and the column vectorï¼Œ and also the current
    thresholdsã€‚And then we say if gain is greater than our best gainï¼Œ then our new
    best gain is the current gainã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 20 å’Œ 25ã€‚ç°åœ¨æˆ‘ä»¬éå†æ‰€æœ‰å¯èƒ½çš„é˜ˆå€¼ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å¯¹äº thã€‚æ—§åœ¨é˜ˆå€¼ä¸­ã€‚ç°åœ¨æˆ‘ä»¬è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œæˆ‘ä»¬è¯´å¢ç›Šç­‰äº self.dotã€‚ä¿¡æ¯å¢ç›Šã€‚å®ƒè·å–
    y å’Œåˆ—å‘é‡ï¼Œä»¥åŠå½“å‰é˜ˆå€¼ã€‚ç„¶åæˆ‘ä»¬è¯´å¦‚æœå¢ç›Šå¤§äºæˆ‘ä»¬æœ€ä½³å¢ç›Šï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„æ–°æœ€ä½³å¢ç›Šå°±æ˜¯å½“å‰å¢ç›Šã€‚
- en: And our best split index is the current feature indexã€‚And our best split threshold
    is the current thresholdã€‚And at the endï¼Œ we want to return themã€‚ So we return
    the splitã€‚Indexï¼Œ firstã€‚And then the split thresholdã€‚So this is the greedy searchã€‚
    And now we need another helper function to calculate the information gainã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æœ€ä½³æ‹†åˆ†ç´¢å¼•æ˜¯å½“å‰ç‰¹å¾ç´¢å¼•ã€‚æˆ‘ä»¬çš„æœ€ä½³æ‹†åˆ†é˜ˆå€¼æ˜¯å½“å‰é˜ˆå€¼ã€‚æœ€åï¼Œæˆ‘ä»¬æƒ³è¦è¿”å›å®ƒä»¬ã€‚æ‰€ä»¥æˆ‘ä»¬å…ˆè¿”å›æ‹†åˆ†ã€‚ç´¢å¼•ï¼Œç„¶åæ˜¯æ‹†åˆ†é˜ˆå€¼ã€‚æ‰€ä»¥è¿™æ˜¯è´ªå©ªæœç´¢ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦å¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥è®¡ç®—ä¿¡æ¯å¢ç›Šã€‚
- en: So let's say define information gain with cellã€‚And then it gets y and an X column
    and the thresholdã€‚ So let's call a split thrashã€‚And nowã€‚Let's sayã€‚Let's have a
    look at the formulaï¼Œ againã€‚Soã€‚Sorryã€‚ so we want to calculate the entropy of the
    parent and then a weighted average of the childrenã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å‡è®¾ç”¨å•å…ƒæ ¼å®šä¹‰ä¿¡æ¯å¢ç›Šã€‚ç„¶åå®ƒè·å– y å’Œä¸€ä¸ª X åˆ—åŠé˜ˆå€¼ã€‚æ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸ºæ‹†åˆ†é˜ˆå€¼ã€‚ç°åœ¨ã€‚è®©æˆ‘ä»¬å†çœ‹çœ‹å…¬å¼ã€‚æ‰€ä»¥ã€‚æŠ±æ­‰ã€‚æˆ‘ä»¬æƒ³è¦è®¡ç®—çˆ¶èŠ‚ç‚¹çš„ç†µï¼Œç„¶åæ˜¯å­èŠ‚ç‚¹çš„åŠ æƒå¹³å‡ã€‚
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_23.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_23.png)'
- en: '![](img/84741cb53cd03bf1f8d55692e7a39444_24.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84741cb53cd03bf1f8d55692e7a39444_24.png)'
- en: Soã€‚We calculate the parent entropyã€‚Thenï¼Œ we generateã€‚A splitã€‚Then we calculate
    the weighted average of the child entropieceã€‚ and then we return the information
    gainã€‚So the parent entropyï¼Œ we can simply say parentã€‚Entropy equals entropy because
    we already have this functionã€‚ So parent entropy of what entropy of yã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ã€‚æˆ‘ä»¬è®¡ç®—çˆ¶èŠ‚ç‚¹ç†µã€‚ç„¶åï¼Œæˆ‘ä»¬ç”Ÿæˆã€‚ä¸€ä¸ªæ‹†åˆ†ã€‚ç„¶åæˆ‘ä»¬è®¡ç®—å­èŠ‚ç‚¹ç†µçš„åŠ æƒå¹³å‡ã€‚ç„¶åæˆ‘ä»¬è¿”å›ä¿¡æ¯å¢ç›Šã€‚æ‰€ä»¥çˆ¶èŠ‚ç‚¹ç†µï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´çˆ¶èŠ‚ç‚¹ã€‚ç†µç­‰äºç†µï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æœ‰è¿™ä¸ªå‡½æ•°ã€‚æ‰€ä»¥çˆ¶èŠ‚ç‚¹ç†µå³
    y çš„ç†µã€‚
- en: Then we generate our splitã€‚So we say left indices and rightã€‚Indices equals self
    dot splitã€‚And we split based on this X columnï¼Œ and a split thresholdã€‚Soã€‚We need
    another help of functionï¼Œ soã€‚I hope you can still follow meã€‚ I hope I try to explain
    everything as clear as possibleã€‚ but the code is a little bit more complex than
    usualã€‚ But yeahï¼Œ let's continueã€‚ So let's sayã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ç”Ÿæˆæˆ‘ä»¬çš„æ‹†åˆ†ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å·¦ç´¢å¼•å’Œå³ã€‚ç´¢å¼•ç­‰äº self.dot.splitã€‚æˆ‘ä»¬æ ¹æ®è¿™ä¸ª X åˆ—å’Œä¸€ä¸ªæ‹†åˆ†é˜ˆå€¼è¿›è¡Œæ‹†åˆ†ã€‚æ‰€ä»¥ã€‚æˆ‘ä»¬éœ€è¦å¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œæ‰€ä»¥ã€‚å¸Œæœ›ä½ èƒ½ç»§ç»­è·Ÿä¸Šæˆ‘ã€‚æˆ‘å°½é‡è§£é‡Šå¾—å°½å¯èƒ½æ¸…æ¥šã€‚ä½†ä»£ç æ¯”é€šå¸¸çš„è¦å¤æ‚ä¸€äº›ã€‚ä¸è¿‡æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ç»§ç»­ã€‚æ‰€ä»¥å‡è®¾ã€‚
- en: define split selfã€‚And then it gets x column and our split thresholdã€‚And here
    we can say left indicesã€‚ So here we apply our question and we can use a function
    that is called nuy arc where and here we ask if the value of x column is smaller
    or equal than our split thresholdã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰ split selfã€‚ç„¶åå®ƒè·å– x åˆ—å’Œæˆ‘ä»¬çš„åˆ†è£‚é˜ˆå€¼ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥è¯´å·¦ç´¢å¼•ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„æ¡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå«åš nuy arc
    çš„å‡½æ•°ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬é—® x åˆ—çš„å€¼æ˜¯å¦å°äºæˆ–ç­‰äºæˆ‘ä»¬çš„åˆ†è£‚é˜ˆå€¼ã€‚
- en: So this will return an array where with all where all the these conditions are
    true for all the values in our x column and we want to Latin this array because
    we only want a 1 d vector please check it for yourselfã€‚ and we do the same for
    the right indicesï¼Œ so we say nuyã€‚Arcï¼Œ whereã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°†è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œå…¶ä¸­æ‰€æœ‰æ¡ä»¶å¯¹æˆ‘ä»¬ x åˆ—ä¸­çš„æ‰€æœ‰å€¼éƒ½ä¸ºçœŸï¼Œæˆ‘ä»¬æƒ³è¦æ‹‰ä¸è¿™ä¸ªæ•°ç»„ï¼Œå› ä¸ºæˆ‘ä»¬åªæƒ³è¦ä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œè¯·è‡ªå·±æ£€æŸ¥ä¸€ä¸‹ã€‚æˆ‘ä»¬å¯¹å³ç´¢å¼•åšåŒæ ·çš„æ“ä½œï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´
    nuyã€‚Arcï¼Œå“ªé‡Œã€‚
- en: And here we check if X column is greater than our split thresholdã€‚ And then
    we flatten thisã€‚And then we return the left indices and the right indicesã€‚So now
    we have the split functionã€‚And nowã€‚ if we have theã€‚å—¯ã€‚With this functionï¼Œ we generate
    the split hereã€‚ And firstï¼Œ we check ifã€‚Lengã€‚Of the left indicesã€‚Is 0 or the length
    of theã€‚Right in the C is 0ã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬æ£€æŸ¥ X åˆ—æ˜¯å¦å¤§äºæˆ‘ä»¬çš„åˆ†è£‚é˜ˆå€¼ã€‚ç„¶åæˆ‘ä»¬æ‰å¹³åŒ–å®ƒã€‚ç„¶åæˆ‘ä»¬è¿”å›å·¦ç´¢å¼•å’Œå³ç´¢å¼•ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†åˆ†è£‚å‡½æ•°ã€‚ç°åœ¨ã€‚å¦‚æœæˆ‘ä»¬æœ‰ã€‚å—¯ã€‚é€šè¿‡è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œç”Ÿæˆåˆ†è£‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ£€æŸ¥å·¦ç´¢å¼•çš„é•¿åº¦ã€‚æ˜¯å¦ä¸º
    0 æˆ–å³è¾¹çš„é•¿åº¦æ˜¯å¦ä¸º 0ã€‚
- en: Then we can immediately return 0 as information gainã€‚ And otherwiseï¼Œ we continueã€‚
    So we calculate the weighted averageã€‚ So we need the number of total occurrences
    of or the the the number ofã€‚å—¯ã€‚Of our samplesã€‚Soï¼Œ this is length ofã€‚Yï¼Œ and then
    the number of our left samples and the number of our right samples equals Lng
    left indices and Lng right indicesã€‚ Then we calculate the entropyã€‚ So we say Eï¼Œ
    L and E R equals entropyã€‚Of yã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥ç«‹å³è¿”å› 0 ä½œä¸ºä¿¡æ¯å¢ç›Šã€‚å¦åˆ™ï¼Œæˆ‘ä»¬ç»§ç»­ã€‚æ‰€ä»¥æˆ‘ä»¬è®¡ç®—åŠ æƒå¹³å‡æ•°ã€‚æˆ‘ä»¬éœ€è¦æ ·æœ¬çš„æ€»å‡ºç°æ¬¡æ•°ã€‚æ‰€ä»¥ï¼Œè¿™æ˜¯ Y çš„é•¿åº¦ï¼Œç„¶åå·¦æ ·æœ¬çš„æ•°é‡å’Œå³æ ·æœ¬çš„æ•°é‡ç­‰äº
    Lng å·¦ç´¢å¼•å’Œ Lng å³ç´¢å¼•ã€‚ç„¶åæˆ‘ä»¬è®¡ç®—ç†µã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ Eï¼ŒL å’Œ E R ç­‰äº y çš„ç†µã€‚
- en: of all the left indices and entropy of y of all the right indicesã€‚And nowï¼Œ our
    childã€‚Entropy equals the weighted averageã€‚ So we say N L divided by N timesã€‚The
    left entropy plusã€‚And now N R divided by n times the right entropyã€‚ So this is
    the child entropyã€‚ And now let's calculate the information gainã€‚ This is just
    the parent entropy minus the child entropyã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å·¦ç´¢å¼•çš„ç†µå’Œæ‰€æœ‰å³ç´¢å¼•çš„ç†µã€‚ç°åœ¨ï¼Œæˆ‘ä»¬çš„å­ç†µç­‰äºåŠ æƒå¹³å‡æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ N L é™¤ä»¥ N ä¹˜ä»¥å·¦ç†µåŠ ä¸Šã€‚ç°åœ¨ N R é™¤ä»¥ n ä¹˜ä»¥å³ç†µã€‚æ‰€ä»¥è¿™æ˜¯å­ç†µã€‚ç°åœ¨è®©æˆ‘ä»¬è®¡ç®—ä¿¡æ¯å¢ç›Šã€‚è¿™åªæ˜¯çˆ¶ç†µå‡å»å­ç†µã€‚
- en: and now we return itã€‚ So return the information gainã€‚So now we have this so
    now this function is completeã€‚And now we can have to continue with the growingã€‚Soã€‚Nowï¼Œ
    after we have selected the best criteriaã€‚ we want to split our tree with this
    best feature and best thresholdã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è¿”å›å®ƒã€‚æ‰€ä»¥è¿”å›ä¿¡æ¯å¢ç›Šã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™ä¸ªï¼Œç°åœ¨è¿™ä¸ªå‡½æ•°å®Œæˆäº†ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­ç”Ÿé•¿ã€‚æ‰€ä»¥ã€‚ç°åœ¨ï¼Œåœ¨æˆ‘ä»¬é€‰æ‹©äº†æœ€ä½³æ ‡å‡†ä¹‹åã€‚æˆ‘ä»¬æƒ³ç”¨è¿™ä¸ªæœ€ä½³ç‰¹å¾å’Œæœ€ä½³é˜ˆå€¼æ¥åˆ†è£‚æˆ‘ä»¬çš„æ ‘ã€‚
- en: So we say left indices and right indices equals self dot splitã€‚ So againã€‚ here
    we can use our split functionã€‚ So we say Xã€‚Offã€‚And now we have to be carefulã€‚
    So now we want to have all samplesã€‚å—¯ã€‚But only the bestã€‚Feature indexã€‚Soï¼Œ this
    is a columnã€‚And here we put in the best thresholdã€‚Andã€‚Nowï¼Œ with our left and right
    indicesã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´å·¦ç´¢å¼•å’Œå³ç´¢å¼•ç­‰äºè‡ªèº«çš„ dot splitã€‚å†è¯´ä¸€æ¬¡ã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ split å‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ Xã€‚Offã€‚ç°åœ¨æˆ‘ä»¬å¿…é¡»å°å¿ƒã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æƒ³è¦æ‰€æœ‰æ ·æœ¬ã€‚å—¯ã€‚ä½†åªæœ‰æœ€å¥½çš„ã€‚ç‰¹å¾ç´¢å¼•ã€‚æ‰€ä»¥ï¼Œè¿™æ˜¯ä¸€åˆ—ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæ”¾å…¥æœ€ä½³é˜ˆå€¼ã€‚ç°åœ¨ï¼Œæœ‰äº†æˆ‘ä»¬çš„å·¦ç´¢å¼•å’Œå³ç´¢å¼•ã€‚
- en: we can continue growingã€‚ So we go to the left and say leftã€‚Equalsã€‚And we call
    this function here in itself recursivelyã€‚ So we say self dotã€‚Grow treeã€‚And here
    we say Xã€‚And then we only want the left indicesï¼Œ but we want allã€‚The featuresã€‚So
    and S Yã€‚ we want only want the left indicesã€‚And then we also say depth plus oneã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç»§ç»­ç”Ÿé•¿ã€‚æ‰€ä»¥æˆ‘ä»¬å»å·¦è¾¹å¹¶è¯´å·¦è¾¹ã€‚ç­‰äºã€‚æˆ‘ä»¬åœ¨è¿™é‡Œé€’å½’åœ°è°ƒç”¨è¿™ä¸ªå‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ self dotã€‚Grow treeã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¯´ Xã€‚ç„¶åæˆ‘ä»¬åªæƒ³è¦å·¦ç´¢å¼•ï¼Œä½†æˆ‘ä»¬æƒ³è¦æ‰€æœ‰ç‰¹å¾ã€‚æ‰€ä»¥
    S Yã€‚æˆ‘ä»¬åªæƒ³è¦å·¦ç´¢å¼•ã€‚ç„¶åæˆ‘ä»¬ä¹Ÿè¯´æ·±åº¦åŠ ä¸€ã€‚
- en: So now our depth is increased by oneã€‚And now we do the same thing for the right
    sideã€‚ So we say rightã€‚Equals scroll3 with the right indicesã€‚And now we return
    a new note in the middleã€‚ So this will get the bestã€‚Featureã€‚The best thresholdã€‚And
    the leftï¼Œ and the rightã€‚Childsã€‚ but no value hereã€‚So this is the growing methodã€‚
    And now the only thing left is to implement the predict methodã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çš„æ·±åº¦å¢åŠ äº†ä¸€ã€‚ç°åœ¨æˆ‘ä»¬å¯¹å³ä¾§åšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ right ç­‰äº scroll3 çš„å³ç´¢å¼•ã€‚ç°åœ¨æˆ‘ä»¬åœ¨ä¸­é—´è¿”å›ä¸€ä¸ªæ–°çš„èŠ‚ç‚¹ã€‚æ‰€ä»¥è¿™å°†è·å¾—æœ€ä½³ã€‚åŠŸèƒ½ã€‚æœ€ä½³é˜ˆå€¼ã€‚å·¦å­èŠ‚ç‚¹å’Œå³å­èŠ‚ç‚¹ã€‚ä½†è¿™é‡Œæ²¡æœ‰å€¼ã€‚è¿™æ˜¯ç”Ÿé•¿æ–¹æ³•ã€‚ç°åœ¨å”¯ä¸€å‰©ä¸‹çš„å°±æ˜¯å®ç°é¢„æµ‹æ–¹æ³•ã€‚
- en: And I promise this will be fairly easyã€‚ So we only need one helper functionã€‚
    So we say returnã€‚å—¯ã€‚Numpy arrayã€‚ And here againï¼Œ we use list comprehensionã€‚ So
    we traverse our treeã€‚ So self dot traverse3ï¼Œ where we put in one sample for all
    the samples in capital Xã€‚So this is our predict methodã€‚ And now let's implement
    theã€‚Traverse3 method as last thingã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¿è¯è¿™ä¼šå¾ˆç®€å•ã€‚æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¿”å›ã€‚å—¯ã€‚Numpy æ•°ç»„ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å†æ¬¡ä½¿ç”¨åˆ—è¡¨æ¨å¯¼ã€‚æ‰€ä»¥æˆ‘ä»¬éå†æˆ‘ä»¬çš„æ ‘ã€‚æ‰€ä»¥ self.dot.traverse3ï¼Œåœ¨å“ªé‡Œæˆ‘ä»¬ä¸ºå¤§å†™
    X ä¸­çš„æ‰€æœ‰æ ·æœ¬æ”¾å…¥ä¸€ä¸ªæ ·æœ¬ã€‚è¿™æ˜¯æˆ‘ä»¬çš„é¢„æµ‹æ–¹æ³•ã€‚ç°åœ¨è®©æˆ‘ä»¬å®ç°ã€‚Traverse3 æ–¹æ³•ä½œä¸ºæœ€åä¸€ä»¶äº‹ã€‚
- en: So this will get self and one sampleã€‚ And it also gets a note where we startã€‚
    So we have to put in self dot root in the beginning because we start at the top
    and hereã€‚We also do this recursivelyã€‚ so firstï¼Œ we can check for the stopping
    criteria so we check if we have reached a leaf node so we can say if node is leaf
    nodeã€‚ So that's why we implemented this helper functionã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°†è·å¾— self å’Œä¸€ä¸ªæ ·æœ¬ã€‚å®ƒè¿˜è·å–æˆ‘ä»¬å¼€å§‹çš„èŠ‚ç‚¹ã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»åœ¨å¼€å§‹æ—¶æ”¾å…¥ self.dot.rootï¼Œå› ä¸ºæˆ‘ä»¬ä»é¡¶éƒ¨å¼€å§‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¹Ÿè¿™æ ·é€’å½’è¿›è¡Œã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥åœæ­¢æ ‡å‡†ï¼Œæ‰€ä»¥æˆ‘ä»¬æ£€æŸ¥æ˜¯å¦å·²ç»åˆ°è¾¾å¶èŠ‚ç‚¹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´å¦‚æœèŠ‚ç‚¹æ˜¯å¶èŠ‚ç‚¹ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å®ç°è¿™ä¸ªè¾…åŠ©å‡½æ•°çš„åŸå› ã€‚
- en: then we return node dot value because if we are at a leafã€‚ we also have a value
    and otherwise we apply our question so we go to the left or the rightã€‚Soã€‚ we say
    ifã€‚X of this noteã€‚The feature index that we storedã€‚Is smaller or equal than the
    threshold that we start at this noteã€‚ Then we returnã€‚Self dot Traverse3ã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿”å›èŠ‚ç‚¹çš„å€¼ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬åœ¨å¶å­ä¸Šã€‚æˆ‘ä»¬ä¹Ÿæœ‰ä¸€ä¸ªå€¼ï¼Œå¦åˆ™æˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„é—®é¢˜ï¼Œæ‰€ä»¥æˆ‘ä»¬å»å·¦è¾¹æˆ–å³è¾¹ã€‚æ‰€ä»¥ã€‚æˆ‘ä»¬è¯´å¦‚æœã€‚è¿™èŠ‚ç‚¹çš„ Xã€‚æˆ‘ä»¬å­˜å‚¨çš„åŠŸèƒ½ç´¢å¼•ã€‚æ˜¯å¦å°äºæˆ–ç­‰äºæˆ‘ä»¬åœ¨è¿™ä¸ªèŠ‚ç‚¹å¼€å§‹çš„é˜ˆå€¼ã€‚é‚£ä¹ˆæˆ‘ä»¬è¿”å›ã€‚Self.dot.Traverse3ã€‚
- en: So we go to the left side ofï¼Œ and we put in X and note leftã€‚ So that's why we
    start the left and the right notes at the notesã€‚And otherwiseï¼Œ we returnã€‚Self
    dot traverses3 of x and no dot rightã€‚Soï¼Œ yeahï¼Œ this is the whole Traverse implementationã€‚
    And now we are finally doneã€‚ This is the whole implementation that we need for
    a decision treeã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å»å·¦ä¾§ï¼ŒæŠŠ X å’ŒèŠ‚ç‚¹å·¦æ”¾å…¥ã€‚æ‰€ä»¥è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨èŠ‚ç‚¹å¤„å¼€å§‹å·¦å’Œå³èŠ‚ç‚¹ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬è¿”å›ã€‚Self.dot.traverses3 çš„ x å’Œ no.dot.rightã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™å°±æ˜¯æ•´ä¸ª
    Traverse å®ç°ã€‚ç°åœ¨æˆ‘ä»¬ç»ˆäºå®Œæˆäº†ã€‚è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦çš„æ•´ä¸ªå†³ç­–æ ‘å®ç°ã€‚
- en: And let's check thisã€‚ So I've little little I've written a little help a scriptã€‚A
    test scriptã€‚Where I implement this decision tree class and I use the data setã€‚
    the breast cancer data set from the psychic learn moduleã€‚And I will split our
    data in training labels and training samples and test labels and test samplesã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ã€‚æ‰€ä»¥æˆ‘å†™äº†ä¸€ç‚¹å°å¸®åŠ©è„šæœ¬ã€‚ä¸€ä¸ªæµ‹è¯•è„šæœ¬ã€‚åœ¨è¿™é‡Œæˆ‘å®ç°è¿™ä¸ªå†³ç­–æ ‘ç±»ï¼Œå¹¶ä½¿ç”¨æ•°æ®é›†ã€‚æ¥è‡ª psychic learn æ¨¡å—çš„ä¹³è…ºç™Œæ•°æ®é›†ã€‚æˆ‘å°†æŠŠæˆ‘ä»¬çš„æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒæ ‡ç­¾å’Œè®­ç»ƒæ ·æœ¬ï¼Œä»¥åŠæµ‹è¯•æ ‡ç­¾å’Œæµ‹è¯•æ ·æœ¬ã€‚
- en: Then I will create our decision tree and fit the dataã€‚ then predict the test
    data and calculate the accuracyã€‚ So let's checkã€‚ let's run the script and check
    if everything's workingã€‚Needs a little time toã€‚å—¯ã€‚Sorryã€‚ as traverse3 missing one
    positional argument noteã€‚å—¯ã€‚Self do traverse 3 Xã€‚ Ohã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘å°†åˆ›å»ºæˆ‘ä»¬çš„å†³ç­–æ ‘å¹¶æ‹Ÿåˆæ•°æ®ã€‚ç„¶åé¢„æµ‹æµ‹è¯•æ•°æ®å¹¶è®¡ç®—å‡†ç¡®æ€§ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ£€æŸ¥ã€‚è®©æˆ‘ä»¬è¿è¡Œè„šæœ¬ï¼Œæ£€æŸ¥ä¸€åˆ‡æ˜¯å¦æ­£å¸¸è¿ä½œã€‚éœ€è¦ä¸€ç‚¹æ—¶é—´å»ã€‚å—¯ã€‚å¯¹ä¸èµ·ã€‚ä½œä¸º
    traverse3 ç¼ºå°‘ä¸€ä¸ªä½ç½®å‚æ•°èŠ‚ç‚¹ã€‚å—¯ã€‚Self do traverse 3 Xã€‚å“¦ã€‚
- en: self do root must be hereï¼Œ not hereã€‚So let's clear this and give this another
    tryã€‚And fingers crossedsã€‚Note objectï¼Œ test no attribute feature indexã€‚So this
    isï¼Œ how did we call itï¼Ÿ
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: self do root å¿…é¡»åœ¨è¿™é‡Œï¼Œè€Œä¸æ˜¯è¿™é‡Œã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ¸…é™¤è¿™ä¸ªï¼Œå†è¯•ä¸€æ¬¡ã€‚ç¥æˆ‘ä»¬å¥½è¿ã€‚æ³¨æ„å¯¹è±¡ï¼Œæµ‹è¯•æ²¡æœ‰å±æ€§åŠŸèƒ½ç´¢å¼•ã€‚æ‰€ä»¥è¿™æ˜¯ï¼Œæˆ‘ä»¬æ€ä¹ˆç§°å‘¼å®ƒï¼Ÿ
- en: Just featureï¼Œ sorryã€‚If note thatã€‚Featureã€‚Threholdã€‚The thresholdï¼Œ threshold yoã€‚Soï¼Œ
    one more timeã€‚I hope I have no more typosã€‚So yeahï¼Œ now we have the accuracy and
    everything's workingã€‚ And yeahã€‚ I hope you enjoyed this tutorialã€‚ If you liked
    itï¼Œ please subscribe to the channelã€‚ And in the next tutorialï¼Œ we will continue
    by extending this decision tree to the random forest modelã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åªæ˜¯åŠŸèƒ½ï¼Œå¯¹ä¸èµ·ã€‚å¦‚æœæ³¨æ„åˆ°ã€‚åŠŸèƒ½ã€‚é˜ˆå€¼ã€‚é˜ˆå€¼ï¼Œé˜ˆå€¼ä½ ã€‚æ‰€ä»¥ï¼Œå†ä¸€æ¬¡ã€‚æˆ‘å¸Œæœ›æˆ‘æ²¡æœ‰æ›´å¤šçš„é”™å­—ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†å‡†ç¡®æ€§ï¼Œä¸€åˆ‡éƒ½åœ¨æ­£å¸¸è¿ä½œã€‚è€Œä¸”æ˜¯çš„ã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ã€‚å¦‚æœä½ å–œæ¬¢ï¼Œè¯·è®¢é˜…é¢‘é“ã€‚åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­å°†è¿™ä¸ªå†³ç­–æ ‘æ‰©å±•åˆ°éšæœºæ£®æ—æ¨¡å‹ã€‚
- en: So yeahï¼Œ see you then byeã€‚ğŸ˜Šã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_26.png)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå¥½çš„ï¼Œå¾…ä¼šè§ï¼Œå†è§ã€‚ğŸ˜Šã€‚![](img/84741cb53cd03bf1f8d55692e7a39444_26.png)
