- en: 【双语字幕+资料下载】PyTorch 极简实战教程！全程代码讲解，在实践中掌握深度学习&搭建全pipeline！＜实战教程系列＞ - P20：L20-
    RNN & LSTM & GRU - 循环神经网络 - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】PyTorch 极简实战教程！全程代码讲解，在实践中掌握深度学习&搭建全pipeline！＜实战教程系列＞ - P20：L20-
    RNN & LSTM & GRU - 循环神经网络 - ShowMeAI - BV12m4y1S7ix
- en: Hi and welcome to your new Pytorch tutorial。 Today。 I show you how we can implement
    a recurrent neural net using the built in R and N module。 In the last tutorial，
    we implemented the R and N from scratch。 and I highly recommend to watch this
    one first to understand the internal architecture of R Ns。😊。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，欢迎来到你的新Pytorch教程。今天，我将向你展示如何使用内置的RnN模块实现一个递归神经网络。在上一个教程中，我们从头开始实现了RnN。我强烈建议先观看这个教程，以了解RnN的内部结构。😊
- en: And now today， we focus on the implementation with Pytorch's own module。 so
    we don't have to implement everything by ourselves。 I will show you how to use
    the RnN module。 And then at the end， I also show you how easily we can switch
    our Rn N model and use special kinds of RNs like LSTM and G。 So let's start。 and
    we are going to use my tutorial about a simple neural net as starting point。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们专注于使用Pytorch自己的模块进行实现，所以我们不必自己实现所有内容。我将向你展示如何使用RnN模块。最后，我还会向你展示如何轻松切换我们的RnN模型，并使用特殊类型的Rn，如LSTM和GRU。所以让我们开始吧。我们将以我的简单神经网络教程作为起点。
- en: So this is tutorial number 13 from my Pytorch beginner course。 You can find
    the link to the video and also to the code on Gitub in the description below。
    So as I said， this is tutorial number 13。 So I already grab this code and copied
    it to my editor。 And then this example， we are doing diit classification on the
    Mnes data sets。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我Pytorch初学者课程的第13个教程。你可以在下面的描述中找到视频和代码的链接。正如我所说，这是第13个教程。我已经将这段代码抓取并复制到我的编辑器中。在这个例子中，我们在Mnes数据集上进行数字分类。
- en: And I have to say that image classification is not the typical example for RnNs。
    But what I want to demonstrate here is how we must treat our input。😊。![](img/4923e3db142c0d58fa13de82f2b481db_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须说，图像分类并不是RnN的典型例子。但我想在这里演示的是我们必须如何处理输入。😊![](img/4923e3db142c0d58fa13de82f2b481db_1.png)
- en: As a sequence and then set up the correct shapes， and it also shows that RnNs
    can indeed be used to get a high accuracy on this classification task。 So last
    time we learned that the special thing about RnNs is that we work on sequences
    of vectors here。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 将其视为一个序列，然后设置正确的形状，这也表明RnN确实可以用于在这个分类任务中获得高准确度。所以下次我们了解到，RnN的特殊之处在于我们在这里处理向量的序列。
- en: So we treat our input as a sequence。 and there can be different types of Rnns。
    So in this example we used this many to one architecture。 So here we have a sequence
    as a input and then only one output at the end。 and this is our class label in
    this case。 So let's jump to the code。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们将输入视为一个序列。RnN有不同类型。在这个例子中，我们使用了这种多对一的架构。这里我们有一个序列作为输入，最后只有一个输出。这个就是我们的类标签。所以让我们跳到代码。
- en: and the first thing we must change is the hyperparameter。 So the Ms data set
    consists of images of size 28 by 28 pixels。 and last time we squeeze that into
    one dimensions。Our input size was 28 times 28 or 784。 and this time， as I said，
    we treat the image as a sequence。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们必须改变的是超参数。所以Ms数据集由28乘28像素的图像组成。上次我们将其压缩为一维。我们的输入大小为28乘28或784。这次，如我所说，我们将图像视为一个序列。
- en: So what we do here now is we treat one image dimension as one sequence and the
    other image dimension as the input or feature size。So you can see this as that
    we are looking at one row at a time。 So let's comment and this out。 and let's
    create a new one。 So let's say our input size equals。 And now， as I said。 we are
    looking at one row at a time。 So this is 28。 And then we also create the sequence
    length。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们做的是将一个图像维度视为一个序列，另一个图像维度视为输入或特征大小。你可以将其视为我们一次查看一行。让我们注释掉这个，然后创建一个新的。假设我们的输入大小等于。现在，如我所说，我们一次查看一行。这是28。然后我们也创建序列长度。
- en: And this is also 28。 And then we change the hidden size to be 128。 So you can
    try our different sizes here。 And we add another hyperparmeter。 and this is the
    number of layers。 And here I set this to2。 So by default， it is one。 And this
    means that we are stacking in this case， two R and Ns together。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是28。然后我们将隐藏层大小更改为128。所以你可以在这里尝试不同的大小。我们再添加一个超参数，这是层数。这里我设置为2。默认情况下为1。这意味着我们在此情况下叠加两个RnN。
- en: and the second R and N takes the output from the first R and n as an input。
    So this can further improve our model。And now we want to implement the R and N
    class。 So let's change the name to R and N。 and also in this super method。And
    then our model down here also now is the R and N。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个R和N将第一个R和N的输出作为输入。这可以进一步改善我们的模型。现在我们想要实现R和N类。所以我们将名称改为R和N。在这个超类方法中也是如此。然后我们下面的模型现在也是R和N。
- en: And now let's delete all of this to start with a new， fresh implementation。So
    now our R and N has still has the input size and the hidden size and the number
    of classes as parameters。 And it also gets the new parameter number of layers。
    So let's put it in here。 So let's say the number of layers here。 And then， of
    course。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们删除所有这些，开始一个新的、干净的实现。所以现在我们的R和N仍然有输入大小、隐藏大小和类别数作为参数。它还获取新的参数层数。我们将其放在这里。因此，假设层数在这里。那么，当然。
- en: we must also pass it to our model when we create it。 So this is our hyperparameter。😊。And
    then what we want to do here first is we simply want to store the number of layers
    and the hidden size。 So let's say self nu layers equals nu layers。And also， self
    dot。Hidden。Size equals hidden size。And then we create the R and N model and use
    the built in Pytorch R and N module。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在创建模型时也必须将其传递给模型。这是我们的超参数。😊。然后我们在这里首先想做的是简单地存储层数和隐藏大小。所以我们说self nu layers等于nu
    layers。还有，self.dot hidden size等于hidden size。然后我们创建R和N模型，并使用内置的Pytorch R和N模块。
- en: So you can find this here on the official documentation。 So this is the R and
    N class that Pytorch provides for us。 So we are going to use this。 So we create
    an R and N and say self R and N equals。 And now this is in the NN module。 So NN
    dot R and N。![](img/4923e3db142c0d58fa13de82f2b481db_3.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以在官方文档中找到这个。所以这是Pytorch为我们提供的R和N类。我们将使用这个。因此，我们创建一个R和N并说self R和N等于。现在这在NN模块中。所以NN.dot
    R和N。![](img/4923e3db142c0d58fa13de82f2b481db_3.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_4.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_4.png)'
- en: And the R and N needs the input size。 It needs the hidden size。 and it needs
    the number of layers in this order。 And then we also use a parameter that is called
    batch first and set this to true。 So this just means that we must have the batch
    as a first dimension。 So our input needs to have the shape。Btch size。Bch size
    and then the sequence length。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: R和N需要输入大小。它需要隐藏大小，并且需要按此顺序的层数。然后我们还使用一个叫做batch first的参数，并将其设置为true。这意味着我们必须将batch作为第一维。因此，我们的输入需要具有形状。Batch
    size，Batch size，然后是序列长度。
- en: and then the input or feature size。 So this is the shape that we need to have
    for our input。![](img/4923e3db142c0d58fa13de82f2b481db_6.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是输入或特征大小。所以这是我们输入所需的形状。![](img/4923e3db142c0d58fa13de82f2b481db_6.png)
- en: And again， you can find this in the documentation。 So if you set batch first
    to true。 then here you need this shape。![](img/4923e3db142c0d58fa13de82f2b481db_8.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你可以在文档中找到这个。所以如果你将batch first设置为true，那么在这里你需要这个形状。![](img/4923e3db142c0d58fa13de82f2b481db_8.png)
- en: So now what we want to do is before we pass the images to our model。 So last
    time we reshaped it to be this size。 So originally our batch or our images have
    the size the batch size than a one and then 28 and then 28 again。 So this time
    we only want to have our batch size and then 28 by 28。 So here we reshape it to
    be this size and then the 28。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们想要做的是在将图像传递给我们的模型之前。所以下次我们将其调整为这个大小。因此，最初我们的batch或图像的大小是batch size，然后是1，然后是28，然后再28。因此，这次我们只想要batch
    size，然后是28乘28。所以在这里我们将其调整为这个大小，然后是28。
- en: the first one is our sequence length and the second one is our input size。 So
    these are both 28。 and the same in our so this is in our training loop and then
    later in our evaluation loop。 we do the same。 So here we also have to reshape
    it to。This size。 So now we have our input in the correct shape。And now we need
    one more layer。 So as I said。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是我们的序列长度，第二个是我们的输入大小。所以这两个都是28。在我们的训练循环中也是如此，然后在我们的评估循环中，我们也做同样的事情。因此，在这里我们还需要将其调整为这个大小。现在我们的输入形状正确了。现在我们还需要一层。因此，正如我所说。
- en: we are using this many to one architecture。 So in the end we have a classification
    task。 So this means that we are using a linear layer and then later the soft marks
    and the crossenttropis。 So let's create one more linear layer。 So let's say self
    dot Fc for fully connected equals nn dot linear。 And now here we want to be careful。
    So for the input size。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用这种多对一的架构。所以最终我们有一个分类任务。这意味着我们使用一个线性层，然后是 softmax 和交叉熵。因此让我们再创建一个线性层。我们可以说
    self dot Fc，表示全连接层等于 nn dot linear。在这里我们要小心。对于输入大小。
- en: we use the hidden size and the output size is the number of classes。 and I will
    explain this later again， but basically as we can see in this image or also in
    this image we only use the last time step of our。ence to do the classification。
    So we only need the last hidden size as the input size for the linear layer。 So
    this is basically the whole init function。 And now， of course。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用隐藏大小，输出大小是类别的数量。我稍后会再次解释，但基本上正如我们在这张图像中看到的，或者在这张图中，我们只使用最后一个时间步的隐藏状态来进行分类。因此，我们只需要最后一个隐藏大小作为线性层的输入大小。这基本上就是整个初始化函数。现在，当然。
- en: we also need to implement the forward pass。 So our R and N。 If we have a look
    at the documentation。![](img/4923e3db142c0d58fa13de82f2b481db_10.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要实现前向传播。因此我们的 R 和 N。如果我们查看文档。![](img/4923e3db142c0d58fa13de82f2b481db_10.png)
- en: Then it needs two inputs， and the one is the the first one is the input。 and
    the second one is the initial hidden state。 So we need this in the correct shape。
    And so let's create an a tensor with just0。 So we say H0 equals。 And then let's
    say torch dot0s。 And then here the first one is the number of layers。 The second
    one is the batch size。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后它需要两个输入，第一个是输入，第二个是初始隐藏状态。所以我们需要以正确的形状来处理这个。因此，让我们创建一个 tensor，内容为 just0。所以我们说
    H0 等于。然后我们说 torch dot0s。在这里，第一个是层数，第二个是批大小。
- en: So we get this by saying x dot size0。 The next dimension is the hidden size。
    So we say self dot hidden size。 And then we also want to push it to the device。
    If you're using one。![](img/4923e3db142c0d58fa13de82f2b481db_12.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们通过说 x dot size0 得到这个。下一个维度是隐藏大小。因此我们说 self dot hidden size。然后我们还想将其推送到设备上。如果你在使用一个。![](img/4923e3db142c0d58fa13de82f2b481db_12.png)
- en: So now this is our initial hidden state， and now we can call our R and N model。
    So we say out and then a underscore because we don't need this。 and then we say
    self dot R and N。 and this gets x and H0。 So again， let's have a look at the documentation。
    So it delivers two outputs。 and the first tenor contains the output features or
    the hidden states from all the time steps。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在这是我们的初始隐藏状态，现在我们可以调用我们的 R 和 N 模型。所以我们说 out，然后加下划线，因为我们不需要这个。然后我们说 self dot
    R 和 N。这会得到 x 和 H0。所以再次查看文档。它返回两个输出，第一个 tensor 包含来自所有时间步的输出特征或隐藏状态。
- en: And the other one is just the hidden state for the step N。 So we don't need
    this in this case。 So now we have the output and the output is of size。 This is
    batch。![](img/4923e3db142c0d58fa13de82f2b481db_14.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 而另一个只是步骤 N 的隐藏状态。因此在这种情况下我们不需要这个。所以现在我们有了输出，输出的大小是。这是批次。![](img/4923e3db142c0d58fa13de82f2b481db_14.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_15.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_15.png)'
- en: Btch size， and then we have the sequence length， and then we have the hidden
    size。 So this is the new shape of our output。And now what we want to do is we
    want to decocode the hidden state only of the last time step。So what we have here
    again， let's write this in number。 So this is n。 and then 28。 and our hidden size
    is 128。 And now we only want the last time step。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 批大小，然后我们有序列长度，然后是隐藏大小。这是我们输出的新形状。现在我们想做的是仅解码最后一个时间步的隐藏状态。因此我们这里再次写出数字。这是 n，和
    28，而我们的隐藏大小是 128。现在我们只想要最后一个时间步。
- en: So we want to have our out to be in n and then 128。 So we get this by saying
    out equals out。 And then we use this slicing here and take all。The samples in
    our batch。 and then only the last time step。 So we can say-1。 And then again。
    a colon for all the features in the hidden size。 So now we have our out in this
    size。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们希望我们的输出在 n 和 128。因此我们通过说 out equals out 得到这个。然后我们在这里使用切片，获取批次中的所有样本，且仅取最后一个时间步。我们可以说
    -1。然后再次使用冒号获取隐藏大小中的所有特征。现在我们得到了这个大小的输出。
- en: And now that's why we need the hidden size as the input size for our linear
    layer。 So now we can call that。 So now we can say out equal self dot fully connected
    with our out。 And then we return the out。 So now this is the whole implementation
    that we need for our R and N。 So。Everything else stays the same in our training
    and evaluation loop。 And again。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要隐藏大小作为线性层输入大小的原因。所以现在我们可以调用它。现在我们可以说out等于self.fully_connected与我们的out。然后我们返回out。这就是我们为R和N所需的整个实现。所以，我们训练和评估循环中的其他一切保持不变。再次。
- en: what we have to be careful here is to treat our input as a sequence。 And then
    when we use the build in R and N that we use the correct shape。 and then we need
    the initial hidden state also in the correct shape。 And then we have to reshape
    it before we pass it to our fully connected layer。 So let's try it out。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要注意的是将输入视为一个序列。当我们使用内置的R和N时，我们需要使用正确的形状。然后我们还需要将初始隐藏状态设置为正确的形状。在将其传递给全连接层之前，我们必须重新调整它的形状。所以我们来试试看。
- en: So let's say Python main dot pi。😊，Al right， so now training is done and as you
    can see。 we get a accuracy of 93%。 so our R and N works and you can see that it
    can be applied on this classification task。![](img/4923e3db142c0d58fa13de82f2b481db_17.png)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们可以说Python main.pi。😊，好的，现在训练完成，正如你所看到的，我们得到了93%的准确率。因此我们的R和N有效，你可以看到它可以应用于这个分类任务。![](img/4923e3db142c0d58fa13de82f2b481db_17.png)
- en: And now at the end， I also want to show you two more R and N modules。 So two
    special kinds。 The first one is the GR U or gated recurrent unit。And the second
    one is the LSTM or long short term memory。 So both both are also very popular
    R and Ns。 And I will not explain the theory about them right now。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在最后，我还想向你展示两个R和N模块。所以两种特殊类型。第一个是GRU或门控递归单元。第二个是LSTM或长短期记忆。两者也是非常流行的R和N。我现在不会解释它们的理论。
- en: I will just show you how easily we can use them as well with this implementation。
    So let's use the R U first。 So we can simply say N N dot G R U。 And let's also
    call this self dot G R U and down here self dot G R U。 And everything else stay
    exactly the same。 So it takes the same input parameters。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我将向你展示我们如何轻松地使用这些实现。所以我们首先使用RU。我们可以简单地说nn.GRU。然后再称之为self.GRU，下面也称为self.GRU。其他一切保持不变。所以它接受相同的输入参数。
- en: It also needs this hidden state。 And then the output is in the same shape。 So
    now let's run this with the G R U and test this。![](img/4923e3db142c0d58fa13de82f2b481db_19.png)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 它还需要这个隐藏状态。然后输出具有相同的形状。现在让我们使用GRU并测试一下。![](img/4923e3db142c0d58fa13de82f2b481db_19.png)
- en: Alright， so now as you can see， the GR U works too。 So the accuracy was even
    higher here。 And now as last thing， let's also try the LSTM。 So as you might know
    for the LSTM。 we need an initial cell state。 So let's use the LSTM。 So let's first
    call the cell dot LSTM。 And then here we use Nn dot LSTM。 The input parameters
    are still the same。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，正如你所看到的，GRU也能正常工作。这里的准确率甚至更高。最后一件事，让我们也试试LSTM。正如你可能知道的，对于LSTM，我们需要一个初始单元状态。所以让我们使用LSTM。首先调用cell.LSTM。然后在这里使用nn.LSTM。输入参数仍然是相同的。
- en: And then here we need an initial tenor for the cell state。 So let's call this
    C0。 And this has the same shape。 And then here we call the self dot LSTM。 And
    this needs the hidden state and the cell state as a as a tuple here。😊。![](img/4923e3db142c0d58fa13de82f2b481db_21.png)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后这里我们需要一个初始的单元状态。所以我们称之为C0。这具有相同的形状。接下来我们调用自我LSTM。这需要隐藏状态和单元状态作为一个元组在这里。😊。![](img/4923e3db142c0d58fa13de82f2b481db_21.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_22.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_22.png)'
- en: So now this is all we need to apply the LSTM。 So let's clear this and run it
    one more time。Alright。 so this one work 2。 and you can see the accuracy is 97%。
    So， yeah。 so now you know how you can implement a R and N in Pyar using the build
    in R and N module。 and you also know how you can use the tier U and the LSTM。
    And yeah。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在这就是我们应用LSTM所需的一切。让我们清理一下，再运行一次。好的，这一次工作得很好。你可以看到准确率是97%。所以，是的，现在你知道如何在Pyar中实现R和N，使用内置的R和N模块。你也知道如何使用GRU和LSTM。嗯，是的。
- en: I hope you enjoyed this tutorial。 If you liked it。 Then please consider subscribing
    to the channel and hit the like button and see you next time bye。😊。![](img/4923e3db142c0d58fa13de82f2b481db_24.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这个教程。如果你喜欢它，请考虑订阅频道并点击点赞，下次见，拜拜。😊。![](img/4923e3db142c0d58fa13de82f2b481db_24.png)
