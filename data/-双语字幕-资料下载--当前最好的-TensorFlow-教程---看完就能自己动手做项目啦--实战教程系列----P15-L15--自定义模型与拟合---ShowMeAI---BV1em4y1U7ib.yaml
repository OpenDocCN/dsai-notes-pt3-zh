- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P15ï¼šL15- è‡ªå®šä¹‰æ¨¡å‹ä¸æ‹Ÿåˆ
    - ShowMeAI - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½]â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P15ï¼šL15- è‡ªå®šä¹‰æ¨¡å‹ä¸æ‹Ÿåˆ
    - ShowMeAI - BV1em4y1U7ib'
- en: Alrightyï¼Œ what is going on guysã€‚ Welcome back for another video In this videoã€‚
    we're gonna to explore how to build more flexible training loopsã€‚ So far we've
    been using model that fit and if you can use model that fit that's greatã€‚ but
    sometimes you need more flexibilityã€‚ So in this video we will look at customizing
    model that fitã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½äº†ï¼Œä¼™è®¡ä»¬å‘ç”Ÿäº†ä»€ä¹ˆã€‚ æ¬¢è¿å›æ¥çœ‹å¦ä¸€ä¸ªè§†é¢‘åœ¨è¿™ä¸ªè§†é¢‘ä¸­ã€‚ æˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•æ„å»ºæ›´çµæ´»çš„è®­ç»ƒå¾ªç¯ã€‚ åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨æ¨¡å‹é€‚åˆï¼Œå¦‚æœæ‚¨å¯ä»¥ä½¿ç”¨æ¨¡å‹é€‚åˆé‚£æ˜¯å¾ˆæ£’çš„ã€‚
    ä½†æœ‰æ—¶å€™ä½ éœ€è¦æ›´å¤šçš„çµæ´»æ€§ã€‚ æ‰€ä»¥åœ¨è¿™ä¸ªè§†é¢‘ä¸­æˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•è‡ªå®šä¹‰æ¨¡å‹é€‚åˆã€‚
- en: And then in the next video how we will look at how to build custom training
    loops from scratchã€‚![](img/a08532ac4d7c10fff24b74debc5b0588_1.png)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä»å¤´å¼€å§‹æ„å»ºè‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ã€‚ ![](img/a08532ac4d7c10fff24b74debc5b0588_1.png)
- en: '![](img/a08532ac4d7c10fff24b74debc5b0588_2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a08532ac4d7c10fff24b74debc5b0588_2.png)'
- en: All rightï¼Œ so first of allï¼Œ here are just some basic importsï¼Œ those are you've
    all seen those beforeã€‚ and then we're just going to load the the Ms data setã€‚So
    we're not going to do anything complicatedã€‚ I'm just going to show you the general
    structure and then that can be applied to many different problemsã€‚Alrightï¼Œ so
    we're going to xtrain y trainï¼Œ x testï¼Œ y testï¼Œ and we're just going to M load
    dataã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œé¦–å…ˆï¼Œè¿™é‡Œåªæ˜¯ä¸€äº›åŸºæœ¬çš„å¯¼å…¥ï¼Œä½ ä»¬ä»¥å‰éƒ½è§è¿‡è¿™äº›ã€‚ ç„¶åæˆ‘ä»¬åªéœ€åŠ è½½Msæ•°æ®é›†ã€‚ æ‰€ä»¥æˆ‘ä»¬ä¸ä¼šåšä»»ä½•å¤æ‚çš„äº‹æƒ…ã€‚ æˆ‘åªæ˜¯æƒ³å‘ä½ å±•ç¤ºä¸€èˆ¬ç»“æ„ï¼Œç„¶åå¯ä»¥åº”ç”¨äºè®¸å¤šä¸åŒçš„é—®é¢˜ã€‚
    å¥½å§ï¼Œæˆ‘ä»¬è¦xtrain y trainï¼Œx æµ‹è¯•ï¼Œy æµ‹è¯•ï¼Œæˆ‘ä»¬åªæ˜¯è¦MåŠ è½½æ•°æ®ã€‚
- en: then we're going to do xtrain is xtrain dot reshape then we're just going to
    haveã€‚ I guess minus1 for all the examples and then 28281 and we're doing reshape
    here just to add this channel right hereã€‚And then as type converted to flow 32
    and then normalize with dividing by 255ã€‚ So let let's copy this and let's go new
    lineã€‚And do X testã€‚testï¼Œ and thenã€‚Let's create our modelã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¦åš xtrain æ˜¯ xtrain ç‚¹é‡å¡‘ç„¶åæˆ‘ä»¬åªä¼šæœ‰ã€‚ æˆ‘çŒœæ‰€æœ‰çš„ä¾‹å­å‡å»1ï¼Œç„¶å28281ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œåšé‡å¡‘åªæ˜¯ä¸ºäº†æ·»åŠ è¿™ä¸ªé¢‘é“ã€‚ ç„¶åä½œä¸ºç±»å‹è½¬æ¢ä¸ºæµ32ï¼Œç„¶åé€šè¿‡é™¤ä»¥255æ¥è§„èŒƒåŒ–ã€‚
    æ‰€ä»¥è®©æˆ‘ä»¬å¤åˆ¶è¿™ä¸ªï¼Œè®©æˆ‘ä»¬æ¢ä¸€è¡Œã€‚ å¹² X æµ‹è¯•ã€‚ æµ‹è¯•ï¼Œå¹¶ä¸”ã€‚ è®©æˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: first of allï¼Œ so as the model is equal to ks that sequentialã€‚Then we're going
    to do layer thatt inputã€‚And then the shape of the input is 28ï¼Œ281ã€‚Layers come
    to the 64ï¼Œ3 kernel size and I'm padding same so I'm just going through this quicklyã€‚
    this is not really the most important part of the videoã€‚ğŸ˜”ï¼ŒSo now that we have
    a modelã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæ‰€ä»¥æ¨¡å‹ç­‰äºksé¡ºåºã€‚ ç„¶åæˆ‘ä»¬è¦åšçš„å±‚è¾“å…¥ã€‚ ç„¶åè¾“å…¥çš„å½¢çŠ¶æ˜¯28,281ã€‚ å±‚æ¥åˆ°64,3å†…æ ¸å¤§å°ï¼Œæˆ‘å¡«å……ç›¸åŒï¼Œæ‰€ä»¥æˆ‘åªæ˜¯å¿«é€Ÿåœ°é€šè¿‡è¿™ä¸ªã€‚ è¿™å®é™…ä¸Šä¸æ˜¯è§†é¢‘çš„æœ€é‡è¦éƒ¨åˆ†ã€‚
    ğŸ˜”ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæ¨¡å‹ã€‚
- en: we're going to create a class and we're going to call it custom fitã€‚And we're
    going inherit from Kaosta modelã€‚ and then the first thing we're going to do is
    we're going to create an init function and all we're going to send in here is
    the modelã€‚ So we're going to first call super to inherit from Kaosta modelã€‚ So
    we're going to self and then in itã€‚Then we're going to do set that model equal
    to modelã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦åˆ›å»ºä¸€ä¸ªç±»ï¼Œæˆ‘ä»¬è¦ç§°å®ƒä¸ºè‡ªå®šä¹‰é€‚åˆã€‚ ç„¶åæˆ‘ä»¬è¦ä»Kaostaæ¨¡å‹ç»§æ‰¿ã€‚ ç„¶åæˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯æˆ‘ä»¬è¦åˆ›å»ºä¸€ä¸ªinitå‡½æ•°ï¼Œæˆ‘ä»¬è¦å‘é€åˆ°è¿™é‡Œçš„æ‰€æœ‰ä¸œè¥¿éƒ½æ˜¯æ¨¡å‹ã€‚
    æ‰€ä»¥æˆ‘ä»¬è¦é¦–å…ˆè°ƒç”¨è¶…çº§æ¥ç»§æ‰¿Kaostaæ¨¡å‹ã€‚ æ‰€ä»¥æˆ‘ä»¬è¦åšçš„æ˜¯è‡ªå·±ç„¶ååœ¨è¿™é‡Œã€‚ ç„¶åæˆ‘ä»¬è¦åšçš„æ˜¯å°†æ¨¡å‹è®¾ç½®ä¸ºæ¨¡å‹ã€‚
- en: Then what we're going to do is we're going to define one training step and that's
    going to be used in a model dot fit rightã€‚ So our goal is basicallyã€‚We want to
    do something like training is a custom customï¼Œ wait customã€‚ what the hell custom
    fit of that modelã€‚ we're gonna to send in that modelã€‚ Then we're going to do training
    dot fit and we're gonna to send in x trainï¼Œ Y trainã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¦åšçš„æ˜¯å®šä¹‰ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼Œè¿™å°†åœ¨æ¨¡å‹ç‚¹æ‹Ÿåˆä¸­ä½¿ç”¨ã€‚ æ‰€ä»¥æˆ‘ä»¬çš„ç›®æ ‡åŸºæœ¬ä¸Šæ˜¯ã€‚ æˆ‘ä»¬æƒ³åšåƒè®­ç»ƒä¸€æ ·çš„è‡ªå®šä¹‰ï¼Œç­‰å¾…è‡ªå®šä¹‰ã€‚ é‚£æ¨¡å‹çš„ä»€ä¹ˆè‡ªå®šä¹‰é€‚åˆã€‚
    æˆ‘ä»¬è¦é€è¿›é‚£ä¸ªæ¨¡å‹ã€‚ ç„¶åæˆ‘ä»¬å°†åšè®­ç»ƒç‚¹é€‚åˆï¼Œæˆ‘ä»¬å°†é€å…¥ x è®­ç»ƒï¼ŒY è®­ç»ƒã€‚
- en: And then batch size and then number of vpos sort of as normalã€‚ although this
    dot fit is going to be done in a custom wayã€‚ we're going to sort of define how
    we want that to be doneã€‚So I mean there are many use cases of this you where you
    need to do custom training loops and sort of you use model Efi when you can and
    when you can't you try to customize your model thatfi which is what we're doing
    in this video and then for that most flexibility you do the training loop from
    scratch but an example of when you actually need to do this is generative adversarial
    networks I'm not assuming you're familiar with that I'm just sort of saying there
    are many examples whereã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ‰¹é‡å¤§å°å’Œvposæ•°é‡é€šå¸¸æ˜¯è¿™æ ·çš„ã€‚å°½ç®¡è¿™ä¸ªé€‚é…å°†ä»¥è‡ªå®šä¹‰æ–¹å¼è¿›è¡Œï¼Œæˆ‘ä»¬å°†å®šä¹‰æˆ‘ä»¬æƒ³è¦å¦‚ä½•æ‰§è¡Œã€‚å› æ­¤ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œæœ‰å¾ˆå¤šç”¨ä¾‹éœ€è¦è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œå°½å¯èƒ½ä½¿ç”¨æ¨¡å‹Efiï¼Œå½“ä¸èƒ½æ—¶å°è¯•è‡ªå®šä¹‰ä½ çš„æ¨¡å‹ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸ªè§†é¢‘ä¸­æ‰€åšçš„ã€‚ä¸ºäº†è·å¾—æœ€å¤§çš„çµæ´»æ€§ï¼Œä½ ä»å¤´å¼€å§‹è®­ç»ƒå¾ªç¯ï¼Œä½†å®é™…ä¸Šéœ€è¦è¿™æ ·åšçš„ä¸€ä¸ªä¾‹å­æ˜¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‚æˆ‘å¹¶ä¸å‡è®¾ä½ ç†Ÿæ‚‰è¿™ä¸ªï¼Œåªæ˜¯è¯´æœ‰å¾ˆå¤šè¿™æ ·çš„ä¾‹å­ã€‚
- en: This is usefulã€‚ Alrightï¼Œ so let's then do a train stepã€‚ we're going to send
    in data and then we're going that's going to be a twople of x and yã€‚ so we're
    just going to do x and y is equal to dataã€‚Then what we're going to do is we're
    going to do withã€‚TF gradient tape as tapeã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆæœ‰ç”¨ã€‚å¥½çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿›è¡Œä¸€æ¬¡è®­ç»ƒæ­¥éª¤ã€‚æˆ‘ä»¬å°†å‘é€æ•°æ®ï¼Œç„¶åæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªxå’Œyçš„å…ƒç»„ã€‚æ‰€ä»¥æˆ‘ä»¬åªéœ€è®©xå’Œyç­‰äºæ•°æ®ã€‚æ¥ç€æˆ‘ä»¬å°†ä½¿ç”¨TFæ¢¯åº¦è®°å½•ä½œä¸ºè®°å½•ã€‚
- en: And why we're doing this is because now we're going to do the for propagation
    and then the loss functionã€‚ and when we're doing it under that tapeï¼Œ it's going
    to record all of the operations that was done and then that will then be useful
    for calculating the gradients for back propagationã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿™æ ·åšçš„åŸå› æ˜¯å› ä¸ºç°åœ¨æˆ‘ä»¬å°†è¿›è¡Œå‰å‘ä¼ æ’­å’ŒæŸå¤±å‡½æ•°ã€‚å½“æˆ‘ä»¬åœ¨é‚£ä¸ªä¸Šä¸‹æ–‡ä¸­è¿›è¡Œæ“ä½œæ—¶ï¼Œå®ƒå°†è®°å½•æ‰€æœ‰æ‰§è¡Œçš„æ“ä½œï¼Œè¿™å°†æœ‰åŠ©äºè®¡ç®—åå‘ä¼ æ’­çš„æ¢¯åº¦ã€‚
- en: So basically we're going to do y prediction is a self dot modelã€‚ We're going
    to send in xã€‚ we're going to specify training is trueï¼Œ and then for this loss
    functionã€‚ we're going to do loss equals self dot compiled lossã€‚ and then we're
    going to send in y and then y predictionã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬è¦åšçš„yé¢„æµ‹æ˜¯ä¸€ä¸ªè‡ªæˆ‘ç‚¹æ¨¡å‹ã€‚æˆ‘ä»¬å°†å‘é€xã€‚æˆ‘ä»¬ä¼šæŒ‡å®šè®­ç»ƒä¸ºçœŸï¼Œç„¶åå¯¹äºè¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬å°†åšæŸå¤±ç­‰äºè‡ªæˆ‘ç¼–è¯‘çš„æŸå¤±ã€‚ç„¶åæˆ‘ä»¬å°†å‘é€yå’Œyé¢„æµ‹ã€‚
- en: and this is going to be done in the compile So right here we're going to do
    training dot compile we're going to send inã€‚And here we're going to send in optimizer
    is Kara's Oprsï¼Œ Adamomã€‚ then we're going to send in loss is Kara's lossesï¼Œ sparseï¼Œ
    categorical cross entropyã€‚ and from logic equals trueã€‚Then also we're going to
    do metrics is accuracyã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åœ¨ç¼–è¯‘ä¸­å®Œæˆã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¿›è¡Œè®­ç»ƒç¼–è¯‘ï¼Œæˆ‘ä»¬å°†å‘é€ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å°†å‘é€ä¼˜åŒ–å™¨ä¸ºKaraçš„Oprsï¼ŒAdamomã€‚ç„¶åæˆ‘ä»¬å°†å‘é€æŸå¤±ä¸ºKaraçš„æŸå¤±ï¼Œç¨€ç–çš„åˆ†ç±»äº¤å‰ç†µã€‚é€»è¾‘ç­‰äºçœŸã€‚ç„¶åæˆ‘ä»¬è¿˜å°†åšæŒ‡æ ‡ä¸ºå‡†ç¡®æ€§ã€‚
- en: And so this is for the first one where we're doing the compileã€‚ I'm also going
    to show you how to do a custom compileã€‚But let's take that as we goã€‚ so we're
    going to first now continue doing the train step when we have this compileã€‚ and
    so this self dot compiled loss is using this sparse category across entropy from
    the training dot compileã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬ç¬¬ä¸€æ¬¡è¿›è¡Œç¼–è¯‘çš„æƒ…å†µã€‚æˆ‘è¿˜å°†å‘ä½ å±•ç¤ºå¦‚ä½•è¿›è¡Œè‡ªå®šä¹‰ç¼–è¯‘ã€‚ä½†è®©æˆ‘ä»¬é€æ­¥è¿›è¡Œã€‚å› æ­¤æˆ‘ä»¬ç°åœ¨å°†ç»§ç»­åœ¨è¿™ä¸ªç¼–è¯‘ä¸‹è¿›è¡Œè®­ç»ƒæ­¥éª¤ã€‚è‡ªæˆ‘ç¼–è¯‘çš„æŸå¤±ä½¿ç”¨è¿™ä¸ªç¨€ç–åˆ†ç±»äº¤å‰ç†µæ¥è‡ªè®­ç»ƒç¼–è¯‘ã€‚
- en: After that we basically want to get the gradients rightï¼Œ we've now done the
    for propagationã€‚ this part is the for propagationï¼Œ which we're doing with this
    gradient under this tape to record all of the operationsã€‚Then we're going to do
    training variables is a self dot trainable variables and these are all stored
    from this parent classã€‚ this cars dot modelï¼Œ so we don't have to bother with thatï¼Œ
    then we want to get the gradientã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‚£ä¹‹åï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šæƒ³è¦è·å¾—æ¢¯åº¦ï¼Œå¯¹å§ï¼Œæˆ‘ä»¬ç°åœ¨å®Œæˆäº†å‰å‘ä¼ æ’­ã€‚è¿™éƒ¨åˆ†æ˜¯å‰å‘ä¼ æ’­ï¼Œæˆ‘ä»¬åœ¨è¿™ä¸ªè®°å½•ä¸‹è¿›è¡Œæ‰€æœ‰æ“ä½œã€‚ç„¶åæˆ‘ä»¬å°†è®­ç»ƒå˜é‡è®¾ç½®ä¸ºè‡ªæˆ‘å¯è®­ç»ƒå˜é‡ï¼Œè¿™äº›å˜é‡éƒ½å­˜å‚¨åœ¨è¿™ä¸ªçˆ¶ç±»ä¸­ã€‚è¿™è¾†è½¦çš„æ¨¡å‹ï¼Œå› æ­¤æˆ‘ä»¬ä¸å¿…æ‹…å¿ƒè¿™ä¸ªï¼Œç„¶åæˆ‘ä»¬æƒ³è¦è·å¾—æ¢¯åº¦ã€‚
- en: we're going to do tape dot the gradientã€‚And we're going to do loss and then
    training variables rightã€‚ so we're getting the gradient of the loss with respect
    to the training variablesã€‚ which is ultimately what we want to changeã€‚Then we're
    going to do a stepï¼Œ an optimizer stepã€‚ a gradient in descent stepã€‚ and we're going
    to do self dot optimizer dot applyã€‚Gradientsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ‰§è¡Œå¸¦æœ‰æ¢¯åº¦çš„è®°å½•ã€‚ç„¶åæˆ‘ä»¬å°†åšæŸå¤±å’Œè®­ç»ƒå˜é‡ï¼Œå¯¹å§ã€‚æ‰€ä»¥æˆ‘ä»¬æ­£åœ¨è·å¾—ç›¸å¯¹äºè®­ç»ƒå˜é‡çš„æŸå¤±æ¢¯åº¦ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦æ”¹å˜çš„ã€‚æ¥ç€æˆ‘ä»¬å°†è¿›è¡Œä¸€æ­¥ï¼Œä¼˜åŒ–å™¨æ­¥éª¤ï¼Œä¸€ä¸ªæ¢¯åº¦ä¸‹é™æ­¥éª¤ï¼Œæˆ‘ä»¬å°†æ‰§è¡Œè‡ªæˆ‘ä¼˜åŒ–å™¨çš„åº”ç”¨ã€‚æ¢¯åº¦ã€‚
- en: And then here we're going do zip gradients and then training variablesã€‚ And
    then we're going to do self that compiled metrics that update state y and then
    y predictionã€‚ And this is this is going to be for the accuracyã€‚ And then in the
    endï¼Œ we're going to returnã€‚M dot nameã€‚And you'll see what it means so M dot name
    M dot result for M in self dot metrics allrightã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬å°†æ‰§è¡Œzipæ¢¯åº¦å’Œè®­ç»ƒå˜é‡ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†è‡ªæˆ‘ç¼–è¯‘çš„åº¦é‡æ›´æ–°çŠ¶æ€Yå’ŒYé¢„æµ‹ã€‚è¿™å°†ç”¨äºå‡†ç¡®ç‡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è¿”å›M.nameã€‚ä½ ä¼šçœ‹åˆ°å®ƒçš„å«ä¹‰ï¼ŒM.name
    M.resultå¯¹äºè‡ªæˆ‘åº¦é‡ã€‚
- en: so we we're getting the MD dot name which is going to be the loss for exampleã€‚
    and then we're getting the result which is the current loss and then we're doing
    that for all of the metrics and that's going to be the loss and the accuracy in
    this caseã€‚And yeahï¼Œ so I think that's it for just this first stepã€‚ and I think
    we should now be able to run thisã€‚And as you can see hereï¼Œ it does seem to workã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è·å–MD.nameï¼Œè¿™å°†æ˜¯æŸå¤±ï¼Œæ¯”å¦‚è¯´ã€‚ç„¶åæˆ‘ä»¬è·å–ç»“æœï¼Œå³å½“å‰æŸå¤±ï¼Œç„¶åæˆ‘ä»¬ä¸ºæ‰€æœ‰åº¦é‡æ‰§è¡Œè¿™ä¸€æ­¥ï¼Œè¿™å°†æ˜¯æŸå¤±å’Œå‡†ç¡®ç‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ã€‚æˆ‘æƒ³è¿™å°±æ˜¯ç¬¬ä¸€æ­¥çš„å…¨éƒ¨å†…å®¹ã€‚æˆ‘ä»¬ç°åœ¨åº”è¯¥èƒ½å¤Ÿè¿è¡Œè¿™ä¸ªã€‚å¦‚ä½ æ‰€è§ï¼Œå®ƒä¼¼ä¹æœ‰æ•ˆã€‚
- en: and yeah so basicallyã€‚So basically the next step now is that we want to do our
    own compileã€‚ so what we're going to do right here is we're going to define compileã€‚
    we're going to send in the optimizer and we're going to send in the lossã€‚And we're
    going to do super custom itself that compileã€‚So yeahã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ‰€ä»¥åŸºæœ¬ä¸Šã€‚æ¥ä¸‹æ¥çš„æ­¥éª¤æ˜¯æˆ‘ä»¬æƒ³è¦è¿›è¡Œè‡ªå·±çš„ç¼–è¯‘ã€‚æ‰€ä»¥æˆ‘ä»¬è¦åœ¨è¿™é‡Œå®šä¹‰ç¼–è¯‘ã€‚æˆ‘ä»¬å°†ä¼ å…¥ä¼˜åŒ–å™¨å’ŒæŸå¤±ã€‚ç„¶åæˆ‘ä»¬å°†æ‰§è¡Œè‡ªå®šä¹‰çš„ç¼–è¯‘ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ã€‚
- en: and then we're going to do self that optimizer is equal to optimizerï¼Œ Se that
    loss is equal to lossã€‚And all we have to do then is we have basically the same
    thing rightï¼Œ trainingã€‚tcompã€‚ except we're not going to send in a metric right
    hereã€‚ so we're just going to use the optimizer and the lossã€‚Andã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è‡ªæˆ‘ä¼˜åŒ–å™¨ç­‰äºä¼˜åŒ–å™¨ï¼Œè‡ªæˆ‘æŸå¤±ç­‰äºæŸå¤±ã€‚ç„¶åæˆ‘ä»¬åªéœ€åšåŸºæœ¬ä¸Šç›¸åŒçš„äº‹æƒ…ï¼Œè®­ç»ƒ.tcompã€‚é™¤äº†æˆ‘ä»¬ä¸åœ¨è¿™é‡Œä¼ å…¥åº¦é‡ï¼Œæ‰€ä»¥æˆ‘ä»¬åªä½¿ç”¨ä¼˜åŒ–å™¨å’ŒæŸå¤±ã€‚
- en: And that should also basically be it now we just have to change this right here
    to this compiled lossã€‚ we're just going to do self that lossï¼Œ it's which we've
    stored right hereã€‚So self dot loss and then let's seeï¼Œ yeahï¼Œ and then we can still
    use self dot optimizer and let's just rerun itã€‚And nowï¼Œ as you can seeï¼Œ we're
    not getting an accuracyã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨åŸºæœ¬ä¸Šå°±æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬åªéœ€å°†è¿™ä¸ªåœ°æ–¹æ”¹ä¸ºç¼–è¯‘åçš„æŸå¤±ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å­˜å‚¨åœ¨è¿™é‡Œçš„è‡ªæˆ‘æŸå¤±ã€‚æ‰€ä»¥è‡ªæˆ‘æŸå¤±ï¼Œç„¶åè®©æˆ‘ä»¬çœ‹çœ‹ï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨è‡ªæˆ‘ä¼˜åŒ–å™¨ï¼Œç„¶åè®©æˆ‘ä»¬é‡æ–°è¿è¡Œå®ƒã€‚ç°åœ¨ï¼Œå¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬æ²¡æœ‰å¾—åˆ°å‡†ç¡®ç‡ã€‚
- en: So we're going to have to keep track of a that metric by ourselvesseã€‚ So what
    we can do is for exampleï¼Œ we couldã€‚Created right hereã€‚ we could doã€‚Accuracy metric
    isã€‚Ca us that matrix that spae categorical accuracyã€‚And let's just call it nameã€‚'s
    see name equalsã€‚Accuracyã€‚And thenï¼Œ in theã€‚And then right hereï¼Œ inside of the compiled
    metricã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬éœ€è¦è‡ªå·±è·Ÿè¸ªè¿™ä¸ªåº¦é‡ã€‚æˆ‘ä»¬å¯ä»¥ï¼Œæ¯”å¦‚è¯´ï¼Œåœ¨è¿™é‡Œåˆ›å»ºã€‚æˆ‘ä»¬å¯ä»¥åšã€‚å‡†ç¡®ç‡åº¦é‡æ˜¯ã€‚Ca usé‚£ä¸ªçŸ©é˜µspaeç±»åˆ«å‡†ç¡®ç‡ã€‚æˆ‘ä»¬å°±å«å®ƒåå­—ã€‚'sçœ‹åå­—ç­‰äºã€‚å‡†ç¡®ç‡ã€‚ç„¶åï¼Œåœ¨è¿™é‡Œï¼Œåœ¨ç¼–è¯‘çš„åº¦é‡å†…ã€‚
- en: what we're going to do is is accuracy metric that update stateã€‚ we're going
    to send in Y and then y predictionï¼Œ and then we can remove this compiled metricã€‚å—¯ã€‚And
    yeahï¼Œ so that should hopefully be itã€‚ Let's see if we can run thisã€‚All rightã€‚
    so now since we're keeping track of the accuracy by ourselvesã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦åšçš„æ˜¯å‡†ç¡®ç‡åº¦é‡çš„æ›´æ–°çŠ¶æ€ã€‚æˆ‘ä»¬å°†ä¼ å…¥Yå’ŒYé¢„æµ‹ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å»æ‰è¿™ä¸ªç¼–è¯‘çš„åº¦é‡ã€‚å—¯ã€‚æ‰€ä»¥å¸Œæœ›è¿™å°±æ˜¯å…¨éƒ¨ã€‚è®©æˆ‘ä»¬çœ‹çœ‹èƒ½å¦è¿è¡Œè¿™ä¸ªã€‚å¥½çš„ã€‚æ—¢ç„¶æˆ‘ä»¬è‡ªå·±åœ¨è·Ÿè¸ªå‡†ç¡®ç‡ã€‚
- en: what we're going to do here is we're going to write it explicitlyã€‚ so we're
    going to do loss is in this caseï¼Œ just lossã€‚And then we're going to do accuracyã€‚Isã€‚Accury
    metric dot resultã€‚And hopefully now we should get the loss and the accuracy Yeahã€‚
    so this looks pretty familiar to what we did previouslyã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œå°†æ˜ç¡®å†™å‡ºã€‚æ‰€ä»¥æˆ‘ä»¬å°†åšæŸå¤±åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå°±æ˜¯æŸå¤±ã€‚ç„¶åæˆ‘ä»¬å°†åšå‡†ç¡®ç‡ã€‚æ˜¯ã€‚å‡†ç¡®ç‡åº¦é‡.resultã€‚å¸Œæœ›ç°åœ¨æˆ‘ä»¬å¯ä»¥å¾—åˆ°æŸå¤±å’Œå‡†ç¡®ç‡ã€‚æ˜¯çš„ã€‚è¿™çœ‹èµ·æ¥å’Œæˆ‘ä»¬ä¹‹å‰åšçš„å¾ˆç›¸ä¼¼ã€‚
- en: except now we're doing the compile completely by ourselvesã€‚And then allrightã€‚
    so now we got the compileï¼Œ we got a train step what we normally do as well is
    in the end after trainingã€‚ we're doing training that evaluate and then x testï¼Œ
    Y testï¼Œ and then we're specifying batch sizeã€‚ let's say 32ã€‚One thing here is that
    this dot fit works on the train step and then evaluate works on a test stepã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åªæ˜¯ç°åœ¨æˆ‘ä»¬å®Œå…¨ç”±è‡ªå·±æ¥è¿›è¡Œ compileã€‚å¥½çš„ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº† compileï¼Œå¾—åˆ°äº†è®­ç»ƒæ­¥éª¤ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šåœ¨è®­ç»ƒç»“æŸåæ‰§è¡Œè®­ç»ƒçš„è¯„ä¼°ï¼Œç„¶åæ˜¯ x
    test å’Œ y testï¼Œæ¥ç€æˆ‘ä»¬æŒ‡å®šæ‰¹é‡å¤§å°ã€‚æˆ‘ä»¬è¯´ 32ã€‚è¿™é‡Œæœ‰ä¸€ä»¶äº‹æ˜¯ï¼Œè¿™ä¸ª dot fit åœ¨è®­ç»ƒæ­¥éª¤ä¸Šæœ‰æ•ˆï¼Œè€Œ evaluate åˆ™åœ¨æµ‹è¯•æ­¥éª¤ä¸Šæœ‰æ•ˆã€‚
- en: so to make this work we actually need to define another function and we need
    to do test step although this one is going to be a little bit easier since well
    first of all we're going to unpack the data and then we're going to compute prediction
    so we're going to do by prediction is selfã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿è¿™ä¸ªå·¥ä½œï¼Œæˆ‘ä»¬å®é™…ä¸Šéœ€è¦å®šä¹‰å¦ä¸€ä¸ªå‡½æ•°ï¼Œå¹¶ä¸”æˆ‘ä»¬éœ€è¦æ‰§è¡Œæµ‹è¯•æ­¥éª¤ï¼Œå°½ç®¡è¿™ä¸ªæ­¥éª¤ä¼šç¨å¾®ç®€å•ä¸€ç‚¹ï¼Œå› ä¸ºé¦–å…ˆæˆ‘ä»¬å°†è§£åŒ…æ•°æ®ï¼Œç„¶åè®¡ç®—é¢„æµ‹ï¼Œå› æ­¤æˆ‘ä»¬çš„é¢„æµ‹å°†æ˜¯
    selfã€‚
- en: t model X and then we're specifying the training is falseã€‚And what we're doing
    is this is if we're using batch norm or dropoutã€‚That has different behaviors during
    testing and training we're just telling the model this is now in testingã€‚ so make
    sure that those modules that have different behaviors are set to test mode or
    evaluation modeã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æŒ‡å®šè®­ç»ƒä¸º false çš„åŒæ—¶ä½¿ç”¨ t model Xã€‚æˆ‘ä»¬æ‰€åšçš„æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ–æˆ– dropoutï¼Œé‚£ä¹ˆåœ¨æµ‹è¯•å’Œè®­ç»ƒæœŸé—´å®ƒä»¬çš„è¡Œä¸ºæ˜¯ä¸åŒçš„ï¼Œæˆ‘ä»¬åªæ˜¯å‘Šè¯‰æ¨¡å‹ç°åœ¨æ˜¯åœ¨æµ‹è¯•æ¨¡å¼ã€‚å› æ­¤ï¼Œè¯·ç¡®ä¿è¿™äº›åœ¨ä¸åŒæƒ…å†µä¸‹æœ‰ä¸åŒè¡Œä¸ºçš„æ¨¡å—è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼æˆ–è¯„ä¼°æ¨¡å¼ã€‚
- en: Then we're going to compute the lossï¼Œ which is sub loss of y predictionã€‚And
    then we're going do accuracysymmetric do update state y y predictionã€‚And in the
    endã€‚ we're going to return a dictionary of lossï¼Œ which is just going to be lossã€‚
    and then accuracyã€‚We're doing acrosymmetric that result all rightï¼Œ so this is
    a very like it's very similar to the training stepã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è®¡ç®—æŸå¤±ï¼Œå³ y é¢„æµ‹çš„å­æŸå¤±ã€‚æ¥ç€æˆ‘ä»¬å°†è¿›è¡Œå‡†ç¡®æ€§å¯¹ç§°æ›´æ–°çŠ¶æ€ y y é¢„æµ‹ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è¿”å›ä¸€ä¸ªåŒ…å«æŸå¤±çš„å­—å…¸ï¼ŒæŸå¤±å°±æ˜¯ lossï¼Œå‡†ç¡®æ€§åˆ™æ˜¯
    accuracyã€‚æˆ‘ä»¬æ­£åœ¨æ‰§è¡Œå¯¹ç§°çš„ç»“æœï¼Œä¸€åˆ‡éƒ½å¾ˆå¥½ï¼Œå› æ­¤è¿™ä¸è®­ç»ƒæ­¥éª¤éå¸¸ç›¸ä¼¼ã€‚
- en: although it's much more simplified and it's simplified because we're not doing
    a gradient descent update so we don't need to keep track of this tape of making
    sure that we have all the gradients and all of that stuffã€‚And yeahï¼Œ so let's run
    this for yeah two epochs and then let's do the evaluationã€‚All rightã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å®ƒè¢«å¤§å¤§ç®€åŒ–äº†ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰è¿›è¡Œæ¢¯åº¦ä¸‹é™æ›´æ–°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦è·Ÿè¸ªè¿™ä¸ª tape æ¥ç¡®ä¿æˆ‘ä»¬æ‹¥æœ‰æ‰€æœ‰çš„æ¢¯åº¦ç­‰ç­‰ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå¤§çº¦ä¸¤ä¸ª epochsï¼Œç„¶åè¿›è¡Œè¯„ä¼°ã€‚å¥½çš„ã€‚
- en: so after thisï¼Œ we see that we get 93 up the  first0poCï¼Œ 97 and then almost 98
    on the test setã€‚But yeahï¼Œ so I mean what we want to establish here that this does
    seem to train and it's working so yeah that's how you create your own you know
    specifying the training step and a test step which overwrites how the training
    do fit and then training that evaluate is done so in this way you can build more
    complicated and complex models in the training steps but still have the flexibility
    of doing training dot fit and that means that you can still use the training do
    compile although in this last one we overwrote theã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬çœ‹åˆ°åœ¨ test set ä¸Šå¾—åˆ°äº† 93ï¼Œç¬¬ä¸€æ¬¡æ˜¯ 0poCï¼Œ97ï¼Œç„¶åå‡ ä¹è¾¾åˆ° 98ã€‚ä¸è¿‡ï¼Œæˆ‘æƒ³æˆ‘ä»¬æƒ³åœ¨è¿™é‡Œå»ºç«‹çš„æ˜¯ï¼Œè¿™ä¼¼ä¹ç¡®å®åœ¨è®­ç»ƒå¹¶ä¸”è¿è¡Œè‰¯å¥½ã€‚æ‰€ä»¥è¿™å°±æ˜¯å¦‚ä½•åˆ›å»ºä½ è‡ªå·±çš„ï¼ŒæŒ‡å®šè®­ç»ƒæ­¥éª¤å’Œæµ‹è¯•æ­¥éª¤ï¼Œä»è€Œè¦†ç›–è®­ç»ƒçš„
    fitï¼Œç„¶åè¿›è¡Œè¯„ä¼°ã€‚è¿™æ ·ï¼Œä½ å¯ä»¥åœ¨è®­ç»ƒæ­¥éª¤ä¸­æ„å»ºæ›´å¤æ‚çš„æ¨¡å‹ï¼Œä½†ä»ç„¶æ‹¥æœ‰æ‰§è¡Œè®­ç»ƒ dot fit çš„çµæ´»æ€§ï¼Œè¿™æ„å‘³ç€ä½ ä»ç„¶å¯ä»¥ä½¿ç”¨è®­ç»ƒ dot compileï¼Œå°½ç®¡åœ¨æœ€åä¸€æ¬¡æˆ‘ä»¬è¿›è¡Œäº†è¦†ç›–ã€‚
- en: The compileï¼Œ but but you get the point in you can still use the their compile
    and the metrics and all of that stuff Yeahã€‚ if you have any questions leave them
    in the comment section below thank you so much for watching the video and I hope
    to see you in the next oneã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: compileï¼Œä½†ä½ æ˜ç™½æˆ‘çš„æ„æ€ï¼Œä½ ä»ç„¶å¯ä»¥ä½¿ç”¨ä»–ä»¬çš„ compile å’Œæ‰€æœ‰é‚£äº›æŒ‡æ ‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·åœ¨ä¸‹é¢çš„è¯„è®ºåŒºç•™è¨€ï¼Œéå¸¸æ„Ÿè°¢ä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œå¸Œæœ›ä¸‹æ¬¡å†è§åˆ°ä½ ã€‚
- en: '![](img/a08532ac4d7c10fff24b74debc5b0588_4.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a08532ac4d7c10fff24b74debc5b0588_4.png)'
