- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P8ï¼šL8- é€»è¾‘å›å½’
    - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P8ï¼šL8- é€»è¾‘å›å½’
    - ShowMeAI - BV12m4y1S7ix
- en: Hiï¼Œ everybodyã€‚ Welcome back to a new Pytorch tutorialã€‚ This timeï¼Œ we implement
    logistic regressionã€‚ If you have watched the previous tutorialsï¼Œ then this should
    be very easy Nowã€‚ Once againã€‚ we implement our typical pytorch pipeline with those
    three stepsã€‚ So firstï¼Œ we set up our modelã€‚ We define the input and output size
    and the forward passã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œæ¬¢è¿å›åˆ°æ–°çš„Pytorchæ•™ç¨‹ã€‚è¿™æ¬¡ï¼Œæˆ‘ä»¬å®ç°é€»è¾‘å›å½’ã€‚å¦‚æœä½ çœ‹è¿‡ä¹‹å‰çš„æ•™ç¨‹ï¼Œé‚£ç°åœ¨åº”è¯¥éå¸¸ç®€å•ã€‚å†æ¬¡ï¼Œæˆ‘ä»¬å®ç°æˆ‘ä»¬çš„å…¸å‹Pytorchç®¡é“ï¼ŒåŒ…å«è¿™ä¸‰ä¸ªæ­¥éª¤ã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘ä»¬å»ºç«‹æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬å®šä¹‰è¾“å…¥å’Œè¾“å‡ºå¤§å°ä»¥åŠå‰å‘ä¼ æ’­ã€‚
- en: Then we create the loss and the optimizer functionsã€‚ and then we do the actual
    training loop with the forward passã€‚ the backward pass and the weight updatesã€‚ğŸ˜Šï¼ŒThe
    code here should be very similar to the code in the last tutorial where we implemented
    linear regressionã€‚ We only have to make slight adjustments for the model and the
    loss functionã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åˆ›å»ºæŸå¤±å’Œä¼˜åŒ–å™¨å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œå®é™…çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°ã€‚ğŸ˜Šè¿™é‡Œçš„ä»£ç åº”è¯¥ä¸ä¸Šä¸€ä¸ªæ•™ç¨‹ä¸­å®ç°çº¿æ€§å›å½’çš„ä»£ç éå¸¸ç›¸ä¼¼ã€‚æˆ‘ä»¬åªéœ€è¦å¯¹æ¨¡å‹å’ŒæŸå¤±å‡½æ•°è¿›è¡Œç¨å¾®è°ƒæ•´ã€‚
- en: So we add one more layer to our modelï¼Œ and we select a different loss function
    from Pytor built in functionsã€‚Soï¼Œ let's startã€‚First of allï¼Œ let let's import some
    things that we needã€‚ So we import torchã€‚ of courseï¼Œ and we import torch dot nn
    as an nã€‚ So the neural network moduleã€‚ Then we import Ny S NP P to make some data
    transformationsã€‚ Then from Sk learnã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åœ¨æ¨¡å‹ä¸­å¢åŠ ä¸€å±‚ï¼Œå¹¶é€‰æ‹©ä¸€ä¸ªä¸åŒçš„æŸå¤±å‡½æ•°æ¥è‡ªPytorchå†…ç½®å‡½æ•°ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥ä¸€äº›æˆ‘ä»¬éœ€è¦çš„ä¸œè¥¿ã€‚æˆ‘ä»¬å¯¼å…¥torchï¼Œå½“ç„¶ï¼Œè¿˜æœ‰torchç‚¹nnä½œä¸ºnã€‚æ‰€ä»¥ç¥ç»ç½‘ç»œæ¨¡å—ã€‚ç„¶åæˆ‘ä»¬å¯¼å…¥Numpyæ¥è¿›è¡Œä¸€äº›æ•°æ®è½¬æ¢ã€‚ç„¶åä»Sklearnã€‚
- en: we import data sets to load a binary classification data setã€‚Then from SK learn
    dot pre processingã€‚ we want to import standard Scalar because we want to scale
    our featuresã€‚ and then from SK learn dot model selectionï¼Œ we import train test
    split because we want to have a separation of training and testing dataã€‚And now
    let's do our three stepsã€‚ So firstï¼Œ we want to set up the modelã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯¼å…¥æ•°æ®é›†æ¥åŠ è½½ä¸€ä¸ªäºŒåˆ†ç±»æ•°æ®é›†ã€‚ç„¶åä»Sklearnç‚¹é¢„å¤„ç†ã€‚æˆ‘ä»¬æƒ³å¯¼å…¥æ ‡å‡†ç¼©æ”¾å™¨ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³å¯¹ç‰¹å¾è¿›è¡Œç¼©æ”¾ã€‚ç„¶åä»Sklearnç‚¹æ¨¡å‹é€‰æ‹©ï¼Œæˆ‘ä»¬å¯¼å…¥è®­ç»ƒæµ‹è¯•æ‹†åˆ†ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›å¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®è¿›è¡Œåˆ†ç¦»ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œæˆ‘ä»¬çš„ä¸‰ä¸ªæ­¥éª¤ã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘ä»¬æƒ³å»ºç«‹æ¨¡å‹ã€‚
- en: Then we want to set up the loss and the optimizerã€‚ And then in the third stepã€‚
    we do the actual training loopã€‚And as a step 0ã€‚We want to prepare the dataã€‚So
    let's do thisã€‚ So let's load the breast cancer data set from S K learn so we can
    say B equals data sets dot load breast cancerã€‚ This is a binary classification
    problem where we can predict cancer based on the input featuresã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³å»ºç«‹æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚ç„¶ååœ¨ç¬¬ä¸‰æ­¥ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œå®é™…çš„è®­ç»ƒå¾ªç¯ã€‚ä½œä¸ºç¬¬0æ­¥ã€‚æˆ‘ä»¬æƒ³å‡†å¤‡æ•°æ®ã€‚è®©æˆ‘ä»¬è¿™æ ·åšã€‚è®©æˆ‘ä»¬ä»SklearnåŠ è½½ä¹³è…ºç™Œæ•°æ®é›†ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´Bç­‰äºæ•°æ®é›†ç‚¹åŠ è½½ä¹³è…ºç™Œã€‚è¿™æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è¾“å…¥ç‰¹å¾é¢„æµ‹ç™Œç—‡ã€‚
- en: So let's say X and Y equals B dot data and B dot targetã€‚And then we want to
    sayï¼Œ ohï¼Œ first of allã€‚ let's the get the number of samples and the number of features
    by saying this isã€‚X dot shapeã€‚![](img/d4aae67709503eb865c057216c0046f3_1.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å‡è®¾Xå’ŒYç­‰äºBç‚¹æ•°æ®å’ŒBç‚¹ç›®æ ‡ã€‚ç„¶åæˆ‘ä»¬æƒ³è¯´ï¼Œå“¦ï¼Œé¦–å…ˆï¼Œè®©æˆ‘ä»¬é€šè¿‡è¯´è¿™æ˜¯æ¥è·å–æ ·æœ¬æ•°é‡å’Œç‰¹å¾æ•°é‡ã€‚Xç‚¹å½¢çŠ¶ã€‚![](img/d4aae67709503eb865c057216c0046f3_1.png)
- en: So let's print this first So print the number of samples and the number of features
    to see how our data set looks likeã€‚![](img/d4aae67709503eb865c057216c0046f3_3.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬å…ˆæ‰“å°è¿™ä¸ªï¼Œæ‰“å°æ ·æœ¬æ•°é‡å’Œç‰¹å¾æ•°é‡ï¼Œçœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®é›†é•¿ä»€ä¹ˆæ ·ã€‚![](img/d4aae67709503eb865c057216c0046f3_3.png)
- en: Andã€‚We see we have 569 samples and 30 different featuresã€‚ So a lot of features
    hereã€‚And now let's continueã€‚ And let's split our data when we say X train and
    X test andã€‚X test and y train and y test equals hereã€‚ We can use the train test
    split function where we put in x and yã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬æœ‰569ä¸ªæ ·æœ¬å’Œ30ä¸ªä¸åŒçš„ç‰¹å¾ã€‚è¿™é‡Œæœ‰å¾ˆå¤šç‰¹å¾ã€‚ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­ã€‚å½“æˆ‘ä»¬è¯´Xè®­ç»ƒå’ŒXæµ‹è¯•ï¼Œä»¥åŠXæµ‹è¯•å’ŒYè®­ç»ƒå’ŒYæµ‹è¯•ç­‰äºè¿™é‡Œæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒæµ‹è¯•æ‹†åˆ†å‡½æ•°ï¼Œå°†Xå’ŒYæ”¾å…¥å…¶ä¸­ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_5.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_5.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_6.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_6.png)'
- en: And we want to be the testã€‚Sizeã€‚![](img/d4aae67709503eb865c057216c0046f3_8.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¿›è¡Œæµ‹è¯•ã€‚å¤§å°ã€‚![](img/d4aae67709503eb865c057216c0046f3_8.png)
- en: To be 20%ã€‚ So this is 02ã€‚![](img/d4aae67709503eb865c057216c0046f3_10.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¾¾åˆ°20%ã€‚æ‰€ä»¥è¿™æ˜¯02ã€‚![](img/d4aae67709503eb865c057216c0046f3_10.png)
- en: And let's also give this a random state equalsï¼Œ let's sayï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ã€‚![](img/d4aae67709503eb865c057216c0046f3_12.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿˜ç»™è¿™ä¸ªä¸€ä¸ªéšæœºçŠ¶æ€ï¼Œç­‰äºï¼Œå‡è®¾æ˜¯1ï¼Œ2ï¼Œ3ï¼Œ4ã€‚![](img/d4aae67709503eb865c057216c0046f3_12.png)
- en: And there should be a small Sã€‚And now let's convertã€‚ orï¼Œ first of allã€‚ now we
    want to scale our featuresã€‚ Sc them Hereã€‚ we set up a standard scalar S C equals
    standard scalarã€‚ which willã€‚Make our features to have zero mean and unit varianceã€‚
    This is always recommended to do when we want to deal with a logistic regressionã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åº”è¯¥æœ‰ä¸€ä¸ªå°Sã€‚ç°åœ¨è®©æˆ‘ä»¬è½¬æ¢ã€‚æˆ–è€…ï¼Œé¦–å…ˆã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦ç¼©æ”¾æˆ‘ä»¬çš„ç‰¹å¾ã€‚Scå®ƒä»¬ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªæ ‡å‡†çš„æ ‡é‡S Cç­‰äºæ ‡å‡†æ ‡é‡ã€‚è¿™å°†ä½¿æˆ‘ä»¬çš„ç‰¹å¾å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ã€‚è¿™åœ¨å¤„ç†é€»è¾‘å›å½’æ—¶æ€»æ˜¯æ¨èçš„ã€‚
- en: So now we scale our dataï¼Œ So we say x train equals sc dot fit transformã€‚ and
    then as an input we put in x trainã€‚ and then we want to do the same thing with
    our test dataã€‚ So we say x test equals SC dot here we only transform itã€‚å—¯ã€‚And
    here we put in X testã€‚ Nowã€‚ we scaled our dataã€‚ Now we want to convert it to torch
    tenzoosã€‚ So let's say x trainã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œç¼©æ”¾ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´x trainç­‰äºsc dot fit transformã€‚ç„¶åä½œä¸ºè¾“å…¥æˆ‘ä»¬æ”¾å…¥x trainã€‚æ¥ç€æˆ‘ä»¬å¸Œæœ›å¯¹æµ‹è¯•æ•°æ®åšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´x
    testç­‰äºSC dotï¼Œè¿™é‡Œæˆ‘ä»¬åªè¿›è¡Œè½¬æ¢ã€‚å—¯ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæ”¾å…¥X testã€‚ç°åœ¨ã€‚æˆ‘ä»¬ç¼©æ”¾äº†æˆ‘ä»¬çš„æ•°æ®ã€‚ç°åœ¨æˆ‘ä»¬æƒ³æŠŠå®ƒè½¬æ¢ä¸ºtorch tenzoosã€‚æ‰€ä»¥å‡è®¾x
    trainã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_14.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_14.png)'
- en: Equals torch dotã€‚ And here we can use the function from nuyã€‚ And then we put
    an x train and cast this to a flow 32 data typeã€‚ So we say x train dot Sã€‚Typeã€‚Numpy
    dot float 32ã€‚ because right nowï¼Œ this is of type doubleã€‚ and then we would run
    into some errorss laterã€‚ So let's cast this and convert this to a tenorã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰äºtorch dotã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨nuyçš„å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬æ”¾å…¥x trainå¹¶å°†å…¶è½¬æ¢ä¸ºflow 32æ•°æ®ç±»å‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´x train dot Sã€‚ç±»å‹ã€‚Numpy
    dot float 32ã€‚å› ä¸ºç°åœ¨ï¼Œè¿™çš„ç±»å‹æ˜¯doubleã€‚ç„¶åæˆ‘ä»¬ä¼šåœ¨ä»¥åçš„æŸäº›é”™è¯¯ä¸­é‡åˆ°é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºtenorã€‚
- en: And now let's do this with all the other arraysã€‚ So let's say xã€‚![](img/d4aae67709503eb865c057216c0046f3_16.png)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å¯¹æ‰€æœ‰å…¶ä»–æ•°ç»„æ‰§è¡Œæ­¤æ“ä½œã€‚æ‰€ä»¥å‡è®¾xã€‚![](img/d4aae67709503eb865c057216c0046f3_16.png)
- en: Testã€‚Equalsã€‚Thisã€‚And our Y trainã€‚And alsoï¼Œ our y test tenzonã€‚W testã€‚And nowã€‚
    as the last thing to prepare our data is to reshape our whyã€‚Tenzoã€‚ So Y train
    equals Y train dot Vã€‚ This is a built in function from Pytorarch that will reshape
    our Tzo with the given sizeã€‚ So it gets the sizeã€‚ Y trainã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Testã€‚ç­‰äºã€‚è¿™ã€‚è¿˜æœ‰æˆ‘ä»¬çš„Y trainã€‚è¿˜æœ‰ï¼Œæˆ‘ä»¬çš„y test tenzonã€‚W testã€‚ç°åœ¨ï¼Œå‡†å¤‡æ•°æ®çš„æœ€åä¸€æ­¥æ˜¯é‡å¡‘æˆ‘ä»¬çš„yã€‚Tenzoã€‚æ‰€ä»¥Y
    trainç­‰äºY train dot Vã€‚è¿™æ˜¯Pytorarchçš„å†…ç½®å‡½æ•°ï¼Œå°†æ ¹æ®ç»™å®šçš„å¤§å°é‡å¡‘æˆ‘ä»¬çš„Tzoã€‚æ‰€ä»¥å®ƒè·å–å¤§å°ã€‚Y trainã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_18.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_18.png)'
- en: That shapeï¼Œ0ã€‚![](img/d4aae67709503eb865c057216c0046f3_20.png)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¸ªå½¢çŠ¶ï¼Œ0ã€‚![](img/d4aae67709503eb865c057216c0046f3_20.png)
- en: And oneã€‚ So right nowï¼Œ our y has only one rowï¼Œ and we want to make it a column
    vectorã€‚ So we want to put each value in one row with only one columnã€‚ So this
    will do exactly thisã€‚ and also for our y testã€‚ So Y test equals this y testã€‚![](img/d4aae67709503eb865c057216c0046f3_22.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åªæœ‰ä¸€ä¸ªã€‚æ‰€ä»¥ç°åœ¨ï¼Œæˆ‘ä»¬çš„yåªæœ‰ä¸€è¡Œï¼Œæˆ‘ä»¬å¸Œæœ›æŠŠå®ƒå˜æˆåˆ—å‘é‡ã€‚æ‰€ä»¥æˆ‘ä»¬å¸Œæœ›å°†æ¯ä¸ªå€¼æ”¾åœ¨ä¸€è¡Œä¸­ï¼Œåªæœ‰ä¸€åˆ—ã€‚æ‰€ä»¥è¿™å°†å®Œå…¨åšåˆ°è¿™ä¸€ç‚¹ã€‚ä¹Ÿé€‚ç”¨äºæˆ‘ä»¬çš„y testã€‚æ‰€ä»¥Y
    testç­‰äºè¿™ä¸ªy testã€‚![](img/d4aae67709503eb865c057216c0046f3_22.png)
- en: '![](img/d4aae67709503eb865c057216c0046f3_23.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_23.png)'
- en: And nowï¼Œ we areã€‚![](img/d4aae67709503eb865c057216c0046f3_25.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æ­£åœ¨ã€‚![](img/d4aae67709503eb865c057216c0046f3_25.png)
- en: Think we are done with our data preparingã€‚So now let's set up our modelã€‚ and
    here our model is a linear combination of weights and a biasã€‚ And then in the
    logistic regression caseï¼Œ we apply a sigmoid function at the endã€‚So let's do thisã€‚
    And for thisï¼Œ we want to write our own classã€‚ So let's call this modelã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºæˆ‘ä»¬å·²ç»å®Œæˆäº†æ•°æ®å‡†å¤‡ã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬å»ºç«‹æˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯æƒé‡å’Œåå·®çš„çº¿æ€§ç»„åˆã€‚åœ¨é€»è¾‘å›å½’çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨æœ€ååº”ç”¨ä¸€ä¸ªsigmoidå‡½æ•°ã€‚æ‰€ä»¥è®©æˆ‘ä»¬è¿™æ ·åšã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æƒ³ç¼–å†™è‡ªå·±çš„ç±»ã€‚æ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸ºæ¨¡å‹ã€‚
- en: or we can also call this logistic regressionã€‚Chaticã€‚Regressionã€‚And this must
    be derived from N and dot moduleã€‚And then this will get a in itã€‚Which has selfã€‚
    And then it gets the number of inputã€‚Featuresã€‚And hereï¼Œ firstï¼Œ we call the super
    in itã€‚ So let's say superã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥ç§°ä¹‹ä¸ºé€»è¾‘å›å½’ã€‚Chaticã€‚å›å½’ã€‚è¿™å¿…é¡»ä»Nå’Œdotæ¨¡å—æ´¾ç”Ÿã€‚ç„¶åè¿™å°†å¾—åˆ°ä¸€ä¸ªinitã€‚å®ƒæœ‰selfã€‚ç„¶åå®ƒè·å–è¾“å…¥çš„æ•°é‡ã€‚ç‰¹å¾ã€‚è¿™é‡Œï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬è°ƒç”¨super
    initã€‚æ‰€ä»¥æˆ‘ä»¬è¯´superã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_27.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_27.png)'
- en: Logistic regression and self dot in itã€‚![](img/d4aae67709503eb865c057216c0046f3_29.png)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’å’Œself dot initã€‚![](img/d4aae67709503eb865c057216c0046f3_29.png)
- en: And then here we define our layerã€‚ So we only have one layer self dot linear
    equalsã€‚ And here we can use the build in layer N N dot linearã€‚ And this gets the
    input sizeã€‚ So an input featuresã€‚ and the output size is just oneã€‚ So we only
    want to have one valueã€‚ one class label at the endã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬åªæœ‰ä¸€å±‚self dot linearç­‰äºã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å†…ç½®çš„layer N N dot linearã€‚è¿™å°†è·å–è¾“å…¥å¤§å°ã€‚æ‰€ä»¥è¾“å…¥ç‰¹å¾ã€‚è€Œè¾“å‡ºå¤§å°åªæœ‰ä¸€ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬åªæƒ³åœ¨æœ€åå¾—åˆ°ä¸€ä¸ªå€¼ï¼Œä¸€ä¸ªç±»åˆ«æ ‡ç­¾ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_31.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_31.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_32.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_32.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_33.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_33.png)'
- en: And then we also have to implement the forward pass hereï¼Œ which has self and
    the dataã€‚ And our forward pass is firstï¼Œ we apply the linear layer and then the
    sigmoid functionã€‚ So here we say why predict itã€‚Equals torch dot siteteã€‚![](img/d4aae67709503eb865c057216c0046f3_35.png)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜å¿…é¡»åœ¨è¿™é‡Œå®ç°å‰å‘ä¼ æ’­ï¼Œå…¶ä¸­åŒ…å«selfå’Œæ•°æ®ã€‚æˆ‘ä»¬çš„å‰å‘ä¼ æ’­é¦–å…ˆæ˜¯åº”ç”¨çº¿æ€§å±‚ï¼Œç„¶åæ˜¯sigmoidå‡½æ•°ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬è¯´ä¸ºä»€ä¹ˆé¢„æµ‹å®ƒã€‚ç­‰äºtorch.siteteã€‚![](img/d4aae67709503eb865c057216c0046f3_35.png)
- en: So this is also a build and function that we can useã€‚ And here we apply ourselves
    to a linear layerã€‚ So linear layer with our data Xã€‚ and then we return our y predictedã€‚![](img/d4aae67709503eb865c057216c0046f3_37.png)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¹Ÿæ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„æ„å»ºå’ŒåŠŸèƒ½ã€‚è¿™é‡Œæˆ‘ä»¬åº”ç”¨çº¿æ€§å±‚ã€‚å°†çº¿æ€§å±‚ä¸æˆ‘ä»¬çš„æ•°æ®Xç›¸ç»“åˆï¼Œç„¶åè¿”å›æˆ‘ä»¬çš„yé¢„æµ‹ã€‚![](img/d4aae67709503eb865c057216c0046f3_37.png)
- en: '![](img/d4aae67709503eb865c057216c0046f3_38.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_38.png)'
- en: So this is our modelã€‚ And now let's create thisã€‚ So model equals logistic regression
    of sizeã€‚ And here we put in the number of features that we haveã€‚ So now our layer
    is of size 30 by  oneã€‚![](img/d4aae67709503eb865c057216c0046f3_40.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºè¿™ä¸ªã€‚æ‰€ä»¥modelç­‰äºå¤§å°çš„logistic regressionã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¾“å…¥æˆ‘ä»¬æ‹¥æœ‰çš„ç‰¹å¾æ•°é‡ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çš„å±‚å¤§å°ä¸º30ä¹˜1ã€‚![](img/d4aae67709503eb865c057216c0046f3_40.png)
- en: '![](img/d4aae67709503eb865c057216c0046f3_41.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_41.png)'
- en: Andã€‚Noï¼Œ sorryï¼Œ30 input features and one output featureã€‚![](img/d4aae67709503eb865c057216c0046f3_43.png)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ã€‚ä¸å¥½æ„æ€ï¼Œ30ä¸ªè¾“å…¥ç‰¹å¾å’Œä¸€ä¸ªè¾“å‡ºç‰¹å¾ã€‚![](img/d4aae67709503eb865c057216c0046f3_43.png)
- en: And now we have our model onã€‚And now we can continue with the loss and the optimizerã€‚
    So for a lossã€‚ the loss function now is different than in the linear regression
    caseã€‚ So here we say criterion equals Nï¼Œ N dot Bï¼Œ E lossã€‚ So the binary cross
    entropy loss hereã€‚And our optimizer is the sameã€‚ So this can beã€‚å—¯ã€‚This is torch
    dot optim dot S G D for stochastic gradient descentã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­è¿›è¡ŒæŸå¤±å’Œä¼˜åŒ–å™¨ã€‚å› æ­¤ï¼Œå¯¹äºæŸå¤±ï¼ŒæŸå¤±å‡½æ•°ç°åœ¨ä¸çº¿æ€§å›å½’æƒ…å†µä¸‹ä¸åŒã€‚è¿™é‡Œæˆ‘ä»¬è¯´criterionç­‰äºN.N.B.E
    lossã€‚æ‰€ä»¥è¿™é‡Œæ˜¯äºŒå…ƒäº¤å‰ç†µæŸå¤±ã€‚æˆ‘ä»¬çš„ä¼˜åŒ–å™¨æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥è¿™å¯ä»¥æ˜¯ã€‚å—¯ã€‚è¿™æ˜¯torch.optim.SGDï¼Œç”¨äºéšæœºæ¢¯åº¦ä¸‹é™ã€‚
- en: And this gets some parameters that we want to optimizeã€‚ So here we just say
    model dot parametersã€‚ And it also needs a learning rateã€‚ So let's say ourã€‚![](img/d4aae67709503eb865c057216c0046f3_45.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è·å–ä¸€äº›æˆ‘ä»¬æƒ³è¦ä¼˜åŒ–çš„å‚æ•°ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬åªè¯´model.dot parametersã€‚åŒæ—¶ä¹Ÿéœ€è¦ä¸€ä¸ªå­¦ä¹ ç‡ã€‚æˆ‘ä»¬è¯´ã€‚![](img/d4aae67709503eb865c057216c0046f3_45.png)
- en: '![](img/d4aae67709503eb865c057216c0046f3_46.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_46.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_47.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_47.png)'
- en: Learning rate equals ã€‚01ã€‚ And then here we say L R equals learning rateã€‚ So
    now this is step 2 and now step 3ã€‚ So let's define some number of epochsã€‚Equalsï¼Œ
    let's sayã€‚ 100 iterationsã€‚ And now we do our training loopã€‚So now we do fourã€‚Epoch
    in range nu epochsã€‚ And then firstï¼Œ we do the forward pass forwardã€‚Pass and the
    loss calculationã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ ç‡ç­‰äº0.01ã€‚ç„¶åè¿™é‡Œæˆ‘ä»¬è¯´LRç­‰äºå­¦ä¹ ç‡ã€‚è¿™æ˜¯æ­¥éª¤2ï¼Œç°åœ¨æ˜¯æ­¥éª¤3ã€‚æˆ‘ä»¬å®šä¹‰ä¸€äº›è®­ç»ƒå‘¨æœŸï¼Œç­‰äºï¼Œæ¯”å¦‚è¯´100æ¬¡è¿­ä»£ã€‚ç°åœ¨æˆ‘ä»¬è¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬è¿›è¡Œå››ä¸ªå‘¨æœŸã€‚åœ¨èŒƒå›´å†…çš„è®­ç»ƒå‘¨æœŸä¸­ã€‚ç„¶åé¦–å…ˆï¼Œæˆ‘ä»¬è¿›è¡Œå‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—ã€‚
- en: Then we do the backward passï¼Œ and then we do the updatesã€‚So let's say y predicted
    equals here we call our model and as thetaï¼Œ it gets x trainã€‚ and then we say loss
    equals criterionï¼Œ and this will get a the y predicted and the actual y trainingã€‚
    So the training samples or the training labelsã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿›è¡Œåå‘ä¼ æ’­ï¼Œç„¶åè¿›è¡Œæ›´æ–°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´yé¢„æµ‹ç­‰äºè¿™é‡Œæˆ‘ä»¬è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹ï¼Œä½œä¸ºthetaï¼Œå®ƒè·å–xè®­ç»ƒã€‚ç„¶åæˆ‘ä»¬è¯´lossç­‰äºcriterionï¼Œè¿™å°†è·å–yé¢„æµ‹å’Œå®é™…yè®­ç»ƒã€‚æ‰€ä»¥è®­ç»ƒæ ·æœ¬æˆ–è®­ç»ƒæ ‡ç­¾ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_49.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_49.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_50.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_50.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_51.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_51.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_52.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_52.png)'
- en: AndNow we do the backward pass and calculate the gradientsï¼Œ and againã€‚ we simply
    have to call lost dot dot backward and piytch will do all the calculations for
    usã€‚And now we update our weightsã€‚ So here we simply have to say optimizer dot
    stepã€‚ And againã€‚ Pytorch will do all the update calculations for usã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬è¿›è¡Œåå‘ä¼ æ’­å¹¶è®¡ç®—æ¢¯åº¦ï¼Œå†æ¬¡ã€‚æˆ‘ä»¬åªéœ€è°ƒç”¨loss.dot.backwardï¼ŒPytorchä¼šä¸ºæˆ‘ä»¬å®Œæˆæ‰€æœ‰çš„è®¡ç®—ã€‚ç°åœ¨æˆ‘ä»¬æ›´æ–°æƒé‡ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬åªéœ€è¯´optimizer.dot.stepã€‚å†ä¸€æ¬¡ï¼ŒPytorchä¼šä¸ºæˆ‘ä»¬å®Œæˆæ‰€æœ‰çš„æ›´æ–°è®¡ç®—ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_54.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_54.png)'
- en: And then we don'tã€‚ orï¼Œ we must not forget to empty our gradients againï¼Œ soã€‚Want
    to0 the gradientsã€‚ because the backward function here will always add up all the
    gradients into the dot gra attributeã€‚ So let's empty them again before the next
    iterationã€‚ And we simply must say optimizer dot0 graã€‚And thenï¼Œ let's alsoã€‚Print
    some information If epoch plus  one modo 10 equals equals 0ã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¸ï¼Œæˆ–è€…è¯´ï¼Œæˆ‘ä»¬ç»ä¸èƒ½å¿˜è®°å†æ¬¡æ¸…ç©ºæˆ‘ä»¬çš„æ¢¯åº¦ï¼Œæ‰€ä»¥ã€‚æƒ³è¦è®¾ç½®æ¢¯åº¦ä¸º 0ã€‚å› ä¸ºè¿™é‡Œçš„åå‘å‡½æ•°å°†å§‹ç»ˆå°†æ‰€æœ‰æ¢¯åº¦ç›¸åŠ åˆ° `dot_grad` å±æ€§ä¸­ã€‚æ‰€ä»¥åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å†æ¬¡æ¸…ç©ºå®ƒä»¬ã€‚æˆ‘ä»¬åªéœ€è¯´
    `optimizer.zero_grad()`ã€‚ç„¶åï¼Œè®©æˆ‘ä»¬ä¹Ÿæ‰“å°ä¸€äº›ä¿¡æ¯ï¼Œå¦‚æœ `epoch + 1 % 10 == 0`ã€‚
- en: So every 10th stepï¼Œ we want to print some informationã€‚ Let's use an F string
    hereã€‚ Let's sayï¼Œ epochã€‚And here we can use epoch plus oneã€‚ And then we also want
    to see the lossã€‚ So the loss equals loss dot itemã€‚ And let's format this to sayï¼Œ
    to only print four decimal valuesã€‚And yeahï¼Œ so now we are doneã€‚ This is our logistic
    regression implementationã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤æ¯åä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬æƒ³æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚è®©æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªæ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚å‡è®¾æ˜¯ `epoch`ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `epoch + 1`ã€‚ç„¶åæˆ‘ä»¬è¿˜æƒ³æŸ¥çœ‹æŸå¤±ã€‚å› æ­¤æŸå¤±ç­‰äº
    `loss.item()`ã€‚è®©æˆ‘ä»¬æ ¼å¼åŒ–ä¸ºåªæ‰“å°å››ä¸ªå°æ•°ä½ã€‚å¥½å§ï¼Œç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚è¿™æ˜¯æˆ‘ä»¬çš„é€»è¾‘å›å½’å®ç°ã€‚
- en: And now let's evaluate our modelã€‚ So the evaluation should not be part of our
    computational graph where we want to track the historyã€‚ So we want to say with
    torch dot no Grã€‚![](img/d4aae67709503eb865c057216c0046f3_56.png)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œè¯„ä¼°ä¸åº”è¯¥æ˜¯æˆ‘ä»¬æƒ³è¦è·Ÿè¸ªå†å²çš„è®¡ç®—å›¾çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬æƒ³è¦ä½¿ç”¨ `torch.no_grad()`ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_57.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_57.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_58.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_58.png)'
- en: And then do our evaluation hereã€‚ So here I want to get the accuracyã€‚ So let's
    get all the predicted classes from our test samplesã€‚ So let's say this is modelã€‚
    And here we put an X testã€‚![](img/d4aae67709503eb865c057216c0046f3_60.png)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œè¿›è¡Œè¯„ä¼°ã€‚æ‰€ä»¥æˆ‘æƒ³å¾—åˆ°å‡†ç¡®ç‡ã€‚è®©æˆ‘ä»¬ä»æµ‹è¯•æ ·æœ¬ä¸­è·å–æ‰€æœ‰é¢„æµ‹ç±»åˆ«ã€‚å‡è®¾è¿™æ˜¯æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨è¿™é‡Œæˆ‘ä»¬æ”¾å…¥ `X_test`ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_61.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_61.png)'
- en: And then let's convert this to class labelsã€‚ So 0 or 1ã€‚ So rememberã€‚ the seeoid
    function here will return a value between 0 and 1ã€‚![](img/d4aae67709503eb865c057216c0046f3_63.png)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè®©æˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾ã€‚æ‰€ä»¥ 0 æˆ– 1ã€‚æ‰€ä»¥è®°ä½ï¼Œè¿™é‡Œçš„ sigmoid å‡½æ•°å°†è¿”å›ä¸€ä¸ªä»‹äº 0 å’Œ 1 ä¹‹é—´çš„å€¼ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_64.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_64.png)'
- en: Andã€‚If this is larger than 05ï¼Œ we say this is class 1ã€‚ and otherwise it's class
    0ã€‚ So let's say why predicted classes equals y predicted dot roundã€‚ So here we
    can use a build and function againã€‚And this will do exactly thisã€‚And yeahï¼Œ so
    if weã€‚Do don't use this statementã€‚ Then this would be part of the computational
    graphã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ï¼Œå¦‚æœè¿™ä¸ªå€¼å¤§äº 0.5ï¼Œæˆ‘ä»¬è¯´è¿™æ˜¯ç±»åˆ« 1ã€‚å¦åˆ™å°±æ˜¯ç±»åˆ« 0ã€‚æ‰€ä»¥å‡è®¾ `y_predicted_classes = y_predicted.round()`ã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥å†æ¬¡ä½¿ç”¨æ„å»ºå‡½æ•°ã€‚è¿™å°†æ­£å¥½åšåˆ°è¿™ä¸€ç‚¹ã€‚å¦‚æœæˆ‘ä»¬ä¸ä½¿ç”¨è¿™ä¸ªè¯­å¥ï¼Œé‚£ä¹ˆè¿™å°†æ˜¯è®¡ç®—å›¾çš„ä¸€éƒ¨åˆ†ã€‚
- en: And it would track the gradient calculations for usã€‚ So here we don't want thisã€‚
    We don't need this because we are doneã€‚ So that's why we used this with statement
    hereã€‚ And now let's calculate the accuracy by saying act equals y predicted classesã€‚
    And here we can call the equal function equals y testã€‚And then thes sumã€‚ So we
    want to sumã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå°†ä¸ºæˆ‘ä»¬è·Ÿè¸ªæ¢¯åº¦è®¡ç®—ã€‚å› æ­¤æˆ‘ä»¬ä¸æƒ³è¿™æ ·ã€‚æˆ‘ä»¬ä¸éœ€è¦è¿™æ ·ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å®Œæˆäº†ã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ `with` è¯­å¥çš„åŸå› ã€‚ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡ `act
    = y_predicted_classes` è®¡ç®—å‡†ç¡®ç‡ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨ `equal` å‡½æ•°ï¼Œç­‰äº `y_test`ï¼Œç„¶åå¯¹å…¶æ±‚å’Œã€‚å› æ­¤æˆ‘ä»¬æƒ³å¯¹å…¶æ±‚å’Œã€‚
- en: Them up for every prediction that is correctã€‚ It will addã€‚Plus 1ã€‚ And then we
    divide this by the number of samples of test samplesã€‚ So why test dot shapeã€‚0ã€‚This
    will return the number of test samplesï¼Œ and then let's print our accuracy printã€‚![](img/d4aae67709503eb865c057216c0046f3_66.png)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ­£ç¡®çš„é¢„æµ‹ï¼Œæˆ‘ä»¬ä¼šåŠ ä¸€ã€‚ç„¶åæˆ‘ä»¬å°†å…¶é™¤ä»¥æµ‹è¯•æ ·æœ¬çš„æ•°é‡ã€‚æ‰€ä»¥ä¸ºä»€ä¹ˆä½¿ç”¨ `test.shape[0]`ã€‚è¿™å°†è¿”å›æµ‹è¯•æ ·æœ¬çš„æ•°é‡ï¼Œç„¶åè®©æˆ‘ä»¬æ‰“å°æˆ‘ä»¬çš„å‡†ç¡®ç‡ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_67.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_67.png)'
- en: Accuracy equalsã€‚å—¯ã€‚Ac dot4 Fï¼Œ also only for decimal valuesã€‚ And now let's run
    this and hope that everything is correctã€‚![](img/d4aae67709503eb865c057216c0046f3_69.png)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å‡†ç¡®ç‡ç­‰äºã€‚å—¯ï¼Œ`ac:.4f`ï¼Œä¹Ÿåªæ˜¾ç¤ºå°æ•°ä½ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå¸Œæœ›ä¸€åˆ‡éƒ½æ˜¯æ­£ç¡®çš„ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_70.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_70.png)'
- en: Andã€‚Standard scalr has no attribute transformã€‚ So here I have a typoã€‚![](img/d4aae67709503eb865c057216c0046f3_72.png)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ï¼Œæ ‡å‡†ç¼©æ”¾å™¨æ²¡æœ‰å±æ€§ transformã€‚å› æ­¤æˆ‘è¿™é‡Œæœ‰ä¸€ä¸ªæ‹¼å†™é”™è¯¯ã€‚
- en: Transformã€‚Nowï¼Œ let's run this againã€‚Transã€‚Formã€‚One more tryã€‚And now we are doneã€‚
    and we have a accuracy of 089ã€‚ So it's okayï¼Œ it's goodï¼Œ but it's not perfectã€‚
    So you might want to play around withï¼Œ for exampleï¼Œ the number of iterationsã€‚
    and where do we have itã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚è½¬æ¢ã€‚å†è¯•ä¸€æ¬¡ã€‚ç°åœ¨å®Œæˆäº†ï¼Œæˆ‘ä»¬çš„å‡†ç¡®ç‡æ˜¯089ã€‚æ‰€ä»¥è¿˜å¯ä»¥ï¼ŒæŒºå¥½çš„ï¼Œä½†ä¸æ˜¯å®Œç¾çš„ã€‚ä½ å¯èƒ½æƒ³è¦è°ƒæ•´ä¸€ä¸‹ï¼Œæ¯”å¦‚è¿­ä»£æ¬¡æ•°ã€‚æˆ‘ä»¬åœ¨å“ªé‡Œè®¾ç½®çš„å‘¢ï¼Ÿ
- en: '![](img/d4aae67709503eb865c057216c0046f3_74.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_74.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_75.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_75.png)'
- en: '![](img/d4aae67709503eb865c057216c0046f3_76.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_76.png)'
- en: The number of epochs or the learning rateï¼Œ for exampleã€‚ or also maybe try out
    a different optimizer hereã€‚ but basically yeah that's how we implement logistic
    regressionã€‚ I hope you liked itã€‚ If you liked itï¼Œ please subscribe to the channel
    and see you next time byeã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå‘¨æœŸæ•°æˆ–å­¦ä¹ ç‡ã€‚æˆ–è€…ä¹Ÿè®¸åœ¨è¿™é‡Œå°è¯•ä¸åŒçš„ä¼˜åŒ–å™¨ã€‚åŸºæœ¬ä¸Šï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•å®ç°é€»è¾‘å›å½’ã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢ã€‚å¦‚æœå–œæ¬¢ï¼Œè¯·è®¢é˜…é¢‘é“ï¼Œæˆ‘ä»¬ä¸‹æ¬¡è§ï¼Œå†è§ã€‚
- en: '![](img/d4aae67709503eb865c057216c0046f3_78.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d4aae67709503eb865c057216c0046f3_78.png)'
