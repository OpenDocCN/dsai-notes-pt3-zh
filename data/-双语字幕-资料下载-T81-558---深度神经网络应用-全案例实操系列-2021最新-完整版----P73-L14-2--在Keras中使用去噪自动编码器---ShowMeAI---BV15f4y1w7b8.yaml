- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P73ï¼šL14.2- åœ¨Kerasä¸­ä½¿ç”¨å»å™ªè‡ªåŠ¨ç¼–ç å™¨
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P73ï¼šL14.2- åœ¨Kerasä¸­ä½¿ç”¨å»å™ªè‡ªåŠ¨ç¼–ç å™¨
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonï¼Œ welcome to Application of Deep neural Network with
    Washington Universityã€‚In this videoï¼Œ we're going to look at auto encoders or specifically
    auto dennoine encodersã€‚ These are auto encoders that can be used to rebuildã€‚Data
    that's been obscured by noise for the latest on my AI course and projectsã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹è‡ªç¼–ç å™¨ï¼Œæˆ–å…·ä½“æ¥è¯´æ˜¯å»å™ªè‡ªç¼–ç å™¨ã€‚è¿™äº›æ˜¯å¯ä»¥ç”¨äºé‡å»ºè¢«å™ªå£°æ¨¡ç³Šçš„æ•°æ®çš„è‡ªç¼–ç å™¨ï¼Œè·å–æˆ‘æœ€æ–°çš„AIè¯¾ç¨‹å’Œé¡¹ç›®ã€‚
- en: click subscribe and the bell next to it to be notified of every new videoã€‚ So
    for auto encodersã€‚ we're going to first look at function approximationã€‚ We've
    been doing function approximation before its' pretty much regressionã€‚ but I am
    going to define a function to do the approximation to chart itã€‚ğŸ˜Šã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹å‡»è®¢é˜…å¹¶ç‚¹å‡»æ—è¾¹çš„é“ƒé“›ä»¥è·å–æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚å¯¹äºè‡ªç¼–ç å™¨ï¼Œæˆ‘ä»¬é¦–å…ˆå°†å…³æ³¨å‡½æ•°é€¼è¿‘ã€‚æˆ‘ä»¬ä¹‹å‰åšè¿‡å‡½æ•°é€¼è¿‘ï¼ŒåŸºæœ¬ä¸Šæ˜¯å›å½’ï¼Œä½†æˆ‘å°†å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è¿›è¡Œé€¼è¿‘å¹¶ç»˜åˆ¶å›¾è¡¨ã€‚ğŸ˜Šã€‚
- en: '![](img/be628560dda59c2203db5dbe7b4cf58a_1.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be628560dda59c2203db5dbe7b4cf58a_1.png)'
- en: And now I am going to create a simple neural network that has essentially the
    sine functionã€‚ We're going to try to predict the sine waveã€‚ If I run thatï¼Œ it
    is going to trainã€‚ and we're essentially just training it on on the sine function
    being passed in how fast forward this while it trainsã€‚ Allrightï¼Œ it's completeã€‚
    You can see it it's tracking it really pretty wellã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘è¦åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼ŒåŸºæœ¬ä¸Šæ˜¯æ­£å¼¦å‡½æ•°ã€‚æˆ‘ä»¬å°†å°è¯•é¢„æµ‹æ­£å¼¦æ³¢ã€‚å¦‚æœæˆ‘è¿è¡Œå®ƒï¼Œå®ƒå°†è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬æœ¬è´¨ä¸Šåªæ˜¯è®­ç»ƒå®ƒå¤„ç†ä¼ å…¥çš„æ­£å¼¦å‡½æ•°ï¼Œå¿«è¿›ä¸€ä¸‹ã€‚å¥½çš„ï¼Œå®ƒå®Œæˆäº†ã€‚ä½ å¯ä»¥çœ‹åˆ°å®ƒè·Ÿè¸ªå¾—ç›¸å½“ä¸é”™ã€‚
- en: Now I put some noise into the expected just so that it's not exactly perfectã€‚
    You can also see the actual in the predicted that prettyï¼Œ pretty closeï¼Œ reallyï¼Œ
    Nextã€‚ we'll do multi output regressionã€‚ Multi outputput regression is critical
    for a autoencoderã€‚ Essentiallyï¼Œ what's happening is you have your inputs just
    like before input 1 input 2 input 3 input 4ã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘åœ¨æœŸæœ›å€¼ä¸­åŠ å…¥äº†ä¸€äº›å™ªå£°ï¼Œä»¥ä½¿å…¶ä¸å®Œå…¨å®Œç¾ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹åˆ°å®é™…å€¼å’Œé¢„æµ‹å€¼éå¸¸æ¥è¿‘ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿›è¡Œå¤šè¾“å‡ºå›å½’ã€‚å¤šè¾“å‡ºå›å½’å¯¹äºè‡ªç¼–ç å™¨è‡³å…³é‡è¦ã€‚æœ¬è´¨ä¸Šï¼Œå‘ç”Ÿçš„äº‹æƒ…æ˜¯ä½ æœ‰è¾“å…¥ï¼Œå°±åƒä¹‹å‰çš„è¾“å…¥1ã€è¾“å…¥2ã€è¾“å…¥3ã€è¾“å…¥4ã€‚
- en: but you can have multiple output neuronsã€‚ Now for an autoencoderã€‚ usually the
    number of inputs matches the number of outputsã€‚ Let's just go ahead and run this
    oneã€‚ğŸ˜Šã€‚Which is attempting to train it on both the sine and the cosine simultaneouslyã€‚
    I'll go in fast forward this until it gets doneã€‚ Okayï¼Œ it completes the RMS E
    looks pretty goodã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ å¯ä»¥æ‹¥æœ‰å¤šä¸ªè¾“å‡ºç¥ç»å…ƒã€‚ç°åœ¨è°ˆè°ˆè‡ªç¼–ç å™¨ã€‚é€šå¸¸ï¼Œè¾“å…¥çš„æ•°é‡ä¸è¾“å‡ºçš„æ•°é‡ç›¸åŒ¹é…ã€‚æˆ‘ä»¬å°±ç›´æ¥è¿è¡Œè¿™ä¸ªã€‚ğŸ˜Šã€‚å®ƒè¯•å›¾åŒæ—¶å¯¹æ­£å¼¦å’Œä½™å¼¦è¿›è¡Œè®­ç»ƒã€‚æˆ‘å°†å¿«è¿›ç›´åˆ°å®ƒå®Œæˆã€‚å¥½çš„ï¼Œå®ƒå®Œæˆäº†ï¼Œå‡æ–¹æ ¹è¯¯å·®çœ‹èµ·æ¥ä¸é”™ã€‚
- en: You can see some of the predictions and expectedã€‚ So it is learning sine and
    cosineã€‚ at the same timeã€‚ which isï¼Œ which is amazingã€‚ Wellï¼Œ not reallyã€‚ I meanï¼Œ
    neural networksã€‚ multiple output regressioning is really a pretty common thingã€‚
    You don't see it a lotï¼Œ thoughã€‚ in other types of machine learning modelã€‚ Nowï¼Œ
    let's do a simple autoencoderã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°ä¸€äº›é¢„æµ‹å€¼å’ŒæœŸæœ›å€¼ã€‚æ‰€ä»¥å®ƒåœ¨åŒæ—¶å­¦ä¹ æ­£å¼¦å’Œä½™å¼¦ã€‚è¿™æ˜¯éå¸¸ä»¤äººæƒŠè®¶çš„ã€‚ä¸è¿‡ï¼Œå…¶å®å¹¶ä¸å¤ªæƒŠäººã€‚æˆ‘æ˜¯è¯´ï¼Œç¥ç»ç½‘ç»œçš„å¤šè¾“å‡ºå›å½’æ˜¯ç›¸å½“å¸¸è§çš„äº‹æƒ…ã€‚å°½ç®¡åœ¨å…¶ä»–ç±»å‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ä¸å¸¸è§ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æ¥åšä¸€ä¸ªç®€å•çš„è‡ªç¼–ç å™¨ã€‚
- en: And notice the autoencoderï¼Œ we have five inputs we have five outputsã€‚ Whatever
    number of inputs you have should be the same number of outputsã€‚ And what we're
    essentially doingã€‚ This is kind of fascinatingã€‚ This is what autoencors doã€‚ We're
    putting inã€‚ğŸ˜Šï¼ŒEssentiallyï¼Œ random numbers hereã€‚And we are training itã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„è¿™ä¸ªè‡ªç¼–ç å™¨ï¼Œæˆ‘ä»¬æœ‰äº”ä¸ªè¾“å…¥å’Œäº”ä¸ªè¾“å‡ºã€‚ä½ æ‹¥æœ‰çš„è¾“å…¥æ•°é‡åº”è¯¥ä¸è¾“å‡ºæ•°é‡ç›¸åŒã€‚è€Œæˆ‘ä»¬æœ¬è´¨ä¸Šåœ¨åšçš„äº‹æƒ…ï¼Œè¿™æœ‰ç‚¹è¿·äººã€‚è¿™å°±æ˜¯è‡ªç¼–ç å™¨çš„ä½œç”¨ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œè¾“å…¥ã€‚ğŸ˜Šï¼ŒåŸºæœ¬ä¸Šæ˜¯éšæœºæ•°å­—ã€‚æˆ‘ä»¬æ­£åœ¨è®­ç»ƒå®ƒã€‚
- en: expecting that we get the same numbers out as we put in originallyã€‚This teaches
    the neural network to use just these two hidden layersã€‚ these two hidden neurons
    here to essentially compressã€‚All the inputs down into just two number of valuesã€‚
    So here we'll just train that same shape1 that we had beforeã€‚ It trains very quicklyã€‚
    And you can see I'm basically passing in 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ8ï¼Œ9ã€‚ And it's essentially
    returning close to the same thingï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ï¼Œ8ã€‚ and in a quite get that oneï¼Œ
    correctã€‚ Oftenï¼Œ these autoenrs are used on imagesã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœŸå¾…æˆ‘ä»¬å¾—åˆ°çš„è¾“å‡ºä¸æœ€åˆè¾“å…¥çš„æ•°å­—ç›¸åŒã€‚è¿™æ•™ä¼šç¥ç»ç½‘ç»œåªä½¿ç”¨è¿™ä¸¤ä¸ªéšè—å±‚ã€‚è¿™ä¸¤ä¸ªéšè—ç¥ç»å…ƒå®é™…ä¸Šå°†æ‰€æœ‰è¾“å…¥å‹ç¼©æˆä»…ä¸¤ä¸ªæ•°å€¼ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¹‹å‰ç›¸åŒçš„å½¢çŠ¶1ã€‚å®ƒè®­ç»ƒå¾—éå¸¸å¿«ã€‚ä½ å¯ä»¥çœ‹åˆ°æˆ‘åŸºæœ¬ä¸Šè¾“å…¥äº†0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ8ï¼Œ9ã€‚å®ƒåŸºæœ¬ä¸Šè¿”å›äº†æ¥è¿‘ç›¸åŒçš„ç»“æœï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ï¼Œ8ã€‚å¹¶ä¸”å¾ˆå¿«å°±å¾—åˆ°äº†é‚£ä¸ªï¼Œæ­£ç¡®çš„ã€‚é€šå¸¸ï¼Œè¿™äº›è‡ªç¼–ç å™¨ç”¨äºå›¾åƒã€‚
- en: So let's go ahead and load some images in that we can make use ofã€‚ I'm showing
    you basically here how we created an autoencor to encode this image of Washington
    Universityã€‚ Nowï¼Œ if you look at the definition for thisã€‚ğŸ˜Šï¼ŒIt's essentially reducing
    through a hidden layer of oneã€‚ So it's teaching it to very highly compress this
    so that just one numeric value can represent itã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€äº›å¯ä»¥åˆ©ç”¨çš„å›¾åƒã€‚æˆ‘åœ¨è¿™é‡ŒåŸºæœ¬ä¸Šå‘ä½ å±•ç¤ºäº†æˆ‘ä»¬æ˜¯å¦‚ä½•åˆ›å»ºä¸€ä¸ªè‡ªç¼–ç å™¨æ¥ç¼–ç åç››é¡¿å¤§å­¦çš„è¿™å¼ å›¾åƒã€‚ç°åœ¨ï¼Œå¦‚æœä½ çœ‹è¿™ä¸ªå®šä¹‰ã€‚ğŸ˜Šï¼Œå®ƒå®é™…ä¸Šæ˜¯é€šè¿‡ä¸€ä¸ªéšè—å±‚è¿›è¡Œé«˜åº¦å‹ç¼©ã€‚å› æ­¤ï¼Œå®ƒæ•™ä¼šè‡ªç¼–ç å™¨å¦‚æ­¤é«˜åº¦å‹ç¼©ï¼Œä»¥è‡³äºä»…ä¸€ä¸ªæ•°å€¼å°±èƒ½è¡¨ç¤ºå®ƒã€‚
- en: Nowï¼Œ of courseï¼Œ the hidden layers above and below it will' have some knowledge
    of the imageã€‚ So that's where you can basically put it into something so small
    and still get meaningful output out of itã€‚ Let's load a number of images and standardize
    themã€‚ We're going to make sure that all the same sizeã€‚ There's other standardizations
    we could doã€‚ We could also make sure that the amount of light matchesã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä¸Šä¸‹çš„éšè—å±‚ä¼šå¯¹å›¾åƒæœ‰ä¸€äº›äº†è§£ã€‚å› æ­¤ï¼Œä½ åŸºæœ¬ä¸Šå¯ä»¥å°†å…¶å‹ç¼©å¾—å¦‚æ­¤å°ï¼Œä»ç„¶èƒ½å¤Ÿè·å¾—æœ‰æ„ä¹‰çš„è¾“å‡ºã€‚è®©æˆ‘ä»¬åŠ è½½ä¸€äº›å›¾åƒå¹¶è¿›è¡Œæ ‡å‡†åŒ–ã€‚æˆ‘ä»¬å°†ç¡®ä¿æ‰€æœ‰å›¾åƒå¤§å°ç›¸åŒã€‚æˆ‘ä»¬è¿˜å¯ä»¥è¿›è¡Œå…¶ä»–æ ‡å‡†åŒ–ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ç¡®ä¿å…‰ç…§é‡ä¸€è‡´ã€‚
- en: which currently it does notã€‚ And now we are going to try to predict thoseã€‚ So
    we essentially loop through these are 1 28 by 128ã€‚ğŸ˜Šã€‚We are compressing them down
    to that size and passing that value as the input and the outputã€‚ trying to get
    the output from the neural network to look just like the training dataã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç›®å‰å®ƒå¹¶æ²¡æœ‰åšåˆ°ã€‚ç°åœ¨æˆ‘ä»¬å°†å°è¯•è¿›è¡Œé¢„æµ‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå¾ªç¯è¿™äº›128ä¹˜128çš„å›¾åƒã€‚ğŸ˜Šã€‚æˆ‘ä»¬æ­£åœ¨å°†å®ƒä»¬å‹ç¼©åˆ°è¿™ä¸ªå¤§å°ï¼Œå¹¶å°†è¯¥å€¼ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºã€‚å°è¯•è®©ç¥ç»ç½‘ç»œçš„è¾“å‡ºçœ‹èµ·æ¥ä¸è®­ç»ƒæ•°æ®ä¸€æ ·ã€‚
- en: I'll fast forward here at this pointã€‚ And here you can see it's able to reconstruct
    the images just based on these vectors coming inã€‚ Nowï¼Œ let's look at a denoisisingã€‚Auto
    encoderã€‚ These are very interestingï¼Œ soã€‚Let's run one and we'll see that we can
    add noise to an imageã€‚ I've just put random boxes in thereã€‚We can essentially
    train it Nowã€‚ normallyï¼Œ an autoencorã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘å°†å¿«é€Ÿå‰è¿›ã€‚åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°å®ƒèƒ½å¤Ÿæ ¹æ®è¿™äº›è¾“å…¥çš„å‘é‡é‡å»ºå›¾åƒã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å»å™ªè‡ªç¼–ç å™¨ã€‚è¿™äº›éå¸¸æœ‰è¶£ï¼Œæ‰€ä»¥ã€‚æˆ‘ä»¬æ¥è¿è¡Œä¸€ä¸ªï¼Œçœ‹çœ‹æˆ‘ä»¬å¯ä»¥ç»™å›¾åƒæ·»åŠ å™ªå£°ã€‚æˆ‘åªæ˜¯æ”¾äº†ä¸€äº›éšæœºçš„æ¡†åœ¨é‚£é‡Œã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šç°åœ¨å¯ä»¥è¿›è¡Œè®­ç»ƒã€‚é€šå¸¸ï¼Œè‡ªç¼–ç å™¨ã€‚
- en: you put in the input and you expect the same output out of itã€‚ But here we're
    going to be putting input with these squares obstructed and expecting to get as
    close we can as the original imageã€‚ This teaches the autoencors to remove noiseã€‚We
    can run it and watch the outputã€‚ These images that are slowly flashing byã€‚ They
    had all those pixels removed with boxesã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¾“å…¥æ•°æ®ï¼ŒæœŸå¾…å¾—åˆ°ç›¸åŒçš„è¾“å‡ºã€‚ä½†åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¾“å…¥è¢«è¿™äº›æ–¹æ¡†é®æŒ¡çš„å›¾åƒï¼Œå¹¶æœŸå¾…å°½å¯èƒ½æ¥è¿‘åŸå§‹å›¾åƒã€‚è¿™æ•™ä¼šè‡ªç¼–ç å™¨å»é™¤å™ªå£°ã€‚æˆ‘ä»¬å¯ä»¥è¿è¡Œå®ƒå¹¶è§‚å¯Ÿè¾“å‡ºã€‚è¿™äº›å›¾åƒæ…¢æ…¢é—ªè¿‡ã€‚å®ƒä»¬çš„æ‰€æœ‰åƒç´ éƒ½è¢«æ¡†å»é™¤äº†ã€‚
- en: but yet they're still coming out pretty wellã€‚ And then we'll train the neural
    network based on those noisy images that we created and we'll run it through 10
    sort of random trialsã€‚ Here you can see with noise and without noiseã€‚ It's doing
    pretty good taking that awayã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒä»¬ä¾ç„¶è¡¨ç°å¾—å¾ˆå¥½ã€‚ç„¶åæˆ‘ä»¬å°†åŸºäºè¿™äº›æˆ‘ä»¬åˆ›å»ºçš„å™ªå£°å›¾åƒè®­ç»ƒç¥ç»ç½‘ç»œï¼Œå¹¶è¿›è¡Œ10æ¬¡éšæœºè¯•éªŒã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œæœ‰å™ªå£°å’Œæ²¡æœ‰å™ªå£°çš„æƒ…å†µä¸‹ã€‚å®ƒåœ¨å»é™¤å™ªå£°æ–¹é¢åšå¾—ç›¸å½“ä¸é”™ã€‚
- en: You'll notice some distortionsã€‚ If you zoom in on where the the boxes areã€‚ But
    this is kind of how that worksã€‚ You can see itã€‚ it's really able to do well at
    removing the noiseã€‚ This is an auto noisingã€‚ This is an auto denoising autoencoderã€‚
    Nowï¼Œ autoencors can do all kinds of thingsã€‚ We will seeã€‚ğŸ˜Šã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šæ³¨æ„åˆ°ä¸€äº›å¤±çœŸã€‚å¦‚æœä½ æ”¾å¤§æ¡†çš„ä½ç½®ã€‚ä½†è¿™å°±æ˜¯å®ƒçš„å·¥ä½œæ–¹å¼ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œå®ƒç¡®å®èƒ½å¤Ÿå¾ˆå¥½åœ°å»é™¤å™ªå£°ã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªå»å™ªã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªå»å™ªè‡ªç¼–ç å™¨ã€‚ç°åœ¨ï¼Œè‡ªç¼–ç å™¨å¯ä»¥åšå„ç§å„æ ·çš„äº‹æƒ…ã€‚æˆ‘ä»¬å°†çœ‹åˆ°ã€‚ğŸ˜Šã€‚
- en: In the next partï¼Œ how we can make use of themã€‚To detect anomaliesã€‚ So input
    is that is different than what we've seen beforeã€‚ this content changes oftenã€‚
    so subscribe to the channel to stay up to date on this course and other topics
    in artificial intelligenceã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•åˆ©ç”¨å®ƒä»¬æ¥æ£€æµ‹å¼‚å¸¸ã€‚å› æ­¤ï¼Œè¾“å…¥ä¸æˆ‘ä»¬ä¹‹å‰è§è¿‡çš„å†…å®¹ä¸åŒã€‚è¿™äº›å†…å®¹ç»å¸¸å˜åŒ–ï¼Œå› æ­¤è¯·è®¢é˜…é¢‘é“ä»¥è·å–æœ¬è¯¾ç¨‹åŠå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜çš„æœ€æ–°ä¿¡æ¯ã€‚
- en: '![](img/be628560dda59c2203db5dbe7b4cf58a_3.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be628560dda59c2203db5dbe7b4cf58a_3.png)'
