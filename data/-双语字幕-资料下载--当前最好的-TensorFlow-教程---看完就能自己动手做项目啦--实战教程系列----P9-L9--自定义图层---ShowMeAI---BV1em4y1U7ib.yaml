- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P9ï¼šL9- è‡ªå®šä¹‰å›¾å±‚ - ShowMeAI
    - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P9ï¼šL9- è‡ªå®šä¹‰å›¾å±‚ - ShowMeAI
    - BV1em4y1U7ib
- en: What is going onï¼Œ guysï¼Œ hope you're doing freaking awesomeã€‚ So in this videoã€‚
    I want to show you how to create custom layersã€‚ğŸ˜Šã€‚![](img/2b96deb5c7669b397136afafb6aca66a_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œå¸Œæœ›ä½ ä»¬è¿‡å¾—éå¸¸ç²¾å½©ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘æƒ³å‘ä½ å±•ç¤ºå¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰å±‚ã€‚ğŸ˜Šï¼[](img/2b96deb5c7669b397136afafb6aca66a_1.png)
- en: '![](img/2b96deb5c7669b397136afafb6aca66a_2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b96deb5c7669b397136afafb6aca66a_2.png)'
- en: So far we've seen how to build very flexible models using subclassing and now
    we want to go one level deeper and even create the layers by ourselvesã€‚ So I'll
    show you what I mean by that but first just to explain the code we have in front
    of us right now we just have the import that we've seen pretty much every video
    and then we have these two lines to avoid any GPU errors and then lastly we're
    just loading the Ms data so this is just to save some time and so what we're going
    to start with is creating our own custom model sort of like we did in the last
    video so it's going to be very simple we're going to do class my model we're going
    to inherit from Kast model we're going to start with finding the init method we're
    going do self and then we could specify the number of classes for Ms 10 and then
    we're going just going call the super super mymod self do in itã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨å­ç±»åŒ–æ„å»ºéå¸¸çµæ´»çš„æ¨¡å‹ï¼Œç°åœ¨æˆ‘ä»¬æƒ³æ›´è¿›ä¸€æ­¥ï¼Œè‡ªå·±åˆ›å»ºå±‚ã€‚å› æ­¤ï¼Œæˆ‘ä¼šå‘ä½ è§£é‡Šæˆ‘æ‰€æŒ‡çš„å†…å®¹ï¼Œä½†é¦–å…ˆä¸ºäº†è¯´æ˜æˆ‘ä»¬é¢å‰çš„ä»£ç ï¼Œæˆ‘ä»¬åªæ˜¯å¼•å…¥äº†åœ¨å‡ ä¹æ¯ä¸ªè§†é¢‘ä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œç„¶åæˆ‘ä»¬æœ‰è¿™ä¸¤è¡Œä»£ç ä»¥é¿å…ä»»ä½•GPUé”™è¯¯ï¼Œæœ€åæˆ‘ä»¬åªæ˜¯åœ¨åŠ è½½Msæ•°æ®ï¼Œè¿™æ ·å¯ä»¥èŠ‚çœä¸€äº›æ—¶é—´ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä»åˆ›å»ºè‡ªå·±çš„è‡ªå®šä¹‰æ¨¡å‹å¼€å§‹ï¼Œåƒæˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªè§†é¢‘ä¸­åšçš„ä¸€æ ·ï¼Œè¿™ä¼šéå¸¸ç®€å•ï¼Œæˆ‘ä»¬å°†åˆ›å»ºç±»my
    modelï¼Œç»§æ‰¿è‡ªKastæ¨¡å‹ï¼Œé¦–å…ˆæ‰¾åˆ°initæ–¹æ³•ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨selfï¼Œç„¶åå¯ä»¥æŒ‡å®šMsçš„ç±»æ•°ä¸º10ï¼Œæ¥ç€æˆ‘ä»¬å°†è°ƒç”¨super mymod selfçš„initã€‚
- en: And then we're going to do self dense1ï¼Œ So all we're going to do here is just
    create two dense layers Allrightã€‚ we're going to do layers do denseï¼Œ let's do
    64 nodes and then self dense2 is layers dense of nu classes we're just going to
    do the call So we're going to call self and then xã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è¿›è¡Œself dense1ï¼Œè¿™é‡Œæˆ‘ä»¬åªéœ€åˆ›å»ºä¸¤ä¸ªå¯†é›†å±‚ã€‚å¥½çš„ã€‚æˆ‘ä»¬å°†ä½¿ç”¨layers do denseï¼Œè®¾å®šä¸º64ä¸ªèŠ‚ç‚¹ï¼Œç„¶åself dense2æ˜¯layers
    denseçš„nu classesï¼Œæˆ‘ä»¬å°†è°ƒç”¨selfï¼Œç„¶åæ˜¯xã€‚
- en: So the input or let's call input tensorã€‚And then we're going to do self do den
    one of input tensorã€‚And then let's run a Tfã€‚nnã€‚relu on top of thatã€‚So this is
    just what we've seen in the last videoã€‚ this is why I'm going through it pretty
    quicklyï¼Œ and then we want to return self do then2 of xã€‚ al rightã€‚So now let's
    quickly build aã€‚And just a model compile a model fit on thatã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥æˆ–ç§°ä¸ºè¾“å…¥å¼ é‡ã€‚ç„¶åæˆ‘ä»¬å°†æ‰§è¡Œself do den oneçš„è¾“å…¥å¼ é‡ã€‚æ¥ç€åœ¨å…¶ä¸Šè¿è¡ŒTf.nn.reluã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªè§†é¢‘ä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œå› æ­¤æˆ‘å¿«é€Ÿè®²è§£ï¼Œç„¶åæˆ‘ä»¬æƒ³è¿”å›self
    do then2çš„xã€‚å¥½çš„ã€‚ç°åœ¨è®©æˆ‘ä»¬å¿«é€Ÿæ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œç¼–è¯‘æ¨¡å‹å¹¶è¿›è¡Œæ‹Ÿåˆã€‚
- en: So we'll do model equals my modelã€‚ We'll do model do compileã€‚Loss equals ksï¼Œ
    lossesï¼Œ barsã€‚ categorical cross entropyã€‚From logic equals trueã€‚ğŸ˜”ï¼ŒAnd then let's
    do our model that fitã€‚ so you've seen all of this beforeï¼Œ so I'm just going to
    write it out pretty quicklyã€‚Alright so now we have a custom model using subclassing
    and then we're just defining our compile and our fit and our evaluate so let's
    just make sure that this actually works so if we run this we see that it's actually
    training and this should go relatively quickly because we just have yeah so we
    have a very very small network like 64 nodes and then 10 output nodes let's actually
    talk about what I want to show you in this video soã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ‰§è¡Œmodel equals my modelã€‚æˆ‘ä»¬å°†æ‰§è¡Œmodel do compileã€‚æŸå¤±ç­‰äºksï¼ŒæŸå¤±ï¼Œbarsã€‚åˆ†ç±»äº¤å‰ç†µã€‚ä»é€»è¾‘ä¸Šè®²ç­‰äºtrueã€‚ğŸ˜”ï¼Œç„¶åè®©æˆ‘ä»¬è¿›è¡Œæ¨¡å‹æ‹Ÿåˆã€‚ä½ ä¹‹å‰è§è¿‡è¿™äº›ï¼Œæ‰€ä»¥æˆ‘ä¼šå¿«é€Ÿå†™å‡ºã€‚å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªä½¿ç”¨å­ç±»åŒ–çš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬å®šä¹‰äº†ç¼–è¯‘ã€æ‹Ÿåˆå’Œè¯„ä¼°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç¡®ä¿è¿™ç¡®å®æœ‰æ•ˆï¼Œå¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å®ƒå®é™…ä¸Šåœ¨è®­ç»ƒï¼Œè¿™åº”è¯¥ç›¸å¯¹è¾ƒå¿«ï¼Œå› ä¸ºæˆ‘ä»¬åªæœ‰æ˜¯çš„ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸éå¸¸å°çš„ç½‘ç»œï¼Œåƒ64ä¸ªèŠ‚ç‚¹ï¼Œç„¶å10ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œè®©æˆ‘ä»¬å®é™…è®¨è®ºä¸€ä¸‹æˆ‘æƒ³åœ¨è¿™ä¸ªè§†é¢‘ä¸­å±•ç¤ºçš„å†…å®¹ã€‚
- en: We now want to actually create these layers by ourselves right now we're using
    the layers from Ks and that has the dense layers in it and then we're using Tfã€‚nã€‚relu
    and that's all right and you can build very flexible models using that that's
    actually in most use cases that's fine but sometimes and just for understanding
    you want to actually be able to build those layers by yourself so that you really
    understand what's going on a more under the hood so I'm going to show you how
    to do that and let's do class and let's do dense and we're going to inherit from
    layers layerã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æƒ³è‡ªå·±åˆ›å»ºè¿™äº›å±‚ã€‚ç›®å‰æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯Ksä¸­çš„å±‚ï¼Œé‡Œé¢åŒ…å«å¯†é›†å±‚ï¼Œç„¶åä½¿ç”¨Tf.n.reluã€‚è¿™æ˜¯å¯ä»¥çš„ï¼Œä½ å¯ä»¥ç”¨å®ƒæ„å»ºéå¸¸çµæ´»çš„æ¨¡å‹ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¿™éƒ½å¾ˆå¥½ã€‚ä½†æœ‰æ—¶ä¸ºäº†ç†è§£ï¼Œä½ æƒ³è‡ªå·±æ„å»ºè¿™äº›å±‚ï¼Œè¿™æ ·å¯ä»¥æ›´æ·±å…¥åœ°ç†è§£å†…éƒ¨æœºåˆ¶ã€‚æ‰€ä»¥æˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚è®©æˆ‘ä»¬åšä¸€ä¸ªç±»ï¼Œå‘½åä¸ºdenseï¼Œå¹¶ç»§æ‰¿è‡ªlayers
    layerã€‚
- en: We're going to create our in functionï¼Œ so we're going to do init and then self
    unitã€‚ and then we're going to specify the input dimensionã€‚So all we got to do
    then is we got to run this super methodï¼Œ so super dense self thatt in itã€‚Then
    we're going to do self that W is self add weightã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åˆ›å»ºæˆ‘ä»¬çš„åˆå§‹åŒ–å‡½æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åšinitï¼Œç„¶åæ˜¯selfå’Œunitã€‚æ¥ç€æˆ‘ä»¬å°†æŒ‡å®šè¾“å…¥ç»´åº¦ã€‚ç„¶åæˆ‘ä»¬è¦åšçš„å°±æ˜¯è¿è¡Œsuperæ–¹æ³•ï¼Œæ‰€ä»¥super
    dense self that initã€‚ç„¶åæˆ‘ä»¬å°†self.Wè®¾ç½®ä¸ºself.add weightã€‚
- en: So there are actually multiple ways of doing thisã€‚ this is the more easy way
    you could also do initialize it by yourself with a T dot variable but this is
    the easy way I'm going to show you in this way Now the first thing we got to do
    is we've got to set it to a name let's just call it W and actually this is quite
    important you'll see in the next video how we can save and load models and I found
    out if you don't actually specify a name you can't save the model so this is very
    important and then we're just going to do a shape we're going to specify a shape
    as input dimension and then to unit All right so input dimension is just what
    we have in the beginning it's going to be 784 which is 28 times 28 and then unit
    is just what we're gonna map it to so when we're using layers164 the unit is 64
    then we can alsoã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šæœ‰å¤šç§æ–¹æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚è¿™æ˜¯æ›´ç®€å•çš„æ–¹æ³•ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨Tç‚¹å˜é‡è‡ªå·±åˆå§‹åŒ–ï¼Œä½†æˆ‘å°†ä»¥è¿™ç§ç®€å•çš„æ–¹æ³•å±•ç¤ºç»™ä½ ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€ä¸ªåç§°ï¼Œæˆ‘ä»¬å°±å«å®ƒWã€‚å®é™…ä¸Šï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼Œä½ ä¼šåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­çœ‹åˆ°å¦‚ä½•ä¿å­˜å’ŒåŠ è½½æ¨¡å‹ã€‚æˆ‘å‘ç°å¦‚æœä¸æŒ‡å®šåç§°ï¼Œå°±æ— æ³•ä¿å­˜æ¨¡å‹ï¼Œæ‰€ä»¥è¿™éå¸¸é‡è¦ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦æŒ‡å®šä¸€ä¸ªè¾“å…¥ç»´åº¦çš„å½¢çŠ¶ï¼Œç„¶åè®¾ç½®å•ä½ã€‚è¾“å…¥ç»´åº¦å°±æ˜¯æˆ‘ä»¬ä¸€å¼€å§‹çš„å€¼ï¼Œ784ï¼Œå³28ä¹˜ä»¥28ï¼Œç„¶åå•ä½å°±æ˜¯æˆ‘ä»¬è¦æ˜ å°„åˆ°çš„å€¼ï¼Œæ‰€ä»¥åœ¨ä½¿ç”¨layers164æ—¶ï¼Œå•ä½æ˜¯64ã€‚
- en: the initializer so we're going to do random normal and you could check out what
    other initialization methods you can doã€‚ and then we're going to specify trainable
    equals trueã€‚And so trainable equals trueã€‚ this is for layers like batch norm and
    so on where some of the parameters are not actually trainableã€‚ but so all of our
    parameters in this dense layer are going to be trainable then we're going to do
    selfã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹åŒ–å™¨æˆ‘ä»¬å°†ä½¿ç”¨éšæœºæ­£æ€åˆ†å¸ƒï¼Œä½ å¯ä»¥æŸ¥çœ‹å…¶ä»–åˆå§‹åŒ–æ–¹æ³•ã€‚ç„¶åæˆ‘ä»¬å°†æŒ‡å®štrainableç­‰äºtrueã€‚æ‰€ä»¥trainableç­‰äºtrueã€‚è¿™é€‚ç”¨äºåƒbatch
    normè¿™æ ·çš„å±‚ï¼Œå…¶ä¸­æŸäº›å‚æ•°å®é™…ä¸Šä¸æ˜¯å¯è®­ç»ƒçš„ã€‚ä½†åœ¨è¿™ä¸ªå¯†é›†å±‚ä¸­ï¼Œæˆ‘ä»¬çš„æ‰€æœ‰å‚æ•°éƒ½å°†æ˜¯å¯è®­ç»ƒçš„ï¼Œç„¶åæˆ‘ä»¬å°†è¿›è¡Œselfã€‚
- en: B is selfã€‚ add weightã€‚We're going to call it B and then shape is just going
    to be unitã€‚RightSo't have so we're doing the matrix multiply with W and that's
    why it has to have the input dimensionã€‚ but then it's just going to be unit nodes
    so we're going to add one for each of themã€‚ that's why we just have units right
    hereã€‚Then we can do initializer and we're just going to initialize it as zerosã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Bæ˜¯self.add weightã€‚æˆ‘ä»¬å°†å…¶å‘½åä¸ºBï¼Œå½¢çŠ¶å°±æ˜¯å•ä½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿›è¡ŒçŸ©é˜µä¹˜æ³•æ—¶éœ€è¦Wï¼Œè¿™å°±æ˜¯å®ƒå¿…é¡»å…·æœ‰è¾“å…¥ç»´åº¦çš„åŸå› ã€‚ç„¶åå®ƒå°†æ˜¯å•ä½èŠ‚ç‚¹ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ä¸€ä¸ªã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œæ‰€ç”¨çš„å•ä½ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è¿›è¡Œåˆå§‹åŒ–ï¼Œæˆ‘ä»¬å°†å…¶åˆå§‹åŒ–ä¸ºé›¶ã€‚
- en: and then this is also a trainable parameterã€‚And lastlyï¼Œ we just have to do the
    call methodã€‚ So call of some inputã€‚ we're going to return T of dot matrix multiply
    with the inputã€‚And then self to Wï¼Œ and lastlyï¼Œ we just got to add Bã€‚So nowã€‚We
    can actually replace this right here so we can do let's do selfta dense 1 is dense
    and then let's do 64 and then 784ã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°ã€‚æœ€åï¼Œæˆ‘ä»¬åªéœ€å®ç°callæ–¹æ³•ã€‚å¯¹äºä¸€äº›è¾“å…¥ï¼Œæˆ‘ä»¬å°†è¿”å›Tç‚¹çŸ©é˜µä¹˜ä»¥è¾“å…¥ã€‚ç„¶åselfåˆ°Wï¼Œæœ€åæˆ‘ä»¬éœ€è¦æ·»åŠ Bã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œæ›¿æ¢ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åšself
    ta dense 1æ˜¯denseï¼Œç„¶åè®¾ç½®64å’Œ784ã€‚
- en: and then let's do selfta dense 2 is dense of 10 and then 64 as inputã€‚So let's
    out that one right there and let's see if this worksã€‚ Allrightã€‚ so we seem to
    get pretty much equal results as we did on the last one and most importantly it
    actually runs So one thing you can notice here first of all is that on these ones
    we didn't have to specify the input dimension and this is what we're going call
    it making the layers lazy in that you don't have to actually even say what the
    input dimension is it's just going to work that out So that's what we want to
    do now we want to actually remove this part and make it work regardless of the
    input dimension So how we can do that is that we're going to create a build method
    all right so we have our in it right now and we're going to remove the input dimension
    right hereã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æ¥åšä¸€ä¸ªè‡ªå¯†é›†å±‚ï¼Œè¾“å…¥ç»´åº¦æ˜¯10ï¼Œç„¶åæ˜¯64ã€‚ç°åœ¨æŠŠè¿™ä¸ªè¾“å‡ºæ”¾åœ¨é‚£é‡Œï¼Œçœ‹çœ‹æ˜¯å¦æœ‰æ•ˆã€‚å¥½çš„ï¼Œæˆ‘ä»¬ä¼¼ä¹å¾—åˆ°äº†ä¸ä¸Šä¸€ä¸ªå‡ ä¹ç›¸ç­‰çš„ç»“æœï¼Œæœ€é‡è¦çš„æ˜¯å®ƒç¡®å®å¯ä»¥è¿è¡Œã€‚é¦–å…ˆï¼Œä½ å¯ä»¥æ³¨æ„åˆ°ï¼Œåœ¨è¿™äº›ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸éœ€è¦æŒ‡å®šè¾“å…¥ç»´åº¦ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºæ‡’æƒ°å±‚ï¼Œè¿™æ ·ä½ æ ¹æœ¬ä¸éœ€è¦è¯´æ˜è¾“å…¥ç»´åº¦ï¼Œå®ƒä¼šè‡ªåŠ¨è®¡ç®—å‡ºæ¥ã€‚æ‰€ä»¥æˆ‘ä»¬ç°åœ¨æƒ³åšçš„æ˜¯ç§»é™¤è¿™ä¸€éƒ¨åˆ†ï¼Œä½¿å…¶æ— è®ºè¾“å…¥ç»´åº¦å¦‚ä½•éƒ½èƒ½å·¥ä½œã€‚æˆ‘ä»¬è¦åšåˆ°è¿™ä¸€ç‚¹çš„æ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªæ„å»ºæ–¹æ³•ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†åˆå§‹åŒ–ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œç§»é™¤è¾“å…¥ç»´åº¦ã€‚
- en: And then we're going to do a build methodã€‚So we're going to do define buildã€‚
    we're going to have selfï¼Œ and then we're going to have an input shapeã€‚And then
    we're actually going to create the Ws right hereã€‚ so we're going to paste that
    in the build method insteadã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ„å»ºæ–¹æ³•ã€‚æˆ‘ä»¬å°†å®šä¹‰æ„å»ºï¼Œä¼ å…¥selfå’Œè¾“å…¥å½¢çŠ¶ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œåˆ›å»ºWsï¼Œå› æ­¤æˆ‘ä»¬å°†æŠŠè¿™æ®µä»£ç ç²˜è´´åˆ°æ„å»ºæ–¹æ³•ä¸­ã€‚
- en: and now what's so great is that instead of using input input dim we can do input
    shape and then we're going to do sort of the last of those so in this case we
    have the training examples on the first dimension and then we have 784 because
    of the way we've reshaped it right hereã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨éå¸¸æ£’çš„æ˜¯ï¼Œä½¿ç”¨è¾“å…¥å½¢çŠ¶è€Œä¸æ˜¯è¾“å…¥ç»´åº¦ï¼Œæˆ‘ä»¬å¯ä»¥å¤„ç†æœ€åä¸€ä¸ªç»´åº¦ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åœ¨ç¬¬ä¸€ç»´æœ‰è®­ç»ƒæ ·æœ¬ï¼Œç„¶åç”±äºæˆ‘ä»¬åœ¨è¿™é‡Œçš„é‡å¡‘ï¼Œæˆ‘ä»¬æœ‰784ã€‚
- en: so that's why we do minus1 here and then we're going to do units although what
    we're going to do in the in methods is do selft units equals unitsã€‚And then we
    got to do replace these units right here with self dot units for both of the for
    the W and then self dot Bã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œåš-1ï¼Œç„¶åæˆ‘ä»¬å°†ä½¿ç”¨å•ä½ï¼Œè™½ç„¶åœ¨åˆå§‹åŒ–æ–¹æ³•ä¸­æˆ‘ä»¬å°†self.unitsè®¾ç½®ä¸ºunitsã€‚æ¥ç€ï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™é‡Œçš„å•ä½æ›¿æ¢ä¸ºself.unitsï¼ŒWå’ŒBéƒ½éœ€è¦å¦‚æ­¤ã€‚
- en: So what's amazing now is that if we would run thisã€‚ we wouldn't have to specify
    the input dimension this hopefully we work so we can actually we can do that classes
    So let's run this now and let's see what we getã€‚And it seems to work and now we
    see that this like these two are pretty similar right the functionality of them
    are pretty much identical and then you might be saying well we're still using
    TfN and dot Reello it would be nice to actually create this ourselves as well
    and so that's our next step you can do this in two ways you can create a function
    or you can create a class like we're doing so far I think the most common way
    is actually defining a function but let's just create a class and you can try
    making a functionã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦æŒ‡å®šè¾“å…¥ç»´åº¦ï¼Œè¿™æ ·å¸Œæœ›å¯ä»¥å·¥ä½œã€‚æˆ‘ä»¬å¯ä»¥è¿è¡Œè¿™äº›ç±»ã€‚ç°åœ¨è®©æˆ‘ä»¬è¯•è¯•ï¼Œçœ‹çœ‹ä¼šå¾—åˆ°ä»€ä¹ˆã€‚å®ƒä¼¼ä¹æœ‰æ•ˆï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™ä¸¤ä¸ªåŠŸèƒ½å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚ä½ å¯èƒ½ä¼šè¯´ï¼Œæˆ‘ä»¬ä»åœ¨ä½¿ç”¨TfNå’Œdot
    Reelloï¼Œå®é™…ä¸Šè‡ªå·±åˆ›å»ºè¿™ä¸ªä¹Ÿä¸é”™ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„ä¸‹ä¸€æ­¥ã€‚ä½ å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªå‡½æ•°æˆ–åƒæˆ‘ä»¬ç°åœ¨è¿™æ ·åˆ›å»ºä¸€ä¸ªç±»ã€‚æˆ‘è®¤ä¸ºæœ€å¸¸è§çš„æ–¹æ³•æ˜¯å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä½†è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç±»ï¼Œä½ å¯ä»¥å°è¯•åˆ¶ä½œä¸€ä¸ªå‡½æ•°ã€‚
- en: It's going to be pretty much the sameã€‚But we're going to do class Mireelloã€‚
    and then we're going to do layers taught layerã€‚And we're going to do define in
    itã€‚Of just selfã€‚ we've gotta call super of my reelloã€‚Selfï¼Œ and then that in itã€‚And
    then for our actual callã€‚We're just going to return Tfã€‚ mathathã€‚ maximumã€‚Of x
    and0ã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå‡ ä¹æ˜¯ä¸€æ ·çš„ã€‚ä½†æˆ‘ä»¬å°†åšä¸€ä¸ªç±»Mireelloï¼Œç„¶åå®šä¹‰åˆå§‹åŒ–ï¼Œåªéœ€ä¼ å…¥selfã€‚æˆ‘ä»¬éœ€è¦è°ƒç”¨superçš„Mireelloï¼Œselfå’Œåˆå§‹åŒ–ã€‚ç„¶ååœ¨æˆ‘ä»¬çš„å®é™…è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¿”å›Tf.math.maximum(x,
    0)ã€‚
- en: this is just going to return the maximum of x or 0ï¼Œ which is exactly the the
    relativeï¼Œ rightã€‚ So at this pointï¼Œ you might be sayingï¼Œ wellï¼Œ how would we actually
    create this Tf math maximum functionã€‚You might be feeling that this is a way of
    cheating and so what I would say is that this would be even more low level and
    this is something you can try out and you could read the documentation and the
    source code for how they've actually implemented this function and so on but there
    will always be times where you can go even deeper and explore the details and
    so this is where I would draw the line and that we can use these mathematical
    operations on these tensors so when we have this myrelu we can do selfã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯è¿”å› x å’Œ 0 ä¸­çš„æœ€å¤§å€¼ï¼Œè¿™æ­£æ˜¯ç›¸å¯¹çš„ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œä½ å¯èƒ½ä¼šè¯´ï¼Œå—¯ï¼Œæˆ‘ä»¬åˆ°åº•å¦‚ä½•åˆ›å»ºè¿™ä¸ª Tf math maximum å‡½æ•°ã€‚ä½ å¯èƒ½è§‰å¾—è¿™æ˜¯ä¸€ç§ä½œå¼Šçš„æ–¹å¼ï¼Œæˆ‘æƒ³è¯´è¿™ç”šè‡³æ›´åº•å±‚ï¼Œè¿™æ˜¯ä½ å¯ä»¥å°è¯•çš„ï¼Œä½ å¯ä»¥é˜…è¯»æ–‡æ¡£å’Œæºä»£ç ï¼Œäº†è§£ä»–ä»¬æ˜¯å¦‚ä½•å®ç°è¿™ä¸ªå‡½æ•°çš„ç­‰ç­‰ï¼Œä½†æ€»ä¼šæœ‰æœºä¼šè®©ä½ æ·±å…¥æ¢ç´¢ç»†èŠ‚ã€‚å› æ­¤ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œåˆ’å®šç•Œé™ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™äº›å¼ é‡ä¸Šä½¿ç”¨è¿™äº›æ•°å­¦è¿ç®—ï¼Œå½“æˆ‘ä»¬æœ‰è¿™ä¸ª
    myrelu æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åš selfã€‚
- en: tre is my Relu so we got to instantiate the class although if you use a function
    this wouldn't be the case what we got to do then is we got to replace this Tf
    and then do relu and then we're going to do selftrelu on top of thatã€‚So we can
    run this first of allã€‚So now you've seen how to build these models by yourself
    with Kaa subclassing and then also how to actually build these layers like dense
    layers and re functions so these are pretty simple ones but you can imagine building
    more complex ones as well and I also suggest you to try that out Alright so that's
    it for this video thank you so much for watching and I hope to see you in the
    next oneã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: tre æ˜¯æˆ‘çš„ Reluï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»å®ä¾‹åŒ–è¿™ä¸ªç±»ï¼Œè™½ç„¶å¦‚æœä½ ä½¿ç”¨ä¸€ä¸ªå‡½æ•°ï¼Œè¿™å°±ä¸æ˜¯è¿™ç§æƒ…å†µã€‚é‚£ä¹ˆæˆ‘ä»¬è¦åšçš„æ˜¯æ›¿æ¢è¿™ä¸ª Tfï¼Œç„¶ååš reluï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šåš
    selftreluã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å…ˆè¿è¡Œè¿™ä¸ªã€‚å› æ­¤ï¼Œä½ ç°åœ¨å·²ç»çœ‹åˆ°å¦‚ä½•é€šè¿‡ Kaa å­ç±»åŒ–è‡ªå·±æ„å»ºè¿™äº›æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•å®é™…æ„å»ºè¿™äº›å±‚ï¼Œæ¯”å¦‚ç¨ å¯†å±‚å’Œ re å‡½æ•°ã€‚è¿™äº›éƒ½æ˜¯ç›¸å½“ç®€å•çš„ï¼Œä½†ä½ å¯ä»¥æƒ³è±¡æ„å»ºæ›´å¤æ‚çš„å±‚ã€‚æˆ‘ä¹Ÿå»ºè®®ä½ å°è¯•ä¸€ä¸‹ã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯æœ¬è§†é¢‘çš„å…¨éƒ¨å†…å®¹ï¼Œéå¸¸æ„Ÿè°¢ä½ çš„è§‚çœ‹ï¼Œå¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘è§åˆ°ä½ ã€‚
- en: '![](img/2b96deb5c7669b397136afafb6aca66a_4.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b96deb5c7669b397136afafb6aca66a_4.png)'
