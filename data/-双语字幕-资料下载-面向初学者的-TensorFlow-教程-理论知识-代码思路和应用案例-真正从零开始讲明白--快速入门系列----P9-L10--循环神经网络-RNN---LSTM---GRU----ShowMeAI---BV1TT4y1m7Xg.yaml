- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P9ï¼šL10-
    å¾ªç¯ç¥ç»ç½‘ç»œ(RNN & LSTM & GRU) - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„TensorFlowæ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P9ï¼šL10- å¾ªç¯ç¥ç»ç½‘ç»œ(RNN
    & LSTM & GRU) - ShowMeAI - BV1TT4y1m7Xg
- en: Heyï¼Œ guysï¼Œ welcomee to another Tensorflow tutorialã€‚ Todayã€‚ we'll be learning
    about recurrent neural nets or short R and Nsã€‚ Rn Ns are a class of neural networks
    that allow previous outputs to be used as inputs while having hidden statesã€‚ So
    this means that we are working with a sequence hereã€‚ And this is super powerfulã€‚
    And with thisã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°å¦ä¸€ä¸ªTensorFlowæ•™ç¨‹ã€‚ä»Šå¤©æˆ‘ä»¬å°†å­¦ä¹ å¾ªç¯ç¥ç»ç½‘ç»œï¼Œç®€ç§°RNNã€‚RNNæ˜¯ä¸€ç±»ç¥ç»ç½‘ç»œï¼Œå…è®¸å°†ä»¥å‰çš„è¾“å‡ºç”¨ä½œè¾“å…¥ï¼ŒåŒæ—¶å…·æœ‰éšè—çŠ¶æ€ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†çš„æ˜¯ä¸€ä¸ªåºåˆ—ã€‚è¿™æ˜¯éå¸¸å¼ºå¤§çš„ã€‚å€Ÿæ­¤ã€‚
- en: we can use R and Ns for many different applications like text generation text
    translationã€‚ sentiment classification and many moreã€‚ So I already have a in depth
    tutorial about Rn Nsã€‚ where I explain these slides here in more detailã€‚ So if
    you want to learn a little bit more about the theoryã€‚ Then check out at least
    the first five minutes of this videoã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†RNNç”¨äºè®¸å¤šä¸åŒçš„åº”ç”¨ï¼Œæ¯”å¦‚æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†ç±»ç­‰ç­‰ã€‚æˆ‘å·²ç»æœ‰ä¸€ä¸ªæ·±å…¥çš„RNNæ•™ç¨‹ï¼Œåœ¨é‚£é‡Œæˆ‘æ›´è¯¦ç»†åœ°è§£é‡Šäº†è¿™äº›å¹»ç¯ç‰‡ã€‚å¦‚æœä½ æƒ³å¤šäº†è§£ä¸€ç‚¹ç†è®ºï¼Œé‚£å°±çœ‹çœ‹è¿™ä¸ªè§†é¢‘çš„å‰äº”åˆ†é’Ÿã€‚
- en: because now I want to focus on the implementation with Tensorflowã€‚ So let's
    jump directly to the codeã€‚ğŸ˜Šï¼ŒğŸ¼ã€‚![](img/19e2da4a4c0b9bf65583ec48e044da69_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ç°åœ¨æƒ³ä¸“æ³¨äºTensorFlowçš„å®ç°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç›´æ¥è¿›å…¥ä»£ç ã€‚ğŸ˜Šï¼ŒğŸ¼ã€‚![](img/19e2da4a4c0b9bf65583ec48e044da69_1.png)
- en: So here I already have some codeï¼Œ and this is the exact same code as in tutorial
    number3ã€‚ where used the Ms data setï¼Œ and then we defined a simple neural nets
    and then we defined a loss and a optimizer and compile our model and then we train
    it and evaluate itã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘å·²ç»æœ‰ä¸€äº›ä»£ç ï¼Œè¿™ä¸æ•™ç¨‹ç¬¬3éƒ¨åˆ†ä¸­çš„ä»£ç å®Œå…¨ç›¸åŒï¼Œä½¿ç”¨äº†Msæ•°æ®é›†ï¼Œç„¶åæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œæ¥ç€å®šä¹‰äº†ä¸€ä¸ªæŸå¤±å‡½æ•°å’Œä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œç¼–è¯‘äº†æ¨¡å‹ï¼Œç„¶åè®­ç»ƒå’Œè¯„ä¼°å®ƒã€‚
- en: So we did digit classification with this data setã€‚ and now the only thing we
    want to change here is to change the model and now use an R andN modelã€‚ So this
    is not the typical application for an RNã€‚ A lot of times it's used when we deal
    with text classification or text generationã€‚ but this example should demonstrate
    that RnNs can indeed be used for an image classification taskã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†è¿›è¡Œäº†æ•°å­—åˆ†ç±»ï¼Œç°åœ¨æˆ‘ä»¬å”¯ä¸€æƒ³è¦æ”¹å˜çš„æ˜¯æ¨¡å‹ï¼Œæ”¹ç”¨RNNæ¨¡å‹ã€‚è¿™ä¸æ˜¯RNNçš„å…¸å‹åº”ç”¨ã€‚å¾ˆå¤šæ—¶å€™å®ƒç”¨äºæ–‡æœ¬åˆ†ç±»æˆ–æ–‡æœ¬ç”Ÿæˆï¼Œä½†è¿™ä¸ªä¾‹å­åº”è¯¥æ¼”ç¤ºRNNç¡®å®å¯ä»¥ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
- en: and you will see how easily we can create our R andN model with the Kaas APIã€‚
    So as I said when we deal with R andNs then we deal with a sequence hereã€‚And in
    our caseã€‚ we have imagesï¼Œ but we don't have to change our data setã€‚ We simply
    have to treat our images as a sequence nowã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†çœ‹åˆ°æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨Keras APIè½»æ¾åˆ›å»ºæˆ‘ä»¬çš„RNNæ¨¡å‹ã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œå½“æˆ‘ä»¬å¤„ç†RNNæ—¶ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†çš„æ˜¯ä¸€ä¸ªåºåˆ—ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬æœ‰å›¾åƒï¼Œä½†æˆ‘ä»¬ä¸éœ€è¦æ›´æ”¹æ•°æ®é›†ã€‚æˆ‘ä»¬åªéœ€å°†å›¾åƒè§†ä¸ºä¸€ä¸ªåºåˆ—ã€‚
- en: So right now our images have to shape 28 by 28ï¼Œ so 28 times 28 pixelsã€‚ and now
    we treat it as a sequenceã€‚ So this means that we say one times step is one row
    in our imageã€‚ And then we also have 28 columnsã€‚ So this means that our input size
    is 28 and our sequence length is also 28ã€‚So againï¼Œ this means we have 28 time
    stepss in our sequence and in each time stepã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„å›¾åƒå¿…é¡»æ˜¯28ä¹˜28ï¼Œæ‰€ä»¥æ˜¯28ä¹˜28ä¸ªåƒç´ ã€‚ç°åœ¨æˆ‘ä»¬å°†å…¶è§†ä¸ºä¸€ä¸ªåºåˆ—ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬è¯´ä¸€ä¸ªæ—¶é—´æ­¥æ˜¯å›¾åƒä¸­çš„ä¸€è¡Œã€‚ç„¶åæˆ‘ä»¬è¿˜æœ‰28åˆ—ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„è¾“å…¥å¤§å°æ˜¯28ï¼Œåºåˆ—é•¿åº¦ä¹Ÿæ˜¯28ã€‚å› æ­¤ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„åºåˆ—ä¸­æœ‰28ä¸ªæ—¶é—´æ­¥ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¸­ã€‚
- en: we have 28 featuresã€‚ And now when we treat it like thisã€‚ and we can simply use
    an R and N now So now let's go ahead and define our modelã€‚ So first let's define
    a empty sequence modelã€‚ and the first thing I want to do is to add a inputã€‚ So
    I say model dot at and then careas and then inputã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰28ä¸ªç‰¹å¾ã€‚ç°åœ¨å½“æˆ‘ä»¬è¿™æ ·å¤„ç†æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ä½¿ç”¨ä¸€ä¸ªRNNã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç©ºçš„åºåˆ—æ¨¡å‹ã€‚æˆ‘è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯æ·»åŠ ä¸€ä¸ªè¾“å…¥ã€‚å› æ­¤æˆ‘è¯´model.addï¼Œç„¶åæ˜¯kerasï¼Œç„¶åæ˜¯inputã€‚
- en: and then here specify the shape and this is 28 by 28ã€‚ So againã€‚ the first the
    first number here is the sequence length and the second number here is the input
    sizeã€‚ and now we can add the R and N modelã€‚ So there are different ones available
    and we start withã€‚The simple R and N layerã€‚ So later I also show you two other
    famous onesã€‚ So for nowã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡ŒæŒ‡å®šå½¢çŠ¶ï¼Œå³28ä¹˜28ã€‚æ‰€ä»¥è¿™é‡Œçš„ç¬¬ä¸€ä¸ªæ•°å­—æ˜¯åºåˆ—é•¿åº¦ï¼Œç¬¬äºŒä¸ªæ•°å­—æ˜¯è¾“å…¥å¤§å°ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥æ·»åŠ RNNæ¨¡å‹ã€‚æœ‰ä¸åŒçš„å¯ç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬ä»ç®€å•çš„RNNå±‚å¼€å§‹ã€‚ç¨åæˆ‘è¿˜ä¼šå±•ç¤ºå¦å¤–ä¸¤ä¸ªè‘—åçš„æ¨¡å‹ã€‚æ‰€ä»¥ç°åœ¨ã€‚
- en: let's say model dot atã€‚ And then we can get this in Caras dot layersã€‚ So we
    already imported this here and then we can say layers dotã€‚ and now we want a simple
    R and N modelã€‚ And now the only thing we have to specify is the number of unitsã€‚
    So the number of output unitsã€‚And this is also the size of the hidden cellã€‚So
    there areï¼Œ of courseã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾model.atã€‚ç„¶åæˆ‘ä»¬å¯ä»¥åœ¨keras.layersä¸­è·å–è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬å·²ç»åœ¨è¿™é‡Œå¯¼å…¥äº†è¿™ä¸ªï¼Œç„¶åæˆ‘ä»¬å¯ä»¥è¯´layers.ã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦ä¸€ä¸ªç®€å•çš„Rå’ŒNæ¨¡å‹ã€‚æˆ‘ä»¬å”¯ä¸€éœ€è¦æŒ‡å®šçš„æ˜¯å•ä½çš„æ•°é‡ã€‚ä¹Ÿå°±æ˜¯è¾“å‡ºå•å…ƒçš„æ•°é‡ã€‚è¿™ä¹Ÿæ˜¯éšè—å•å…ƒçš„å¤§å°ã€‚æ‰€ä»¥å½“ç„¶æœ‰å¾ˆå¤šã€‚
- en: a lot of more parametersã€‚ So I recommend that you check out the documentation
    for yourselvesã€‚ So one thing that you should notice that by defaultã€‚ the activation
    function in an R and N is the ton H functionã€‚ So let's in our caseã€‚ let's try
    out the relu functionã€‚And now this is all that we need for the R and N modelã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šçš„å‚æ•°ã€‚å› æ­¤æˆ‘å»ºè®®ä½ è‡ªå·±æŸ¥çœ‹æ–‡æ¡£ã€‚æœ‰ä¸€ç‚¹ä½ åº”è¯¥æ³¨æ„ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒRå’ŒNä¸­çš„æ¿€æ´»å‡½æ•°æ˜¯tanhå‡½æ•°ã€‚é‚£ä¹ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œè¯•è¯•reluå‡½æ•°ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„å…¨éƒ¨å†…å®¹ï¼Œç”¨äºRå’ŒNæ¨¡å‹ã€‚
- en: So now we have thatã€‚ And nowï¼Œ as we want to do classificationsã€‚ we have 10 different
    classes in the M this data setã€‚ So then we alsoï¼Œ like in the other tutorialã€‚ we
    add a dense layer at the endã€‚ So we say layers dotã€‚Denseï¼Œ and then we want 10
    outputsã€‚ And this is all we needã€‚ So we don't use an activation function here
    at the endã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªã€‚ç°åœ¨ï¼Œæ—¢ç„¶æˆ‘ä»¬è¦è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬åœ¨è¿™ä¸ªæ•°æ®é›†ä¸­æœ‰10ä¸ªä¸åŒçš„ç±»åˆ«ã€‚é‚£ä¹ˆåƒåœ¨å…¶ä»–æ•™ç¨‹ä¸­ä¸€æ ·ï¼Œæˆ‘ä»¬åœ¨æœ€åæ·»åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚å› æ­¤æˆ‘ä»¬è¯´layers.Denseï¼Œç„¶åæˆ‘ä»¬æƒ³è¦10ä¸ªè¾“å‡ºã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„å…¨éƒ¨ã€‚æ‰€ä»¥åœ¨æœ€åæˆ‘ä»¬ä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°ã€‚
- en: But then we must be carefulï¼Œ and we must specify from logict equals true in
    our loss functionã€‚And now this is all that we need for nowã€‚ So this is the whole
    sequential model that we need for a simple R and Nã€‚ So firstï¼Œ let's import cis
    and say cis dot exit so that it runs only until hereã€‚ So let's run the code until
    here and print the summaryã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬å¿…é¡»å°å¿ƒï¼Œå¿…é¡»åœ¨æˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸­æŒ‡å®šä»logitç­‰äºtrueã€‚è€Œç°åœ¨è¿™å°±æ˜¯æˆ‘ä»¬ç›®å‰æ‰€éœ€çš„å…¨éƒ¨ã€‚è¿™æ˜¯æˆ‘ä»¬éœ€è¦çš„ç®€å•Rå’ŒNçš„æ•´ä¸ªé¡ºåºæ¨¡å‹ã€‚æ‰€ä»¥é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥cisï¼Œå¹¶è¯´cis.exitï¼Œè¿™æ ·å®ƒåªä¼šè¿è¡Œåˆ°è¿™é‡Œã€‚è®©æˆ‘ä»¬è¿è¡Œåˆ°è¿™é‡Œçš„ä»£ç å¹¶æ‰“å°æ‘˜è¦ã€‚
- en: So let's say Python and then the name of this fileã€‚ So this oneã€‚Ohã€‚ and here
    I missed the equal signï¼Œ of courseã€‚ So shape equals 28 by 28ã€‚ So againï¼Œ let's
    writeã€‚ And then here we see our simple R and N has this output shapeã€‚ And I explain
    this in a secondã€‚ And then we have the dense layer with 10 outputsã€‚So let's have
    another look at the R and Nsã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´Pythonï¼Œç„¶åæ˜¯è¿™ä¸ªæ–‡ä»¶çš„åç§°ã€‚æ‰€ä»¥è¿™ä¸ªã€‚å“¦ï¼Œè¿™é‡Œæˆ‘æ¼æ‰äº†ç­‰å·ï¼Œå½“ç„¶äº†ã€‚æ‰€ä»¥shapeç­‰äº28ä¹˜28ã€‚é‚£ä¹ˆæˆ‘ä»¬å†å†™ä¸€æ¬¡ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„ç®€å•Rå’ŒNæœ‰è¿™ä¸ªè¾“å‡ºå½¢çŠ¶ã€‚æˆ‘ç¨åä¼šè§£é‡Šè¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬æœ‰ä¸€ä¸ªå…·æœ‰10ä¸ªè¾“å‡ºçš„å…¨è¿æ¥å±‚ã€‚è®©æˆ‘ä»¬å†çœ‹çœ‹Rå’ŒNã€‚
- en: So the output shape is nã€‚ So the number of samples that we haveã€‚ and then 128ã€‚
    like we specified hereã€‚ And what this includes is this is a single vector for
    each sampleã€‚ And the output that we get is the output of the only of theã€‚Last
    cellï¼Œ the last time stepã€‚ But this includes all the information about the previous
    time stepã€‚ So this is all that we needã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¾“å‡ºçš„å½¢çŠ¶æ˜¯nã€‚è¿™æ˜¯æˆ‘ä»¬æ‹¥æœ‰çš„æ ·æœ¬æ•°é‡ã€‚ç„¶åæ˜¯128ï¼Œå°±åƒæˆ‘ä»¬åœ¨è¿™é‡ŒæŒ‡å®šçš„é‚£æ ·ã€‚å®ƒåŒ…å«çš„æ˜¯æ¯ä¸ªæ ·æœ¬çš„ä¸€ä¸ªå•ä¸€å‘é‡ã€‚æˆ‘ä»¬å¾—åˆ°çš„è¾“å‡ºæ˜¯æœ€åä¸€ä¸ªå•å…ƒï¼Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºã€‚ä½†è¿™åŒ…æ‹¬äº†å…³äºå‰ä¸€ä¸ªæ—¶é—´æ­¥çš„æ‰€æœ‰ä¿¡æ¯ã€‚æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬æ‰€éœ€è¦çš„å…¨éƒ¨ã€‚
- en: So we only need this last cell hereã€‚ So this is why our output is in this shapeã€‚
    But you can also get an output of the shapeï¼Œ the number of batches times the number
    of sequencesã€‚ the number of time steps or the sequence lengthã€‚ And then the number
    of unitsã€‚ And we get this when we specify and there's an additional parameterã€‚
    and this is called returnã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦è¿™é‡Œçš„æœ€åä¸€ä¸ªå•å…ƒã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬çš„è¾“å‡ºæ˜¯è¿™ä¸ªå½¢çŠ¶ã€‚ä½†ä½ ä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªå½¢çŠ¶ä¸ºæ‰¹æ¬¡æ•°é‡ä¹˜ä»¥åºåˆ—æ•°é‡ã€æ—¶é—´æ­¥æ•°é‡æˆ–åºåˆ—é•¿åº¦çš„è¾“å‡ºã€‚ç„¶åæ˜¯å•ä½æ•°é‡ã€‚å½“æˆ‘ä»¬æŒ‡å®šä¸€ä¸ªé¢å¤–çš„å‚æ•°æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°è¿™ä¸ªï¼Œç§°ä¸ºreturnã€‚
- en: Return sequences equals trueã€‚ So if we use this by defaultï¼Œ it's falseã€‚ And
    if we use thisã€‚ then our output is in this shapeã€‚ And this isï¼Œ for exampleã€‚ useful
    when we want to stack multiple R and Ns togetherã€‚ Soï¼Œ for exampleï¼Œ we can use
    the first oneã€‚ which will return all the time stepsã€‚ And then we use a second
    one where we say this isã€‚Fallsã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: return sequencesç­‰äºtrueã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªï¼Œé»˜è®¤æƒ…å†µä¸‹æ˜¯falseã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„è¾“å‡ºå°±æ˜¯è¿™ä¸ªå½¢çŠ¶ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬æƒ³å°†å¤šä¸ªRå’ŒNå †å åœ¨ä¸€èµ·æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¬¬ä¸€ä¸ªï¼Œå®ƒå°†è¿”å›æ‰€æœ‰æ—¶é—´æ­¥ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨ç¬¬äºŒä¸ªï¼Œæˆ‘ä»¬è¯´è¿™æ˜¯falseã€‚
- en: And then here we get this output shapeã€‚ So againï¼Œ let's have a look if that's
    correctã€‚ So let's clear this and run this againã€‚And yeahï¼Œ what I told you was
    correctã€‚ So the first R and N has this output shape because we said return sequences
    equals trueã€‚ And the other one has only this output shapeã€‚ And then againï¼Œ we
    have our dense layerã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¾—åˆ°äº†è¿™ä¸ªè¾“å‡ºå½¢çŠ¶ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å†æ¬¡æ£€æŸ¥ä¸€ä¸‹è¿™æ˜¯å¦æ­£ç¡®ã€‚æ¸…é™¤è¿™ä¸ªå¹¶å†æ¬¡è¿è¡Œã€‚æ²¡é”™ï¼Œæˆ‘å‘Šè¯‰ä½ çš„ç¡®æ˜¯æ­£ç¡®çš„ã€‚ç¬¬ä¸€ä¸ª R å’Œ N æœ‰è¿™ä¸ªè¾“å‡ºå½¢çŠ¶ï¼Œå› ä¸ºæˆ‘ä»¬è®¾ç½®äº†è¿”å›åºåˆ—ä¸ºçœŸã€‚å¦ä¸€ä¸ªåˆ™åªæœ‰è¿™ä¸ªè¾“å‡ºå½¢çŠ¶ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆæœ‰äº†æˆ‘ä»¬çš„å…¨è¿æ¥å±‚ã€‚
- en: So this might improve the performance of your modelã€‚ So againã€‚ you can play
    around with stacking of multiple R and Nsã€‚ So let's for nowï¼Œ let's just use oneã€‚
    and then let's remove thisã€‚ and then train it and see if it performs well for
    this classification taskã€‚ So againï¼Œ let's clear this and run thisã€‚Alrightï¼Œ so
    we see that our accuracy at the end is 97%ã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½ä¼šæé«˜ä½ çš„æ¨¡å‹æ€§èƒ½ã€‚æ‰€ä»¥å†æ¬¡ï¼Œä½ å¯ä»¥å°è¯•å †å å¤šä¸ª R å’Œ Nã€‚ç›®å‰ï¼Œæˆ‘ä»¬å°±ä½¿ç”¨ä¸€ä¸ªï¼Œç„¶åå»æ‰è¿™ä¸ªï¼Œè®­ç»ƒå®ƒï¼Œçœ‹çœ‹å®ƒåœ¨è¿™ä¸ªåˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°å¦‚ä½•ã€‚å†æ¬¡æ¸…é™¤å¹¶è¿è¡Œã€‚å¥½çš„ï¼Œæˆ‘ä»¬çœ‹åˆ°æœ€åçš„å‡†ç¡®ç‡æ˜¯
    97%ã€‚
- en: So our RnN indeed works well here for this image classification taskã€‚ And now
    you know how you can set up your R andN with this simple R andN layer and you
    should know how you can treat your input as a sequenceã€‚ And now I also want to
    show you two other famous RnNsã€‚ So this is only the simple RnN layerã€‚ but there's
    alsoï¼Œ for exampleï¼Œ the LSTM or the G R Uã€‚ So both are two popular RnNs as wellã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤æˆ‘ä»¬çš„ RnN ç¡®å®åœ¨è¿™ä¸ªå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚ç°åœ¨ä½ çŸ¥é“å¦‚ä½•ä½¿ç”¨è¿™ä¸ªç®€å•çš„ RnN å±‚æ¥è®¾ç½®ä½ çš„ R å’Œ Nï¼Œå¹¶ä¸”ä½ åº”è¯¥çŸ¥é“å¦‚ä½•å°†è¾“å…¥è§†ä¸ºåºåˆ—ã€‚æˆ‘è¿˜æƒ³ç»™ä½ å±•ç¤ºå¦å¤–ä¸¤ä¸ªè‘—åçš„
    RnNã€‚è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„ RnN å±‚ï¼Œä½†è¿˜æœ‰ï¼Œæ¯”å¦‚ LSTM æˆ– GRUã€‚è¿™ä¸¤ä¸ªä¹Ÿæ˜¯å¾ˆå—æ¬¢è¿çš„ RnNã€‚
- en: they both typically perform a little bit better than the simple RnN and I think
    you don't have to change anything elseã€‚ So the parameters are mostly the same
    and also the structure of the outputs is the sameã€‚ So yeah playã€‚Around with this
    as well and try out the GRU or the LSTMã€‚And yeahã€‚ I think that's it for nowã€‚ And
    in the next tutorialã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬çš„è¡¨ç°é€šå¸¸æ¯”ç®€å•çš„ RnN ç•¥å¥½ï¼Œæˆ‘è®¤ä¸ºä½ ä¸éœ€è¦æ›´æ”¹å…¶ä»–ä»»ä½•å†…å®¹ã€‚æ‰€ä»¥å‚æ•°å¤§å¤šæ•°æ˜¯ç›¸åŒçš„ï¼Œè¾“å‡ºçš„ç»“æ„ä¹Ÿæ˜¯ç›¸åŒçš„ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œä¹Ÿå¯ä»¥å°è¯• GRU æˆ– LSTMã€‚å¥½çš„ï¼Œæˆ‘æƒ³ç°åœ¨å°±åˆ°è¿™é‡Œã€‚åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­å†è§ã€‚
- en: we learn how we apply this for a text classification taskã€‚ So I hope to see
    you in the next video thenã€‚ And if you enjoyed this tutorialã€‚ please hit the like
    button and consider subscribing to the channel and see you next time byeã€‚ğŸ˜Šã€‚![](img/19e2da4a4c0b9bf65583ec48e044da69_3.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å­¦ä¹ å¦‚ä½•å°†å…¶åº”ç”¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œè¯·ç‚¹å‡»å–œæ¬¢æŒ‰é’®å¹¶è€ƒè™‘è®¢é˜…é¢‘é“ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§ï¼Œæ‹œæ‹œã€‚ğŸ˜Šã€‚![](img/19e2da4a4c0b9bf65583ec48e044da69_3.png)
