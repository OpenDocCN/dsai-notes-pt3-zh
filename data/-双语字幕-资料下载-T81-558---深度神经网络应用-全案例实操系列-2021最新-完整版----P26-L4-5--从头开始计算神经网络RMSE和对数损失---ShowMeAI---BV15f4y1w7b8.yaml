- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P26ï¼šL4.5- ä»å¤´å¼€å§‹è®¡ç®—ç¥ç»ç½‘ç»œRMSEå’Œå¯¹æ•°æŸå¤±
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P26ï¼šL4.5- ä»å¤´å¼€å§‹è®¡ç®—ç¥ç»ç½‘ç»œRMSEå’Œå¯¹æ•°æŸå¤±
    - ShowMeAI - BV15f4y1w7b8
- en: Hi this is Jeff Heatonï¼Œ welcome to App of Deep neural Networks with Washington
    Universityã€‚In this videoï¼Œ we're going to see how to calculate some of the error
    metrics by hand so that you can literally see how these numeric values actually
    come aboutã€‚ We'll look in particularï¼Œ at log loss and root mean square error for
    the latest on my AI course and projectsã€‚ Click subscribe in the bell next to it
    to be notified of every new videoã€‚ Nowã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•æ‰‹åŠ¨è®¡ç®—ä¸€äº›é”™è¯¯æŒ‡æ ‡ï¼Œè¿™æ ·ä½ å°±å¯ä»¥çœŸæ­£çœ‹åˆ°è¿™äº›æ•°å€¼æ˜¯å¦‚ä½•äº§ç”Ÿçš„ã€‚æˆ‘ä»¬å°†ç‰¹åˆ«å…³æ³¨å¯¹æ•°æŸå¤±å’Œå‡æ–¹æ ¹è¯¯å·®ï¼Œå…³äºæˆ‘æœ€æ–°çš„äººå·¥æ™ºèƒ½è¯¾ç¨‹å’Œé¡¹ç›®ï¼Œè¯·ç‚¹å‡»è®¢é˜…æ—è¾¹çš„é“ƒé“›ï¼Œä»¥ä¾¿æ”¶åˆ°æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚ç°åœ¨ã€‚
- en: we'll see how to calculate R S E and log lossã€‚ completely from scratchã€‚ We'll
    start with regressionã€‚ğŸ˜Šã€‚![](img/17f6495026b126d073de254c1e55eb13_1.png)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä»å¤´å¼€å§‹è®¡ç®—å‡æ–¹æ ¹è¯¯å·®å’Œå¯¹æ•°æŸå¤±ã€‚æˆ‘ä»¬å°†ä»å›å½’å¼€å§‹ã€‚ğŸ˜Šã€‚![](img/17f6495026b126d073de254c1e55eb13_1.png)
- en: You can see the code hereï¼Œ the code near the top is demonstrating how you would
    calculate mean square error and then root mean square error using the built in
    functions normally this is how you want to do and this is what we saw earlier
    howeverã€‚ if you want to see how to actually calculate thisï¼ŒYou can see that we
    get the exact same resultsã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ä»£ç ï¼Œé¡¶éƒ¨çš„ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨å†…ç½®å‡½æ•°è®¡ç®—å‡æ–¹è¯¯å·®å’Œå‡æ–¹æ ¹è¯¯å·®ã€‚é€šå¸¸è¿™å°±æ˜¯ä½ æƒ³è¦çš„ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ã€‚ç„¶è€Œï¼Œå¦‚æœä½ æƒ³çœ‹çœ‹å¦‚ä½•å®é™…è®¡ç®—è¿™ä¸ªï¼Œä½ ä¼šå‘ç°æˆ‘ä»¬å¾—åˆ°äº†å®Œå…¨ç›¸åŒçš„ç»“æœã€‚
- en: we're basically taking a sum of squaresã€‚Here you can see the predicted minus
    the expectedã€‚ and we sum those the squaresï¼Œ and then finally we divide that by
    the length of the predictedã€‚ so it's kind of like an average where the squares
    are being used to negate the signs for one thingã€‚ and it's also it can be easier
    to take the derivative of those square terms than the absolute values for training
    purposesã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯åœ¨è®¡ç®—å¹³æ–¹å’Œã€‚è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°é¢„æµ‹å€¼å‡å»æœŸæœ›å€¼ã€‚æˆ‘ä»¬å°†è¿™äº›å¹³æ–¹ç›¸åŠ ï¼Œæœ€åå°†å…¶é™¤ä»¥é¢„æµ‹å€¼çš„é•¿åº¦ã€‚æ‰€ä»¥è¿™æœ‰ç‚¹åƒå¹³å‡å€¼ï¼Œå¹³æ–¹ç”¨äºæ¶ˆé™¤ç¬¦å·ã€‚æ­¤å¤–ï¼Œå¯¹äºè®­ç»ƒç›®çš„ï¼Œå¹³æ–¹é¡¹çš„å¯¼æ•°æ¯”ç»å¯¹å€¼æ›´å®¹æ˜“å¤„ç†ã€‚
- en: For classificationï¼Œ we're doing a similar sort of thingã€‚Except we're using the
    log lossã€‚ You can see at the top how you have the expected and the predicted and
    how you can literally calculate eachã€‚ each piece of the of the log loss and sum
    of them togetherã€‚ getting the exact same value as you would have gotten from the
    built in functionã€‚ Nowã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ï¼Œæˆ‘ä»¬æ­£åœ¨åšç±»ä¼¼çš„äº‹æƒ…ã€‚åªæ˜¯æˆ‘ä»¬ä½¿ç”¨å¯¹æ•°æŸå¤±ã€‚ä½ å¯ä»¥åœ¨é¡¶éƒ¨çœ‹åˆ°é¢„æœŸå€¼å’Œé¢„æµ‹å€¼ï¼Œä»¥åŠä½ å¦‚ä½•é€ä¸ªè®¡ç®—æ¯ä¸ªå¯¹æ•°æŸå¤±çš„éƒ¨åˆ†ï¼Œå¹¶å°†å®ƒä»¬ç›¸åŠ ï¼Œå¾—åˆ°ä¸ä½ ä»å†…ç½®å‡½æ•°è·å¾—çš„å®Œå…¨ç›¸åŒçš„å€¼ã€‚ç°åœ¨ã€‚
- en: we'll see how to work through all of theseã€‚ Nowï¼Œ let's go through and calculate
    both of those by handã€‚We're going to start with log lossã€‚Here's the equation for
    itã€‚ Okayã€‚ this equation might look somewhat complicatedï¼Œ but there's actually
    several parts to itã€‚ and let me kind of take this piece by piece and show you
    really what is going on thereã€‚First of allã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å¤„ç†è¿™äº›å†…å®¹ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ‰‹åŠ¨è®¡ç®—è¿™ä¸¤ä¸ªå€¼ã€‚æˆ‘ä»¬å°†ä»å¯¹æ•°æŸå¤±å¼€å§‹ã€‚è¿™é‡Œæ˜¯å®ƒçš„å…¬å¼ã€‚å¥½çš„ï¼Œè¿™ä¸ªå…¬å¼çœ‹èµ·æ¥å¯èƒ½æœ‰äº›å¤æ‚ï¼Œä½†å®é™…ä¸Šæœ‰å‡ ä¸ªéƒ¨åˆ†ï¼Œè®©æˆ‘åˆ†å¼€è®²è§£ä¸€ä¸‹ï¼Œç»™ä½ å±•ç¤ºä¸€ä¸‹åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆã€‚é¦–å…ˆã€‚
- en: let's look at the graph of what a logarith actually looks like because that
    helps to explain some of thisã€‚So for the log rhythmï¼Œ there's a couple of very
    important points log of zero isã€‚Essentially undefined or asymptote to negative
    infinityã€‚ log of1 is 0 of is as you plot the logarithmã€‚It crosses here at 0ã€‚ Nowã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å¯¹æ•°çš„å›¾å½¢ï¼Œå› ä¸ºè¿™æœ‰åŠ©äºè§£é‡Šä¸€äº›å†…å®¹ã€‚å› æ­¤ï¼Œå¯¹äºå¯¹æ•°ï¼Œæœ‰å‡ ä¸ªéå¸¸é‡è¦çš„ç‚¹ï¼Œå¯¹æ•°é›¶æ˜¯æœ¬è´¨ä¸Šæœªå®šä¹‰æˆ–æ¸è¿‘äºè´Ÿæ— ç©·ã€‚å¯¹æ•°1æ˜¯0ï¼Œå½“ä½ ç»˜åˆ¶å¯¹æ•°æ—¶ï¼Œå®ƒåœ¨è¿™é‡Œä¸0ç›¸äº¤ã€‚ç°åœ¨ã€‚
- en: I am really bad at drawing equationsï¼Œ but you'll get the general ideaã€‚ bit of
    infinity kind of asymptotically thereã€‚And thenï¼Œ it grows really relativelyã€‚Small
    as itã€‚ as it continues in that directionã€‚Logarï¼Œ I in my studiesã€‚ it's come up
    really twice where we care about what it actually looks likeã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çœŸçš„å¾ˆç³Ÿç³•äºç»˜åˆ¶æ–¹ç¨‹ï¼Œä½†ä½ ä¼šæ˜ç™½å¤§è‡´çš„æƒ³æ³•ã€‚æœ‰ä¸€ç‚¹æ— ç©·å¤§ï¼Œåœ¨é‚£é‡Œæ¸è¿‘ã€‚ç„¶åï¼Œå®ƒç›¸å¯¹è¾ƒå°åœ°å¢é•¿ã€‚Logarï¼Œåœ¨æˆ‘çš„ç ”ç©¶ä¸­ï¼Œè¿™å®é™…ä¸Šå‡ºç°äº†ä¸¤æ¬¡ï¼Œæˆ‘ä»¬å…³å¿ƒå®ƒå®é™…çš„æ ·å­ã€‚
- en: It comes up a lot more than thatã€‚ but just in the areas that I particularly
    dealt withã€‚ if you're dealing with computer scienceã€‚It is this region that is
    particularly interestingã€‚ because when you're doing algorithm analysisï¼Œ orderï¼Œ
    order N type stuffï¼Œ a logarithmicã€‚Scale is actually pretty goodã€‚ It's not really
    increasing all that fast compared to something like exponentialã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ¯”é‚£å¤šå¾—å¤šï¼Œä½†å°±æˆ‘ç‰¹åˆ«å¤„ç†çš„é¢†åŸŸè€Œè¨€ã€‚å¦‚æœä½ å¤„ç†è®¡ç®—æœºç§‘å­¦ï¼Œè¿™ä¸ªåŒºåŸŸç‰¹åˆ«æœ‰è¶£ã€‚å› ä¸ºå½“ä½ è¿›è¡Œç®—æ³•åˆ†ææ—¶ï¼ŒNé˜¶çš„ä¸œè¥¿ï¼Œå¯¹æ•°è§„æ¨¡å®é™…ä¸Šæ˜¯ç›¸å½“ä¸é”™çš„ã€‚ä¸æŒ‡æ•°çº§å¢é•¿ç›¸æ¯”ï¼Œå®ƒå¹¶æ²¡æœ‰çœŸçš„é‚£ä¹ˆå¿«å¢é•¿ã€‚
- en: which is just going to go up veryï¼Œ veryï¼Œ very fastã€‚But that's that part of the
    of the logar graph is not what we're interested here in the realm of data science
    or machine learningã€‚ Data science and machine learning is more interested in this
    segment of itã€‚That is where we use to analyze errorã€‚So this is the data science
    regionã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¼šéå¸¸éå¸¸éå¸¸å¿«åœ°ä¸Šå‡ã€‚ä½†å¯¹äºæ•°æ®ç§‘å­¦æˆ–æœºå™¨å­¦ä¹ é¢†åŸŸè€Œè¨€ï¼Œæ—¥å¿—å›¾çš„è¿™ä¸€éƒ¨åˆ†å¹¶ä¸æ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„ã€‚æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ æ›´å…³æ³¨çš„æ˜¯å®ƒçš„è¿™ä¸€æ®µã€‚è¿™æ˜¯æˆ‘ä»¬ç”¨æ¥åˆ†æé”™è¯¯çš„åœ°æ–¹ã€‚æ‰€ä»¥è¿™æ˜¯æ•°æ®ç§‘å­¦åŒºåŸŸã€‚
- en: It's probably not strictly mathematically correctiveï¼Œ computer science and data
    scienceã€‚ I'm sure the two cross over into these other two realmsã€‚ but this is
    just a good way to think of this in a very simplified viewã€‚So in data scienceã€‚Or
    in this machine learning log loss function that we're calculating this regionã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨æ•°å­¦ä¸Šå¯èƒ½ä¸æ˜¯ä¸¥æ ¼çš„ï¼Œè®¡ç®—æœºç§‘å­¦å’Œæ•°æ®ç§‘å­¦ã€‚æˆ‘ç¡®ä¿¡è¿™ä¸¤ä¸ªé¢†åŸŸä¼šäº¤å‰åˆ°å¦å¤–ä¸¤ä¸ªé¢†åŸŸï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç®€åŒ–æ€ç»´æ–¹å¼ã€‚æ‰€ä»¥åœ¨æ•°æ®ç§‘å­¦ä¸­ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬è®¡ç®—çš„è¿™ä¸ªæœºå™¨å­¦ä¹ å¯¹æ•°æŸå¤±å‡½æ•°çš„åŒºåŸŸã€‚
- en: if you think of one is beingã€‚Is being completely correctï¼Œ or you've guessed
    it correctã€‚ So you're trying to classify somethingã€‚ It was trueã€‚ You've chosen
    trueã€‚ That means that the error that is contributed toï¼Œ to your to your error
    equation is going to be 0ã€‚ which is goodã€‚You guessed it completely correctã€‚What
    you don't want to be is confidently incorrectã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è®¤ä¸º1æ˜¯å®Œå…¨æ­£ç¡®çš„ï¼Œæˆ–è€…ä½ çŒœå¯¹äº†ã€‚æ‰€ä»¥ä½ åœ¨å°è¯•åˆ†ç±»æŸäº›ä¸œè¥¿ã€‚å¦‚æœå®ƒæ˜¯çœŸçš„ï¼Œä½ é€‰æ‹©äº†çœŸçš„ã€‚è¿™æ„å‘³ç€è´¡çŒ®ç»™ä½ çš„é”™è¯¯æ–¹ç¨‹çš„é”™è¯¯å°†æ˜¯0ï¼Œè¿™æ˜¯å¥½çš„ã€‚ä½ å®Œå…¨çŒœå¯¹äº†ã€‚ä½ ä¸å¸Œæœ›è‡ªä¿¡åœ°é”™è¯¯ã€‚
- en: So in these machine learning algorithmsï¼Œ if you want to say trueã€‚ you don't
    just usually say true or falseã€‚ you will sayï¼Œ I think with 0ã€‚9% probabilityï¼Œ it
    is trueã€‚Don't you wish you could have done that back on true false questions in
    in school if youreã€‚ if you're just really not sure you could put 0ã€‚5 probabilityã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™äº›æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œå¦‚æœä½ æƒ³è¯´â€œçœŸâ€ï¼Œä½ é€šå¸¸ä¸ä¼šåªæ˜¯è¯´â€œçœŸâ€æˆ–â€œå‡â€ã€‚ä½ ä¼šè¯´ï¼Œæˆ‘è®¤ä¸ºå®ƒæœ‰0.9%çš„æ¦‚ç‡æ˜¯çœŸçš„ã€‚ä½ ä¸å¸Œæœ›åœ¨å­¦æ ¡çš„çœŸå‡é¢˜ä¸Šä¹Ÿèƒ½è¿™æ ·ï¼Œå¦‚æœä½ ä¸å¤ªç¡®å®šï¼Œå¯ä»¥è¯´0.5çš„æ¦‚ç‡ã€‚
- en: meaning I don't know it could be true it could be falseã€‚ You'd mostly lose half
    a pointã€‚Wellã€‚ or you could do 0ã€‚75 probabilityã€‚ You would get you'd get three
    quarters of your point if you're correctã€‚ but only lose ã€‚25 if you were notã€‚ So
    that'sï¼Œ that's how these are evaluatedã€‚ What you don't want to beï¼Œ is confidently
    incorrectã€‚ So if you say it's true with 100% probabilityã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ„æ€æ˜¯æˆ‘ä¸çŸ¥é“ï¼Œå®ƒå¯èƒ½æ˜¯çœŸçš„ï¼Œä¹Ÿå¯èƒ½æ˜¯å‡çš„ã€‚ä½ é€šå¸¸ä¼šæŸå¤±åŠåˆ†ã€‚é‚£ä¹ˆï¼Œæˆ–è€…ä½ å¯ä»¥è¯´0.75çš„æ¦‚ç‡ã€‚å¦‚æœä½ ç­”å¯¹äº†ï¼Œä½ ä¼šå¾—åˆ°ä¸‰åˆ†ä¹‹å››çš„åˆ†æ•°ï¼Œä½†å¦‚æœä¸å¯¹ï¼ŒåªæŸå¤±0.25åˆ†ã€‚æ‰€ä»¥ï¼Œè¿™å°±æ˜¯å®ƒä»¬çš„è¯„ä¼°æ–¹å¼ã€‚ä½ ä¸å¸Œæœ›çš„æ˜¯è‡ªä¿¡åœ°é”™è¯¯ã€‚å› æ­¤å¦‚æœä½ è¯´å®ƒçš„æ¦‚ç‡æ˜¯100%æ˜¯çœŸçš„ã€‚
- en: And then it's falseã€‚ then you're down here at a infinitely bad scoreã€‚ I'm glad
    school isn't like thatã€‚ You can't get an infinitely bad scoreã€‚ You can just get
    a 0ã€‚ Butã€‚Here you can be so bad that it's infinitely badï¼Œ that's why usually when
    you look at these sort of predictionsã€‚ you'll very rarely see predictions at zero
    or1ï¼Œ they're going to be very close to it because they want the optimizer algorithms
    will usually clamp it at thatã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¦‚æœå®ƒæ˜¯å‡çš„ï¼Œé‚£ä½ å°±åœ¨ä¸€ä¸ªæ— é™ç³Ÿç³•çš„åˆ†æ•°ä¸Šã€‚æˆ‘å¾ˆé«˜å…´å­¦æ ¡ä¸æ˜¯è¿™æ ·çš„ã€‚ä½ ä¸èƒ½å¾—åˆ°æ— é™ç³Ÿç³•çš„åˆ†æ•°ã€‚ä½ åªèƒ½å¾—åˆ°0åˆ†ã€‚ä½†æ˜¯ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥ç³Ÿç³•åˆ°æ— é™ç³Ÿç³•ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆé€šå¸¸å½“ä½ æŸ¥çœ‹è¿™äº›é¢„æµ‹æ—¶ï¼Œä½ å¾ˆå°‘ä¼šçœ‹åˆ°0æˆ–1çš„é¢„æµ‹ï¼Œå®ƒä»¬ä¼šéå¸¸æ¥è¿‘ï¼Œå› ä¸ºä¼˜åŒ–ç®—æ³•é€šå¸¸ä¼šå°†å…¶é™åˆ¶åœ¨é‚£ä¸ªèŒƒå›´ã€‚
- en: So notice twoï¼Œ for that regionï¼Œ for the data science part of itï¼Œ everything
    is negativeã€‚You could talk about negative errorsã€‚ You could say I have a negative
    025 log loss or something like thatã€‚ But just to get itï¼Œ we're used to errors
    being reported as positiveã€‚ So that's why you have this negative up frontã€‚ That
    essentially just shifts it entirely to theã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ³¨æ„ï¼Œå¯¹äºæ•°æ®ç§‘å­¦çš„é‚£ä¸ªåŒºåŸŸï¼Œä¸€åˆ‡éƒ½æ˜¯è´Ÿæ•°ã€‚ä½ å¯ä»¥è°ˆè®ºè´Ÿé”™è¯¯ã€‚ä½ å¯ä»¥è¯´æˆ‘æœ‰è´Ÿ0.025çš„å¯¹æ•°æŸå¤±æˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚ä½†ä¸ºäº†ç†è§£ï¼Œæˆ‘ä»¬ä¹ æƒ¯äºå°†é”™è¯¯æŠ¥å‘Šä¸ºæ­£æ•°ã€‚æ‰€ä»¥è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå‰é¢æœ‰è¿™ä¸ªè´Ÿå·ã€‚è¿™æœ¬è´¨ä¸Šå°†å…¶å®Œå…¨è½¬ç§»åˆ°ã€‚
- en: To the positive rangeï¼Œ that's all that negative is accomplishing thereã€‚The one
    over nã€‚That part of it is essentiallyï¼Œ that's the averageã€‚So n is the number of
    elements in your training setã€‚ You don't want to have extremely large error for
    extremely large training setsã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ­£èŒƒå›´ï¼Œé‚£å°±æ˜¯æ‰€æœ‰è´Ÿå€¼æ‰€è¾¾åˆ°çš„æ•ˆæœã€‚è¿™ä¸ªä¸€é™¤ä»¥ nã€‚é‚£éƒ¨åˆ†åŸºæœ¬ä¸Šå°±æ˜¯å¹³å‡å€¼ã€‚æ‰€ä»¥ n æ˜¯ä½ è®­ç»ƒé›†ä¸­çš„å…ƒç´ æ•°é‡ã€‚ä½ ä¸å¸Œæœ›åœ¨éå¸¸å¤§çš„è®­ç»ƒé›†ä¸­å‡ºç°æå¤§çš„é”™è¯¯ã€‚
- en: you need you want to normalize that just like the percent on your exam paperã€‚That's
    why you divide it by the numberï¼Œ the number of questionsã€‚ If you just deal in
    pointsã€‚ if you sayï¼Œ heyï¼Œ I scored 30 points on my examã€‚ Wellï¼Œ if it's out of 30ï¼Œ
    that's pretty goodã€‚ If it's out of 3000ï¼Œ that's really badã€‚ So that is that is
    what the negative and the one over n isã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦åƒè€ƒè¯•çº¸ä¸Šçš„ç™¾åˆ†æ¯”ä¸€æ ·å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ è¦é™¤ä»¥é—®é¢˜çš„æ•°é‡ã€‚å¦‚æœä½ åªå¤„ç†åˆ†æ•°ã€‚å¦‚æœä½ è¯´ï¼Œæˆ‘åœ¨è€ƒè¯•ä¸­å¾—äº† 30 åˆ†ã€‚å¥½å§ï¼Œå¦‚æœæ»¡åˆ†æ˜¯ 30ï¼Œé‚£æŒºå¥½çš„ã€‚å¦‚æœæ»¡åˆ†æ˜¯
    3000ï¼Œé‚£å°±çœŸçš„å¾ˆç³Ÿç³•ã€‚æ‰€ä»¥è¿™å°±æ˜¯è´Ÿå€¼å’Œä¸€é™¤ä»¥ n çš„å«ä¹‰ã€‚
- en: is accomplishingã€‚ Then we need to sumit sum all of thoseï¼Œ all of those log loss
    errorsã€‚ And that is going toï¼Œ that is basically going toã€‚Give you the summation
    of all your log lossesã€‚And then you divide them by nã€‚All of your log lossesï¼Œ zeroã€‚
    ones near zero are not particularly bad you are close and either true or falseã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åœ¨å®Œæˆã€‚ç„¶åæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰è¿™äº›æ—¥å¿—æŸå¤±é”™è¯¯è¿›è¡Œæ±‡æ€»ã€‚è¿™å°†ç»™ä½ æ‰€æœ‰æ—¥å¿—æŸå¤±çš„æ€»å’Œã€‚ç„¶åä½ å°†å®ƒä»¬é™¤ä»¥ nã€‚æ‰€æœ‰çš„æ—¥å¿—æŸå¤±ï¼Œé›¶ã€‚æ¥è¿‘é›¶çš„å€¼å¹¶ä¸æ˜¯ç‰¹åˆ«ç³Ÿç³•ï¼Œä½ æ˜¯æ¥è¿‘çœŸå®æˆ–è™šå‡çš„ã€‚
- en: Or the higher ones you areã€‚You were largely incorrectã€‚ You try to preventã€‚You
    usually clamp this so that you don't have Y hat valuesï¼Œ Y hatï¼Œ by the wayï¼Œ are
    your predictionsã€‚So the two y hats that you see here and hereï¼Œ those are your
    predictionsã€‚Why is the truthã€‚ That is the value you're comparing it againstã€‚ And
    we have the subscript eye on each of these just so that we can calculateã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ä½ æ‰€å¤„çš„æ›´é«˜å€¼ã€‚ä½ åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯é”™è¯¯çš„ã€‚ä½ å°è¯•é˜²æ­¢è¿™ç§æƒ…å†µã€‚ä½ é€šå¸¸ä¼šé™åˆ¶è¿™ä¸ªï¼Œä»¥ä¾¿ä½ ä¸ä¼šæœ‰ Y hat å€¼ï¼Œé¡ºä¾¿è¯´ä¸€ä¸‹ï¼ŒY hat æ˜¯ä½ çš„é¢„æµ‹ã€‚ä½ åœ¨è¿™é‡Œçœ‹åˆ°çš„ä¸¤ä¸ª
    y hatsï¼Œå°±æ˜¯ä½ çš„é¢„æµ‹ã€‚ä¸ºä»€ä¹ˆæ˜¯çœŸå®çš„ã€‚é‚£æ˜¯ä½ æ¯”è¾ƒçš„å€¼ã€‚æˆ‘ä»¬åœ¨æ¯ä¸€ä¸ªå€¼ä¸Šéƒ½æœ‰ä¸‹æ ‡ iï¼Œä»¥ä¾¿è¿›è¡Œè®¡ç®—ã€‚
- en: Or just because that's the individual number or the individual training set
    element and your predictionã€‚The first part of itï¼Œ which is right hereã€‚That's dealing
    with true casesã€‚And then the other part of it is dealing with false casesã€‚So you're
    classifyingï¼Œ is it true or falseï¼Ÿ
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…åªæ˜¯å› ä¸ºé‚£æ˜¯å•ä¸ªç¼–å·æˆ–å•ä¸ªè®­ç»ƒé›†å…ƒç´ ä»¥åŠä½ çš„é¢„æµ‹ã€‚å®ƒçš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå°±åœ¨è¿™é‡Œã€‚è¿™éƒ¨åˆ†å¤„ç†çœŸå®æƒ…å†µã€‚ç„¶åå¦ä¸€éƒ¨åˆ†å¤„ç†è™šå‡æƒ…å†µã€‚æ‰€ä»¥ä½ åœ¨åˆ†ç±»ï¼Œæ˜¯å¯¹è¿˜æ˜¯é”™ï¼Ÿ
- en: The way that these are controlled is sort of a mathematical if statementã€‚ Mathematicians
    like to use coefficientsï¼Œ often for if statementsã€‚And the two F statements that
    you are dealing with are basically hereã€‚Andã€‚And thereã€‚If y sub Iã€‚ that is the
    absolute truthï¼Œ that is the value from the training set that you're comparing
    againstã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è¢«æ§åˆ¶çš„æ–¹å¼æœ‰ç‚¹åƒæ•°å­¦ä¸­çš„ if è¯­å¥ã€‚æ•°å­¦å®¶å–œæ¬¢ä½¿ç”¨ç³»æ•°ï¼Œé€šå¸¸ç”¨äº if è¯­å¥ã€‚è€Œä½ æ‰€å¤„ç†çš„ä¸¤ä¸ª F è¯­å¥åŸºæœ¬ä¸Šåœ¨è¿™é‡Œã€‚è¿˜æœ‰é‚£é‡Œã€‚å¦‚æœ y sub
    Iã€‚è¿™æ˜¯ç»å¯¹çœŸå®çš„ï¼Œæ˜¯ä½ æ¯”è¾ƒçš„è®­ç»ƒé›†ä¸­çš„å€¼ã€‚
- en: If it's trueï¼Œ then this is going to be oneã€‚ The green y sub I is going to be
    oneã€‚ If it's falseã€‚ then it's going to be 0ã€‚ So thisï¼Œ the first coefficientï¼Œ the
    green arrow is going to be oneã€‚ In all cases where we are dealing with true valuesã€‚
    and the red arrow is going to be false in all cases where we're dealing with false
    valuesã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ˜¯çœŸçš„ï¼Œé‚£ä¹ˆè¿™å°†æ˜¯ 1ã€‚ç»¿è‰²çš„ y sub I å°†æ˜¯ 1ã€‚å¦‚æœæ˜¯å‡çš„ï¼Œé‚£ä¹ˆå®ƒå°†æ˜¯ 0ã€‚æ‰€ä»¥åœ¨å¤„ç†çœŸå®å€¼çš„æ‰€æœ‰æƒ…å†µä¸‹ï¼Œç¬¬ä¸€ä¸ªç³»æ•°ï¼Œç»¿è‰²ç®­å¤´å°†æ˜¯ 1ã€‚è€Œåœ¨å¤„ç†è™šå‡å€¼çš„æ‰€æœ‰æƒ…å†µä¸‹ï¼Œçº¢è‰²ç®­å¤´å°†æ˜¯
    0ã€‚
- en: Because of the1 minusã€‚ So that essentially turns off these two sidesã€‚ So one
    of those two sides is going to cancel out each timeã€‚ depending on if it's true
    or if it's falseã€‚So if this really is trueã€‚ then sub1 y sub i is going to be oneã€‚So
    it won't cancel outã€‚ and then the log ideallyã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸º 1 å‡å»ã€‚æ‰€ä»¥è¿™æœ¬è´¨ä¸Šå…³é—­äº†è¿™ä¸¤ä¾§ã€‚æ‰€ä»¥å…¶ä¸­ä¸€ä¾§æ¯æ¬¡éƒ½ä¼šæŠµæ¶ˆï¼Œå…·ä½“å–å†³äºå®ƒæ˜¯çœŸè¿˜æ˜¯å‡ã€‚æ‰€ä»¥å¦‚æœè¿™ç¡®å®æ˜¯çœŸçš„ã€‚åˆ™ sub1 y sub i å°†æ˜¯ 1ã€‚è¿™æ ·å°±ä¸ä¼šæŠµæ¶ˆï¼Œç„¶åç†æƒ³çš„æ—¥å¿—ã€‚
- en: if the real answer is trueï¼Œ you would like why hat to also be true or oneã€‚ if
    that is the case and you nail this right on the noseï¼Œ then log of one0ã€‚ so that
    term will then cancel outã€‚But that's good because you hadã€‚ you had a perfectly
    correct answerã€‚ And it nowï¼Œ you don't want any error to be contributedã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœçœŸå®ç­”æ¡ˆæ˜¯çœŸçš„ï¼Œä½ å¸Œæœ› y hat ä¹Ÿæ˜¯çœŸçš„æˆ–è€…æ˜¯ 1ã€‚å¦‚æœæƒ…å†µæ˜¯è¿™æ ·ï¼Œä½ æ­£å¥½æŠ“ä½è¿™ä¸€ç‚¹ï¼Œé‚£ä¹ˆ log çš„ä¸€å°†ä¼šæŠµæ¶ˆã€‚ä½†è¿™å¾ˆå¥½ï¼Œå› ä¸ºä½ å¾—åˆ°äº†ä¸€ä¸ªå®Œå…¨æ­£ç¡®çš„ç­”æ¡ˆã€‚è€Œä¸”ç°åœ¨ï¼Œä½ ä¸å¸Œæœ›æœ‰ä»»ä½•é”™è¯¯è¢«è´¡çŒ®ã€‚
- en: If you had guess ã€‚9ï¼Œ then the log ã€‚9 will be added to yourï¼Œ to your errorã€‚ But
    that's not so bad because you're stillã€‚Basicallyï¼Œ the closer you get to zeroã€‚
    the worse your score is going to beã€‚Look at the at theã€‚At the curve on the Cartesian
    plane that I have drawnã€‚ Nowï¼Œ on the other side of the coinã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çŒœçš„æ˜¯0.9ï¼Œé‚£ä¹ˆlog 0.9å°†è¢«åŠ åˆ°ä½ çš„é”™è¯¯ä¸­ã€‚ä½†è¿™å¹¶ä¸ç®—å¤ªç³Ÿï¼Œå› ä¸ºä½ ä»ç„¶åŸºæœ¬ä¸Šè¶Šæ¥è¿‘é›¶ï¼Œå¾—åˆ†å°±ä¼šè¶Šç³Ÿã€‚çœ‹çœ‹æˆ‘åœ¨ç›´è§’åæ ‡å¹³é¢ä¸Šç»˜åˆ¶çš„æ›²çº¿ã€‚ç°åœ¨ï¼Œä»å¦ä¸€ä¸ªè§’åº¦æ¥çœ‹ã€‚
- en: if it's falseï¼Œ So if the correct answer y sub I is is is false or 0ï¼Œ then that
    firstã€‚ the true term is going to cancel outã€‚And then the false is going to be
    oneã€‚ So it's going to have a coefficient of 1ï¼Œ1-0 is 1 multiplied by the log of
    1ã€‚1 minus y sub Iã€‚ We're basically now doing that in reverseã€‚So doing that in
    reverseã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ˜¯é”™è¯¯çš„ï¼Œæ‰€ä»¥å¦‚æœæ­£ç¡®ç­”æ¡ˆyä¸‹æ ‡iæ˜¯é”™è¯¯çš„æˆ–0ï¼Œé‚£ä¹ˆç¬¬ä¸€ä¸ªçœŸå€¼é¡¹å°†è¢«æŠµæ¶ˆã€‚ç„¶åå‡å€¼å°†å˜ä¸º1ã€‚æ‰€ä»¥å®ƒå°†å…·æœ‰ç³»æ•°1ï¼Œ1-0æ˜¯1ï¼Œä¹˜ä»¥1çš„å¯¹æ•°ã€‚1å‡å»yä¸‹æ ‡iã€‚æˆ‘ä»¬ç°åœ¨åŸºæœ¬ä¸Šåœ¨åå‘æ‰§è¡Œè¿™ä¸ªæ“ä½œã€‚
- en: we are now basically going to deal withã€‚If you had a one now in this caseã€‚ So
    it was falseã€‚ but you guessed trueï¼Œ you're now infinitely wrong because 1-1 is
    0ã€‚ and that takes you toã€‚ to infinity on the on the logã€‚ Nowï¼Œ if you had guessed
    close like 0ã€‚1ï¼Œ Wellï¼Œ1-0ã€‚1 is ã€‚9ã€‚ and that's not quite as badã€‚ you're kind of
    in the same in the same location that I just describedã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨åŸºæœ¬ä¸Šè¦å¤„ç†çš„æƒ…å†µæ˜¯ã€‚å¦‚æœåœ¨è¿™ç§æƒ…å†µä¸‹ä½ çŒœçš„æ˜¯1ã€‚å®ƒæ˜¯é”™è¯¯çš„ï¼Œä½†ä½ çŒœçš„æ˜¯å¯¹çš„ï¼Œä½ ç°åœ¨æ˜¯æ— é™é”™è¯¯ï¼Œå› ä¸º1-1æ˜¯0ã€‚è¿™å°†ä½¿ä½ è¿›å…¥å¯¹æ•°çš„æ— ç©·å¤§ã€‚ç°åœ¨ï¼Œå¦‚æœä½ çŒœå¾—æ¯”è¾ƒæ¥è¿‘ï¼Œæ¯”å¦‚0.1ï¼Œé‚£ä¹ˆ1-0.1æ˜¯0.9ã€‚è¿™å¹¶ä¸ç®—å¤ªç³Ÿï¼Œä½ å¤§è‡´åœ¨æˆ‘åˆšæ‰æè¿°çš„ç›¸åŒä½ç½®ã€‚
- en: So you're closer up that closer to 0 on that log calculationã€‚Now when you actually
    implement thisã€‚This approach has a couple of errors when I mean issues when you're
    dealing with this in computer science or implementing this as a program for oneã€‚Your
    depending on how smart yourï¼Œ your programming language is to cancel out things
    that are 0ã€‚ You're potentially calculating the log rather twiceã€‚ You really don't
    need toã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ åœ¨å¯¹æ•°è®¡ç®—ä¸Šæ›´æ¥è¿‘äº0ã€‚ç°åœ¨ï¼Œå½“ä½ å®é™…å®ç°è¿™ä¸ªæ–¹æ³•æ—¶ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤„ç†è®¡ç®—æœºç§‘å­¦æˆ–å°†å…¶ä½œä¸ºç¨‹åºå®ç°æ—¶ä¼šæœ‰å‡ ä¸ªé—®é¢˜ã€‚ä¸€æ–¹é¢ï¼Œä½ ä¾èµ–äºä½ çš„ç¼–ç¨‹è¯­è¨€å¦‚ä½•èªæ˜ï¼Œä»¥ä¾¿æ¶ˆé™¤é›¶çš„ä¸œè¥¿ã€‚ä½ å¯èƒ½ä¼šè®¡ç®—å¯¹æ•°ä¸¤æ¬¡ã€‚ä½ å…¶å®ä¸éœ€è¦è¿™æ ·åšã€‚
- en: because it's going to cancel outã€‚ The other issue that I have been burned by
    at least a couple of times is that if either of these sides go to negative infinityã€‚You're
    now effectively multiplyingï¼Œ even thoughã€‚You even though you would like that to
    cancel out in most programming languagesã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå®ƒä¼šæŠµæ¶ˆã€‚æˆ‘è‡³å°‘è¢«è¿™ä¸ªé—®é¢˜çƒ§è¿‡å‡ æ¬¡ï¼Œå¦‚æœè¿™ä¸¤ä¾§ä¸­çš„ä»»ä½•ä¸€ä¾§å˜ä¸ºè´Ÿæ— ç©·ã€‚ä½ å®é™…ä¸Šæ˜¯åœ¨ä¹˜ä»¥ï¼Œå³ä½¿ä½ å¸Œæœ›åœ¨å¤§å¤šæ•°ç¼–ç¨‹è¯­è¨€ä¸­æŠµæ¶ˆå®ƒã€‚
- en: zero times infinity is in factï¼Œ zero or is in factï¼Œ infinityã€‚Mathematicallyã€‚
    you can make the case that it is0 if you useï¼Œ I believe it's Haital's ruleã€‚ looking
    at basically the rates at which get of infinity on one side or the otherã€‚ you
    multiply it by the good halfã€‚ And even though you may have answered this completely
    correctlyã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶ä¹˜ä»¥æ— ç©·å®é™…ä¸Šæ˜¯é›¶ï¼Œæˆ–è€…å®é™…ä¸Šæ˜¯æ— ç©·ã€‚ä»æ•°å­¦ä¸Šè®²ï¼Œå¦‚æœä½ ä½¿ç”¨æˆ‘ç›¸ä¿¡æ˜¯æµ·å¡”å°”æ³•åˆ™ï¼Œä½ å¯ä»¥è®¤ä¸ºå®ƒæ˜¯0ï¼ŒåŸºæœ¬ä¸Šæ˜¯åœ¨ä¸€ä¾§æˆ–å¦ä¸€ä¾§è§‚å¯Ÿæ— ç©·çš„é€Ÿç‡ã€‚ä½ ä¹˜ä»¥å¥½çš„éƒ¨åˆ†ã€‚å³ä½¿ä½ å¯èƒ½å®Œå…¨æ­£ç¡®åœ°å›ç­”äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: and it shouldn't cause the equation to blow upï¼Œ it does cause the equation to
    blow up because you've got infinity on one side or the other of a multiplicationã€‚
    and the whole thing then goes to infinityã€‚Or NAï¼Œ depending on the implementationã€‚So
    now let's look at how we will actually calculate thisã€‚ So the way that I'll show
    you to calculate itï¼Œ we're not going to actuallyã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸åº”è¯¥å¯¼è‡´æ–¹ç¨‹å´©æºƒï¼Œä½†ç¡®å®ä¼šå¯¼è‡´æ–¹ç¨‹å´©æºƒï¼Œå› ä¸ºä½ åœ¨ä¹˜æ³•çš„ä¸€ä¾§æˆ–å¦ä¸€ä¾§æœ‰æ— ç©·å¤§ã€‚ç„¶åæ•´ä¸ªç»“æœä¼šå˜æˆæ— ç©·å¤§ï¼Œæˆ–è€…å–å†³äºå®ç°å¯èƒ½æ˜¯NAã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å°†å¦‚ä½•å®é™…è®¡ç®—å®ƒã€‚æ‰€ä»¥æˆ‘å°†å‘ä½ å±•ç¤ºçš„è®¡ç®—æ–¹å¼ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šã€‚
- en: we're going to do it more like the computer would do itã€‚ We're not going to
    literally take the log two logs for every single line on thisã€‚ So let's go ahead
    and look at a couple of casesã€‚ We're going to look at the cases just like we hadã€‚In
    the code that I showed you earlierï¼Œ so that's how I know my math is correctã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ›´åƒè®¡ç®—æœºé‚£æ ·åšã€‚æˆ‘ä»¬ä¸ä¼šé€è¡Œå–ä¸¤ä¸ªå¯¹æ•°ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹å‡ ä¸ªæ¡ˆä¾‹ã€‚æˆ‘ä»¬å°†æŸ¥çœ‹çš„æƒ…å†µå°±åƒæˆ‘ä¹‹å‰å±•ç¤ºçš„ä»£ç ï¼Œæ‰€ä»¥æˆ‘çŸ¥é“æˆ‘çš„æ•°å­¦æ˜¯æ­£ç¡®çš„ã€‚
- en: I'm largely regurgitating what I already did in Pythonã€‚So we're going to have
    the data set where we're going to have whyã€‚And then why hatï¼Ÿ
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¤§è‡´æ˜¯åœ¨é‡å¤æˆ‘åœ¨Pythonä¸­åšçš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬å°†æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬å°†æœ‰yã€‚ç„¶åæ˜¯yçš„å¸½å­ã€‚
- en: So this is the why is the correct answerï¼Œ why hat is what we predictedï¼Ÿ
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç­”æ¡ˆæ­£ç¡®ï¼Œä¸ºä»€ä¹ˆé¢„æµ‹æ˜¯è¿™æ ·çš„ï¼Ÿ
- en: We're not really calculating the differencesã€‚Up in the top partï¼Œ thereã€‚ the
    only difference really is the the one minusesã€‚ but largelyï¼Œ that's what we're
    getting toã€‚ Essentiallyï¼Œ we areï¼Œ we are calculating theã€‚We're calculating how
    far offã€‚You are from and and adding the log of thatã€‚ So the difference is that
    I am calculating hereã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¹¶ä¸æ˜¯åœ¨çœŸæ­£è®¡ç®—å·®å¼‚ã€‚åœ¨é¡¶éƒ¨éƒ¨åˆ†ï¼Œå”¯ä¸€çš„å·®åˆ«å…¶å®å°±æ˜¯ä¸€ä¸ªè´Ÿå·ï¼Œä½†å¤§ä½“ä¸Šï¼Œè¿™å°±æ˜¯æˆ‘ä»¬è¦å¾—åˆ°çš„ã€‚å®è´¨ä¸Šï¼Œæˆ‘ä»¬æ˜¯åœ¨è®¡ç®—ä½ ä¸ç›®æ ‡ä¹‹é—´çš„åå·®ï¼Œå¹¶åŠ ä¸Šå…¶å¯¹æ•°ã€‚å› æ­¤ï¼Œæˆ‘åœ¨è¿™é‡Œè®¡ç®—çš„å·®å¼‚å°±æ˜¯è¿™ä¸ªã€‚
- en: By the wayï¼Œ this is the absolute value of the differenceï¼Œ not a square like
    we would do in R R Cã€‚ but just the absolute differencesã€‚ Now we need to take the
    logs of those mentionedã€‚ let's go ahead and sun theseï¼Œ and then we will divide
    those by nã€‚ the absolute value of thatã€‚ That isã€‚ That is the value that we had
    for in the Pythonã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: é¡ºä¾¿æä¸€ä¸‹ï¼Œè¿™æ˜¯å·®å¼‚çš„ç»å¯¹å€¼ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬åœ¨RRCä¸­ä¼šåšçš„å¹³æ–¹ï¼Œè€Œä»…ä»…æ˜¯ç»å¯¹å·®å¼‚ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦è®¡ç®—è¿™äº›å€¼çš„å¯¹æ•°ã€‚æˆ‘ä»¬å…ˆè¿›è¡Œæ±‚å’Œï¼Œç„¶åå†é™¤ä»¥nã€‚è¿™ä¸ªç»å¯¹å€¼å°±æ˜¯æˆ‘ä»¬åœ¨Pythonä¸­å¾—åˆ°çš„å€¼ã€‚
- en: So this is how you calculate the log loss just completely from handã€‚L R on a
    seaã€‚Pencil battery is lowã€‚ I need to hurryã€‚Everything needs to be recharged these
    daysï¼Œ even pencils onã€‚ you have the one over nã€‚ just like beforeã€‚ You don't need
    a negative because these these are inherently going to stay positiveã€‚ And it's
    a sum of squaresã€‚ You're essentially taking y hat minus Y for each of these doesn't
    really matter the order that those are even taken inã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯ä½ å¦‚ä½•å®Œå…¨æ‰‹åŠ¨è®¡ç®—å¯¹æ•°æŸå¤±ã€‚L Råœ¨ä¸€ä¸ªæµ·ä¸Šã€‚é“…ç¬”ç”µé‡ä½äº†ã€‚æˆ‘éœ€è¦èµ¶å¿«ã€‚è¿™äº›å¤©ä¸€åˆ‡éƒ½éœ€è¦å……ç”µï¼Œè¿é“…ç¬”ä¹Ÿæ˜¯ã€‚ä½ æœ‰ä¸€ä¸ª1/nï¼Œå’Œä¹‹å‰ä¸€æ ·ã€‚ä½ ä¸éœ€è¦è´Ÿå·ï¼Œå› ä¸ºè¿™äº›æ•°æœ¬è´¨ä¸Šä¼šä¿æŒæ­£å€¼ã€‚è¿™æ˜¯å¹³æ–¹å’Œã€‚ä½ åŸºæœ¬ä¸Šæ˜¯å¯¹æ¯ä¸€ä¸ªy
    hatå‡å»Yï¼Œé¡ºåºå¹¶ä¸é‡è¦ã€‚
- en: because you're going to square those differencesã€‚ But numbersã€‚ But these are
    the ones that I used in Pythonã€‚ And that lets me check my math to know that I'm
    actually doing these correctlyã€‚Now we take the differenceã€‚Go'ming to go ahead
    and square each of thoseã€‚And sum that going to divide them by nã€‚This value is
    actually called the sum of squared errorsã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºä½ ä¼šå¯¹è¿™äº›å·®å¼‚è¿›è¡Œå¹³æ–¹ã€‚ä½†è¿™äº›æ˜¯æˆ‘åœ¨Pythonä¸­ä½¿ç”¨çš„æ•°å€¼ã€‚è¿™è®©æˆ‘å¯ä»¥æ£€æŸ¥æˆ‘çš„æ•°å­¦è®¡ç®—ï¼Œä»¥ç¡®ä¿æˆ‘å®é™…ä¸Šæ˜¯æ­£ç¡®çš„ã€‚ç°åœ¨æˆ‘ä»¬è®¡ç®—å·®å¼‚ã€‚æ¥ä¸‹æ¥å¯¹æ¯ä¸ªå€¼è¿›è¡Œå¹³æ–¹ï¼Œå¹¶å¯¹å…¶æ±‚å’Œï¼Œæœ€åé™¤ä»¥nã€‚è¿™ä¸ªå€¼å®é™…ä¸Šè¢«ç§°ä¸ºå¹³æ–¹è¯¯å·®å’Œã€‚
- en: This numberï¼Œ if you'reï¼Œ if you're just writing an algorithm and you're trying
    to optimizeã€‚ meaning you're trying to push a number to zeroï¼Œ stop hereï¼Œ use this
    on squared errors becauseã€‚Doing the square root on top of it is just to get it
    into the same units as the training dataã€‚ If you're just optimizingï¼Œ just use
    some of squareï¼Œ that'sï¼Œ that's plenty goodã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ•°å­—ï¼Œå¦‚æœä½ åªæ˜¯ç¼–å†™ä¸€ä¸ªç®—æ³•å¹¶è¯•å›¾ä¼˜åŒ–ï¼Œä¹Ÿå°±æ˜¯è¯´ä½ è¯•å›¾å°†ä¸€ä¸ªæ•°å­—æ¨å‘é›¶ï¼Œåœåœ¨è¿™é‡Œï¼Œä½¿ç”¨å¹³æ–¹è¯¯å·®ï¼Œå› ä¸ºåœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå¹³æ–¹æ ¹åªæ˜¯ä¸ºäº†ä½¿å…¶ä¸è®­ç»ƒæ•°æ®å¤„äºç›¸åŒå•ä½ã€‚å¦‚æœä½ åªæ˜¯è¿›è¡Œä¼˜åŒ–ï¼Œä½¿ç”¨å¹³æ–¹å°±è¶³å¤Ÿäº†ã€‚
- en: But if you're trying to report this toã€‚To somebody to actually see how off you
    areã€‚ then you need to take the square root to get RNSCã€‚![](img/17f6495026b126d073de254c1e55eb13_3.png)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœä½ æƒ³å°†å…¶æŠ¥å‘Šç»™æŸäººï¼Œä»¥ä¾¿ä»–ä»¬å®é™…æŸ¥çœ‹ä½ çš„åå·®ï¼Œé‚£ä¹ˆä½ éœ€è¦è¿›è¡Œå¹³æ–¹æ ¹è¿ç®—æ¥å¾—åˆ°RNSCã€‚![](img/17f6495026b126d073de254c1e55eb13_3.png)
- en: So that is the Romen square errorã€‚ Thank you for watching this videoã€‚ In the
    next videoã€‚ we're going to begin to look at regularizationï¼Œ which is yet another
    way that you can combat overfitting for a neural networkã€‚ This content changes
    oftenã€‚ So subscribe to the channel to stay up to date on this course and other
    topics in artificial intelligenceã€‚ğŸ˜Šã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ç½—é—¨å¹³æ–¹è¯¯å·®ã€‚æ„Ÿè°¢ä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘ã€‚åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å¼€å§‹ç ”ç©¶æ­£åˆ™åŒ–ï¼Œè¿™åˆæ˜¯ä¸€ç§å¯ä»¥æŠµæŠ—ç¥ç»ç½‘ç»œè¿‡æ‹Ÿåˆçš„æ–¹æ³•ã€‚è¿™ä¸ªå†…å®¹ç»å¸¸ä¼šå˜åŒ–ï¼Œæ‰€ä»¥è¯·è®¢é˜…é¢‘é“ä»¥ä¿æŒå¯¹è¿™ä¸ªè¯¾ç¨‹å’Œå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜çš„æœ€æ–°äº†è§£ã€‚ğŸ˜Š
