- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P16ï¼šL16- è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ -
    ShowMeAI - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P16ï¼šL16- è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ -
    ShowMeAI - BV1em4y1U7ib
- en: What is going on guys hope you're doing freaking awesome in this video I'm going
    to show you how to do training loops from scratchã€‚![](img/38a145700a6404a2026fbca3d7269917_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œå¸Œæœ›ä½ ä»¬è¿‡å¾—éå¸¸æ£’ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä»é›¶å¼€å§‹å®ç°è®­ç»ƒå¾ªç¯ã€‚![](img/38a145700a6404a2026fbca3d7269917_1.png)
- en: '![](img/38a145700a6404a2026fbca3d7269917_2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_2.png)'
- en: So this means that we're no longer using modelã€‚fiï¼Œ but rather we're doing everything
    by ourselves from scratch if you're familiar with coding and Pythtorch then this
    is going to be more how you're used to training networks but anyways let's get
    started and we aren't going to do anything complicated in this video in terms
    of what we're going to train on and the data and so onã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æˆ‘ä»¬ä¸å†ä½¿ç”¨`model.fi`ï¼Œè€Œæ˜¯å®Œå…¨ä»å¤´å¼€å§‹è‡ªå·±åšã€‚å¦‚æœä½ å¯¹ç¼–ç å’ŒPythtorchç†Ÿæ‚‰ï¼Œé‚£ä¹ˆè¿™å°†æ›´ç¬¦åˆä½ è®­ç»ƒç½‘ç»œçš„ä¹ æƒ¯ã€‚ä¸è¿‡ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼Œåœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šåœ¨è®­ç»ƒå†…å®¹å’Œæ•°æ®ç­‰æ–¹é¢åšä»»ä½•å¤æ‚çš„äº‹æƒ…ã€‚
- en: the point is just to show you the general structure of how it looks likeã€‚So
    the starter code right here is just some basic imports that you've seen in previous
    videosã€‚ we're going to use Tensorflowlow data setsï¼Œ so if you haven't watched
    that video then it's going to be in the top right cornerã€‚So we're loading the
    Ms data set right here so we have a training and the test set and then we're just
    so we have a function for normalizedized images and all of this is from that video
    just copy pasted and then we have some very very simple model right hereã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: é‡ç‚¹æ˜¯å‘ä½ å±•ç¤ºå®ƒçš„æ•´ä½“ç»“æ„ã€‚è¿™é‡Œçš„å¯åŠ¨ä»£ç åªæ˜¯ä¸€äº›ä½ åœ¨ä¹‹å‰è§†é¢‘ä¸­è§è¿‡çš„åŸºæœ¬å¯¼å…¥ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`Tensorflowlow data sets`ï¼Œæ‰€ä»¥å¦‚æœä½ è¿˜æ²¡çœ‹è¿‡é‚£ä¸ªè§†é¢‘ï¼Œå¯ä»¥åœ¨å³ä¸Šè§’æ‰¾åˆ°ã€‚æˆ‘ä»¬åœ¨è¿™é‡ŒåŠ è½½`Ms
    data set`ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç„¶åæˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªç”¨äºæ ‡å‡†åŒ–å›¾åƒçš„å‡½æ•°ï¼Œè¿™äº›éƒ½æ˜¯ä»é‚£ä¸ªè§†é¢‘å¤åˆ¶ç²˜è´´è¿‡æ¥çš„ï¼Œç„¶åæˆ‘ä»¬è¿™é‡Œæœ‰ä¸€ä¸ªéå¸¸éå¸¸ç®€å•çš„æ¨¡å‹ã€‚
- en: just some one convolutional layer and then one dense layer and let's do layers
    that dense here just like that and then so then let's get started and what we're
    going to do is that first of all we're gonna have some metric so let's do accuracy
    metric is a ks do metrics dot ourã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€ä¸€ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œæ·»åŠ å…¨è¿æ¥å±‚ï¼Œå°±åƒè¿™æ ·ï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹äº†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›æŒ‡æ ‡ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬è®¾ç½®å‡†ç¡®ç‡æŒ‡æ ‡ï¼Œè¿™æ˜¯`ks
    do metrics dot our`ã€‚
- en: '![](img/38a145700a6404a2026fbca3d7269917_4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_4.png)'
- en: Categorical accuracyã€‚And then let's do firstï¼Œ let's do the training loopã€‚So
    the first thing we're going to do is we're going to train it for a number of epochsã€‚
    so we're going to train it for epochs is5 in this caseã€‚ So what we just do is
    we we write for epoch in range epochsã€‚Or maybe we should call itã€‚ğŸ˜”ï¼ŒNum epochã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»å‡†ç¡®ç‡ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å…ˆè¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†è®­ç»ƒè‹¥å¹²ä¸ªå‘¨æœŸã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†è®­ç»ƒ`epochs`ä¸º5ã€‚æˆ‘ä»¬åªéœ€å†™`for epoch in
    range epochs`ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥ç§°å®ƒä¸ºğŸ˜”ï¼Œ`Num epoch`ã€‚
- en: So nu epoch right thereã€‚ğŸ˜”ï¼ŒAnd then we could do printã€‚Justã€‚To printã€‚Slash n and
    then start of training epochã€‚And thenï¼Œ we could doã€‚I we can do it like this epochã€‚Now
    it's do F stringã€‚And so then we're going to iterate through all of the batches
    in our trainingã€‚ And so we're going to do for batch index and thenã€‚X batch comm
    a Y batch in enumerateã€‚AD trainã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å°±åœ¨è¿™é‡Œè¿›è¡Œ`nu epoch`ã€‚ğŸ˜” ç„¶åæˆ‘ä»¬å¯ä»¥æ‰“å°ã€‚åªéœ€æ‰“å°ã€‚æ¢è¡Œï¼Œç„¶åå¼€å§‹è®­ç»ƒå‘¨æœŸã€‚æ¥ç€ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼š`epoch`ã€‚ç°åœ¨æˆ‘ä»¬ä½¿ç”¨Få­—ç¬¦ä¸²ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†éå†è®­ç»ƒä¸­çš„æ‰€æœ‰æ‰¹æ¬¡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`for
    batch index`ç„¶å`X batch comm a Y batch in enumerate AD train`ã€‚
- en: Alrightï¼Œ so we're going to go through the strain for a number of epochsã€‚ So
    right here we're going to first of allï¼Œ write the width Tf gradient tapeã€‚As tapeã€‚
    And this is for recording all of the operations that we're going to do in the
    forward propagation so that we can then do back propagation for the the model
    weightsã€‚ So we're going to do Y prediction is modelã€‚X batchï¼Œ and then specify
    training is trueã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘ä»¬å°†è¿›è¡Œè‹¥å¹²ä¸ªå‘¨æœŸçš„è®­ç»ƒã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆå†™`with Tf gradient tape`ä½œä¸º`tape`ã€‚è¿™ç”¨äºè®°å½•æˆ‘ä»¬åœ¨å‰å‘ä¼ æ’­ä¸­è¦è¿›è¡Œçš„æ‰€æœ‰æ“ä½œï¼Œä»¥ä¾¿åç»­è¿›è¡Œæ¨¡å‹æƒé‡çš„åå‘ä¼ æ’­ã€‚æˆ‘ä»¬å°†è¿›è¡Œ`Y
    prediction is model.X batch`ï¼Œç„¶åæŒ‡å®š`training is true`ã€‚
- en: Then we're going to do loss is loss function right that we specified over hereã€‚And
    we're going to send in the y batchï¼Œ the true labelsï¼Œ and then the y predictionsã€‚
    the one we just calculated for from forward propagationã€‚All rightã€‚ so then we
    have those under that tapeï¼Œ then we can do gradients our equal tape dot gradientã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è®¡ç®—æŸå¤±ï¼Œä½¿ç”¨æˆ‘ä»¬åœ¨è¿™é‡ŒæŒ‡å®šçš„æŸå¤±å‡½æ•°ã€‚æˆ‘ä»¬å°†è¾“å…¥`y batch`ï¼ŒçœŸå®æ ‡ç­¾ï¼Œä»¥åŠ`y predictions`ï¼Œå°±æ˜¯æˆ‘ä»¬åˆšåˆšé€šè¿‡å‰å‘ä¼ æ’­è®¡ç®—å¾—åˆ°çš„ã€‚å¥½çš„ï¼Œè¿™æ ·æˆ‘ä»¬å°±æœ‰äº†é‚£äº›åœ¨`tape`ä¸‹çš„å†…å®¹ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥è®¡ç®—æ¢¯åº¦`our
    equal tape dot gradient`ã€‚
- en: And then we specify the loss and then model our trainable weightsã€‚So we basically
    want the gradients of the loss with respect to trainable parametersã€‚Then or the
    trainable weights ratherã€‚ And then we're going to do optimizerã€‚That apply gradientsã€‚
    We can do zip gradientsï¼Œ model the trainable weightã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æŒ‡å®šæŸå¤±ï¼Œç„¶åæ˜¯æ¨¡å‹æˆ‘ä»¬çš„å¯è®­ç»ƒæƒé‡ã€‚æ‰€ä»¥æˆ‘ä»¬åŸºæœ¬ä¸Šæƒ³è¦æŸå¤±å¯¹å¯è®­ç»ƒå‚æ•°çš„æ¢¯åº¦ã€‚ç„¶åæˆ–è€…è¯´æ˜¯å¯è®­ç»ƒæƒé‡ã€‚ç„¶åæˆ‘ä»¬å°†è¿›è¡Œä¼˜åŒ–å™¨ã€‚åº”ç”¨æ¢¯åº¦ã€‚æˆ‘ä»¬å¯ä»¥
    zip æ¢¯åº¦ï¼Œæ¨¡å‹å¯è®­ç»ƒæƒé‡ã€‚
- en: And then we're going to do accuracy metric dot update stateã€‚Why batch and then
    why predictionã€‚Just so that we have a sense of what the accuracy was of that epochã€‚So
    at the end hereã€‚ we're going to do training accuracy is equal to accuracy metric
    to resultã€‚ and then we could print that so we could do accuracy overã€‚Epochï¼Œ and
    thenã€‚We can just doã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è¿›è¡Œå‡†ç¡®åº¦æŒ‡æ ‡ dot æ›´æ–°çŠ¶æ€ã€‚Y batch å’Œ Y é¢„æµ‹ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½äº†è§£é‚£ä¸ª epoch çš„å‡†ç¡®åº¦ã€‚åˆ°è¿™é‡Œç»“æŸã€‚æˆ‘ä»¬å°†åšè®­ç»ƒå‡†ç¡®åº¦ç­‰äºå‡†ç¡®åº¦æŒ‡æ ‡çš„ç»“æœã€‚ç„¶åæˆ‘ä»¬å¯ä»¥æ‰“å°ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¤„ç†
    epoch çš„å‡†ç¡®åº¦ï¼Œç„¶åã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥åšã€‚
- en: Train accuracy like thatã€‚And then we could reset the accuracy metric so that
    it's going to be zeroed for the next epochã€‚ So accuracysymmetric dot reset statesã€‚And
    that's it for the training loopã€‚ so that's that's how it would look like it's
    very similar to the last video where we went through how to customize modelã€‚ fitï¼Œ
    except now we're just removing the model that fit and we're just adding a loop
    here for the number of epochs that we want to trainã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå‡†ç¡®åº¦å°±æ˜¯è¿™æ ·ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥é‡ç½®å‡†ç¡®åº¦æŒ‡æ ‡ï¼Œä»¥ä¾¿å®ƒåœ¨ä¸‹ä¸€ä¸ª epoch æ—¶ä¸ºé›¶ã€‚æ‰€ä»¥ accuracysymmetric dot é‡ç½®çŠ¶æ€ã€‚è¿™å°±æ˜¯è®­ç»ƒå¾ªç¯çš„å†…å®¹ã€‚è¿™çœ‹èµ·æ¥éå¸¸ç±»ä¼¼äºæˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªè§†é¢‘ä¸­è®²è§£å¦‚ä½•è‡ªå®šä¹‰æ¨¡å‹çš„è¿‡ç¨‹ï¼Œåªä¸è¿‡ç°åœ¨æˆ‘ä»¬åªæ˜¯å»æ‰äº†æ¨¡å‹çš„æ‹Ÿåˆï¼Œè€Œæ˜¯ä¸ºæˆ‘ä»¬æƒ³è®­ç»ƒçš„
    epoch æ•°æ·»åŠ äº†ä¸€ä¸ªå¾ªç¯ã€‚
- en: And then all we want to do is I guessã€‚So test loopã€‚ so this is for the training
    and then we're going to want to have a test loop to evaluate our modelã€‚And then
    we don't need to run it for a couple of epochsã€‚ we could just run through the
    data set onceã€‚ so we're going to do batch index and then X batchã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³åšçš„å°±æ˜¯ï¼Œæˆ‘æƒ³ã€‚æµ‹è¯•å¾ªç¯ã€‚è¿™æ˜¯ç”¨äºè®­ç»ƒçš„ï¼Œç„¶åæˆ‘ä»¬å°†éœ€è¦ä¸€ä¸ªæµ‹è¯•å¾ªç¯æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬ä¸éœ€è¦è¿è¡Œå‡ ä¸ª epochã€‚æˆ‘ä»¬å¯ä»¥åªè¿è¡Œä¸€æ¬¡æ•°æ®é›†ã€‚æ‰€ä»¥æˆ‘ä»¬å°†åšæ‰¹æ¬¡ç´¢å¼•å’Œ
    X batchã€‚
- en: Y batchge enumerate DSs test and I guess right now we're not using the batch
    indexã€‚ but I mean you could So I guess you could just iterate through the DSs
    test as well there's no point of doing the enumerateã€‚ but sometimes you want the
    batch indexã€‚Anywaysã€‚We don't need to do gradient tapeã€‚ We're not going to collect
    the gradientsã€‚ So we're just going to do y prediction in this model of X batch
    training equals true and then accuracysymmetric dot updateã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Y batchge åˆ—ä¸¾ DSs æµ‹è¯•ï¼Œæˆ‘æƒ³ç°åœ¨æˆ‘ä»¬å¹¶æ²¡æœ‰ä½¿ç”¨æ‰¹æ¬¡ç´¢å¼•ã€‚ä½†æˆ‘çš„æ„æ€æ˜¯ï¼Œä½ å¯ä»¥ã€‚æ‰€ä»¥æˆ‘æƒ³ä½ ä¹Ÿå¯ä»¥éå† DSs æµ‹è¯•ï¼Œæ²¡æœ‰å¿…è¦åš enumerateã€‚ä¸è¿‡æœ‰æ—¶ä½ ä¼šæƒ³è¦æ‰¹æ¬¡ç´¢å¼•ã€‚æ— è®ºå¦‚ä½•ã€‚æˆ‘ä»¬ä¸éœ€è¦ä½¿ç”¨æ¢¯åº¦è®°å½•ã€‚æˆ‘ä»¬ä¸ä¼šæ”¶é›†æ¢¯åº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åœ¨è¿™ä¸ªæ¨¡å‹ä¸­åš
    y é¢„æµ‹ï¼Œå½“ X batch è®­ç»ƒç­‰äºçœŸæ—¶ï¼Œç„¶å accuracysymmetric dot æ›´æ–°ã€‚
- en: State Y badgeï¼Œ and then Y predictionã€‚Then in the end we could do train accuracy
    is accuracysymmetric dot resultã€‚ right same as we did right hereã€‚And then we couldï¼Œ
    I guess we could print accuracy over testã€‚Setã€‚Then we could just write training
    as hereã€‚And then in the endï¼Œ we could againï¼Œ reset itã€‚We don't have to do this
    thoughï¼Œ since that's the last thing we're going to doã€‚But anywaysã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: çŠ¶æ€ Y badgeï¼Œç„¶å Y é¢„æµ‹ã€‚æœ€åæˆ‘ä»¬å¯ä»¥åšè®­ç»ƒå‡†ç¡®åº¦ç­‰äº accuracysymmetric dot ç»“æœã€‚å¯¹ï¼Œå°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„ä¸€æ ·ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ï¼Œæˆ‘æƒ³æˆ‘ä»¬å¯ä»¥æ‰“å°æµ‹è¯•é›†çš„å‡†ç¡®åº¦ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥åƒè¿™é‡Œä¸€æ ·å†™è®­ç»ƒã€‚æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å†æ¬¡é‡ç½®ã€‚è™½ç„¶æˆ‘ä»¬ä¸å¿…è¿™æ ·åšï¼Œå› ä¸ºé‚£æ˜¯æˆ‘ä»¬è¦åšçš„æœ€åä¸€ä»¶äº‹ã€‚ä¸è¿‡æ— è®ºå¦‚ä½•ã€‚
- en: that's how it looks like if you want a training loop and a test loopï¼Œ of course
    you can alsoã€‚ I meanï¼Œ you could put this right here in a function like define
    train or somethingã€‚ and then you could you know for epoking range of you could
    just call that functionã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è¦ä¸€ä¸ªè®­ç»ƒå¾ªç¯å’Œæµ‹è¯•å¾ªç¯ï¼Œå®ƒçœ‹èµ·æ¥å°±æ˜¯è¿™æ ·ï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥ã€‚æˆ‘æ˜¯è¯´ï¼Œä½ å¯ä»¥æŠŠè¿™ä¸ªæ”¾åœ¨ä¸€ä¸ªåƒ define train çš„å‡½æ•°é‡Œã€‚ç„¶åä½ å¯ä»¥ï¼Œæ¯”å¦‚è¯´ï¼ŒæŒ‰èŒƒå›´çš„
    epoch åªéœ€è°ƒç”¨é‚£ä¸ªå‡½æ•°ã€‚
- en: '![](img/38a145700a6404a2026fbca3d7269917_6.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_6.png)'
- en: '![](img/38a145700a6404a2026fbca3d7269917_7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_7.png)'
- en: Train 1 epochï¼Œ maybeã€‚And then run run itã€‚So you know you could think of the
    structure of you could think of how you want to structure thisã€‚ but this is the
    fundamentals of how you do a training loopã€‚ it's very simple we've done it in
    the most simple way that we can and of course if you're doing something more complicated
    like generative adversary networks or GANSã€‚ then it's going to look more complicated
    than thisã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒ1ä¸ªå‘¨æœŸï¼Œä¹Ÿè®¸ã€‚ç„¶åè¿è¡Œå®ƒã€‚æ‰€ä»¥ä½ çŸ¥é“ä½ å¯ä»¥æ€è€ƒä¸€ä¸‹ä½ æƒ³å¦‚ä½•æ„å»ºè¿™ä¸ªç»“æ„ã€‚ä½†æ˜¯è¿™å°±æ˜¯è®­ç»ƒå¾ªç¯çš„åŸºæœ¬åŸç†ã€‚è¿™éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä»¥æœ€ç®€å•çš„æ–¹å¼å®ç°äº†å®ƒï¼Œå½“ç„¶ï¼Œå¦‚æœä½ åœ¨åšä¸€äº›æ›´å¤æ‚çš„äº‹æƒ…ï¼Œæ¯”å¦‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæˆ–GANï¼Œé‚£ä¹ˆå®ƒçœ‹èµ·æ¥ä¼šæ¯”è¿™ä¸ªå¤æ‚å¾—å¤šã€‚
- en: but it's still going to be a fundamentally the same method and I think if you
    sort of understand this basic layout then and then when do more complicated things
    it's going to help you and understand it general structureã€‚All rightï¼Œ so first
    of allï¼Œ we should run this and make sure that it worksã€‚And it doesn'tã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åŸºæœ¬æ–¹æ³•ä»ç„¶æ˜¯ç›¸åŒçš„ï¼Œæˆ‘è®¤ä¸ºå¦‚æœä½ ç†è§£äº†è¿™ä¸ªåŸºæœ¬æ¡†æ¶ï¼Œé‚£ä¹ˆåœ¨å¤„ç†æ›´å¤æ‚çš„äº‹æƒ…æ—¶ï¼Œè¿™å°†å¸®åŠ©ä½ ç†è§£å®ƒçš„æ•´ä½“ç»“æ„ã€‚å¥½çš„ï¼Œé¦–å…ˆæˆ‘ä»¬åº”è¯¥è¿è¡Œè¿™ä¸ªå¹¶ç¡®ä¿å®ƒèƒ½å·¥ä½œã€‚ä½†å®ƒæ²¡æœ‰ã€‚
- en: So it has no attribute gradientsã€‚ that's because we want to have a tap dot gradientã€‚All
    rightã€‚ and as we can see it makes sense it's training and this worksã€‚So yeahã€‚Anywaysã€‚
    that's it for this videoï¼Œ hopefully you found this useful if you have any questions
    then leave them in the comment section belowã€‚ I think I said thank you for watching
    but thank you for watching and I hope to see you in the next videoã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒæ²¡æœ‰å±æ€§æ¢¯åº¦ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬æƒ³è¦ä¸€ä¸ªtap dotæ¢¯åº¦ã€‚å¥½çš„ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¿™å¾ˆæœ‰é“ç†ï¼Œå®ƒæ­£åœ¨è®­ç»ƒå¹¶ä¸”æœ‰æ•ˆã€‚æ‰€ä»¥æ˜¯çš„ã€‚æ— è®ºå¦‚ä½•ï¼Œè¿™å°±æ˜¯æœ¬è§†é¢‘çš„å†…å®¹ï¼Œå¸Œæœ›ä½ è§‰å¾—æœ‰ç”¨ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·åœ¨ä¸‹é¢çš„è¯„è®ºåŒºç•™è¨€ã€‚æˆ‘æƒ³æˆ‘ä¹‹å‰è¯´è¿‡æ„Ÿè°¢è§‚çœ‹ï¼Œä½†è°¢è°¢ä½ è§‚çœ‹ï¼Œå¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚
- en: '![](img/38a145700a6404a2026fbca3d7269917_9.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_9.png)'
