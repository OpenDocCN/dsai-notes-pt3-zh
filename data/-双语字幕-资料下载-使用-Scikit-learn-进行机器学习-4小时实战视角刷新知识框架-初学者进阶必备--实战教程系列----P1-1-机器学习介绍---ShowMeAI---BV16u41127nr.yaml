- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ä½¿ç”¨ Scikit-learn è¿›è¡Œæœºå™¨å­¦ä¹ ï¼Œ4å°æ—¶å®æˆ˜è§†è§’åˆ·æ–°çŸ¥è¯†æ¡†æ¶ï¼Œåˆå­¦è€…è¿›é˜¶å¿…å¤‡ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P1ï¼š1ï¼‰æœºå™¨å­¦ä¹ ä»‹ç»
    - ShowMeAI - BV16u41127nr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ä½¿ç”¨ Scikit-learn è¿›è¡Œæœºå™¨å­¦ä¹ ï¼Œ4å°æ—¶å®æˆ˜è§†è§’åˆ·æ–°çŸ¥è¯†æ¡†æ¶ï¼Œåˆå­¦è€…è¿›é˜¶å¿…å¤‡ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P1ï¼š1ï¼‰æœºå™¨å­¦ä¹ ä»‹ç»
    - ShowMeAI - BV16u41127nr
- en: '![](img/cca75afc4da139e8d5dce602f436c338_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_0.png)'
- en: '![](img/cca75afc4da139e8d5dce602f436c338_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_1.png)'
- en: Well in this part of the course we're going to be moving into a new section
    which is machine learningã€‚ there's a lot of material we're going to coverï¼Œ but
    at the same time it's really the tip of the iceberg for all the material you can
    do in this fieldã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™éƒ¨åˆ†è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†è¿›å…¥ä¸€ä¸ªæ–°çš„éƒ¨åˆ†ï¼Œå³æœºå™¨å­¦ä¹ ã€‚æˆ‘ä»¬å°†æ¶µç›–å¤§é‡ææ–™ï¼Œä½†ä¸æ­¤åŒæ—¶ï¼Œè¿™åªæ˜¯ä½ åœ¨è¿™ä¸ªé¢†åŸŸå¯ä»¥åšçš„ææ–™çš„å†°å±±ä¸€è§’ã€‚
- en: Let me try to start by relating to something that we're familiar withã€‚And then
    connected to something new we're going to be doing which is building models so
    all of you have been running functions for a long time right so hey maybe I'll
    write this code and then our function take inputs maybe in the form of parameters
    and then they have some outputs maybe maybe either they're printing something
    or or I might return a valueã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘è¯•ç€ä»æˆ‘ä»¬ç†Ÿæ‚‰çš„äº‹ç‰©å¼€å§‹ï¼Œç„¶åè¿æ¥åˆ°æˆ‘ä»¬å°†è¦åšçš„æ–°äº‹ç‰©ï¼Œå³æ„å»ºæ¨¡å‹ã€‚ä½ ä»¬å·²ç»è¿è¡Œå‡½æ•°å¾ˆé•¿æ—¶é—´äº†ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ï¼Œä¹Ÿè®¸æˆ‘ä¼šå†™è¿™æ®µä»£ç ï¼Œç„¶åæˆ‘ä»¬çš„å‡½æ•°æ¥æ”¶è¾“å…¥ï¼Œå¯èƒ½ä»¥å‚æ•°çš„å½¢å¼ï¼Œç„¶åå®ƒä»¬æœ‰ä¸€äº›è¾“å‡ºï¼Œä¹Ÿè®¸å®ƒä»¬åœ¨æ‰“å°æŸäº›å†…å®¹ï¼Œæˆ–è€…æˆ‘å¯èƒ½ä¼šè¿”å›ä¸€ä¸ªå€¼ã€‚
- en: And so for exampleï¼Œ I can imagine that a function could be doing something like
    making some sort of predictionã€‚ maybe my input is that I have some details about
    a house sets for saleã€‚And then I might be predicting what it might sell forï¼Œ and
    so when I have a function like thisã€‚ that's an example of a modelã€‚And and I could
    imagine having it feed in a bunch of values at the same time and making a bunch
    of predictionsã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘å¯ä»¥æƒ³è±¡ä¸€ä¸ªå‡½æ•°å¯ä»¥åšä¸€äº›é¢„æµ‹ã€‚ä¹Ÿè®¸æˆ‘çš„è¾“å…¥æ˜¯æˆ‘æœ‰ä¸€äº›å¾…å”®æˆ¿å±‹çš„è¯¦ç»†ä¿¡æ¯ã€‚ç„¶åæˆ‘å¯èƒ½ä¼šé¢„æµ‹å®ƒå¯èƒ½å–å¤šå°‘é’±ï¼Œæ‰€ä»¥å½“æˆ‘æœ‰è¿™æ ·çš„å‡½æ•°æ—¶ã€‚è¿™å°±æ˜¯ä¸€ä¸ªæ¨¡å‹çš„ä¾‹å­ã€‚æˆ‘å¯ä»¥æƒ³è±¡åŒæ—¶è¾“å…¥ä¸€å †å€¼å¹¶åšå‡ºå¾ˆå¤šé¢„æµ‹ã€‚
- en: So the idea of machine learning is that instead of having a computer write these
    or instead of having a human write these functions where I have a computer automatically
    generate these functionsã€‚ and the way they're going to do that is they're going
    to learn by exampleã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æœºå™¨å­¦ä¹ çš„æƒ³æ³•æ˜¯ï¼Œç”µè„‘ä¸å†ç”±äººç±»ç¼–å†™è¿™äº›å‡½æ•°ï¼Œè€Œæ˜¯ç”±ç”µè„‘è‡ªåŠ¨ç”Ÿæˆè¿™äº›å‡½æ•°ã€‚å®ƒä»¬çš„åšæ³•æ˜¯é€šè¿‡å®ä¾‹å­¦ä¹ ã€‚
- en: so we'll feed in a bunch of training data where we have a bunch of her of houses
    that have sold for different amounts and have different bedrooms and bathsã€‚ we't
    trying to infer things like well how much is the bedroom worthï¼Œ how much is the
    bath worthã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å°†è¾“å…¥ä¸€å †è®­ç»ƒæ•°æ®ï¼Œå…¶ä¸­æœ‰è®¸å¤šæˆ¿å±‹ä»¥ä¸åŒçš„ä»·æ ¼å‡ºå”®ï¼Œå¹¶ä¸”æœ‰ä¸åŒçš„å§å®¤å’Œæµ´å®¤ã€‚æˆ‘ä»¬è¯•å›¾æ¨æ–­ä¸€äº›äº‹æƒ…ï¼Œæ¯”å¦‚å§å®¤å€¼å¤šå°‘é’±ï¼Œæµ´å®¤å€¼å¤šå°‘é’±ã€‚
- en: how useful is it have a newer houseï¼ŸAnd then based on that functionã€‚ we're be
    we're going to be able to generate that function and then use that to make predictions
    on otherã€‚Data and you can imagine why that might be useful for a lot of thingsã€‚
    maybe you're doing property assessments or maybe a realtor and you're trying to
    figure out how to price a house properlyã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‹¥æœ‰ä¸€åº§æ–°æˆ¿å­æœ‰å¤šæœ‰ç”¨ï¼Ÿç„¶ååŸºäºé‚£ä¸ªå‡½æ•°ã€‚æˆ‘ä»¬å°†èƒ½å¤Ÿç”Ÿæˆé‚£ä¸ªå‡½æ•°ï¼Œç„¶åç”¨å®ƒæ¥å¯¹å…¶ä»–æ•°æ®åšå‡ºé¢„æµ‹ã€‚ä½ å¯ä»¥æƒ³è±¡è¿™å¯¹è®¸å¤šäº‹æƒ…å¯èƒ½æ˜¯æœ‰ç”¨çš„ã€‚ä¹Ÿè®¸ä½ åœ¨è¿›è¡Œç‰©ä¸šè¯„ä¼°ï¼Œæˆ–è€…ä½ æ˜¯æˆ¿åœ°äº§ç»çºªäººï¼Œæ­£åœ¨åŠªåŠ›ç¡®å®šå¦‚ä½•æ­£ç¡®å®šä»·æˆ¿å­ã€‚
- en: So the example I've given here is an example of a regression model and a regression
    model is trying to more broadly a type of supervised machine learning which is
    one of the main three categories of machine learningã€‚ so I'm going to start broad
    now and talk about these three areas and then we're going to be talking about
    regression in more detail and I'll actually explain on what it isã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œç»™å‡ºçš„ä¾‹å­æ˜¯å›å½’æ¨¡å‹çš„ä¾‹å­ï¼Œå›å½’æ¨¡å‹è¯•å›¾æ›´å¹¿æ³›åœ°è¯´æ˜¯ä¸€ç§ç›‘ç£å¼æœºå™¨å­¦ä¹ ï¼Œå®ƒæ˜¯æœºå™¨å­¦ä¹ çš„ä¸‰å¤§ä¸»è¦ç±»åˆ«ä¹‹ä¸€ã€‚æ‰€ä»¥æˆ‘ç°åœ¨è¦å¼€å§‹å¹¿æ³›åœ°è®¨è®ºè¿™ä¸‰ä¸ªé¢†åŸŸï¼Œç„¶åæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°è°ˆè®ºå›å½’ï¼Œæˆ‘å®é™…ä¸Šä¼šè§£é‡Šå®ƒæ˜¯ä»€ä¹ˆã€‚
- en: So the three main areas of machine learning are reinforcement learningã€‚ which
    is basically a situation where you have to make a series of decisionsã€‚And you're
    trying to optimize some sort of reward so you can imagine some sort of robot moving
    around in the world and picking up coins or something like that we're not going
    to be doing that kind of work in this class instead we're going to focus on two
    areas which are supervised machine learning and unsupervised machine learning
    and in both of these cases we just have all our data upfront and we're trying
    to gain information about that some people will say there's a fourth category
    of machine learning called super super semisupvised but we won't be talking about
    that hereã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ çš„ä¸‰ä¸ªä¸»è¦é¢†åŸŸæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ä¸€ç§éœ€è¦åšä¸€ç³»åˆ—å†³ç­–çš„æƒ…å†µã€‚ä½ è¯•å›¾ä¼˜åŒ–æŸç§å¥–åŠ±ï¼Œæ‰€ä»¥ä½ å¯ä»¥æƒ³è±¡æŸç§æœºå™¨äººåœ¨ä¸–ç•Œä¸­ç§»åŠ¨å¹¶æ‹¾å–ç¡¬å¸ï¼Œæˆ–è€…ç±»ä¼¼çš„äº‹æƒ…ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é—¨è¯¾ä¸­ä¸ä¼šåšé‚£ç§å·¥ä½œï¼Œè€Œæ˜¯ä¼šä¸“æ³¨äºä¸¤ä¸ªé¢†åŸŸï¼šç›‘ç£æœºå™¨å­¦ä¹ å’Œæ— ç›‘ç£æœºå™¨å­¦ä¹ ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½æœ‰æ‰€æœ‰çš„æ•°æ®ï¼Œè€Œæˆ‘ä»¬è¯•å›¾ä»ä¸­è·å–ä¿¡æ¯ã€‚æœ‰äº›äººä¼šè¯´æœ‰ä¸€ä¸ªç¬¬å››ç±»æœºå™¨å­¦ä¹ ï¼Œç§°ä¸ºè¶…ç›‘ç£å­¦ä¹ ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šè®¨è®ºé‚£ä¸ªã€‚
- en: Within supervised machine learning there are two different things that we're
    going to learn this semesterã€‚ one is regression and with regression we're trying
    to predict a quantity and then with a classification we're going to try to predict
    a category so in any of these cases where we're trying to predict something that's
    known as a supervised problem and the way it works is while the data we have has
    some labels on it usually there's some special column that's telling us you know
    a quantity like the price for house or some sort of category and then from that
    we can try to predict that label and cases where the label is unknown and on supervised
    learning there's no special label column that we're trying to predict we're just
    trying to look for general patterns in the data and so we might do a couple things
    we might try to cluster our data we're replacing rows into different groupsã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç›‘ç£æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬è¿™å­¦æœŸè¦å­¦ä¹ ä¸¤ç§ä¸åŒçš„å†…å®¹ã€‚ä¸€ç§æ˜¯å›å½’ï¼Œåœ¨å›å½’ä¸­æˆ‘ä»¬è¯•å›¾é¢„æµ‹ä¸€ä¸ªæ•°é‡ï¼Œç„¶åé€šè¿‡åˆ†ç±»æˆ‘ä»¬å°†å°è¯•é¢„æµ‹ä¸€ä¸ªç±»åˆ«ï¼Œå› æ­¤åœ¨æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„ä»»ä½•æƒ…å†µä¸‹ï¼Œè¿™è¢«ç§°ä¸ºç›‘ç£é—®é¢˜ï¼Œå·¥ä½œåŸç†æ˜¯æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®ä¸Šæœ‰ä¸€äº›æ ‡ç­¾ï¼Œé€šå¸¸æœ‰ä¸€ä¸ªç‰¹æ®Šçš„åˆ—å‘Šè¯‰æˆ‘ä»¬ï¼Œä¾‹å¦‚æˆ¿å­çš„ä»·æ ¼æˆ–æŸç§ç±»åˆ«ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°è¯•é¢„æµ‹è¿™ä¸ªæ ‡ç­¾ï¼Œè€Œåœ¨æ ‡ç­¾æœªçŸ¥çš„æƒ…å†µä¸‹ï¼Œæ— ç›‘ç£å­¦ä¹ æ²¡æœ‰æˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„ç‰¹æ®Šæ ‡ç­¾åˆ—ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨å¯»æ‰¾æ•°æ®ä¸­çš„ä¸€èˆ¬æ¨¡å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯èƒ½ä¼šåšå‡ ä»¶äº‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå°è¯•å¯¹æ•°æ®è¿›è¡Œèšç±»ï¼Œå°†è¡Œæ›¿æ¢åˆ°ä¸åŒçš„ç»„ä¸­ã€‚
- en: Or we might try to decompose our rowsï¼Œ we might notice that you know I might
    have these rows which eachF5 numbers in themã€‚ but maybe every row is like a combination
    of kind of two component rowsã€‚ and so there's some simplicity in there even though
    there might be a lot of columns on our dataã€‚So I'm going to go through these four
    types of thing that we're going learn this semester and just try to make it more
    concrete so here I have a table right this is just a regular data frame and so
    this is my index here here are my column names right now I have a Y column which
    is my label so that's going to be generally what I'm trying to predictã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…æˆ‘ä»¬å¯èƒ½ä¼šå°è¯•å¯¹æˆ‘ä»¬çš„è¡Œè¿›è¡Œåˆ†è§£ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæ³¨æ„åˆ°æˆ‘å¯èƒ½æœ‰è¿™äº›æ¯è¡Œæœ‰F5ä¸ªæ•°å­—çš„è¡Œã€‚ä½†ä¹Ÿè®¸æ¯ä¸€è¡Œæ˜¯ä¸¤ç§ç»„ä»¶è¡Œçš„ç»„åˆã€‚æ‰€ä»¥å°½ç®¡æˆ‘ä»¬çš„æ•°æ®å¯èƒ½æœ‰å¾ˆå¤šåˆ—ï¼Œä½†é‡Œé¢ä»ç„¶æœ‰ä¸€äº›ç®€å•æ€§ã€‚å› æ­¤ï¼Œæˆ‘å°†è®¨è®ºè¿™å­¦æœŸæˆ‘ä»¬è¦å­¦ä¹ çš„è¿™å››ç§ç±»å‹çš„å†…å®¹ï¼Œå¹¶å°è¯•è®©å®ƒä»¬æ›´å…·ä½“ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªè¡¨æ ¼ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå¸¸è§„çš„æ•°æ®æ¡†ï¼Œè¿™é‡Œæ˜¯æˆ‘çš„ç´¢å¼•ï¼Œè¿™é‡Œæ˜¯æˆ‘çš„åˆ—åï¼Œç°åœ¨æˆ‘æœ‰ä¸€ä¸ªYåˆ—ï¼Œå®ƒæ˜¯æˆ‘çš„æ ‡ç­¾ï¼Œè¿™é€šå¸¸å°±æ˜¯æˆ‘è¯•å›¾é¢„æµ‹çš„å†…å®¹ã€‚
- en: And then I have these different problems here that I guess I'm just drawing
    the x0 through x4ã€‚ but usually those would have some sort of real name right like
    before I saw that we had like the number of beds in a houseã€‚So this label that
    we're trying to predict is what we're going to try to do is look for a relationship
    between that and these other columnsã€‚ which we're going to call featuresã€‚ğŸ˜Šï¼ŒSo
    in general what will happen is that we have some examplesã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘è¿™é‡Œæœ‰ä¸€äº›ä¸åŒçš„é—®é¢˜ï¼Œæˆ‘æƒ³æˆ‘åªæ˜¯åœ¨ç”» x0 åˆ° x4ã€‚ä½†é€šå¸¸è¿™äº›ä¼šæœ‰ä¸€äº›å®é™…çš„åç§°ï¼Œæ¯”å¦‚åœ¨æˆ‘çœ‹åˆ°çš„ä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰æˆ¿å­é‡Œçš„åºŠä½æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯•å›¾é¢„æµ‹çš„è¿™ä¸ªæ ‡ç­¾æ˜¯æˆ‘ä»¬è¦å¯»æ‰¾ä¸å…¶ä»–åˆ—ä¹‹é—´å…³ç³»çš„å†…å®¹ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºç‰¹å¾ã€‚ğŸ˜Š
    æ€»çš„æ¥è¯´ï¼Œå‘ç”Ÿçš„äº‹æƒ…æ˜¯æˆ‘ä»¬æœ‰ä¸€äº›ç¤ºä¾‹ã€‚
- en: some rows where we have examples of bothï¼Œ and then there might be some other
    data where we only have the features but we don't have the y label and so we want
    to try to predict what should're draw here and you can imagine why they might
    be maybe these are all different houses and some of them have already sold so
    we know what they sold for and then these have not drawn on the market yetã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›è¡Œä¸­æˆ‘ä»¬æœ‰ä¸¤ä¸ªæ–¹é¢çš„ä¾‹å­ï¼Œç„¶åå¯èƒ½è¿˜æœ‰ä¸€äº›å…¶ä»–æ•°æ®ï¼Œå…¶ä¸­æˆ‘ä»¬åªæœ‰ç‰¹å¾ï¼Œä½†æ²¡æœ‰yæ ‡ç­¾ï¼Œå› æ­¤æˆ‘ä»¬æƒ³å°è¯•é¢„æµ‹è¿™é‡Œåº”è¯¥æ˜¯ä»€ä¹ˆæ ·çš„ã€‚ä½ å¯ä»¥æƒ³è±¡ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Œä¹Ÿè®¸è¿™äº›éƒ½æ˜¯ä¸åŒçš„æˆ¿å­ï¼Œå…¶ä¸­ä¸€äº›å·²ç»å‡ºå”®ï¼Œæ‰€ä»¥æˆ‘ä»¬çŸ¥é“å®ƒä»¬çš„å”®ä»·ï¼Œè€Œè¿™äº›è¿˜æ²¡æœ‰ä¸Šå¸‚ã€‚
- en: so we're trying to predict would they sell if they do go on the market so the
    problem here with regression I just want to state again is that we want to predict
    a quantity the y column in this case based on the features and by a quantity I
    mean this is like a numberã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åœ¨å°è¯•é¢„æµ‹å¦‚æœå®ƒä»¬ä¸Šå¸‚çš„è¯ä¼šä¸ä¼šå‡ºå”®ã€‚è¿™é‡Œå›å½’é—®é¢˜æˆ‘æƒ³å†æ¬¡å¼ºè°ƒçš„æ˜¯ï¼Œæˆ‘ä»¬æƒ³é¢„æµ‹ä¸€ä¸ªé‡ï¼Œè¿™é‡Œçš„yåˆ—æ˜¯åŸºäºç‰¹å¾çš„ï¼Œè€Œè¿™ä¸ªé‡æˆ‘æŒ‡çš„æ˜¯ä¸€ä¸ªæ•°å­—ã€‚
- en: So how we're going to do that well we might actually break it down into the
    three parts first we might select a subset of the data that we for which we know
    the answer and then we might leave some other data aside for which we also know
    the answer and what we'll do is we'll run an algorithm that is able to infer what
    the relationship is between these features and these labelsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹å‘¢ï¼Ÿæˆ‘ä»¬å¯èƒ½ä¼šé¦–å…ˆå°†å…¶åˆ†è§£ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œé¦–å…ˆé€‰æ‹©ä¸€éƒ¨åˆ†æˆ‘ä»¬çŸ¥é“ç­”æ¡ˆçš„æ•°æ®ï¼Œç„¶åå°†å…¶ä»–ä¸€äº›æˆ‘ä»¬ä¹ŸçŸ¥é“ç­”æ¡ˆçš„æ•°æ®æ”¾åœ¨ä¸€è¾¹ï¼Œæˆ‘ä»¬è¦åšçš„æ˜¯è¿è¡Œä¸€ä¸ªèƒ½å¤Ÿæ¨æ–­è¿™äº›ç‰¹å¾ä¸è¿™äº›æ ‡ç­¾ä¹‹é—´å…³ç³»çš„ç®—æ³•ã€‚
- en: Once I've done that I might run my model on these other ones for which I also
    know the answer now of course I already know the real answer and unless my model
    is perfect it's probably going to give me somewhat different answers and so why
    would I do thisã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘åšå®Œè¿™äº›ï¼Œæˆ‘å¯èƒ½ä¼šåœ¨å…¶ä»–æˆ‘ä¹ŸçŸ¥é“ç­”æ¡ˆçš„æ¡ˆä¾‹ä¸Šè¿è¡Œæˆ‘çš„æ¨¡å‹ã€‚å½“ç„¶ï¼Œæˆ‘å·²ç»çŸ¥é“çœŸå®çš„ç­”æ¡ˆï¼Œé™¤éæˆ‘çš„æ¨¡å‹æ˜¯å®Œç¾çš„ï¼Œå¦åˆ™å®ƒå¯èƒ½ä¼šç»™å‡ºä¸€äº›ä¸åŒçš„ç­”æ¡ˆï¼Œæ‰€ä»¥æˆ‘ä¸ºä»€ä¹ˆè¦è¿™æ ·åšå‘¢ï¼Ÿ
- en: why would I want to make a prediction if I already know the answer and the reason
    is that I can do this to evaluate my model or I might say test my model so for
    example if my model says that this rush of in 70 and it's actually 72 well that's
    an error same thing hereã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘å·²ç»çŸ¥é“ç­”æ¡ˆï¼Œä¸ºä»€ä¹ˆè¿˜è¦åšé¢„æµ‹ï¼ŸåŸå› æ˜¯æˆ‘å¯ä»¥è¿™æ ·æ¥è¯„ä¼°æˆ‘çš„æ¨¡å‹ï¼Œæˆ–è€…æˆ‘å¯èƒ½ä¼šè¯´æµ‹è¯•æˆ‘çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘çš„æ¨¡å‹è¯´è¿™ä¸ªæˆ¿å­çš„ä»·æ ¼æ˜¯70ï¼Œè€Œå®é™…ä¸Šæ˜¯72ï¼Œé‚£å°±æ˜¯ä¸€ä¸ªé”™è¯¯ï¼Œè¿™é‡Œä¹Ÿæ˜¯åŒæ ·çš„é“ç†ã€‚
- en: 60 versus 59 that's an error and I can try to quantify all of these errors and
    then Jim my model some sort of score that's the testing phaseï¼Ÿ
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 60ä¸59ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªé”™è¯¯ï¼Œæˆ‘å¯ä»¥å°è¯•é‡åŒ–æ‰€æœ‰è¿™äº›é”™è¯¯ï¼Œç„¶åç»™æˆ‘çš„æ¨¡å‹æ‰“åˆ†ï¼Œè¿™å°±æ˜¯æµ‹è¯•é˜¶æ®µå—ï¼Ÿ
- en: So after thatï¼Œ after I've learned my model up hereã€‚ and then I've kind of evaluated
    it on some known casesã€‚Then I might actually put it in productionã€‚ production
    means I'm using it for real thingsã€‚And I'm trying to predict actual unknowns in
    the worldã€‚ likeï¼Œ for exampleï¼Œ if I add a new house to the marketï¼Œ what might itself
    moreã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨é‚£ä¹‹åï¼Œåœ¨æˆ‘å­¦ä¼šäº†æˆ‘çš„æ¨¡å‹å¹¶å¯¹ä¸€äº›å·²çŸ¥æ¡ˆä¾‹è¿›è¡Œäº†è¯„ä¼°åï¼Œæˆ‘å¯èƒ½ä¼šæŠŠå®ƒæŠ•å…¥ç”Ÿäº§ã€‚ç”Ÿäº§æ„å‘³ç€æˆ‘åœ¨ç”¨å®ƒåšå®é™…çš„äº‹æƒ…ã€‚æˆ‘åœ¨å°è¯•é¢„æµ‹ä¸–ç•Œä¸Šå®é™…çš„æœªçŸ¥é‡ï¼Œæ¯”å¦‚è¯´ï¼Œå¦‚æœæˆ‘åœ¨å¸‚åœºä¸Šå¢åŠ ä¸€å¥—æ–°æˆ¿ï¼Œå®ƒå¯èƒ½ä¼šå–å¤šå°‘é’±ã€‚
- en: And I could all put these different values thereã€‚other thing we might do even
    beyond making predictions is that I might look at that model and just try to learn
    things about the worldã€‚ so I keep going back to the example where we're selling
    housesã€‚ I think it's interesting to just know well for each additional house or
    for each additional bedroom or bathroom I have in my houseã€‚How much does that
    increase the value of my house and I can use that to make different decisions
    right like maybe I want to do a housing remodel am I going to get more benefit
    by adding another bathroom or another bedroom right so we can just kind of learn
    things about the world and also make decisions in that wayã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥æŠŠè¿™äº›ä¸åŒçš„å€¼æ”¾åœ¨é‚£é‡Œã€‚æˆ‘ä»¬å¯èƒ½åšçš„å¦ä¸€ä»¶äº‹ï¼Œç”šè‡³è¶…è¶Šé¢„æµ‹ï¼Œæ˜¯æˆ‘å¯ä»¥æŸ¥çœ‹é‚£ä¸ªæ¨¡å‹å¹¶å°è¯•å­¦ä¹ ä¸€äº›å…³äºä¸–ç•Œçš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä¸€ç›´å›åˆ°å–æˆ¿å­çš„ä¾‹å­ã€‚æˆ‘è®¤ä¸ºäº†è§£æ¯å¢åŠ ä¸€å¥—æˆ¿å­æˆ–æ¯å¢åŠ ä¸€ä¸ªå§å®¤æˆ–æµ´å®¤ï¼Œæˆ¿å­çš„ä»·å€¼ä¼šå¢åŠ å¤šå°‘æ˜¯å¾ˆæœ‰è¶£çš„ï¼Œæˆ‘å¯ä»¥åˆ©ç”¨è¿™äº›æ¥åšå‡ºä¸åŒçš„å†³ç­–ï¼Œæ¯”å¦‚è¯´ä¹Ÿè®¸æˆ‘æƒ³è¿›è¡Œæˆ¿å±‹æ”¹é€ ï¼Œæˆ‘æ˜¯é€šè¿‡å¢åŠ ä¸€ä¸ªæµ´å®¤è¿˜æ˜¯ä¸€ä¸ªå§å®¤æ¥è·å¾—æ›´å¤šçš„æ”¶ç›Šå‘¢ï¼Ÿæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä»¥è¿™ç§æ–¹å¼å­¦ä¹ ä¸€äº›å…³äºä¸–ç•Œçš„äº‹æƒ…å¹¶åšå‡ºå†³ç­–ã€‚
- en: Okayï¼Œ so all of this was regression which was the first kind of supervised learning
    we're going to learn this semester and when we're doing these regressions right
    the key thing that makes the regression is that we're trying to predict some quantity
    and our Y label now it's totally possible that our features might be a mix of
    both quantities and categories right so something like green red blue is a categoryã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ‰€ä»¥æ‰€æœ‰è¿™äº›éƒ½æ˜¯å›å½’ï¼Œè¿™æ˜¯æˆ‘ä»¬æœ¬å­¦æœŸè¦å­¦ä¹ çš„ç¬¬ä¸€ç§ç›‘ç£å­¦ä¹ ã€‚å½“æˆ‘ä»¬è¿›è¡Œè¿™äº›å›å½’æ—¶ï¼Œå…³é”®åœ¨äºæˆ‘ä»¬è¯•å›¾é¢„æµ‹æŸä¸ªæ•°é‡ï¼Œè€Œæˆ‘ä»¬çš„Yæ ‡ç­¾ç°åœ¨å®Œå…¨å¯èƒ½æ˜¯ç‰¹å¾çš„æ•°é‡å’Œç±»åˆ«çš„æ··åˆï¼Œå¯¹å§ï¼Ÿåƒç»¿è‰²ã€çº¢è‰²ã€è“è‰²è¿™æ ·çš„å°±æ˜¯ä¸€ä¸ªç±»åˆ«ã€‚
- en: something like shape as a categoryï¼Œ a lot of things are strings or categoriesã€‚That's
    fine rightã€‚ the distinguishing characteristic of a regression is that the label
    column is quantitativeã€‚If I somehow am working on a problem where my Y is categoricalï¼Œ
    then this is no longer regressionã€‚ it's a classification problemï¼Œ but otherwise
    all these other things I've been talking about where I kind of do training and
    testing and then I put in productionã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å½¢çŠ¶ä¹Ÿæ˜¯ä¸€ä¸ªç±»åˆ«ï¼Œå¾ˆå¤šä¸œè¥¿éƒ½æ˜¯å­—ç¬¦ä¸²æˆ–ç±»åˆ«ã€‚æ²¡é—®é¢˜ï¼Œå¯¹å§ã€‚å›å½’çš„æ˜¾è‘—ç‰¹å¾æ˜¯æ ‡ç­¾åˆ—æ˜¯å®šé‡çš„ã€‚å¦‚æœæˆ‘åœ¨å¤„ç†ä¸€ä¸ªYæ˜¯åˆ†ç±»çš„æƒ…å†µï¼Œé‚£ä¹ˆè¿™å°±ä¸å†æ˜¯å›å½’äº†ã€‚è¿™æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œä½†å¦åˆ™æˆ‘è°ˆè®ºçš„æ‰€æœ‰å…¶ä»–å†…å®¹ï¼ŒåŒ…æ‹¬è®­ç»ƒå’Œæµ‹è¯•ï¼Œç„¶åæŠ•å…¥ç”Ÿäº§ã€‚
- en: all of that is the same we're just dealing with categories instead of instead
    of quantitiesã€‚Okayã€‚ so moving on we saw the two kinds of supervised learning which
    is both regression and classification what about unsupervised learning The main
    thing hereã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™ä¸€åˆ‡éƒ½æ˜¯ç›¸åŒçš„ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨å¤„ç†ç±»åˆ«è€Œä¸æ˜¯æ•°é‡ã€‚å¥½çš„ã€‚é‚£ä¹ˆç»§ç»­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸¤ç§ç›‘ç£å­¦ä¹ ï¼Œåˆ†åˆ«æ˜¯å›å½’å’Œåˆ†ç±»ã€‚é‚£ä¹ˆæ— ç›‘ç£å­¦ä¹ å‘¢ï¼Ÿè¿™é‡Œçš„ä¸»è¦å†…å®¹æ˜¯ã€‚
- en: the main point is that there is no label column right I just have a bunch of
    featuresã€‚And then I can try to still learn some patterns about thisã€‚ even though
    I'm not trying to predict anythingã€‚And so one of the things I might want to learn
    is well are there any sort of natural groupings of these rows and so there are
    algorithms out there that will let's say put all these rows into three groups
    and might and assign them numbers like zeroã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦çš„è¦ç‚¹æ˜¯æ²¡æœ‰æ ‡ç­¾åˆ—ï¼Œå¯¹å§ï¼Ÿæˆ‘åªæœ‰ä¸€å †ç‰¹å¾ã€‚ç„¶åæˆ‘ä»ç„¶å¯ä»¥å°è¯•å­¦ä¹ ä¸€äº›å…³äºè¿™ä¸ªçš„æ¨¡å¼ã€‚å³ä½¿æˆ‘å¹¶ä¸æ˜¯åœ¨è¯•å›¾é¢„æµ‹ä»»ä½•ä¸œè¥¿ã€‚æ‰€ä»¥æˆ‘å¯èƒ½æƒ³è¦å­¦ä¹ çš„å…¶ä¸­ä¸€ä»¶äº‹æ˜¯ï¼Œè¿™äº›è¡Œæ˜¯å¦æœ‰ä»»ä½•è‡ªç„¶çš„åˆ†ç»„ï¼Œå› æ­¤æœ‰ç®—æ³•å¯ä»¥å°†æ‰€æœ‰è¿™äº›è¡Œåˆ†æˆä¸‰ä¸ªç»„ï¼Œå¹¶å¯èƒ½ç»™å®ƒä»¬åˆ†é…æ•°å­—ï¼Œæ¯”å¦‚é›¶ã€‚
- en: one and two right and then just to kind of draw what that looks like while all
    of these rows be lying togetherã€‚Now I really want to stress here that there's
    no data out there that tells me what the proper grouping is or even how many groups
    there are so when I'm doing thisã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å’ŒäºŒï¼Œå¯¹å§ï¼Ÿç„¶åä»…ä»…æ˜¯ä¸ºäº†ç”»å‡ºé‚£æ ·çš„æ ·å­ï¼Œè™½ç„¶æ‰€æœ‰è¿™äº›è¡Œéƒ½åœ¨ä¸€èµ·ã€‚ç°åœ¨æˆ‘çœŸçš„æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œæ²¡æœ‰æ•°æ®å‘Šè¯‰æˆ‘æ­£ç¡®çš„åˆ†ç»„æ˜¯ä»€ä¹ˆï¼Œæˆ–è€…ç”šè‡³æœ‰å¤šå°‘ç»„ï¼Œæ‰€ä»¥åœ¨æˆ‘åšè¿™ä¸ªçš„æ—¶å€™ã€‚
- en: it's not exactly like there's one right answerï¼Œ but that doesn't mean that all
    groupings or classifications are equal I can measure within a group how similar
    those rows are to each other if I have some metric for that and so then my goal
    is to have a grouping that kind of maximizes a similarity within each group and
    there might be different groupings that are equally good right but as long as
    I'm kind of having a high similarity within groups well then I still learn something
    meaningful and you can imagine lots of different reasons I might do this like
    maybe each of theseã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸æ˜¯è¯´åªæœ‰ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆï¼Œä½†è¿™å¹¶ä¸æ„å‘³ç€æ‰€æœ‰çš„åˆ†ç»„æˆ–åˆ†ç±»éƒ½æ˜¯ç›¸ç­‰çš„ã€‚å¦‚æœæˆ‘æœ‰æŸç§åº¦é‡æ ‡å‡†ï¼Œæˆ‘å¯ä»¥è¡¡é‡ç»„å†…é‚£äº›è¡Œä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå› æ­¤æˆ‘çš„ç›®æ ‡æ˜¯æ‹¥æœ‰ä¸€ç§å°½é‡æœ€å¤§åŒ–æ¯ä¸ªç»„å†…ç›¸ä¼¼æ€§çš„åˆ†ç»„ï¼Œå¯èƒ½ä¼šæœ‰ä¸åŒçš„åˆ†ç»„åŒæ ·æœ‰æ•ˆï¼Œå¯¹å§ï¼Ÿä½†åªè¦æˆ‘åœ¨ç»„å†…ä¿æŒé«˜ç›¸ä¼¼æ€§ï¼Œé‚£ä¹ˆæˆ‘ä¾ç„¶èƒ½å­¦åˆ°ä¸€äº›æœ‰æ„ä¹‰çš„ä¸œè¥¿ï¼Œä½ å¯ä»¥æƒ³è±¡æˆ‘å¯èƒ½å‡ºäºå¾ˆå¤šä¸åŒçš„åŸå› è¿™æ ·åšï¼Œæˆ–è®¸æ¯ä¸ªè¿™äº›ã€‚
- en: Things represent a different user for my web application and then if I can sayï¼Œ
    heyã€‚ while there's these 10 different kinds of web users for my applicationã€‚ I
    could maybe run a different marketing campaign for each of these different groupsã€‚Okayã€‚
    so clustering again is unsupervised and it's unsupervised because while there
    was no label column I'm trying to predictã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›äº‹ç‰©ä»£è¡¨äº†æˆ‘ç½‘é¡µåº”ç”¨ç¨‹åºä¸­çš„ä¸åŒç”¨æˆ·ï¼Œç„¶åå¦‚æœæˆ‘å¯ä»¥è¯´ï¼Œå˜¿ã€‚è™½ç„¶æˆ‘çš„åº”ç”¨ç¨‹åºæœ‰è¿™10ç§ä¸åŒç±»å‹çš„ç½‘ç»œç”¨æˆ·ã€‚æˆ‘å¯èƒ½å¯ä»¥ä¸ºæ¯ä¸ªä¸åŒçš„ç¾¤ä½“å¼€å±•ä¸åŒçš„è¥é”€æ´»åŠ¨ã€‚å¥½çš„ã€‚æ‰€ä»¥èšç±»å†æ¬¡æ˜¯æ— ç›‘ç£çš„ï¼Œä¹‹æ‰€ä»¥æ˜¯æ— ç›‘ç£çš„ï¼Œå› ä¸ºè™½ç„¶æ²¡æœ‰æ ‡ç­¾åˆ—ï¼Œä½†æˆ‘åœ¨å°è¯•é¢„æµ‹ã€‚
- en: The last kind of machine learning problem when I talk about this semester and
    which is probably the most complicated is called a decomposition and and decomposition
    is also unsupervised is againã€‚ rightï¼Œ there's no column I'm trying to predict
    hereã€‚And the idea with a decomposition is that I'm going to look through all these
    rows and see if there's any patternã€‚ are there kind of a couple archtype rows
    that really can be mixed together to create other thingsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘è°ˆè®ºæœ¬å­¦æœŸçš„æœ€åä¸€ç§æœºå™¨å­¦ä¹ é—®é¢˜æ—¶ï¼Œå¯èƒ½æ˜¯æœ€å¤æ‚çš„ï¼Œç§°ä¸ºåˆ†è§£ï¼Œè€Œåˆ†è§£ä¹Ÿæ˜¯æ— ç›‘ç£çš„ã€‚å¯¹å§ï¼Œè¿™é‡Œæ²¡æœ‰æˆ‘è¯•å›¾é¢„æµ‹çš„åˆ—ã€‚åˆ†è§£çš„æ€æƒ³æ˜¯æˆ‘ä¼šæŸ¥çœ‹æ‰€æœ‰è¿™äº›è¡Œï¼Œçœ‹çœ‹æ˜¯å¦æœ‰ä»»ä½•æ¨¡å¼ã€‚æ˜¯å¦æœ‰å‡ ç§åŸå‹è¡Œå¯ä»¥çœŸæ­£æ··åˆåœ¨ä¸€èµ·ä»¥åˆ›å»ºå…¶ä»–ä¸œè¥¿ã€‚
- en: so maybe what I see is that with some small error most of these rows are just
    combinations of these three rows over here and I would call these my component
    rowsã€‚ So you notice the columns are the same right between my original data and
    my component rowsã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä¹Ÿè®¸æˆ‘çœ‹åˆ°çš„æ˜¯ï¼Œå¸¦æœ‰ä¸€äº›å°é”™è¯¯çš„å¤§å¤šæ•°è¡Œåªæ˜¯è¿™ä¸‰è¡Œçš„ç»„åˆï¼Œæˆ‘ä¼šç§°è¿™äº›ä¸ºæˆ‘çš„ç»„æˆè¡Œã€‚æ‰€ä»¥ä½ ä¼šæ³¨æ„åˆ°æˆ‘çš„åŸå§‹æ•°æ®å’Œæˆ‘çš„ç»„æˆè¡Œä¹‹é—´çš„åˆ—æ˜¯ç›¸åŒçš„ã€‚
- en: And then to get this row hereï¼Œ like negative 11ï¼Œ negative 7ï¼Œ 3ï¼Œ 2020ã€‚ what I
    would do is I would multiply this row by negative V 11ã€‚And then add it to 21 times
    this row and then add it to negative8 times this row right so I'm kind of taking
    a weighted average of these three rowsã€‚To produce this row and if you actually
    crunch these numbers you'd see that I would just something kind of similar to
    thisã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä¸ºäº†å¾—åˆ°è¿™ä¸€è¡Œï¼Œæ¯”å¦‚è´Ÿ11ï¼Œè´Ÿ7ï¼Œ3ï¼Œ2020ã€‚æˆ‘ä¼šå°†è¿™ä¸€è¡Œä¹˜ä»¥è´ŸV 11ï¼Œç„¶ååŠ ä¸Š21ä¹˜ä»¥è¿™ä¸€è¡Œï¼Œå†åŠ ä¸Šè´Ÿ8ä¹˜ä»¥è¿™ä¸€è¡Œã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘åœ¨å¯¹è¿™ä¸‰è¡Œè¿›è¡ŒåŠ æƒå¹³å‡ï¼Œä»¥äº§ç”Ÿè¿™ä¸€è¡Œã€‚å¦‚æœä½ å®é™…è®¡ç®—è¿™äº›æ•°å­—ï¼Œä½ ä¼šçœ‹åˆ°æˆ‘å¾—åˆ°çš„ç»“æœä¸è¿™ä¸ªç±»ä¼¼ã€‚
- en: but there would be some error right it's not a perfect match which is fine I
    mean the fewer components I have well then I kind of have a simpler model but
    while there might be more errorã€‚So so I have that here and I have these numbers
    here and what we'll generally do when I'm trying to mix these components to create
    a row is I'll put these numbers in another table down hereã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¼šæœ‰ä¸€äº›é”™è¯¯ï¼Œå¯¹å§ï¼Ÿè¿™ä¸æ˜¯ä¸€ä¸ªå®Œç¾çš„åŒ¹é…ï¼Œè¿™æ²¡å…³ç³»ï¼Œæˆ‘çš„ç»„æˆéƒ¨åˆ†è¶Šå°‘ï¼Œæˆ‘å°±ä¼šæœ‰ä¸€ä¸ªæ›´ç®€å•çš„æ¨¡å‹ï¼Œä½†å¯èƒ½ä¼šæœ‰æ›´å¤šçš„é”™è¯¯ã€‚æ‰€ä»¥æˆ‘åœ¨è¿™é‡Œæœ‰è¿™äº›æ•°å­—ï¼Œå½“æˆ‘è¯•å›¾æ··åˆè¿™äº›ç»„ä»¶ä»¥åˆ›å»ºä¸€è¡Œæ—¶ï¼Œæˆ‘é€šå¸¸ä¼šæŠŠè¿™äº›æ•°å­—æ”¾åœ¨ä¸‹é¢çš„å¦ä¸€ä¸ªè¡¨ä¸­ã€‚
- en: so this will be a table of all my weights or maybe my principal component scores
    and so I'll put you know negative 11 hereã€‚ 21 here and then negative8 here and
    then for this next row down here right I'll do the same thing I'll say a negative
    43 hereã€‚ 12 here and then the negative6 here and so since I'm doing this I'm putting
    kind of these mixtures for every row down here down hereã€‚ what that means is that
    if there's n rows over hereã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°†æ˜¯æˆ‘æ‰€æœ‰æƒé‡çš„è¡¨ï¼Œæˆ–è€…è¯´æˆ‘çš„ä¸»æˆåˆ†å¾—åˆ†ï¼Œå› æ­¤æˆ‘ä¼šåœ¨è¿™é‡Œå†™ä¸Šè´Ÿ11ï¼Œåœ¨è¿™é‡Œå†™ä¸Š21ï¼Œç„¶ååœ¨è¿™é‡Œå†™ä¸Šè´Ÿ8ï¼Œç„¶åå¯¹äºä¸‹é¢çš„è¿™ä¸€è¡Œï¼Œæˆ‘ä¼šåšåŒæ ·çš„äº‹æƒ…ï¼Œæˆ‘ä¼šåœ¨è¿™é‡Œå†™ä¸Šè´Ÿ43ï¼Œåœ¨è¿™é‡Œå†™ä¸Š12ï¼Œç„¶ååœ¨è¿™é‡Œå†™ä¸Šè´Ÿ6ã€‚æ‰€ä»¥ç”±äºæˆ‘åœ¨è¿™æ ·åšï¼Œæˆ‘åœ¨è¿™é‡Œä¸ºæ¯ä¸€è¡Œæ”¾å…¥è¿™äº›æ··åˆã€‚è¿™æ„å‘³ç€å¦‚æœè¿™é‡Œæœ‰nè¡Œã€‚
- en: Then there are also going to be N rows over here if there are M columns over
    hereã€‚ well then there would be M columns over hereï¼Œ so basically what I can do
    is I can take this big table and I can reduce it to having some components here
    I can have some weights here it's useful for lots of things one is just if I'm
    trying to save space on my storage system right I can have these things be smaller
    but then it's also nice if I'm trying to do other phases of machine learning like
    a classification or regression it's kind of nice if I only have like three feature
    columns instead of the original five that's trying to help me in a number of casesã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¦‚æœè¿™é‡Œæœ‰Nè¡Œï¼Œé‚£é‡Œæœ‰Måˆ—ã€‚é‚£ä¹ˆé‚£è¾¹ä¹Ÿä¼šæœ‰Måˆ—ã€‚å› æ­¤ï¼ŒåŸºæœ¬ä¸Šæˆ‘å¯ä»¥å°†è¿™ä¸ªå¤§è¡¨æ ¼å‡å°‘åˆ°ä¸€äº›ç»„ä»¶ï¼Œæˆ‘å¯ä»¥åœ¨è¿™é‡Œæœ‰ä¸€äº›æƒé‡ï¼Œè¿™å¯¹è®¸å¤šäº‹æƒ…éƒ½æœ‰ç”¨ï¼Œå…¶ä¸­ä¹‹ä¸€å°±æ˜¯å¦‚æœæˆ‘æƒ³åœ¨æˆ‘çš„å­˜å‚¨ç³»ç»Ÿä¸ŠèŠ‚çœç©ºé—´ï¼Œæˆ‘å¯ä»¥è®©è¿™äº›ä¸œè¥¿å˜å¾—æ›´å°ï¼Œä½†å¦‚æœæˆ‘è¯•å›¾è¿›è¡Œæœºå™¨å­¦ä¹ çš„å…¶ä»–é˜¶æ®µï¼Œæ¯”å¦‚åˆ†ç±»æˆ–å›å½’ï¼Œå¦‚æœæˆ‘åªæœ‰ä¸‰ä¸ªç‰¹å¾åˆ—è€Œä¸æ˜¯åŸæ¥çš„äº”ä¸ªï¼Œé‚£åœ¨è®¸å¤šæƒ…å†µä¸‹å¯¹æˆ‘æœ‰æ‰€å¸®åŠ©ã€‚
- en: Okayï¼Œ so that's a whirlwind tour of these four poems where I solve regressionã€‚
    classificationificationï¼Œ those are both supervised because again it's labeledï¼Œ
    clustersteringã€‚ decompositionï¼Œ there is no column we're trying to predict that's
    unlabeledï¼Œ it's unsupervisedã€‚Learning and and so for each of these four things
    there's actually a ton of different algorithms out there and and in this semester
    we only really have time to learn like one algorithm for each of them and so if
    I go to this website down here this is the website for PsyH Learn which is the
    module we're going to be learningã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™å°±æ˜¯å¯¹è¿™å››é¦–è¯—çš„å¿«é€Ÿæ¦‚è¿°ï¼Œå…¶ä¸­æˆ‘è§£å†³äº†å›å½’ã€åˆ†ç±»ï¼Œè¿™ä¸¤è€…éƒ½æ˜¯ç›‘ç£å­¦ä¹ ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æœ‰æ ‡ç­¾çš„ï¼Œè€Œèšç±»å’Œåˆ†è§£åˆ™æ˜¯æ— ç›‘ç£çš„ï¼Œå› ä¸ºæ²¡æœ‰è¦é¢„æµ‹çš„æ— æ ‡ç­¾åˆ—ã€‚å¯¹äºè¿™å››ä¸ªä¸»é¢˜ï¼Œå…¶å®æœ‰å¾ˆå¤šä¸åŒçš„ç®—æ³•ï¼Œè€Œåœ¨è¿™ä¸ªå­¦æœŸæˆ‘ä»¬åªä¼šå­¦ä¹ æ¯ä¸ªä¸»é¢˜çš„ä¸€ä¸ªç®—æ³•ï¼Œæ‰€ä»¥å¦‚æœæˆ‘è®¿é—®ä¸‹é¢è¿™ä¸ªç½‘ç«™ï¼Œè¿™æ˜¯æˆ‘ä»¬å°†è¦å­¦ä¹ çš„PsyH
    Learnæ¨¡å—çš„ç½‘ç«™ã€‚
- en: ğŸ˜Šï¼ŒAnd there's probably close to hundreds of different algorithms or different
    classes they have thereã€‚ I put a small subset under here and so I can see well
    here's all these different things they have for clustering and we're going to
    just learn one of those which is k means clusteringã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œå¯èƒ½æœ‰æ¥è¿‘æ•°ç™¾ç§ä¸åŒçš„ç®—æ³•æˆ–ä¸åŒçš„ç±»åˆ«ã€‚æˆ‘åœ¨è¿™é‡Œåˆ—å‡ºäº†ä¸€ä¸ªå°å­é›†ï¼Œå› æ­¤æˆ‘å¯ä»¥çœ‹åˆ°ï¼Œå…³äºèšç±»çš„æ‰€æœ‰ä¸åŒå†…å®¹ï¼Œæˆ‘ä»¬å°†åªå­¦ä¹ å…¶ä¸­ä¸€ä¸ªï¼Œé‚£å°±æ˜¯Kå‡å€¼èšç±»ã€‚
- en: decompositionï¼Œ all these different things I can doï¼Œ we're going to learn just
    one of themã€‚ which is PCAã€‚It turns out that for a lot of algorithmsã€‚ the classification
    and regression common pairsï¼Œ so for exampleã€‚Here I have like a decision tree classifier
    here I have a decision tree regressorã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ†è§£æ–¹é¢ï¼Œæˆ‘èƒ½åšçš„æ‰€æœ‰ä¸åŒçš„äº‹æƒ…ï¼Œæˆ‘ä»¬å°†åªå­¦ä¹ å…¶ä¸­ä¸€ä¸ªï¼Œé‚£å°±æ˜¯PCAã€‚äº‹å®è¯æ˜ï¼Œå¯¹äºå¾ˆå¤šç®—æ³•ï¼Œåˆ†ç±»å’Œå›å½’æ˜¯å¸¸è§çš„é…å¯¹ï¼Œä¾‹å¦‚ï¼Œè¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªå†³ç­–æ ‘åˆ†ç±»å™¨ï¼Œè¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªå†³ç­–æ ‘å›å½’å™¨ã€‚
- en: Here I have a K neighbors classifier here I have a K neighbors regressor and
    that's why I didn't kind of split these out and I just put both of these under
    these two categories and so we're going to learn two things here we're going to
    learn logistic regression and we're going to learn linear regression and this
    is a little bit confusing becauseã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªKé‚»å±…åˆ†ç±»å™¨ï¼Œè¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªKé‚»å±…å›å½’å™¨ï¼Œå› æ­¤æˆ‘æ²¡æœ‰æŠŠè¿™äº›åˆ†å¼€ï¼Œè€Œæ˜¯å°†å®ƒä»¬æ”¾åœ¨è¿™ä¸¤ä¸ªç±»åˆ«ä¸‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åœ¨è¿™é‡Œå­¦ä¹ ä¸¤ä¸ªå†…å®¹ï¼Œæˆ‘ä»¬å°†å­¦ä¹ é€»è¾‘å›å½’å’Œçº¿æ€§å›å½’ï¼Œè¿™æœ‰ç‚¹ä»¤äººå›°æƒ‘ï¼Œå› ä¸ºã€‚
- en: Well this part's obviousï¼Œ right the linear regression is going to be a regression
    hereã€‚ this is the one that people get confusedfused on because even though it
    says regression in the nameã€‚ it is not a regressionï¼Œ it's actually classification
    right so these are the four things we're going to be learning this semester and
    logistic regression is when people always get infused on because well it's not
    actually a regressionã€‚And I think once we learn all these thingsï¼Œ the very nice
    thing is that the interface to using the other ones is relatively simpleã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éƒ¨åˆ†å¾ˆæ˜æ˜¾ï¼Œçº¿æ€§å›å½’åœ¨è¿™é‡Œå°±æ˜¯å›å½’ã€‚è¿™æ˜¯ä¸€ä¸ªäººä»¬å®¹æ˜“æ··æ·†çš„åœ°æ–¹ï¼Œå› ä¸ºå°½ç®¡å®ƒçš„åç§°ä¸­æœ‰å›å½’ï¼Œä½†å®é™…ä¸Šå®ƒå¹¶ä¸æ˜¯å›å½’ï¼Œè€Œæ˜¯åˆ†ç±»ã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬è¿™ä¸ªå­¦æœŸå°†è¦å­¦ä¹ çš„å››ä¸ªå†…å®¹ï¼Œè€Œé€»è¾‘å›å½’æ€»æ˜¯è®©äººå›°æƒ‘ï¼Œå› ä¸ºå®ƒå®é™…ä¸Šå¹¶ä¸æ˜¯å›å½’ã€‚æˆ‘è®¤ä¸ºä¸€æ—¦æˆ‘ä»¬å­¦ä¹ äº†æ‰€æœ‰è¿™äº›ï¼Œä½¿ç”¨å…¶ä»–ç®—æ³•çš„æ¥å£å°±ä¼šç›¸å¯¹ç®€å•ã€‚
- en: So for exampleï¼Œ once you know how to use a linear regressionã€‚You could very
    easily just replace the word linear regression with Ridge and you're still going
    to be able to do all your machine learning stuff correctly now before you do that
    you should probably learn about how Ridge works and then think about which model
    is best for youã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸€æ—¦ä½ çŸ¥é“å¦‚ä½•ä½¿ç”¨çº¿æ€§å›å½’ï¼Œä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†â€œçº¿æ€§å›å½’â€æ›¿æ¢ä¸ºâ€œå²­å›å½’â€ï¼Œä½ ä»ç„¶èƒ½å¤Ÿæ­£ç¡®åœ°è¿›è¡Œæ‰€æœ‰æœºå™¨å­¦ä¹ çš„å·¥ä½œã€‚åœ¨ä½ è¿™æ ·åšä¹‹å‰ï¼Œæœ€å¥½äº†è§£å²­å›å½’çš„å·¥ä½œåŸç†ï¼Œç„¶åæ€è€ƒå“ªä¸ªæ¨¡å‹æœ€é€‚åˆä½ ã€‚
- en: but at least in terms of the code it's very simple to switch between different
    modelsã€‚I without any any of these four categoriesã€‚So I want to talk a little bitã€‚
    that was pretty high levelï¼Œ I want to talk a little bit about the foundations
    where I need to be learning this machine learning both in terms of the code and
    then also the mathã€‚Where I learn a few different modulesï¼Œ the main one is atsyKt
    Learnã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘åœ¨ä»£ç æ–¹é¢ï¼Œåˆ‡æ¢ä¸åŒæ¨¡å‹æ˜¯éå¸¸ç®€å•çš„ï¼Œè€Œä¸éœ€è¦è€ƒè™‘è¿™å››ä¸ªç±»åˆ«ã€‚æˆ‘æƒ³å¤šè°ˆè°ˆï¼Œè¿™äº›éƒ½æ˜¯æ¯”è¾ƒé«˜å±‚æ¬¡çš„å†…å®¹ï¼Œæˆ‘æƒ³è°ˆè°ˆåŸºç¡€çŸ¥è¯†ï¼Œæˆ‘éœ€è¦å­¦ä¹ çš„æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬ä»£ç å’Œæ•°å­¦æ–¹é¢ã€‚æˆ‘å­¦ä¹ äº†å‡ ä¸ªä¸åŒçš„æ¨¡å—ï¼Œä¸»è¦çš„æ˜¯`scikit-learn`ã€‚
- en: I would showing you some documentation from PsyKt Learnã€‚We're also gonna learn
    nuyï¼Œ which hasã€‚ lets us deal with matricesã€‚ It turns out that nuyã€‚Numpy is really
    the foundation for pandas rightã€‚ all panda data is actually stored in Numpy and
    now will be a good time for us to actually see thatã€‚And then when I learned this
    thing called Pytorch and Pytorrch can do a couple things for usã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ç»™ä½ å±•ç¤ºä¸€äº›æ¥è‡ª PsyKt Learn çš„æ–‡æ¡£ã€‚æˆ‘ä»¬è¿˜å°†å­¦ä¹  nuyï¼Œå®ƒå¯ä»¥è®©æˆ‘ä»¬å¤„ç†çŸ©é˜µã€‚äº‹å®è¯æ˜ï¼Œnuyï¼ŒNumpy å®é™…ä¸Šæ˜¯ pandas
    çš„åŸºç¡€ï¼Œæ²¡é”™ï¼Œæ‰€æœ‰çš„ pandas æ•°æ®å®é™…ä¸Šå­˜å‚¨åœ¨ Numpy ä¸­ï¼Œç°åœ¨æ˜¯æˆ‘ä»¬å®é™…çœ‹åˆ°è¿™ä¸€ç‚¹çš„å¥½æ—¶æœºã€‚ç„¶åå½“æˆ‘å­¦ä¹ äº†è¿™ä¸ªå« Pytorch çš„ä¸œè¥¿æ—¶ï¼ŒPytorch
    å¯ä»¥ä¸ºæˆ‘ä»¬åšå‡ ä»¶äº‹æƒ…ã€‚
- en: one is it can do calculus for usï¼Œ which is pretty coolã€‚Another thing it can
    let us do is it can actually let us run our code on GPUsã€‚ which are graphics processing
    unitsï¼Œ everything we've been running so far this semester has been running on
    CPUsã€‚ right your central processing unitã€‚And and it turns out that GPUs that originally
    built for graphics also happen to be really good at machine learning and so a
    lot of things if you're dealing with a lot of data or kind of complex modelsã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ˜¯å®ƒå¯ä»¥ä¸ºæˆ‘ä»¬è¿›è¡Œå¾®ç§¯åˆ†ï¼Œè¿™éå¸¸é…·ã€‚å¦ä¸€ä¸ªå®ƒå¯ä»¥è®©æˆ‘ä»¬åšçš„äº‹æƒ…æ˜¯å®ƒå®é™…ä¸Šå¯ä»¥è®©æˆ‘ä»¬åœ¨ GPU ä¸Šè¿è¡Œä»£ç ï¼Œè¿™äº›æ˜¯å›¾å½¢å¤„ç†å•å…ƒï¼Œæˆ‘ä»¬è¿™ä¸€å­¦æœŸåˆ°ç›®å‰ä¸ºæ­¢æ‰€æœ‰çš„è¿è¡Œéƒ½æ˜¯åœ¨
    CPU ä¸Šè¿›è¡Œçš„ï¼Œæ²¡é”™ï¼Œå°±æ˜¯ä½ çš„ä¸­å¤®å¤„ç†å•å…ƒã€‚ç»“æœå‘ç°ï¼ŒåŸæœ¬ä¸ºå›¾å½¢æ„å»ºçš„ GPU åœ¨æœºå™¨å­¦ä¹ æ–¹é¢ä¹Ÿè¡¨ç°å¾—éå¸¸å¥½ï¼Œå› æ­¤ï¼Œå¦‚æœä½ å¤„ç†å¤§é‡æ•°æ®æˆ–å¤æ‚æ¨¡å‹æ—¶ï¼Œå®ƒä»¬ä¼šéå¸¸æœ‰ç”¨ã€‚
- en: a GPU will be better at itã€‚Where I have to learn a little bit of mathã€‚ I'm not
    assuming you have any math background besides what you might learn in high schoolã€‚
    but let me give you an example of how math is going to come into play here for
    a regression problem right so we have this example again with all the houses and
    these characteristics and then we have a function that predicts the priceã€‚How
    would we do that with matricesï¼Œ well I might take all these numbers in the data
    frame and put them in this matrix hereï¼Ÿ
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPU ä¼šæ›´å¥½ã€‚æˆ‘è¦å­¦ä¹ ä¸€ç‚¹æ•°å­¦ã€‚æˆ‘å¹¶ä¸å‡è®¾ä½ æœ‰ä»»ä½•æ•°å­¦èƒŒæ™¯ï¼Œé™¤äº†ä½ å¯èƒ½åœ¨é«˜ä¸­å­¦åˆ°çš„å†…å®¹ï¼Œä½†è®©æˆ‘ç»™ä½ ä¸€ä¸ªä¾‹å­ï¼Œè¯´æ˜æ•°å­¦åœ¨è¿™é‡Œå¦‚ä½•åº”ç”¨äºå›å½’é—®é¢˜ã€‚å› æ­¤æˆ‘ä»¬å†æ¬¡ä»¥æ‰€æœ‰æˆ¿å±‹åŠå…¶ç‰¹å¾çš„ä¾‹å­ä¸ºåŸºç¡€ï¼Œç„¶åæˆ‘ä»¬æœ‰ä¸€ä¸ªé¢„æµ‹ä»·æ ¼çš„å‡½æ•°ã€‚æˆ‘ä»¬å¦‚ä½•ç”¨çŸ©é˜µæ¥åšåˆ°è¿™ä¸€ç‚¹å‘¢ï¼Ÿæˆ‘å¯èƒ½ä¼šå°†æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰è¿™äº›æ•°å­—æ”¾å…¥è¿™ä¸ªçŸ©é˜µä¸­ã€‚
- en: And then for my functionï¼Œ I may have kind of just an algebraic expression which
    is using matricesã€‚ So my x here is this matrix C is a vectorï¼Œ B is just a number
    And when I run this well I'm going to get this other vector out here which actually
    has all all the prices so to understand what's going on here and we have to learn
    a little bit of linear algebraã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¹äºæˆ‘çš„å‡½æ•°ï¼Œæˆ‘å¯èƒ½åªæ˜¯æœ‰ä¸€ä¸ªä½¿ç”¨çŸ©é˜µçš„ä»£æ•°è¡¨è¾¾å¼ã€‚å› æ­¤ï¼Œæˆ‘è¿™é‡Œçš„ x æ˜¯è¿™ä¸ªçŸ©é˜µï¼ŒC æ˜¯ä¸€ä¸ªå‘é‡ï¼ŒB åªæ˜¯ä¸€ä¸ªæ•°å­—ã€‚å½“æˆ‘è¿è¡Œè¿™ä¸ªæ—¶ï¼Œæˆ‘å°†å¾—åˆ°å¦ä¸€ä¸ªå‘é‡ï¼Œå®é™…ä¸ŠåŒ…å«æ‰€æœ‰çš„ä»·æ ¼ã€‚å› æ­¤ï¼Œä¸ºäº†ç†è§£è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬å¿…é¡»å­¦ä¹ ä¸€ç‚¹çº¿æ€§ä»£æ•°ã€‚
- en: this is not a regular multiplicationï¼Œ it's actually something called the dot
    product and it looks like this right I can take this X matrix hereã€‚Dot product
    with this vector and then add a number and then that's how'm going to get my results
    over here on the righthand side do one prediction and what's cool is that if I
    can do one row times times this vector here and I get one house value and it's
    going to go through without having a loop even the beauty of linear your algebra
    and multiplying matrices together with the dot product is that do in one step
    and I'm going get actually all of these numbers the code for it is pretty simple
    if I say data frame of values then x is actually going to be a nuy array and if
    I want to I can just say well I want the dot product of these two things and I
    want to add B and it just work so we're going be talking about that in quite a
    bit more detail at some point before the end of the semesterã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯å¸¸è§„çš„ä¹˜æ³•ï¼Œå®ƒå®é™…ä¸Šæ˜¯è¢«ç§°ä¸ºç‚¹ç§¯çš„ä¸œè¥¿ï¼Œçœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼Œæˆ‘å¯ä»¥å°†è¿™ä¸ª X çŸ©é˜µä¸è¿™ä¸ªå‘é‡è¿›è¡Œç‚¹ç§¯ï¼Œç„¶ååŠ ä¸Šä¸€ä¸ªæ•°å­—ï¼Œç„¶åè¿™å°±æ˜¯æˆ‘å°†å¦‚ä½•åœ¨å³ä¾§è·å¾—æˆ‘çš„ç»“æœï¼Œè¿›è¡Œä¸€æ¬¡é¢„æµ‹ï¼Œä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå¦‚æœæˆ‘å¯ä»¥å°†ä¸€è¡Œä¸è¿™ä¸ªå‘é‡ç›¸ä¹˜ï¼Œæˆ‘å°±å¾—åˆ°äº†ä¸€ä¸ªæˆ¿å±‹çš„ä»·å€¼ï¼Œå¹¶ä¸”è¿™ä¼šåœ¨æ²¡æœ‰å¾ªç¯çš„æƒ…å†µä¸‹è¿›è¡Œï¼Œçº¿æ€§ä»£æ•°å’Œé€šè¿‡ç‚¹ç§¯ç›¸ä¹˜çŸ©é˜µçš„ç¾å¦™ä¹‹å¤„åœ¨äºï¼Œè¿™å¯ä»¥ä¸€æ­¥å®Œæˆï¼Œæˆ‘å®é™…ä¸Šä¼šå¾—åˆ°æ‰€æœ‰è¿™äº›æ•°å­—ã€‚ä»£ç éå¸¸ç®€å•ï¼Œå¦‚æœæˆ‘è¯´æ•°æ®æ¡†çš„å€¼ï¼Œé‚£ä¹ˆ
    x å®é™…ä¸Šå°†æ˜¯ä¸€ä¸ª nuy æ•°ç»„ï¼Œå¦‚æœæˆ‘æƒ³çš„è¯ï¼Œæˆ‘å¯ä»¥è¯´æˆ‘æƒ³è¦è¿™ä¸¤ä¸ªä¸œè¥¿çš„ç‚¹ç§¯ï¼Œå¹¶ä¸”æˆ‘æƒ³è¦åŠ ä¸Š Bï¼Œè¿™æ ·å°±èƒ½æ­£å¸¸å·¥ä½œã€‚å› æ­¤åœ¨å­¦æœŸç»“æŸå‰çš„æŸä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬ä¼šå¯¹æ­¤è¿›è¡Œæ›´å¤šè¯¦ç»†çš„è®¨è®ºã€‚
- en: One thing I want to note is that if you're reading other documentationã€‚ a lot
    of resources will use A instead of Xsï¼Œ which I find confusingã€‚ I think that's
    not intuitive if you're kind of working on all of thesesyKt learn modules because
    those will generally use x for data and then even stranger we'll often have a
    C when we're in PsyKt learn but then they call that little acts instead so just
    be you know as we're learning linear algebra stuffã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œå¦‚æœä½ åœ¨é˜…è¯»å…¶ä»–æ–‡æ¡£ï¼Œå¾ˆå¤šèµ„æºä¼šä½¿ç”¨Aè€Œä¸æ˜¯Xsï¼Œæˆ‘è§‰å¾—è¿™å¾ˆè®©äººå›°æƒ‘ã€‚å¦‚æœä½ æ­£åœ¨ç ”ç©¶è¿™äº›syKtå­¦ä¹ æ¨¡å—ï¼Œè¿™æ ·å¹¶ä¸ç›´è§‚ï¼Œå› ä¸ºè¿™äº›é€šå¸¸ä¼šä½¿ç”¨xè¡¨ç¤ºæ•°æ®ï¼Œè€Œæ›´å¥‡æ€ªçš„æ˜¯ï¼Œåœ¨PsyKtå­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæœ‰ä¸€ä¸ªCï¼Œä½†ä»–ä»¬ä¼šæŠŠå®ƒç§°ä¸ºå°xï¼Œæ‰€ä»¥åœ¨æˆ‘ä»¬å­¦ä¹ çº¿æ€§ä»£æ•°çš„è¿‡ç¨‹ä¸­è¦ä¿æŒæ¸…é†’ã€‚
- en: I just want to say upfront and I'll say it again be aware that the variable
    names are a little bit wackyã€‚So what is kind of the scope of linear algebra and
    what kind of things are we trying to solve Well one thing that we're not going
    to solve is something like this y equals x squared that is not linear anything
    quadratic or cubic or anything like that not linear really all we can do is multiply
    multiply variables by numbers and then add things off right so this is an example
    of a linear equation right I just have I have some different variablesã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æå‰è¯´æ¸…æ¥šï¼Œæˆ‘ä¼šå†è¯´ä¸€éï¼Œè¦æ³¨æ„å˜é‡åç§°æœ‰ç‚¹å¥‡æ€ªã€‚é‚£ä¹ˆçº¿æ€§ä»£æ•°çš„èŒƒå›´æ˜¯ä»€ä¹ˆï¼Œæˆ‘ä»¬è¯•å›¾è§£å†³å“ªäº›é—®é¢˜å‘¢ï¼Ÿæˆ‘ä»¬ä¸ä¼šè§£å†³ç±»ä¼¼äºyç­‰äºxå¹³æ–¹çš„ä¸œè¥¿ï¼Œé‚£ä¸æ˜¯çº¿æ€§çš„ï¼Œä»»ä½•äºŒæ¬¡æˆ–ä¸‰æ¬¡æ–¹çš„ä¸œè¥¿éƒ½ä¸æ˜¯çº¿æ€§çš„ï¼Œå®é™…ä¸Šæˆ‘ä»¬èƒ½åšçš„å°±æ˜¯å°†å˜é‡ä¹˜ä»¥æ•°å­—ï¼Œç„¶åå†åŠ èµ·æ¥ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªçº¿æ€§æ–¹ç¨‹çš„ä¾‹å­ï¼Œæˆ‘æœ‰ä¸€äº›ä¸åŒçš„å˜é‡ã€‚
- en: And then I'm multiplying them by different numbers one of the things where I
    notice is that the way we're going to be doing linear algebra in this course is
    we actually have very big matrices and at a lot of variables and a lot of equations
    right so you can see here I actually have 50 variables so I think the key takeaway
    is that more variables more data but simpler equationsã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘å°†å®ƒä»¬ä¹˜ä»¥ä¸åŒçš„æ•°å­—ï¼Œæˆ‘æ³¨æ„åˆ°æˆ‘ä»¬åœ¨è¿™é—¨è¯¾ä¸­è¿›è¡Œçº¿æ€§ä»£æ•°çš„æ–¹å¼æ˜¯æˆ‘ä»¬å®é™…ä¸Šæœ‰éå¸¸å¤§çš„çŸ©é˜µï¼Œå¾ˆå¤šå˜é‡å’Œå¾ˆå¤šæ–¹ç¨‹ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œæˆ‘å®é™…ä¸Šæœ‰50ä¸ªå˜é‡ï¼Œæ‰€ä»¥å…³é”®è¦ç‚¹æ˜¯ï¼Œæ›´å¤šçš„å˜é‡æ„å‘³ç€æ›´å¤šçš„æ•°æ®ï¼Œä½†æ–¹ç¨‹æ›´ç®€å•ã€‚
- en: what about calculus so here I have that situation again with the house where
    I have some training dataã€‚ so I have both my features and my labelï¼Œ it draws into
    an algorithm and that algorithm will basically spit out this formula for me that
    I can use to predict housing pricesã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå¾®ç§¯åˆ†ï¼Œè¿™é‡Œæˆ‘å†æ¬¡é‡åˆ°æˆ¿å­çš„æƒ…å†µï¼Œæˆ‘æœ‰ä¸€äº›è®­ç»ƒæ•°æ®ã€‚æ‰€ä»¥æˆ‘æœ‰æˆ‘çš„ç‰¹å¾å’Œæ ‡ç­¾ï¼Œå®ƒä¼šå¼•å…¥ä¸€ä¸ªç®—æ³•ï¼Œè¯¥ç®—æ³•åŸºæœ¬ä¸Šä¼šä¸ºæˆ‘è¾“å‡ºè¿™ä¸ªå…¬å¼ï¼Œæˆ‘å¯ä»¥ç”¨æ¥é¢„æµ‹æˆ¿ä»·ã€‚
- en: Rightã€‚Nowï¼Œ it turns out that when I was doing this trainingï¼Œ rightã€‚ I had the
    original prices and the new prices might be a little bit different right This
    is 140ã€‚ this is 190ï¼Œ240ï¼Œ254 rightï¼Œ They're all a little bit differentã€‚ And so
    what I can do is for this given equation I end up withã€‚I can have some sort of
    functionã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ã€‚ç°åœ¨ï¼Œäº‹å®è¯æ˜ï¼Œå½“æˆ‘è¿›è¡Œè®­ç»ƒæ—¶ï¼Œæˆ‘æœ‰åŸå§‹ä»·æ ¼ï¼Œè€Œæ–°ä»·æ ¼å¯èƒ½æœ‰ä¸€ç‚¹ä¸åŒï¼Œå¯¹å§ï¼Ÿè¿™æ˜¯140ã€‚è¿™æ˜¯190ã€240ã€254ï¼Œå¯¹å§ï¼Œå®ƒä»¬éƒ½ç¨å¾®æœ‰äº›ä¸åŒã€‚å› æ­¤ï¼Œå¯¹äºè¿™ä¸ªç»™å®šçš„æ–¹ç¨‹ï¼Œæˆ‘æœ€ç»ˆä¼šæœ‰æŸç§å‡½æ•°ã€‚
- en: total loss function that compares the correct answer with my model's answersï¼Œ
    rightã€‚ so I compare these two and I get one number out right that's kind like
    what my error is or how bad it isã€‚And of courseï¼Œ how bad it is really depends
    on kind of the numbers that are part of this equation down hereã€‚ so the whole
    idea of this training thing with this algorithm is that I want to find outï¼Œ wellã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»æŸå¤±å‡½æ•°æ¯”è¾ƒæ­£ç¡®ç­”æ¡ˆä¸æˆ‘æ¨¡å‹çš„ç­”æ¡ˆï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥æˆ‘æ¯”è¾ƒè¿™ä¸¤ä¸ªï¼Œå¾—åˆ°ä¸€ä¸ªæ•°å€¼å‡ºæ¥ï¼Œè¿™å°±åƒæ˜¯æˆ‘çš„è¯¯å·®æˆ–å®ƒæœ‰å¤šç³Ÿç³•ã€‚å½“ç„¶ï¼Œå®ƒçš„ç³Ÿç³•ç¨‹åº¦å®é™…ä¸Šå–å†³äºè¿™ä¸ªæ–¹ç¨‹ä¸‹é¢çš„æ•°å­—ã€‚æ‰€ä»¥è¿™ä¸ªè®­ç»ƒç®—æ³•çš„æ•´ä¸ªæƒ³æ³•æ˜¯ï¼Œæˆ‘æƒ³æ‰¾å‡ºï¼Œå—¯ã€‚
- en: what see can I do that is going to make my error or my loss as small as possible
    so we're trying to minimize something and I don't expect you if they can calculusã€‚
    but I know a lot of you have and in calculus we're often trying to minimize or
    maximize thingsï¼Ÿ
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘èƒ½åšä»€ä¹ˆæ‰èƒ½è®©æˆ‘çš„è¯¯å·®æˆ–æŸå¤±å°½å¯èƒ½å°ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯•å›¾æœ€å°åŒ–æŸç§ä¸œè¥¿ï¼Œæˆ‘ä¸æŒ‡æœ›ä½ ä»¬éƒ½èƒ½åšå¾®ç§¯åˆ†ã€‚ä½†æˆ‘çŸ¥é“ä½ ä»¬ä¸­çš„è®¸å¤šäººéƒ½å­¦è¿‡ï¼Œè€Œåœ¨å¾®ç§¯åˆ†ä¸­æˆ‘ä»¬é€šå¸¸è¯•å›¾æœ€å°åŒ–æˆ–æœ€å¤§åŒ–æŸäº›ä¸œè¥¿ï¼Ÿ
- en: And that's why it's trying to come into play a little bit hereã€‚ The good news
    is that we don't have to understand calculus there's going to be modules that
    can do it for such as this pitorrch thing I're going be learning pi torchã€‚Its
    also going to help us be able to run our code on GPUã€‚ we're going to be able to
    do things like take two matricesã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯å®ƒè¯•å›¾åœ¨è¿™é‡Œå‘æŒ¥ä½œç”¨çš„åŸå› ã€‚å¥½æ¶ˆæ¯æ˜¯æˆ‘ä»¬ä¸éœ€è¦ç†è§£å¾®ç§¯åˆ†ï¼Œä¼šæœ‰ä¸€äº›æ¨¡å—å¯ä»¥å¤„ç†ï¼Œä¾‹å¦‚è¿™ä¸ªpitorrchçš„ä¸œè¥¿ï¼Œæˆ‘ä¼šå­¦ä¹ pi torchã€‚å®ƒä¹Ÿå°†å¸®åŠ©æˆ‘ä»¬èƒ½å¤Ÿåœ¨GPUä¸Šè¿è¡Œæˆ‘ä»¬çš„ä»£ç ã€‚æˆ‘ä»¬å°†èƒ½å¤Ÿåšä¸€äº›åƒå¤„ç†ä¸¤ä¸ªçŸ©é˜µçš„äº‹æƒ…ã€‚
- en: shove them over to a GPU and then multiply them together and it'll just kind
    ofã€‚It almost feels like it's just magically going faster than it would if we're
    running on a CPU and it doesn't take a lot of code to move it around so Pytorrch
    is going be very powerful both in terms of calculus and using GPUsã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å®ƒä»¬ç§»åˆ° GPU ä¸Šï¼Œç„¶åç›¸ä¹˜ï¼Œè¿™å‡ ä¹æ„Ÿè§‰å°±åƒæ˜¯å®ƒæ¯”åœ¨ CPU ä¸Šè¿è¡Œæ—¶ç¥å¥‡åœ°å¿«å¾—å¤šï¼Œè€Œä¸”ç§»åŠ¨è¿™äº›ä»£ç å¹¶ä¸éœ€è¦å¾ˆå¤šã€‚å› æ­¤ï¼ŒPytorch åœ¨å¾®ç§¯åˆ†å’Œä½¿ç”¨
    GPU æ–¹é¢å°†éå¸¸å¼ºå¤§ã€‚
- en: To conclude this videoï¼Œ I just want to talk about this difference between developers
    and users and then who we areã€‚å—¯ã€‚When I'm looking at this picture hereï¼Œ I'm feeding
    all this training data into a machine learning algorithmã€‚ and then that's giving
    us a function we can use make predictionsã€‚There are classes and I guess people
    in generalï¼Œ who either develop a new algorithms or write code and optimize code
    for existing algorithmsã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸè¿™ä¸ªè§†é¢‘æ—¶ï¼Œæˆ‘æƒ³è°ˆè°ˆå¼€å‘è€…å’Œç”¨æˆ·ä¹‹é—´çš„åŒºåˆ«ï¼Œä»¥åŠæˆ‘ä»¬æ˜¯è°ã€‚å—¯ã€‚å½“æˆ‘çœ‹åˆ°è¿™é‡Œçš„è¿™å¼ å›¾ç‰‡æ—¶ï¼Œæˆ‘æ­£åœ¨å°†æ‰€æœ‰è¿™äº›è®­ç»ƒæ•°æ®è¾“å…¥åˆ°ä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•ä¸­ã€‚ç„¶åè¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªå¯ä»¥ç”¨æ¥è¿›è¡Œé¢„æµ‹çš„å‡½æ•°ã€‚è¿™é‡Œæœ‰ä¸€äº›ç±»åˆ«ï¼Œæˆ‘æƒ³äººä»¬é€šå¸¸ä¼šå¼€å‘æ–°çš„ç®—æ³•ï¼Œæˆ–è€…ç¼–å†™ä»£ç å¹¶ä¼˜åŒ–ç°æœ‰ç®—æ³•çš„ä»£ç ã€‚
- en: And we'll just do a tiny bit of thatï¼Œ but that's not our focus we aren't trying
    to do machine learning research or trouble to put novel ideasã€‚We aren't developers
    instead of're going to be users of machine learning algorithms that trauma and
    I cant learn and so some of the questions that we're gonna be interested in going
    forward for the rest of this class is well which algorithm should we use an SK
    learn how should we pick it and I guess how should we configure it right a lot
    of these have different parameters in terms of the data how can we clean it off
    so it's trying to work well with the machine learning algorithm we chose and then
    finally when we actually use this thingã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¼šåšä¸€ç‚¹ç‚¹è¿™æ–¹é¢çš„å·¥ä½œï¼Œä½†è¿™ä¸æ˜¯æˆ‘ä»¬çš„é‡ç‚¹ï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨è¿›è¡Œæœºå™¨å­¦ä¹ ç ”ç©¶æˆ–å°è¯•æå‡ºæ–°æƒ³æ³•ã€‚æˆ‘ä»¬ä¸æ˜¯å¼€å‘è€…ï¼Œè€Œæ˜¯æœºå™¨å­¦ä¹ ç®—æ³•çš„ç”¨æˆ·ï¼Œè¿™è®©æˆ‘èƒ½å­¦ä¹ åˆ°ä¸€äº›å†…å®¹ã€‚å› æ­¤ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åœ¨è¿™é—¨è¯¾ä¸­ä¼šæ„Ÿå…´è¶£çš„ä¸€äº›é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªä¸ªç®—æ³•ï¼Ÿåœ¨
    SK learn ä¸­æˆ‘ä»¬åº”è¯¥å¦‚ä½•é€‰æ‹©ï¼Ÿæˆ‘æƒ³æˆ‘ä»¬åº”è¯¥å¦‚ä½•é…ç½®å®ƒï¼Ÿå¾ˆå¤šè¿™äº›ç®—æ³•åœ¨æ•°æ®æ–¹é¢æœ‰ä¸åŒçš„å‚æ•°ï¼Œæˆ‘ä»¬å¦‚ä½•æ¸…ç†æ•°æ®ï¼Œä»¥ä½¿å…¶ä¸æˆ‘ä»¬é€‰æ‹©çš„æœºå™¨å­¦ä¹ ç®—æ³•è‰¯å¥½é…åˆï¼Œæœ€åå½“æˆ‘ä»¬å®é™…ä½¿ç”¨è¿™ä¸ªä¸œè¥¿æ—¶ã€‚
- en: we're going to get all these predictions that we can compare it back to the
    original and how do we want to score that there's not necessarily one right way
    to evaluate how good or bad it is and so we want to get some experience with that
    as well so that's a bit of a preview about what's toing up in the course and hopefully
    this is kind of a fun change of pace compared to what we've been doingã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è·å¾—æ‰€æœ‰è¿™äº›é¢„æµ‹ï¼Œå¯ä»¥ä¸åŸå§‹æ•°æ®è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¸Œæœ›å¦‚ä½•è¯„åˆ†å‘¢ï¼Ÿå¹¶æ²¡æœ‰ä¸€ç§ç»å¯¹æ­£ç¡®çš„æ–¹æ³•æ¥è¯„ä¼°å®ƒçš„å¥½åï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿå¸Œæœ›è·å¾—ä¸€äº›ç»éªŒï¼Œè¿™ä¹Ÿæ˜¯è¯¾ç¨‹å†…å®¹çš„ä¸€ä¸ªå°é¢„å‘Šï¼Œå¸Œæœ›è¿™ä¸æˆ‘ä»¬ä¹‹å‰æ‰€åšçš„ç›¸æ¯”æ˜¯ä¸€æ¬¡æœ‰è¶£çš„å˜åŒ–ã€‚
- en: '![](img/cca75afc4da139e8d5dce602f436c338_3.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_3.png)'
