- en: 【双语字幕+资料下载】使用 Scikit-learn 进行机器学习，4小时实战视角刷新知识框架，初学者进阶必备！＜实战教程系列＞ - P1：1）机器学习介绍
    - ShowMeAI - BV16u41127nr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】使用 Scikit-learn 进行机器学习，4小时实战视角刷新知识框架，初学者进阶必备！＜实战教程系列＞ - P1：1）机器学习介绍
    - ShowMeAI - BV16u41127nr
- en: '![](img/cca75afc4da139e8d5dce602f436c338_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_0.png)'
- en: '![](img/cca75afc4da139e8d5dce602f436c338_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_1.png)'
- en: Well in this part of the course we're going to be moving into a new section
    which is machine learning。 there's a lot of material we're going to cover， but
    at the same time it's really the tip of the iceberg for all the material you can
    do in this field。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分课程中，我们将进入一个新的部分，即机器学习。我们将涵盖大量材料，但与此同时，这只是你在这个领域可以做的材料的冰山一角。
- en: Let me try to start by relating to something that we're familiar with。And then
    connected to something new we're going to be doing which is building models so
    all of you have been running functions for a long time right so hey maybe I'll
    write this code and then our function take inputs maybe in the form of parameters
    and then they have some outputs maybe maybe either they're printing something
    or or I might return a value。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我试着从我们熟悉的事物开始，然后连接到我们将要做的新事物，即构建模型。你们已经运行函数很长时间了，对吧？所以，也许我会写这段代码，然后我们的函数接收输入，可能以参数的形式，然后它们有一些输出，也许它们在打印某些内容，或者我可能会返回一个值。
- en: And so for example， I can imagine that a function could be doing something like
    making some sort of prediction。 maybe my input is that I have some details about
    a house sets for sale。And then I might be predicting what it might sell for， and
    so when I have a function like this。 that's an example of a model。And and I could
    imagine having it feed in a bunch of values at the same time and making a bunch
    of predictions。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我可以想象一个函数可以做一些预测。也许我的输入是我有一些待售房屋的详细信息。然后我可能会预测它可能卖多少钱，所以当我有这样的函数时。这就是一个模型的例子。我可以想象同时输入一堆值并做出很多预测。
- en: So the idea of machine learning is that instead of having a computer write these
    or instead of having a human write these functions where I have a computer automatically
    generate these functions。 and the way they're going to do that is they're going
    to learn by example。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以机器学习的想法是，电脑不再由人类编写这些函数，而是由电脑自动生成这些函数。它们的做法是通过实例学习。
- en: so we'll feed in a bunch of training data where we have a bunch of her of houses
    that have sold for different amounts and have different bedrooms and baths。 we't
    trying to infer things like well how much is the bedroom worth， how much is the
    bath worth。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将输入一堆训练数据，其中有许多房屋以不同的价格出售，并且有不同的卧室和浴室。我们试图推断一些事情，比如卧室值多少钱，浴室值多少钱。
- en: how useful is it have a newer house？And then based on that function。 we're be
    we're going to be able to generate that function and then use that to make predictions
    on other。Data and you can imagine why that might be useful for a lot of things。
    maybe you're doing property assessments or maybe a realtor and you're trying to
    figure out how to price a house properly。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一座新房子有多有用？然后基于那个函数。我们将能够生成那个函数，然后用它来对其他数据做出预测。你可以想象这对许多事情可能是有用的。也许你在进行物业评估，或者你是房地产经纪人，正在努力确定如何正确定价房子。
- en: So the example I've given here is an example of a regression model and a regression
    model is trying to more broadly a type of supervised machine learning which is
    one of the main three categories of machine learning。 so I'm going to start broad
    now and talk about these three areas and then we're going to be talking about
    regression in more detail and I'll actually explain on what it is。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里给出的例子是回归模型的例子，回归模型试图更广泛地说是一种监督式机器学习，它是机器学习的三大主要类别之一。所以我现在要开始广泛地讨论这三个领域，然后我们将更详细地谈论回归，我实际上会解释它是什么。
- en: So the three main areas of machine learning are reinforcement learning。 which
    is basically a situation where you have to make a series of decisions。And you're
    trying to optimize some sort of reward so you can imagine some sort of robot moving
    around in the world and picking up coins or something like that we're not going
    to be doing that kind of work in this class instead we're going to focus on two
    areas which are supervised machine learning and unsupervised machine learning
    and in both of these cases we just have all our data upfront and we're trying
    to gain information about that some people will say there's a fourth category
    of machine learning called super super semisupvised but we won't be talking about
    that here。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的三个主要领域是强化学习，这基本上是一种需要做一系列决策的情况。你试图优化某种奖励，所以你可以想象某种机器人在世界中移动并拾取硬币，或者类似的事情，但我们在这门课中不会做那种工作，而是会专注于两个领域：监督机器学习和无监督机器学习。在这两种情况下，我们都有所有的数据，而我们试图从中获取信息。有些人会说有一个第四类机器学习，称为超监督学习，但我们在这里不会讨论那个。
- en: Within supervised machine learning there are two different things that we're
    going to learn this semester。 one is regression and with regression we're trying
    to predict a quantity and then with a classification we're going to try to predict
    a category so in any of these cases where we're trying to predict something that's
    known as a supervised problem and the way it works is while the data we have has
    some labels on it usually there's some special column that's telling us you know
    a quantity like the price for house or some sort of category and then from that
    we can try to predict that label and cases where the label is unknown and on supervised
    learning there's no special label column that we're trying to predict we're just
    trying to look for general patterns in the data and so we might do a couple things
    we might try to cluster our data we're replacing rows into different groups。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督机器学习中，我们这学期要学习两种不同的内容。一种是回归，在回归中我们试图预测一个数量，然后通过分类我们将尝试预测一个类别，因此在我们试图预测的任何情况下，这被称为监督问题，工作原理是我们拥有的数据上有一些标签，通常有一个特殊的列告诉我们，例如房子的价格或某种类别，然后我们可以尝试预测这个标签，而在标签未知的情况下，无监督学习没有我们试图预测的特殊标签列，我们只是在寻找数据中的一般模式，所以我们可能会做几件事，我们可能会尝试对数据进行聚类，将行替换到不同的组中。
- en: Or we might try to decompose our rows， we might notice that you know I might
    have these rows which eachF5 numbers in them。 but maybe every row is like a combination
    of kind of two component rows。 and so there's some simplicity in there even though
    there might be a lot of columns on our data。So I'm going to go through these four
    types of thing that we're going learn this semester and just try to make it more
    concrete so here I have a table right this is just a regular data frame and so
    this is my index here here are my column names right now I have a Y column which
    is my label so that's going to be generally what I'm trying to predict。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们可能会尝试对我们的行进行分解，我们可能会注意到我可能有这些每行有F5个数字的行。但也许每一行是两种组件行的组合。所以尽管我们的数据可能有很多列，但里面仍然有一些简单性。因此，我将讨论这学期我们要学习的这四种类型的内容，并尝试让它们更具体，所以这里我有一个表格，这只是一个常规的数据框，这里是我的索引，这里是我的列名，现在我有一个Y列，它是我的标签，这通常就是我试图预测的内容。
- en: And then I have these different problems here that I guess I'm just drawing
    the x0 through x4。 but usually those would have some sort of real name right like
    before I saw that we had like the number of beds in a house。So this label that
    we're trying to predict is what we're going to try to do is look for a relationship
    between that and these other columns。 which we're going to call features。😊，So
    in general what will happen is that we have some examples。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我这里有一些不同的问题，我想我只是在画 x0 到 x4。但通常这些会有一些实际的名称，比如在我看到的之前，我们有房子里的床位数。因此，我们试图预测的这个标签是我们要寻找与其他列之间关系的内容，我们将其称为特征。😊
    总的来说，发生的事情是我们有一些示例。
- en: some rows where we have examples of both， and then there might be some other
    data where we only have the features but we don't have the y label and so we want
    to try to predict what should're draw here and you can imagine why they might
    be maybe these are all different houses and some of them have already sold so
    we know what they sold for and then these have not drawn on the market yet。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一些行中我们有两个方面的例子，然后可能还有一些其他数据，其中我们只有特征，但没有y标签，因此我们想尝试预测这里应该是什么样的。你可以想象为什么会这样，也许这些都是不同的房子，其中一些已经出售，所以我们知道它们的售价，而这些还没有上市。
- en: so we're trying to predict would they sell if they do go on the market so the
    problem here with regression I just want to state again is that we want to predict
    a quantity the y column in this case based on the features and by a quantity I
    mean this is like a number。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在尝试预测如果它们上市的话会不会出售。这里回归问题我想再次强调的是，我们想预测一个量，这里的y列是基于特征的，而这个量我指的是一个数字。
- en: So how we're going to do that well we might actually break it down into the
    three parts first we might select a subset of the data that we for which we know
    the answer and then we might leave some other data aside for which we also know
    the answer and what we'll do is we'll run an algorithm that is able to infer what
    the relationship is between these features and these labels。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们将如何做到这一点呢？我们可能会首先将其分解为三个部分，首先选择一部分我们知道答案的数据，然后将其他一些我们也知道答案的数据放在一边，我们要做的是运行一个能够推断这些特征与这些标签之间关系的算法。
- en: Once I've done that I might run my model on these other ones for which I also
    know the answer now of course I already know the real answer and unless my model
    is perfect it's probably going to give me somewhat different answers and so why
    would I do this。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我做完这些，我可能会在其他我也知道答案的案例上运行我的模型。当然，我已经知道真实的答案，除非我的模型是完美的，否则它可能会给出一些不同的答案，所以我为什么要这样做呢？
- en: why would I want to make a prediction if I already know the answer and the reason
    is that I can do this to evaluate my model or I might say test my model so for
    example if my model says that this rush of in 70 and it's actually 72 well that's
    an error same thing here。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我已经知道答案，为什么还要做预测？原因是我可以这样来评估我的模型，或者我可能会说测试我的模型。例如，如果我的模型说这个房子的价格是70，而实际上是72，那就是一个错误，这里也是同样的道理。
- en: 60 versus 59 that's an error and I can try to quantify all of these errors and
    then Jim my model some sort of score that's the testing phase？
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 60与59，这就是一个错误，我可以尝试量化所有这些错误，然后给我的模型打分，这就是测试阶段吗？
- en: So after that， after I've learned my model up here。 and then I've kind of evaluated
    it on some known cases。Then I might actually put it in production。 production
    means I'm using it for real things。And I'm trying to predict actual unknowns in
    the world。 like， for example， if I add a new house to the market， what might itself
    more。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在那之后，在我学会了我的模型并对一些已知案例进行了评估后，我可能会把它投入生产。生产意味着我在用它做实际的事情。我在尝试预测世界上实际的未知量，比如说，如果我在市场上增加一套新房，它可能会卖多少钱。
- en: And I could all put these different values there。other thing we might do even
    beyond making predictions is that I might look at that model and just try to learn
    things about the world。 so I keep going back to the example where we're selling
    houses。 I think it's interesting to just know well for each additional house or
    for each additional bedroom or bathroom I have in my house。How much does that
    increase the value of my house and I can use that to make different decisions
    right like maybe I want to do a housing remodel am I going to get more benefit
    by adding another bathroom or another bedroom right so we can just kind of learn
    things about the world and also make decisions in that way。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以把这些不同的值放在那里。我们可能做的另一件事，甚至超越预测，是我可以查看那个模型并尝试学习一些关于世界的事情。所以我一直回到卖房子的例子。我认为了解每增加一套房子或每增加一个卧室或浴室，房子的价值会增加多少是很有趣的，我可以利用这些来做出不同的决策，比如说也许我想进行房屋改造，我是通过增加一个浴室还是一个卧室来获得更多的收益呢？所以我们可以以这种方式学习一些关于世界的事情并做出决策。
- en: Okay， so all of this was regression which was the first kind of supervised learning
    we're going to learn this semester and when we're doing these regressions right
    the key thing that makes the regression is that we're trying to predict some quantity
    and our Y label now it's totally possible that our features might be a mix of
    both quantities and categories right so something like green red blue is a category。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以所有这些都是回归，这是我们本学期要学习的第一种监督学习。当我们进行这些回归时，关键在于我们试图预测某个数量，而我们的Y标签现在完全可能是特征的数量和类别的混合，对吧？像绿色、红色、蓝色这样的就是一个类别。
- en: something like shape as a category， a lot of things are strings or categories。That's
    fine right。 the distinguishing characteristic of a regression is that the label
    column is quantitative。If I somehow am working on a problem where my Y is categorical，
    then this is no longer regression。 it's a classification problem， but otherwise
    all these other things I've been talking about where I kind of do training and
    testing and then I put in production。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 形状也是一个类别，很多东西都是字符串或类别。没问题，对吧。回归的显著特征是标签列是定量的。如果我在处理一个Y是分类的情况，那么这就不再是回归了。这是一个分类问题，但否则我谈论的所有其他内容，包括训练和测试，然后投入生产。
- en: all of that is the same we're just dealing with categories instead of instead
    of quantities。Okay。 so moving on we saw the two kinds of supervised learning which
    is both regression and classification what about unsupervised learning The main
    thing here。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这一切都是相同的，我们只是在处理类别而不是数量。好的。那么继续，我们看到了两种监督学习，分别是回归和分类。那么无监督学习呢？这里的主要内容是。
- en: the main point is that there is no label column right I just have a bunch of
    features。And then I can try to still learn some patterns about this。 even though
    I'm not trying to predict anything。And so one of the things I might want to learn
    is well are there any sort of natural groupings of these rows and so there are
    algorithms out there that will let's say put all these rows into three groups
    and might and assign them numbers like zero。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的要点是没有标签列，对吧？我只有一堆特征。然后我仍然可以尝试学习一些关于这个的模式。即使我并不是在试图预测任何东西。所以我可能想要学习的其中一件事是，这些行是否有任何自然的分组，因此有算法可以将所有这些行分成三个组，并可能给它们分配数字，比如零。
- en: one and two right and then just to kind of draw what that looks like while all
    of these rows be lying together。Now I really want to stress here that there's
    no data out there that tells me what the proper grouping is or even how many groups
    there are so when I'm doing this。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一和二，对吧？然后仅仅是为了画出那样的样子，虽然所有这些行都在一起。现在我真的想强调的是，没有数据告诉我正确的分组是什么，或者甚至有多少组，所以在我做这个的时候。
- en: it's not exactly like there's one right answer， but that doesn't mean that all
    groupings or classifications are equal I can measure within a group how similar
    those rows are to each other if I have some metric for that and so then my goal
    is to have a grouping that kind of maximizes a similarity within each group and
    there might be different groupings that are equally good right but as long as
    I'm kind of having a high similarity within groups well then I still learn something
    meaningful and you can imagine lots of different reasons I might do this like
    maybe each of these。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 并不是说只有一个正确答案，但这并不意味着所有的分组或分类都是相等的。如果我有某种度量标准，我可以衡量组内那些行之间的相似性，因此我的目标是拥有一种尽量最大化每个组内相似性的分组，可能会有不同的分组同样有效，对吧？但只要我在组内保持高相似性，那么我依然能学到一些有意义的东西，你可以想象我可能出于很多不同的原因这样做，或许每个这些。
- en: Things represent a different user for my web application and then if I can say，
    hey。 while there's these 10 different kinds of web users for my application。 I
    could maybe run a different marketing campaign for each of these different groups。Okay。
    so clustering again is unsupervised and it's unsupervised because while there
    was no label column I'm trying to predict。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些事物代表了我网页应用程序中的不同用户，然后如果我可以说，嘿。虽然我的应用程序有这10种不同类型的网络用户。我可能可以为每个不同的群体开展不同的营销活动。好的。所以聚类再次是无监督的，之所以是无监督的，因为虽然没有标签列，但我在尝试预测。
- en: The last kind of machine learning problem when I talk about this semester and
    which is probably the most complicated is called a decomposition and and decomposition
    is also unsupervised is again。 right， there's no column I'm trying to predict
    here。And the idea with a decomposition is that I'm going to look through all these
    rows and see if there's any pattern。 are there kind of a couple archtype rows
    that really can be mixed together to create other things。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当我谈论本学期的最后一种机器学习问题时，可能是最复杂的，称为分解，而分解也是无监督的。对吧，这里没有我试图预测的列。分解的思想是我会查看所有这些行，看看是否有任何模式。是否有几种原型行可以真正混合在一起以创建其他东西。
- en: so maybe what I see is that with some small error most of these rows are just
    combinations of these three rows over here and I would call these my component
    rows。 So you notice the columns are the same right between my original data and
    my component rows。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以也许我看到的是，带有一些小错误的大多数行只是这三行的组合，我会称这些为我的组成行。所以你会注意到我的原始数据和我的组成行之间的列是相同的。
- en: And then to get this row here， like negative 11， negative 7， 3， 2020。 what I
    would do is I would multiply this row by negative V 11。And then add it to 21 times
    this row and then add it to negative8 times this row right so I'm kind of taking
    a weighted average of these three rows。To produce this row and if you actually
    crunch these numbers you'd see that I would just something kind of similar to
    this。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后为了得到这一行，比如负11，负7，3，2020。我会将这一行乘以负V 11，然后加上21乘以这一行，再加上负8乘以这一行。也就是说，我在对这三行进行加权平均，以产生这一行。如果你实际计算这些数字，你会看到我得到的结果与这个类似。
- en: but there would be some error right it's not a perfect match which is fine I
    mean the fewer components I have well then I kind of have a simpler model but
    while there might be more error。So so I have that here and I have these numbers
    here and what we'll generally do when I'm trying to mix these components to create
    a row is I'll put these numbers in another table down here。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但会有一些错误，对吧？这不是一个完美的匹配，这没关系，我的组成部分越少，我就会有一个更简单的模型，但可能会有更多的错误。所以我在这里有这些数字，当我试图混合这些组件以创建一行时，我通常会把这些数字放在下面的另一个表中。
- en: so this will be a table of all my weights or maybe my principal component scores
    and so I'll put you know negative 11 here。 21 here and then negative8 here and
    then for this next row down here right I'll do the same thing I'll say a negative
    43 here。 12 here and then the negative6 here and so since I'm doing this I'm putting
    kind of these mixtures for every row down here down here。 what that means is that
    if there's n rows over here。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这将是我所有权重的表，或者说我的主成分得分，因此我会在这里写上负11，在这里写上21，然后在这里写上负8，然后对于下面的这一行，我会做同样的事情，我会在这里写上负43，在这里写上12，然后在这里写上负6。所以由于我在这样做，我在这里为每一行放入这些混合。这意味着如果这里有n行。
- en: Then there are also going to be N rows over here if there are M columns over
    here。 well then there would be M columns over here， so basically what I can do
    is I can take this big table and I can reduce it to having some components here
    I can have some weights here it's useful for lots of things one is just if I'm
    trying to save space on my storage system right I can have these things be smaller
    but then it's also nice if I'm trying to do other phases of machine learning like
    a classification or regression it's kind of nice if I only have like three feature
    columns instead of the original five that's trying to help me in a number of cases。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后如果这里有N行，那里有M列。那么那边也会有M列。因此，基本上我可以将这个大表格减少到一些组件，我可以在这里有一些权重，这对许多事情都有用，其中之一就是如果我想在我的存储系统上节省空间，我可以让这些东西变得更小，但如果我试图进行机器学习的其他阶段，比如分类或回归，如果我只有三个特征列而不是原来的五个，那在许多情况下对我有所帮助。
- en: Okay， so that's a whirlwind tour of these four poems where I solve regression。
    classificationification， those are both supervised because again it's labeled，
    clusterstering。 decomposition， there is no column we're trying to predict that's
    unlabeled， it's unsupervised。Learning and and so for each of these four things
    there's actually a ton of different algorithms out there and and in this semester
    we only really have time to learn like one algorithm for each of them and so if
    I go to this website down here this is the website for PsyH Learn which is the
    module we're going to be learning。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这就是对这四首诗的快速概述，其中我解决了回归、分类，这两者都是监督学习，因为它们是有标签的，而聚类和分解则是无监督的，因为没有要预测的无标签列。对于这四个主题，其实有很多不同的算法，而在这个学期我们只会学习每个主题的一个算法，所以如果我访问下面这个网站，这是我们将要学习的PsyH
    Learn模块的网站。
- en: 😊，And there's probably close to hundreds of different algorithms or different
    classes they have there。 I put a small subset under here and so I can see well
    here's all these different things they have for clustering and we're going to
    just learn one of those which is k means clustering。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 😊，可能有接近数百种不同的算法或不同的类别。我在这里列出了一个小子集，因此我可以看到，关于聚类的所有不同内容，我们将只学习其中一个，那就是K均值聚类。
- en: decomposition， all these different things I can do， we're going to learn just
    one of them。 which is PCA。It turns out that for a lot of algorithms。 the classification
    and regression common pairs， so for example。Here I have like a decision tree classifier
    here I have a decision tree regressor。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在分解方面，我能做的所有不同的事情，我们将只学习其中一个，那就是PCA。事实证明，对于很多算法，分类和回归是常见的配对，例如，这里我有一个决策树分类器，这里我有一个决策树回归器。
- en: Here I have a K neighbors classifier here I have a K neighbors regressor and
    that's why I didn't kind of split these out and I just put both of these under
    these two categories and so we're going to learn two things here we're going to
    learn logistic regression and we're going to learn linear regression and this
    is a little bit confusing because。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我有一个K邻居分类器，这里我有一个K邻居回归器，因此我没有把这些分开，而是将它们放在这两个类别下，所以我们将在这里学习两个内容，我们将学习逻辑回归和线性回归，这有点令人困惑，因为。
- en: Well this part's obvious， right the linear regression is going to be a regression
    here。 this is the one that people get confusedfused on because even though it
    says regression in the name。 it is not a regression， it's actually classification
    right so these are the four things we're going to be learning this semester and
    logistic regression is when people always get infused on because well it's not
    actually a regression。And I think once we learn all these things， the very nice
    thing is that the interface to using the other ones is relatively simple。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分很明显，线性回归在这里就是回归。这是一个人们容易混淆的地方，因为尽管它的名称中有回归，但实际上它并不是回归，而是分类。因此，这就是我们这个学期将要学习的四个内容，而逻辑回归总是让人困惑，因为它实际上并不是回归。我认为一旦我们学习了所有这些，使用其他算法的接口就会相对简单。
- en: So for example， once you know how to use a linear regression。You could very
    easily just replace the word linear regression with Ridge and you're still going
    to be able to do all your machine learning stuff correctly now before you do that
    you should probably learn about how Ridge works and then think about which model
    is best for you。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一旦你知道如何使用线性回归，你可以很容易地将“线性回归”替换为“岭回归”，你仍然能够正确地进行所有机器学习的工作。在你这样做之前，最好了解岭回归的工作原理，然后思考哪个模型最适合你。
- en: but at least in terms of the code it's very simple to switch between different
    models。I without any any of these four categories。So I want to talk a little bit。
    that was pretty high level， I want to talk a little bit about the foundations
    where I need to be learning this machine learning both in terms of the code and
    then also the math。Where I learn a few different modules， the main one is atsyKt
    Learn。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在代码方面，切换不同模型是非常简单的，而不需要考虑这四个类别。我想多谈谈，这些都是比较高层次的内容，我想谈谈基础知识，我需要学习的机器学习，包括代码和数学方面。我学习了几个不同的模块，主要的是`scikit-learn`。
- en: I would showing you some documentation from PsyKt Learn。We're also gonna learn
    nuy， which has。 lets us deal with matrices。 It turns out that nuy。Numpy is really
    the foundation for pandas right。 all panda data is actually stored in Numpy and
    now will be a good time for us to actually see that。And then when I learned this
    thing called Pytorch and Pytorrch can do a couple things for us。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我将给你展示一些来自 PsyKt Learn 的文档。我们还将学习 nuy，它可以让我们处理矩阵。事实证明，nuy，Numpy 实际上是 pandas
    的基础，没错，所有的 pandas 数据实际上存储在 Numpy 中，现在是我们实际看到这一点的好时机。然后当我学习了这个叫 Pytorch 的东西时，Pytorch
    可以为我们做几件事情。
- en: one is it can do calculus for us， which is pretty cool。Another thing it can
    let us do is it can actually let us run our code on GPUs。 which are graphics processing
    units， everything we've been running so far this semester has been running on
    CPUs。 right your central processing unit。And and it turns out that GPUs that originally
    built for graphics also happen to be really good at machine learning and so a
    lot of things if you're dealing with a lot of data or kind of complex models。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个是它可以为我们进行微积分，这非常酷。另一个它可以让我们做的事情是它实际上可以让我们在 GPU 上运行代码，这些是图形处理单元，我们这一学期到目前为止所有的运行都是在
    CPU 上进行的，没错，就是你的中央处理单元。结果发现，原本为图形构建的 GPU 在机器学习方面也表现得非常好，因此，如果你处理大量数据或复杂模型时，它们会非常有用。
- en: a GPU will be better at it。Where I have to learn a little bit of math。 I'm not
    assuming you have any math background besides what you might learn in high school。
    but let me give you an example of how math is going to come into play here for
    a regression problem right so we have this example again with all the houses and
    these characteristics and then we have a function that predicts the price。How
    would we do that with matrices， well I might take all these numbers in the data
    frame and put them in this matrix here？
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GPU 会更好。我要学习一点数学。我并不假设你有任何数学背景，除了你可能在高中学到的内容，但让我给你一个例子，说明数学在这里如何应用于回归问题。因此我们再次以所有房屋及其特征的例子为基础，然后我们有一个预测价格的函数。我们如何用矩阵来做到这一点呢？我可能会将数据框中的所有这些数字放入这个矩阵中。
- en: And then for my function， I may have kind of just an algebraic expression which
    is using matrices。 So my x here is this matrix C is a vector， B is just a number
    And when I run this well I'm going to get this other vector out here which actually
    has all all the prices so to understand what's going on here and we have to learn
    a little bit of linear algebra。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后对于我的函数，我可能只是有一个使用矩阵的代数表达式。因此，我这里的 x 是这个矩阵，C 是一个向量，B 只是一个数字。当我运行这个时，我将得到另一个向量，实际上包含所有的价格。因此，为了理解这里发生了什么，我们必须学习一点线性代数。
- en: this is not a regular multiplication， it's actually something called the dot
    product and it looks like this right I can take this X matrix here。Dot product
    with this vector and then add a number and then that's how'm going to get my results
    over here on the righthand side do one prediction and what's cool is that if I
    can do one row times times this vector here and I get one house value and it's
    going to go through without having a loop even the beauty of linear your algebra
    and multiplying matrices together with the dot product is that do in one step
    and I'm going get actually all of these numbers the code for it is pretty simple
    if I say data frame of values then x is actually going to be a nuy array and if
    I want to I can just say well I want the dot product of these two things and I
    want to add B and it just work so we're going be talking about that in quite a
    bit more detail at some point before the end of the semester。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是常规的乘法，它实际上是被称为点积的东西，看起来是这样的，我可以将这个 X 矩阵与这个向量进行点积，然后加上一个数字，然后这就是我将如何在右侧获得我的结果，进行一次预测，令人惊讶的是，如果我可以将一行与这个向量相乘，我就得到了一个房屋的价值，并且这会在没有循环的情况下进行，线性代数和通过点积相乘矩阵的美妙之处在于，这可以一步完成，我实际上会得到所有这些数字。代码非常简单，如果我说数据框的值，那么
    x 实际上将是一个 nuy 数组，如果我想的话，我可以说我想要这两个东西的点积，并且我想要加上 B，这样就能正常工作。因此在学期结束前的某个时候，我们会对此进行更多详细的讨论。
- en: One thing I want to note is that if you're reading other documentation。 a lot
    of resources will use A instead of Xs， which I find confusing。 I think that's
    not intuitive if you're kind of working on all of thesesyKt learn modules because
    those will generally use x for data and then even stranger we'll often have a
    C when we're in PsyKt learn but then they call that little acts instead so just
    be you know as we're learning linear algebra stuff。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我想注意的一点是，如果你在阅读其他文档，很多资源会使用A而不是Xs，我觉得这很让人困惑。如果你正在研究这些syKt学习模块，这样并不直观，因为这些通常会使用x表示数据，而更奇怪的是，在PsyKt学习中，我们通常会有一个C，但他们会把它称为小x，所以在我们学习线性代数的过程中要保持清醒。
- en: I just want to say upfront and I'll say it again be aware that the variable
    names are a little bit wacky。So what is kind of the scope of linear algebra and
    what kind of things are we trying to solve Well one thing that we're not going
    to solve is something like this y equals x squared that is not linear anything
    quadratic or cubic or anything like that not linear really all we can do is multiply
    multiply variables by numbers and then add things off right so this is an example
    of a linear equation right I just have I have some different variables。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我想提前说清楚，我会再说一遍，要注意变量名称有点奇怪。那么线性代数的范围是什么，我们试图解决哪些问题呢？我们不会解决类似于y等于x平方的东西，那不是线性的，任何二次或三次方的东西都不是线性的，实际上我们能做的就是将变量乘以数字，然后再加起来，对吧？所以这是一个线性方程的例子，我有一些不同的变量。
- en: And then I'm multiplying them by different numbers one of the things where I
    notice is that the way we're going to be doing linear algebra in this course is
    we actually have very big matrices and at a lot of variables and a lot of equations
    right so you can see here I actually have 50 variables so I think the key takeaway
    is that more variables more data but simpler equations。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我将它们乘以不同的数字，我注意到我们在这门课中进行线性代数的方式是我们实际上有非常大的矩阵，很多变量和很多方程，对吧？所以你可以看到这里我实际上有50个变量，所以关键要点是，更多的变量意味着更多的数据，但方程更简单。
- en: what about calculus so here I have that situation again with the house where
    I have some training data。 so I have both my features and my label， it draws into
    an algorithm and that algorithm will basically spit out this formula for me that
    I can use to predict housing prices。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于微积分，这里我再次遇到房子的情况，我有一些训练数据。所以我有我的特征和标签，它会引入一个算法，该算法基本上会为我输出这个公式，我可以用来预测房价。
- en: Right。Now， it turns out that when I was doing this training， right。 I had the
    original prices and the new prices might be a little bit different right This
    is 140。 this is 190，240，254 right， They're all a little bit different。 And so
    what I can do is for this given equation I end up with。I can have some sort of
    function。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对。现在，事实证明，当我进行训练时，我有原始价格，而新价格可能有一点不同，对吧？这是140。这是190、240、254，对吧，它们都稍微有些不同。因此，对于这个给定的方程，我最终会有某种函数。
- en: total loss function that compares the correct answer with my model's answers，
    right。 so I compare these two and I get one number out right that's kind like
    what my error is or how bad it is。And of course， how bad it is really depends
    on kind of the numbers that are part of this equation down here。 so the whole
    idea of this training thing with this algorithm is that I want to find out， well。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总损失函数比较正确答案与我模型的答案，对吧？所以我比较这两个，得到一个数值出来，这就像是我的误差或它有多糟糕。当然，它的糟糕程度实际上取决于这个方程下面的数字。所以这个训练算法的整个想法是，我想找出，嗯。
- en: what see can I do that is going to make my error or my loss as small as possible
    so we're trying to minimize something and I don't expect you if they can calculus。
    but I know a lot of you have and in calculus we're often trying to minimize or
    maximize things？
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我能做什么才能让我的误差或损失尽可能小，所以我们试图最小化某种东西，我不指望你们都能做微积分。但我知道你们中的许多人都学过，而在微积分中我们通常试图最小化或最大化某些东西？
- en: And that's why it's trying to come into play a little bit here。 The good news
    is that we don't have to understand calculus there's going to be modules that
    can do it for such as this pitorrch thing I're going be learning pi torch。Its
    also going to help us be able to run our code on GPU。 we're going to be able to
    do things like take two matrices。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是它试图在这里发挥作用的原因。好消息是我们不需要理解微积分，会有一些模块可以处理，例如这个pitorrch的东西，我会学习pi torch。它也将帮助我们能够在GPU上运行我们的代码。我们将能够做一些像处理两个矩阵的事情。
- en: shove them over to a GPU and then multiply them together and it'll just kind
    of。It almost feels like it's just magically going faster than it would if we're
    running on a CPU and it doesn't take a lot of code to move it around so Pytorrch
    is going be very powerful both in terms of calculus and using GPUs。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将它们移到 GPU 上，然后相乘，这几乎感觉就像是它比在 CPU 上运行时神奇地快得多，而且移动这些代码并不需要很多。因此，Pytorch 在微积分和使用
    GPU 方面将非常强大。
- en: To conclude this video， I just want to talk about this difference between developers
    and users and then who we are。嗯。When I'm looking at this picture here， I'm feeding
    all this training data into a machine learning algorithm。 and then that's giving
    us a function we can use make predictions。There are classes and I guess people
    in general， who either develop a new algorithms or write code and optimize code
    for existing algorithms。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这个视频时，我想谈谈开发者和用户之间的区别，以及我们是谁。嗯。当我看到这里的这张图片时，我正在将所有这些训练数据输入到一个机器学习算法中。然后这给了我们一个可以用来进行预测的函数。这里有一些类别，我想人们通常会开发新的算法，或者编写代码并优化现有算法的代码。
- en: And we'll just do a tiny bit of that， but that's not our focus we aren't trying
    to do machine learning research or trouble to put novel ideas。We aren't developers
    instead of're going to be users of machine learning algorithms that trauma and
    I cant learn and so some of the questions that we're gonna be interested in going
    forward for the rest of this class is well which algorithm should we use an SK
    learn how should we pick it and I guess how should we configure it right a lot
    of these have different parameters in terms of the data how can we clean it off
    so it's trying to work well with the machine learning algorithm we chose and then
    finally when we actually use this thing。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会做一点点这方面的工作，但这不是我们的重点，我们不是在进行机器学习研究或尝试提出新想法。我们不是开发者，而是机器学习算法的用户，这让我能学习到一些内容。因此，接下来我们在这门课中会感兴趣的一些问题是，我们应该使用哪个算法？在
    SK learn 中我们应该如何选择？我想我们应该如何配置它？很多这些算法在数据方面有不同的参数，我们如何清理数据，以使其与我们选择的机器学习算法良好配合，最后当我们实际使用这个东西时。
- en: we're going to get all these predictions that we can compare it back to the
    original and how do we want to score that there's not necessarily one right way
    to evaluate how good or bad it is and so we want to get some experience with that
    as well so that's a bit of a preview about what's toing up in the course and hopefully
    this is kind of a fun change of pace compared to what we've been doing。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获得所有这些预测，可以与原始数据进行比较，我们希望如何评分呢？并没有一种绝对正确的方法来评估它的好坏，因此我们也希望获得一些经验，这也是课程内容的一个小预告，希望这与我们之前所做的相比是一次有趣的变化。
- en: '![](img/cca75afc4da139e8d5dce602f436c338_3.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cca75afc4da139e8d5dce602f436c338_3.png)'
