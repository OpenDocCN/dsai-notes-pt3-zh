- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P7ï¼šL8- ä¹é«˜æ˜Ÿçƒå¤§æˆ˜å°äººä»”åˆ†ç±»ä»»åŠ¡  å®Œæ•´é¡¹ç›®æµç¨‹
    - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P7ï¼šL8- ä¹é«˜æ˜Ÿçƒå¤§æˆ˜å°äººä»”åˆ†ç±»ä»»åŠ¡
    å®Œæ•´é¡¹ç›®æµç¨‹ - ShowMeAI - BV1TT4y1m7Xg
- en: '![](img/7956a7f6b5a10c99728c67c08635cf0e_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7956a7f6b5a10c99728c67c08635cf0e_0.png)'
- en: ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ welcome to another Tensorflow tutorial Todayï¼Œ I'll do another full
    project walkthroughã€‚ And I think this project is going to be real fun because
    we're going use a real image data set from Kaaggle with Lego Star Wars minifisã€‚
    And we're trying to classify the charactersã€‚ So along the wayã€‚ we will learn how
    we download and organize our data and how we load the images into Tensorflow and
    preprocessed themã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°å¦ä¸€ä¸ª Tensorflow æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘å°†è¿›è¡Œå¦ä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®æ¼”ç¤ºã€‚æˆ‘è®¤ä¸ºè¿™ä¸ªé¡¹ç›®ä¼šå¾ˆæœ‰è¶£ï¼Œå› ä¸ºæˆ‘ä»¬å°†ä½¿ç”¨æ¥è‡ª Kaaggle
    çš„çœŸå®å›¾åƒæ•°æ®é›†ï¼ŒåŒ…å«ä¹é«˜æ˜Ÿçƒå¤§æˆ˜å°äººä»”ã€‚æˆ‘ä»¬è¦å¯¹è§’è‰²è¿›è¡Œåˆ†ç±»ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä¸‹è½½å’Œç»„ç»‡æˆ‘ä»¬çš„æ•°æ®ï¼Œä»¥åŠå¦‚ä½•å°†å›¾åƒåŠ è½½åˆ° Tensorflow
    ä¸­å¹¶è¿›è¡Œé¢„å¤„ç†ã€‚
- en: Then we set up a convolutional neural netï¼Œ train it and save our modelã€‚ And
    along the wayã€‚ I'll also introduce some new concepts like image augmentation and
    Kara callbesã€‚ So I hope you stay until the end and we'll find out if we can correctly
    identify Luke Skywalkerã€‚ So here is the image data set that's available on Cagelã€‚
    and I will put the link in a descriptionã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œè®­ç»ƒå®ƒå¹¶ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘è¿˜ä¼šä»‹ç»ä¸€äº›æ–°æ¦‚å¿µï¼Œæ¯”å¦‚å›¾åƒå¢å¼ºå’Œ Keras å›è°ƒã€‚æ‰€ä»¥æˆ‘å¸Œæœ›ä½ èƒ½åšæŒåˆ°æœ€åï¼Œæˆ‘ä»¬å°†çœ‹çœ‹èƒ½å¦æ­£ç¡®è¯†åˆ«å¢å…‹Â·å¤©è¡Œè€…ã€‚è¿™æ˜¯å¯åœ¨
    Kaggle ä¸Šè·å–çš„å›¾åƒæ•°æ®é›†ï¼Œæˆ‘ä¼šåœ¨æè¿°ä¸­æ”¾ä¸Šé“¾æ¥ã€‚
- en: and then you can just click on download and download the dataã€‚ So I already
    did this and copied it inã€‚ğŸ˜Šï¼Œto my project directoryã€‚ So here this Lego folderã€‚
    And we have some different categories like Harry Potter and Jurasic Worldã€‚ But
    now I'm only going to use the Star Wars figures to make it simpler and easier
    to follow for youã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥ç›´æ¥ç‚¹å‡»ä¸‹è½½å¹¶ä¸‹è½½æ•°æ®ã€‚æˆ‘å·²ç»åšè¿‡è¿™ä¸€æ­¥ï¼Œå¹¶å°†å…¶å¤åˆ¶åˆ°æˆ‘çš„é¡¹ç›®ç›®å½•ä¸­ã€‚ğŸ˜Šï¼Œåœ¨è¿™ä¸ªä¹é«˜æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€äº›ä¸åŒçš„ç±»åˆ«ï¼Œæ¯”å¦‚å“ˆåˆ©Â·æ³¢ç‰¹å’Œä¾ç½—çºªä¸–ç•Œã€‚ä½†ç°åœ¨æˆ‘åªä¼šä½¿ç”¨æ˜Ÿçƒå¤§æˆ˜çš„äººç‰©ï¼Œä»¥ä¾¿äºä½ æ›´å®¹æ˜“è·Ÿä¸Šã€‚
- en: So let's make a copy of this folder so that we have a backup because we are
    going to reorganize the data a little bitã€‚ So let's rename this to Star Wars imagesã€‚
    And then inside hereï¼Œ we have 10 different classesã€‚ but right now I'm only going
    to use the first fiveã€‚ So againï¼Œ to make it simpler for youã€‚ And now let's have
    a look at these imagesã€‚ So now in this Star Wars images folderã€‚ We haveã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æ¥å¤åˆ¶è¿™ä¸ªæ–‡ä»¶å¤¹ï¼Œä»¥ä¾¿æˆ‘ä»¬æœ‰ä¸€ä¸ªå¤‡ä»½ï¼Œå› ä¸ºæˆ‘ä»¬å°†ç¨å¾®é‡æ–°ç»„ç»‡æ•°æ®ã€‚æˆ‘ä»¬å°†å…¶é‡å‘½åä¸ºæ˜Ÿçƒå¤§æˆ˜å›¾åƒã€‚ç„¶ååœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰10ä¸ªä¸åŒçš„ç±»åˆ«ï¼Œä½†ç°åœ¨æˆ‘åªä¼šä½¿ç”¨å‰äº”ä¸ªã€‚è¿™æ ·åšæ˜¯ä¸ºäº†è®©ä½ æ›´å®¹æ˜“ç†è§£ã€‚ç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹è¿™äº›å›¾åƒã€‚æ‰€ä»¥ç°åœ¨åœ¨è¿™ä¸ªæ˜Ÿçƒå¤§æˆ˜å›¾åƒæ–‡ä»¶å¤¹ä¸­ã€‚æˆ‘ä»¬æœ‰ã€‚
- en: for exampleï¼Œ class1ã€‚ This is Yodaã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_2.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œclass1ã€‚è¿™æ˜¯å°¤è¾¾ã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_2.png)
- en: Class two is Luke Skywalkerã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_4.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: class2 æ˜¯å¢å…‹Â·å¤©è¡Œè€…ã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_4.png)
- en: Then we also have R2 D2ï¼Œ then we also have Macce windowã€‚ and as last characterã€‚
    we use general grievsã€‚ So these are the characters that we want to identify and
    right now the first thing I want to do is to reorganize this folder structure
    a little bitã€‚ So you could load it like this and you also have some met data with
    the information for each directory so can you can load it with thisã€‚ So I want
    to make it a little bit simpler so that we can easily load it with the tens of
    low image and loaderã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜æœ‰ R2-D2ï¼Œè¿˜æœ‰éº¦å…‹æ–¯Â·æ¸©åº¦ã€‚æœ€åä¸€ä¸ªè§’è‰²æ˜¯æ ¼é‡Œå¤«æ–¯å°†å†›ã€‚æ‰€ä»¥è¿™äº›æ˜¯æˆ‘ä»¬æƒ³è¦è¯†åˆ«çš„è§’è‰²ï¼Œç°åœ¨æˆ‘æƒ³åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯ç¨å¾®é‡æ–°ç»„ç»‡ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶å¤¹ç»“æ„ã€‚è¿™æ ·ä½ å°±å¯ä»¥åƒè¿™æ ·åŠ è½½å®ƒï¼ŒåŒæ—¶ä½ è¿˜å¯ä»¥é€šè¿‡æ¯ä¸ªç›®å½•ä¸­çš„å…ƒæ•°æ®è¿›è¡ŒåŠ è½½ã€‚æˆ‘æƒ³è®©å®ƒç®€å•ä¸€ç‚¹ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è½»æ¾åŠ è½½åˆ°
    Tensorflow çš„å›¾åƒåŠ è½½å™¨ä¸­ã€‚
- en: So I want to separate the data set into training images validation images and
    test imagesã€‚ So we create three folders in here and then inã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_6.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘æƒ³å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒå›¾åƒã€éªŒè¯å›¾åƒå’Œæµ‹è¯•å›¾åƒã€‚æˆ‘ä»¬åœ¨è¿™é‡Œåˆ›å»ºä¸‰ä¸ªæ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨ã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_6.png)
- en: Each of the foldersï¼Œ we again create images for each characterã€‚ For exampleã€‚
    we have a training folderï¼Œ and then in the subfoldï¼Œ we have a folder for Yodaã€‚
    Luke Skywalker and so onã€‚ So this is the first thing we are going to doã€‚ So here
    I'm in a twopyter notebookã€‚ And here we import the things that we needã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘ä»¬ä¼šä¸ºæ¯ä¸ªè§’è‰²åˆ›å»ºå›¾åƒã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªè®­ç»ƒæ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨å­æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå…³äºå°¤è¾¾çš„æ–‡ä»¶å¤¹ï¼Œå¢å…‹Â·å¤©è¡Œè€…ç­‰ç­‰ã€‚æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘åœ¨ä¸€ä¸ª
    Jupyter notebook ä¸­ï¼Œæˆ‘ä»¬å¯¼å…¥æ‰€éœ€çš„å†…å®¹ã€‚
- en: Then here I named the base directory where we have the images and then I hardcoded
    the names of each characterã€‚ So these five and I'm also setting a random seat
    to make it a little bit more reproducible and now the first thing we want to do
    is to create our different foldersã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™é‡Œæˆ‘å‘½åäº†åŒ…å«å›¾åƒçš„åŸºæœ¬ç›®å½•ï¼Œç„¶åæˆ‘ç¡¬ç¼–ç äº†æ¯ä¸ªè§’è‰²çš„åç§°ã€‚è¿™äº”ä¸ªè§’è‰²ï¼Œæˆ‘è¿˜è®¾ç½®äº†ä¸€ä¸ªéšæœºç§å­ï¼Œä½¿å…¶æ›´å…·å¯é‡å¤æ€§ï¼Œç°åœ¨æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯åˆ›å»ºä¸åŒçš„æ–‡ä»¶å¤¹ã€‚
- en: So we can of course automate this with Pythonã€‚ So now if I run this code and
    we have a look then here in here it created these three new folders and then inside
    of each it created a folder for each character that we haveã€‚ So right now these
    are empty and now we're going to take the images from in here and then copy them
    into here and so weã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å½“ç„¶å¯ä»¥ç”¨Pythonè‡ªåŠ¨åŒ–è¿™ä¸ªã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªä»£ç å¹¶æŸ¥çœ‹ï¼Œè¿™é‡Œåˆ›å»ºäº†è¿™ä¸‰ä¸ªæ–°æ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨æ¯ä¸ªæ–‡ä»¶å¤¹å†…ä¸ºæˆ‘ä»¬æ‹¥æœ‰çš„æ¯ä¸ªè§’è‰²åˆ›å»ºäº†ä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚å› æ­¤ï¼Œç°åœ¨è¿™äº›éƒ½æ˜¯ç©ºçš„ï¼Œæˆ‘ä»¬å°†ä»è¿™é‡Œè·å–å›¾åƒï¼Œç„¶åå¤åˆ¶åˆ°è¿™é‡Œã€‚
- en: We have about 12 or 12 to 14 different images for each characterã€‚I know this
    is not a big amountã€‚ especially not for deep learningï¼Œ but it's enough for this
    tutorial and I show you at the end that we get a pretty good accuracyã€‚So yeahï¼Œ
    now we want to take about 60% for trainingã€‚ then 25% for validation and the rest
    for testing and then copy them into these foldersã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¯ä¸ªè§’è‰²å¤§çº¦æœ‰12åˆ°14å¹…ä¸åŒçš„å›¾åƒã€‚æˆ‘çŸ¥é“è¿™ä¸æ˜¯å¾ˆå¤šï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ·±åº¦å­¦ä¹ ï¼Œä½†å¯¹äºæœ¬æ•™ç¨‹æ¥è¯´è¶³å¤Ÿäº†ï¼Œæˆ‘ä¼šåœ¨æœ€åå‘ä½ å±•ç¤ºæˆ‘ä»¬å¾—åˆ°äº†ç›¸å½“ä¸é”™çš„å‡†ç¡®ç‡ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬ç°åœ¨æƒ³è¦å°†å¤§çº¦60%ç”¨äºè®­ç»ƒï¼Œ25%ç”¨äºéªŒè¯ï¼Œå‰©ä¸‹çš„ç”¨äºæµ‹è¯•ï¼Œç„¶åå°†å®ƒä»¬å¤åˆ¶åˆ°è¿™äº›æ–‡ä»¶å¤¹ä¸­ã€‚
- en: So if I run thisã€‚Then it prints the total number of images in each directory
    and then the number of training samplesã€‚ validation samples and test samplesã€‚
    So now if we go back in hereã€‚ then each of these folders here are empty so we
    can actually delete them so now move to trash and now in the training folderã€‚
    for exampleï¼Œ we should have the imagesï¼Œ so we have training images for each one
    testing images for each one and validation images for each characterã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªã€‚ç„¶åå®ƒä¼šæ‰“å°æ¯ä¸ªç›®å½•ä¸­å›¾åƒçš„æ€»æ•°ï¼Œä»¥åŠè®­ç»ƒæ ·æœ¬ã€éªŒè¯æ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬çš„æ•°é‡ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬å›åˆ°è¿™é‡Œï¼Œè¿™äº›æ–‡ä»¶å¤¹éƒ½æ˜¯ç©ºçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥åˆ é™¤å®ƒä»¬ï¼Œç°åœ¨ç§»åŠ¨åˆ°åƒåœ¾æ¡¶ï¼Œç°åœ¨åœ¨è®­ç»ƒæ–‡ä»¶å¤¹ä¸­ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬åº”è¯¥æœ‰å›¾åƒï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ºæ¯ä¸ªè§’è‰²æœ‰è®­ç»ƒå›¾åƒã€æµ‹è¯•å›¾åƒå’ŒéªŒè¯å›¾åƒã€‚
- en: So againï¼Œ this is what your structure should look likeã€‚ and this makes it very
    easy for the Tensorflow image data loaderã€‚So now we can go ahead and set up our
    image data generator so we can get this from Kras preprocessing dot image do image
    data generator and in here you can pass in your own preprocessing function for
    exampleã€‚ you can write a function that normalizes the dataã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å†ä¸€æ¬¡ï¼Œè¿™å°±æ˜¯ä½ çš„ç»“æ„åº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚è¿™ä½¿å¾—Tensorflowå›¾åƒæ•°æ®åŠ è½½å™¨éå¸¸ç®€å•ã€‚å› æ­¤ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­è®¾ç½®æˆ‘ä»¬çš„å›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œä»¥ä¾¿ä»Krasé¢„å¤„ç†å›¾åƒä¸­è·å–å›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥ä¼ å…¥è‡ªå·±çš„é¢„å¤„ç†å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œä½ å¯ä»¥ç¼–å†™ä¸€ä¸ªè§„èŒƒåŒ–æ•°æ®çš„å‡½æ•°ã€‚
- en: but in the special case that we only want to normalize itã€‚ we can also pass
    in the rescale argument and then here we use one divided by 255 so we want to
    have our image in the range between0 and1 like we did in the examples beforeã€‚And
    then we have to call this with this generatorï¼Œ we call the flow from directory
    functionã€‚ and then in here we pass in the directory for trainingã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªæƒ³è§„èŒƒåŒ–å®ƒã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä¼ å…¥rescaleå‚æ•°ï¼Œç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨1é™¤ä»¥255ï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å›¾åƒèŒƒå›´åœ¨0åˆ°1ä¹‹é—´ï¼Œå°±åƒä¹‹å‰çš„ç¤ºä¾‹ä¸€æ ·ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»è°ƒç”¨è¿™ä¸ªç”Ÿæˆå™¨ï¼Œè°ƒç”¨ä»ç›®å½•æµçš„å‡½æ•°ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¼ å…¥è®­ç»ƒçš„ç›®å½•ã€‚
- en: So this is in Lego Star Wars images and then train and then we can specify the
    target sizeã€‚ So right now I think the images have to dimension 512 by 512 and
    we can specify a target size and Tensorflow automatically does the resizing for
    usã€‚Then I specify the class mode because I want to have the labels as a single
    integer valueã€‚ So you can alsoï¼Œ for exampleï¼Œ use one hot encoding hereã€‚Then you
    can use the batch sizeã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯ä¹é«˜æ˜Ÿçƒå¤§æˆ˜çš„å›¾åƒï¼Œç„¶åè®­ç»ƒï¼Œç„¶åæˆ‘ä»¬å¯ä»¥æŒ‡å®šç›®æ ‡å¤§å°ã€‚å› æ­¤ï¼Œç°åœ¨æˆ‘è®¤ä¸ºå›¾åƒçš„å°ºå¯¸å¿…é¡»æ˜¯512ä¹˜512ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šä¸€ä¸ªç›®æ ‡å¤§å°ï¼ŒTensorflowä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬è°ƒæ•´å¤§å°ã€‚ç„¶åæˆ‘æŒ‡å®šç±»æ¨¡å¼ï¼Œå› ä¸ºæˆ‘æƒ³å°†æ ‡ç­¾ä½œä¸ºå•ä¸ªæ•´æ•°å€¼ã€‚å› æ­¤ï¼Œä½ ä¹Ÿå¯ä»¥ï¼Œä¾‹å¦‚ï¼Œåœ¨è¿™é‡Œä½¿ç”¨ç‹¬çƒ­ç¼–ç ã€‚ç„¶åä½ å¯ä»¥ä½¿ç”¨æ‰¹é‡å¤§å°ã€‚
- en: Then for our training imagesï¼Œ we say shuffle equals trueã€‚ Then we specify that
    we have RGB imagesã€‚ So againï¼Œ you canï¼Œ you can check out the arguments in the
    documentationã€‚ and then we specify the class names that I hard coded up hereã€‚And
    then we do the same thing for the validation and testã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¹äºæˆ‘ä»¬çš„è®­ç»ƒå›¾åƒï¼Œæˆ‘ä»¬è¯´shuffleç­‰äºtrueã€‚ç„¶åæˆ‘ä»¬æŒ‡å®šæˆ‘ä»¬æœ‰RGBå›¾åƒã€‚å› æ­¤ï¼Œä½ å¯ä»¥åœ¨æ–‡æ¡£ä¸­æ£€æŸ¥å‚æ•°ã€‚ç„¶åæˆ‘ä»¬æŒ‡å®šæˆ‘åœ¨è¿™é‡Œç¡¬ç¼–ç çš„ç±»åã€‚å¯¹äºéªŒè¯å’Œæµ‹è¯•æˆ‘ä»¬ä¹ŸåšåŒæ ·çš„äº‹æƒ…ã€‚
- en: Images and the only difference here is that we use so for trainingï¼Œ we use shuffle
    equals trueã€‚ and for validationï¼Œ we say this is falseã€‚ And so here it doesn't
    really matterã€‚ but especially for testingï¼Œ you want shuffle equals falseã€‚ So now
    if we run thisã€‚ then Tensorflow automatically loads this for usã€‚ So for exampleï¼Œ
    we have let's print theã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒçš„å”¯ä¸€ä¸åŒä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ `shuffle=True`ã€‚è€Œåœ¨éªŒè¯æ—¶ï¼Œæˆ‘ä»¬è®¾ç½®ä¸º `false`ã€‚æ‰€ä»¥è¿™é‡Œå…¶å®æ²¡ä»€ä¹ˆå…³ç³»ï¼Œä½†å°¤å…¶åœ¨æµ‹è¯•æ—¶ï¼Œä½ å¸Œæœ›
    `shuffle=False`ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆ Tensorflow ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬åŠ è½½è¿™äº›ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ¥æ‰“å°ä¸€ä¸‹ã€‚
- en: Shapes of the test batchã€‚ So we said we only have batch size of fourã€‚ So this
    is why we have four differentã€‚Labels hereã€‚And if we have a look at the very first
    batchã€‚ then this is four because we have four samples and then each image has
    the size 256 by 256 by3 because here we specified this image size and we have
    three color channels so let's for exampleã€‚ plot some images with Matpllip so here
    for example it prints the first four images of the test batch so here we have
    Yoda and Duke Skywalker and here we have we print four images of the training
    batch So yeah and now one more thing that I want to show you what we can very
    easily do with this image data generator is to use image augmentation so if we
    have a look at tens of flowã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æµ‹è¯•æ‰¹æ¬¡çš„å½¢çŠ¶ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´æˆ‘ä»¬åªæœ‰å››ä¸ªçš„æ‰¹æ¬¡å¤§å°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬æœ‰å››ä¸ªä¸åŒçš„æ ‡ç­¾ã€‚å¦‚æœæˆ‘ä»¬çœ‹çœ‹ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼Œé‚£ä¹ˆè¿™æ˜¯å››ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å››ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªå›¾åƒçš„å¤§å°æ˜¯
    `256 x 256 x 3`ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è¿™é‡ŒæŒ‡å®šäº†è¿™ä¸ªå›¾åƒå¤§å°ï¼Œå¹¶ä¸”æˆ‘ä»¬æœ‰ä¸‰ä¸ªé¢œè‰²é€šé“ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬ä¾‹å¦‚ç”¨ Matplotlib ç»˜åˆ¶ä¸€äº›å›¾åƒï¼Œè¿™é‡Œæ‰“å°äº†æµ‹è¯•æ‰¹æ¬¡çš„å‰å››ä¸ªå›¾åƒï¼Œè¿™é‡Œæˆ‘ä»¬æœ‰å°¤è¾¾å’Œæœå…‹Â·å¤©è¡Œè€…ï¼Œå¹¶ä¸”æˆ‘ä»¬æ‰“å°äº†è®­ç»ƒæ‰¹æ¬¡çš„å››ä¸ªå›¾åƒã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼Œç°åœ¨æˆ‘æƒ³å‘ä½ å±•ç¤ºçš„å¦ä¸€ä»¶äº‹æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥éå¸¸è½»æ¾åœ°ä½¿ç”¨è¿™ä¸ªå›¾åƒæ•°æ®ç”Ÿæˆå™¨è¿›è¡Œå›¾åƒå¢å¼ºï¼Œå› æ­¤å¦‚æœæˆ‘ä»¬çœ‹çœ‹
    Tensorflowã€‚
- en: Then data augmentation is a technique to increase the diversity of your training
    set by applying random transformations such as image rotation or flippingã€‚So this
    is very useful to have a better generalization of your modelã€‚ and we can very
    easily get this with this data generatorã€‚ So the only thing we have to pass in
    here are some more argumentsã€‚ And then if we want to have thisã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å¢å¼ºæ˜¯ä¸€ç§é€šè¿‡åº”ç”¨éšæœºå˜æ¢ï¼ˆä¾‹å¦‚å›¾åƒæ—‹è½¬æˆ–ç¿»è½¬ï¼‰æ¥å¢åŠ è®­ç»ƒé›†å¤šæ ·æ€§çš„æŠ€æœ¯ã€‚å› æ­¤ï¼Œè¿™å¯¹äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›éå¸¸æœ‰ç”¨ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªæ•°æ®ç”Ÿæˆå™¨éå¸¸å®¹æ˜“åœ°å®ç°è¿™ä¸€ç‚¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¼ å…¥çš„å”¯ä¸€å†…å®¹å°±æ˜¯ä¸€äº›é¢å¤–çš„å‚æ•°ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦è¿™ä¸ªã€‚
- en: then we only do this for the training data setã€‚ So hereï¼Œ for exampleã€‚ we can
    specify the rotation rangeã€‚ we can specify a random horizontal flip and we can
    also specify the a high shift and a width shift and also shearing and zoomingã€‚So
    now if we use thisã€‚ So let me apply all these andã€‚Then againã€‚ you only want to
    do this for your training data and not for theseã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬åªå¯¹è®­ç»ƒæ•°æ®é›†è¿™æ ·åšã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ—‹è½¬èŒƒå›´ï¼ŒæŒ‡å®šéšæœºæ°´å¹³ç¿»è½¬ï¼Œè¿˜å¯ä»¥æŒ‡å®šé«˜åº¦å¹³ç§»ã€å®½åº¦å¹³ç§»ä»¥åŠå‰ªåˆ‡å’Œç¼©æ”¾ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªã€‚é‚£ä¹ˆè®©æˆ‘åº”ç”¨æ‰€æœ‰è¿™äº›ã€‚ç„¶åå†ä¸€æ¬¡ï¼Œä½ åªå¸Œæœ›å¯¹ä½ çš„è®­ç»ƒæ•°æ®è¿™æ ·åšï¼Œè€Œä¸æ˜¯å¯¹è¿™äº›ã€‚
- en: And there are several different waysã€‚ Soï¼Œ of courseã€‚ you can also write your
    own functions to do thisã€‚ But this image data generator makes it very simpleã€‚
    So now let's run this again with an image augmentationã€‚ So let's run this and
    thisã€‚ and this one againã€‚ and yeahï¼Œ so here we seeï¼Œ for exampleã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•ã€‚æ‰€ä»¥ï¼Œå½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥ç¼–å†™è‡ªå·±çš„å‡½æ•°æ¥å®ç°è¿™ä¸ªã€‚ä½†è¿™ä¸ªå›¾åƒæ•°æ®ç”Ÿæˆå™¨ä½¿å¾—è¿™ä¸€åˆ‡å˜å¾—éå¸¸ç®€å•ã€‚é‚£ä¹ˆç°åœ¨è®©æˆ‘ä»¬å†æ¬¡è¿è¡Œè¿™ä¸ªå›¾åƒå¢å¼ºã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå’Œè¿™ä¸ªï¼Œè¿˜æœ‰è¿™ä¸ªï¼Œå†æ¬¡è¿è¡Œã€‚æ˜¯çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¾‹å¦‚ã€‚
- en: we have a slight rotation and probably also a different zoom factor and maybe
    some shearing effects hereã€‚ So yeahï¼Œ let's run it againã€‚ So let's take another
    random pick from the batchesã€‚And againã€‚ let's have a lookã€‚And yeahï¼Œ I think you
    can definitely see that it's doing something with the imagesã€‚ So againï¼Œ this one
    is rotated hereã€‚ So yeahï¼Œ this is a very nice technique that you can easily apply
    hereã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è½»å¾®çš„æ—‹è½¬ï¼Œå¯èƒ½è¿˜æœ‰ä¸åŒçš„ç¼©æ”¾å› å­ï¼Œæˆ–è€…è¿™é‡Œå¯èƒ½æœ‰ä¸€äº›å‰ªåˆ‡æ•ˆæœã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼Œè®©æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬ä»æ‰¹æ¬¡ä¸­éšæœºé€‰æ‹©å¦ä¸€ä¸ªæ ·æœ¬ã€‚å†ä¸€æ¬¡ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºä½ ç»å¯¹å¯ä»¥çœ‹åˆ°å®ƒæ­£åœ¨å¯¹å›¾åƒè¿›è¡Œå¤„ç†ã€‚å› æ­¤ï¼Œè¿™ä¸ªå›¾åƒç¡®å®æ˜¯æ—‹è½¬è¿‡çš„ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™æ˜¯ä¸€ç§ä½ å¯ä»¥å¾ˆå®¹æ˜“åº”ç”¨çš„å¥½æŠ€æœ¯ã€‚
- en: So I'm going to remove this again for nowï¼Œ So because we don't have so many
    imagesã€‚ And in this caseï¼Œ its it actually might confuse our model and make the
    accuracy worseã€‚ So in this exampleï¼Œ I'm going to leave this outã€‚ but keep in mind
    that you can easily do this hereã€‚ So let's use run this and this and this againï¼Œ
    and then we should not see the augmentation anymoreã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ç°åœ¨è¦æš‚æ—¶ç§»é™¤è¿™ä¸ªï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰é‚£ä¹ˆå¤šå›¾åƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå®é™…ä¸Šå¯èƒ½ä¼šæ··æ·†æˆ‘ä»¬çš„æ¨¡å‹å¹¶é™ä½å‡†ç¡®æ€§ã€‚å› æ­¤åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘å°†æŠŠå®ƒæ’é™¤ï¼Œä½†è¯·è®°ä½ï¼Œä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨è¿™é‡Œåšåˆ°è¿™ä¸€ç‚¹ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬å†æ¬¡è¿è¡Œè¿™ä¸ªå’Œè¿™ä¸ªï¼Œç„¶åæˆ‘ä»¬å°±ä¸åº”è¯¥å†çœ‹åˆ°å¢å¼ºæ•ˆæœäº†ã€‚
- en: So yeahï¼Œ I think these are the normal images without rotation or any other effectsã€‚And
    now we set up our convolutional modelã€‚ So this is the same as in tutorial number
    5ã€‚ a simple convolutional neural net with different convolutional layers and max
    pooling and activation functions in betweenã€‚And then at the endï¼Œ we use a dense
    layerã€‚ And this very last layer is importantã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿™äº›æ˜¯æ²¡æœ‰æ—‹è½¬æˆ–å…¶ä»–æ•ˆæœçš„æ­£å¸¸å›¾åƒã€‚ç°åœ¨æˆ‘ä»¬è®¾ç½®å·ç§¯æ¨¡å‹ã€‚è¿™ä¸æ•™ç¨‹5ä¸­çš„å†…å®¹ç›¸åŒï¼Œæ˜¯ä¸€ä¸ªç®€å•çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå…·æœ‰ä¸åŒçš„å·ç§¯å±‚ã€æœ€å¤§æ± åŒ–å’Œæ¿€æ´»å‡½æ•°ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚è¿™ä¸ªæœ€åä¸€å±‚å¾ˆé‡è¦ã€‚
- en: So here we are only using five outputs because we have five different classesã€‚
    So let's run this and print the summary of our modelã€‚ So here we can inspect the
    architectureã€‚And now we set up the loss and the optimizer and the metrics and
    compile our modelã€‚ So this isã€‚ againï¼Œ the same as the last timeã€‚ So what's important
    here is to set from Lo it equals true because we don't use the activation function
    here as last layerã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨äº”ä¸ªè¾“å‡ºï¼Œå› ä¸ºæˆ‘ä»¬æœ‰äº”ä¸ªä¸åŒçš„ç±»åˆ«ã€‚æ‰€ä»¥è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå¹¶æ‰“å°å‡ºæˆ‘ä»¬æ¨¡å‹çš„æ‘˜è¦ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ¶æ„ã€‚ç„¶åæˆ‘ä»¬è®¾ç½®æŸå¤±ã€ä¼˜åŒ–å™¨å’ŒæŒ‡æ ‡å¹¶ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å‹ã€‚è¿™å†æ¬¡ä¸ä¸Šæ¬¡ç›¸åŒã€‚åœ¨è¿™é‡Œé‡è¦çš„æ˜¯è¦è®¾ç½®from_logitsç­‰äºtrueï¼Œå› ä¸ºæˆ‘ä»¬åœ¨æœ€åä¸€å±‚ä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°ã€‚
- en: So let's compile itã€‚And then we can easily call model fit to train our modelã€‚
    And now here I want to show you another new thingã€‚ So I want toã€‚Talk about Karas
    callbacksã€‚ So with callbacksï¼Œ a callback is a function that is applied after each
    training epochã€‚ So here you canï¼Œ for exampleï¼Œ safe checkpoints or use different
    thingsã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬ç¼–è¯‘å®ƒã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è½»æ¾è°ƒç”¨model.fitæ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨æˆ‘æƒ³ç»™ä½ å±•ç¤ºå¦ä¸€ä¸ªæ–°ä¸œè¥¿ã€‚æˆ‘æƒ³è°ˆè°ˆKeraså›è°ƒã€‚å›è°ƒæ˜¯åº”ç”¨äºæ¯ä¸ªè®­ç»ƒepochä¹‹åçš„å‡½æ•°ã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥ï¼Œä¾‹å¦‚ï¼Œä¿å­˜æ£€æŸ¥ç‚¹æˆ–ä½¿ç”¨å…¶ä»–ä¸åŒçš„åŠŸèƒ½ã€‚
- en: And what I want to do here is to use a early stopping callbackã€‚ So we can very
    easily use this because this one is implemented in Kas dot callbacksã€‚ And then
    we say early stoppingã€‚And we want to monitor the validation loss and have a patience
    of fiveã€‚And this means that if the validation laws does not improve for the next
    five epochsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œæƒ³åšçš„æ˜¯ä½¿ç”¨æ—©åœå›è°ƒã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿åœ°ä½¿ç”¨å®ƒï¼Œå› ä¸ºå®ƒå·²ç»åœ¨Kerasçš„å›è°ƒä¸­å®ç°äº†ã€‚ç„¶åæˆ‘ä»¬è®¾ç½®æ—©åœã€‚æˆ‘ä»¬å¸Œæœ›ç›‘æ§éªŒè¯æŸå¤±ï¼Œå¹¶è®¾å®šè€å¿ƒä¸ºäº”ã€‚è¿™æ„å‘³ç€å¦‚æœéªŒè¯æŸå¤±åœ¨æ¥ä¸‹æ¥çš„äº”ä¸ªepochä¸­æ²¡æœ‰æ”¹å–„ã€‚
- en: then it will automatically do an early stopping of our trainingã€‚ Soï¼Œ and then
    when we have thisã€‚ we can specify this argumentã€‚ So we can say callbacks equalsã€‚
    And then this is a list because we can pass in more callbacksï¼Œ if we wantã€‚ And
    then we say early and then stoppingã€‚And then we used the rest of the argumentsã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®ƒå°†è‡ªåŠ¨è¿›è¡Œæ—©åœè®­ç»ƒã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬æœ‰è¿™ä¸ªæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šè¿™ä¸ªå‚æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´å›è°ƒç­‰äºã€‚ç„¶åè¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå› ä¸ºå¦‚æœéœ€è¦ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥æ›´å¤šçš„å›è°ƒã€‚ç„¶åæˆ‘ä»¬è¯´æ—©åœã€‚æ¥ç€æˆ‘ä»¬ä½¿ç”¨å…¶ä½™çš„å‚æ•°ã€‚
- en: And now let's train this and see what happensã€‚Alrightï¼Œ so training is doneã€‚
    So we actually said we want to have 30 epochsï¼Œ but then it stopped after epoch
    10 because our validation loss didn't improveã€‚ So here we have a our lowest value
    or hereï¼Œ And then it didn't get better in the next 5 epochã€‚ So that's why it stopped
    hereã€‚ And what we can see here is if we have a look at the accuracy of our training
    data Then hereã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬è®­ç»ƒè¿™ä¸ªå¹¶çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚å¥½çš„ï¼Œè®­ç»ƒå®Œæˆäº†ã€‚æˆ‘ä»¬å®é™…ä¸Šè¯´æˆ‘ä»¬æƒ³è¦30ä¸ªepochï¼Œä½†åœ¨ç¬¬10ä¸ªepochååœæ­¢äº†ï¼Œå› ä¸ºæˆ‘ä»¬çš„éªŒè¯æŸå¤±æ²¡æœ‰æ”¹å–„ã€‚æ‰€ä»¥è¿™é‡Œæ˜¯æˆ‘ä»¬çš„æœ€ä½å€¼ï¼Œæ¥ç€åœ¨æ¥ä¸‹æ¥çš„5ä¸ªepochä¸­æ²¡æœ‰æ›´å¥½ã€‚å› æ­¤å®ƒåœ¨è¿™é‡Œåœæ­¢äº†ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæˆ‘ä»¬æŸ¥çœ‹è®­ç»ƒæ•°æ®çš„å‡†ç¡®ç‡ï¼Œé‚£ä¹ˆè¿™é‡Œã€‚
- en: for exampleï¼Œ we have 100ã€‚ and 97 in the last epochã€‚ So this is very goodã€‚ But
    now if we have a look at the validation accuracyã€‚ then we see that this one was
    the best and then it's actually getting worseã€‚ and our validation accuracy is
    not very good at allã€‚ So this is aã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨æœ€åä¸€ä¸ªepochä¸­å¾—åˆ°äº†100å’Œ97ã€‚è¿™æ˜¯éå¸¸å¥½çš„ã€‚ä½†æ˜¯ç°åœ¨å¦‚æœæˆ‘ä»¬çœ‹çœ‹éªŒè¯å‡†ç¡®ç‡ï¼Œæˆ‘ä»¬ä¼šå‘ç°è¿™æ˜¯æœ€ä½³çš„ï¼Œä½†å®é™…ä¸Šå´åœ¨ä¸‹é™ï¼Œè€Œæˆ‘ä»¬çš„éªŒè¯å‡†ç¡®ç‡å¹¶ä¸å¥½ã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªã€‚
- en: Clear indicator that we have an overfitting problem to our training dataã€‚ In
    this caseã€‚ it's a little bit due to the problem that we don't have so many images
    available and especially not very much images for the validation setã€‚ So this
    can be one problemã€‚But yeahï¼Œ I think in this caseï¼Œ it's very nice to have this
    call backã€‚ And then we can stop and try to improve this modelã€‚ So I leave this
    for you as homeworkã€‚ You canã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ¸…æ™°åœ°è¡¨æ˜æˆ‘ä»¬å¯¹è®­ç»ƒæ•°æ®å­˜åœ¨è¿‡æ‹Ÿåˆé—®é¢˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéƒ¨åˆ†åŸå› æ˜¯æˆ‘ä»¬æ²¡æœ‰é‚£ä¹ˆå¤šå¯ç”¨çš„å›¾åƒï¼Œå°¤å…¶æ˜¯éªŒè¯é›†çš„å›¾åƒå¾ˆå°‘ã€‚æ‰€ä»¥è¿™å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚ä¸è¿‡ï¼Œæ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‹¥æœ‰è¿™ä¸ªå›è°ƒéå¸¸å¥½ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥åœæ­¢å¹¶å°è¯•æ”¹è¿›è¿™ä¸ªæ¨¡å‹ã€‚æ‰€ä»¥æˆ‘æŠŠè¿™ç•™ç»™ä½ ä½œä¸ºä½œä¸šã€‚ä½ å¯ä»¥ã€‚
- en: for exampleï¼Œ try to use the image augmentation that I showed you or play around
    with the learning rate or per also try to change the architecture of our model
    a little bitã€‚ So yeahï¼Œ this is one thing that we can doã€‚ğŸ˜Šï¼ŒAnd in the next tutorialã€‚
    I also show you another very powerful technique with which we can achieve a very
    high validation accuracyã€‚ even on the small data setã€‚ So I hope you also watch
    the next tutorialã€‚ So for nowã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå°è¯•ä½¿ç”¨æˆ‘å‘ä½ å±•ç¤ºçš„å›¾åƒå¢å¼ºï¼Œæˆ–è€…è°ƒæ•´å­¦ä¹ ç‡ï¼Œæˆ–è€…ä¹Ÿå°è¯•ç¨å¾®æ”¹å˜æˆ‘ä»¬æ¨¡å‹çš„æ¶æ„ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¯ä»¥åšçš„ä¸€ä»¶äº‹ã€‚ğŸ˜Šåœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘è¿˜ä¼šå‘ä½ å±•ç¤ºå¦ä¸€ç§éå¸¸å¼ºå¤§çš„æŠ€æœ¯ï¼Œé€šè¿‡è¿™ç§æŠ€æœ¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å°æ•°æ®é›†ä¸Šå®ç°éå¸¸é«˜çš„éªŒè¯å‡†ç¡®ç‡ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›ä½ ä¹Ÿèƒ½è§‚çœ‹ä¸‹ä¸€ä¸ªæ•™ç¨‹ã€‚æš‚æ—¶å°±è¿™æ ·ã€‚
- en: what I also want to doã€‚ So we can easily save our modelï¼Œ this is one thing I
    already showed youã€‚ So we can save it like thisã€‚ And then if we have a look at
    this folderï¼Œ then it should be hereã€‚ So yeahï¼Œ there it isã€‚ğŸ˜Šï¼ŒAnd then let's plot
    some dataã€‚So here we see the lossã€‚ the training loss decrease trees very nicelyï¼Œ
    but the validation loss not so muchã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æƒ³åšçš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è½»æ¾ä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä»¶æˆ‘å·²ç»å‘ä½ å±•ç¤ºè¿‡çš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åƒè¿™æ ·ä¿å­˜å®ƒã€‚ç„¶åå¦‚æœæˆ‘ä»¬æŸ¥çœ‹è¿™ä¸ªæ–‡ä»¶å¤¹ï¼Œå®ƒåº”è¯¥åœ¨è¿™é‡Œã€‚æ‰€ä»¥æ˜¯çš„ï¼Œå°±åœ¨é‚£é‡Œã€‚ğŸ˜Šç„¶åæˆ‘ä»¬æ¥ç»˜åˆ¶ä¸€äº›æ•°æ®ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æŸå¤±ã€‚è®­ç»ƒæŸå¤±ä¸‹é™å¾—éå¸¸å¥½ï¼Œä½†éªŒè¯æŸå¤±å°±æ²¡é‚£ä¹ˆå¥½äº†ã€‚
- en: And the same with the training accuracy for the trainingï¼Œ it's very goodã€‚ but
    full of validationã€‚ it isn'tã€‚ Soï¼Œ againï¼Œ this can be an indicator that we have
    overfitting hereã€‚ And yeahã€‚ And so now let's evaluate it on the test dataã€‚ And
    againã€‚ here we see that our accuracy is not very good on this test dataã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒçš„å‡†ç¡®ç‡ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œéå¸¸å¥½ã€‚ä½†æ˜¯éªŒè¯çš„å‡†ç¡®ç‡å°±ä¸å¥½äº†ã€‚æ‰€ä»¥ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªæŒ‡æ ‡ï¼Œè¡¨æ˜æˆ‘ä»¬åœ¨è¿™é‡Œå­˜åœ¨è¿‡æ‹Ÿåˆã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°å®ƒã€‚å†æ¬¡åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬åœ¨è¿™ä¸ªæµ‹è¯•æ•°æ®ä¸Šçš„å‡†ç¡®ç‡ä¸æ˜¯å¾ˆå¥½ã€‚
- en: And then if we try to do predictionsï¼Œ we call model predictã€‚ then we also have
    to apply the soft marks here because we didn't use it in our model layers as the
    last layerã€‚ and then to get the actual labelsï¼Œ we have to call the artrc max along
    axis 1ã€‚ So now if we print theã€‚Actual labels and the predicted labelsã€‚ Then we
    see we haveã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¦‚æœæˆ‘ä»¬å°è¯•è¿›è¡Œé¢„æµ‹ï¼Œæˆ‘ä»¬è°ƒç”¨æ¨¡å‹é¢„æµ‹ã€‚ç„¶åæˆ‘ä»¬è¿˜éœ€è¦åœ¨è¿™é‡Œåº”ç”¨è½¯æ ‡è®°ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨æ¨¡å‹å±‚çš„æœ€åä¸€å±‚æ²¡æœ‰ä½¿ç”¨å®ƒã€‚ç„¶åä¸ºäº†è·å–å®é™…æ ‡ç­¾ï¼Œæˆ‘ä»¬å¿…é¡»æ²¿ç€è½´1è°ƒç”¨arctmaxã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬æ‰“å°å®é™…æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾ã€‚ç„¶åæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬æœ‰ã€‚
- en: it's only 50% correct in this caseã€‚ So now againï¼Œ let's print someã€‚New images
    and predictionsã€‚ So yeahï¼Œ so here our prediction is Luke Skywalker againï¼Œ So Luke
    Skywalkerã€‚ this was not very goodã€‚So yeahï¼Œ but now I think you should know how
    we can apply a full project with a real world image data setã€‚And we even achieved
    a high accuracy on the training data set with the techniques that we usedã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒçš„æ­£ç¡®ç‡åªæœ‰50%ã€‚æ‰€ä»¥ç°åœ¨å†æ¬¡æ‰“å°ä¸€äº›æ–°å›¾åƒå’Œé¢„æµ‹ã€‚æ˜¯çš„ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬çš„é¢„æµ‹å†æ¬¡æ˜¯å¢å…‹Â·å¤©è¡Œè€…ï¼Œæ‰€ä»¥å¢å…‹Â·å¤©è¡Œè€…ã€‚è¿™ä¸æ˜¯å¾ˆå¥½ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œä½†ç°åœ¨æˆ‘æƒ³ä½ åº”è¯¥çŸ¥é“æˆ‘ä»¬å¦‚ä½•åº”ç”¨ä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®ï¼Œä½¿ç”¨çœŸå®çš„å›¾åƒæ•°æ®é›†ã€‚æˆ‘ä»¬ç”šè‡³åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå®ç°äº†é«˜å‡†ç¡®ç‡ï¼Œä½¿ç”¨äº†æˆ‘ä»¬æ‰€ç”¨çš„æŠ€æœ¯ã€‚
- en: But yeahï¼Œ we still have to improve it so that it's also good on the validation
    data set and for new data for the test data setã€‚ So in the next tutorialï¼Œ were
    going to learn about transfer learningã€‚ And with thisï¼Œ weã€‚ I think we will achieve
    a pretty good accuracyã€‚ So I hope to see you in the next videoã€‚ and if you enjoyed
    the tutorialï¼Œ please hit the like button and consider subscribing to the channel
    and see you next timeã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ä»ç„¶éœ€è¦æ”¹è¿›ï¼Œä½¿å…¶åœ¨éªŒè¯æ•°æ®é›†å’Œæ–°çš„æµ‹è¯•æ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°è‰¯å¥½ã€‚æ‰€ä»¥åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ è¿ç§»å­¦ä¹ ã€‚é€šè¿‡è¿™ä¸ªï¼Œæˆ‘æƒ³æˆ‘ä»¬ä¼šå®ç°ç›¸å½“ä¸é”™çš„å‡†ç¡®ç‡ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œè¯·ç‚¹å‡»å–œæ¬¢æŒ‰é’®ï¼Œå¹¶è€ƒè™‘è®¢é˜…é¢‘é“ï¼Œä¸‹æ¬¡è§ã€‚
- en: byeã€‚ğŸ˜Šã€‚![](img/7956a7f6b5a10c99728c67c08635cf0e_8.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å†è§ã€‚ğŸ˜Šï¼[](img/7956a7f6b5a10c99728c67c08635cf0e_8.png)
