- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P36ï¼šL6.5- ä½¿ç”¨YOLODarknetè¯†åˆ«å¤šä¸ªå›¾åƒ
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P36ï¼šL6.5- ä½¿ç”¨YOLODarknetè¯†åˆ«å¤šä¸ªå›¾åƒ
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonã€‚ Wecome to applications of deep neural networks with
    Washington Universityã€‚ In this videoï¼Œ we're going to talk about Darknet and yellowã€‚
    I don't mean darknet like the Internetã€‚ I meanï¼Œ darknetï¼Œ like multiple object
    detectionã€‚ You probably see all these boxes around me as the system is able to
    detect various thingsã€‚ğŸ˜Šï¼ŒWe will see how we can make use of this technology in
    Python using Tensorflow for the latest on my AI course and projectsã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚åœ¨è¿™æ®µè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºDarknetå’ŒYoloã€‚æˆ‘ä¸æ˜¯æŒ‡åƒäº’è”ç½‘é‚£æ ·çš„æš—ç½‘ã€‚æˆ‘æ˜¯æŒ‡ï¼Œæš—ç½‘ï¼Œåƒå¤šä¸ªç‰©ä½“æ£€æµ‹ã€‚ä½ å¯èƒ½ä¼šçœ‹åˆ°æˆ‘å‘¨å›´çš„æ‰€æœ‰è¿™äº›æ¡†ï¼Œå› ä¸ºç³»ç»Ÿèƒ½å¤Ÿæ£€æµ‹å„ç§äº‹ç‰©ã€‚ğŸ˜Šï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨Tensorflowåœ¨Pythonä¸­åˆ©ç”¨è¿™é¡¹æŠ€æœ¯ï¼Œäº†è§£æˆ‘AIè¯¾ç¨‹å’Œé¡¹ç›®çš„æœ€æ–°åŠ¨æ€ã€‚
- en: click subscribe and the bell next to it to be notified of every new videoã€‚ All
    rightã€‚ you'll notice I am in Google co layout for this oneã€‚ We're going to be
    making use of the GPUã€‚ So let's go aheadï¼Œ make sure you have class 6 of mine open
    andã€‚ğŸ˜Šï¼ŒGoogle Collaboratoryã€‚ It's on Githubã€‚ I have a link to the Github repository
    at the bottom of this video in the descriptionã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹å‡»è®¢é˜…å¹¶æŒ‰æ—è¾¹çš„é“ƒé“›ä»¥æ¥æ”¶æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚å¥½å§ã€‚ä½ ä¼šæ³¨æ„åˆ°æˆ‘åœ¨è¿™æ¬¡çš„è§†é¢‘ä¸­ä½¿ç”¨äº†Googleåä½œå¸ƒå±€ã€‚æˆ‘ä»¬å°†åˆ©ç”¨GPUã€‚æ‰€ä»¥è®©æˆ‘ä»¬å¼€å§‹ï¼Œç¡®ä¿ä½ æ‰“å¼€äº†æˆ‘çš„ç¬¬6èŠ‚è¯¾ã€‚ğŸ˜Šï¼ŒGoogle
    Collaboratoryã€‚è¿™åœ¨Githubä¸Šã€‚æˆ‘åœ¨æœ¬è§†é¢‘æè¿°çš„åº•éƒ¨æœ‰ä¸€ä¸ªæŒ‡å‘Githubå­˜å‚¨åº“çš„é“¾æ¥ã€‚
- en: And we're going to go to runtimeï¼Œ change runtime typeã€‚ And I already have it
    in thereã€‚ But make sure that you have the GPUã€‚ Don't worry about this Python 3ï¼Œ6
    yellowã€‚ That was from my local environmentã€‚ Google does not have thatã€‚ So you'll
    want Python 3ã€‚ And we'll save thatã€‚ So let's scroll down to part 5 of thisã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å»è¿è¡Œæ—¶ï¼Œæ”¹å˜è¿è¡Œæ—¶ç±»å‹ã€‚æˆ‘å·²ç»æŠŠå®ƒæ”¾è¿›å»äº†ã€‚ä½†ç¡®ä¿ä½ æœ‰GPUã€‚ä¸è¦æ‹…å¿ƒè¿™ä¸ªPython 3,6é»„è‰²ã€‚è¿™æ˜¯æˆ‘æœ¬åœ°ç¯å¢ƒä¸­çš„ã€‚Googleæ²¡æœ‰é‚£ä¸ªã€‚æ‰€ä»¥ä½ è¦Python
    3ã€‚ç„¶åæˆ‘ä»¬ä¼šä¿å­˜å®ƒã€‚è®©æˆ‘ä»¬å‘ä¸‹æ»šåŠ¨åˆ°ç¬¬5éƒ¨åˆ†ã€‚
- en: because this is what we're talking aboutã€‚ We're going to look at how I was able
    to shoot that video that you saw leading up to this that has all the squares around
    thatã€‚ğŸ˜Šã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºè¿™å°±æ˜¯æˆ‘ä»¬æ‰€è°ˆè®ºçš„ã€‚æˆ‘ä»¬å°†çœ‹çœ‹æˆ‘å¦‚ä½•æ‹æ‘„ä½ åœ¨è¿™ä¹‹å‰çœ‹åˆ°çš„è§†é¢‘ï¼Œå…¶ä¸­æœ‰æ‰€æœ‰çš„æ–¹æ¡†ã€‚ğŸ˜Šã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_1.png)
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_2.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_2.png)'
- en: But we're going to startï¼Œ and we're going to look at how we can now recognize
    multiple images with a convolution neural networkã€‚ A single convolution neural
    networkï¼Œ like we look at a few parts agoï¼Œ can recognize multiple imagesã€‚ If it's
    big enoughã€‚ It's able to look at an image and mark theseã€‚ So you'll see microwave
    personã€‚ Heyï¼Œ I'm a personã€‚ And several bottles sitting on my windowã€‚ That is trueã€‚
    This isã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬å°†å¼€å§‹ï¼Œçœ‹çœ‹å¦‚ä½•ç°åœ¨é€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œè¯†åˆ«å¤šä¸ªå›¾åƒã€‚åƒæˆ‘ä»¬å‡ éƒ¨åˆ†å‰çœ‹åˆ°çš„å•ä¸ªå·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥è¯†åˆ«å¤šä¸ªå›¾åƒã€‚å¦‚æœå®ƒè¶³å¤Ÿå¤§ã€‚å®ƒèƒ½å¤ŸæŸ¥çœ‹å›¾åƒå¹¶æ ‡è®°è¿™äº›ã€‚æ‰€ä»¥ä½ ä¼šçœ‹åˆ°å¾®æ³¢ç‚‰æ—è¾¹æœ‰äººã€‚å˜¿ï¼Œæˆ‘æ˜¯ä¸€ä¸ªäººã€‚è¿˜æœ‰å‡ ç“¶ååœ¨æˆ‘çš„çª—å°ä¸Šã€‚è¿™æ˜¯çœŸçš„ã€‚è¿™å°±æ˜¯ã€‚
- en: this is my kitchenã€‚ actuallyï¼Œ sink starting to make dinnerï¼Œ for for meï¼Œ not
    the dogã€‚ but he's there wanting to see what I'm see what I'm doingã€‚ He's always
    right around whenever we're cooking somethingã€‚ But this image is trained using
    exactly the sameã€‚ğŸ˜Šã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘çš„å¨æˆ¿ã€‚å®é™…ä¸Šï¼Œæ°´æ§½å¼€å§‹ä¸ºæˆ‘åšæ™šé¤ï¼Œè€Œä¸æ˜¯ä¸ºç‹—ã€‚ä½†å®ƒåœ¨é‚£é‡Œæƒ³çœ‹çœ‹æˆ‘åœ¨åšä»€ä¹ˆã€‚æ¯å½“æˆ‘ä»¬åšé¥­æ—¶ï¼Œå®ƒæ€»æ˜¯åœ¨é™„è¿‘ã€‚ä½†è¿™ä¸ªå›¾åƒæ­£æ˜¯ç”¨ç›¸åŒçš„æ–¹æ³•è®­ç»ƒçš„ã€‚ğŸ˜Šã€‚
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_4.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_4.png)'
- en: Technology that we saw with the convolution neural networksã€‚ This is something
    called Yoloã€‚ And I give you a link to the paperã€‚ Yolow stands for you only look
    onceã€‚ and what's so cool about this technology is it is using a single convolution
    neural network that has a fairly complex output layerã€‚ So it's not a simple classificationsã€‚
    Also regressionã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­çœ‹åˆ°çš„æŠ€æœ¯ã€‚è¿™æ˜¯ä¸€ç§å«åšYoloçš„ä¸œè¥¿ã€‚æˆ‘ç»™ä½ ä¸€ä¸ªé“¾æ¥åˆ°è®ºæ–‡ã€‚Yoloä»£è¡¨ä½ åªçœ‹ä¸€æ¬¡ã€‚è€Œè¿™é¡¹æŠ€æœ¯çš„é…·ä¹‹å¤„åœ¨äºï¼Œå®ƒä½¿ç”¨çš„æ˜¯ä¸€ä¸ªå…·æœ‰ç›¸å½“å¤æ‚è¾“å‡ºå±‚çš„å•ä¸ªå·ç§¯ç¥ç»ç½‘ç»œã€‚æ‰€ä»¥è¿™ä¸ä»…ä»…æ˜¯ç®€å•çš„åˆ†ç±»ï¼Œè¿˜æœ‰å›å½’ã€‚
- en: And it literally sends out to you all of these images that are foundã€‚ So that's
    what's reallyã€‚ really cool about this about convolution neural networksã€‚ you can
    make those output layers send out just about anything that you wantï¼Œ reallyã€‚ you
    can have it send out in this caseï¼Œ multiple bounding rectangles and what it thinks
    is in each of thoseã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒç¡®å®å‘ä½ å‘é€äº†æ‰€æœ‰è¿™äº›æ‰¾åˆ°çš„å›¾åƒã€‚æ‰€ä»¥è¿™å°±æ˜¯å·ç§¯ç¥ç»ç½‘ç»œçœŸæ­£é…·çš„åœ°æ–¹ã€‚ä½ å¯ä»¥è®©è¾“å‡ºå±‚å‘é€å‡ ä¹ä»»ä½•ä½ æƒ³è¦çš„ä¸œè¥¿ï¼Œå®é™…ä¸Šã€‚ä½ å¯ä»¥è®©å®ƒåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå‘é€å¤šä¸ªè¾¹ç•ŒçŸ©å½¢ä»¥åŠå®ƒè®¤ä¸ºæ¯ä¸ªçŸ©å½¢ä¸­çš„å†…å®¹ã€‚
- en: ğŸ˜Šï¼ŒIn the next moduleï¼Œ we'll look at GNs and we'll see that it can even output
    an imageã€‚ The input to aganN won't be an imageã€‚ It will actually be a number like
    a seedã€‚ and the output will be an imageã€‚ So a convolution neural networkï¼Œ the
    input can be imagesã€‚ The output can be imagesã€‚ Both the input and the output can
    be images or one or the otherã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œåœ¨ä¸‹ä¸€ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹GANsï¼Œçœ‹çœ‹å®ƒç”šè‡³å¯ä»¥è¾“å‡ºä¸€å¼ å›¾åƒã€‚è¾“å…¥åˆ°GANçš„ä¸æ˜¯å›¾åƒï¼Œè€Œæ˜¯ä¸€ä¸ªåƒç§å­ä¸€æ ·çš„æ•°å­—ã€‚è¾“å‡ºå°†æ˜¯å›¾åƒã€‚æ‰€ä»¥å·ç§¯ç¥ç»ç½‘ç»œï¼Œè¾“å…¥å¯ä»¥æ˜¯å›¾åƒã€‚è¾“å‡ºä¹Ÿå¯ä»¥æ˜¯å›¾åƒã€‚è¾“å…¥å’Œè¾“å‡ºéƒ½å¯ä»¥æ˜¯å›¾åƒæˆ–å…¶ä¸­ä¹‹ä¸€ã€‚
- en: So we're going to look at convolution neural networks in quite a few of the
    modules of this class because they're very multifacetedã€‚ You can use them for
    natural language processing imagesã€‚ Nowã€‚ you can also run this on a live streamã€‚
    So this was just a picture that my wife took on on her cell phoneã€‚ğŸ˜Šã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å°†åœ¨è¿™èŠ‚è¯¾çš„å¤šä¸ªæ¨¡å—ä¸­ç ”ç©¶å·ç§¯ç¥ç»ç½‘ç»œï¼Œå› ä¸ºå®ƒä»¬éå¸¸å¤šé¢åŒ–ã€‚ä½ å¯ä»¥å°†å®ƒä»¬ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†å›¾åƒã€‚ç°åœ¨ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ç›´æ’­ä¸­è¿è¡Œè¿™ä¸ªã€‚æ‰€ä»¥è¿™åªæ˜¯æˆ‘å¦»å­ç”¨æ‰‹æœºæ‹çš„ç…§ç‰‡ã€‚ğŸ˜Šã€‚
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_6.png)'
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_7.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_7.png)'
- en: This isï¼Œ wellï¼Œ this is also from a cell phoneã€‚ This was not using the normal
    camera that I record this class fromã€‚ So when I was on that video talking about
    thisï¼Œ I wasn't able to speak to some of the things that it was classifying or
    misclassifying correctly because it was being recorded to a videoã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ï¼Œå—¯ï¼Œè¿™ä¹Ÿæ˜¯ç”¨æ‰‹æœºæ‹çš„ã€‚è¿™å¹¶ä¸æ˜¯æˆ‘ç”¨æ¥å½•åˆ¶è¿™èŠ‚è¯¾çš„æ­£å¸¸ç›¸æœºã€‚æ‰€ä»¥å½“æˆ‘åœ¨è§†é¢‘ä¸­è°ˆè®ºè¿™äº›æ—¶ï¼Œæˆ‘æ— æ³•æ­£ç¡®åœ°è®¨è®ºå®ƒæ­£åœ¨åˆ†ç±»æˆ–é”™è¯¯åˆ†ç±»çš„æŸäº›å†…å®¹ï¼Œå› ä¸ºå®ƒæ˜¯å½•åˆ¶åˆ°è§†é¢‘ä¸­çš„ã€‚
- en: I don't have a strong enough GPU hooked up on one of my local computers hereã€‚
    I normally do GP in the cloud to actually live stream this sort of videoã€‚ if you
    want to live stream this sort of videoã€‚ the GPU a Titan V would be greatã€‚ about
    3000 bucks for one of thoseã€‚ So I presently do not do not own one of thoseã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œçš„æœ¬åœ°ç”µè„‘ä¸Šæ²¡æœ‰è¿æ¥å¼ºå¤§çš„GPUã€‚æˆ‘é€šå¸¸åœ¨äº‘ç«¯åšGPUä»¥ç›´æ’­è¿™ç§è§†é¢‘ã€‚å¦‚æœä½ æƒ³ç›´æ’­è¿™ç§è§†é¢‘ï¼ŒTitan Vçš„GPUå°†éå¸¸åˆé€‚ã€‚å¤§çº¦3000ç¾å…ƒã€‚æ‰€ä»¥æˆ‘ç›®å‰å¹¶ä¸æ‹¥æœ‰è¿™æ ·çš„è®¾å¤‡ã€‚
- en: I've thought of itï¼Œ but just have not most of the stuff that I do is not live
    streaming videoã€‚ So I I just do this in the cloudï¼Œ and I use B100sï¼Œ which are
    similar to thoseã€‚ but it's 4 bucks an hour rather than many thousands of dollars
    for a onetime investmentã€‚ just depends on what you're going to doã€‚ if I was using
    that thing hours and hours a dayã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è¿‡è¿™ä¸ªï¼Œä½†å¤§å¤šæ•°æˆ‘åšçš„äº‹æƒ…å¹¶ä¸æ˜¯ç›´æ’­è§†é¢‘ã€‚æ‰€ä»¥æˆ‘åªæ˜¯åœ¨äº‘ç«¯åšè¿™ä¸ªï¼Œæˆ‘ä½¿ç”¨B100sï¼Œè¿™äº›ä¸é‚£äº›ç›¸ä¼¼ã€‚ä½†æ¯å°æ—¶4ç¾å…ƒï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§æŠ•èµ„å‡ åƒç¾å…ƒã€‚è¿™å®Œå…¨å–å†³äºä½ è¦åšä»€ä¹ˆã€‚å¦‚æœæˆ‘æ¯å¤©ä½¿ç”¨é‚£ä¸ªè®¾å¤‡æ•°å°æ—¶ã€‚
- en: it would make sense to do the 3ã€‚ If you look at thisã€‚ This does show some of
    the limitationsã€‚ notice it's going beerk on my bookshelfã€‚ It is classifying every
    single one of those booksã€‚ğŸ˜Šã€‚Is fascinating about this up here in the image of
    my kitchenã€‚ It's not It's classifiedifying as a handful of things Hereã€‚ It's classifying
    hundredsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åšè¿™ä¸ª3æ˜¯æœ‰æ„ä¹‰çš„ã€‚å¦‚æœä½ çœ‹ä¸€ä¸‹ï¼Œè¿™ç¡®å®æ˜¾ç¤ºå‡ºä¸€äº›é™åˆ¶ã€‚æ³¨æ„å®ƒåœ¨æˆ‘çš„ä¹¦æ¶ä¸Šæ­£åœ¨åˆ†ç±»æ¯ä¸€æœ¬ä¹¦ã€‚ğŸ˜Šã€‚æœ‰è¶£çš„æ˜¯ï¼Œåœ¨æˆ‘å¨æˆ¿çš„è¿™ä¸ªå›¾åƒä¸­ã€‚å®ƒæ²¡æœ‰ï¼Œå®ƒåˆ†ç±»ä¸ºè¿™é‡Œçš„ä¸€å°éƒ¨åˆ†ä¸œè¥¿ã€‚å®ƒæ­£åœ¨åˆ†ç±»æˆç™¾ä¸Šåƒçš„ä¸œè¥¿ã€‚
- en: The processing time is consistentã€‚ You only look once it's not looking at each
    of those booksã€‚ We'll see how that works in a momentã€‚ But you can see it's classifying
    the TV monitor and other thingsã€‚ this yellow thing here is actually a toolboxã€‚
    but it keeps thinking it's a remote control or or other thingsã€‚ it is correctly
    classifying my laptop in the videoï¼Œ it's not always classifying it correctlyã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†æ—¶é—´æ˜¯ä¸€è‡´çš„ã€‚ä½ åªéœ€çœ‹ä¸€æ¬¡ï¼Œå®ƒå¹¶æ²¡æœ‰æŸ¥çœ‹é‚£äº›ä¹¦ç±ä¸­çš„æ¯ä¸€æœ¬ã€‚æˆ‘ä»¬ç¨åä¼šçœ‹çœ‹è¿™å¦‚ä½•è¿ä½œã€‚ä½†æ˜¯ä½ å¯ä»¥çœ‹åˆ°å®ƒæ­£åœ¨åˆ†ç±»ç”µè§†ç›‘è§†å™¨å’Œå…¶ä»–ä¸œè¥¿ã€‚è¿™é‡Œçš„é»„è‰²ä¸œè¥¿å®é™…ä¸Šæ˜¯ä¸€ä¸ªå·¥å…·ç®±ï¼Œä½†å®ƒä¸€ç›´è®¤ä¸ºå®ƒæ˜¯ä¸€ä¸ªé¥æ§å™¨æˆ–å…¶ä»–ä¸œè¥¿ã€‚å®ƒåœ¨è§†é¢‘ä¸­æ­£ç¡®åœ°åˆ†ç±»äº†æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œä½†å¹¶ä¸æ€»æ˜¯æ­£ç¡®åˆ†ç±»ã€‚
- en: It is classifying me as two peopleã€‚ My head is one personï¼Œ the rest of me is
    another personã€‚ I also stood for thisã€‚ stood up because normallyï¼Œ if you've watched
    a lot of my videos and hopefully have go ahead and subscribe so that you you can
    when I'm sitting down with the usual pose that I use when I introduce and conclude
    a videoã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå°†æˆ‘åˆ†ç±»ä¸ºä¸¤ä¸ªäººã€‚æˆ‘çš„å¤´æ˜¯ä¸€äººï¼Œå‰©ä¸‹çš„æˆ‘æ˜¯å¦ä¸€ä¸ªäººã€‚æˆ‘ä¹Ÿç«™ç€è¿™ä¸ªã€‚å› ä¸ºå¦‚æœä½ çœ‹è¿‡æˆ‘å¾ˆå¤šè§†é¢‘ï¼Œå¸Œæœ›ä½ èƒ½å»è®¢é˜…ï¼Œä»¥ä¾¿åœ¨æˆ‘åç€æ—¶å¯ä»¥çœ‹åˆ°æˆ‘é€šå¸¸ä»‹ç»å’Œæ€»ç»“è§†é¢‘çš„å§¿åŠ¿ã€‚
- en: It wasn't recognizing meã€‚ It was just recognizing all my booksã€‚ And who caresã€‚
    That's boringã€‚ I wanted to recognize meã€‚ Not that I felt chited or anything by
    thatã€‚ It's also recognizing my chairï¼Œ which is goodã€‚ that's really just one chairã€‚
    So let's talk about how Yoã€‚ğŸ˜Šï¼Œright nowï¼Œ this is just about state of the art for
    multiimage detectionã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ²¡æœ‰è¯†åˆ«æˆ‘ã€‚å®ƒåªæ˜¯è¯†åˆ«äº†æˆ‘æ‰€æœ‰çš„ä¹¦ã€‚è°åœ¨ä¹å‘¢ï¼Ÿè¿™å¤ªæ— èŠäº†ã€‚æˆ‘æƒ³è®©å®ƒè¯†åˆ«æˆ‘ã€‚å¹¶ä¸æ˜¯è¯´æˆ‘è§‰å¾—è¢«å¿½è§†ã€‚å®ƒè¿˜è¯†åˆ«äº†æˆ‘çš„æ¤…å­ï¼Œè¿™å¾ˆå¥½ã€‚å…¶å®å°±ä¸€æŠŠæ¤…å­ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬è°ˆè°ˆYoã€‚ğŸ˜Šï¼Œç°åœ¨ï¼Œè¿™æ­£æ˜¯å¤šå›¾åƒæ£€æµ‹çš„æœ€å‰æ²¿æŠ€æœ¯ã€‚
- en: And you can do some reallyï¼Œ really cool things with thisã€‚ I mean say I wanted
    to put a dog door on the back of my houseã€‚ and I only wanted the dog to go throughã€‚
    I could just write a very simple program to stream itã€‚ And so long as I saw a
    dog somewhere it would open the doorã€‚ Hopefullyã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ç”¨è¿™ä¸ªåšä¸€äº›éå¸¸ã€éå¸¸é…·çš„äº‹æƒ…ã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œå‡è®¾æˆ‘æƒ³åœ¨æˆ‘å®¶åé¢æ”¾ä¸€ä¸ªç‹—é—¨ï¼Œè€Œæˆ‘åªå¸Œæœ›ç‹—å¯ä»¥é€šè¿‡ã€‚æˆ‘å¯ä»¥å†™ä¸€ä¸ªéå¸¸ç®€å•çš„ç¨‹åºæ¥å®ç°ã€‚åªè¦æˆ‘åœ¨æŸä¸ªåœ°æ–¹çœ‹åˆ°ä¸€åªç‹—ï¼Œå®ƒå°±ä¼šæ‰“å¼€é—¨ã€‚å¸Œæœ›å¦‚æ­¤ã€‚
- en: it would not misclassify a raccoon as a dogã€‚ So how does Yolo workã€‚ This is
    a convolution neural network just like we've seenã€‚ We create an S by S gridã€‚ There's
    several standard sizes for thisã€‚ Usually it's not too bigã€‚ It's in the teensã€‚
    typicallyyp it basically resizes your imageï¼Œ or it puts a grid over it more soã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸ä¼šæŠŠæµ£ç†Šè¯¯åˆ¤ä¸ºç‹—ã€‚é‚£ä¹ˆYoloæ˜¯å¦‚ä½•å·¥ä½œçš„å‘¢ï¼Ÿè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå°±åƒæˆ‘ä»¬çœ‹åˆ°çš„é‚£æ ·ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªSä¹˜Sçš„ç½‘æ ¼ã€‚å¯¹æ­¤æœ‰å‡ ä¸ªæ ‡å‡†å°ºå¯¸ã€‚é€šå¸¸ä¸ä¼šå¤ªå¤§ã€‚é€šå¸¸åœ¨åå‡ çš„èŒƒå›´å†…ã€‚å®ƒåŸºæœ¬ä¸Šä¼šè°ƒæ•´ä½ çš„å›¾åƒå¤§å°ï¼Œæˆ–è€…åœ¨å…¶ä¸Šæ”¾ç½®ä¸€ä¸ªç½‘æ ¼ã€‚
- en: And it runs the convolution neural networkï¼Œ and it gets a lot of these squaresã€‚
    these potential bounding boxes are called with predictionsã€‚ But most of them are
    not going to be good enoughã€‚ We throw them awayã€‚ We set a threshold and only things
    above that fairly wellestablish thresholdã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿è¡Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¹¶è·å¾—äº†å¾ˆå¤šè¿™äº›æ–¹æ¡†ã€‚è¿™äº›æ½œåœ¨çš„è¾¹ç•Œæ¡†è¢«ç§°ä¸ºé¢„æµ‹ã€‚ä½†å¤§å¤šæ•°éƒ½ä¸å¤Ÿå¥½ã€‚æˆ‘ä»¬æŠŠå®ƒä»¬æ‰”æ‰ã€‚æˆ‘ä»¬è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œåªä¿ç•™é«˜äºè¿™ä¸ªç›¸å¯¹ç¡®å®šçš„é˜ˆå€¼çš„ä¸œè¥¿ã€‚
- en: Are we going to actually displayã€‚ So you can tune how sensitive it is in that
    regardã€‚ Nowã€‚ this is a convolution neural networkã€‚ So we need to see how thisã€‚ğŸ˜Šï¼ŒIs
    workingã€‚ The output layer to this is very interestingã€‚ So previous neural networks
    that I showed you were either classification or regressionã€‚ This is bothã€‚ technicalnicallyï¼Œ
    the paper calls it regressionã€‚ So I suppose it's regressionï¼Œ butã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦å®é™…å±•ç¤ºå—ï¼Ÿæ‰€ä»¥ä½ å¯ä»¥è°ƒèŠ‚å®ƒåœ¨è¿™æ–¹é¢çš„æ•æ„Ÿåº¦ã€‚ç°åœ¨ï¼Œè¿™æ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦çœ‹çœ‹è¿™ä¸ªã€‚ğŸ˜Šï¼Œå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚è¾“å‡ºå±‚éå¸¸æœ‰è¶£ã€‚æˆ‘ä¹‹å‰å±•ç¤ºçš„ç¥ç»ç½‘ç»œéƒ½æ˜¯åˆ†ç±»æˆ–å›å½’ã€‚è¿™æ˜¯ä¸¤è€…å…¼å…·ã€‚æŠ€æœ¯ä¸Šï¼Œè®ºæ–‡ç§°ä¹‹ä¸ºå›å½’ã€‚æ‰€ä»¥æˆ‘æƒ³è¿™ç®—æ˜¯å›å½’ï¼Œä½†ã€‚
- en: I consider this almost a hybrid of classification because here's what's happeningã€‚Essentialã€‚
    a whole bunch of bounding boxes are coming backã€‚ What confused me when I first
    looked at Yolo was you'll see hereã€‚ a whole bunch of squares come back hereã€‚ Not
    so manyã€‚ neural network output layers are fixed lengthã€‚ They don't change their
    lengthã€‚ unless they're generative neural networkã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å‡ ä¹å°†å…¶è§†ä¸ºåˆ†ç±»çš„æ··åˆä½“ï¼Œå› ä¸ºå‘ç”Ÿçš„äº‹æƒ…æ˜¯ã€‚åŸºæœ¬ä¸Šï¼Œå¾ˆå¤šè¾¹ç•Œæ¡†è¢«è¿”å›ã€‚å½“æˆ‘ç¬¬ä¸€æ¬¡çœ‹åˆ°Yoloæ—¶ï¼Œè¿™è®©æˆ‘å›°æƒ‘ã€‚ä½ ä¼šçœ‹åˆ°è¿™é‡Œè¿”å›äº†ä¸€å †æ–¹æ¡†ã€‚æ²¡æœ‰é‚£ä¹ˆå¤šã€‚ç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚æ˜¯å›ºå®šé•¿åº¦çš„ã€‚é™¤éå®ƒä»¬æ˜¯ç”Ÿæˆå‹ç¥ç»ç½‘ç»œï¼Œå¦åˆ™ä¸ä¼šæ”¹å˜é•¿åº¦ã€‚
- en: but we'll get more into that when we get into natural language processingã€‚ But
    these are not generative in that regardã€‚ They're just giving you one set of fixed
    output neuronsã€‚ And the number of output neurons is fixedã€‚ It's a tensorã€‚ I was
    wondering at firstã€‚ how is it giving me a variable list ofã€‚ Wellï¼Œ the answer isã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å½“æˆ‘ä»¬è¿›å…¥è‡ªç„¶è¯­è¨€å¤„ç†æ—¶ï¼Œæˆ‘ä»¬ä¼šæ›´æ·±å…¥åœ°è®¨è®ºã€‚ä½†è¿™äº›åœ¨è¿™æ–¹é¢ä¸æ˜¯ç”Ÿæˆå‹çš„ã€‚å®ƒä»¬åªæ˜¯ç»™ä½ ä¸€ç»„å›ºå®šçš„è¾“å‡ºç¥ç»å…ƒã€‚è¾“å‡ºç¥ç»å…ƒçš„æ•°é‡æ˜¯å›ºå®šçš„ã€‚è¿™æ˜¯ä¸€ä¸ªå¼ é‡ã€‚æˆ‘èµ·åˆåœ¨æƒ³ã€‚å®ƒæ˜¯å¦‚ä½•ç»™æˆ‘ä¸€ä¸ªå¯å˜çš„åˆ—è¡¨çš„ã€‚å¥½å§ï¼Œç­”æ¡ˆæ˜¯ã€‚
- en: and it's more evident And this figure from the paperã€‚ This is the overall gridsã€‚
    that's that S by S that you're presenting inã€‚ It returns something like thisã€‚
    It returns a ton of bounding boxesã€‚ The total number of bounding boxes returned
    is always fixedã€‚ So there is a fixed number of output neuronsã€‚ It's just you throw
    away the weaker ones that it's not as confident inã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´æ˜æ˜¾çš„æ˜¯æ¥è‡ªè®ºæ–‡ä¸­çš„è¿™ä¸ªå›¾ã€‚è¿™æ˜¯æ•´ä½“ç½‘æ ¼ã€‚è¿™å°±æ˜¯ä½ å±•ç¤ºçš„Sä¹˜Sã€‚å®ƒè¿”å›ç±»ä¼¼è¿™æ ·çš„ä¸œè¥¿ã€‚å®ƒè¿”å›å¤§é‡çš„è¾¹ç•Œæ¡†ã€‚è¿”å›çš„è¾¹ç•Œæ¡†æ€»æ•°å§‹ç»ˆæ˜¯å›ºå®šçš„ã€‚å› æ­¤ï¼Œè¾“å‡ºç¥ç»å…ƒçš„æ•°é‡æ˜¯å›ºå®šçš„ã€‚åªéœ€æ‰”æ‰é‚£äº›å®ƒä¸å¤ªè‡ªä¿¡çš„è¾ƒå¼±çš„ã€‚
- en: And here you can see the darkness of the bounding boxã€‚ So reallyã€‚ğŸ˜Šã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_9.png)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°è¾¹ç•Œæ¡†çš„é»‘æš—ã€‚æ‰€ä»¥çœŸçš„ã€‚ğŸ˜Šã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_9.png)
- en: That's darkï¼Œ that's darkã€‚ That's star and that's darkã€‚ So dog by carã€‚ So that
    is those are the ones that are ultimately above the threshold and consideredã€‚
    So let's look at what that output layer actually looks like because the input
    layer on upã€‚ that's just a typical convolution neural networkã€‚ It's got convolution
    layersã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£æ˜¯é»‘æš—çš„ï¼Œé‚£æ˜¯é»‘æš—çš„ã€‚é‚£æ˜¯æ˜Ÿæ˜Ÿï¼Œé‚£æ˜¯é»‘æš—çš„ã€‚æ‰€ä»¥ç‹—ä¸è½¦ã€‚æ‰€ä»¥è¿™äº›æœ€ç»ˆéƒ½æ˜¯è¶…è¿‡é˜ˆå€¼å¹¶è¢«è€ƒè™‘çš„æ ‡ç­¾ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¾“å‡ºå±‚å®é™…æ˜¯ä»€ä¹ˆæ ·å­ï¼Œå› ä¸ºè¾“å…¥å±‚åŠå…¶ä»¥ä¸Šçš„éƒ¨åˆ†ã€‚è¿™åªæ˜¯ä¸€ä¸ªå…¸å‹çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚å®ƒæœ‰å·ç§¯å±‚ã€‚
- en: maxpoing layers and dense layersã€‚ just like any other that you have What you
    haveï¼Œ thoughã€‚ for the output neurons is a bunch of bounding boxes coming backã€‚
    And each bounding boxã€‚ So these are the values that are in your output layerã€‚
    and it's just these six things repeated over and over and over againã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¤§æ± åŒ–å±‚å’Œå¯†é›†å±‚ã€‚å°±åƒä½ æ‹¥æœ‰çš„ä»»ä½•å…¶ä»–å±‚ä¸€æ ·ã€‚ç„¶è€Œï¼Œè¾“å‡ºç¥ç»å…ƒè¿”å›çš„æ˜¯ä¸€å †è¾¹ç•Œæ¡†ã€‚æ¯ä¸ªè¾¹ç•Œæ¡†ã€‚è¿™äº›æ˜¯ä½ è¾“å‡ºå±‚ä¸­çš„å€¼ï¼Œå®ƒä»¬åªæ˜¯è¿™å…­ä¸ªå€¼ä¸æ–­é‡å¤ã€‚
- en: So you have x coordinate a Y coordinateã€‚ that's the center of one of these bounding
    boxesã€‚ Wellã€‚ they're not boxesï¼Œ they're rectangles and the width and the heightã€‚
    because these don't have to be the sameã€‚ So they're rectangles that are drawn
    around various thingsã€‚ And then the labelsã€‚ this is where you can get a bunch
    of these because you might have many thousands of labelsã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ æœ‰Xåæ ‡å’ŒYåæ ‡ã€‚è¿™æ˜¯è¿™äº›è¾¹ç•Œæ¡†çš„ä¸­å¿ƒã€‚å—¯ã€‚å®ƒä»¬ä¸æ˜¯æ¡†ï¼Œè€Œæ˜¯çŸ©å½¢ï¼Œå®½åº¦å’Œé«˜åº¦ã€‚å› ä¸ºè¿™äº›ä¸å¿…ç›¸åŒã€‚æ‰€ä»¥å®ƒä»¬æ˜¯å›´ç»•å„ç§äº‹ç‰©ç»˜åˆ¶çš„çŸ©å½¢ã€‚ç„¶åæ˜¯æ ‡ç­¾ã€‚è¿™æ˜¯ä½ å¯ä»¥å¾—åˆ°å¾ˆå¤šæ ‡ç­¾çš„åœ°æ–¹ï¼Œå› ä¸ºä½ å¯èƒ½æœ‰æˆåƒä¸Šä¸‡çš„æ ‡ç­¾ã€‚
- en: And here you might have just a handful or 100ã€‚ each label represents something
    like person dog houseã€‚ And this is essentially a one hot sort of encoding for
    these labelsã€‚ So what you get here isã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_11.png)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œä½ å¯èƒ½åªæœ‰å‡ ä¹ä¸€ç™¾ä¸ªã€‚æ¯ä¸ªæ ‡ç­¾ä»£è¡¨åƒâ€œäººâ€ã€â€œç‹—â€ã€â€œæˆ¿å­â€è¿™æ ·çš„ä¸œè¥¿ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯è¿™äº›æ ‡ç­¾çš„ç‹¬çƒ­ç¼–ç ã€‚æ‰€ä»¥ä½ å¾—åˆ°çš„æ˜¯ã€‚![](img/e158ad4b49aacee0b95f33252bd7ee13_11.png)
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_12.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_12.png)'
- en: For the labelsï¼Œ whichever one has the highest value that is the label that it
    actually chose it wasã€‚ So person would probably have the highest the highest value
    in that labelã€‚ you could probably also look at the second highest and see if it
    may be thought that it was what the runner up for that guy there was other than
    personã€‚ That label aloneï¼Œ though is not the overall confidence that you're looking
    atã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ ‡ç­¾ï¼Œæ— è®ºå“ªä¸ªæ ‡ç­¾çš„å€¼æœ€é«˜ï¼Œè¿™å°±æ˜¯å®ƒå®é™…é€‰æ‹©çš„æ ‡ç­¾ã€‚æ‰€ä»¥â€œäººâ€å¯èƒ½ä¼šåœ¨è¯¥æ ‡ç­¾ä¸­å…·æœ‰æœ€é«˜å€¼ã€‚ä½ ä¹Ÿå¯ä»¥æŸ¥çœ‹ç¬¬äºŒé«˜çš„å€¼ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥è®¤ä¸ºå®ƒæ˜¯è¿™ä¸ªäººçš„äºšå†›ã€‚å•é è¯¥æ ‡ç­¾ï¼Œå¹¶ä¸èƒ½åæ˜ ä½ æ‰€å¯»æ‰¾çš„æ•´ä½“ç½®ä¿¡åº¦ã€‚
- en: you're looking at this confidenceã€‚ and this confidence is a number that specifies
    if it thinks that there truly is something thereã€‚ So all of these other boxes
    that you hadï¼Œ you're not going to display thoseã€‚ you don't even count thoseã€‚ So
    that's how you essentially get this variable number of values coming backã€‚ You're
    always getting the same number of bounding rectangles backã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨çœ‹è¿™ä¸ªç½®ä¿¡åº¦ã€‚è¿™ä¸ªç½®ä¿¡åº¦æ˜¯ä¸€ä¸ªæ•°å­—ï¼ŒæŒ‡ç¤ºå®ƒæ˜¯å¦è®¤ä¸ºé‚£é‡ŒçœŸçš„æœ‰ä¸œè¥¿ã€‚å› æ­¤ï¼Œæ‰€æœ‰è¿™äº›å…¶ä»–æ¡†ä½ éƒ½ä¸ä¼šæ˜¾ç¤ºã€‚ä½ ç”šè‡³ä¸è®¡ç®—é‚£äº›ã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯ä½ æœ¬è´¨ä¸Šå¾—åˆ°çš„å˜é‡æ•°é‡çš„å€¼è¿”å›ã€‚ä½ æ€»æ˜¯å¾—åˆ°ç›¸åŒæ•°é‡çš„è¾¹ç•ŒçŸ©å½¢è¿”å›ã€‚
- en: You're just throwing away most of themã€‚ Now let's look at how many actual neurons
    that we haveã€‚ It's a 3D tensor that comes backã€‚ So it's not just a simple linear
    set of output neuronsã€‚ you can think of it that wayã€‚ It's really S by Sã€‚ So however
    many however big that grid wasã€‚ say 10 by 10ã€‚ It would be 100 times B B is the
    number of potentially bounding rectangles per grid cellã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åŸºæœ¬ä¸Šæ˜¯æŠ›å¼ƒäº†å¤§å¤šæ•°æ ‡ç­¾ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å®é™…çš„ç¥ç»å…ƒæ•°é‡ã€‚è¿”å›çš„æ˜¯ä¸€ä¸ª3Då¼ é‡ã€‚æ‰€ä»¥è¿™å¹¶ä¸ä»…ä»…æ˜¯ä¸€ç»„ç®€å•çš„çº¿æ€§è¾“å‡ºç¥ç»å…ƒã€‚ä½ å¯ä»¥è¿™æ ·æƒ³ï¼Œå®ƒå®é™…ä¸Šæ˜¯Sä¹˜ä»¥Sã€‚å› æ­¤ï¼Œæ— è®ºé‚£ä¸ªç½‘æ ¼æœ‰å¤šå¤§ï¼Œæ¯”å¦‚è¯´10ä¹˜ä»¥10ã€‚å°†ä¼šæ˜¯100ä¹˜ä»¥Bï¼ŒBæ˜¯æ¯ä¸ªç½‘æ ¼å•å…ƒå¯èƒ½çš„è¾¹ç•ŒçŸ©å½¢æ•°é‡ã€‚
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_14.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_14.png)'
- en: How many of those you're going this equation is basically straight fromï¼Œ from
    the paperã€‚ The5 comes from 1ï¼Œ2ï¼Œ3ï¼Œ4 for the Xï¼Œ Yï¼Œ height widthï¼Œ and then the confidenceã€‚
    So that's 5ã€‚And then the number of labels that we haveã€‚ So that one hot and coatingã€‚
    And C is the number of classes that we haveã€‚ So you have to deal with thatã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¦ä½¿ç”¨çš„æ–¹ç¨‹å¼åŸºæœ¬ä¸Šç›´æ¥æ¥è‡ªäºè®ºæ–‡ã€‚5æ¥è‡ªäºXã€Yã€å®½åº¦å’Œé«˜åº¦çš„1ã€2ã€3ã€4ï¼Œç„¶åæ˜¯ç½®ä¿¡åº¦ã€‚æ‰€ä»¥ä¸€å…±æ˜¯5ã€‚å†åŠ ä¸Šæˆ‘ä»¬æ‹¥æœ‰çš„æ ‡ç­¾æ•°é‡ã€‚è¿™æ ·å°±æ˜¯ç‹¬çƒ­ç¼–ç ã€‚è€ŒCæ˜¯æˆ‘ä»¬æ‹¥æœ‰çš„ç±»åˆ«æ•°é‡ã€‚æ‰€ä»¥ä½ å¿…é¡»å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚
- en: It can only classify for actual known known classesã€‚ And that gives you all
    your bounding rectanglesã€‚ You run thatã€‚ And that's really all there isã€‚ is to
    thisã€‚ Nowï¼Œ looking at what that convolution neural network actually looks likeã€‚
    This is your image coming in 4ï¼Œ4ï¼Œ8 by 4ï¼Œ4ï¼Œ8 is the size that the paper was usingã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåªèƒ½ä¸ºå®é™…å·²çŸ¥çš„ç±»åˆ«è¿›è¡Œåˆ†ç±»ã€‚è¿™æ ·ä½ å°±å¯ä»¥å¾—åˆ°æ‰€æœ‰çš„è¾¹ç•ŒçŸ©å½¢ã€‚ä½ è¿è¡Œå®ƒã€‚è¿™å°±æ˜¯å…¨éƒ¨ã€‚ç°åœ¨ï¼Œçœ‹çœ‹å·ç§¯ç¥ç»ç½‘ç»œçš„å®é™…æ ·å­ã€‚è¿™æ˜¯ä½ è¾“å…¥çš„å›¾åƒï¼Œå¤§å°ä¸º 4ï¼Œ4ï¼Œ8ï¼Œè®ºæ–‡ä½¿ç”¨çš„æ­£æ˜¯è¿™ä¸ªå°ºå¯¸ã€‚
- en: It was a scanning convolution layer 7 by 7 goes into another convolution layerã€‚
    another convolution layerã€‚ Also with max pooling layersã€‚ just exactly like we've
    seen beforeã€‚ There's nothing new about thisã€‚ The only difference here is we have
    the 7 by 7 by 30 tensor that is being output from itã€‚ These are sample images
    from the paperã€‚ They even show an example of where it's misclassifying here it
    has problems with the person jumping from that car of that carã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ª 7x7 çš„æ‰«æå·ç§¯å±‚ï¼Œè¿›å…¥å¦ä¸€ä¸ªå·ç§¯å±‚ã€‚è¿˜æœ‰å…¶ä»–å·ç§¯å±‚ï¼ŒåŠæœ€å¤§æ± åŒ–å±‚ï¼Œå’Œæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ä¸€æ ·ã€‚è¿™æ²¡æœ‰ä»€ä¹ˆæ–°é²œäº‹ã€‚è¿™é‡Œå”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬æœ‰ä¸€ä¸ª 7x7x30
    çš„å¼ é‡ä½œä¸ºè¾“å‡ºã€‚è¿™äº›æ˜¯è®ºæ–‡ä¸­çš„ç¤ºä¾‹å›¾åƒã€‚ä»–ä»¬ç”šè‡³å±•ç¤ºäº†ä¸€ä¸ªé”™è¯¯åˆ†ç±»çš„ç¤ºä¾‹ï¼Œè¿™é‡Œä»–å¯¹ä»æ±½è½¦ä¸Šè·³ä¸‹æ¥çš„äººæœ‰é—®é¢˜ã€‚
- en: Heyï¼Œ he's a planeã€‚ Nopeï¼Œ he's notï¼Œ's he's acting a lot like an airplaneï¼Œ but
    he's not an airplaneã€‚ They also talk about some of the limitations of this in
    the paper for yellowã€‚ Like if there was a flock of birdsã€‚Up here and they were
    fairly far off in the distanceã€‚ it would not recognize them because it has trouble
    recognizing very smallã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å˜¿ï¼Œä»–æ˜¯ä¸€æ¶é£æœºã€‚ä¸ï¼Œä»–ä¸æ˜¯ï¼Œä»–çš„è¡Œä¸ºå¾ˆåƒé£æœºï¼Œä½†ä»–å¹¶ä¸æ˜¯é£æœºã€‚è®ºæ–‡ä¸­ä¹Ÿæåˆ°äº†è¿™ä¸€ç‚¹çš„æŸäº›å±€é™æ€§ï¼Œæ¯”å¦‚å¦‚æœæœ‰ä¸€ç¾¤é¸Ÿåœ¨è¿œå¤„ï¼Œå®ƒå°±æ— æ³•è¯†åˆ«ï¼Œå› ä¸ºå®ƒåœ¨è¯†åˆ«éå¸¸å°çš„ç‰©ä½“æ—¶æœ‰å›°éš¾ã€‚
- en: Highly dense groups of thingsã€‚ It was doing pretty well with the books that
    we saw earlier wouldn't do so well if they were muchã€‚ much smallerã€‚ Now using
    this in Pythonã€‚ I give you some links hereã€‚ This is to darknetã€‚ Now I use this
    as wellã€‚ This is the C version of itã€‚ I've compiled that and basically can run
    it from the command lineã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜å¯†åº¦çš„äº‹ç‰©ç¾¤ä½“ã€‚å¦‚æœæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ä¹¦ç±è¦å°å¾—å¤šï¼Œå®ƒä»¬çš„è¡¨ç°å°±ä¸ä¼šé‚£ä¹ˆå¥½ã€‚ç°åœ¨åœ¨ Python ä¸­ä½¿ç”¨è¿™ä¸ªã€‚æˆ‘åœ¨è¿™é‡Œç»™ä½ ä¸€äº›é“¾æ¥ã€‚è¿™æ˜¯ç»™ darknet
    çš„ã€‚ç°åœ¨æˆ‘ä¹Ÿä½¿ç”¨è¿™ä¸ªã€‚è¿™æ˜¯å®ƒçš„ C ç‰ˆæœ¬ã€‚æˆ‘å·²ç»ç¼–è¯‘äº†å®ƒï¼Œå¹¶ä¸”åŸºæœ¬ä¸Šå¯ä»¥ä»å‘½ä»¤è¡Œè¿è¡Œã€‚
- en: I've not used it in a C program yetã€‚ but many people haveï¼Œ it's certainly available
    for youã€‚ We're going focus more on darkflowã€‚ Darkflow is going to let you use
    this in Pythonã€‚ Now we're not going to train a yellow networkã€‚ You canã€‚ We're
    going to go ahead and install darkflowã€‚ Now you've got your choiceã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æ²¡æœ‰åœ¨ C ç¨‹åºä¸­ä½¿ç”¨å®ƒï¼Œä½†å¾ˆå¤šäººå·²ç»ä½¿ç”¨è¿‡ï¼Œå®ƒå½“ç„¶æ˜¯å¯ç”¨çš„ã€‚æˆ‘ä»¬å°†æ›´å¤šå…³æ³¨ darkflowã€‚Darkflow è®©ä½ å¯ä»¥åœ¨ Python ä¸­ä½¿ç”¨è¿™ä¸ªã€‚æˆ‘ä»¬ä¸æ‰“ç®—è®­ç»ƒä¸€ä¸ªé»„è‰²ç½‘ç»œã€‚ä½ å¯ä»¥ã€‚æˆ‘ä»¬å°†ç»§ç»­å®‰è£…
    darkflowã€‚ç°åœ¨ä½ æœ‰é€‰æ‹©äº†ã€‚
- en: You can do this on Google coababã€‚ That's what I'm going to demonstrateã€‚ so that
    we can run it with a GPã€‚ It'll be a little fasterã€‚ mostly for recognizing individual
    imagesã€‚ You you're fine without a GPã€‚ If you want to actually record live videoã€‚
    then you're really going to want to have some sort of a GP on your actual systemã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨ Google Coabab ä¸Šæ‰§è¡Œæ­¤æ“ä½œã€‚è¿™å°±æ˜¯æˆ‘è¦æ¼”ç¤ºçš„ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ç”¨ GP è¿è¡Œã€‚ä¼šå¿«ä¸€ç‚¹ï¼Œä¸»è¦æ˜¯ä¸ºäº†è¯†åˆ«å•ç‹¬çš„å›¾åƒã€‚å¦‚æœä½ æƒ³å®é™…å½•åˆ¶å®æ—¶è§†é¢‘ï¼Œé‚£ä½ çœŸçš„éœ€è¦åœ¨ç³»ç»Ÿä¸Šæœ‰æŸç§
    GPã€‚
- en: but using individual imagesã€‚ You're fine with you're fine with a CPUã€‚ It'll
    take like 5 to 10 seconds for a single imageã€‚ We're going toã€‚Run dark low Yolo
    from Google Colã€‚ I'm going to take you through the instructions real quickã€‚ It's
    that hardã€‚ We're going to need some filesã€‚ So we're going need the weights because
    we're not going to train a yoloã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å•ç‹¬çš„å›¾åƒå°±å¯ä»¥ã€‚ä½¿ç”¨ CPU æ²¡é—®é¢˜ã€‚å¤„ç†å•ä¸ªå›¾åƒå¤§çº¦éœ€è¦ 5 åˆ° 10 ç§’ã€‚æˆ‘ä»¬å°†ä» Google Col è¿è¡Œ dark low Yoloã€‚æˆ‘å°†å¿«é€Ÿå¸¦ä½ å®Œæˆè¯´æ˜ã€‚è¿™å¹¶ä¸å›°éš¾ã€‚æˆ‘ä»¬éœ€è¦ä¸€äº›æ–‡ä»¶ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æƒé‡ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æ‰“ç®—è®­ç»ƒä¸€ä¸ª
    Yoloã€‚
- en: We're going to use the original weights that the author of the paper got for
    usã€‚ This is kind of leading up to transfer learningï¼Œ which we're going learn about
    later where we can make weights that we're actually generated by people who have
    very high training environments with manyã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨è®ºæ–‡ä½œè€…ä¸ºæˆ‘ä»¬å‡†å¤‡çš„åŸå§‹æƒé‡ã€‚è¿™æ˜¯åœ¨å¼•å…¥è¿ç§»å­¦ä¹ çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å°†ç¨åå­¦ä¹ è¿™ä¸€ç‚¹ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‚£äº›ç”±åœ¨é«˜è®­ç»ƒç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒçš„äººç”Ÿæˆçš„æƒé‡ã€‚
- en: many GPs and spent potentially manyï¼Œ many weeks training themã€‚ So we'll be able
    to benefit from those weights and load them inã€‚ This is starting to get thereã€‚
    We're going to do this both in this module in the next moduleã€‚ we're going to
    benefit from already trained neural networksã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è®¸å¤š GPï¼Œå¹¶ä¸”å¯èƒ½èŠ±è´¹äº†è®¸å¤šå‘¨æ¥è®­ç»ƒå®ƒä»¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿåˆ©ç”¨è¿™äº›æƒé‡å¹¶åŠ è½½å®ƒä»¬ã€‚è¿™å¼€å§‹å˜å¾—æœ‰è¶£ã€‚æˆ‘ä»¬å°†åœ¨è¿™ä¸ªæ¨¡å—å’Œä¸‹ä¸€ä¸ªæ¨¡å—ä¸­éƒ½è¿›è¡Œæ­¤æ“ä½œã€‚æˆ‘ä»¬å°†ä»å·²ç»è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œä¸­å—ç›Šã€‚
- en: And we're not sending them off to the cloudã€‚ We've literally got these weights
    in our computer and can look at them if we so desireã€‚ So you're going to need
    three files to run thisï¼Œ and you'll need to put them in your Google driveã€‚ You're
    going to need weightsï¼Œ Yolo do weightsã€‚ We're going to need the configuration
    fileã€‚ and we're going to need the labels fileã€‚ Nowï¼Œ I have some scripts that you
    can run here that do this really quite easily for youã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¹¶æ²¡æœ‰æŠŠå®ƒä»¬å‘é€åˆ°äº‘ç«¯ã€‚æˆ‘ä»¬å®é™…ä¸Šåœ¨æˆ‘ä»¬çš„è®¡ç®—æœºä¸Šæœ‰è¿™äº›æƒé‡ï¼Œå¹¶ä¸”å¯ä»¥åœ¨éœ€è¦æ—¶æŸ¥çœ‹å®ƒä»¬ã€‚æ‰€ä»¥ä½ éœ€è¦ä¸‰ä¸ªæ–‡ä»¶æ¥è¿è¡Œè¿™ä¸ªï¼Œä½ éœ€è¦æŠŠå®ƒä»¬æ”¾åœ¨ä½ çš„ Google
    Drive ä¸­ã€‚ä½ éœ€è¦æƒé‡ï¼ŒYolo çš„æƒé‡ã€‚æˆ‘ä»¬è¿˜éœ€è¦é…ç½®æ–‡ä»¶ã€‚æˆ‘ä»¬éœ€è¦æ ‡ç­¾æ–‡ä»¶ã€‚ç°åœ¨ï¼Œæˆ‘æœ‰ä¸€äº›è„šæœ¬å¯ä»¥åœ¨è¿™é‡Œè¿è¡Œï¼Œå¸®åŠ©ä½ è½»æ¾å®Œæˆè¿™ä¸ªæ“ä½œã€‚
- en: So the first thing we're going to need to do isã€‚ğŸ˜Šï¼Œone the dark flow and Githubã€‚
    So let's do thatã€‚ So we're resetting all runtimeã€‚ So I've run this before because
    I tested itã€‚ ands it still has to re clone itã€‚ Google deletes everything that
    you put on here except for what you put in Google Driveã€‚ So always remember thatã€‚
    we've made a clone of itã€‚ Now we're going do a special Pip installã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆéœ€è¦åšçš„äº‹æƒ…æ˜¯ã€‚ğŸ˜Šï¼Œå®‰è£… darkflow å’Œ GitHubã€‚æ‰€ä»¥æˆ‘ä»¬æ¥åšè¿™ä¸ªã€‚æˆ‘ä»¬æ­£åœ¨é‡ç½®æ‰€æœ‰è¿è¡Œæ—¶ã€‚æˆ‘ä¹‹å‰è¿è¡Œè¿‡è¿™ä¸ªï¼Œå› ä¸ºæˆ‘æµ‹è¯•è¿‡å®ƒã€‚å®ƒä»ç„¶éœ€è¦é‡æ–°å…‹éš†ã€‚Google
    åˆ é™¤äº†ä½ æ”¾åœ¨è¿™é‡Œçš„æ‰€æœ‰å†…å®¹ï¼Œé™¤äº†ä½ æ”¾åœ¨ Google Drive çš„å†…å®¹ã€‚æ‰€ä»¥è¯·å§‹ç»ˆè®°ä½è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å·²ç»å…‹éš†äº†å®ƒã€‚ç°åœ¨æˆ‘ä»¬è¦è¿›è¡Œç‰¹æ®Šçš„ Pip å®‰è£…ã€‚
- en: And this will install darkflow into Pythonã€‚ Now I'm in Google Coabã€‚ I've got
    to do this every time that I restart my environmentã€‚ And notice I'm giving it
    a directoryã€‚ That's that same darkflow directory that we just checked outã€‚ So
    that's handyã€‚ So I run that and we're now doing a Pip install of darkflowã€‚ And
    now we have darkflow installedã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æŠŠ darkflow å®‰è£…åˆ° Python ä¸­ã€‚ç°åœ¨æˆ‘åœ¨ Google Colabã€‚æ¯æ¬¡æˆ‘é‡æ–°å¯åŠ¨ç¯å¢ƒæ—¶ï¼Œéƒ½å¿…é¡»æ‰§è¡Œè¿™ä¸ªæ“ä½œã€‚æ³¨æ„æˆ‘ç»™å®ƒæŒ‡å®šäº†ä¸€ä¸ªç›®å½•ã€‚é‚£å°±æ˜¯æˆ‘ä»¬åˆšåˆšæ£€æŸ¥è¿‡çš„
    darkflow ç›®å½•ã€‚è¿™å¾ˆæ–¹ä¾¿ã€‚æˆ‘è¿è¡Œå®ƒï¼Œæˆ‘ä»¬ç°åœ¨æ­£åœ¨è¿›è¡Œ darkflow çš„ Pip å®‰è£…ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»å®‰è£…äº† darkflowã€‚
- en: Now if you're doing this on your local computerï¼Œ you'll need to basically do
    these exact same stepsã€‚ but you need some prerequisites to be able to run darkflowã€‚
    You needthon and open Cã€‚ So make sure you install those and read up on how to
    do thoseã€‚ Def the easier approach for this is to use Google coab here I'm going
    to mount my driveã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¦‚æœä½ åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šæ‰§è¡Œæ­¤æ“ä½œï¼Œä½ éœ€è¦åŸºæœ¬ä¸Šè¿›è¡Œå®Œå…¨ç›¸åŒçš„æ­¥éª¤ã€‚ä½†æ˜¯ä½ éœ€è¦ä¸€äº›å…ˆå†³æ¡ä»¶æ‰èƒ½è¿è¡Œ darkflowã€‚ä½ éœ€è¦å®‰è£… Python å’Œ OpenCVã€‚å› æ­¤ï¼Œè¯·ç¡®ä¿ä½ å®‰è£…è¿™äº›å¹¶äº†è§£å¦‚ä½•æ“ä½œã€‚å¯¹ä½ æ¥è¯´ï¼Œä½¿ç”¨
    Google Colab æ˜¯æ›´ç®€å•çš„æ–¹æ³•ï¼Œæˆ‘å°†æŒ‚è½½æˆ‘çš„é©±åŠ¨å™¨ã€‚
- en: This is how I actually make my G drive available in hereã€‚ And I'm running that
    has to do some securityã€‚ I have to pick who I want to be Now amã€‚ğŸ˜Šã€‚Blocking this
    all for security reasonsã€‚ and then you copy and paste this little token that it
    gives meã€‚ come back to Google coab put it into hereã€‚ and now I can unblock Now
    these commandsã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘å¦‚ä½•åœ¨è¿™é‡Œä½¿æˆ‘çš„ G Drive å¯ç”¨ã€‚æˆ‘æ­£åœ¨è¿è¡Œè¿™ä¸ªä»¥è¿›è¡Œä¸€äº›å®‰å…¨è®¾ç½®ã€‚æˆ‘å¿…é¡»é€‰æ‹©æˆ‘å¸Œæœ›æˆä¸ºè°ã€‚ç°åœ¨æ˜¯æˆ‘ã€‚ğŸ˜Šã€‚å‡ºäºå®‰å…¨åŸå› ï¼Œæˆ‘æ­£åœ¨é˜»æ­¢æ‰€æœ‰è¿™äº›ã€‚ç„¶åä½ å¤åˆ¶å¹¶ç²˜è´´å®ƒç»™æˆ‘çš„è¿™ä¸ªå°ä»¤ç‰Œã€‚å›æ¥
    Google Colabï¼ŒæŠŠå®ƒæ”¾åˆ°è¿™é‡Œã€‚ç°åœ¨æˆ‘å¯ä»¥è§£é”è¿™äº›å‘½ä»¤ã€‚
- en: these are Unix commandsã€‚ this saves you the trouble of having to drag and drop
    all of those individual filesã€‚ I'm going go ahead and run this and all this is
    doing is creating a directory called projects in my Google Drive then inside of
    there I have Yoloã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯ Unix å‘½ä»¤ã€‚è¿™å¯ä»¥è®©ä½ å…å»æ‹–æ”¾æ‰€æœ‰å•ä¸ªæ–‡ä»¶çš„éº»çƒ¦ã€‚æˆ‘å°†ç»§ç»­è¿è¡Œè¿™ä¸ªï¼Œæ‰€æœ‰çš„æ“ä½œå°±æ˜¯åœ¨æˆ‘çš„ Google Drive ä¸­åˆ›å»ºä¸€ä¸ªåä¸º projects
    çš„ç›®å½•ï¼Œç„¶ååœ¨é‡Œé¢æœ‰ Yoloã€‚
- en: So I typically create a projects directory my Google Drive and all these things
    that I need coab I just put them in these various locationã€‚ So in Yoloï¼Œ we have
    a bin and we have a configuration directory hopefully that all worked that should
    have all so that is all those files have now been downloaded you're going run
    locally here's a link with instructions from the author site on how to do this
    Now we're going to run this partã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘é€šå¸¸åœ¨æˆ‘çš„ Google Drive ä¸­åˆ›å»ºä¸€ä¸ª projects ç›®å½•ï¼Œæ‰€æœ‰è¿™äº›æˆ‘åœ¨ Colab ä¸­éœ€è¦çš„ä¸œè¥¿ï¼Œæˆ‘åªéœ€æŠŠå®ƒä»¬æ”¾åœ¨è¿™äº›ä¸åŒçš„ä½ç½®ã€‚å› æ­¤ï¼Œåœ¨
    Yolo ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ª bin å’Œä¸€ä¸ªé…ç½®ç›®å½•ï¼Œå¸Œæœ›è¿™ä¸€åˆ‡éƒ½èƒ½æ­£å¸¸å·¥ä½œï¼Œæ‰€æœ‰è¿™äº›æ–‡ä»¶ç°åœ¨éƒ½å·²ä¸‹è½½å®Œæ¯•ã€‚ä½ å°†åœ¨æœ¬åœ°è¿è¡Œï¼Œä»¥ä¸‹æ˜¯æ¥è‡ªä½œè€…ç½‘ç«™çš„è¯´æ˜é“¾æ¥ï¼Œå…³äºå¦‚ä½•åšè¿™ä»¶äº‹ã€‚ç°åœ¨æˆ‘ä»¬è¦è¿è¡Œè¿™éƒ¨åˆ†ã€‚
- en: first of all pick which of these you want to have So we have to change into
    the directory that we're actually running this fromã€‚ So if you downloaded this
    your local drive you need whatever your path is's where I tend to store thingsã€‚
    But here I'm going to change myã€‚Diy to my Google drive to yellowã€‚ and then the
    optionsã€‚ If you're running a GPUï¼Œ then you want this part to be GPU 1ã€‚ Otherwiseï¼Œ
    you don'tã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆé€‰æ‹©ä½ æƒ³è¦çš„å†…å®¹ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ‡æ¢åˆ°æˆ‘ä»¬å®é™…è¿è¡Œæ­¤ç¨‹åºçš„ç›®å½•ã€‚å¦‚æœä½ åœ¨æœ¬åœ°é©±åŠ¨å™¨ä¸Šä¸‹è½½äº†è¿™ä¸ªï¼Œé‚£ä¹ˆä½ éœ€è¦æ ¹æ®ä½ çš„è·¯å¾„æ¥å­˜å‚¨ä¸œè¥¿ã€‚ä½†åœ¨è¿™é‡Œï¼Œæˆ‘å°†æˆ‘çš„Diyæ”¹ä¸ºæˆ‘çš„Google
    Driveåˆ°é»„è‰²ã€‚ç„¶åé€‰æ‹©é€‰é¡¹ã€‚å¦‚æœä½ ä½¿ç”¨GPUï¼Œé‚£ä¹ˆä½ å¸Œæœ›è¿™ä¸€éƒ¨åˆ†æ˜¯GPU 1ã€‚å¦åˆ™ï¼Œä½ å°±ä¸éœ€è¦ã€‚
- en: So we're gonna run it with GPUã€‚ We're going to pull an image across the Internetã€‚
    We're going to use cook JPgï¼Œ which is me cooking in the kitchenã€‚ You saw that
    earlier with my dog And let's go ahead and run thisã€‚ Now it's going to load the
    weights in from that pretrained neural networkã€‚ See it's building itã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨GPUæ¥è¿è¡Œå®ƒã€‚æˆ‘ä»¬å°†ä»äº’è”ç½‘ä¸Šæ‹‰å–ä¸€å¼ å›¾åƒã€‚æˆ‘ä»¬å°†ä½¿ç”¨cook JPgï¼Œé‚£æ˜¯æˆ‘åœ¨å¨æˆ¿é‡Œåšé¥­çš„æ ·å­ã€‚ä½ æ—©äº›æ—¶å€™çœ‹åˆ°è¿‡æˆ‘å’Œæˆ‘çš„ç‹—ï¼Œè®©æˆ‘ä»¬ç»§ç»­è¿è¡Œè¿™ä¸ªã€‚ç°åœ¨å®ƒå°†åŠ è½½æ¥è‡ªé¢„è®­ç»ƒç¥ç»ç½‘ç»œçš„æƒé‡ã€‚ä½ çœ‹ï¼Œå®ƒæ­£åœ¨æ„å»ºå®ƒã€‚
- en: There's all those convolution layers that we sawã€‚ and this is a decently complicated
    convolution neural networkã€‚ but it's just one convolution neural network that
    learns to recognize all those different image typesã€‚ That's what's reallyï¼Œ really
    cool about thisã€‚ We run in GPU mode and it finishes veryï¼Œ very quicklyã€‚ Nowï¼Œ the
    GPU that Google gives you is greatï¼Œ and it saves us hours on thisã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°äº†æ‰€æœ‰çš„å·ç§¯å±‚ï¼Œè¿™æ˜¯ä¸€ç§ç›¸å½“å¤æ‚çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå­¦ä¹ è¯†åˆ«æ‰€æœ‰ä¸åŒçš„å›¾åƒç±»å‹ã€‚è¿™çœŸçš„æ˜¯éå¸¸é…·ã€‚æˆ‘ä»¬åœ¨GPUæ¨¡å¼ä¸‹è¿è¡Œï¼Œå®ƒå®Œæˆå¾—éå¸¸éå¸¸å¿«ã€‚ç°åœ¨ï¼Œè°·æ­Œç»™ä½ çš„GPUéå¸¸æ£’ï¼ŒèŠ‚çœäº†æˆ‘ä»¬æ•°å°æ—¶çš„æ—¶é—´ã€‚
- en: but it's nothing compared to the next level upï¼Œ which would be like a Titan
    Vï¼Œ whichã€‚ğŸ˜Šã€‚I haven't run it on that highï¼Œ high end of1ã€‚ I couldã€‚ I could do that
    with the enterprise equivalent on of V 100 on Amazonã€‚ But that would do this even
    quickerã€‚ And that's what you need for real time real time video because you need
    to be able to do 30 or so a secondã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä¸ä¸‹ä¸€ä¸ªçº§åˆ«ç›¸æ¯”ï¼Œç®€ç›´ä¸å€¼ä¸€æï¼Œæ¯”å¦‚Titan Vï¼ŒğŸ˜Šã€‚æˆ‘è¿˜æ²¡æœ‰åœ¨é‚£ä¸ªé«˜ç«¯ä¸Šè¿è¡Œè¿‡ã€‚æˆ‘å¯ä»¥åœ¨äºšé©¬é€Šçš„ä¼ä¸šçº§V 100ä¸Šåšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†é‚£ä¼šæ›´å¿«ã€‚è€Œè¿™æ­£æ˜¯ä½ è¿›è¡Œå®æ—¶è§†é¢‘æ‰€éœ€çš„ï¼Œå› ä¸ºä½ éœ€è¦èƒ½å¤Ÿåšåˆ°æ¯ç§’30å¸§å·¦å³ã€‚
- en: if you truly want to be in the range of real timeã€‚ Nowï¼Œ let's run it and we'll
    see the resultsã€‚ Nowã€‚ instead of getting that image with the bounding boxes and
    text all around itã€‚ Now I get those output values that we talked aboutã€‚ So we
    see personï¼Œ dogï¼Œ catï¼Œ bottleï¼Œ microwaveã€‚ ovenï¼Œ sink all those various thingsï¼Œ
    the confidenceã€‚ And then the coordinates and sizesã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çœŸçš„æƒ³è¦æ¥è¿‘å®æ—¶çš„èŒƒå›´ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿è¡Œå®ƒï¼Œçœ‹çœ‹ç»“æœã€‚ç°åœ¨ï¼Œä¸æ˜¯å¾—åˆ°å¸¦æœ‰è¾¹ç•Œæ¡†å’Œæ–‡æœ¬çš„å›¾åƒï¼Œè€Œæ˜¯å¾—åˆ°æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„è¾“å‡ºå€¼ã€‚æˆ‘ä»¬çœ‹åˆ°äººï¼Œç‹—ï¼ŒçŒ«ï¼Œç“¶å­ï¼Œå¾®æ³¢ç‚‰ï¼Œæ°´æ§½ï¼Œæ‰€æœ‰è¿™äº›ä¸åŒçš„ä¸œè¥¿ï¼Œä»¥åŠç½®ä¿¡åº¦ã€‚ç„¶åæ˜¯åæ ‡å’Œå¤§å°ã€‚
- en: So we see basically the top left in the bottom rightã€‚ It's translating the centers
    and the width and height into into bounding coordinatesã€‚ So this is greatã€‚ You
    can do all kinds of things with this in your own programs to detect various things
    in imagesã€‚ğŸ˜Šã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬åŸºæœ¬ä¸Šçœ‹åˆ°å·¦ä¸Šè§’å’Œå³ä¸‹è§’ã€‚å®ƒå°†ä¸­å¿ƒã€å®½åº¦å’Œé«˜åº¦è½¬æ¢ä¸ºè¾¹ç•Œåæ ‡ã€‚è¿™å¾ˆå¥½ï¼Œä½ å¯ä»¥åœ¨è‡ªå·±çš„ç¨‹åºä¸­ç”¨è¿™ä¸ªæ¥æ£€æµ‹å›¾åƒä¸­çš„å„ç§äº‹ç‰©ã€‚ğŸ˜Šã€‚
- en: '![](img/e158ad4b49aacee0b95f33252bd7ee13_16.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e158ad4b49aacee0b95f33252bd7ee13_16.png)'
- en: Thank you for watching this video in the next video we're going to begin to
    look at GAN neural networksã€‚This content changes oftenï¼Œ so subscribe to the channel
    to stay up to date on this course and other topics in artificial intelligenceã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­æˆ‘ä»¬å°†å¼€å§‹ç ”ç©¶GANç¥ç»ç½‘ç»œã€‚æ­¤å†…å®¹ç»å¸¸å˜åŒ–ï¼Œå› æ­¤è¯·è®¢é˜…é¢‘é“ä»¥ä¿æŒæ›´æ–°ï¼Œäº†è§£æœ¬è¯¾ç¨‹åŠäººå·¥æ™ºèƒ½çš„å…¶ä»–ä¸»é¢˜ã€‚
