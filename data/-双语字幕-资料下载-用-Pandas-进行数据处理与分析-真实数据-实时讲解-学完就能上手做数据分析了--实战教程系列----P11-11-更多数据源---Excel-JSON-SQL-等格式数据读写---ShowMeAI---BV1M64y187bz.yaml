- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Pandas è¿›è¡Œæ•°æ®å¤„ç†ä¸åˆ†æï¼çœŸå®æ•°æ®&å®æ—¶è®²è§£ï¼Œå­¦å®Œå°±èƒ½ä¸Šæ‰‹åšæ•°æ®åˆ†æäº†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P11ï¼š11ï¼‰æ›´å¤šæ•°æ®æº
    - Excelã€JSONã€SQL ç­‰æ ¼å¼æ•°æ®è¯»å†™ - ShowMeAI - BV1M64y187bz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ç”¨ Pandas è¿›è¡Œæ•°æ®å¤„ç†ä¸åˆ†æï¼çœŸå®æ•°æ®&å®æ—¶è®²è§£ï¼Œå­¦å®Œå°±èƒ½ä¸Šæ‰‹åšæ•°æ®åˆ†æäº†ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P11ï¼š11ï¼‰æ›´å¤šæ•°æ®æº
    - Excelã€JSONã€SQL ç­‰æ ¼å¼æ•°æ®è¯»å†™ - ShowMeAI - BV1M64y187bz
- en: Hey thereã€‚ how's it goingï¼Œ everybodyã€‚ In this videoã€‚ we're gonna be learning
    how to read and write data to different sourcesã€‚ So we'll learn how to read and
    write data using CV filesï¼Œ Excel filesï¼Œ Json and also SQL databasesã€‚ Nowï¼Œ in this
    series so farã€‚ we've been reading data from CV filesã€‚ But in data scienceã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å˜¿ï¼Œå¤§å®¶å¥½ï¼Œæœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿåœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•è¯»å–å’Œå†™å…¥ä¸åŒæ¥æºçš„æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ CV æ–‡ä»¶ã€Excel æ–‡ä»¶ã€Json ä»¥åŠ SQL
    æ•°æ®åº“è¿›è¡Œæ•°æ®çš„è¯»å–å’Œå†™å…¥ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨è¿™ä¸ªç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ä» CV æ–‡ä»¶ä¸­è¯»å–æ•°æ®ã€‚ä½†åœ¨æ•°æ®ç§‘å­¦ä¸­ã€‚
- en: there are so many different ways for data to be storedã€‚ So by the end of this
    videoã€‚ you should be able to get your data to and from pandasï¼Œ no matter what
    data format you're usingã€‚ Nowï¼Œ if you're watching this video because you're looking
    for how to read and write a specific file formatã€‚ Then I'll be sure to add timestamps
    in the description section below to where we read and write from each different
    formatã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å­˜å‚¨çš„æ–¹å¼æœ‰å¾ˆå¤šç§ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªè§†é¢‘ç»“æŸæ—¶ï¼Œä½ åº”è¯¥èƒ½å¤Ÿå°†æ•°æ®è¿›å‡º pandasï¼Œæ— è®ºä½ ä½¿ç”¨ä»€ä¹ˆæ•°æ®æ ¼å¼ã€‚ç°åœ¨ï¼Œå¦‚æœä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘æ˜¯å› ä¸ºä½ åœ¨å¯»æ‰¾å¦‚ä½•è¯»å–å’Œå†™å…¥ç‰¹å®šæ–‡ä»¶æ ¼å¼ï¼Œé‚£ä¹ˆæˆ‘ä¼šåœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†æ·»åŠ æ—¶é—´æˆ³ï¼ŒæŒ‡å‘æˆ‘ä»¬ä»æ¯ç§ä¸åŒæ ¼å¼è¯»å–å’Œå†™å…¥çš„åœ°æ–¹ã€‚
- en: Nowï¼Œ I would like to mention that we do have a sponsor for this series videosã€‚
    And that is brilliantã€‚ So I really want to thank brilliant for sponsoring this
    seriesã€‚ And it would be great if you all can check them out using the link in
    the description section below and support the sponsorsã€‚ And I'll talk more about
    their services in just a bitã€‚ So with that saidã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘æƒ³æåˆ°çš„æ˜¯æˆ‘ä»¬ç¡®å®æœ‰ä¸€ä¸ªèµåŠ©å•†æ¥æ”¯æŒè¿™ä¸€ç³»åˆ—è§†é¢‘ã€‚é‚£å°±æ˜¯ **brilliant**ã€‚æ‰€ä»¥æˆ‘éå¸¸æ„Ÿè°¢ **brilliant** èµåŠ©è¿™ä¸ªç³»åˆ—ã€‚å¦‚æœå¤§å®¶èƒ½é€šè¿‡ä¸‹é¢æè¿°éƒ¨åˆ†çš„é“¾æ¥æŸ¥çœ‹ä»–ä»¬ï¼Œå¹¶æ”¯æŒèµåŠ©å•†ï¼Œé‚£å°±å¤ªå¥½äº†ã€‚æˆ‘ä¼šåœ¨ç¨åæ›´å¤šåœ°è°ˆè®ºä»–ä»¬çš„æœåŠ¡ã€‚å› æ­¤ï¼Œè¯è¯´å›æ¥ã€‚
- en: let's go ahead and get startedã€‚ Okayï¼Œ so firstï¼Œ let's look at CV files since
    we've already beenã€‚ğŸ˜Šã€‚Using these throughout the series we should already be familiar
    with reading data in from CSv since that's what we've been doing so farã€‚ But in
    case this is the first video of the series that you're watchingã€‚ let's go over
    this one more time and then we'll also learn how to write to a cv file as wellã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ã€‚å¥½çš„ï¼Œé¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ CV æ–‡ä»¶ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨è¿™ä¸€ç³»åˆ—ä¸­ä½¿ç”¨è¿‡è¿™äº›ğŸ˜Šã€‚æˆ‘ä»¬åº”è¯¥å·²ç»ç†Ÿæ‚‰ä» CSV ä¸­è¯»å–æ•°æ®ï¼Œå› ä¸ºåˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬ä¸€ç›´åœ¨åšè¿™ä¸ªã€‚ä½†å¦‚æœè¿™æ˜¯ä½ è§‚çœ‹çš„ç³»åˆ—çš„ç¬¬ä¸€éƒ¨è§†é¢‘ï¼Œè®©æˆ‘ä»¬å†å¤ä¹ ä¸€éï¼Œç„¶åæˆ‘ä»¬ä¹Ÿå°†å­¦ä¹ å¦‚ä½•å†™å…¥
    CV æ–‡ä»¶ã€‚
- en: So up here towards the top of my notebook here we can see that I'm reading in
    this CSv file and this Cv file is within a data folder that is in the same location
    as this Jupyter notebook on the file system Now if you have a cv file loaded elsewhere
    on the system then you'll need to pass in the full path to that file instead of
    just this relative location that we have hereã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨æˆ‘ç¬”è®°æœ¬çš„é¡¶éƒ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘æ­£åœ¨è¯»å–è¿™ä¸ª CSV æ–‡ä»¶ï¼Œè¿™ä¸ª Cv æ–‡ä»¶ä½äºä¸æ–‡ä»¶ç³»ç»Ÿä¸­çš„ Jupyter ç¬”è®°æœ¬ç›¸åŒä½ç½®çš„ä¸€ä¸ªæ•°æ®æ–‡ä»¶å¤¹ä¸­ã€‚å¦‚æœä½ åœ¨ç³»ç»Ÿçš„å…¶ä»–åœ°æ–¹åŠ è½½äº†ä¸€ä¸ª
    cv æ–‡ä»¶ï¼Œé‚£ä¹ˆä½ éœ€è¦ä¼ é€’è¯¥æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼Œè€Œä¸ä»…ä»…æ˜¯æˆ‘ä»¬è¿™é‡Œçš„ç›¸å¯¹ä½ç½®ã€‚
- en: and we can see that we have different arguments that we can pass in when reading
    our Cv filesã€‚ So in this example I'm automatically setting the index to this respondent
    column here which is the respondent ID for each person who answered this survey
    And when I read in the Cv we can see that it sets this data frame equalã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨è¯»å–æˆ‘ä»¬çš„ Cv æ–‡ä»¶æ—¶å¯ä»¥ä¼ é€’ä¸åŒçš„å‚æ•°ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘å°†ç´¢å¼•è‡ªåŠ¨è®¾ç½®ä¸ºæ­¤å—è®¿è€…åˆ—ï¼Œå³æ¯ä¸ªå‚ä¸æ­¤è°ƒæŸ¥çš„äººçš„å—è®¿è€… IDã€‚å½“æˆ‘è¯»å–
    Cv æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒå°†è¿™ä¸ªæ•°æ®æ¡†æ¶è®¾ç½®ä¸ºç›¸ç­‰ã€‚
- en: to the data and we can print this data out down here at the bottomã€‚ So that
    is the read CSV method and it allows us to pull data in to pandasã€‚ Now let's learn
    how to write this data back to a CSv So maybe you're gonna make some changes and
    some different analysis here to your data frame and then we want to export this
    back to our file system for later use or so that we can share it with someone
    else or something like thatã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åº•éƒ¨æ‰“å°å‡ºè¿™äº›æ•°æ®ã€‚æ‰€ä»¥è¿™æ˜¯è¯»å– CSV çš„æ–¹æ³•ï¼Œå®ƒå…è®¸æˆ‘ä»¬å°†æ•°æ®å¯¼å…¥åˆ° pandas ä¸­ã€‚ç°åœ¨è®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•å°†è¿™äº›æ•°æ®å†™å›åˆ° CSV
    ä¸­ã€‚ä¹Ÿè®¸ä½ ä¼šå¯¹æ•°æ®æ¡†è¿›è¡Œä¸€äº›æ›´æ”¹å’Œä¸åŒçš„åˆ†æï¼Œç„¶åæˆ‘ä»¬æƒ³å°†å…¶å¯¼å‡ºå›æ–‡ä»¶ç³»ç»Ÿä»¥ä¾¿åç»­ä½¿ç”¨ï¼Œæˆ–è€…ä¸å…¶ä»–äººåˆ†äº«ä¹‹ç±»çš„ã€‚
- en: So for exampleï¼Œ let's filter down for a specific location in this survey you
    know maybe you're doing some analysis for your specific country and you just want
    to see the survey results from that location we've seen this in previous videosã€‚
    but if we want to filter then we can simply say I'll create a filter here and
    just say that I want the country here and I'll grab if the country is equal to
    India so let's say you're doing some analysis and you only want the survey results
    from India So now I'm going create a new data frame hereã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¿‡æ»¤è¿™ä¸ªè°ƒæŸ¥ä¸­çš„ç‰¹å®šä½ç½®ï¼Œå¯èƒ½ä½ æ­£åœ¨ä¸ºä½ çš„ç‰¹å®šå›½å®¶è¿›è¡Œä¸€äº›åˆ†æï¼Œä½ åªæƒ³çœ‹åˆ°æ¥è‡ªè¯¥ä½ç½®çš„è°ƒæŸ¥ç»“æœï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­è§è¿‡è¿™ä¸€ç‚¹ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬æƒ³è¿‡æ»¤ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´æˆ‘ä¼šåœ¨è¿™é‡Œåˆ›å»ºä¸€ä¸ªè¿‡æ»¤å™¨ï¼Œåªè¦è¯´æˆ‘æƒ³è¦è¿™é‡Œçš„å›½å®¶ï¼Œå¦‚æœå›½å®¶ç­‰äºå°åº¦ã€‚æ‰€ä»¥å‡è®¾ä½ åœ¨åšä¸€äº›åˆ†æï¼Œä½ åªæƒ³è¦æ¥è‡ªå°åº¦çš„è°ƒæŸ¥ç»“æœï¼Œç°åœ¨æˆ‘è¦åœ¨è¿™é‡Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®æ¡†ã€‚
- en: I'll call this Indiadf and do a Df do Lo and pass in filterã€‚ So now if I do
    an Indiadf do head to take a look at the beginning of this new data frame if we
    look over here in the country column then we can see that all of these countries
    here are now set to India so now let's say that we want to export this new filter
    data frame to a CSv file So to do this we can use the two CSv methodã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ç§°ä¹‹ä¸º Indiadf å¹¶åšä¸€ä¸ª Df do Lo å¹¶ä¼ å…¥è¿‡æ»¤å™¨ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘åšä¸€ä¸ª Indiadf do head æ¥æŸ¥çœ‹è¿™ä¸ªæ–°æ•°æ®æ¡†çš„å¼€å¤´ï¼Œå¦‚æœæˆ‘ä»¬åœ¨å›½å®¶åˆ—ä¸­æŸ¥çœ‹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œæ‰€æœ‰çš„å›½å®¶ç°åœ¨éƒ½è®¾ç½®ä¸ºå°åº¦ã€‚æ‰€ä»¥ç°åœ¨å‡è®¾æˆ‘ä»¬æƒ³å°†è¿™ä¸ªæ–°çš„è¿‡æ»¤æ•°æ®æ¡†å¯¼å‡ºåˆ°ä¸€ä¸ª
    CSv æ–‡ä»¶ã€‚å› æ­¤ï¼Œä¸ºæ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸¤ä¸ª CSv æ–¹æ³•ã€‚
- en: So we can say I'll just say India underscore Dfï¼Œ which is our data frame do2
    underscore CSv and now I'm just going to pass it into that same location in that
    data directory and then I'll just call this modified do cv So if I run this we
    can see that we don't get any errors and now if I go back and look at my file
    system here then I have this modified do cvã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´æˆ‘ä¼šè¯´å°åº¦ä¸‹åˆ’çº¿ Dfï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„æ•°æ®æ¡† do2 ä¸‹åˆ’çº¿ CSvï¼Œç°åœ¨æˆ‘å°†æŠŠå®ƒä¼ å…¥é‚£ä¸ªæ•°æ®ç›®å½•ä¸­çš„ç›¸åŒä½ç½®ï¼Œç„¶åæˆ‘å°†ç§°ä¹‹ä¸ºè¿™ä¸ªä¿®æ”¹åçš„
    do cvã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ²¡æœ‰ä»»ä½•é”™è¯¯ï¼Œç°åœ¨å¦‚æœæˆ‘å›å»çœ‹çœ‹æˆ‘çš„æ–‡ä»¶ç³»ç»Ÿï¼Œé‚£ä¹ˆæˆ‘æœ‰è¿™ä¸ªä¿®æ”¹åçš„ do cvã€‚
- en: so if I click on thisã€‚Then we can see that this is know a little bunch together
    since it's a CSV fileã€‚ a Ros CSsv file that we're looking atã€‚ but we can see that
    we have all of our column names hereã€‚ and then the second row should be the first
    result and I can see here that we have India for that country if I look at the
    second result we can see we have India again and India again down here most likely
    I can't see it but you know we can just assume that it's there it's looking goodã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘ç‚¹å‡»è¿™ä¸ªã€‚é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ç°åœ¨æ˜¯ä¸€ä¸ªå°å—åœ¨ä¸€èµ·ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ª CSV æ–‡ä»¶ã€‚æˆ‘ä»¬æ­£åœ¨æŸ¥çœ‹ä¸€ä¸ª Ros CSsv æ–‡ä»¶ã€‚ä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰æ‰€æœ‰çš„åˆ—ååœ¨è¿™é‡Œã€‚ç„¶åç¬¬äºŒè¡Œåº”è¯¥æ˜¯ç¬¬ä¸€ä¸ªç»“æœï¼Œæˆ‘å¯ä»¥çœ‹åˆ°è¿™é‡Œæˆ‘ä»¬æœ‰å°åº¦ä½œä¸ºé‚£ä¸ªå›½å®¶ï¼Œå¦‚æœæˆ‘æŸ¥çœ‹ç¬¬äºŒä¸ªç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å†æ¬¡æœ‰å°åº¦ï¼Œå¹¶ä¸”åœ¨è¿™é‡Œå†æ¬¡æœ‰å°åº¦ï¼Œæˆ‘å¯èƒ½çœ‹ä¸åˆ°ï¼Œä½†ä½ çŸ¥é“æˆ‘ä»¬å¯ä»¥å‡è®¾å®ƒåœ¨é‚£é‡Œï¼Œçœ‹èµ·æ¥å¾ˆå¥½ã€‚
- en: and actually there it is right thereã€‚ so we can see that we did actually export
    that data frame where we filtered that down to a new CSv file so that was easy
    enough so now let's look at how to read and write to some other formatsã€‚ So one
    thing that you might run into is a tabbedlim file these are almost exactly the
    same thing as CSV filesã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œå®ƒå°±åœ¨é‚£å„¿ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ç¡®å®å°†è¿™ä¸ªæ•°æ®æ¡†å¯¼å‡ºåˆ°ä¸€ä¸ªæ–°çš„ CSv æ–‡ä»¶ä¸­ï¼Œæ‰€ä»¥è¿™å¾ˆç®€å•ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è¯»å–å’Œå†™å…¥ä¸€äº›å…¶ä»–æ ¼å¼ã€‚æ‰€ä»¥ä½ å¯èƒ½ä¼šé‡åˆ°ä¸€ä¸ªåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡ä»¶ï¼Œè¿™å‡ ä¹ä¸
    CSV æ–‡ä»¶å®Œå…¨ç›¸åŒã€‚
- en: but instead of your data being separated by a comma the data is instead separated
    by tabs so to do thisã€‚pasï¼Œ we're still going to use the same CSV methods that
    we've already seenã€‚ but we're going to pass in a custom separator so we can write
    to a tabbedlim file just by changing the file extension here to do TSV and I'm
    also going to specify a separator argumentã€‚ So I'm going to sayep SPã€‚ and then
    you want to pass in your separatorã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ çš„æ•°æ®ä¸æ˜¯ç”¨é€—å·åˆ†éš”ï¼Œè€Œæ˜¯ç”¨åˆ¶è¡¨ç¬¦åˆ†éš”ã€‚å› æ­¤ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬ä»å°†ä½¿ç”¨æˆ‘ä»¬å·²ç»çœ‹åˆ°çš„ç›¸åŒçš„ CSV æ–¹æ³•ï¼Œä½†æˆ‘ä»¬å°†ä¼ å…¥ä¸€ä¸ªè‡ªå®šä¹‰åˆ†éš”ç¬¦ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æ–‡ä»¶æ‰©å±•åæ›´æ”¹ä¸º
    TSV æ¥å†™å…¥ä¸€ä¸ªåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡ä»¶ï¼Œæˆ‘è¿˜å°†æŒ‡å®šä¸€ä¸ªåˆ†éš”ç¬¦å‚æ•°ã€‚æ‰€ä»¥æˆ‘ä¼šè¯´ep SPã€‚ç„¶åä½ æƒ³ä¼ å…¥ä½ çš„åˆ†éš”ç¬¦ã€‚
- en: Now you can pass in anything here if you want you know a file that is separated
    by hashes or anythingã€‚ but commas and tabs are probably the most commonã€‚ So I'm
    going to put a backslash T there because that's how we specified tabs in Pythonã€‚
    And now if I run this cellã€‚ I'm going to go back to our data directory hereã€‚ we
    can see that now we have this modified do TSvã€‚ if I click on that then we can
    see that now this looks almost exactly the same as the comma separated fileã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³ä¼ å…¥ä»»ä½•å†…å®¹ï¼Œä¾‹å¦‚ç”¨äº•å·åˆ†éš”çš„æ–‡ä»¶æˆ–å…¶ä»–å†…å®¹ï¼Œä½†é€—å·å’Œåˆ¶è¡¨ç¬¦å¯èƒ½æ˜¯æœ€å¸¸è§çš„ã€‚æ‰€ä»¥æˆ‘å°†åœ¨è¿™é‡Œæ”¾ä¸€ä¸ªåæ–œæ  Tï¼Œå› ä¸ºè¿™å°±æ˜¯æˆ‘ä»¬åœ¨ Python ä¸­æŒ‡å®šåˆ¶è¡¨ç¬¦çš„æ–¹å¼ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªå•å…ƒï¼Œæˆ‘å°†è¿”å›åˆ°æˆ‘ä»¬çš„æ•°æ®ç›®å½•ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªä¿®æ”¹åçš„
    do TSvã€‚å¦‚æœæˆ‘ç‚¹å‡»å®ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™çœ‹èµ·æ¥å‡ ä¹å’Œé€—å·åˆ†éš”çš„æ–‡ä»¶ä¸€æ ·ã€‚
- en: but now we have tabs here instead of commasã€‚Nowï¼Œ if you're reading in tab CSV
    filesã€‚ then all you need to do is take this SP equal to backslash Tã€‚ and you can
    just add that as an argument up here to read CSVï¼Œ so it's basically the same thingã€‚Okayã€‚
    so now let's move on to some other file formatsã€‚ Nowã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ç°åœ¨æˆ‘ä»¬è¿™é‡Œæœ‰åˆ¶è¡¨ç¬¦è€Œä¸æ˜¯é€—å·ã€‚ç°åœ¨ï¼Œå¦‚æœä½ æ­£åœ¨è¯»å–åˆ¶è¡¨ç¬¦åˆ†éš”çš„ CSV æ–‡ä»¶ï¼Œä½ åªéœ€è¦å°† SP è®¾ç½®ä¸ºåæ–œæ  Tã€‚ä½ å¯ä»¥å°†å…¶ä½œä¸ºå‚æ•°æ·»åŠ åˆ°è¿™é‡Œçš„
    read CSVï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ç›¸åŒçš„ã€‚å¥½çš„ï¼Œç°åœ¨è®©æˆ‘ä»¬ç»§ç»­å…¶ä»–æ–‡ä»¶æ ¼å¼ã€‚
- en: a very popular file format when working with this kind of data is Excelã€‚ Nowã€‚
    if we want to write to Excelï¼Œ then we're going to need to Pip install a couple
    of packagesã€‚ So I have my terminal open with the current environment that I am
    using this is my Jupyter notebook running hereã€‚ let me grab my other terminalã€‚
    So I have the same environment that I'm using within Jupiterã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤„ç†è¿™ç§æ•°æ®æ—¶ï¼Œéå¸¸æµè¡Œçš„æ–‡ä»¶æ ¼å¼æ˜¯ Excelã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å†™å…¥ Excelï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ Pip å®‰è£…å‡ ä¸ªè½¯ä»¶åŒ…ã€‚æ‰€ä»¥æˆ‘æ‰“å¼€äº†æˆ‘çš„ç»ˆç«¯ï¼Œå½“å‰ç¯å¢ƒæ˜¯æˆ‘åœ¨ä½¿ç”¨çš„
    Jupyter notebookã€‚è®©æˆ‘æŠ“å–æˆ‘çš„å¦ä¸€ä¸ªç»ˆç«¯ã€‚æ‰€ä»¥æˆ‘åœ¨ Jupiter ä¸­ä½¿ç”¨çš„æ˜¯ç›¸åŒçš„ç¯å¢ƒã€‚
- en: You want to be sure that you're using that same environment so that your Pip
    installing in the right locationã€‚ and now we're going to install a couple of packagesã€‚
    So first I'm going say Pip installã€‚ and this is Xl W Tã€‚ So Xwt will write to an
    older Xls Excel formatã€‚ but if you want to write to a newer Excells X Excel formatã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æƒ³ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„ç¯å¢ƒï¼Œä»¥ä¾¿ä½ çš„ Pip å®‰è£…åœ¨æ­£ç¡®çš„ä½ç½®ã€‚ç°åœ¨æˆ‘ä»¬è¦å®‰è£…å‡ ä¸ªè½¯ä»¶åŒ…ã€‚é¦–å…ˆï¼Œæˆ‘è¦è¯´ Pip installã€‚è¿™æ˜¯ Xl W Tã€‚Xwt
    å°†å†™å…¥è¾ƒæ—§çš„ Xls Excel æ ¼å¼ã€‚ä½†å¦‚æœä½ æƒ³å†™å…¥è¾ƒæ–°çš„ Excel æ ¼å¼ã€‚
- en: then we'll also need to install open pi XLã€‚ and you can p install multipleã€‚ğŸ˜Šï¼Œpackageagesã€‚
    but just by list them all right hereã€‚ And finallyï¼Œ we wantï¼Œ if we want to read
    Excel filesã€‚ then we can install the X LRD packageã€‚ So I think that is the three
    packages that we're going to need in order to work with Excel files hereã€‚ So I'll
    go ahead and install all of those and let those finishã€‚And once those are installedã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜éœ€è¦å®‰è£… open pi XLã€‚ä½ å¯ä»¥é€šè¿‡åˆ—å‡ºæ‰€æœ‰è½¯ä»¶åŒ…æ¥å®‰è£…å¤šä¸ªã€‚ğŸ˜Šï¼Œä½†åªéœ€åœ¨è¿™é‡Œåˆ—å‡ºå®ƒä»¬ã€‚æœ€åï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¯»å– Excel æ–‡ä»¶ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å®‰è£…
    X LRD åŒ…ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™æ˜¯æˆ‘ä»¬åœ¨å¤„ç† Excel æ–‡ä»¶æ—¶æ‰€éœ€çš„ä¸‰ä¸ªè½¯ä»¶åŒ…ã€‚æ‰€ä»¥æˆ‘å°†ç»§ç»­å®‰è£…æ‰€æœ‰è¿™äº›ï¼Œè®©å®ƒä»¬å®Œæˆã€‚ä¸€æ—¦å®‰è£…å®Œæˆã€‚
- en: let's go back to our notebookã€‚ And now let's try to write to an Excel fileã€‚
    So to write to an Excel fileï¼Œ I'm just going to write the same modified data frame
    that we have hereã€‚ And we are going to use the two underscore Excel methodã€‚ and
    this is just as easy as passing inã€‚ let's say I'll save it in that data folder
    againã€‚ I'll call this modified dot Xls Xã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„ç¬”è®°æœ¬ã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•å†™å…¥ä¸€ä¸ª Excel æ–‡ä»¶ã€‚ä¸ºäº†å†™å…¥ Excel æ–‡ä»¶ï¼Œæˆ‘å°†å†™å…¥æˆ‘ä»¬è¿™é‡Œçš„ç›¸åŒä¿®æ”¹åçš„æ•°æ®æ¡†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªä¸‹åˆ’çº¿
    Excel æ–¹æ³•ã€‚è¿™å°±åƒä¼ å…¥ä¸€ä¸ªå‚æ•°ä¸€æ ·ç®€å•ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘å°†æŠŠå®ƒä¿å­˜åœ¨é‚£ä¸ªæ•°æ®æ–‡ä»¶å¤¹ä¸­ã€‚æˆ‘å°†å…¶å‘½åä¸º modified dot Xls Xã€‚
- en: So I'm going to write to the newer Excel formatã€‚ So if I run thisã€‚ then it might
    take a second here for this to work because it's actually creating this Excel
    file on the back endã€‚ So let's let this finish and we can tell it's finished when
    this turns from an asterisk to a number hereã€‚Okayï¼Œ so once that's finishedï¼Œ let's
    flip over to our data folder here and we can see that we do have that dot Xlsx
    fileã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†å†™å…¥è¾ƒæ–°çš„ Excel æ ¼å¼ã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œå®ƒå¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´æ¥å®Œæˆï¼Œå› ä¸ºå®ƒå®é™…ä¸Šæ˜¯åœ¨åå°åˆ›å»ºè¿™ä¸ª Excel æ–‡ä»¶ã€‚è®©æˆ‘ä»¬ç­‰å®ƒå®Œæˆï¼Œå½“è¿™ä¸ªä»æ˜Ÿå·å˜ä¸ºæ•°å­—æ—¶ï¼Œæˆ‘ä»¬å°±å¯ä»¥çŸ¥é“å®ƒå®Œæˆäº†ã€‚å¥½çš„ï¼Œå®Œæˆåï¼Œè®©æˆ‘ä»¬ç¿»åˆ°æ•°æ®æ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç¡®å®æœ‰é‚£ä¸ª
    dot Xlsx æ–‡ä»¶ã€‚
- en: Now this likely won't open up in Jupiter because this is an Excel fileã€‚ We can
    see here that we can't open this up in the browserã€‚ We actually need Excelã€‚ So
    let me open up my finder window hereã€‚ I have this open down hereã€‚ And I am within
    this data folderã€‚ and we can see that we have our modified dot Xsx file hereã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™åœ¨ Jupiter ä¸­å¯èƒ½æ— æ³•æ‰“å¼€ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ª Excel æ–‡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æ— æ³•åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€å®ƒã€‚æˆ‘ä»¬å®é™…ä¸Šéœ€è¦ Excelã€‚æ‰€ä»¥è®©æˆ‘æ‰“å¼€æˆ‘çš„æŸ¥æ‰¾å™¨çª—å£ã€‚æˆ‘åœ¨è¿™é‡Œæ‰“å¼€äº†å®ƒã€‚æˆ‘åœ¨è¿™ä¸ªæ•°æ®æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰ä¿®æ”¹åçš„
    dot Xsx æ–‡ä»¶ã€‚
- en: Now I don't actually have Excel on this machineã€‚ I have numbersã€‚ So I'm going
    to open this up in numbersã€‚ It should basically be the same on Windowsã€‚ but you
    can just open it up with Excelã€‚ Nowï¼Œ againã€‚ this might take a second to open up
    because we do still have a lot of rows here in this dataã€‚Okayã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å®é™…ä¸Šåœ¨è¿™å°æœºå™¨ä¸Šæ²¡æœ‰ Excelï¼Œæˆ‘æœ‰ Numbersã€‚æ‰€ä»¥æˆ‘å°†åœ¨ Numbers ä¸­æ‰“å¼€å®ƒã€‚å®ƒåœ¨ Windows ä¸ŠåŸºæœ¬ä¸Šåº”è¯¥æ˜¯ä¸€æ ·çš„ï¼Œä½†ä½ å¯ä»¥ç›´æ¥ç”¨
    Excel æ‰“å¼€ã€‚å†æ¬¡è¯´æ˜ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€ç§’é’Ÿæ¥æ‰“å¼€ï¼Œå› ä¸ºæˆ‘ä»¬è¿™é‡Œçš„æ•°æ®ä»ç„¶æœ‰å¾ˆå¤šè¡Œã€‚å¥½çš„ã€‚
- en: so we've got this opened up in Excelã€‚ againï¼Œ I'm on numbers because I'm on a
    Mac and I don't have Excel installedã€‚ but it should open up find in Excel as wellã€‚
    Let me zoom in a little bit hereã€‚ So we can see and we can format these if we
    need toã€‚ Soï¼Œ for exampleã€‚ we can change the column sizes here so that all these
    fit in but we can see here that we have our respondent Isã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å·²ç»åœ¨ Excel ä¸­æ‰“å¼€äº†è¿™ä¸ªæ–‡ä»¶ã€‚å†æ¬¡è¯´æ˜ï¼Œæˆ‘ç”¨çš„æ˜¯ Numbersï¼Œå› ä¸ºæˆ‘åœ¨ Mac ä¸Šï¼Œæ²¡æœ‰å®‰è£… Excelã€‚ä½†å®ƒåœ¨ Excel ä¸­ä¹Ÿåº”è¯¥èƒ½æ­£å¸¸æ‰“å¼€ã€‚è®©æˆ‘æ”¾å¤§ä¸€ç‚¹ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœéœ€è¦ï¼Œæˆ‘ä»¬å¯ä»¥æ ¼å¼åŒ–è¿™äº›å†…å®¹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œæ›´æ”¹åˆ—çš„å¤§å°ï¼Œä½¿æ‰€æœ‰å†…å®¹é€‚åº”ï¼Œä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å›åº”è€…æ˜¯ã€‚
- en: if I look over at countryï¼Œ we can see that it did export the filtered data frame
    that we were hoping to exportã€‚ So everything looks good hereã€‚ Now there are also
    some more advanced things that we can do with Excel as wellã€‚ if you're familiar
    with Excelã€‚ then you might know that we have the concept of different sheets where
    we can have multiple spreadsheets and one Excel fileã€‚ And if you want to read
    or write to a specific sheetã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘æŸ¥çœ‹å›½å®¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒç¡®å®å¯¼å‡ºäº†æˆ‘ä»¬å¸Œæœ›å¯¼å‡ºçš„è¿‡æ»¤æ•°æ®æ¡†ã€‚æ‰€ä»¥ä¸€åˆ‡çœ‹èµ·æ¥éƒ½å¾ˆå¥½ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å¯¹ Excel åšä¸€äº›æ›´é«˜çº§çš„æ“ä½œã€‚å¦‚æœä½ ç†Ÿæ‚‰
    Excelï¼Œå¯èƒ½çŸ¥é“æˆ‘ä»¬æœ‰ä¸åŒå·¥ä½œè¡¨çš„æ¦‚å¿µï¼Œå¯ä»¥åœ¨ä¸€ä¸ª Excel æ–‡ä»¶ä¸­æœ‰å¤šä¸ªç”µå­è¡¨æ ¼ã€‚å¦‚æœä½ æƒ³è¯»å–æˆ–å†™å…¥ç‰¹å®šå·¥ä½œè¡¨ã€‚
- en: then you can pass in a sheet argument to these methods actually I trying to
    scroll over to my notebook hereã€‚Let me scroll down here to the bottomã€‚ So like
    I was sayingã€‚ if you want to read or write to a specific sheetï¼Œ then you can pass
    in a sheet argument to these methodsã€‚ And there's also a way to start from different
    columns and rows as wellã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆä½ å¯ä»¥å°†å·¥ä½œè¡¨å‚æ•°ä¼ é€’ç»™è¿™äº›æ–¹æ³•ã€‚å®é™…ä¸Šï¼Œæˆ‘æ­£åœ¨å°è¯•æ»šåŠ¨åˆ°æˆ‘çš„ç¬”è®°æœ¬ä¸Šã€‚è®©æˆ‘æ»šåŠ¨åˆ°æœ€åº•éƒ¨ã€‚æ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œå¦‚æœä½ æƒ³è¯»å–æˆ–å†™å…¥ç‰¹å®šå·¥ä½œè¡¨ï¼Œä½ å¯ä»¥å°†å·¥ä½œè¡¨å‚æ•°ä¼ é€’ç»™è¿™äº›æ–¹æ³•ã€‚è¿˜æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä»ä¸åŒçš„åˆ—å’Œè¡Œå¼€å§‹ã€‚
- en: But I'm not going go into all these little details hereã€‚ If you Google this
    method name to Excelã€‚ Then you can find the arguments that you can pass in and
    all the additional details in the documentationã€‚ So for nowï¼Œ let's go ahead and
    move on and see how that we can read in that same Excel file that we just created
    and make sure that this worksã€‚ Nowï¼Œ by defaultï¼Œ it's going to load in with a default
    indexï¼Œ just like when we read a Cv fileã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä¸æ‰“ç®—åœ¨è¿™é‡Œæ·±å…¥æ¢è®¨è¿™äº›å°ç»†èŠ‚ã€‚å¦‚æœä½ åœ¨è°·æ­Œä¸Šæœç´¢è¿™ä¸ªæ–¹æ³•åç§°ä¸ Excel ç›¸å…³çš„å†…å®¹ï¼Œä½ å¯ä»¥æ‰¾åˆ°å¯ä»¥ä¼ å…¥çš„å‚æ•°å’Œæ–‡æ¡£ä¸­çš„æ‰€æœ‰é¢å¤–ç»†èŠ‚ã€‚æ‰€ä»¥ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»§ç»­ï¼Œçœ‹çœ‹å¦‚ä½•è¯»å–æˆ‘ä»¬åˆšåˆ›å»ºçš„åŒä¸€ä¸ª
    Excel æ–‡ä»¶ï¼Œå¹¶ç¡®ä¿è¿™èƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä¼šåŠ è½½ä¸€ä¸ªé»˜è®¤ç´¢å¼•ï¼Œå°±åƒæˆ‘ä»¬è¯»å– Cv æ–‡ä»¶æ—¶ä¸€æ ·ã€‚
- en: So we'll have to specify that we want our index column to be that respondent
    columnã€‚ So to do thatã€‚ I'm just going to call this test since we're going to be
    creating a new data frame here from that Excel file that we just createdã€‚ And
    we're going to use the read underscore Excel method hereã€‚ and now weã€‚I want to
    pass in the locationï¼Œ and I'll just go ahead and copy this hereã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬éœ€è¦æŒ‡å®šæˆ‘ä»¬çš„ç´¢å¼•åˆ—æ˜¯é‚£ä¸ªå›åº”è€…åˆ—ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘å°±å«å®ƒæµ‹è¯•ï¼Œå› ä¸ºæˆ‘ä»¬å°†ä»åˆšåˆ›å»ºçš„ Excel æ–‡ä»¶ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®æ¡†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `read_excel`
    æ–¹æ³•ï¼Œå¹¶ä¸”æˆ‘æƒ³ä¼ å…¥ä½ç½®ï¼Œæˆ‘ä¼šå¤åˆ¶è¿™ä¸ªä½ç½®ã€‚
- en: So that is modified Xl S X on my machineã€‚ And now I'm going to set that index
    column equal to and that was respondent on your data that might be differentã€‚
    but I want my index column to be equal to that respondentã€‚ So I'm going to run
    that cell and load that in and then I'm going to look at that test data frameã€‚
    Now before I run thisï¼Œ I'm going to make sure that this finishes processing here
    and that this asterisk goes away againã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘æœºå™¨ä¸Šçš„ä¿®æ”¹ç‰ˆ Xl S Xã€‚ç°åœ¨æˆ‘è¦å°†ç´¢å¼•åˆ—è®¾ç½®ä¸ºå›åº”è€…ï¼Œåœ¨ä½ çš„æ•°æ®ä¸­å¯èƒ½ä¼šä¸åŒï¼Œä½†æˆ‘å¸Œæœ›æˆ‘çš„ç´¢å¼•åˆ—ç­‰äºé‚£ä¸ªå›åº”è€…ã€‚æ‰€ä»¥æˆ‘å°†è¿è¡Œé‚£ä¸ªå•å…ƒæ ¼å¹¶åŠ è½½å®ƒï¼Œç„¶åæŸ¥çœ‹æµ‹è¯•æ•°æ®æ¡†ã€‚åœ¨æˆ‘è¿è¡Œè¿™ä¸ªä¹‹å‰ï¼Œæˆ‘ä¼šç¡®ä¿è¿™ä¸ªå¤„ç†å®Œæˆï¼Œå¹¶ä¸”è¿™ä¸ªæ˜Ÿå·æ¶ˆå¤±ã€‚
- en: it can take some time because it's actually you know loading in that data from
    Excel nowã€‚ which is a little more tricky than loading it in from a CSvã€‚ So now
    if we look at that test data frameï¼Œ let me just look at the head here instead
    of looking at the whole thingã€‚ So if I look at the headï¼Œ then we can see that
    we have the same data frame here that we had up hereã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå› ä¸ºå®ƒå®é™…ä¸Šæ˜¯åœ¨ä»ExcelåŠ è½½æ•°æ®ï¼Œè¿™æ¯”ä»CSVåŠ è½½è¦å¤æ‚ä¸€äº›ã€‚é‚£ä¹ˆç°åœ¨å¦‚æœæˆ‘ä»¬æŸ¥çœ‹è¿™ä¸ªæµ‹è¯•æ•°æ®æ¡†ï¼Œè®©æˆ‘åªçœ‹ä¸€ä¸‹å¤´éƒ¨ï¼Œè€Œä¸æ˜¯æŸ¥çœ‹æ•´ä¸ªå†…å®¹ã€‚å¦‚æœæˆ‘æŸ¥çœ‹å¤´éƒ¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªä¸ä¸Šé¢ç›¸åŒçš„æ•°æ®æ¡†ã€‚
- en: So that was exported to Excel and imported correctlyã€‚ Okayã€‚ so now let's cover
    some other popular fileã€‚Formats now JSson is also really popular for this kind
    of dataã€‚ So let's take a look at thatã€‚ Firstï¼Œ let's write our modified data frame
    to a Json fileã€‚ Now for writing to a Json fileï¼Œ then we can use the two Json methodã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™è¢«å¯¼å‡ºåˆ°Excelå¹¶æ­£ç¡®å¯¼å…¥äº†ã€‚å¥½çš„ã€‚é‚£ä¹ˆç°åœ¨æˆ‘ä»¬æ¥ä»‹ç»ä¸€äº›å…¶ä»–æµè¡Œçš„æ–‡ä»¶æ ¼å¼ã€‚ç°åœ¨JSonåœ¨è¿™ç§æ•°æ®ä¸­ä¹Ÿéå¸¸æµè¡Œã€‚é‚£ä¹ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†ä¿®æ”¹åçš„æ•°æ®æ¡†å†™å…¥ä¸€ä¸ªJsonæ–‡ä»¶ã€‚å¯¹äºå†™å…¥Jsonæ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨to_jsonæ–¹æ³•ã€‚
- en: So you're probably starting to see a pattern hereã€‚ These method names are very
    straightforwardã€‚ Now this one is a bit different since there are some different
    orientations that we can use for Jsonã€‚ So just by using the default argumentsã€‚
    I can just say so that was India Df do2 underscore Jsonã€‚ and now I'll pass in
    a file location hereã€‚ but instead of an Excel fileï¼Œ we want a Json fileã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯èƒ½å¼€å§‹çœ‹åˆ°ä¸€ä¸ªæ¨¡å¼ã€‚è¿™äº›æ–¹æ³•åç§°éå¸¸ç›´æ¥ã€‚ç°åœ¨è¿™ä¸ªç¨å¾®æœ‰ç‚¹ä¸åŒï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ä¸ºJsonä½¿ç”¨ä¸€äº›ä¸åŒçš„æ–¹å‘ã€‚å› æ­¤ï¼Œåªéœ€ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œæˆ‘å¯ä»¥è¯´ï¼Œè¿™å°±æ˜¯India_Df.to_jsonã€‚ç„¶åæˆ‘å°†ä¼ å…¥ä¸€ä¸ªæ–‡ä»¶ä½ç½®ï¼Œä½†ä¸æ˜¯Excelæ–‡ä»¶ï¼Œè€Œæ˜¯Jsonæ–‡ä»¶ã€‚
- en: Now I'm just going to use the default arguments for nowã€‚ and then I'll show
    you how we can change this up a bitã€‚ So if I run thisã€‚ we can see that ran very
    quicklyã€‚ if I go back to my data folder hereã€‚ Then now we have this JSson fileã€‚
    if I look within hereã€‚Okayã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å°†æš‚æ—¶ä½¿ç”¨é»˜è®¤å‚æ•°ã€‚ç„¶åæˆ‘ä¼šå‘Šè¯‰ä½ å¦‚ä½•ç¨å¾®æ”¹å˜ä¸€ä¸‹ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒè¿è¡Œå¾—éå¸¸å¿«ã€‚å¦‚æœæˆ‘è¿”å›åˆ°æˆ‘çš„æ•°æ®æ–‡ä»¶å¤¹ã€‚é‚£ä¹ˆç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™ä¸ªJSonæ–‡ä»¶ã€‚å¦‚æœæˆ‘åœ¨è¿™é‡ŒæŸ¥çœ‹ã€‚å¥½çš„ã€‚
- en: that took just a second to open up on my machineã€‚ againï¼Œ we do have a lot of
    data in hereã€‚ But if we look in hereï¼Œ then we can see that this is very dictionarylikeã€‚
    So we have a main branch key here and then the value for that key are all of the
    responses just for that column And if I was to scroll down here then I would be
    able to find the other keys and the other responses as wellã€‚ So by defaultï¼Œ this
    is a dictionary like Jsonã€‚ Now there are also different ways that we can write
    Json filesã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªèŠ±äº†ä¸€ç§’é’Ÿå°±èƒ½åœ¨æˆ‘çš„æœºå™¨ä¸Šæ‰“å¼€ã€‚å†è¯´ï¼Œæˆ‘ä»¬è¿™é‡Œç¡®å®æœ‰å¾ˆå¤šæ•°æ®ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬åœ¨è¿™é‡ŒæŸ¥çœ‹ï¼Œå°±ä¼šå‘ç°è¿™éå¸¸åƒå­—å…¸ã€‚æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œæœ‰ä¸€ä¸ªä¸»åˆ†æ”¯é”®ï¼Œç„¶åè¯¥é”®çš„å€¼æ˜¯ä»…é’ˆå¯¹è¯¥åˆ—çš„æ‰€æœ‰å“åº”ã€‚å¦‚æœæˆ‘å‘ä¸‹æ»šåŠ¨ï¼Œå°±èƒ½æ‰¾åˆ°å…¶ä»–é”®å’Œå…¶ä»–å“åº”ã€‚å› æ­¤ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™å°±åƒä¸€ä¸ªå­—å…¸ç±»å‹çš„Jsonã€‚ç°åœ¨ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ä¸åŒçš„æ–¹å¼æ¥ç¼–å†™Jsonæ–‡ä»¶ã€‚
- en: againï¼Œ I'm not going to go into every single little detail hereã€‚ but let's say
    that we wanted this Json to be list like instead of dictionary like which is how
    it is by defaultã€‚ So to do thisï¼Œ we can change the orient argumentã€‚ So instead
    let's add one here to our argumentsã€‚ And I'm going to say Orient is equal toã€‚
    And if we pass in recordsã€‚And lines equal to trueã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œæˆ‘ä¸ä¼šæ·±å…¥åˆ°æ¯ä¸€ä¸ªç»†èŠ‚ã€‚ä½†å‡è®¾æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªJsonæ˜¯åˆ—è¡¨å½¢å¼è€Œä¸æ˜¯é»˜è®¤çš„å­—å…¸å½¢å¼ã€‚é‚£ä¹ˆä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ”¹orientå‚æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨å‚æ•°ä¸­æ·»åŠ ä¸€ä¸ªã€‚å¹¶ä¸”æˆ‘ä¼šè¯´orientç­‰äºã€‚å¦‚æœæˆ‘ä»¬ä¼ å…¥recordsï¼Œå¹¶ä¸”linesç­‰äºtrueã€‚
- en: Then this will now make this records likeï¼Œ which is list likeã€‚ And this lines
    equal to trueã€‚ Let me spell that rightã€‚ Well just make each of these on a new
    lineã€‚ So it might be a little bit easier to readã€‚ Nowï¼Œ if you want to see the
    exact arguments that you can pass into Orientã€‚ then againï¼Œ just look up pandas
    to Json methodã€‚ and it'll take you to the documentation with all the different
    things that you can pass in hereã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™å°†ä½¿å…¶å˜æˆè®°å½•å½¢å¼ï¼Œå³åˆ—è¡¨å½¢å¼ã€‚å¹¶ä¸”linesç­‰äºtrueã€‚è®©æˆ‘æ‹¼å†™æ­£ç¡®ã€‚å¥½å§ï¼Œåªæ˜¯è®©æ¯ä¸ªéƒ½åœ¨æ–°çš„ä¸€è¡Œä¸Šã€‚è¿™æ ·å¯èƒ½æ›´å®¹æ˜“é˜…è¯»ã€‚å¦‚æœä½ æƒ³æŸ¥çœ‹å¯ä»¥ä¼ é€’ç»™orientçš„ç¡®åˆ‡å‚æ•°ï¼Œé‚£ä¹ˆå†æ¬¡æŸ¥çœ‹pandasçš„to_jsonæ–¹æ³•ã€‚å®ƒä¼šå¸¦ä½ åˆ°æ–‡æ¡£ä¸­ï¼Œé‚£é‡Œæœ‰æ‰€æœ‰å¯ä»¥ä¼ å…¥çš„ä¸åŒå†…å®¹ã€‚
- en: So let me run thisã€‚ And now let's go back and reload our Json file to see how
    this looksã€‚ And now what we have here is more list likeã€‚ So before we had a single
    dictionary where the values were a list of all of the responsesã€‚ But now we have
    one response at a timeã€‚ So we have the main branchã€‚ And then So this is actually
    this first one hereã€‚ If I scroll downã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘è¿è¡Œè¿™ä¸ªã€‚ç°åœ¨è®©æˆ‘ä»¬è¿”å›å¹¶é‡æ–°åŠ è½½æˆ‘ä»¬çš„Jsonæ–‡ä»¶ï¼Œçœ‹çœ‹å®ƒçš„æ ·å­ã€‚ç°åœ¨æˆ‘ä»¬è¿™é‡Œæœ‰çš„æ›´åƒæ˜¯åˆ—è¡¨å½¢å¼ã€‚å› æ­¤åœ¨ä¹‹å‰æˆ‘ä»¬æœ‰ä¸€ä¸ªå•ä¸€çš„å­—å…¸ï¼Œå…¶ä¸­çš„å€¼æ˜¯æ‰€æœ‰å“åº”çš„åˆ—è¡¨ã€‚ä½†æ˜¯ç°åœ¨æˆ‘ä»¬ä¸€æ¬¡åªæœ‰ä¸€ä¸ªå“åº”ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰ä¸»åˆ†æ”¯ã€‚ç„¶åè¿™å®é™…ä¸Šæ˜¯è¿™é‡Œçš„ç¬¬ä¸€ä¸ªã€‚å¦‚æœæˆ‘å‘ä¸‹æ»šåŠ¨ã€‚
- en: we can see that this is the secondã€‚ğŸ˜Šï¼ŒThis is actually the entire first responseã€‚
    So we have the main branch and then that answer and then open source and then
    that answerã€‚ and then so onã€‚ And we can see here that for the countryï¼Œ we have
    Indiaã€‚ and each response within this survey is actually on a different lineã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™æ˜¯ç¬¬äºŒä¸ªã€‚ğŸ˜Šè¿™å®é™…ä¸Šæ˜¯æ•´ä¸ªç¬¬ä¸€ä¸ªå“åº”ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰ä¸»è¦åˆ†æ”¯ï¼Œç„¶åæ˜¯ç­”æ¡ˆï¼Œç„¶åæ˜¯å¼€æºï¼Œç„¶åæ˜¯ç­”æ¡ˆï¼Œä¾æ­¤ç±»æ¨ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°ï¼Œå¯¹äºå›½å®¶ï¼Œæˆ‘ä»¬æœ‰å°åº¦ã€‚æ¯ä¸ªè°ƒæŸ¥ä¸­çš„å“åº”å®é™…ä¸Šéƒ½åœ¨ä¸åŒçš„è¡Œä¸Šã€‚
- en: So that's a little bit different than how it was beforeã€‚ but there's just different
    ways that we can export these Json files depending on your needsã€‚ Okayã€‚ so now
    that we've written our data to JSson filesã€‚ Now let's also read this JSson file
    so that we can make sure that we know how that's done as wellã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ä¹‹å‰çš„æƒ…å†µæœ‰ç‚¹ä¸åŒï¼Œä½†æˆ‘ä»¬å¯ä»¥æ ¹æ®éœ€è¦ä»¥ä¸åŒçš„æ–¹å¼å¯¼å‡ºè¿™äº› Json æ–‡ä»¶ã€‚å¥½çš„ã€‚é‚£ä¹ˆç°åœ¨æˆ‘ä»¬å·²ç»å°†æ•°æ®å†™å…¥ Json æ–‡ä»¶ã€‚ç°åœ¨è®©æˆ‘ä»¬ä¹Ÿè¯»å–è¿™ä¸ª
    Json æ–‡ä»¶ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬çŸ¥é“å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: Nowï¼Œ since we wrote the Json file with these different arguments hereã€‚ then
    we need to use those same arguments when we read the data in as wellã€‚ So if you're
    reading in Json files and have any issuesã€‚ then you might need to play around
    with the different arguments to fit the data that you're trying to read inã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œç”±äºæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨è¿™äº›ä¸åŒçš„å‚æ•°å†™äº† Json æ–‡ä»¶ã€‚é‚£ä¹ˆåœ¨è¯»å–æ•°æ®æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦ä½¿ç”¨ç›¸åŒçš„å‚æ•°ã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ åœ¨è¯»å– Json æ–‡ä»¶æ—¶é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œé‚£ä¹ˆä½ å¯èƒ½éœ€è¦è°ƒæ•´ä¸åŒçš„å‚æ•°ä»¥é€‚åº”ä½ å°è¯•è¯»å–çš„æ•°æ®ã€‚
- en: So in this caseï¼Œ I'm just gonna copy this whole line hereã€‚ And I'm going say
    test is equal toã€‚And actuallyï¼Œ let me just grab this partã€‚And I'll say PDdã€‚ read
    underscore Jsonã€‚ and now I'll pass in all those arguments hereã€‚So we are reading
    the JSON file from this locationã€‚ We know that the Orient is list like instead
    of dictionary like and that all of these are on new linesã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¦å¤åˆ¶æ•´è¡Œã€‚ç„¶åæˆ‘ä¼šè¯´ test ç­‰äºã€‚å®é™…ä¸Šï¼Œè®©æˆ‘å…ˆæŠ“å–è¿™éƒ¨åˆ†ã€‚æˆ‘ä¼šè¯´ pd.read_jsonï¼Œç„¶åå°†æ‰€æœ‰è¿™äº›å‚æ•°ä¼ é€’åœ¨è¿™é‡Œã€‚æ‰€ä»¥æˆ‘ä»¬ä»è¿™ä¸ªä½ç½®è¯»å–
    JSON æ–‡ä»¶ã€‚æˆ‘ä»¬çŸ¥é“ Orient æ˜¯åˆ—è¡¨è€Œä¸æ˜¯å­—å…¸ï¼Œå¹¶ä¸”è¿™äº›éƒ½æ˜¯åœ¨æ–°è¡Œä¸Šã€‚
- en: And againï¼Œ depending on your JSsonN dataï¼Œ you might need to go in and change
    these around depending on how your data looksã€‚ So if I run thisï¼Œ then let's seeã€‚If
    we have the same data that we exported beforeã€‚ and it seems like we doï¼Œ this looks
    exactly like it did whenever we exported this dataã€‚ Okayã€‚ so now the last file
    format that we're gonna look atã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæ ¹æ®ä½ çš„ JSON æ•°æ®ï¼Œä½ å¯èƒ½éœ€è¦æ ¹æ®æ•°æ®çš„å¤–è§‚æ¥è°ƒæ•´è¿™äº›è®¾ç½®ã€‚æ‰€ä»¥å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œçœ‹çœ‹ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¹‹å‰å¯¼å‡ºçš„ç›¸åŒæ•°æ®ã€‚çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼Œè¿™çœ‹èµ·æ¥ä¸æˆ‘ä»¬å¯¼å‡ºæ•°æ®æ—¶å®Œå…¨ç›¸åŒã€‚å¥½çš„ã€‚é‚£ä¹ˆæˆ‘ä»¬è¦æŸ¥çœ‹çš„æœ€åä¸€ç§æ–‡ä»¶æ ¼å¼ã€‚
- en: let's learn how we can read and write data from SQL databasesã€‚ Nowã€‚ this is
    probably the most complicated simply because you have to have the database set
    up and all of that good stuffã€‚ But for the sake of this videoï¼Œ I'm going to assume
    that you already have a database with the correct credentials to log into that
    databaseã€‚ So I have a Postgres database set up on my machine that will be reading
    and writing toã€‚ So firstã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å­¦ä¹ å¦‚ä½•ä» SQL æ•°æ®åº“è¯»å–å’Œå†™å…¥æ•°æ®ã€‚ç°åœ¨ï¼Œè¿™å¯èƒ½æ˜¯æœ€å¤æ‚çš„ï¼Œå› ä¸ºä½ éœ€è¦å…ˆè®¾ç½®æ•°æ®åº“ä»¥åŠæ‰€æœ‰ç›¸å…³çš„é…ç½®ã€‚ä½†ä¸ºäº†æœ¬è§†é¢‘çš„ç›®çš„ï¼Œæˆ‘å°†å‡è®¾ä½ å·²ç»æœ‰ä¸€ä¸ªå¸¦æœ‰æ­£ç¡®ç™»å½•å‡­æ®çš„æ•°æ®åº“ã€‚å› æ­¤ï¼Œæˆ‘åœ¨æˆ‘çš„æœºå™¨ä¸Šè®¾ç½®äº†ä¸€ä¸ª
    Postgres æ•°æ®åº“ï¼Œå°†ç”¨äºè¯»å–å’Œå†™å…¥ã€‚
- en: let's see how we would connect to this databaseã€‚ Nowï¼Œ just like with Excelã€‚
    We're going to need to install a package to do thisã€‚ So let me bring up my terminal
    hereã€‚ I'll close this numbers file hereã€‚ Let's seeï¼Œ let me try to quit out of
    thisï¼Œ actuallyã€‚ I'll just minimize itã€‚Having trouble shutting downã€‚ Okayã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è¿æ¥åˆ°è¿™ä¸ªæ•°æ®åº“ã€‚ç°åœ¨ï¼Œå°±åƒä½¿ç”¨ Excel ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…ä¸€ä¸ªåŒ…æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥è®©æˆ‘æ‰“å¼€æˆ‘çš„ç»ˆç«¯ã€‚æˆ‘è¦å…³é—­è¿™ä¸ªæ•°å­—æ–‡ä»¶ã€‚è®©æˆ‘è¯•ç€é€€å‡ºè¿™ä¸ªï¼Œå®é™…ä¸Šï¼Œæˆ‘ä¼šæŠŠå®ƒæœ€å°åŒ–ã€‚å…³é—­æ—¶é‡åˆ°äº†ä¸€äº›éº»çƒ¦ã€‚å¥½çš„ã€‚
- en: so let me go back to the terminal that I hope opens to where I can install some
    different packagesã€‚ And that's my Jupiter notebookã€‚ Where's my other terminalã€‚
    Here we goã€‚ Okayã€‚ so to connect to our databaseã€‚ We're going to want to install
    SQL alchemyã€‚ And this is a very popular O RM for Python that allows us to more
    easily work with databasesã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘å›åˆ°æˆ‘å¸Œæœ›èƒ½æ‰“å¼€ä»¥å®‰è£…ä¸€äº›ä¸åŒåŒ…çš„ç»ˆç«¯ã€‚è¿™æ˜¯æˆ‘çš„ Jupyter notebookã€‚æˆ‘çš„å¦ä¸€ä¸ªç»ˆç«¯åœ¨å“ªé‡Œï¼Ÿæ¥äº†ã€‚å¥½çš„ã€‚é‚£ä¹ˆè¦è¿æ¥åˆ°æˆ‘ä»¬çš„æ•°æ®åº“ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…
    SQL Alchemyã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„ Python ORMï¼Œå®ƒä½¿æˆ‘ä»¬æ›´å®¹æ˜“å¤„ç†æ•°æ®åº“ã€‚
- en: If you don't know what an O RM isï¼Œ it stands for object relational mapperã€‚ And
    it's just a way for us to use Python objects in order to connect to a databaseã€‚
    I plan on doing a complete video or a complete series on SQL alchemy in the futureã€‚
    But for nowã€‚ let's go ahead and just install thisã€‚ So this is Pip install S QLã€‚Alchemyã€‚And
    I'll install thatã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸çŸ¥é“ä»€ä¹ˆæ˜¯ ORMï¼Œå®ƒæ˜¯å¯¹è±¡å…³ç³»æ˜ å°„çš„ç¼©å†™ã€‚è¿™åªæ˜¯æˆ‘ä»¬ç”¨ Python å¯¹è±¡è¿æ¥åˆ°æ•°æ®åº“çš„ä¸€ç§æ–¹å¼ã€‚æˆ‘è®¡åˆ’å°†æ¥åˆ¶ä½œä¸€ä¸ªå…³äº SQLAlchemy
    çš„å®Œæ•´è§†é¢‘æˆ–ç³»åˆ—æ•™ç¨‹ã€‚ä½†ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»§ç»­å®‰è£…è¿™ä¸ªã€‚æ‰€ä»¥è¿™æ˜¯ Pip install SQLAlchemyã€‚æˆ‘å°†å®‰è£…å®ƒã€‚
- en: And depending on the database that you're usingï¼Œ you might not need to do anything
    else hereã€‚ Soã€‚ for exampleï¼Œ if you're using SQLite or something like thatã€‚ But
    since I'm using a Postgres database for this tutorialã€‚ I also need to install
    the psycho P G2 package that allows us to work with Postgresã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ ä½¿ç”¨çš„æ•°æ®åº“ï¼Œä½ å¯èƒ½åœ¨è¿™é‡Œä¸éœ€è¦åšå…¶ä»–ä»»ä½•äº‹æƒ…ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ SQLite æˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚ä½†ç”±äºæˆ‘åœ¨è¿™ä¸ªæ•™ç¨‹ä¸­ä½¿ç”¨çš„æ˜¯ Postgres
    æ•°æ®åº“ï¼Œæˆ‘è¿˜éœ€è¦å®‰è£… psycopg2 åŒ…ï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨ Postgresã€‚
- en: I'm not sure if that's actually how you say that package nameã€‚ But that's what
    I've always called itã€‚ So Pip install and to install this package to work with
    Postgresã€‚ it's psycho Pg2 dash binaryã€‚ So I'll install thatï¼Œ And with those packages
    installedã€‚ let's go back to our notebook and see if we can connect to this database
    using SQL alchemyã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ç¡®å®šè¿™æ˜¯å¦æ˜¯è¿™ä¸ªåŒ…çš„æ­£ç¡®å‘éŸ³ï¼Œä½†æˆ‘ä¸€ç›´éƒ½æ˜¯è¿™ä¹ˆç§°å‘¼å®ƒçš„ã€‚æ‰€ä»¥ Pip install ä»¥å®‰è£…è¿™ä¸ªä¸ Postgres ä¸€èµ·ä½¿ç”¨çš„åŒ…ï¼Œå®ƒæ˜¯ psycopg2-binaryã€‚æ‰€ä»¥æˆ‘å°†å®‰è£…å®ƒï¼Œå®‰è£…äº†è¿™äº›åŒ…åï¼Œè®©æˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„ç¬”è®°æœ¬ï¼Œçœ‹çœ‹èƒ½å¦ä½¿ç”¨
    SQLAlchemy è¿æ¥åˆ°è¿™ä¸ªæ•°æ®åº“ã€‚
- en: So firstï¼Œ we're going to want to import everything that we needã€‚ So fromã€‚SQL
    alchemyã€‚I'm going to want to import their create engineï¼Œ and this will allow us
    to connect to the databaseã€‚ Now I'm also going to want to import psychoPg2ã€‚ So
    let me run this cellã€‚ and now that those are importedï¼Œ we should be able to create
    the engineã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥æ‰€æœ‰éœ€è¦çš„å†…å®¹ã€‚æ‰€ä»¥ä» SQLAlchemy ä¸­ï¼Œæˆ‘å°†å¯¼å…¥ä»–ä»¬çš„åˆ›å»ºå¼•æ“ï¼Œè¿™å°†å…è®¸æˆ‘ä»¬è¿æ¥åˆ°æ•°æ®åº“ã€‚ç°åœ¨æˆ‘è¿˜éœ€è¦å¯¼å…¥ psycopg2ã€‚æ‰€ä»¥è®©æˆ‘è¿è¡Œè¿™ä¸ªå•å…ƒï¼Œç°åœ¨è¿™äº›éƒ½å·²å¯¼å…¥ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿåˆ›å»ºå¼•æ“ã€‚
- en: which is basically our database connectionã€‚ And againã€‚ I'm going to assume that
    you've already created this database and have a username and passwordã€‚ So to create
    thisï¼Œ I can say engine is equal toã€‚And use that create engine function that we
    just imported from SQL alchemy and now we need our Postgres connection string
    Now if you don't know how to make Postgres connection strings then you know they
    have this available on the SQL alchemy site as well let me make sure I spelled
    this correctly that is PostgresqL and then we want to pass in the username and
    password for our database now for my case I just made a user of Db user and a
    password of Db pass now another thing here that I'd like to mention is that you
    probably shouldn't put credentials within code like this I'll leave a link in
    the description section below where I show how in Python you should use you something
    like environment variables or a config file to hide this information but for the
    sake of this tutorial I'm just going to put it directly in hereã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šæ˜¯æˆ‘ä»¬çš„æ•°æ®åº“è¿æ¥ã€‚å†æ¬¡å‡è®¾ä½ å·²ç»åˆ›å»ºäº†è¿™ä¸ªæ•°æ®åº“å¹¶æ‹¥æœ‰ç”¨æˆ·åå’Œå¯†ç ã€‚ä¸ºäº†åˆ›å»ºå®ƒï¼Œæˆ‘å¯ä»¥è¯´ engine ç­‰äºï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬åˆšåˆšä» SQLAlchemy
    å¯¼å…¥çš„ create_engine å‡½æ•°ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦æˆ‘ä»¬çš„ Postgres è¿æ¥å­—ç¬¦ä¸²ã€‚å¦‚æœä½ ä¸çŸ¥é“å¦‚ä½•åˆ›å»º Postgres è¿æ¥å­—ç¬¦ä¸²ï¼Œä»–ä»¬åœ¨ SQLAlchemy
    ç½‘ç«™ä¸Šä¹Ÿæœ‰ç›¸å…³ä¿¡æ¯ã€‚è®©æˆ‘ç¡®ä¿æˆ‘æ‹¼å†™æ­£ç¡®ï¼Œåº”è¯¥æ˜¯ PostgresQLï¼Œç„¶åæˆ‘ä»¬è¦ä¼ å…¥æ•°æ®åº“çš„ç”¨æˆ·åå’Œå¯†ç ã€‚åœ¨æˆ‘çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘åªåˆ›å»ºäº†ä¸€ä¸ªåä¸º Db_user
    çš„ç”¨æˆ·å’Œä¸€ä¸ªå¯†ç  Db_passã€‚è¿˜æœ‰ä¸€ç‚¹æˆ‘æƒ³æåˆ°çš„æ˜¯ï¼Œä½ å¯èƒ½ä¸åº”è¯¥åƒè¿™æ ·åœ¨ä»£ç ä¸­æ”¾ç½®å‡­æ®ã€‚æˆ‘ä¼šåœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†ç•™ä¸€ä¸ªé“¾æ¥ï¼Œå±•ç¤ºå¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ¥éšè—è¿™äº›ä¿¡æ¯ï¼Œä½†ä¸ºäº†æœ¬æ•™ç¨‹çš„æ–¹ä¾¿ï¼Œæˆ‘å°±ç›´æ¥æ”¾åœ¨è¿™é‡Œã€‚
- en: but if you're doingã€‚And in production codeï¼Œ I would highly recommend using environment
    variables so thatã€‚ you know you don't expose your username and passwords within
    your code baseã€‚ Okayã€‚ so there we have our username and passwordã€‚ And now the
    database that we want to connect to So this is on local hostã€‚ This is on my local
    machineã€‚ It's running on port 5ï¼Œ4ï¼Œ3ï¼Œ2 and now the name of the databaseã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœä½ åœ¨åšç”Ÿäº§ä»£ç ï¼Œæˆ‘å¼ºçƒˆå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šåœ¨ä»£ç ä¸­æš´éœ²ç”¨æˆ·åå’Œå¯†ç ã€‚å¥½çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ‰äº†æˆ‘ä»¬çš„ç”¨æˆ·åå’Œå¯†ç ã€‚ç°åœ¨æ˜¯æˆ‘ä»¬æƒ³è¦è¿æ¥çš„æ•°æ®åº“ã€‚è¿™æ˜¯åœ¨æœ¬åœ°ä¸»æœºä¸Šã€‚è¿™æ˜¯åœ¨æˆ‘çš„æœ¬åœ°æœºå™¨ä¸Šã€‚å®ƒè¿è¡Œåœ¨
    5432 ç«¯å£ï¼Œç°åœ¨æ˜¯æ•°æ®åº“çš„åç§°ã€‚
- en: Now I have Pg admin open here where I can see my databasesã€‚ and we can see that
    I've just created an empty database here called sample underscore Dbã€‚ So that
    is the database that I'm going to connect to Okay so if I typed everything correctly
    hereã€‚ then I should be able to get a connection to that databaseã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘åœ¨è¿™é‡Œæ‰“å¼€äº† Pg ç®¡ç†å™¨ï¼Œå¯ä»¥çœ‹åˆ°æˆ‘çš„æ•°æ®åº“ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘åˆšåˆšåˆ›å»ºäº†ä¸€ä¸ªåä¸º sample underscore Db çš„ç©ºæ•°æ®åº“ã€‚è¿™å°±æ˜¯æˆ‘å°†è¦è¿æ¥çš„æ•°æ®åº“ã€‚å¥½çš„ï¼Œå¦‚æœæˆ‘åœ¨è¿™é‡Œè¾“å…¥çš„å†…å®¹æ­£ç¡®ï¼Œé‚£ä¹ˆæˆ‘åº”è¯¥èƒ½å¤Ÿè¿æ¥åˆ°è¿™ä¸ªæ•°æ®åº“ã€‚
- en: So now let's try to write our modified database frame to a table in this databaseã€‚
    and this table doesn't need to currently existã€‚ by defaultï¼Œ it will create this
    table for usã€‚ if it does already existã€‚ then we'll need to add another argument
    to handle thatã€‚But we'll see that in just a secondã€‚ So to do thisï¼Œ I can just
    say India underscore Dfã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å°è¯•å°†ä¿®æ”¹åçš„æ•°æ®åº“æ¡†æ¶å†™å…¥è¿™ä¸ªæ•°æ®åº“ä¸­çš„ä¸€ä¸ªè¡¨ã€‚è¿™ä¸ªè¡¨ä¸éœ€è¦å½“å‰å­˜åœ¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä¼šä¸ºæˆ‘ä»¬åˆ›å»ºè¿™ä¸ªè¡¨ã€‚å¦‚æœå®ƒå·²ç»å­˜åœ¨ï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ å¦ä¸€ä¸ªå‚æ•°æ¥å¤„ç†ã€‚ä½†æˆ‘ä»¬é©¬ä¸Šå°±ä¼šçœ‹åˆ°è¿™ä¸€ç‚¹ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘å¯ä»¥ç›´æ¥è¯´
    India underscore Dfã€‚
- en: which is the data frame we want to exportã€‚ Then this is to underscore S Q Oã€‚
    And now the table that we want to write this data tooã€‚ I'm just going to call
    this sample underscore tableã€‚ Nowï¼Œ againï¼Œ this doesn't currently existã€‚ but it
    should create itã€‚ And now we need to pass in our database connection hereã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬æƒ³è¦å¯¼å‡ºçš„æ•°æ®æ¡†ã€‚æ¥ç€æ˜¯ to underscore S Q Oã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦å†™å…¥æ­¤æ•°æ®çš„è¡¨ã€‚æˆ‘å°†å…¶ç§°ä¸º sample underscore tableã€‚ç°åœ¨ï¼Œè¿™ä¸ªè¡¨ç›®å‰ä¸å­˜åœ¨ï¼Œä½†å®ƒåº”è¯¥ä¼šè¢«åˆ›å»ºã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦ä¼ å…¥æˆ‘ä»¬çš„æ•°æ®åº“è¿æ¥ã€‚
- en: I called mine engineã€‚ So let's pass that inã€‚ And if I run thisï¼Œ let's see if
    this worksã€‚Okayã€‚ so we didn't get any errors whenever I read that or whenever
    I wrote thatã€‚ But now let's go back to my PG admin hereã€‚ and let's see if I can
    see this tableã€‚ So firstã€‚ I'm just gonna right click and refreshã€‚ I like to do
    that anytime I've made any changesã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç§°ä¹‹ä¸ºå¼•æ“ã€‚ç°åœ¨è®©æˆ‘ä»¬ä¼ å…¥å®ƒã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆã€‚å¥½çš„ï¼Œæ‰€ä»¥åœ¨æˆ‘è¯»å–æˆ–å†™å…¥æ—¶æ²¡æœ‰å‡ºç°ä»»ä½•é”™è¯¯ã€‚ä½†ç°åœ¨è®©æˆ‘ä»¬å›åˆ°æˆ‘çš„ PG ç®¡ç†å™¨ï¼Œçœ‹çœ‹æˆ‘èƒ½å¦çœ‹åˆ°è¿™ä¸ªè¡¨ã€‚é¦–å…ˆï¼Œæˆ‘åªéœ€å³é”®å•å‡»å¹¶åˆ·æ–°ã€‚æˆ‘å–œæ¬¢åœ¨è¿›è¡Œä»»ä½•æ›´æ”¹æ—¶è¿™æ ·åšã€‚
- en: And we can see there here that we have a sample table down hereã€‚ I'm going to
    right click on that and go to view and edit data and look at all the rows hereã€‚And
    we can see it does look like this workedã€‚ I know that this is probably a little
    difficult to see on my screen hereã€‚ but we have all of our data written here into
    the databaseã€‚ Okayã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢æœ‰ä¸€ä¸ªæ ·æœ¬è¡¨ã€‚æˆ‘å°†å³é”®å•å‡»å®ƒï¼Œé€‰æ‹©æŸ¥çœ‹å’Œç¼–è¾‘æ•°æ®ï¼ŒæŸ¥çœ‹æ‰€æœ‰è¡Œã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ç¡®å®æœ‰æ•ˆã€‚æˆ‘çŸ¥é“åœ¨æˆ‘çš„å±å¹•ä¸Šå¯èƒ½æœ‰ç‚¹éš¾ä»¥çœ‹åˆ°ï¼Œä½†æˆ‘ä»¬çš„æ‰€æœ‰æ•°æ®éƒ½å†™å…¥äº†æ•°æ®åº“ã€‚å¥½çš„ã€‚
- en: so that's good that we were able to get this from pandas into SQLã€‚ But now what
    if we updated our data and wanted to rewrite that data to this databaseã€‚ So let's
    go back to our notebook and see what this would look likeã€‚ Nowã€‚ if I try to run
    this same line again where we export this to SQLã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥èƒ½å¤Ÿå°†æ•°æ®ä» pandas å¯¼å…¥ SQL å¾ˆå¥½ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬æ›´æ–°äº†æ•°æ®å¹¶å¸Œæœ›å°†å…¶é‡å†™åˆ°è¿™ä¸ªæ•°æ®åº“ä¸­æ€ä¹ˆåŠï¼Ÿè®©æˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„ç¬”è®°æœ¬ï¼Œçœ‹çœ‹è¿™å°†æ˜¯ä»€ä¹ˆæ ·å­ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘å°è¯•å†æ¬¡è¿è¡Œè¿™è¡Œï¼Œå°†å…¶å¯¼å‡ºåˆ°
    SQLã€‚
- en: then we're actually going to get it an error because this table already existsã€‚
    If you want to write over a tableï¼Œ then we can add in an additional argumentã€‚
    And the argument that we want to add in is called if underscore exists equalsã€‚
    And now what we want to do if this table already existsã€‚ Nowï¼Œ in my caseã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å®é™…ä¸Šä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œå› ä¸ºè¿™ä¸ªè¡¨å·²ç»å­˜åœ¨ã€‚å¦‚æœä½ æƒ³è¦†ç›–ä¸€ä¸ªè¡¨ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªé¢å¤–çš„å‚æ•°ã€‚æˆ‘ä»¬æƒ³è¦æ·»åŠ çš„å‚æ•°ç§°ä¸º if underscore exists
    ç­‰äºã€‚ç°åœ¨ï¼Œå¦‚æœè¿™ä¸ªè¡¨å·²ç»å­˜åœ¨ï¼Œæˆ‘ä»¬è¯¥æ€ä¹ˆåŠã€‚ç°åœ¨ï¼Œåœ¨æˆ‘çš„æƒ…å†µä¸‹ã€‚
- en: I'm just going to replace that table with our new dataã€‚![](img/77e06e113266309258f73542889b4603_1.png)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æŠŠé‚£ä¸ªè¡¨æ›¿æ¢ä¸ºæˆ‘ä»¬çš„æ–°æ•°æ®ã€‚![](img/77e06e113266309258f73542889b4603_1.png)
- en: But there are also other options as wellã€‚ we could have it throw an error we
    could which is what it does by defaultã€‚ we could also append data to a tableã€‚
    So if you're doing like a daily script where you're analyzing information then
    you can just append that daily data to your existing table but for this exampleã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿˜æœ‰å…¶ä»–é€‰é¡¹ã€‚æˆ‘ä»¬å¯ä»¥è®©å®ƒæŠ›å‡ºä¸€ä¸ªé”™è¯¯ï¼Œè¿™å°±æ˜¯é»˜è®¤æƒ…å†µä¸‹çš„è¡Œä¸ºã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†æ•°æ®è¿½åŠ åˆ°ä¸€ä¸ªè¡¨ä¸­ã€‚å› æ­¤ï¼Œå¦‚æœä½ åœ¨è¿›è¡Œæ¯æ—¥è„šæœ¬ä»¥åˆ†æä¿¡æ¯ï¼Œä½ å¯ä»¥å°†æ¯æ—¥æ•°æ®è¿½åŠ åˆ°ç°æœ‰è¡¨ä¸­ï¼Œä½†å¯¹äºè¿™ä¸ªä¾‹å­æ¥è¯´ã€‚
- en: I'm just going to have this replace the table So let's run this and once this
    is finished processingã€‚ then I will go back to PG admin now againï¼Œ let me come
    up here and refresh this and dig back down into the database and let me close
    this view here and let's see if we still have this data Okay so we can see that
    this worked we were able to rerun that command and it just replaced that data
    that was in that existing table with our new data In this case it was the sameã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åªæ˜¯è¦ç”¨è¿™ä¸ªæ›¿æ¢è¡¨ã€‚ç°åœ¨è¿è¡Œè¿™ä¸ªï¼Œå¤„ç†å®Œæˆåæˆ‘ä¼šå›åˆ°PG adminï¼Œå†æ¬¡è®©æˆ‘ä¸Šå»åˆ·æ–°ä¸€ä¸‹ï¼Œæ·±å…¥æ•°æ®åº“ï¼Œå…³é—­è¿™ä¸ªè§†å›¾ï¼Œçœ‹çœ‹æˆ‘ä»¬æ˜¯å¦ä»ç„¶æœ‰è¿™ä¸ªæ•°æ®ã€‚å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸ªæœ‰æ•ˆï¼Œæˆ‘ä»¬èƒ½å¤Ÿé‡æ–°è¿è¡Œé‚£ä¸ªå‘½ä»¤ï¼Œå¹¶ä¸”ç”¨æˆ‘ä»¬çš„æ–°æ•°æ®æ›¿æ¢äº†åŸæœ‰è¡¨ä¸­çš„æ•°æ®ã€‚åœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼Œå®ƒæ˜¯ç›¸åŒçš„ã€‚
- en: Daï¼Œ but that's how you would do thatã€‚ Okayï¼Œ so lastlyã€‚ now that we've seen how
    to add our data to a databaseã€‚ Now let's see how we can read in this same data
    using SQLã€‚ Now if you skip to this part of the video using the timestamps in the
    description sections belowã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œä½†è¿™å°±æ˜¯ä½ è¦æ€ä¹ˆåšçš„ã€‚å¥½äº†ï¼Œæœ€åï¼Œç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•å°†æ•°æ®æ·»åŠ åˆ°æ•°æ®åº“ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨SQLè¯»å–ç›¸åŒçš„æ•°æ®ã€‚å¦‚æœä½ è·³åˆ°è§†é¢‘çš„è¿™ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨ä¸‹é¢æè¿°éƒ¨åˆ†çš„æ—¶é—´æˆ³ã€‚
- en: Then please go back to when we wrote data to our database and see how I set
    up this database connection here because we're going to reuse that same connection
    to read in our dataã€‚ Okayï¼Œ so this is pretty simple now that we actually have
    this database connection set up to do thisã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè¯·å›å»æŸ¥çœ‹æˆ‘ä»¬å¦‚ä½•å°†æ•°æ®å†™å…¥æ•°æ®åº“ï¼Œå¹¶çœ‹çœ‹æˆ‘åœ¨è¿™é‡Œæ˜¯å¦‚ä½•è®¾ç½®è¿™ä¸ªæ•°æ®åº“è¿æ¥çš„ï¼Œå› ä¸ºæˆ‘ä»¬å°†é‡ç”¨é‚£ä¸ªè¿æ¥æ¥è¯»å–æˆ‘ä»¬çš„æ•°æ®ã€‚å¥½äº†ï¼Œæ‰€ä»¥è¿™ç°åœ¨å¾ˆç®€å•ï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šå·²ç»è®¾ç½®å¥½äº†è¿™ä¸ªæ•°æ®åº“è¿æ¥æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: we can just say I'll call this SQl underscore Dfã€‚ and we will just say PD do
    read underscore SQl and now we want to pass in the table that we're going to read
    fromã€‚ And that was sampleï¼Œ underscore table and now pass in our database connectionã€‚
    My connection hereã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´æˆ‘ä¼šç§°ä¹‹ä¸º`SQL_df`ã€‚ç„¶åæˆ‘ä»¬ä¼šè¯´`pd.read_sql`ï¼Œç°åœ¨æˆ‘ä»¬æƒ³ä¼ å…¥æˆ‘ä»¬è¦è¯»å–çš„è¡¨ã€‚é‚£ä¸ªæ˜¯`sample_table`ï¼Œç°åœ¨ä¼ å…¥æˆ‘ä»¬çš„æ•°æ®åº“è¿æ¥ã€‚æˆ‘è¿™é‡Œçš„è¿æ¥ã€‚
- en: I called engineã€‚And alsoï¼Œ I'm also going to pass in an index column just like
    we did when we read in our CSvã€‚ So I'll say index column is equal toï¼Œ and that
    is going to be this respondent row right here for your data that might be differentã€‚
    So whatever you want to be your index just pass it in there if you want pandas
    to just do a default indexã€‚ then you can just leave this off entirelyã€‚ Okayï¼Œ so
    if I run this then let's look at SQL Df dot head to make sure this workedã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç§°ä¹‹ä¸º`engine`ã€‚è€Œä¸”ï¼Œæˆ‘è¿˜ä¼šä¼ å…¥ä¸€ä¸ªç´¢å¼•åˆ—ï¼Œå°±åƒæˆ‘ä»¬åœ¨è¯»å–CSVæ—¶æ‰€åšçš„é‚£æ ·ã€‚æ‰€ä»¥æˆ‘ä¼šè¯´ç´¢å¼•åˆ—ç­‰äºï¼Œè¿™å°†æ˜¯ä½ æ•°æ®ä¸­çš„è¿™ä¸ª`respondent`è¡Œï¼Œå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚å› æ­¤ï¼Œæ— è®ºä½ æƒ³è¦ä»€ä¹ˆä½œä¸ºç´¢å¼•ï¼Œéƒ½å¯ä»¥ä¼ å…¥ã€‚å¦‚æœä½ æƒ³è®©pandasä½¿ç”¨é»˜è®¤ç´¢å¼•ï¼Œé‚£ä¹ˆä½ å¯ä»¥å®Œå…¨çœç•¥è¿™ä¸ªã€‚å¥½çš„ï¼Œå¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œé‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹`SQL_df.head`ä»¥ç¡®ä¿è¿™ä¸ªæœ‰æ•ˆã€‚
- en: And we can see that that worked wellï¼Œ We still have the same data frame here
    that we started off with where we filter down these countries to just be the results
    from Indiaã€‚ Now there might be instances where you don't want to load in an entire
    table but you want to run a specific SQL query in order to load in our data to
    do thisã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™è¿è¡Œå¾—å¾ˆå¥½ï¼Œæˆ‘ä»¬ä»ç„¶æœ‰ä¸å¼€å§‹æ—¶ç›¸åŒçš„æ•°æ®æ¡†ï¼Œæˆ‘ä»¬å°†è¿™äº›å›½å®¶ç­›é€‰ä¸ºä»…æ¥è‡ªå°åº¦çš„ç»“æœã€‚ç°åœ¨å¯èƒ½æœ‰ä¸€äº›æƒ…å†µï¼Œä½ ä¸æƒ³åŠ è½½æ•´ä¸ªè¡¨ï¼Œè€Œæ˜¯æƒ³è¿è¡Œä¸€ä¸ªç‰¹å®šçš„SQLæŸ¥è¯¢æ¥åŠ è½½æˆ‘ä»¬çš„æ•°æ®ã€‚
- en: we can use the methodï¼Œ readï¼Œ underscore SQLï¼Œ underscore queryã€‚To run a specific
    S Ql queryã€‚ So let me just copy what I did hereã€‚And paste this down hereã€‚ And
    now instead of reading in this entire tableï¼Œ I'm going to actually run a query
    hereã€‚ So I'll do read underscore SQL underscore queryã€‚ And now instead of the
    table name hereã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ–¹æ³•`read_sql_query`æ¥è¿è¡Œä¸€ä¸ªç‰¹å®šçš„SQLæŸ¥è¯¢ã€‚æ‰€ä»¥è®©æˆ‘å¤åˆ¶æˆ‘åœ¨è¿™é‡Œæ‰€åšçš„ï¼Œå¹¶ç²˜è´´åˆ°è¿™é‡Œã€‚ç°åœ¨æˆ‘ä¸æ‰“ç®—è¯»å–æ•´ä¸ªè¡¨ï¼Œè€Œæ˜¯å®é™…ä¸Šè¦åœ¨è¿™é‡Œè¿è¡Œä¸€ä¸ªæŸ¥è¯¢ã€‚æ‰€ä»¥æˆ‘ä¼šåš`read_sql_query`ã€‚ç°åœ¨åœ¨è¿™é‡Œä¸å†æ˜¯è¡¨åã€‚
- en: I'm actually going pass in a SQL queryã€‚ Now I'm just going to load in everything
    hereã€‚ So I'll say select star from sample underscore table and everything else
    here is going to be the sameã€‚ we're still have we still have our database connection
    and we still want our index column to be equal to respondentã€‚ So this is still
    going to grab all the rowsï¼Œ but if you wanted to customize thisã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å®é™…ä¸Šè¦ä¼ å…¥ä¸€ä¸ªSQLæŸ¥è¯¢ã€‚ç°åœ¨æˆ‘åªæ˜¯è¦åœ¨è¿™é‡ŒåŠ è½½æ‰€æœ‰å†…å®¹ã€‚æ‰€ä»¥æˆ‘ä¼šè¯´`select * from sample_table`ï¼Œå…¶ä»–æ‰€æœ‰å†…å®¹éƒ½å°†æ˜¯ç›¸åŒçš„ã€‚æˆ‘ä»¬ä»ç„¶æœ‰æˆ‘ä»¬çš„æ•°æ®åº“è¿æ¥ï¼Œå¹¶ä¸”æˆ‘ä»¬ä»ç„¶å¸Œæœ›ç´¢å¼•åˆ—ç­‰äº`respondent`ã€‚æ‰€ä»¥è¿™ä»ç„¶ä¼šæŠ“å–æ‰€æœ‰è¡Œï¼Œä½†å¦‚æœä½ æƒ³è‡ªå®šä¹‰è¿™ä¸ªã€‚
- en: then you could add in a where clause here to filter this downã€‚ So let me run
    thisã€‚ And now let's look at our SQL data frame hereã€‚ And we can see that that
    worked as wellã€‚ So we load in this data using a SQL query instead of just reading
    in the entire tableã€‚ So that can be especially usefulã€‚You're working with large
    databases where you only want to load in specific data using a queryã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸€ä¸ª where å­å¥æ¥è¿‡æ»¤æ•°æ®ã€‚è®©æˆ‘æ¥è¿è¡Œä¸€ä¸‹ã€‚ç°åœ¨æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹æˆ‘ä»¬çš„ SQL æ•°æ®æ¡†ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¹ŸæˆåŠŸäº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ SQL
    æŸ¥è¯¢åŠ è½½è¿™äº›æ•°æ®ï¼Œè€Œä¸æ˜¯ç®€å•åœ°è¯»å–æ•´ä¸ªè¡¨ã€‚è¿™åœ¨å¤„ç†å¤§æ•°æ®åº“æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œä½ åªæƒ³é€šè¿‡æŸ¥è¯¢åŠ è½½ç‰¹å®šæ•°æ®ã€‚
- en: Okayï¼Œ so we're just about finished up hereã€‚ But let me show you one more tip
    before we wrap this up So you may have seen people load in data using a URL instead
    of a specific file for some of the methods that we've looked at beforeã€‚ and we
    can do thatã€‚ all you need to do is you need to be sure that you're using the correct
    method for whatever form of data is on the URLã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘ä»¬å¿«è¦å®Œæˆäº†ã€‚ä½†åœ¨ç»“æŸä¹‹å‰è®©æˆ‘å†ç»™ä½ ä¸€ä¸ªæç¤ºã€‚ä½ å¯èƒ½è§è¿‡ä¸€äº›äººä½¿ç”¨ URL è€Œä¸æ˜¯ç‰¹å®šæ–‡ä»¶åŠ è½½æ•°æ®ï¼Œè¿™å¯¹äºæˆ‘ä»¬ä¹‹å‰çœ‹è¿‡çš„ä¸€äº›æ–¹æ³•æ˜¯å¯ä»¥çš„ã€‚ä½ åªéœ€ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•æ¥å¤„ç†
    URL ä¸Šçš„æ•°æ®æ ¼å¼ã€‚
- en: Soï¼Œ for exampleï¼Œ in my flask and django seriesï¼Œ I created a Json file of some
    sample posts for the website that werereating in that seriesã€‚ And I have that
    Json file on my Github pageã€‚ Nowï¼Œ if I wanted to bring that into pandasã€‚ then
    I could simply use the read Json method and then pass in that URLã€‚ I wouldn't
    actually have to download that Json first and then pass it in that wayã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨æˆ‘çš„ Flask å’Œ Django ç³»åˆ—ä¸­ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ª Json æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«è¯¥ç³»åˆ—ç½‘ç«™çš„ä¸€äº›ç¤ºä¾‹å¸–å­ã€‚è¿™ä¸ª Json æ–‡ä»¶åœ¨æˆ‘çš„ GitHub
    é¡µé¢ä¸Šã€‚å¦‚æœæˆ‘æƒ³å°†å…¶å¼•å…¥ pandasï¼Œé‚£ä¹ˆæˆ‘å¯ä»¥ç®€å•åœ°ä½¿ç”¨è¯»å– Json æ–¹æ³•ï¼Œå¹¶ä¼ å…¥é‚£ä¸ª URLã€‚å®é™…ä¸Šæˆ‘ä¸éœ€è¦å…ˆä¸‹è½½é‚£ä¸ª Jsonï¼Œç„¶åå†ä»¥é‚£ç§æ–¹å¼ä¼ å…¥ã€‚
- en: So I have this open hereã€‚ if you didn't know on Githubï¼Œ you can look at the
    raw filesã€‚ So we can see that this is a longã€‚URL hereï¼Œ but I will have this code
    posted in the description section below if you'd like to follow alongã€‚ So I'm
    just going to copy this URLã€‚ and this isn't on my file systemã€‚ And now let's see
    if we can just load this inã€‚ So I'm going to call this post underscore Dfã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œæ‰“å¼€è¿™ä¸ªã€‚å¦‚æœä½ ä¸çŸ¥é“ï¼ŒGitHub ä¸Šå¯ä»¥æŸ¥çœ‹åŸå§‹æ–‡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªå¾ˆé•¿çš„ URLï¼Œä½†æˆ‘ä¼šåœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†å‘å¸ƒè¿™æ®µä»£ç ï¼Œæ–¹ä¾¿ä½ è·Ÿè¿›ã€‚æ‰€ä»¥æˆ‘å°†å¤åˆ¶è¿™ä¸ª
    URLã€‚è¿™ä¸åœ¨æˆ‘çš„æ–‡ä»¶ç³»ç»Ÿä¸Šã€‚ç°åœ¨çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥ç›´æ¥åŠ è½½å®ƒã€‚æˆ‘å°†è¿™ä¸ªå‘½åä¸º post_dfã€‚
- en: And I'll set this equal to P D dot read underscore Json since this is Json on
    the URLã€‚ If it was Cvã€‚ then you'd want to use read CSv and so onã€‚ So now I can
    just paste in that URL thereã€‚ And now let's just run that cellã€‚ And we can see
    that we didn't get any errorsã€‚ So let meã€‚Nowã€‚I'll look at the headã€‚Of our data
    frame hereã€‚ And we can see that I do have my sample posts hereã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†å…¶è®¾ç½®ä¸º P D.dot.read_jsonï¼Œå› ä¸ºè¿™æ˜¯ URL ä¸Šçš„ Jsonã€‚å¦‚æœæ˜¯ Cvï¼Œä½ éœ€è¦ä½¿ç”¨ read_csvï¼Œä¾æ­¤ç±»æ¨ã€‚ç°åœ¨æˆ‘å¯ä»¥åœ¨è¿™é‡Œç²˜è´´é‚£ä¸ª
    URLã€‚ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªå•å…ƒæ ¼ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ²¡æœ‰å‡ºç°é”™è¯¯ã€‚ç°åœ¨æˆ‘æ¥æŸ¥çœ‹ä¸€ä¸‹æˆ‘ä»¬æ•°æ®æ¡†çš„å¤´éƒ¨ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ç¡®å®æœ‰æˆ‘çš„ç¤ºä¾‹å¸–å­ã€‚
- en: These are the sample posts that I used on that website seriesã€‚ So depending
    on the data in that URLã€‚ you should be able to use the methods that we've seen
    to load in data from a URL just like we did hereã€‚ Nowï¼Œ before we end hereï¼Œ I would
    like to thank the sponsor of this video and that is brilliantã€‚ I really enjoy
    the tutorials that brilliant provides and would definitely recommend checking
    them outã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯æˆ‘åœ¨é‚£ä¸ªç½‘ç«™ç³»åˆ—ä¸­ä½¿ç”¨çš„ç¤ºä¾‹å¸–å­ã€‚å› æ­¤ï¼Œæ ¹æ®é‚£ä¸ª URL ä¸­çš„æ•°æ®ï¼Œä½ åº”è¯¥èƒ½å¤Ÿä½¿ç”¨æˆ‘ä»¬çœ‹åˆ°çš„æ–¹æ³•ï¼Œä» URL åŠ è½½æ•°æ®ï¼Œå°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„ä¸€æ ·ã€‚åœ¨ç»“æŸä¹‹å‰ï¼Œæˆ‘æƒ³æ„Ÿè°¢æœ¬è§†é¢‘çš„èµåŠ©å•†ï¼Œé‚£å°±æ˜¯
    Brilliantã€‚æˆ‘éå¸¸å–œæ¬¢ Brilliant æä¾›çš„æ•™ç¨‹ï¼Œç»å¯¹æ¨èä½ å»çœ‹çœ‹ã€‚
- en: brilliant is a problem solving website that helps you understand underlying
    concepts by actively working through guided lessonsã€‚ and brilliant would be an
    excellent way to supplement what you learn here with their handson coursesã€‚ They
    have some excellent courses and lessons on data science that do a deep dive on
    how to think about and analyze data correctlyã€‚ So if you're watching my panda
    series because you're getting into the data science fieldã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Brilliant æ˜¯ä¸€ä¸ªé—®é¢˜è§£å†³ç½‘ç«™ï¼Œé€šè¿‡ä¸»åŠ¨å®ŒæˆæŒ‡å¯¼è¯¾ç¨‹æ¥å¸®åŠ©ä½ ç†è§£åŸºç¡€æ¦‚å¿µã€‚Brilliant æ˜¯è¡¥å……ä½ åœ¨è¿™é‡Œå­¦åˆ°çš„å†…å®¹çš„ç»ä½³æ–¹å¼ï¼Œæä¾›åŠ¨æ‰‹è¯¾ç¨‹ã€‚ä»–ä»¬åœ¨æ•°æ®ç§‘å­¦æ–¹é¢æœ‰ä¸€äº›ä¼˜ç§€çš„è¯¾ç¨‹å’Œè¯¾ç¨‹ï¼Œæ·±å…¥æ¢è®¨å¦‚ä½•æ­£ç¡®æ€è€ƒå’Œåˆ†ææ•°æ®ã€‚å› æ­¤ï¼Œå¦‚æœä½ åœ¨çœ‹æˆ‘çš„
    Pandas ç³»åˆ—ï¼Œæ˜¯å› ä¸ºä½ æƒ³è¿›å…¥æ•°æ®ç§‘å­¦é¢†åŸŸã€‚
- en: then I would highly recommend also checking out brilliant and seeing what other
    data science skills you can learnã€‚ They even use Python in their statistics course
    and will quiz you on how to correctlyã€‚ğŸ˜Šã€‚![](img/77e06e113266309258f73542889b4603_3.png)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘å¼ºçƒˆå»ºè®®ä½ ä¹Ÿå»æŸ¥çœ‹ brilliantï¼Œçœ‹çœ‹ä½ å¯ä»¥å­¦ä¹ å“ªäº›å…¶ä»–çš„æ•°æ®ç§‘å­¦æŠ€èƒ½ã€‚ä»–ä»¬åœ¨ç»Ÿè®¡è¯¾ç¨‹ä¸­ç”šè‡³ä½¿ç”¨ Pythonï¼Œå¹¶ä¼šè€ƒä½ å¦‚ä½•æ­£ç¡®ä½¿ç”¨ã€‚ğŸ˜Šã€‚![](img/77e06e113266309258f73542889b4603_3.png)
- en: '![](img/77e06e113266309258f73542889b4603_4.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77e06e113266309258f73542889b4603_4.png)'
- en: '![](img/77e06e113266309258f73542889b4603_5.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77e06e113266309258f73542889b4603_5.png)'
- en: '![](img/77e06e113266309258f73542889b4603_6.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77e06e113266309258f73542889b4603_6.png)'
- en: ize the data within the languageã€‚ Their guided lessons will challenge youã€‚ but
    you also have the ability to get hints or even solutions if you need themã€‚ It's
    really tailored towards understanding the materialã€‚ So to support my channel and
    learn more about brilliantã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¯¥è¯­è¨€ä¸­ç»„ç»‡æ•°æ®ã€‚å®ƒä»¬çš„æŒ‡å¯¼è¯¾ç¨‹ä¼šæŒ‘æˆ˜ä½ ï¼Œä½†ä½ ä¹Ÿå¯ä»¥è·å¾—æç¤ºç”šè‡³è§£å†³æ–¹æ¡ˆï¼Œå¦‚æœä½ éœ€è¦çš„è¯ã€‚å®ƒçœŸçš„å¾ˆæ³¨é‡ç†è§£ææ–™ã€‚æ‰€ä»¥æ”¯æŒæˆ‘çš„é¢‘é“å¹¶äº†è§£æ›´å¤šå…³äº brilliant
    çš„ä¿¡æ¯ã€‚
- en: You can go to brilliant org forms to sign up for free and also the first 200
    people to go to that link will'll get 20% off the annual premium subscription
    and you can find that link in the description section below againã€‚ that's brilliant
    org so I think that's going to do it for this pandas videoã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å» brilliant.org æ³¨å†Œå…è´¹è´¦æˆ·ï¼Œå¹¶ä¸”å‰ 200 ä½è®¿é—®è¯¥é“¾æ¥çš„äººå°†è·å¾—å¹´åº¦é«˜çº§è®¢é˜… 20% çš„æŠ˜æ‰£ï¼Œä½ å¯ä»¥åœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†æ‰¾åˆ°è¿™ä¸ªé“¾æ¥ã€‚å†æ¬¡æé†’ï¼Œé‚£æ˜¯
    brilliant.orgï¼Œæ‰€ä»¥æˆ‘è®¤ä¸ºè¿™æ®µ pandas è§†é¢‘å°±åˆ°è¿™é‡Œã€‚
- en: I hope you feel like you got a good idea for how to read and write data from
    multiple different sourcesã€‚ what we covered here should cover the vast majority
    of file formats that you're going to be seeing and using in the data science fieldã€‚
    Now I'm probably going to take a break from this pandas series after this video
    and do a few one off videos that I've been wanting to coverã€‚ but I know that there
    are a lot of topics in pandas left to cover and I will get around to those more
    advanced topics in future videoã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ èƒ½å¯¹å¦‚ä½•ä»å¤šä¸ªä¸åŒæ¥æºè¯»å–å’Œå†™å…¥æ•°æ®æœ‰ä¸€ä¸ªæ¸…æ™°çš„è®¤è¯†ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œè®¨è®ºçš„å†…å®¹åº”è¯¥æ¶µç›–ä½ åœ¨æ•°æ®ç§‘å­¦é¢†åŸŸä¼šçœ‹åˆ°å’Œä½¿ç”¨çš„å¤§å¤šæ•°æ–‡ä»¶æ ¼å¼ã€‚ç°åœ¨ï¼Œåœ¨è¿™æ®µè§†é¢‘ä¹‹åï¼Œæˆ‘å¯èƒ½ä¼šæš‚æ—¶ä¸­æ–­è¿™ä¸ª
    pandas ç³»åˆ—ï¼Œåˆ¶ä½œå‡ ä¸ªæˆ‘ä¸€ç›´æƒ³è¦è¦†ç›–çš„å•ç‹¬è§†é¢‘ã€‚ä½†æˆ‘çŸ¥é“ pandas è¿˜æœ‰å¾ˆå¤šä¸»é¢˜éœ€è¦æ¢è®¨ï¼Œæˆ‘ä¼šåœ¨æœªæ¥çš„è§†é¢‘ä¸­æ¶‰åŠé‚£äº›æ›´é«˜çº§çš„è¯é¢˜ã€‚
- en: ğŸ˜Šã€‚![](img/77e06e113266309258f73542889b4603_8.png)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šã€‚![](img/77e06e113266309258f73542889b4603_8.png)
- en: '![](img/77e06e113266309258f73542889b4603_9.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77e06e113266309258f73542889b4603_9.png)'
- en: But in the meantimeï¼Œ if you'd like a good source for learning pandasã€‚ then I
    would highly recommend checking out the channel Data schoolã€‚ That's run by Kevin
    Markhamã€‚ and he's done the panda tutorials at Pycon for several years now he didn't
    ask me to suggest his channel or anything like thatã€‚ I just think that he does
    a good jobã€‚ And his channel is actually completely devoted to pandas and data
    scienceã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¸æ­¤åŒæ—¶ï¼Œå¦‚æœä½ æƒ³æ‰¾åˆ°ä¸€ä¸ªå­¦ä¹  pandas çš„å¥½èµ„æºï¼Œé‚£ä¹ˆæˆ‘å¼ºçƒˆå»ºè®®ä½ æŸ¥çœ‹ Data School é¢‘é“ã€‚è¿™ä¸ªé¢‘é“ç”± Kevin Markham è¿è¥ï¼Œä»–å·²ç»åœ¨
    Pycon ä¸Šåšäº†å‡ å¹´çš„ pandas æ•™ç¨‹ï¼Œä»–å¹¶æ²¡æœ‰è®©æˆ‘æ¨èä»–çš„é¢‘é“ï¼Œæˆ‘åªæ˜¯è®¤ä¸ºä»–åšå¾—å¾ˆå¥½ã€‚å…¶å®ä»–çš„é¢‘é“å®Œå…¨è‡´åŠ›äº pandas å’Œæ•°æ®ç§‘å­¦ã€‚
- en: So he's already covered some of the more advanced topics that I do plan to cover
    in future videosã€‚ But if anyone has any questions about what be covered in this
    video then feel free to ask in the comment section below and I'll do my best to
    answer thoseã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–å·²ç»æ¶µç›–äº†ä¸€äº›æˆ‘è®¡åˆ’åœ¨æœªæ¥è§†é¢‘ä¸­è®¨è®ºçš„æ›´é«˜çº§ä¸»é¢˜ã€‚å¦‚æœæœ‰äººå¯¹æœ¬è§†é¢‘ä¸­çš„å†…å®¹æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶åœ¨è¯„è®ºåŒºæé—®ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ã€‚
- en: And if you enjoy these tutorials and would like to support them then there are
    several ways you can do thatã€‚ the easiest ways to simply like the video and give
    it a thumbs up and also it's a huge help to share these videos with anyone who
    you think would find them useful And if you have the means you can contribute
    through Patreon and there's a link to that page in the description section belowã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™äº›æ•™ç¨‹å¹¶æƒ³è¦æ”¯æŒä»–ä»¬ï¼Œè¿˜æœ‰å‡ ç§æ–¹å¼å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯ç»™è§†é¢‘ç‚¹ä¸ªèµï¼Œå¹¶åˆ†äº«è¿™äº›è§†é¢‘ç»™ä»»ä½•ä½ è®¤ä¸ºä¼šè§‰å¾—æœ‰ç”¨çš„äººã€‚å¦‚æœä½ æœ‰èƒ½åŠ›çš„è¯ï¼Œå¯ä»¥é€šè¿‡
    Patreon è´¡çŒ®æ”¯æŒï¼Œç›¸å…³é“¾æ¥åœ¨ä¸‹é¢çš„æè¿°éƒ¨åˆ†ã€‚
- en: be sure to subscribe for future videosã€‚ and thank you all for watchingã€‚![](img/77e06e113266309258f73542889b4603_11.png)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿è®¢é˜…ä»¥è·å–æœªæ¥çš„è§†é¢‘ã€‚æ„Ÿè°¢å¤§å®¶çš„è§‚çœ‹ã€‚![](img/77e06e113266309258f73542889b4603_11.png)
