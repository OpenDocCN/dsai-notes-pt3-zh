- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P6ï¼šL6- Pyspark
    Mlib ç®€ä»‹ - ShowMeAI - BV1sL4y147dP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P6ï¼šL6- Pyspark
    Mlib ç®€ä»‹ - ShowMeAI - BV1sL4y147dP
- en: ã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ã€‚
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_1.png)'
- en: So guysï¼Œ Spark Mlib also has an amazing documentation with respect to various
    examplesã€‚ so here you can go and click on examples and basically check out this
    particular documentationã€‚ You can actually see different different kind of examplesã€‚
    how it is basically doneã€‚ But with respect to Spar Mlã€‚ there are two different
    techniquesã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼ŒSpark Mlibä¹Ÿæœ‰å‡ºè‰²çš„æ–‡æ¡£ï¼Œæ¶µç›–äº†å„ç§ç¤ºä¾‹ã€‚åœ¨è¿™é‡Œä½ å¯ä»¥ç‚¹å‡»ç¤ºä¾‹ï¼ŒåŸºæœ¬ä¸ŠæŸ¥çœ‹è¿™ä»½ç‰¹å®šçš„æ–‡æ¡£ã€‚ä½ å¯ä»¥çœ‹åˆ°ä¸åŒç±»å‹çš„ç¤ºä¾‹ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å®Œæˆçš„ã€‚ä½†å°±Spar
    Mlè€Œè¨€ï¼Œæœ‰ä¸¤ç§ä¸åŒçš„æŠ€æœ¯ã€‚
- en: One is the RdiD techniques and one is the data frame APIsã€‚ Now what we are going
    to do guysã€‚ data frame API is the most recent oneã€‚ you know and it is pretty much
    famously used everywhereã€‚ So we'll be focusing on data frame APIã€‚ That is the
    reason why we learn data frame in Pipar very much nicelyã€‚ So we'll try to learn
    through data frame APIs and we'll try to see the technique how we can basically
    solve a machine learning use caseã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§æ˜¯RdiDæŠ€æœ¯ï¼Œå¦ä¸€ç§æ˜¯æ•°æ®æ¡†APIã€‚ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯ï¼Œæ•°æ®æ¡†APIæ˜¯æœ€è¿‘çš„ï¼Œä½ çŸ¥é“ï¼Œå®ƒåœ¨å„å¤„éƒ½å¾ˆæœ‰åã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºæ•°æ®æ¡†APIã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨Piparä¸­éå¸¸å¥½åœ°å­¦ä¹ æ•°æ®æ¡†çš„åŸå› ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ•°æ®æ¡†APIå­¦ä¹ ï¼Œå¹¶å°è¯•çœ‹çœ‹æˆ‘ä»¬å¦‚ä½•åŸºæœ¬ä¸Šè§£å†³æœºå™¨å­¦ä¹ çš„ç”¨ä¾‹ã€‚
- en: Nowï¼Œ let's go and see one very simple example guysã€‚ and always remember the
    documentation is pretty much amazingly given you can actually check out over here
    and try to read all these thingsã€‚ So let's proceed and let's try to see what are
    things we can actually doã€‚ğŸ˜Šã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œä¼™è®¡ä»¬ã€‚æ°¸è¿œè®°ä½ï¼Œæ–‡æ¡£æä¾›å¾—éå¸¸å¥½ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæ£€æŸ¥å¹¶é˜…è¯»æ‰€æœ‰è¿™äº›å†…å®¹ã€‚è®©æˆ‘ä»¬ç»§ç»­ï¼Œçœ‹çœ‹æˆ‘ä»¬å®é™…ä¸Šå¯ä»¥åšäº›ä»€ä¹ˆã€‚ğŸ˜Š
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_3.png)'
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_4.png)'
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_5.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_5.png)'
- en: In this particular exampleï¼Œ I'm just going to take a simple machine learning
    problem statementã€‚ So let me just open a specific data set for you all and then
    probably willll try to do itã€‚ Okayã€‚ so this is my data setï¼Œ guysï¼Œ I know there
    are not many records over hereã€‚ Okayã€‚ so I have a data set which has like nameï¼Œ
    ageï¼Œ experience and salaryã€‚ğŸ˜Šã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç‰¹å®šçš„ä¾‹å­ä¸­ï¼Œæˆ‘å°†å¤„ç†ä¸€ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ é—®é¢˜é™ˆè¿°ã€‚æ‰€ä»¥è®©æˆ‘ä¸ºä½ ä»¬æ‰“å¼€ä¸€ä¸ªç‰¹å®šçš„æ•°æ®é›†ï¼Œç„¶åå¯èƒ½ä¼šå°è¯•ä¸€ä¸‹ã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯æˆ‘çš„æ•°æ®é›†ï¼Œä¼™è®¡ä»¬ï¼Œæˆ‘çŸ¥é“è¿™é‡Œæ²¡æœ‰å¾ˆå¤šè®°å½•ã€‚å¥½çš„ï¼Œæˆ‘æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å§“åã€å¹´é¾„ã€ç»éªŒå’Œå·¥èµ„ã€‚ğŸ˜Š
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_7.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_7.png)'
- en: And this is just a simple problem statement to just show you that how powerful
    Sp actually is with respect to an MLla libraryã€‚ just to show you a demo from the
    next videoï¼Œ I'll be showing you detailed explanation of the regression algorithms
    how we can basically do the implementation doll theoretical and all guys I have
    already uploadedã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„é—®é¢˜é™ˆè¿°ï¼Œæ—¨åœ¨å‘ä½ å±•ç¤ºSpåœ¨MLlaåº“ä¸­æ˜¯å¤šä¹ˆå¼ºå¤§ã€‚æ¥ä¸‹æ¥çš„è§†é¢‘ä¸­ï¼Œæˆ‘ä¼šè¯¦ç»†è§£é‡Šå›å½’ç®—æ³•ä»¥åŠæˆ‘ä»¬å¦‚ä½•ç†è®ºä¸Šè¿›è¡Œå®ç°ï¼Œæ‰€æœ‰å†…å®¹æˆ‘å·²ç»ä¸Šä¼ äº†ã€‚
- en: you can see over here I'll be doing see after this tutorial5ã€‚ This is basically
    the tutorial 6ã€‚ I'll try to add it after this and thenã€‚ğŸ˜Šã€‚![](img/f720d66f49fae41d670aae65c8eaadee_9.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œï¼Œæˆ‘å°†åœ¨è¿™ä¸ªæ•™ç¨‹ä¹‹åè¿›è¡Œè®²è§£ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯æ•™ç¨‹6ã€‚æˆ‘ä¼šå°½é‡åœ¨ä¹‹åæ·»åŠ å®ƒã€‚ğŸ˜Šï¼[](img/f720d66f49fae41d670aae65c8eaadee_9.png)
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_10.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_10.png)'
- en: Whenever I will be uploading the linear regression algorithm before thatã€‚ please
    make sure that you watch this maths intuitionã€‚ Okayã€‚ I've uploaded this specific
    video Also in the playlistã€‚ So after this tutorial 26 white is seeing tutorial
    26ã€‚ because Ive also added this in my machine learning playishã€‚ So after thisã€‚
    you'll also be able to find out when we'll be discussing about linear regressionã€‚
    how we can implement in depth that video will also get uploadedã€‚ So let's proceedã€‚
    and here is my entire data guysï¼Œ this is my dataã€‚ Now what I have to do is that
    based on age and experienceã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯å½“æˆ‘ä¸Šä¼ çº¿æ€§å›å½’ç®—æ³•ä¹‹å‰ï¼Œè¯·ç¡®ä¿è§‚çœ‹è¿™æ®µæ•°å­¦ç›´è§‰ã€‚å¥½çš„ï¼Œæˆ‘ä¹Ÿåœ¨æ’­æ”¾åˆ—è¡¨ä¸­ä¸Šä¼ äº†è¿™ä¸ªç‰¹å®šçš„è§†é¢‘ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªæ•™ç¨‹26ä¹‹åï¼Œå› ä¸ºæˆ‘ä¹ŸæŠŠå®ƒæ·»åŠ åˆ°äº†æˆ‘çš„æœºå™¨å­¦ä¹ æ’­æ”¾åˆ—è¡¨ä¸­ã€‚åœ¨ä¹‹åï¼Œä½ ä¹Ÿä¼šæ‰¾åˆ°æˆ‘ä»¬è®¨è®ºçº¿æ€§å›å½’æ—¶ï¼Œå¦‚ä½•æ·±å…¥å®ç°ï¼Œè¿™æ®µè§†é¢‘ä¹Ÿä¼šä¸Šä¼ ã€‚æ‰€ä»¥è®©æˆ‘ä»¬ç»§ç»­ã€‚è¿™é‡Œæ˜¯æˆ‘çš„å…¨éƒ¨æ•°æ®ï¼Œä¼™è®¡ä»¬ï¼Œè¿™æ˜¯æˆ‘çš„æ•°æ®ã€‚ç°åœ¨æˆ‘éœ€è¦æ ¹æ®å¹´é¾„å’Œç»éªŒæ¥è¿›è¡Œæ“ä½œã€‚
- en: I need to predict the salaryï¼Œ very simple use caseï¼Œ not not much data3 processingingã€‚
    not much transformationï¼Œ not much standardization and allã€‚ I'm just going to take
    up this to independent featureã€‚ and I will be predicting the salary of this particular
    person based on age and experienceã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘éœ€è¦é¢„æµ‹è–ªæ°´ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç”¨ä¾‹ï¼Œæ•°æ®å¤„ç†ä¸å¤šï¼Œè½¬æ¢ä¸å¤šï¼Œæ ‡å‡†åŒ–ä¹Ÿä¸å¤šã€‚æˆ‘åªä¼šé‡‡ç”¨è¿™ä¸¤ä¸ªç‹¬ç«‹ç‰¹å¾ï¼Œå¹¶æ ¹æ®å¹´é¾„å’Œç»éªŒæ¥é¢„æµ‹è¿™ä¸ªç‰¹å®šäººçš„è–ªæ°´ã€‚
- en: Okay so this is what I'm actually going to doã€‚ğŸ˜Šã€‚![](img/f720d66f49fae41d670aae65c8eaadee_12.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™å°±æ˜¯æˆ‘å°†è¦åšçš„ã€‚ğŸ˜Šï¼[](img/f720d66f49fae41d670aae65c8eaadee_12.png)
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_13.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_13.png)'
- en: So here is a perfect exampleã€‚ Againï¼Œ detailï¼Œ I'll try to show you how to basically
    implement line by lineã€‚ probably from the upcoming videos where I'll be discussing
    about linear regression and allã€‚ And if I go see this particular problemï¼Œ this
    is also a linear regression exampleã€‚ So let's go away first of allï¼Œ as usualï¼Œ
    I will be creating a spark sessionã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªå®Œç¾çš„ä¾‹å­ã€‚å†ä¸€æ¬¡ï¼Œç»†èŠ‚ä¸Šï¼Œæˆ‘å°†å°è¯•é€è¡Œå‘ä½ å±•ç¤ºå¦‚ä½•åŸºæœ¬å®ç°ã€‚å¯èƒ½åœ¨æ¥ä¸‹æ¥çš„å‡ æœŸè§†é¢‘ä¸­ï¼Œæˆ‘å°†è®¨è®ºçº¿æ€§å›å½’ç­‰å†…å®¹ã€‚å¦‚æœæˆ‘æŸ¥çœ‹è¿™ä¸ªç‰¹å®šé—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªçº¿æ€§å›å½’ç¤ºä¾‹ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬å…ˆæ¥ï¼Œå’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘å°†åˆ›å»ºä¸€ä¸ª
    spark ä¼šè¯ã€‚
- en: So I'll use frompar do sql import spa session and then I'm going to use spark
    session do builder dot app name here I'm actually creating a spark session or
    missing let me execute it I think this is pretty much familiarã€‚ you are familiar
    with this then what I'm going to do over here is that we are just going to read
    this particular data set with test1 dot csv header is equal to true and in first
    schema is equal to trueã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†ä½¿ç”¨ frompar do sql import spa sessionï¼Œç„¶åæˆ‘å°†ä½¿ç”¨ spark session do builder.dot
    app nameï¼Œè¿™é‡Œæˆ‘å®é™…ä¸Šæ˜¯åœ¨åˆ›å»ºä¸€ä¸ª spark ä¼šè¯ã€‚è®©æˆ‘æ‰§è¡Œä¸€ä¸‹ï¼Œæˆ‘è§‰å¾—è¿™ä½ åº”è¯¥å¾ˆç†Ÿæ‚‰ã€‚å¦‚æœä½ ç†Ÿæ‚‰è¿™ä¸ªï¼Œé‚£ä¹ˆæˆ‘åœ¨è¿™é‡Œè¦åšçš„æ˜¯ï¼Œæˆ‘ä»¬åªä¼šè¯»å–è¿™ä¸ªç‰¹å®šæ•°æ®é›†ï¼Œä½¿ç”¨
    test1.dot csvï¼Œheader è®¾ç½®ä¸º trueï¼Œfirst schema è®¾ç½®ä¸º trueã€‚
- en: So when I go and see my training do show this are all my features over hereã€‚
    perfectã€‚ I'll be giving you this data Also don't worry Nowã€‚ from this particular
    data if I go and check out my print schema So here you'll be able to see that
    I'm getting this particular information this is my entire print schema over hereã€‚ğŸ˜Šï¼ŒTeachatures
    like nameï¼Œ ageï¼Œ experience and salaryã€‚ Nowï¼Œ if I go and see training dot columnsã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å½“æˆ‘å»æŸ¥çœ‹æˆ‘çš„è®­ç»ƒæ—¶ï¼Œæ‰€æœ‰çš„ç‰¹å¾éƒ½åœ¨è¿™é‡Œã€‚å®Œç¾ã€‚æˆ‘ä¹Ÿä¼šç»™ä½ è¿™äº›æ•°æ®ã€‚åˆ«æ‹…å¿ƒã€‚ç°åœ¨ï¼Œä»è¿™äº›ç‰¹å®šæ•°æ®ä¸­ï¼Œå¦‚æœæˆ‘å»æ£€æŸ¥æˆ‘çš„æ‰“å°æ¨¡å¼ï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°æˆ‘è·å¾—çš„ç‰¹å®šä¿¡æ¯ï¼Œè¿™æ˜¯æˆ‘æ•´ä¸ªæ‰“å°æ¨¡å¼ã€‚ğŸ˜Šç‰¹å¾åŒ…æ‹¬å§“åã€å¹´é¾„ã€ç»éªŒå’Œè–ªæ°´ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘å»æŸ¥çœ‹è®­ç»ƒçš„åˆ—ã€‚
- en: this is my training dot columnsã€‚ Nowï¼Œ always rememberï¼Œ guys in Piparã€‚ we use
    a different funda or mechanism or a kind of data pre processingsing before Cã€‚
    Usually what we do is thatã€‚And by using machine learning algorithms that are available
    in Ecalaã€‚ we basically do a train test splitï¼Œ rightï¼Œ And then we first of allã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘çš„è®­ç»ƒåˆ—ã€‚ç°åœ¨ï¼Œå¤§å®¶ä¸€å®šè¦è®°ä½ï¼Œåœ¨ Pipar ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„åŸç†æˆ–æœºåˆ¶ï¼Œæˆ–ä¸€ç§æ•°æ®é¢„å¤„ç†æ–¹æ³•ï¼Œé€šå¸¸æˆ‘ä»¬æ‰€åšçš„æ˜¯ã€‚é€šè¿‡ä½¿ç”¨åœ¨ Ecala ä¸­å¯ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šè¿›è¡Œè®­ç»ƒæµ‹è¯•åˆ’åˆ†ï¼Œæ²¡é”™ï¼Œç„¶åæˆ‘ä»¬é¦–å…ˆã€‚
- en: divide that into independent featuresï¼Œ dependent featuresï¼Œ rightï¼Œ which we use
    an x and y variableã€‚ and then we do train test split by doing this in in Piparï¼Œ
    we just do some different techniquesã€‚ What we do is that yesï¼Œ we have to basically
    create a way where I can group all my independent featuresã€‚ So probably I'll try
    to create vector asmblerã€‚ we basically say it as a vector assemb C the class Ive
    actually used the vector assembler will make sure that I have all my features
    together grouped like this grouped like this in the form of age and experienceã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å…¶åˆ’åˆ†ä¸ºç‹¬ç«‹ç‰¹å¾å’Œä¾èµ–ç‰¹å¾ï¼Œæ²¡é”™ï¼Œæˆ‘ä»¬ä½¿ç”¨ x å’Œ y å˜é‡ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡åœ¨ Pipar ä¸­è¿›è¡Œè®­ç»ƒæµ‹è¯•åˆ’åˆ†ï¼Œé‡‡ç”¨ä¸åŒçš„æŠ€æœ¯ã€‚æˆ‘ä»¬æ‰€åšçš„æ˜¯ï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šéœ€è¦åˆ›å»ºä¸€ç§æ–¹æ³•ï¼Œå°†æ‰€æœ‰ç‹¬ç«‹ç‰¹å¾åˆ†ç»„åœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œæˆ‘å¯èƒ½ä¼šå°è¯•åˆ›å»ºå‘é‡ç»„è£…å™¨ã€‚æˆ‘ä»¬é€šå¸¸ç§°ä¹‹ä¸ºå‘é‡ç»„è£…å™¨ï¼Œæˆ‘å®é™…ä½¿ç”¨çš„ç±»å°†ç¡®ä¿æˆ‘æ‰€æœ‰ç‰¹å¾éƒ½åƒè¿™æ ·åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå½¢æˆå¹´é¾„å’Œç»éªŒçš„å½¢å¼ã€‚
- en: over here my two main features are age and experienceã€‚ which are my independent
    feature right So itll be grouped like this for every recordã€‚ it will be grouped
    like thisã€‚ Okayï¼Œ for everyï¼Œ it will be grouped like thisã€‚ And then what I will
    be doing is that I will be treating this grouped asã€‚ğŸ˜Šï¼ŒDifferent featureã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘çš„ä¸¤ä¸ªä¸»è¦ç‰¹å¾æ˜¯å¹´é¾„å’Œç»éªŒï¼Œå®ƒä»¬æ˜¯æˆ‘çš„ç‹¬ç«‹ç‰¹å¾ã€‚æ‰€ä»¥å®ƒä¼šåƒè¿™æ ·ä¸ºæ¯æ¡è®°å½•åˆ†ç»„ã€‚å®ƒä¼šåƒè¿™æ ·åˆ†ç»„ã€‚å¥½çš„ï¼Œå¯¹äºæ¯æ¡è®°å½•ï¼Œå®ƒä¼šåƒè¿™æ ·åˆ†ç»„ã€‚ç„¶åæˆ‘å°†æŠŠè¿™ä¸ªåˆ†ç»„è§†ä¸ºã€‚ğŸ˜Šä¸åŒçš„ç‰¹å¾ã€‚
- en: So this will basically be my new featureã€‚Rightï¼Œ and rememberã€‚ this new feature
    is my independent featureã€‚So my independent feature will look like this in a group
    of age comma experienceã€‚ which will be treated as a new featureã€‚ and this is exactly
    my independent featureã€‚ So I have to group this particular wayã€‚ So in order to
    group this what we do is that in Piparã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™åŸºæœ¬ä¸Šå°†æ˜¯æˆ‘çš„æ–°ç‰¹å¾ã€‚å¯¹ï¼Œè®°ä½ï¼Œè¿™ä¸ªæ–°ç‰¹å¾æ˜¯æˆ‘ç‹¬ç«‹çš„ç‰¹å¾ã€‚æ‰€ä»¥æˆ‘çš„ç‹¬ç«‹ç‰¹å¾åœ¨å¹´é¾„å’Œç»éªŒçš„åˆ†ç»„ä¸­çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼Œè¿™å°†è¢«è§†ä¸ºä¸€ä¸ªæ–°ç‰¹å¾ï¼Œè¿™æ­£æ˜¯æˆ‘çš„ç‹¬ç«‹ç‰¹å¾ã€‚å› æ­¤ï¼Œæˆ‘å¿…é¡»ä»¥è¿™ç§ç‰¹å®šæ–¹å¼è¿›è¡Œåˆ†ç»„ã€‚ä¸ºäº†åˆ†ç»„ï¼Œæˆ‘ä»¬åœ¨Piparä¸­è¿™æ ·åšã€‚
- en: we use something called as vector aslerã€‚ So in this vector asmbr is basically
    present in pipar do ml dot featureã€‚ we use this vector asmblerã€‚ we use two thingsã€‚
    one is input columnã€‚ which all column we are basically taking to group itã€‚ So
    two columns one is age and experienceã€‚ right we don't have to take name because
    name is fixed it is a stringã€‚ Yesã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä¸€ç§å«åšå‘é‡ç»„è£…å™¨çš„ä¸œè¥¿ã€‚å› æ­¤ï¼Œè¿™ä¸ªå‘é‡ç»„è£…å™¨åŸºæœ¬ä¸Šåœ¨pipar do ml dot featureä¸­å­˜åœ¨ã€‚æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªå‘é‡ç»„è£…å™¨ï¼Œä½¿ç”¨ä¸¤ä¸ªä¸œè¥¿ã€‚ä¸€ä¸ªæ˜¯è¾“å…¥åˆ—ï¼Œæ‰€æœ‰æˆ‘ä»¬è¦è¿›è¡Œåˆ†ç»„çš„åˆ—ã€‚å› æ­¤ï¼Œä¸¤ä¸ªåˆ—ï¼Œä¸€ä¸ªæ˜¯å¹´é¾„ï¼Œå¦ä¸€ä¸ªæ˜¯ç»éªŒã€‚å¯¹ï¼Œæˆ‘ä»¬ä¸éœ€è¦è€ƒè™‘å§“åï¼Œå› ä¸ºå§“åæ˜¯å›ºå®šçš„ï¼Œå®ƒæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚æ˜¯çš„ã€‚
- en: if category features are thereã€‚ what we doï¼Œ what we need to doã€‚ we will convert
    that into some numerical representation that I'll be showing you when I'm doing
    some inepth implementation in the upcoming videos of linear regression logistic
    regression and dot But here you'll be able to see that I'm going to take input
    columns H comma experience in the form of a list and then I will try to group
    this and create a new columnã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰åˆ†ç±»ç‰¹å¾ï¼Œæˆ‘ä»¬éœ€è¦åšä»€ä¹ˆï¼Œæˆ‘ä»¬å°†æŠŠå®ƒè½¬æ¢ä¸ºä¸€äº›æ•°å€¼è¡¨ç¤ºï¼Œè¿™åœ¨æˆ‘å³å°†å‘å¸ƒçš„çº¿æ€§å›å½’ã€é€»è¾‘å›å½’å’Œå…¶ä»–è§†é¢‘ä¸­çš„æ·±å…¥å®ç°ä¸­ä¼šå‘ä½ å±•ç¤ºã€‚ä½†åœ¨è¿™é‡Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ï¼Œæˆ‘å°†ä»¥åˆ—è¡¨çš„å½¢å¼è·å–è¾“å…¥åˆ—å¹´é¾„ã€ç»éªŒï¼Œç„¶åæˆ‘å°†å°è¯•å¯¹å…¶è¿›è¡Œåˆ†ç»„å¹¶åˆ›å»ºä¸€ä¸ªæ–°åˆ—ã€‚
- en: which is calledã€‚ğŸ˜Šï¼ŒDedependent feature over hereã€‚ right That is what I'm actually
    doingã€‚ So if I go and execute this vector in similarã€‚ So here I'm got my feature
    in similarã€‚ and then I do dot transformã€‚ I do dot transform on my training dataã€‚
    So this is basically my training dataã€‚ When I do this And when I do output dot
    show hereã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œå«åšğŸ˜Šï¼Œä¾èµ–ç‰¹å¾ã€‚è¿™å°±æ˜¯æˆ‘å®é™…ä¸Šåœ¨åšçš„ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘å»æ‰§è¡Œè¿™ä¸ªå‘é‡åœ¨ç›¸ä¼¼çš„åœ°æ–¹ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘å¾—åˆ°äº†æˆ‘çš„ç‰¹å¾åœ¨ç›¸ä¼¼çš„åœ°æ–¹ï¼Œç„¶åæˆ‘è¿›è¡Œç‚¹å˜æ¢ã€‚æˆ‘å¯¹æˆ‘çš„è®­ç»ƒæ•°æ®è¿›è¡Œç‚¹å˜æ¢ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯æˆ‘çš„è®­ç»ƒæ•°æ®ã€‚å½“æˆ‘è¿™æ ·åšæ—¶ï¼Œå½“æˆ‘åœ¨è¿™é‡Œè¾“å‡ºç‚¹æ˜¾ç¤ºã€‚
- en: you'll be able to see I have this all featuresã€‚ and a new feature has been createdã€‚
    which is called as independent featureã€‚ Okayï¼Œ so we have actually created an independent
    featureã€‚ And you can see over here age and experience age and experienceï¼Œ age
    and experienceã€‚ So this is my grouped rows that I've actually got in shortï¼Œ what
    I've doneã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†èƒ½å¤Ÿçœ‹åˆ°æˆ‘æœ‰æ‰€æœ‰è¿™äº›ç‰¹å¾ï¼Œå¹¶ä¸”åˆ›å»ºäº†ä¸€ä¸ªæ–°ç‰¹å¾ï¼Œç§°ä¸ºç‹¬ç«‹ç‰¹å¾ã€‚å¥½çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šåˆ›å»ºäº†ä¸€ä¸ªç‹¬ç«‹ç‰¹å¾ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œçš„å¹´é¾„å’Œç»éªŒï¼Œå¹´é¾„å’Œç»éªŒï¼Œå¹´é¾„å’Œç»éªŒã€‚å› æ­¤ï¼Œè¿™æ˜¯æˆ‘å®é™…å¾—åˆ°çš„åˆ†ç»„è¡Œã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘æ‰€åšçš„ã€‚
- en: I've combined this two column and made it as a single independent featureã€‚ Okayã€‚
    now this will be my input featureã€‚ Okayï¼Œ and this will be my output feature and
    will try to train the modelã€‚ Okayï¼Œ so over here now if I go and see output dot
    columnsã€‚ I have name age experience independent featureã€‚ now what I do out of
    thisã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»å°†è¿™ä¸¤åˆ—ç»“åˆåœ¨ä¸€èµ·ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸€ä¸ªç‹¬ç«‹ç‰¹å¾ã€‚å¥½çš„ï¼Œç°åœ¨è¿™å°†æ˜¯æˆ‘çš„è¾“å…¥ç‰¹å¾ã€‚å¥½çš„ï¼Œè¿™å°†æ˜¯æˆ‘çš„è¾“å‡ºç‰¹å¾ï¼Œæˆ‘ä»¬å°†å°è¯•è®­ç»ƒæ¨¡å‹ã€‚å¥½çš„ï¼Œå› æ­¤åœ¨è¿™é‡Œç°åœ¨å¦‚æœæˆ‘å»æŸ¥çœ‹è¾“å‡ºç‚¹åˆ—ï¼Œæˆ‘æœ‰å§“åã€å¹´é¾„ã€ç»éªŒã€ç‹¬ç«‹ç‰¹å¾ã€‚ç°åœ¨æˆ‘ä»ä¸­åšä»€ä¹ˆã€‚
- en: let's take which all data set I'm actually interested inã€‚ğŸ˜Šï¼ŒSo out of thisã€‚ I
    will just be interested in this two data setï¼Œ rightï¼Œ In features and salaryã€‚ salary
    will be my output featureã€‚ The y variableï¼Œ rightï¼Œ and this will be my input featureã€‚
    So what I'm going to doï¼Œ I am going to select output dot select independent features
    and salaryã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘å®é™…æ„Ÿå…´è¶£çš„æ•°æ®é›†ã€‚ğŸ˜Šå› æ­¤ï¼Œåœ¨è¿™äº›ä¸­ï¼Œæˆ‘åªä¼šå¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†æ„Ÿå…´è¶£ï¼Œå¯¹ï¼Œç‰¹å¾å’Œè–ªæ°´ã€‚è–ªæ°´å°†æ˜¯æˆ‘çš„è¾“å‡ºç‰¹å¾ã€‚yå˜é‡ï¼Œå¯¹ï¼Œè¿™å°†æ˜¯æˆ‘çš„è¾“å…¥ç‰¹å¾ã€‚å› æ­¤ï¼Œæˆ‘è¦åšçš„æ˜¯ï¼Œæˆ‘å°†é€‰æ‹©è¾“å‡ºç‚¹é€‰æ‹©ç‹¬ç«‹ç‰¹å¾å’Œè–ªæ°´ã€‚
- en: And I'm going to put that in my finalizer underscore dataã€‚ That is what I'm
    actually doingã€‚ If I now go and see my dot show hereï¼Œ you will be able to see
    the entire thingã€‚ğŸ˜Šï¼ŒNowï¼Œ this are myã€‚Independent featureã€‚ These are my dependent
    featureã€‚ Nowï¼Œ the first stepï¼Œ what we doã€‚ we do a train test splitï¼Œ like how we
    do it in Scalã€‚ So in order to do a train test splitã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†æŠŠå®ƒæ”¾å…¥æˆ‘çš„æœ€ç»ˆå™¨ä¸‹åˆ’çº¿æ•°æ®ä¸­ã€‚è¿™å°±æ˜¯æˆ‘å®é™…ä¸Šåœ¨åšçš„ã€‚å¦‚æœæˆ‘ç°åœ¨å»æŸ¥çœ‹æˆ‘çš„ç‚¹æ˜¾ç¤ºï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°æ•´ä¸ªå†…å®¹ã€‚ğŸ˜Šç°åœ¨ï¼Œè¿™äº›æ˜¯æˆ‘çš„ç‹¬ç«‹ç‰¹å¾ã€‚è¿™äº›æ˜¯æˆ‘çš„ä¾èµ–ç‰¹å¾ã€‚ç°åœ¨ï¼Œç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬è¦åšä»€ä¹ˆï¼Ÿæˆ‘ä»¬è¿›è¡Œè®­ç»ƒæµ‹è¯•æ‹†åˆ†ï¼Œå°±åƒæˆ‘ä»¬åœ¨Scalä¸­æ‰€åšçš„é‚£æ ·ã€‚ä¸ºäº†è¿›è¡Œè®­ç»ƒæµ‹è¯•æ‹†åˆ†ã€‚
- en: I use a function inside my finalized dataï¼Œ which is called a random splitã€‚ Rememberï¼Œ
    guysã€‚ I'll try to explain you line by line by implementing it when I'm doing a
    bigger project right nowã€‚ since this is just an introduction sessionã€‚ I really
    want to explain you how things are actually doneã€‚ So this is basically my train
    test splitã€‚ So here let me write it down the commentã€‚ğŸ˜Šã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨æˆ‘çš„æœ€ç»ˆæ•°æ®ä¸­ä½¿ç”¨ä¸€ä¸ªå«åšéšæœºæ‹†åˆ†çš„å‡½æ•°ã€‚è®°ä½ï¼Œå¤§å®¶ã€‚æˆ‘ä¼šå°½é‡é€è¡Œè§£é‡Šï¼Œå½“æˆ‘åœ¨åšä¸€ä¸ªæ›´å¤§çš„é¡¹ç›®æ—¶ã€‚ç›®å‰è¿™åªæ˜¯ä¸€ä¸ªä»‹ç»è¯¾ç¨‹ã€‚æˆ‘çœŸçš„æƒ³å‘Šè¯‰ä½ ä»¬äº‹æƒ…æ˜¯å¦‚ä½•å®é™…è¿›è¡Œçš„ã€‚è¿™åŸºæœ¬ä¸Šå°±æ˜¯æˆ‘çš„è®­ç»ƒæµ‹è¯•æ‹†åˆ†ã€‚æ‰€ä»¥è®©æˆ‘åœ¨è¿™é‡Œå†™ä¸‹æ³¨é‡Šã€‚ğŸ˜Š
- en: Rrain test splitã€‚And I will be using the linear regression like how we import
    a class from S scalelon similarly by using Pipar dot ml dot regressionã€‚ import
    linear regressionã€‚ And then I'm doing a random slip of 75 to 25%ã€‚ That basically
    means my training data will be having 75 percentage of the data and my test data
    will be having 25 percentage of the data right Then after that I'll be using this
    linear regression in thisã€‚ you have to important variables that we need to giveã€‚
    One is feature columnsã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæµ‹è¯•æ‹†åˆ†ã€‚æˆ‘å°†ä½¿ç”¨çº¿æ€§å›å½’ï¼Œå°±åƒæˆ‘ä»¬ä» S ç±»åº“å¯¼å…¥ä¸€ä¸ªç±»ä¸€æ ·ï¼Œç±»ä¼¼åœ°é€šè¿‡ä½¿ç”¨ Pipar.ml.regression å¯¼å…¥çº¿æ€§å›å½’ã€‚ç„¶åæˆ‘è¿›è¡Œéšæœºæ‹†åˆ†ï¼Œæ¯”ä¾‹ä¸º
    75% å¯¹ 25%ã€‚è¿™åŸºæœ¬ä¸Šæ„å‘³ç€æˆ‘çš„è®­ç»ƒæ•°æ®å°†å æ•°æ®çš„ 75%ï¼Œè€Œæˆ‘çš„æµ‹è¯•æ•°æ®å°†å  25%ã€‚ç„¶åæˆ‘å°†åœ¨æ­¤ä½¿ç”¨çº¿æ€§å›å½’ã€‚ä½ éœ€è¦æä¾›ä¸¤ä¸ªé‡è¦å˜é‡ã€‚ä¸€ä¸ªæ˜¯ç‰¹å¾åˆ—ã€‚
- en: How many number of feature columns are there that is completely present in this
    independent featureã€‚ So I'm giving it over hereï¼Œ Similarlyly in label columnã€‚
    This is my second feature that I have to giveã€‚ this is my output featureã€‚ So after
    I provide both these things and do a fit on train dataã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¤šå°‘ä¸ªç‰¹å¾åˆ—åœ¨è¿™ä¸ªç‹¬ç«‹ç‰¹å¾ä¸­æ˜¯å®Œå…¨å­˜åœ¨çš„ã€‚æ‰€ä»¥æˆ‘åœ¨è¿™é‡Œç»™å‡ºï¼Œæ ‡ç­¾åˆ—ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™æ˜¯æˆ‘éœ€è¦æä¾›çš„ç¬¬äºŒä¸ªç‰¹å¾ã€‚è¿™æ˜¯æˆ‘çš„è¾“å‡ºç‰¹å¾ã€‚æ‰€ä»¥åœ¨æˆ‘æä¾›è¿™ä¸¤ä¸ªå†…å®¹å¹¶å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ‹Ÿåˆåã€‚
- en: I will be able to find out my coefficientã€‚ These are my coefficientsã€‚ This are
    my interceptsã€‚ And here I can now evaluate and see my outputã€‚ right So by using
    this evaluate functionã€‚ we will be able to see the outputã€‚ and inside this there
    will beã€‚ğŸ˜Šï¼ŒAddction variableã€‚ which will have the outputã€‚ Okayï¼Œ so this is my predictionã€‚
    This is my salaryã€‚ the real valueã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†èƒ½å¤Ÿæ‰¾å‡ºæˆ‘çš„ç³»æ•°ã€‚è¿™äº›æ˜¯æˆ‘çš„ç³»æ•°ã€‚è¿™äº›æ˜¯æˆ‘çš„æˆªè·ã€‚ç°åœ¨æˆ‘å¯ä»¥è¯„ä¼°å¹¶æŸ¥çœ‹æˆ‘çš„è¾“å‡ºã€‚é€šè¿‡ä½¿ç”¨è¿™ä¸ªè¯„ä¼°å‡½æ•°ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿçœ‹åˆ°è¾“å‡ºã€‚åœ¨é‡Œé¢ä¼šæœ‰ã€‚ğŸ˜Šï¼Œé™„åŠ å˜é‡ã€‚å®ƒå°†åŒ…å«è¾“å‡ºã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯æˆ‘çš„é¢„æµ‹ã€‚è¿™æ˜¯æˆ‘çš„è–ªæ°´ï¼ŒçœŸå®å€¼ã€‚
- en: This is my other thingã€‚ Nowï¼Œ if I really want to find out the other important
    parameters of metricsã€‚ let's press tab here you'll be able to see mean absolute
    error underscore result dot mean square errorã€‚ Supp if I do see this particular
    word valueï¼Œ you'll be able to understand that how the model is actually performedã€‚
    So that's just a various very simple exampleï¼Œ guysï¼Œ don't worryï¼Œ I'll be explaining
    in depthã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘çš„å¦ä¸€ä¸ªå†…å®¹ã€‚å¦‚æœæˆ‘çœŸçš„æƒ³æ‰¾å‡ºå…¶ä»–é‡è¦çš„æŒ‡æ ‡å‚æ•°ã€‚è®©æˆ‘ä»¬æŒ‰ä¸€ä¸‹ tab é”®ï¼Œä½ å°†èƒ½çœ‹åˆ°å¹³å‡ç»å¯¹è¯¯å·®_ç»“æœ.å‡æ–¹è¯¯å·®ã€‚æ‰€ä»¥å¦‚æœæˆ‘çœ‹åˆ°è¿™ä¸ªç‰¹å®šçš„è¯å€¼ï¼Œä½ å°†èƒ½å¤Ÿç†è§£æ¨¡å‹æ˜¯å¦‚ä½•å®é™…è¡¨ç°çš„ã€‚è¿™åªæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œå¤§å®¶ï¼Œåˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šæ·±å…¥è§£é‡Šã€‚
- en: probably in the upcoming videos when we'll be starting from linear regressionã€‚
    nowï¼Œ rememberã€‚ the next video is about linear regression implementation in depth
    implementation right the theoretical part you can see over hereã€‚ I've already
    added the videoã€‚ Okayï¼Œ so I hope you like this particular videoã€‚ please do subscribe
    the channel if you as youll in the next video have a great Thank you mobileã€‚ğŸ˜Šã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½åœ¨æ¥ä¸‹æ¥çš„å‡ æœŸè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†ä»çº¿æ€§å›å½’å¼€å§‹ã€‚ç°åœ¨ï¼Œè¯·è®°ä½ï¼Œä¸‹ä¸€ä¸ªè§†é¢‘æ˜¯å…³äºçº¿æ€§å›å½’çš„æ·±å…¥å®ç°ï¼Œç†è®ºéƒ¨åˆ†ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ã€‚æˆ‘å·²ç»æ·»åŠ äº†è§†é¢‘ã€‚å¥½çš„ï¼Œæˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªè§†é¢‘ã€‚å¦‚æœä½ å–œæ¬¢ï¼Œè¯·è®¢é˜…é¢‘é“ï¼Œæˆ‘ä»¬åœ¨ä¸‹ä¸ªè§†é¢‘è§ã€‚ç¥ä½ æœ‰ä¸ªç¾å¥½çš„ä¸€å¤©ã€‚ğŸ˜Š
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_15.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_15.png)'
- en: '![](img/f720d66f49fae41d670aae65c8eaadee_16.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f720d66f49fae41d670aae65c8eaadee_16.png)'
