- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P5ï¼šL5- å·ç§¯ç¥ç»ç½‘ç»œ(CNN)
    - ShowMeAI - BV1TT4y1m7Xg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P5ï¼šL5- å·ç§¯ç¥ç»ç½‘ç»œ(CNN)
    - ShowMeAI - BV1TT4y1m7Xg
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02af098f9ad70406fc18680eac4bd94_0.png)'
- en: ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ welcome to another Tensorflow tutorialã€‚ Todayã€‚ we are going to
    implement our first convolutional neural netã€‚ So a convolutional neural net looks
    similar to our feet forward neural net from lesson number 3ã€‚ The main difference
    now is that we use convolutional filters instead of just dense layersã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°å¦ä¸€ä¸ª Tensorflow æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†å®ç°æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œã€‚æ‰€ä»¥å·ç§¯ç¥ç»ç½‘ç»œçœ‹èµ·æ¥ç±»ä¼¼äºç¬¬ä¸‰è¯¾ä¸­çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚ä¸»è¦åŒºåˆ«åœ¨äºæˆ‘ä»¬ä½¿ç”¨å·ç§¯æ»¤æ³¢å™¨ï¼Œè€Œä¸ä»…ä»…æ˜¯å¯†é›†å±‚ã€‚
- en: So here's a typical architecture of a confnetã€‚ We have our input imageã€‚ and
    then we apply different convolutional layers with activationation functions like
    hereï¼Œ the reloã€‚ And we also apply pooling layers to reduce the size of our imageã€‚
    And then at the endã€‚ we do classificationã€‚ And this means that we use a fully
    connected layer at the endã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªå…¸å‹çš„å·ç§¯ç½‘ç»œæ¶æ„ã€‚æˆ‘ä»¬æœ‰è¾“å…¥å›¾åƒï¼Œç„¶ååº”ç”¨ä¸åŒçš„å·ç§¯å±‚å’Œæ¿€æ´»å‡½æ•°ï¼Œæ¯”å¦‚è¿™é‡Œçš„ ReLUã€‚æˆ‘ä»¬è¿˜åº”ç”¨æ± åŒ–å±‚æ¥å‡å°‘å›¾åƒçš„å¤§å°ã€‚æœ€åï¼Œæˆ‘ä»¬è¿›è¡Œåˆ†ç±»ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨æœ€åä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚
- en: Also known as the dense layerã€‚ with an output for each class that we haveã€‚ So
    our convolutional layer uses convolutional filters and the filter slides over
    the image and thenã€‚ğŸ˜Šï¼ŒCalculates a new value and writes it into the output imageã€‚
    so I will not go into detail hereã€‚ but I will provide some links if you want to
    learn more about the theory hereã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè¢«ç§°ä¸ºå¯†é›†å±‚ï¼Œä¸ºæˆ‘ä»¬æ¯ä¸ªç±»åˆ«æä¾›è¾“å‡ºã€‚æ‰€ä»¥æˆ‘ä»¬çš„å·ç§¯å±‚ä½¿ç”¨å·ç§¯æ»¤æ³¢å™¨ï¼Œæ»¤æ³¢å™¨æ»‘åŠ¨åœ¨å›¾åƒä¸Šï¼Œç„¶åğŸ˜Šï¼Œè®¡ç®—ä¸€ä¸ªæ–°å€¼å¹¶å°†å…¶å†™å…¥è¾“å‡ºå›¾åƒã€‚æˆ‘è¿™é‡Œä¸å†è¯¦ç»†è¯´æ˜ï¼Œä½†æˆ‘ä¼šæä¾›ä¸€äº›é“¾æ¥ï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šç†è®ºã€‚
- en: So here's another image of a convolutional filterã€‚ So at first we put it at
    the rat position and then we calculate the convolution and write the output in
    here and then we slide it to the next positionã€‚ So the green one and do the same
    and then we slide it to the blue position and do the sameã€‚ And this is how we
    calculate the convolutionsã€‚ And then we also apply max poolingã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦ä¸€ä¸ªå·ç§¯æ»¤æ³¢å™¨çš„å›¾åƒã€‚ä¸€å¼€å§‹æˆ‘ä»¬å°†å…¶æ”¾åœ¨é¼ æ ‡ä½ç½®ï¼Œç„¶åè®¡ç®—å·ç§¯å¹¶å°†è¾“å‡ºå†™å…¥è¿™é‡Œï¼Œç„¶åæˆ‘ä»¬æ»‘åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®ã€‚æ‰€ä»¥åœ¨ç»¿è‰²çš„ä½ç½®è¿›è¡Œç›¸åŒæ“ä½œï¼Œç„¶åæ»‘åŠ¨åˆ°è“è‰²ä½ç½®å†åšä¸€æ¬¡ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•è®¡ç®—å·ç§¯ã€‚æ¥ç€æˆ‘ä»¬è¿˜åº”ç”¨æœ€å¤§æ± åŒ–ã€‚
- en: which is also just a filterï¼Œ for exampleï¼Œ hereï¼Œ a two by two filter and we put
    it at the first position and calculate just the maximum value like hereã€‚ the 20
    and write it to the outputã€‚ and then we slide it to the next position and do the
    same and so onã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ˜¯ä¸€ä¸ªæ»¤æ³¢å™¨ï¼Œä¾‹å¦‚ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ª 2x2 çš„æ»¤æ³¢å™¨ï¼Œæˆ‘ä»¬å°†å…¶æ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®å¹¶è®¡ç®—æœ€å¤§å€¼ï¼Œæ¯”å¦‚è¿™é‡Œçš„ 20ï¼Œç„¶åå†™å…¥è¾“å‡ºã€‚æ¥ç€æˆ‘ä»¬æ»‘åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®å¹¶è¿›è¡Œç›¸åŒæ“ä½œï¼Œä¾æ­¤ç±»æ¨ã€‚
- en: So this reducesã€‚The size of our imageã€‚ And this is all the concepts that we're
    going to applyã€‚ So here again is an image of the architecture that we are going
    to implementã€‚ So we have the input image then we apply convolution plus the reo
    activationation function plus poolingã€‚ then we do the same thing againã€‚ And at
    the end we do we flatten the image to squeeze it into one dimension and use a
    fully connected dense layer with the softmax activationation function and then
    do the classificationã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†å‡å°‘æˆ‘ä»¬çš„å›¾åƒå¤§å°ã€‚è¿™äº›å°±æ˜¯æˆ‘ä»¬è¦åº”ç”¨çš„æ‰€æœ‰æ¦‚å¿µã€‚è¿™æ˜¯æˆ‘ä»¬å°†è¦å®ç°çš„æ¶æ„å›¾åƒã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰è¾“å…¥å›¾åƒï¼Œç„¶ååº”ç”¨å·ç§¯åŠ ä¸Š ReLU æ¿€æ´»å‡½æ•°å†åŠ ä¸Šæ± åŒ–ã€‚ç„¶åå†é‡å¤ä¸€æ¬¡ã€‚æœ€åæˆ‘ä»¬å°†å›¾åƒå±•å¹³ï¼Œå‹ç¼©æˆä¸€ç»´ï¼Œå¹¶ä½¿ç”¨å…¨è¿æ¥çš„å¯†é›†å±‚å’Œ
    Softmax æ¿€æ´»å‡½æ•°ï¼Œç„¶åè¿›è¡Œåˆ†ç±»ã€‚
- en: So this step at the end is the exact same that we used in tutorial number3ã€‚
    So I recommend that you watch this one firstã€‚ if you haven't already And now we
    can jump to the codeã€‚ So in this exampleï¼Œ we are going to use the scipher 10 dataset
    setã€‚ This is a image data set of 60032 by 32 color images and we have0ã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æœ€åè¿™ä¸€æ­¥å’Œæˆ‘ä»¬åœ¨ç¬¬ä¸‰è¯¾ä¸­ä½¿ç”¨çš„å®Œå…¨ç›¸åŒã€‚å› æ­¤æˆ‘å»ºè®®ä½ å…ˆè§‚çœ‹è¿™ä¸€è¯¾ï¼Œå¦‚æœä½ è¿˜æ²¡æœ‰çš„è¯ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›å…¥ä»£ç ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ CIFAR-10
    æ•°æ®é›†ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å« 60000 å¼  32x32 çš„å½©è‰²å›¾åƒã€‚
- en: 1 different classes that we see hereï¼Œ for exampleï¼Œ airplaneï¼Œ a carï¼Œ bird cat
    and so onã€‚ And this is what were going to classifyã€‚ So now let's jump to the codeã€‚
    Alrightã€‚ so here I've already written some codeã€‚ So this is similar to the code
    and tutorial number 3 So againã€‚ we import the things we need like Tensorflow and
    ks and layersã€‚ Then I import matpllipã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçœ‹åˆ°çš„ä¸åŒç±»åˆ«ï¼Œæ¯”å¦‚é£æœºã€æ±½è½¦ã€é¸Ÿã€çŒ«ç­‰ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦åˆ†ç±»çš„å†…å®¹ã€‚é‚£ä¹ˆç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç ã€‚å¥½çš„ï¼Œæˆ‘è¿™é‡Œå·²ç»å†™äº†ä¸€äº›ä»£ç ã€‚è¿™å’Œç¬¬ä¸‰è¯¾ä¸­çš„ä»£ç ç±»ä¼¼ã€‚æ‰€ä»¥æˆ‘ä»¬å†æ¬¡å¯¼å…¥éœ€è¦çš„ä¸œè¥¿ï¼Œæ¯”å¦‚
    Tensorflowã€Keras å’Œå±‚ã€‚ç„¶åæˆ‘å¯¼å…¥ matplotlibã€‚
- en: Then we use the ci for 10 data setï¼Œ which is integrated in Kara data sets and
    we can split this into training images and test imagesã€‚ And now if you print the
    shapeï¼Œ we seeï¼Œ for exampleã€‚ that this is the training images has 50000 samples
    and each image has the site 32 by 32 by 3 because it has three color channelsã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä½¿ç”¨ciè¿›è¡Œ10ä¸ªæ•°æ®é›†ï¼Œå®ƒé›†æˆåœ¨Karaæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†æˆè®­ç»ƒå›¾åƒå’Œæµ‹è¯•å›¾åƒã€‚ç°åœ¨å¦‚æœä½ æ‰“å°å½¢çŠ¶ï¼Œæˆ‘ä»¬çœ‹åˆ°ï¼Œä¾‹å¦‚ï¼Œè®­ç»ƒå›¾åƒæœ‰50000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªå›¾åƒçš„å°ºå¯¸æ˜¯32x32x3ï¼Œå› ä¸ºå®ƒæœ‰ä¸‰ä¸ªé¢œè‰²é€šé“ã€‚
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_2.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02af098f9ad70406fc18680eac4bd94_2.png)'
- en: Then we normalize our dataã€‚ So we want it to be in the range from 0 to 1ã€‚ Then
    here I have the different class namesã€‚ and I written I've written a helper function
    to show you some example imagesã€‚ So let's run it up until hereã€‚ So now if I say
    Pythonã€‚ and then the name of this fileã€‚ Then we see some example images hereã€‚
    and the images are very blur because our dimensions are very smallã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å½’ä¸€åŒ–æ•°æ®ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒåœ¨0åˆ°1çš„èŒƒå›´å†…ã€‚ç„¶åè¿™é‡Œæˆ‘æœ‰ä¸åŒçš„ç±»åã€‚æˆ‘å†™äº†ä¸€ä¸ªå¸®åŠ©å‡½æ•°æ¥å±•ç¤ºä¸€äº›ç¤ºä¾‹å›¾åƒã€‚æ‰€ä»¥æˆ‘ä»¬è¿è¡Œåˆ°è¿™é‡Œã€‚ç°åœ¨å¦‚æœæˆ‘è¯´Pythonï¼Œç„¶åè¿™ä¸ªæ–‡ä»¶çš„åç§°ã€‚æˆ‘ä»¬å°±ä¼šçœ‹åˆ°ä¸€äº›ç¤ºä¾‹å›¾åƒï¼Œè¿™äº›å›¾åƒéå¸¸æ¨¡ç³Šï¼Œå› ä¸ºæˆ‘ä»¬çš„ç»´åº¦éå¸¸å°ã€‚
- en: but that's okayã€‚ So now let's stop thisã€‚ and now I can remove this code for
    plottingã€‚ So we don't need this anymoreã€‚![](img/f02af098f9ad70406fc18680eac4bd94_4.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ²¡å…³ç³»ã€‚ç°åœ¨è®©æˆ‘ä»¬åœæ­¢è¿™ä¸ªã€‚ç°åœ¨æˆ‘å¯ä»¥åˆ é™¤è¿™ä¸ªç»˜å›¾ä»£ç ã€‚æˆ‘ä»¬ä¸å†éœ€è¦è¿™ä¸ªäº†ã€‚![](img/f02af098f9ad70406fc18680eac4bd94_4.png)
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02af098f9ad70406fc18680eac4bd94_5.png)'
- en: And now here we define our Kaa sequential model like the last timeã€‚ And now
    this is what we have to implementã€‚ And then the code after that is exactly the
    same as in tutorial number 3ã€‚ So againï¼Œ we define our loss and the optimizerã€‚
    So here we want the sparse categorical cross entropy and say from logics equals
    trueã€‚ So that it applies the softmã€‚ So this is important hereã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„Kaaé¡ºåºæ¨¡å‹ï¼Œå°±åƒä¸Šæ¬¡ä¸€æ ·ã€‚è¿™æ˜¯æˆ‘ä»¬éœ€è¦å®ç°çš„ã€‚æ¥ä¸‹æ¥çš„ä»£ç ä¸æ•™ç¨‹3ä¸­çš„å®Œå…¨ç›¸åŒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡å®šä¹‰æˆ‘ä»¬çš„æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚è¿™é‡Œæˆ‘ä»¬æƒ³è¦ç¨€ç–åˆ†ç±»äº¤å‰ç†µï¼Œå¹¶ä¸”è¯´é€»è¾‘ç­‰äºçœŸã€‚æ‰€ä»¥å®ƒåº”ç”¨softmã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ã€‚
- en: Then we define some metrics that we want to trackã€‚ And then we have to call
    model compileã€‚ and after thatï¼Œ we start our training by simply calling model dot
    fit with our training images and training labelsã€‚ And then we can evaluate it
    by calling model dot evaluate with the test images and the test labelsã€‚ So yeahï¼Œ
    that's the whole codeã€‚ And now the only thing left to do here is to define our
    modelã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å®šä¹‰ä¸€äº›æƒ³è¦è·Ÿè¸ªçš„æŒ‡æ ‡ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»è°ƒç”¨model.compileï¼Œä¹‹åé€šè¿‡ç®€å•è°ƒç”¨model.fitä¸æˆ‘ä»¬çš„è®­ç»ƒå›¾åƒå’Œè®­ç»ƒæ ‡ç­¾æ¥å¼€å§‹è®­ç»ƒã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨model.evaluateä¸æµ‹è¯•å›¾åƒå’Œæµ‹è¯•æ ‡ç­¾æ¥è¯„ä¼°å®ƒã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™å°±æ˜¯æ•´ä¸ªä»£ç ã€‚ç°åœ¨è¿™é‡Œå”¯ä¸€å‰©ä¸‹çš„å°±æ˜¯å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: So now let's have a look againã€‚ So againï¼Œ we want to applyã€‚![](img/f02af098f9ad70406fc18680eac4bd94_7.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬å†çœ‹çœ‹ã€‚æ‰€ä»¥æˆ‘ä»¬å†æ¬¡æƒ³åº”ç”¨ã€‚![](img/f02af098f9ad70406fc18680eac4bd94_7.png)
- en: Convolutional layers with an activation function and a pooling layerã€‚ And then
    the same thing againã€‚ And at the endï¼Œ we want to flatten it and apply the fully
    connected layerã€‚ So let's do thisã€‚ So firstï¼Œ let's add a convolution layerã€‚ So
    we can do this by saying model dot atã€‚ And then we use a layer from ks dot layersã€‚
    And then this is the con2D layerã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰æ¿€æ´»å‡½æ•°å’Œæ± åŒ–å±‚çš„å·ç§¯å±‚ã€‚ç„¶åå†æ¥ä¸€æ¬¡ã€‚æœ€åï¼Œæˆ‘ä»¬å¸Œæœ›å±•å¹³å¹¶åº”ç”¨å…¨è¿æ¥å±‚ã€‚æ‰€ä»¥è®©æˆ‘ä»¬è¿™æ ·åšã€‚é¦–å…ˆï¼Œæ·»åŠ ä¸€ä¸ªå·ç§¯å±‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´model.atæ¥å®Œæˆã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨ks.layersä¸­çš„ä¸€ä¸ªå±‚ã€‚è¿™å°±æ˜¯con2Då±‚ã€‚
- en: So a 2D convolutional layerã€‚ And now firstï¼Œ we have to specify the filtersã€‚
    So this is the number of output filters after this convolutionã€‚ So here we say
    32ã€‚ Then we have to specify the kernel sizeã€‚ So here let's use a filter kernel
    of size 3 by3ã€‚ Then I also write the strides andã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šè¿‡æ»¤å™¨ã€‚è¿™æ˜¯å·ç§¯åçš„è¾“å‡ºè¿‡æ»¤å™¨æ•°é‡ã€‚è¿™é‡Œæˆ‘ä»¬è¯´æ˜¯32ã€‚ç„¶åæˆ‘ä»¬éœ€è¦æŒ‡å®šå†…æ ¸å¤§å°ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨3x3çš„è¿‡æ»¤å™¨å†…æ ¸ã€‚æ¥ç€ï¼Œæˆ‘è¿˜å†™äº†æ­¥å¹…ã€‚
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_9.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02af098f9ad70406fc18680eac4bd94_9.png)'
- en: Heading here for youã€‚ So strides equalsï¼Œ let's say 1 and oneã€‚ This is just the
    defaultã€‚ How much we want to slideï¼Œ how far we want to slide it over the imageã€‚And
    padding equals valetã€‚ So you have the option to say validale or sameã€‚ These are
    basically two different rulesã€‚ How the padding is appliedã€‚ So let's say valid
    hereã€‚ And thenï¼Œ as I saidã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æ ‡é¢˜ã€‚æ‰€ä»¥æ­¥å¹…ç­‰äº1å’Œ1ã€‚è¿™åªæ˜¯é»˜è®¤å€¼ã€‚æˆ‘ä»¬å¸Œæœ›æ»‘åŠ¨å¤šå°‘ï¼Œä»¥åŠåœ¨å›¾åƒä¸Šæ»‘åŠ¨å¤šè¿œã€‚å¡«å……ç­‰äºæœ‰æ•ˆã€‚æ‰€ä»¥ä½ å¯ä»¥é€‰æ‹©æœ‰æ•ˆæˆ–ç›¸åŒã€‚è¿™åŸºæœ¬ä¸Šæ˜¯ä¸¤ç§ä¸åŒçš„è§„åˆ™ã€‚å¡«å……æ˜¯å¦‚ä½•åº”ç”¨çš„ã€‚æˆ‘ä»¬è¿™é‡Œè¯´æœ‰æ•ˆã€‚ç„¶åï¼Œå¦‚æˆ‘æ‰€è¯´ã€‚
- en: we want to use an activationationã€‚ So we say activationation equals Reluã€‚ And
    for our first layerã€‚ we also specify the input shapeã€‚ And this is 32 by 32 by
    3ã€‚And now we have thisã€‚ So nowï¼Œ after thatã€‚ we want to apply a pooling layerã€‚
    So we say model dot atã€‚ And then againï¼Œ layers dot maxsã€‚Poulling 2Dã€‚ And then
    here also we can define the pool sizeã€‚ So hereã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¦ä½¿ç”¨æ¿€æ´»å‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾ç½®`activation equals Relu`ã€‚å¯¹äºæˆ‘ä»¬çš„ç¬¬ä¸€å±‚ï¼Œæˆ‘ä»¬è¿˜æŒ‡å®šè¾“å…¥å½¢çŠ¶ã€‚è¿™ä¸ªæ˜¯32x32x3ã€‚ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªã€‚ç„¶åï¼Œåœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬æƒ³è¦åº”ç”¨ä¸€ä¸ªæ± åŒ–å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´`model.add`ã€‚ç„¶åå†æ¬¡ï¼Œ`layers.maxPooling2D`ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰æ± å¤§å°ã€‚æ‰€ä»¥åœ¨è¿™é‡Œã€‚
- en: let's just use two by two as defaultã€‚ or I can again write it for you so that
    it's clearer so we use a two by2 max pooling layer And then we do the same thing
    againã€‚ So let's copy and paste thisã€‚ And here we remove the input shape so we
    don't need this anymoreã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é»˜è®¤ä½¿ç”¨2x2ï¼Œæˆ–è€…æˆ‘å¯ä»¥å†æ¬¡ä¸ºä½ å†™å‡ºæ¥ï¼Œè®©å®ƒæ›´æ¸…æ™°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª2x2çš„æœ€å¤§æ± åŒ–å±‚ï¼Œç„¶åå†åšä¸€æ¬¡ã€‚æ‰€ä»¥æˆ‘ä»¬å¤åˆ¶å¹¶ç²˜è´´è¿™ä¸ªã€‚è¿™é‡Œæˆ‘ä»¬ç§»é™¤è¾“å…¥å½¢çŠ¶ï¼Œå› æ­¤æˆ‘ä»¬ä¸å†éœ€è¦è¿™ä¸ªã€‚
- en: And let's also remove this because this is just the defaultã€‚ And then here I
    want to show you that you can specify a value for each dimensionã€‚ or you can just
    specify a single integer valueã€‚ And then it's using this for each dimensionã€‚ So
    this is the same as thisã€‚And then againï¼Œ a another max pooling layerã€‚And now we
    want toã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä¹Ÿå»æ‰è¿™ä¸ªï¼Œå› ä¸ºè¿™åªæ˜¯é»˜è®¤è®¾ç½®ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘æƒ³å‘Šè¯‰ä½ ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªç»´åº¦æŒ‡å®šä¸€ä¸ªå€¼ï¼Œæˆ–è€…å¯ä»¥åªæŒ‡å®šä¸€ä¸ªæ•´æ•°å€¼ã€‚è¿™æ ·å¯¹äºæ¯ä¸ªç»´åº¦éƒ½æ˜¯ä¸€æ ·çš„ã€‚å†æ¥ä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚ã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦ã€‚
- en: let's have a look againã€‚ Now we want to flatten it and then apply the fully
    connected layerã€‚ So now we add a model dot add and then layers dot flattenã€‚![](img/f02af098f9ad70406fc18680eac4bd94_11.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å†çœ‹çœ‹ã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦æ‰å¹³åŒ–ï¼Œç„¶ååº”ç”¨å…¨è¿æ¥å±‚ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æ·»åŠ `model.add`ï¼Œç„¶å`layers.flatten`ã€‚![](img/f02af098f9ad70406fc18680eac4bd94_11.png)
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_12.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02af098f9ad70406fc18680eac4bd94_12.png)'
- en: So we squeeze it into one dimensionï¼Œ and then we say model dot addã€‚ And we want
    to add a dense layerã€‚ So layers dotã€‚Denseï¼Œ and then here let's use a hidden size
    of 64ã€‚ and also an activationã€‚ And here againï¼Œ we use reluã€‚ And then let's do
    the same thing at the endã€‚ So model dot at a dense layerã€‚ And now we have to specify
    10 output classesã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†å…¶æŒ¤å‹æˆä¸€ç»´ï¼Œç„¶åè¯´`model.add`ã€‚æˆ‘ä»¬æƒ³è¦æ·»åŠ ä¸€ä¸ªå¯†é›†å±‚ã€‚æ‰€ä»¥`layers.Dense`ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬è®¾ç½®éšè—å±‚å¤§å°ä¸º64ï¼ŒåŒæ—¶ä¹Ÿæœ‰ä¸€ä¸ªæ¿€æ´»å‡½æ•°ã€‚ç„¶ååœ¨æœ€åæˆ‘ä»¬å†åšä¸€æ¬¡ã€‚æ‰€ä»¥`model.add`ä¸€ä¸ªå¯†é›†å±‚ã€‚ç°åœ¨æˆ‘ä»¬å¿…é¡»æŒ‡å®š10ä¸ªè¾“å‡ºç±»ã€‚
- en: And here we don't want an activation function because we say from Los equals
    true for our lossã€‚And now this is all that we needã€‚ So this is our first convolutional
    neural networkã€‚ And nowã€‚ for exampleï¼Œ we can call print and then print the model
    dot summaryã€‚ And nowã€‚So for nowã€‚ let's stop hereã€‚ So I say import cis and cis
    dot exitã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬ä¸æƒ³è¦æ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºæˆ‘ä»¬å¯¹æŸå¤±è®¾ç½®äº†`loss equals true`ã€‚ç°åœ¨è¿™å°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„æ‰€æœ‰å†…å®¹ã€‚è¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œã€‚ç°åœ¨ï¼Œæ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨æ‰“å°ï¼Œç„¶åæ‰“å°æ¨¡å‹çš„æ‘˜è¦ã€‚ç°åœ¨ï¼Œæš‚æ—¶å…ˆåœåœ¨è¿™é‡Œã€‚æˆ‘è¯´å¯¼å…¥`cis`ï¼Œç„¶å`cis.exit`ã€‚
- en: So it stops here and then don't start the trainingã€‚ So let's run it again and
    see if it worksã€‚Alrightï¼Œ so now this worksã€‚ So here it prints the summaryã€‚ And
    then againã€‚ we can inspect our different layers and the output shapes of each
    layers and the number of parameters that we have for trainingã€‚ So yeahï¼Œ this is
    basically an overview of our convolutional neural netã€‚ And now we can remove thisã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åˆ°è¿™é‡Œå°±åœæ­¢ï¼Œä¸è¦å¼€å§‹è®­ç»ƒã€‚æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æœ‰æ•ˆã€‚å¥½å§ï¼Œç°åœ¨è¿™ä¸ªæœ‰æ•ˆã€‚è¿™é‡Œæ‰“å°å‡ºæ‘˜è¦ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ä¸åŒå±‚çš„è¾“å‡ºå½¢çŠ¶ä»¥åŠæ¯å±‚çš„å‚æ•°æ•°é‡ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯æˆ‘ä»¬å·ç§¯ç¥ç»ç½‘ç»œçš„æ¦‚è¿°ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å»æ‰è¿™ä¸ªã€‚
- en: And then the same as last time we compile the model and fit it and evaluate
    itã€‚ So let's run itã€‚ So let's clear this and run the trainingã€‚ Alrightï¼Œ so training
    is doneã€‚ And we see that the loss decreased and the accuracy improve with with
    each epochã€‚ and then we have a final evaluation accuracyã€‚ So it's not perfect
    yetã€‚ It's only an accuracy of 65%ã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œä¸Šæ¬¡ä¸€æ ·ï¼Œæˆ‘ä»¬ç¼–è¯‘æ¨¡å‹ï¼Œæ‹Ÿåˆå®ƒå¹¶è¯„ä¼°å®ƒã€‚è®©æˆ‘ä»¬è¿è¡Œå®ƒã€‚æ¸…ç†ä¸€ä¸‹ï¼Œç„¶åå¼€å§‹è®­ç»ƒã€‚å¥½å§ï¼Œè®­ç»ƒå®Œæˆã€‚æˆ‘ä»¬çœ‹åˆ°æŸå¤±ä¸‹é™ï¼Œå‡†ç¡®æ€§éšç€æ¯ä¸ªå‘¨æœŸæé«˜ã€‚æœ€åï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªæœ€ç»ˆè¯„ä¼°å‡†ç¡®æ€§ã€‚æ‰€ä»¥å®ƒè¿˜ä¸å®Œç¾ï¼Œå‡†ç¡®ç‡åªæœ‰65%ã€‚
- en: But we also only train it for 5 epochã€‚ So I'm sure that this will get better
    if we train itã€‚Longerã€‚ soï¼Œ yeahï¼Œ now you see that our con is workingã€‚ and you
    know how you define and set up your modelã€‚ And now you canï¼Œ for exampleï¼Œ play
    around with the learning rate or play around with different architectures hereã€‚
    And then you can further improve the accuracyã€‚ Soï¼Œ yeahã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬åªè®­ç»ƒäº†5ä¸ªå‘¨æœŸã€‚æ‰€ä»¥æˆ‘ç›¸ä¿¡å¦‚æœæˆ‘ä»¬è®­ç»ƒå¾—æ›´ä¹…ï¼Œè¿™ä¼šå˜å¾—æ›´å¥½ã€‚æ‰€ä»¥ï¼Œç°åœ¨ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å·ç§¯ç½‘ç»œåœ¨å·¥ä½œã€‚ä½ çŸ¥é“å¦‚ä½•å®šä¹‰å’Œè®¾ç½®ä½ çš„æ¨¡å‹ã€‚ç°åœ¨ä½ å¯ä»¥ï¼Œæ¯”å¦‚è¯´ï¼Œè°ƒæ•´å­¦ä¹ ç‡æˆ–å°è¯•ä¸åŒçš„æ¶æ„ã€‚ç„¶åä½ å¯ä»¥è¿›ä¸€æ­¥æé«˜å‡†ç¡®æ€§ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ã€‚
- en: I hope you enjoyed this tutorial and please hit the like button and consider
    subscribing to the channelã€‚ And I hope to see you in the next video byã€‚![](img/f02af098f9ad70406fc18680eac4bd94_14.png)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œè¯·ç‚¹å‡»ç‚¹èµæŒ‰é’®å¹¶è€ƒè™‘è®¢é˜…é¢‘é“ã€‚å¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ï¼![](img/f02af098f9ad70406fc18680eac4bd94_14.png)
