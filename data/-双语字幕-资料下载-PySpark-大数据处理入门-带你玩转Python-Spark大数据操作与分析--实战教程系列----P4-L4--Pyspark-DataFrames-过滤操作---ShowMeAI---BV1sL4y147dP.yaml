- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- Pyspark
    DataFrames è¿‡æ»¤æ“ä½œ - ShowMeAI - BV1sL4y147dP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬ Python+Spark å¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- Pyspark
    DataFrames è¿‡æ»¤æ“ä½œ - ShowMeAI - BV1sL4y147dP
- en: ã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ã€‚
- en: '![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_1.png)'
- en: Hello allã€‚ my name is Kushak and welcome to my YouTube channelã€‚ So guys we will
    be continuing the Pispar playlist series and when I started this particular series
    guysã€‚ they were request for many people to please also complete the MysQL with
    Python playlist also don't worry about it guys now since you have that specific
    request also what I'll do is that every day one Pipar video1 SQL videos at least
    I'll try to do it I also wanted to complete that particular playlistã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œæˆ‘çš„åå­—æ˜¯ Kushakï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„ YouTube é¢‘é“ã€‚æ‰€ä»¥æˆ‘ä»¬å°†ç»§ç»­è¿™ä¸ª Pipar æ’­æ”¾åˆ—è¡¨ç³»åˆ—ã€‚å½“æˆ‘å¼€å§‹è¿™ä¸ªç³»åˆ—æ—¶ï¼Œæœ‰å¾ˆå¤šäººè¯·æ±‚æˆ‘å®Œæˆ
    MysQL ä¸ Python çš„æ’­æ”¾åˆ—è¡¨ï¼Œåˆ«æ‹…å¿ƒã€‚ç°åœ¨æ—¢ç„¶ä½ ä»¬æœ‰è¿™ä¸ªç‰¹å®šçš„è¯·æ±‚ï¼Œæˆ‘æ¯å¤©è‡³å°‘ä¼šå°è¯•ä¸Šä¼ ä¸€ä¸ª Pipar è§†é¢‘å’Œä¸€ä¸ª SQL è§†é¢‘ã€‚æˆ‘ä¹Ÿæƒ³å®Œæˆè¿™ä¸ªæ’­æ”¾åˆ—è¡¨ã€‚
- en: but because of time I was not able to create much more materials So because
    of that it laggged but don't worry againã€‚ the main aim is to upload more and more
    videos for you all so that you'll be able to follow them properly you'll be able
    to utilize them for your successful transition in any career that you're going
    ahead so please make sure that just be patient I'll try to upload parallelly both
    of this and I will try to complete the playlistã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç”±äºæ—¶é—´åŸå› ï¼Œæˆ‘æ²¡èƒ½åˆ›å»ºæ›´å¤šçš„ææ–™ï¼Œå› æ­¤æœ‰äº›æ»åï¼Œä½†åˆ«æ‹…å¿ƒã€‚ä¸»è¦ç›®çš„æ˜¯ä¸ºä½ ä»¬ä¸Šä¼ æ›´å¤šçš„è§†é¢‘ï¼Œè¿™æ ·ä½ ä»¬å°±èƒ½æ›´å¥½åœ°è·Ÿéšï¼Œèƒ½å¤Ÿåœ¨æœªæ¥çš„èŒä¸šè½¬å‹ä¸­åˆ©ç”¨è¿™äº›å†…å®¹ã€‚æ‰€ä»¥è¯·ç¡®ä¿è€å¿ƒç­‰å¾…ï¼Œæˆ‘ä¼šå¹¶è¡Œä¸Šä¼ è¿™ä¸¤ä¸ªç³»åˆ—ï¼Œå¹¶å°½åŠ›å®Œæˆè¿™ä¸ªæ’­æ”¾åˆ—è¡¨ã€‚
- en: So yes enjoy this particular videos guysello my name is Krna and welcome to
    my YouTubetu channelã€‚![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_3.png)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå¤§å®¶å¥½ï¼Œæˆ‘çš„åå­—æ˜¯ Krnaï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„ YouTube é¢‘é“ã€‚![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_3.png)
- en: Guysï¼Œ today we are in the tutorial for of Pi Park data frames and here in this
    particular video we are going to discuss about filter operationã€‚ğŸ˜Šï¼ŒAF up operation
    is pretty much important for data preprosing techniqueã€‚ If you want to retrieve
    some of the records based on some kind of conditionsã€‚ some kind of boolean conditionsï¼Œ
    we can definitely do that with the help of filter operationã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œä»Šå¤©æˆ‘ä»¬åœ¨ Pi Park æ•°æ®æ¡†çš„æ•™ç¨‹ä¸­ï¼Œè¿™ä¸ªè§†é¢‘æˆ‘ä»¬å°†è®¨è®ºè¿‡æ»¤æ“ä½œã€‚ğŸ˜Šï¼Œè¿‡æ»¤æ“ä½œå¯¹äºæ•°æ®é¢„å¤„ç†æŠ€æœ¯éå¸¸é‡è¦ã€‚å¦‚æœä½ æƒ³æ ¹æ®æŸäº›æ¡ä»¶ï¼ŒæŸäº›å¸ƒå°”æ¡ä»¶æ¥æ£€ç´¢ä¸€äº›è®°å½•ï¼Œæˆ‘ä»¬ç»å¯¹å¯ä»¥é€šè¿‡è¿‡æ»¤æ“ä½œæ¥å®ç°ã€‚
- en: Now guysï¼Œ please make sure that you follow this particular playlist with respect
    to Pipar I will be uploading more and more videos as we go ahead and remember
    one more thing there was a lot of complaint from people telling to upload sql
    with Pythonã€‚ don't worry parallel I'll start uploading sql with Pythonã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¤§å®¶ï¼Œè¯·ç¡®ä¿ä½ ä»¬è·Ÿéšè¿™ä¸ª Pipar çš„æ’­æ”¾åˆ—è¡¨ï¼Œæˆ‘ä¼šéšç€è¿›å±•ä¸Šä¼ æ›´å¤šè§†é¢‘ã€‚å¦å¤–ï¼Œè¿˜æœ‰å¾ˆå¤šäººæŠ±æ€¨å¸Œæœ›ä¸Šä¼  SQL ä¸ Python çš„å†…å®¹ï¼Œåˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šå¹¶è¡Œå¼€å§‹ä¸Šä¼ 
    SQL ä¸ Python çš„è§†é¢‘ã€‚
- en: I make sure me sorry because of some delay because I was doing some kind of
    work busy with something but I'll make sure that I'll try to upload all the videosã€‚
    So parallel Sql with Python will also get uploadedã€‚ So let's proceedã€‚ Now first
    of allã€‚ let me go and make some cellã€‚ Now today for thisï¼Œ Ive taken a data setï¼Œ
    a small data setã€‚ which is called a test1 do csv Here I have some data set like
    name age experience and salary and I'm just going to use this and try to show
    you some of the example with respect to filter operation initially whenever you
    want to work with Pipar you have to make sure that you install allã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¾ˆæŠ±æ­‰å› ä¸ºä¸€äº›å»¶è¯¯ï¼Œæˆ‘ä¸€ç›´å¿™äºæŸäº›å·¥ä½œï¼Œä½†æˆ‘ä¼šç¡®ä¿å°½é‡ä¸Šä¼ æ‰€æœ‰è§†é¢‘ã€‚æ‰€ä»¥å¹¶è¡Œçš„ SQL ä¸ Python ä¹Ÿä¼šè¢«ä¸Šä¼ ã€‚é‚£ä¹ˆæˆ‘ä»¬å¼€å§‹å§ã€‚é¦–å…ˆï¼Œè®©æˆ‘åˆ›å»ºä¸€äº›å•å…ƒæ ¼ã€‚ä»Šå¤©æˆ‘ä½¿ç”¨äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œä¸€ä¸ªå°æ•°æ®é›†ï¼Œå«åš
    test1.csvã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æœ‰ä¸€äº›æ•°æ®ï¼Œæ¯”å¦‚å§“åã€å¹´é¾„ã€ç»éªŒå’Œè–ªæ°´ï¼Œæˆ‘å°†ç”¨è¿™äº›æ•°æ®å±•ç¤ºä¸€äº›å…³äºè¿‡æ»¤æ“ä½œçš„ç¤ºä¾‹ã€‚é¦–å…ˆï¼Œæ¯å½“ä½ æƒ³ä½¿ç”¨ Pipar æ—¶ï¼Œå¿…é¡»ç¡®ä¿å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ã€‚
- en: ğŸ˜Šï¼ŒLibrariesï¼Œ so I'm going to use pass spicepar dot sql import spark session
    and this will actually help us to create a spark session right and that is the
    first step whenever we want to basically work with Pipar right so we will be using
    spark session dot builder dot app nameã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œåº“ï¼Œæˆ‘å°†ä½¿ç”¨ `from pyspark.sql import SparkSession`ï¼Œè¿™å°†å¸®åŠ©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Spark ä¼šè¯ï¼Œè¿™æ˜¯æˆ‘ä»¬åŸºæœ¬ä¸Šåœ¨ä½¿ç”¨
    Pipar æ—¶çš„ç¬¬ä¸€æ­¥ã€‚å› æ­¤æˆ‘ä»¬å°†ä½¿ç”¨ `SparkSession.builder.appName`ã€‚
- en: Then I'm just going to create my app name as data frame and basically write
    get or create functionã€‚ which will actually help me to quickly create a spark
    sessionã€‚ I think this is pretty much familiar with every one of youã€‚ Now let's
    proceed and let's try to read a specific data setã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘å°†æˆ‘çš„åº”ç”¨ç¨‹åºå‘½åä¸ºdata frameï¼Œå¹¶åŸºæœ¬ä¸Šç¼–å†™getæˆ–createå‡½æ•°ã€‚è¿™å®é™…ä¸Šå°†å¸®åŠ©æˆ‘å¿«é€Ÿåˆ›å»ºä¸€ä¸ªsparkä¼šè¯ã€‚æˆ‘æƒ³è¿™å¯¹ä½ ä»¬æ¯ä¸ªäººæ¥è¯´éƒ½æ˜¯éå¸¸ç†Ÿæ‚‰çš„ã€‚ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­ï¼Œå°è¯•è¯»å–ç‰¹å®šçš„æ•°æ®é›†ã€‚
- en: So over here what I'm going to do I'm just going to create a variable Df underscoreosco
    I spark and I'm going to use this spark variable dot read or dot csv And here
    I'm just going to consider my data set test oneã€‚ğŸ˜Šï¼ŒDot csvã€‚And here I'm just going
    to make sure that we have this particular option selected Hesical to true and
    in for schemaã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘è¦åšçš„å°±æ˜¯åˆ›å»ºä¸€ä¸ªå˜é‡Df underscoreosco I sparkï¼Œæˆ‘å°†ä½¿ç”¨è¿™ä¸ªsparkå˜é‡.dot readæˆ–.dot csvã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†è€ƒè™‘æˆ‘çš„æ•°æ®é›†test
    oneã€‚ğŸ˜Šï¼ŒDot csvã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†ç¡®ä¿é€‰ä¸­äº†è¿™ä¸ªç‰¹å®šçš„é€‰é¡¹Hesicalä¸ºtrueï¼Œå¹¶åœ¨æ¨¡å¼ä¸­ã€‚
- en: physical to trueã€‚ I think this all I've actually explained youã€‚ then if I write
    D F dot pricepar dot showã€‚ here you'll be able to see your data setã€‚ Okayã€‚ so
    it is readingï¼Œ let's see how will get the outputã€‚ So this is my entire outputã€‚
    Nowï¼Œ guysã€‚ as I showed you that we will be working onã€‚ğŸ˜Šï¼ŒFilter operationã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: physicalä¸ºtrueã€‚æˆ‘æƒ³è¿™å°±æ˜¯æˆ‘å®é™…ä¸Šå‘ä½ è§£é‡Šçš„å…¨éƒ¨å†…å®¹ã€‚ç„¶åå¦‚æœæˆ‘å†™D F dot pricepar dot showã€‚åœ¨è¿™é‡Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ä½ çš„æ•°æ®é›†ã€‚å¥½çš„ã€‚å®ƒæ­£åœ¨è¯»å–ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹è¾“å‡ºã€‚è¿™ä¸ªæ˜¯æˆ‘çš„å…¨éƒ¨è¾“å‡ºã€‚ç°åœ¨ï¼Œä¼™è®¡ä»¬ã€‚æ­£å¦‚æˆ‘æ‰€å±•ç¤ºçš„ï¼Œæˆ‘ä»¬å°†è¿›è¡Œã€‚ğŸ˜Šï¼Œè¿‡æ»¤æ“ä½œã€‚
- en: I will try to retrieve some of the records based on some conditionsã€‚ Rememberã€‚
    filters also are available in pandasï¼Œ but there you try to write in a different
    wayã€‚ Let me just show you how we can perform filter operation by using pie sparkã€‚
    Okayã€‚ so filter operationsã€‚ Let me make this as a markdownã€‚ So it looks bigã€‚ It
    looks amazingã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†å°è¯•æ ¹æ®ä¸€äº›æ¡ä»¶æ£€ç´¢ä¸€äº›è®°å½•ã€‚è®°ä½ï¼Œè¿‡æ»¤å™¨åœ¨pandasä¸­ä¹Ÿæ˜¯å¯ç”¨çš„ï¼Œä½†åœ¨é‚£é‡Œä½ å°è¯•ç”¨ä¸åŒçš„æ–¹å¼æ¥å†™ã€‚è®©æˆ‘å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨pie sparkè¿›è¡Œè¿‡æ»¤æ“ä½œã€‚å¥½çš„ã€‚æ‰€ä»¥è¿‡æ»¤æ“ä½œã€‚è®©æˆ‘æŠŠè¿™ä¸ªåšæˆmarkdownã€‚è¿™æ ·çœ‹èµ·æ¥æ›´å¤§ã€‚çœ‹èµ·æ¥å¾ˆæ£’ã€‚
- en: let me make some more cells perfectã€‚ Nowï¼Œ first stepï¼Œ how do I do a filter operationã€‚
    Supp I want to find out salary of the people who less than probably 20000ã€‚ Okayã€‚
    less than or equal to 20000ã€‚ I can write like thatã€‚ less than or equal to 20000ã€‚ğŸ˜Šï¼ŒNow
    for thisã€‚ there are two ways how we can write it first wayã€‚ I'll just try to use
    the filter operationã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘å†åšä¸€äº›å®Œç¾çš„å•å…ƒã€‚ç°åœ¨ï¼Œç¬¬ä¸€æ­¥ï¼Œæˆ‘è¯¥å¦‚ä½•è¿›è¡Œè¿‡æ»¤æ“ä½œã€‚å‡è®¾æˆ‘æƒ³æ‰¾å‡ºå·¥èµ„ä½äº20000çš„äººã€‚å¥½çš„ã€‚å°äºæˆ–ç­‰äº20000ã€‚æˆ‘å¯ä»¥è¿™æ ·å†™ã€‚å°äºæˆ–ç­‰äº20000ã€‚ğŸ˜Šï¼Œç°åœ¨ä¸ºæ­¤ã€‚æˆ‘ä»¬æœ‰ä¸¤ç§å†™æ³•ï¼Œç¬¬ä¸€ç§æ–¹å¼ã€‚æˆ‘å°†å°è¯•ä½¿ç”¨è¿‡æ»¤æ“ä½œã€‚
- en: So you have like dot filter and here you just have to specify the condition
    that you wantã€‚ supposeupp I'll write salary is less than or equal to 20000ã€‚ remember
    this salary should be the same name of the column over here right and when I write
    dot show you will be able to see this specific records and you'll be able to see
    okay less than or equal to 20000 is this form four people Sunny Paul Herun Subumm
    here you'll be able to see all these things along with the experience right now
    this is one way probably I just want to pick up after putting this particular
    condition I want to pick up two columns So what I can do I can use this and then
    I can basically write dot select and here I'm going to specify my name probably
    I want the name and Hã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ æœ‰åƒ.dot filterï¼Œè¿™é‡Œä½ åªéœ€æŒ‡å®šä½ æƒ³è¦çš„æ¡ä»¶ã€‚å‡è®¾æˆ‘å†™å·¥èµ„å°äºæˆ–ç­‰äº20000ã€‚è®°ä½ï¼Œè¿™ä¸ªå·¥èµ„åº”è¯¥æ˜¯è¿™é‡Œåˆ—çš„åŒåã€‚å½“æˆ‘å†™.dot showæ—¶ï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°è¿™äº›ç‰¹å®šçš„è®°å½•ï¼Œä½ ä¼šçœ‹åˆ°å°äºæˆ–ç­‰äº20000çš„æœ‰å››ä¸ªäººSunny
    Paul Herun Subummï¼Œåœ¨è¿™é‡Œä½ èƒ½å¤Ÿçœ‹åˆ°æ‰€æœ‰è¿™äº›ä¿¡æ¯ä»¥åŠç»éªŒï¼Œç°åœ¨è¿™æ˜¯å…¶ä¸­ä¸€ç§æ–¹å¼ï¼Œå¯èƒ½æˆ‘åªæƒ³åœ¨è®¾ç½®äº†è¿™ä¸ªç‰¹å®šæ¡ä»¶åæŒ‘é€‰ä¸¤åˆ—ã€‚é‚£ä¹ˆæˆ‘å¯ä»¥è¿™æ ·åšï¼Œæˆ‘å¯ä»¥ä½¿ç”¨è¿™ä¸ªï¼Œç„¶ååŸºæœ¬ä¸Šå†™.dot
    selectï¼Œåœ¨è¿™é‡Œæˆ‘å°†æŒ‡å®šæˆ‘çš„åå­—ï¼Œå¯èƒ½æˆ‘æƒ³è¦åå­—å’ŒHã€‚
- en: Name comma Hã€‚ So dot shopã€‚I do thisã€‚Nowï¼Œ this is how you can actually do it
    againã€‚here you can see that name underscore age is actually there and you are
    able to get that specific information After thisã€‚ probably I want to do some of
    the operationã€‚ you can actually do less than greater than whatever things you
    wantã€‚ Probably I want to put two different conditionsã€‚ Then how should I put itã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Name comma Hã€‚æ‰€ä»¥.dot shopã€‚æˆ‘è¿™æ ·åšã€‚ç°åœ¨ï¼Œè¿™å°±æ˜¯ä½ å¯ä»¥å®é™…åšåˆ°çš„ï¼Œå†æ¬¡ã€‚åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°name underscore ageå®é™…ä¸Šæ˜¯å­˜åœ¨çš„ï¼Œä½ èƒ½å¤Ÿè·å–é‚£ä¸ªç‰¹å®šçš„ä¿¡æ¯ã€‚åœ¨æ­¤ä¹‹åã€‚å¯èƒ½æˆ‘æƒ³åšä¸€äº›æ“ä½œã€‚ä½ å¯ä»¥å®é™…åšå°äºå¤§äºç­‰ä½ æƒ³è¦çš„ä»»ä½•äº‹æƒ…ã€‚å¯èƒ½æˆ‘æƒ³æ”¾ä¸¤ä¸ªä¸åŒçš„æ¡ä»¶ã€‚é‚£ä¹ˆæˆ‘åº”è¯¥æ€ä¹ˆåšã€‚
- en: Let's see let's see for that alsoï¼Œ So I'll write D D F Ppar dotã€‚ğŸ˜Šï¼ŒFterã€‚ And
    here I am going to specify my first conditionã€‚ Suppose this is one wayã€‚ this is
    one way by using filter operationã€‚ Alsoï¼Œ guysï¼Œ and this conditions that I'm writingã€‚
    I can also write something like thisã€‚ see thisã€‚ Supp if I write D F pie spark
    of salaryã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ï¼Œå¥½çš„ï¼Œæˆ‘ä¼šå†™D D F Pparç‚¹ã€‚ğŸ˜Šï¼ŒFterã€‚è¿™é‡Œæˆ‘å°†æŒ‡å®šæˆ‘çš„ç¬¬ä¸€ä¸ªæ¡ä»¶ã€‚å‡è®¾è¿™æ˜¯ä¸€ä¸ªæ–¹æ³•ã€‚è¿™æ˜¯ä½¿ç”¨è¿‡æ»¤æ“ä½œçš„ä¸€ç§æ–¹å¼ã€‚è¿˜æœ‰ï¼Œä¼™è®¡ä»¬ï¼Œæˆ‘æ­£åœ¨å†™çš„è¿™äº›æ¡ä»¶ï¼Œæˆ‘ä¹Ÿå¯ä»¥å†™æˆè¿™æ ·ã€‚çœ‹è¿™ä¸ªã€‚å¦‚æœæˆ‘å†™D
    F pie sparkçš„å·¥èµ„ã€‚
- en: suppose salary isã€‚ğŸ˜Šï¼ŒLess than or equal to 20000ã€‚ I can also write like thisã€‚
    I will also be able to get the same outputã€‚ So here you'll be able to see the
    same output over hereã€‚ Nowï¼Œ suppose I want to write multiple conditionsã€‚ How do
    I writeï¼Œ it's very simpleã€‚ I will take thisã€‚ This is first this is one of my conditionã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾å·¥èµ„æ˜¯ã€‚ğŸ˜Šï¼Œå°äºæˆ–ç­‰äº20000ã€‚æˆ‘ä¹Ÿå¯ä»¥è¿™æ ·å†™ã€‚æˆ‘ä¹Ÿä¼šå¾—åˆ°ç›¸åŒçš„è¾“å‡ºã€‚æ‰€ä»¥åœ¨è¿™é‡Œä½ ä¼šçœ‹åˆ°ç›¸åŒçš„è¾“å‡ºã€‚ç°åœ¨ï¼Œå‡è®¾æˆ‘æƒ³å†™å¤šä¸ªæ¡ä»¶ã€‚æˆ‘è¯¥æ€ä¹ˆå†™ï¼Œå®é™…ä¸Šå¾ˆç®€å•ã€‚æˆ‘ä¼šè¿™æ ·åšã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªï¼Œè¿™æ˜¯æˆ‘çš„ä¸€ä¸ªæ¡ä»¶ã€‚
- en: So I'm just going to use this conditionã€‚ and I can also use an and operationï¼Œ
    you knowã€‚ So I'll say and or or any kind of operation that you want probably I
    want to say that Df underscorecope pi for salary is great less than or equal to
    2000 20000 and probably I want a Df ppar of salaryã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘åªæ˜¯è¦ä½¿ç”¨è¿™ä¸ªæ¡ä»¶ã€‚æˆ‘ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸æ“ä½œï¼Œä½ çŸ¥é“çš„ã€‚æ‰€ä»¥æˆ‘ä¼šè¯´å’Œæˆ–ä»»ä½•ä½ æƒ³è¦çš„æ“ä½œã€‚å¯èƒ½æˆ‘æƒ³è¯´Df underscorecope piçš„å·¥èµ„å¤§äºç­‰äº2000
    20000ï¼Œè€Œä¸”æˆ‘å¯èƒ½æƒ³è¦Df pparçš„å·¥èµ„ã€‚
- en: ğŸ˜Šï¼ŒSalaryã€‚Greater than or equal to 15000ã€‚ So I'll be able to get all those specific
    recordsã€‚ Okayã€‚ and againï¼Œ I'll try to put this in another bracketsã€‚ Make sure
    that you do thisã€‚ otherwiseã€‚ you will be getting an error okayã€‚ğŸ˜Šï¼ŒVeryï¼Œ very simple
    guysã€‚ So let's see how Ive actually returnã€‚ It is something like this Df underscore
    Pi dot filterã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œå·¥èµ„ã€‚å¤§äºç­‰äº15000ã€‚æ‰€ä»¥æˆ‘å°†èƒ½å¤Ÿè·å–æ‰€æœ‰è¿™äº›ç‰¹å®šè®°å½•ã€‚å¥½çš„ï¼Œç„¶åï¼Œæˆ‘ä¼šå°è¯•å°†å…¶æ”¾åœ¨å¦ä¸€ä¸ªæ‹¬å·ä¸­ã€‚ç¡®ä¿ä½ è¿™æ ·åšã€‚å¦åˆ™ä½ ä¼šæ”¶åˆ°é”™è¯¯ä¿¡æ¯ã€‚å¥½çš„ã€‚ğŸ˜Šï¼Œéå¸¸éå¸¸ç®€å•ï¼Œä¼™è®¡ä»¬ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘å®é™…æ˜¯å¦‚ä½•å†™çš„ã€‚å®ƒæ˜¯è¿™æ ·çš„
    Df underscore Pi ç‚¹è¿‡æ»¤å™¨ã€‚
- en: Df Pipar of sal less than or equal to 20000 greater equal to 150 If I executeã€‚
    you'll be able to see between 15000 to 20000 you'll be able to find outã€‚ you can
    also write or Then you'll be able to get all the different different valuesã€‚ Now
    this is a kind of filter operation that you can basically specify rememberã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Df Piparçš„å·¥èµ„å°äºæˆ–ç­‰äº20000ä¸”å¤§äºç­‰äº150ã€‚å¦‚æœæˆ‘æ‰§è¡Œï¼Œä½ å°†èƒ½çœ‹åˆ°åœ¨15000åˆ°20000ä¹‹é—´çš„è®°å½•ã€‚ä½ ä¹Ÿå¯ä»¥å†™æˆ–ï¼Œç„¶åä½ å°†èƒ½å¤Ÿå¾—åˆ°æ‰€æœ‰ä¸åŒçš„å€¼ã€‚è¿™æ˜¯ä¸€ç§ä½ å¯ä»¥åŸºæœ¬ä¸ŠæŒ‡å®šçš„è¿‡æ»¤æ“ä½œï¼Œè¯·è®°ä½ã€‚
- en: this will be pretty much handy when you are probably retrieving some of the
    records with respect to any kind of data setsã€‚ and you can try different different
    thingsã€‚ this is one way where you are actually directly providing your column
    name and putting a condition internally this Pi spark actually Pipar data frameã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æ£€ç´¢ä¸ä»»ä½•æ•°æ®é›†ç›¸å…³çš„ä¸€äº›è®°å½•æ—¶ï¼Œè¿™å°†éå¸¸æ–¹ä¾¿ã€‚ä½ å¯ä»¥å°è¯•ä¸åŒçš„æ–¹å¼ã€‚è¿™æ˜¯ä½ å®é™…æä¾›åˆ—åå¹¶åœ¨å†…éƒ¨æ”¾ç½®æ¡ä»¶çš„ä¸€ç§æ–¹å¼ï¼Œè¿™ä¸ªPi sparkå®é™…ä¸Šæ˜¯Piparæ•°æ®æ¡†ã€‚
- en: understand thatï¼Œ and you'll be able to get the output rightï¼Œ So yesã€‚ this was
    it all about this particular videoã€‚ I hope you like itã€‚ I hope you like this particular
    filter operationã€‚ Just try to do it from your sideã€‚ Okay one more operation is
    basically pendingã€‚ I can also write like this Cã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£è¿™ä¸€ç‚¹ï¼Œä½ å°±èƒ½æ­£ç¡®è·å–è¾“å‡ºã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ã€‚è¿™å°±æ˜¯è¿™æ®µè§†é¢‘çš„å…¨éƒ¨å†…å®¹ã€‚å¸Œæœ›ä½ å–œæ¬¢å®ƒã€‚å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªè¿‡æ»¤æ“ä½œã€‚è¯•ç€ä»ä½ è¿™è¾¹åšä¸€ä¸‹ã€‚å¥½çš„ï¼Œè¿˜æœ‰ä¸€ä¸ªæ“ä½œåŸºæœ¬ä¸Šæ˜¯æœªå®Œæˆçš„ã€‚æˆ‘ä¹Ÿå¯ä»¥å†™æˆè¿™æ ·Cã€‚
- en: everybody I can basicallyã€‚ğŸ˜Šï¼ŒSay thatï¼Œ okayã€‚Probably I can use this operationã€‚
    which is called as not operationï¼Œ let's seeã€‚How this not operation will be comingã€‚
    Okayï¼Œ basicallyã€‚ the inverse condition operationï¼Œ we basically sayï¼Œ So I'll be
    using thisã€‚Okayã€‚And thisã€‚ and inside thisï¼Œ I can put a not conditionï¼Œ which like
    thisã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªäººæˆ‘åŸºæœ¬ä¸Šå¯ä»¥ã€‚ğŸ˜Šï¼Œè¯´ï¼Œå¥½å§ã€‚ä¹Ÿè®¸æˆ‘å¯ä»¥ä½¿ç”¨è¿™ä¸ªæ“ä½œï¼Œç§°ä¸ºéæ“ä½œï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ã€‚è¿™ä¸ªéæ“ä½œå°†å¦‚ä½•å‡ºç°ã€‚å¥½çš„ï¼ŒåŸºæœ¬ä¸Šã€‚é€†æ¡ä»¶æ“ä½œï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šè¿™æ ·è¯´ã€‚æ‰€ä»¥æˆ‘ä¼šä½¿ç”¨è¿™ä¸ªã€‚å¥½çš„ã€‚åœ¨é‡Œé¢ï¼Œæˆ‘å¯ä»¥æ”¾ä¸€ä¸ªéæ¡ä»¶ï¼Œå°±åƒè¿™æ ·ã€‚
- en: So I'll say this is a not of Df of5par salaries less than equal equal to 200ã€‚
    So anything that is greater than 20000 will be given over hereã€‚ Okayï¼Œ so inverse
    operationã€‚ you can say inverse filter operationã€‚ So yesï¼Œ this was one of the thing
    I'll say inverse filter operationã€‚ And I've actually shown you what things we
    have actually discussed over hereã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä¼šè¯´è¿™æ˜¯ä¸€ä¸ªä¸ç­‰äºDf of5parçš„å·¥èµ„å°äºç­‰äº200çš„æƒ…å†µã€‚æ‰€ä»¥ä»»ä½•å¤§äº20000çš„å°†ä¼šåœ¨è¿™é‡Œç»™å‡ºã€‚å¥½çš„ï¼Œæ‰€ä»¥è¿™æ˜¯é€†æ“ä½œã€‚ä½ å¯ä»¥è¯´æ˜¯é€†è¿‡æ»¤æ“ä½œã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä¼šè¯´çš„é€†è¿‡æ»¤æ“ä½œã€‚æˆ‘å®é™…ä¸Šå‘ä½ å±•ç¤ºäº†æˆ‘ä»¬åœ¨è¿™é‡Œè®¨è®ºçš„å†…å®¹ã€‚
- en: So I hope you like this particular videoï¼Œ please to subscribe the channel if
    you are not subscribeã€‚ I'll see in the next videoã€‚ Have have a great dayã€‚ Thank
    you bye byeã€‚ğŸ˜Šã€‚![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_5.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªè§†é¢‘ï¼Œå¦‚æœä½ è¿˜æ²¡æœ‰è®¢é˜…ï¼Œè¯·è®¢é˜…é¢‘é“ã€‚æˆ‘ä¼šåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚ç¥ä½ æœ‰ä¸ªç¾å¥½çš„ä¸€å¤©ã€‚è°¢è°¢ï¼Œå†è§ã€‚ğŸ˜Šï¼![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_5.png)
