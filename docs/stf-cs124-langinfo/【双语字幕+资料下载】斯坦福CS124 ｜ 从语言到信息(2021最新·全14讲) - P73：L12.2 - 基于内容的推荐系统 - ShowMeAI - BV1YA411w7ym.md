# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘æ–¯å¦ç¦CS124 ï½œ ä»è¯­è¨€åˆ°ä¿¡æ¯(2021æœ€æ–°Â·å…¨14è®²) - P73ï¼šL12.2 - åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿ - ShowMeAI - BV1YA411w7ym

![](img/0b8b7b4ca089d92633a45efc2a111e3e_0.png)

Let's turn to the first methodã€‚Recommenmdending based on features of the content itselfã€‚

The main idea of content based recommendation is to recommend items to customer X that are similar to things X already rated highlyã€‚

What do we mean by similarï¼ŸHaving similar contentï¼Œ so for movie recommendationsã€‚

 we could recommend movies with the same actors or the same director or genreã€‚

Or for websites or blogsï¼Œ we could recommend other sites with similar genre tags like cooking news or science news or similar wordsã€‚

Here's our plan of actionã€‚ The user likes some itemsã€‚

 and we have profiles for these items so we can build a user profile summarizing the items they likeã€‚

 This user seems to like red items and circles and trianglesã€‚

Now we can look in a database and match things that match our user profileã€‚

So maybe this red object and this circleã€‚And we can recommend them back to the userã€‚

So we'll need to create a profile for each itemï¼Œ a vector of featuresã€‚For exampleï¼Œ for moviesã€‚

 a typical feature could be genre director actors for text we use sets of wordsã€‚

How do we pick out these featuresï¼ŸWe set some by handï¼Œ for exampleã€‚

 using our knowledge about movies to suggest that genre is importantã€‚

Others we can learn automaticallyï¼Œ for wordsï¼Œ we could use a subsetï¼Œ for exampleã€‚

 by computing TF IDF features for words and including any word that had a height that had a high TF IDDF value in trainingã€‚

Maybe we don't include the actual TF IDF valueï¼Œ but we just keep words that have a TF IDF value over some threshold and we create an element in our vector for each of those wordsã€‚

 and we'll put a one in that dimension if a document has that word and a zero otherwiseã€‚

Here is a sample item profile for two itemsï¼Œ Mo Xï¼Œ a Johnny Depp pirate movieï¼Œ and Mo Yã€‚

 a Melissa McCarthy comedyã€‚Each item profile is a vector of binary valuesï¼Œ ones or zerosã€‚

But what if we want to have real or ordinal features tooï¼ŸFor exampleã€‚

 me and might want to add a feature for the average rating of a movieã€‚This average is a real numberã€‚

That's fineï¼Œ cosine still works with combinations of binary and real valued values in the cellã€‚

We mightï¼Œ howeverï¼Œ want to scale the non Boolean components with some alphaã€‚

 so they neither dominate the calculation nor become irrelevantã€‚

If we compute the cosine of the angle between the vectors for movies X and yã€‚

 we can see that their dot product is 2 plus 12 alpha squaredã€‚

And the lengths of each of the vectors are 5 plus9 alpha squared square root and square root of 5 plus 16 alpha squaredã€‚

So there's the cosine of the angle between the vectorsã€‚If we choose alpha equals1ã€‚

That is we take the average ratings exactly as they areï¼Œ then the value of that expression is 0ã€‚82ã€‚

If we use alpha equals 2ã€‚That is we double the value of the ratingsï¼Œ now the cosine is 0ã€‚94ã€‚

 so the similarity is higherã€‚ğŸ˜¡ï¼ŒBecause we're emphasizing that these ratings are similarã€‚

 three and four are pretty similarã€‚By contrastï¼Œ if alpha is only 0ã€‚5ã€‚

 then we'll get a lower similarity of 0ã€‚69ã€‚So the choice of alpha is very influential and that's something we'll need to set perhaps on a held outset to maximize our evaluation metricã€‚



![](img/0b8b7b4ca089d92633a45efc2a111e3e_2.png)

We not only need to create vectors describing itemsã€‚

 we need to create vectors with the same components that describe the user preferencesã€‚

We can do this from the utility matrix representing the connection between users and itemsã€‚

We could estimate the values for items the user likes as some aggregation of the profiles of those items like the average of the items with ratingsã€‚



![](img/0b8b7b4ca089d92633a45efc2a111e3e_4.png)

For exampleï¼Œ suppose items are movies represented by Boolean profiles with components corresponding to actorsã€‚

And the utility matrix has a one if the users seen the movie and is blank otherwiseã€‚

So if 20% of the movies have Melissa McCarthy in themã€‚

Then the user profile for you will have 02 in the component for Melissa McCarthyã€‚

Now that we have profile vectors for both users and items in the same dimensionsã€‚

 we can estimate the degree to which a user would prefer an item by finding the most similar itemã€‚

 which we can do just by computing the cosine distance between the user's profile and the items profileã€‚



![](img/0b8b7b4ca089d92633a45efc2a111e3e_6.png)

The content based approach has many advantagesï¼Œ it doesn't rely on sparse information about other usersã€‚

 we can recommend to users with unique taste if they just played an obscure songã€‚

 we can play them another obscure songã€‚And we can recommend new or rare items because they'll all have features that let us choose themã€‚

 and the algorithm has transparencyï¼Œ we can explain to the user why we recommended the item just by listing the featuresã€‚



![](img/0b8b7b4ca089d92633a45efc2a111e3e_8.png)

On the other handï¼Œ the content based approach requires that we come up with the featuresã€‚

 that's hardï¼Œ and we do have a new user problemã€‚We have to build a profile for a new userã€‚

The content based approach also can give very non diverse suggestionsã€‚

 we never recommend items outside the user's content profileã€‚And related to this problemã€‚

 the content based approach is unable to exploit the quality judgments of other usersã€‚

 something that the collaborative filtering approach is designed forã€‚



![](img/0b8b7b4ca089d92633a45efc2a111e3e_10.png)

We've seen how to recommend items based on their content featuresã€‚

