# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘æ–¯å¦ç¦CS124 ï½œ ä»è¯­è¨€åˆ°ä¿¡æ¯(2021æœ€æ–°Â·å…¨14è®²) - P42ï¼šL7.4- é€†æ–‡æœ¬é¢‘ç‡æƒé‡ - ShowMeAI - BV1YA411w7ym

In this segment I'm going to introduce another score that's used for ranking the matches of documents to a query and that is to make use of this notion of document frequency in particular we always use in reverse so it's normally referred to as inverse document frequency weightingã€‚



![](img/8774c1e58724136f7bead964d8757f30_1.png)

The idea behind making use of document frequency is that rare terms are more informative than frequent terms So if you remember earlier on we talked about stop words which was you know words like the and to and ofã€‚

ğŸ˜Šï¼ŒAnd so the idea that was that these words were so commonã€‚

 so semantically empty that we didn't have to include them in our information retrieval system at allã€‚

 they had no effect on how good a match a document was to a query Wellï¼Œ that's maybe not quite trueã€‚

 but there's some truth in it in particular it seems like in generalã€‚

 very common words aren't very determinative of the matching of a document and a queryã€‚

 whereas rare words are more importantã€‚ğŸ˜Šï¼ŒSo consider a term in the query that is very rare in the collectionã€‚

 perhaps something like a rechnocentric Well if someone had type that word into their query and we can find a document that contains the word aracchnocentricã€‚

 it's very likely to be a document that the user would be interested in seeing so we want to give a high weight in our match score for rare terms like aracchnocentricã€‚

ğŸ˜Šï¼ŒOn the other handï¼Œ frequent terms are less informative than rare termsã€‚

 So consider a term that is frequent in the collection like high increased lineã€‚

 which might occur in lots of documentsã€‚ Wellï¼Œ a document containing such a term is more likely to be relevant than a document that doesn't if the query contained one of those termsã€‚

 that is not such a sure indicator of relevanceã€‚ So if frequent termsã€‚

 we want to give positive weights for a document matching a term in the queryã€‚

 but lower weights than for rare termsã€‚ğŸ˜Šï¼ŒAnd so the way we're going to go about doing that is by making use of this notion of document frequency scoresã€‚

So what exactly is thatï¼ŸWellã€‚The document frequency of a term is the number of documents that contain the term so what this means is that we're looking at the entire collectionã€‚

 so maybe the collection is a million documents and if10 documents have this word we're saying that the document frequency is 10 so that's just counting the number of documents that occurs regardless of the number of times that occurs that's something I'll come back toã€‚

So document frequency is an inverse measure of informativeness of the term and we also note that the document frequency has to be of a term has to be smaller than the number of documents in the collection So putting that together this gives us the measure of inverse document frequency where we start with the document frequency and use it as the denominator and the numerator N here is the number of documentsã€‚

 so for a word that appears in just one document this part will be n and for a word that appears in every document its value will be1ã€‚

ğŸ˜Šï¼ŒSo it's some value between one and nã€‚ and so then what we do after that is we take the log of itã€‚

And the log is used to dampen the effective inverse document frequencyã€‚

 the idea again is that if you just use the absolute scoreï¼Œ that would be too strong a factorã€‚ğŸ˜Šã€‚

Now in this computationï¼Œ as you can see I've used log to the basease 10 and that's very commonly usedã€‚

 but actually it turns out that what we use as the base of the log isn't really importantã€‚ğŸ˜Šï¼ŒOkayã€‚

 let's go through a concrete example where again we're going to suppose that the size of our document collection is 1 million documentsã€‚

ğŸ˜Šï¼ŒSo if we take an extremely rare word like Caluriaï¼Œ which let's say occurs in just one documentã€‚

 well then what we're going to be doing is we're going to be taking one million the number of documentsã€‚

Divided by one and then taking the log of that which means with log to the base 10 that there'll be six if we take a somewhat more common document word that occurs in maybe 100 documents then we're going to get the the inverse document frequency of that is four and so then we can work on down for progressively more common words and the inverse document frequency or countdown and in particular for the final case we assume the word that occurred in every one of our documents well then we've gotã€‚

A millionã€‚Divided by a millionã€‚Which is oneã€‚ and if we take the log of thatã€‚

 which we get the answer zeroã€‚So the result we actually get is that a word that occurs in every document does have a weight of zero according to an IDF score and has no effect on the ordering of words and retrieval and that makes sense because if it occurs in every documentã€‚

 it has no discriminatory value between documents and gets a weight of zero and so what you can see with these numbers overall thoughã€‚

 is that this inverse document frequency weighting will give a small multiplier that pay more attention to words that are rarer words rather than very common wordsã€‚

ğŸ˜Šï¼ŒAnother thing to note here is that IDF values aren't things that change for each queryã€‚

 that there's precisely one IDF value for each term in the collectionã€‚

 and that's going to be the same regardless of what query you're issuing of the collectionã€‚ğŸ˜Šï¼ŒOkayã€‚

 here's aã€‚Now yesï¼Œ no question for you guysã€‚ Does the IDF have an effect on ranking for one term queries like this oneï¼Ÿ

The answer isï¼Œ noï¼Œ it doesn'tã€‚ IF has no effect on one term queriesã€‚ So for a one term queryã€‚

 you're going to have one of these terms of in over the document frequencyã€‚

 and it will be worked outï¼Œ but it's going to be just a scaling factorã€‚

Which since there's only one IF value for eachã€‚Term will be applied to every document and therefore it won't affect the ranking in any wayã€‚

You only get an effect from IDF when you have multiple terms in a queryï¼Œ so for exampleã€‚

 if we have the query capricious personï¼Œ well now we're in a situation where capricious is a much rarer word and so IDF will sayPa much more attention to documents that contain the word capricious than to documents that contain just the word person in ranking your retrieval resultsã€‚

There's another measure that reflects the frequency of a term and indeed you might have been wondering why we're not using it and that other measure is what information retrieval people refer to as the collection frequency of a term so the collection frequency of a term it's just the total number of times that appears in the collection counting multiple occurrences so that's the measure that we've been using in other places it's the measure we' are using to build ungram language models or when we're working out spam classifiers or something like that but it's not what's usually used in information retrieval ranking systems and this next example can maybe help explain whyã€‚

ğŸ˜Šï¼ŒSo here we have two words insurance and try and I pick those two words because they have virtually identical collection frequency overall they both occur somewhat more than 10ã€‚

000 times in the collection but let's then look at their document frequency so the wordtry occurs in 8ã€‚

700 odd documents and that stands in contrast to insurance which occurs in slightly under 4000 documents and so what does that mean what that means is that when try occurs in a document it tends to occur only once but the try is widely distributed across documents on the other handã€‚

 when insurance occurs in a document it tends to occur several times it tends to occur two to three times and so what does that reflect it reflects the fact that they tend to be documents about insurance which Sha mentioned insurance several timesã€‚

ğŸ˜Šï¼ŒWhere there don't really tend to be documents about tryingã€‚ğŸ˜Šã€‚

And so what does that mean in terms of coming up with a score for retrieval systems with words matchingã€‚

 What it seems to suggest is that what we should be doing is giving higher weighting to instances of the word insurance appearingã€‚

 So if we had some kind of imagine some kind of queryï¼Œ like try to buyã€‚Insuranceã€‚

The most important word to make sure we're finding inã€‚

Our documents to match the query is insurance and probably the second most important word it is by and try should be becoming in third placeã€‚



![](img/8774c1e58724136f7bead964d8757f30_3.png)

Before then near stop word of2ã€‚And so that's an idea that is being correctly captured by looking at the document frequencyã€‚

 but as you can see it's not captured by the collection frequencyï¼Œ which would scoreã€‚

 try and insurance equallyã€‚ğŸ˜Šï¼ŒOkayï¼Œ so I hope now you know what document frequency weighting is and why people usually use that as a retrieval ranking score rather than collection frequencyã€‚

ğŸ˜Šã€‚

![](img/8774c1e58724136f7bead964d8757f30_5.png)