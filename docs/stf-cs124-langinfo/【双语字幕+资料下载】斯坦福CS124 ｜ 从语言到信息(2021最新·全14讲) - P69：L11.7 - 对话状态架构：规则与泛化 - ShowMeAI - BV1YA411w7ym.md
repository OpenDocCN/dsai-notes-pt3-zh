# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘æ–¯å¦ç¦CS124 ï½œ ä»è¯­è¨€åˆ°ä¿¡æ¯(2021æœ€æ–°Â·å…¨14è®²) - P69ï¼šL11.7 - å¯¹è¯çŠ¶æ€æ¶æ„ï¼šè§„åˆ™ä¸æ³›åŒ– - ShowMeAI - BV1YA411w7ym

Let's talk about dialogue policyï¼Œ what to sayï¼Œ and dialogue generationï¼Œ how to say itã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_1.png)

![](img/729f491a52ff62cc3329b87f3c71d216_2.png)

The goal of the dialogue policy is to decide what action the system should take nextã€‚

 That is what dialogue Act to generate more formallyï¼Œ at turn I in the conversationã€‚

 we want to predict which action a sub I to take based on the entire dialogue stateã€‚

 The state could mean the entire sequence of dialogue acts from the system andll call those a for agentã€‚

And from the userï¼Œ in which case the task would be to compute the arg max over all possible next actions of the probability of the actionã€‚

 given this long sequenceï¼Œ Age said something user said somethingã€‚

 Age said something user said something all the wayã€‚

We can simplify this by maintaining as a dialogueg stateã€‚

 mainly just the set of slot fillers that the user has expressedã€‚

 collapsing across the many different conversational paths that could lead to the same set of filled slotsã€‚

So instead of conditioning on the entire previous stateã€‚

 we the condition simply on the current state of the frame and the previous thing that the agent said and the previous thing that the user saidã€‚

 and then again picking the AGmax over all possible next actions based on their probabilityã€‚

These probabilities can be estimated by a neural classifier using neural representations of the slot fillersã€‚

 for exampleï¼Œ representations of the spans of words and the utterancesï¼Œ for exampleã€‚

 a sentence embeddings computed over contextual embeddingã€‚

Modern dialogue systems often make mistakesï¼Œ so it's important for dialogue systems to make sure they've achieved the correct interpretationã€‚

 and this is generally done by two methodsï¼Œ confirming understandings with the user and rejecting utterances that the system is likely to have misunderstoodã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_4.png)

When using the explicit confirmation strategyï¼Œ the system asks the user a direct question to make sure it's understood user says Baltimoreã€‚

 the system says do you want to leave from Baltimore or the user says yesã€‚

I'd like to fly from Denver to New York on Septemberï¼Œ so and so and the system saysï¼Œ let's seeã€‚

 I have you going from Denver to New Yorkï¼Œ blahï¼Œ blah blahï¼Œ is that correctï¼Œ yesã€‚

 an explicit questionã€‚

![](img/729f491a52ff62cc3329b87f3c71d216_6.png)

When using the implicit confirmation strategyï¼Œ the system instead demonstrates its understanding as a grounding strategyã€‚

 for exampleï¼Œ repeating back the system's understanding only as part of asking the next questionã€‚

 I want to travel to Berlinï¼Œ when do you want to travel to Berlinï¼Ÿ

Explicit and implicit confirmation have complementary strengthsã€‚

Explicit confirmation makes it easier to correct the system's misrecognitions since the user can just answer noã€‚

But explicit confirmation is awkwardï¼Œ increases the length of the conversationã€‚

Those explicit confirmation dialogue fragments that we just saw sound non natural and non humanã€‚

 so implicit conversationï¼Œ much more conversationally naturalã€‚

Confirmation is just one kind of conversational action by which a system can express lack of understandingã€‚

 Another option is rejection in which a system gives the user a prompt likeï¼Œ I'm sorryã€‚

 I didn't understand thatã€‚Sometimes utterances are rejected multiple timesã€‚

This might mean that the user is using language that the system is unable to followã€‚Thusã€‚

 when an utterance is rejectedï¼Œ systems often follow a strategy of progressive prompting or escalating this detailã€‚

 As in this exampleï¼Œ the system didn't understand this long sentence from the callerã€‚

 And instead of just repeating the questionï¼Œ when would you like to leaveã€‚

 the rejection prompt gives the caller more guidance about how to formulate an utterance the system will understandã€‚

Theseï¼Œ you can sayï¼Œ help messages are important in helping improve systems understanding performanceã€‚

It's common to use rich features other than just the dialogue state representation to make policy decisionsã€‚

For exampleï¼Œ the confidence that the ASR system assigns to an utterance can be used by explicitly confirming only low confidence sentencesã€‚

Confidence is a metric that the speech recognizer assigns to its transcript of a sentence to indicate how confident it is in that transcriptionã€‚

So a system might have a fourtered level of confidence with thresholds alpha beta and gammaã€‚

 if the ASR confidence is very lowï¼Œ we rejectï¼Œ if it's slightly above thatï¼Œ we confirm explicitlyã€‚

 if we're pretty sure of the sentenceï¼Œ we confirm implicitly and if we're absolutely certainly know what they said and understood itã€‚

 we don't have to confirm it allã€‚Another common feature in confirmation is the cost of making an errorã€‚

 for exampleï¼Œ explicit confirmation is common before a flight is actually booked or money in an account is movedã€‚

Finallyï¼Œ once the policy has decided what Sp Act to generateã€‚

 the natural language generation component needs to generate the text of the response to the userã€‚

The task of natural language generation in the information state architecture is often modeled in two stagesã€‚

 content planningï¼Œ what to sayï¼Œ and sentence realization how to say itã€‚Hereã€‚

 let's assume content planning has been done by the dialogueo policyã€‚

 which has chosen the dialogueog Act to generate and chosen some attributes like slots and values that the planner wants to say to the userã€‚

 either to give the user an answer or as part of a confirmation strategyã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_8.png)

So here are some sample input outputs for the sentence realization phaseã€‚So in this first exampleã€‚

 the Content Planner has chosen the Dialog Act recommend and some particular slotsã€‚

 the name of the restaurant Omi D and the neighborhood and the cuisineã€‚

 and the goal of the sentence Realr is to generate a sentence like number one or number two here by training on many such examples of representation and sentence pairs from a large corpus of labeled dialoguesã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_10.png)

Training dataï¼Œ howeverï¼Œ is hard to come byï¼Œ we're unlikely to see every possible restaurant with every possible attribute in the many different worded sentencesã€‚

So it's common in sentence realization to increase the generality of the training examples by delexicalization Dlexicalization is the process of replacing specific words in the training set that represent slot values with a generic placeholder token representing the slotã€‚

ğŸ˜Šï¼ŒSo we can delexicalize both of these two sentences by replacing Omidiï¼Œ midtown and Frenchã€‚æˆ‘äº†ã€‚

Restaurant name is in neighborhood and serves cuisine foodã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_12.png)

Nowï¼Œ mapping from frames to delexxiicalized sentences can be done by encoder decor models trained on large hand labeled corpora of task oriented dialogueã€‚

 The input to the encoder is a sequence of tokens that represent the dialogueo Act and its argumentsã€‚

 So the dialogueo Act recommend and the attribute value pairsã€‚Service decent cuisineï¼Œ noã€‚

 might be represented as just a flat sequence of tokensï¼Œ each map to a learned embeddingã€‚

And the encoder reads all the input slot value representationsã€‚

 then the decoder outputs the following delexxiicalized English sentenceï¼Œ name has decent serviceã€‚

 and then we can use the input frame from the content planner to relexxiicalizeã€‚

 replacing restaurant name with OmiDï¼Œ resulting in OmiD has decent serviceã€‚

It's also possible to design NLG algorithms that are specific to a particular dialogue actã€‚

 for exampleï¼Œ consider the task of generating clarification questions in cases where the speech recognition fails to understand some part of the user's utteranceã€‚

While it's possible to use the generic dialogueog Actï¼Œ rejectï¼Œ like please repeatã€‚

 or I don't understandï¼Œ we can do something more targetedã€‚ For exampleï¼Œ hereã€‚

 the system reprises the words going and on the fifth to make it clear which aspects of the user's turn the system needs to be clarified targeted clarification questions can be created by rules such as replace going to unknown word with going whereã€‚

Or by building classifiers to guess which slots might have been or misrecognized in the sentenceã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_14.png)

We've now seen all the pieces of the dialogue state architectureã€‚



![](img/729f491a52ff62cc3329b87f3c71d216_16.png)