# P69ÔºöL11.7 - ÂØπËØùÁä∂ÊÄÅÊû∂ÊûÑÔºöËßÑÂàô‰∏éÊ≥õÂåñ - ShowMeAI - BV1YA411w7ym

Let's talk about dialogue policyÔºå what to sayÔºå and dialogue generationÔºå how to say it„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_1.png)

![](img/729f491a52ff62cc3329b87f3c71d216_2.png)

The goal of the dialogue policy is to decide what action the system should take next„ÄÇ

 That is what dialogue Act to generate more formallyÔºå at turn I in the conversation„ÄÇ

 we want to predict which action a sub I to take based on the entire dialogue state„ÄÇ

 The state could mean the entire sequence of dialogue acts from the system andll call those a for agent„ÄÇ

And from the userÔºå in which case the task would be to compute the arg max over all possible next actions of the probability of the action„ÄÇ

 given this long sequenceÔºå Age said something user said something„ÄÇ

 Age said something user said something all the way„ÄÇ

We can simplify this by maintaining as a dialogueg state„ÄÇ

 mainly just the set of slot fillers that the user has expressed„ÄÇ

 collapsing across the many different conversational paths that could lead to the same set of filled slots„ÄÇ

So instead of conditioning on the entire previous state„ÄÇ

 we the condition simply on the current state of the frame and the previous thing that the agent said and the previous thing that the user said„ÄÇ

 and then again picking the AGmax over all possible next actions based on their probability„ÄÇ

These probabilities can be estimated by a neural classifier using neural representations of the slot fillers„ÄÇ

 for exampleÔºå representations of the spans of words and the utterancesÔºå for example„ÄÇ

 a sentence embeddings computed over contextual embedding„ÄÇ

Modern dialogue systems often make mistakesÔºå so it's important for dialogue systems to make sure they've achieved the correct interpretation„ÄÇ

 and this is generally done by two methodsÔºå confirming understandings with the user and rejecting utterances that the system is likely to have misunderstood„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_4.png)

When using the explicit confirmation strategyÔºå the system asks the user a direct question to make sure it's understood user says Baltimore„ÄÇ

 the system says do you want to leave from Baltimore or the user says yes„ÄÇ

I'd like to fly from Denver to New York on SeptemberÔºå so and so and the system saysÔºå let's see„ÄÇ

 I have you going from Denver to New YorkÔºå blahÔºå blah blahÔºå is that correctÔºå yes„ÄÇ

 an explicit question„ÄÇ

![](img/729f491a52ff62cc3329b87f3c71d216_6.png)

When using the implicit confirmation strategyÔºå the system instead demonstrates its understanding as a grounding strategy„ÄÇ

 for exampleÔºå repeating back the system's understanding only as part of asking the next question„ÄÇ

 I want to travel to BerlinÔºå when do you want to travel to BerlinÔºü

Explicit and implicit confirmation have complementary strengths„ÄÇ

Explicit confirmation makes it easier to correct the system's misrecognitions since the user can just answer no„ÄÇ

But explicit confirmation is awkwardÔºå increases the length of the conversation„ÄÇ

Those explicit confirmation dialogue fragments that we just saw sound non natural and non human„ÄÇ

 so implicit conversationÔºå much more conversationally natural„ÄÇ

Confirmation is just one kind of conversational action by which a system can express lack of understanding„ÄÇ

 Another option is rejection in which a system gives the user a prompt likeÔºå I'm sorry„ÄÇ

 I didn't understand that„ÄÇSometimes utterances are rejected multiple times„ÄÇ

This might mean that the user is using language that the system is unable to follow„ÄÇThus„ÄÇ

 when an utterance is rejectedÔºå systems often follow a strategy of progressive prompting or escalating this detail„ÄÇ

 As in this exampleÔºå the system didn't understand this long sentence from the caller„ÄÇ

 And instead of just repeating the questionÔºå when would you like to leave„ÄÇ

 the rejection prompt gives the caller more guidance about how to formulate an utterance the system will understand„ÄÇ

TheseÔºå you can sayÔºå help messages are important in helping improve systems understanding performance„ÄÇ

It's common to use rich features other than just the dialogue state representation to make policy decisions„ÄÇ

For exampleÔºå the confidence that the ASR system assigns to an utterance can be used by explicitly confirming only low confidence sentences„ÄÇ

Confidence is a metric that the speech recognizer assigns to its transcript of a sentence to indicate how confident it is in that transcription„ÄÇ

So a system might have a fourtered level of confidence with thresholds alpha beta and gamma„ÄÇ

 if the ASR confidence is very lowÔºå we rejectÔºå if it's slightly above thatÔºå we confirm explicitly„ÄÇ

 if we're pretty sure of the sentenceÔºå we confirm implicitly and if we're absolutely certainly know what they said and understood it„ÄÇ

 we don't have to confirm it all„ÄÇAnother common feature in confirmation is the cost of making an error„ÄÇ

 for exampleÔºå explicit confirmation is common before a flight is actually booked or money in an account is moved„ÄÇ

FinallyÔºå once the policy has decided what Sp Act to generate„ÄÇ

 the natural language generation component needs to generate the text of the response to the user„ÄÇ

The task of natural language generation in the information state architecture is often modeled in two stages„ÄÇ

 content planningÔºå what to sayÔºå and sentence realization how to say it„ÄÇHere„ÄÇ

 let's assume content planning has been done by the dialogueo policy„ÄÇ

 which has chosen the dialogueog Act to generate and chosen some attributes like slots and values that the planner wants to say to the user„ÄÇ

 either to give the user an answer or as part of a confirmation strategy„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_8.png)

So here are some sample input outputs for the sentence realization phase„ÄÇSo in this first example„ÄÇ

 the Content Planner has chosen the Dialog Act recommend and some particular slots„ÄÇ

 the name of the restaurant Omi D and the neighborhood and the cuisine„ÄÇ

 and the goal of the sentence Realr is to generate a sentence like number one or number two here by training on many such examples of representation and sentence pairs from a large corpus of labeled dialogues„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_10.png)

Training dataÔºå howeverÔºå is hard to come byÔºå we're unlikely to see every possible restaurant with every possible attribute in the many different worded sentences„ÄÇ

So it's common in sentence realization to increase the generality of the training examples by delexicalization Dlexicalization is the process of replacing specific words in the training set that represent slot values with a generic placeholder token representing the slot„ÄÇ

üòäÔºåSo we can delexicalize both of these two sentences by replacing OmidiÔºå midtown and French„ÄÇÊàë‰∫Ü„ÄÇ

Restaurant name is in neighborhood and serves cuisine food„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_12.png)

NowÔºå mapping from frames to delexxiicalized sentences can be done by encoder decor models trained on large hand labeled corpora of task oriented dialogue„ÄÇ

 The input to the encoder is a sequence of tokens that represent the dialogueo Act and its arguments„ÄÇ

 So the dialogueo Act recommend and the attribute value pairs„ÄÇService decent cuisineÔºå no„ÄÇ

 might be represented as just a flat sequence of tokensÔºå each map to a learned embedding„ÄÇ

And the encoder reads all the input slot value representations„ÄÇ

 then the decoder outputs the following delexxiicalized English sentenceÔºå name has decent service„ÄÇ

 and then we can use the input frame from the content planner to relexxiicalize„ÄÇ

 replacing restaurant name with OmiDÔºå resulting in OmiD has decent service„ÄÇ

It's also possible to design NLG algorithms that are specific to a particular dialogue act„ÄÇ

 for exampleÔºå consider the task of generating clarification questions in cases where the speech recognition fails to understand some part of the user's utterance„ÄÇ

While it's possible to use the generic dialogueog ActÔºå rejectÔºå like please repeat„ÄÇ

 or I don't understandÔºå we can do something more targeted„ÄÇ For exampleÔºå here„ÄÇ

 the system reprises the words going and on the fifth to make it clear which aspects of the user's turn the system needs to be clarified targeted clarification questions can be created by rules such as replace going to unknown word with going where„ÄÇ

Or by building classifiers to guess which slots might have been or misrecognized in the sentence„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_14.png)

We've now seen all the pieces of the dialogue state architecture„ÄÇ



![](img/729f491a52ff62cc3329b87f3c71d216_16.png)