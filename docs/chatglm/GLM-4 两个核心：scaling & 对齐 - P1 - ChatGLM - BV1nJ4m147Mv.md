# GLM-4 两个核心：scaling & 对齐 - P1 - ChatGLM - BV1nJ4m147Mv

那么很荣幸能代表团队来给大家分享，我们恰G近两年的一些进展，随着CHAG，随着CHAGBT和GM4的，GPT4的发布以来呢，呃引领了大模型的又一轮热潮，那么与此于此。

与此与此相伴的是大模模型的算力迅速的增长，那么GBT2019年发布的gt2，只有1。5B的参数，那么到了GPT3就有1750亿的参数，那么谣传说GBT4呢，具有着1。8万亿的这样一个参数，那么可以说呃。

单模型的参数量，或者说计算量，依然承认是每年十倍的这样一个增长的趋势，那么我，那么我们为什么要追求这样一个参数量增加呢，我们可以从右边这个图中看到，这是谷歌的一项研究。

他在新算符和新算符定义算术和国际音标翻译，两个两个具有挑战的任务中做了一系列实验，可以看到从10B到1B规模的模型呢，几乎没有任何性能，而当模型的规模扩展到10B到一，百B规模的时候呢。

模型的性能出现了快速涌现的这样一个现象，我们把这种效应叫做模型性能的涌现效应，那正是这种从量变到质变这样一种勇气能力，那正是我们去扩扩增我们的计算量，去我们做scaling的这样一种。

关键的一个因素所在，那么如果我们把现在的现在，现在现有的一些经典的模型去列成一张表格，我们就会看到，sky仍然是提升我们模型性能的一个有效途径，我们去对比我们的GBT3模型，和这130B两个模型。

我们可以看到，这两个模型的总的计算算力大致相同，因此他们在mu数据集上，这个表现也大致是相同的，然而并非所有的skinny都是最有效的，我们可以看到，pm540B模型，和LAMQ70B两个模型的对比。

那么怕他们判540B模型的算力呢，几乎是拉满Q70B模型的三倍，但是他们在MU数据集上，准确率就差不多是相同的，那我们认为呢在模型容量足够的情况下呢，我们有效的学习越多的高质量的数据。

我们的性能模型的性能就会越强大，那我们既然团队在近两年来呢，也是不断的在sky方面进行了探索，那么从最早的2020年来，我们就是做GM系列的模型，那么在2021年，我们也是开源了gm10B的模型。

那么一直到2022年，我们也是开源了，既然我们130B系列的模型，知道之后的G7GM2，恰gm3，都是我们团队不断的在sky方面进行了，进一步的探索，提升了模型的这样一个基座能力。

那么光有了基座模型可能还不够，那我们大模型最终是要满足人类的意图，去完成人类的任务，那么从GBT3到这个chat GB t，关键的步骤并不在于说机动能力的提升，而在于我们去更好的对模型进行了对齐。

使得它能够更好地理解人类的意图，那么呃随着恰gm基座模型的不断提升，垂直走，恰gm130P，MU只有44%左右的性能，乃至我们恰gm4模型，现在MU能够达到81。7%的性能。

我们的模型的对齐能力也在不断的获得提升，我们最早的一代模型，我们在模型的基座基础之上呢，我们进行了初步的人类技术，人类的意图对齐，我们的模型从机构从基座模型一个问他问题，可能只会复读你的问题的。

一个看起来有点傻的模型，变成一个可以进行流畅对话的，一个人工智能助手，那我们二代的TGI模型呢，则是解锁了32K的常温理解能力，使得我们的模型呢可以去支撑像PDF阅读。

像那个常温长文档解读这样一系一系列的呃，下游的应用，那么CHARGM3代的模型呢，则是进一步引入这样一个函数调用的能力，使得我们的模型首次能够去和外界的API，进行一些初步的交互。

那么基于我们GM4强大的机动能力呢，我们也是进一步的去解锁了，我们128K长，下上长上下文上的复杂点的能力，也就被称为我们CHARGM4auto s模型，也我们一般也将称为autos系统。

那么这个autos系统的总体的架构图，大概如下所示，那么基于我们GM4的强大的基座能力，加上它比较强大的工具调用能力，加上一个128K的长下下文，我们的模型呢能够处理非常复杂的呃，用户的任务需求。

当用户提出它的任务需求以后呢，我们的模型会智能的分析进行进行工具的调用，当然如果不需要工具调用，模型呢也会正常的进行的回复，那么相比于普通的函数调用，不同的是呢，我们的模型可以呃智能的规划。

并且迭代的去交互，我们的这样一个工具调用，可以进行多轮这样一个工具调用，那么同时模型也可以进行多工具的这个调用，最终的目的呢是，我要完成这个用户的这样一个需求，那么以上说的那么多，可能还稍微有一点抽象。

那么我们用这个gm4，AUTOOLS这个网页浏览器的例子，来给大家详细讲解一下，我们这个叫M4autos的，这个复杂的这样一个交互能力，那么我们呢比如说我们的传统的这个，基于检索生成的RG方法呢。

通常是将用户输入的这个prompt呢，经过一个检索器模块，而这个检索模块呢生成检索到相关的内容，然后给模型，然后模型去综合这个参考信息和，任务的和用户的输入去输出了相关的回复。

那么呃对于大部分的一个正常的case来说呢，这个传统的RG已经可以表现的很好了，但是对于一些比较复杂的场景，比如说多跳的去问答的场景呢，疑似检索可能没有办法去检测到，比较有意义的信息。

此时模型呢并没有办法从参考信息中得到，比较有意义的回复，那么此时呢，传统的RG方法并不能让模型和RNG，这个检索这个模块进行再次的这个交互，也就是说，传统的RG模块呢，还是有一个比较大的局限性的。

那么我们的autos高级联网功能呢，则是可以呃，模型直接的去接受用户的这样一个任务，他可以去自行的规划检索子任务，然后自行的选择信息源，并且自行的与信息源交互，同时呢。

根据任务的进度去迭代获取这样一个信息，那么使得我们的模型的这个强大的信息，信息收集能力变得更加强大，那么我们的benchmark上，benchmark上也可以看到呢。

我们gm4的这样一个加上gm4的这样一个，高级联网的功能呢，相比于我们GM3的这个，传统的检索生成方案呢是有非常大的提升，同时呢相比于GBT4的那个web browsing。

功能呢也是有一个比较明显的这样一个优势，那么这是一个那么展示这样一个，我们这个autos bring能力的，一个多跳的能力的一个case。



![](img/36205b00817753cf5caa868e616ecccf_1.png)

呃，这个case是问我要去参加这个2023年CCF，中国开源大会。

![](img/36205b00817753cf5caa868e616ecccf_3.png)

当地当天的天气如何，那么要想解答这个case，传统RG模块拿到这个query，他是很难去一跳就解锁出来用户想要的答案的，那么我们的这样4autos模型呢，可以将它分解为两个query，我们先去检索呃。

CCM开完大会的日期和地点，并且拿到我们这个日期是10月21号，以及地点是长沙，然后同样的我们去模型综，综合到了这样一个两个信息，我们就可以去回答出呃，用户想要问的这样一个信息。

这就是我们GSOPPOSE啊去采用一个网页浏览，进行，在这个网络环境中进行一个，复杂交互的这样一个例子，那么gm4呢同样也引入了这样一个代码解释器，这样一个功能，现在呢已经有大量的这个研究表明了。

即使是GBT4，也并没有很很很好的能做到这样一个多数加减，乃至是更不及说是我将做一个复杂的这样一个，计算的这样一个能力，那么我们呢gm4的autos模型呢，可以通过调用这个Python解释器，同时呢。

呃通过一种扬长避短的方式来进行模型呃，去解决模型无法调用的这样复杂计算，从而提高呢模型的数学能力，我们可以从by mart上看到呢，我们的gm4加上这个代码解释器的autos能力呢。

在各个数学班级Mark上基本上都拿到了第一梯队，同时呢相比于GBT4没有加代码解释，这个功能呢其实是有着非常明显的一个提升，其实可以看到用这个代码解释，去解这样一个数学题。

解这样一个数学计算的这样一个思路，其实是能够取得一个非常大的这样一个，性能收益的，我们没有必要让一个呃不太本就不太擅长，直接做计算的一个语言模型呢，去直接做这样一个计算的这样一个任务呃，这是呃。

这个我们刚才介绍了一个网页浏览，和这样一个代码解释器的这样一个工具，那么我们同时呢我们的autos模型可以连，同时联合多个工具进行调用，那么这是一个比较复杂的case。

这个case是说呢啊这pi去年公告的披露，中国P过多少融资，并且要计算最新汇率下约合多少美元，那么这个query企业是比较复杂的模型，就要去搜索去年公告中披露多少融资，又要去搜索我当天的最新汇率。

用户问的这一天的最新汇率是多少，同时还要能进行正确的计算，将人民币转换成美元，那我们可以看到我们的AUTOOLS模型呢，能够很完美的进行执执，执行了两个搜索指令，同时搜出了这个融资额和这个美元的金额。

并且是调用了这个代码的解释器，进行了一个计算，我们可以看到这个计算结果是准确无误的，这也展现出了我们这个autos模型，这样一个，一个是将计算转转变成了一个。

Python解释器调用的形式来避免计算的误差，另外一个就是我们可以通过网页搜索去结连，去结合掉，去去解决掉用户比较复杂的一些需求，去解决问题，那么这个case呢是呃，我们在去年10月份的时候。

就已经上线了这个三代模型，上线了这样一个数据分析功能，那么联合起网页搜索功能呢，我们的模型其实可以进行一些更复杂场景下的，这样一个代码解释，比如说我问他查询一下今年的GDP。

并且分析一下今年哪些年份中GBT下降了啊，并且去画折线图，要求要求将年份标红，那我们的模型呢可以自动的去搜索这样一个，今年的GBTGDP的一个信息啊，并且呢去调用这个代码解释器功能，去去去去呈现出来。

去分析，并且呈现出来我们这样一个用户需求，要画的这样一个折线图，我们可以看到通过这样一个AUTOOLS，是一个多工具联合的那个能力，相比于呃单个模型做代码生成的，是可以去联合多个工具。

去实现更复杂的这样一个用户需求的，那么恰恰M4auto s模型的一呃，最后也跟这个最新的一代的这个，cos view模型联合了呃，相比于传统的这样一个单轮绘画呢，我们的模型就可以实现。

结合上下文的这样一个哎这个互动创作，那其实原理是其原理是说呃，我的模型在呃进行一次呃co view生成的时候呢，他会把这个prompt留在他的这个对话历史中，然后当模型进行下一轮提问的时候呢。

模型会自主判断这一轮是否是需要用户提出的，一个呃画图这样一个请求，那么如果不是的话，它会自动的啊走正常的这样生产流程，如果是的话呢，他会去根据上一轮的模型的这样一个，画图的prompt去智能的去修改。

按照用户的需求去修改这个画图的prompt，从而去得实现一个结合上下文的这样一个，AI绘图创作这样一个能力，那么我在这个例子中呢是呃，首先是要求是画一个这个，开发者大会的这样一个场景。

然后是要求不断的去呃修改我的需求，比如说我现在是变成CEO在讲了，比如说我现在是最后大家画一张合影，那么我们的AUTOOS模型能够很好地理解，这个多轮的这样一个绘画的需求。

并且最终呈现出了一个具有故事感的这样一个，连续的一个AI创作，那么这个case呢也是刚才张鹏总演示的一个case，就是呃我要先先让这个呃模型画一个科技，然后呢我不断的让它跑的越来越快，越来越快。

嗯可以看到这个模型呢能够很好的理解我的，尊重这样一个指令，从原来的一个比较呃可爱的柯基小狗，然后变得跑的越来越快，可以看到这个从背景中的加了Q越多的虚化，然后最后呢甚至嗯都有点虚拟的这样一种感觉。

也就是说我们GM4呢，能够去针对用户的需求了，去进行一个这个画图，prom的，基于上一上下文的这样一个problem的修改，能够就能够实现很很复杂的这样一个创作的，这样一个需求。

那么呃呃我们的这个coco view的生成模型呢，也可以去联合一我们这样一个网络浏览，比如说我让他问这个拆解，拆，那个2024大部队的这样一个宣传语是什么，并且画一幅图。

所以表示这个去突出这个宣传语中的场景，那么我们的模型呢能够自动的去联网搜索，这个呃宣传语的内容，并且呢根据我这个宣传语的内容去呢，描绘出我这样一个呃，嗯符合这样一个主题的，这样一个一个一幅图片来。

那这也是体现出了我们一个autos模型，一个多工具联合，并且去根据呃上一轮搜索的内容，去智能的生成下一轮这样一个呃，画图的这个prompt这样一个能力。

然后呢嗯以上就是我介绍的一个关于gm or two的，是你的一些一些情况，然后呢欢迎大家立即下载这个质朴清扬，去试用gm4OTT这样一个模型，然后感谢大家的观看哦。

