- en: 【双语字幕+资料下载】“当前最好的 TensorFlow 教程！”，看完就能自己动手做项目啦！＜实战教程系列＞ - P16：L16- 自定义训练循环 -
    ShowMeAI - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】“当前最好的 TensorFlow 教程！”，看完就能自己动手做项目啦！＜实战教程系列＞ - P16：L16- 自定义训练循环 -
    ShowMeAI - BV1em4y1U7ib
- en: What is going on guys hope you're doing freaking awesome in this video I'm going
    to show you how to do training loops from scratch。![](img/38a145700a6404a2026fbca3d7269917_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大家好，希望你们过得非常棒。在这个视频中，我将向你展示如何从零开始实现训练循环。![](img/38a145700a6404a2026fbca3d7269917_1.png)
- en: '![](img/38a145700a6404a2026fbca3d7269917_2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_2.png)'
- en: So this means that we're no longer using model。fi， but rather we're doing everything
    by ourselves from scratch if you're familiar with coding and Pythtorch then this
    is going to be more how you're used to training networks but anyways let's get
    started and we aren't going to do anything complicated in this video in terms
    of what we're going to train on and the data and so on。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们不再使用`model.fi`，而是完全从头开始自己做。如果你对编码和Pythtorch熟悉，那么这将更符合你训练网络的习惯。不过，让我们开始吧，在这个视频中，我们不会在训练内容和数据等方面做任何复杂的事情。
- en: the point is just to show you the general structure of how it looks like。So
    the starter code right here is just some basic imports that you've seen in previous
    videos。 we're going to use Tensorflowlow data sets， so if you haven't watched
    that video then it's going to be in the top right corner。So we're loading the
    Ms data set right here so we have a training and the test set and then we're just
    so we have a function for normalizedized images and all of this is from that video
    just copy pasted and then we have some very very simple model right here。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是向你展示它的整体结构。这里的启动代码只是一些你在之前视频中见过的基本导入。我们将使用`Tensorflowlow data sets`，所以如果你还没看过那个视频，可以在右上角找到。我们在这里加载`Ms
    data set`，所以我们有训练集和测试集，然后我们还有一个用于标准化图像的函数，这些都是从那个视频复制粘贴过来的，然后我们这里有一个非常非常简单的模型。
- en: just some one convolutional layer and then one dense layer and let's do layers
    that dense here just like that and then so then let's get started and what we're
    going to do is that first of all we're gonna have some metric so let's do accuracy
    metric is a ks do metrics dot our。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 只需一个卷积层和一个全连接层，然后我们在这里添加全连接层，就像这样，然后我们就可以开始了。首先，我们需要一些指标，所以让我们设置准确率指标，这是`ks
    do metrics dot our`。
- en: '![](img/38a145700a6404a2026fbca3d7269917_4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_4.png)'
- en: Categorical accuracy。And then let's do first， let's do the training loop。So
    the first thing we're going to do is we're going to train it for a number of epochs。
    so we're going to train it for epochs is5 in this case。 So what we just do is
    we we write for epoch in range epochs。Or maybe we should call it。😔，Num epoch。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 分类准确率。接下来，我们先进行训练循环。首先，我们将训练若干个周期。在这种情况下，我们将训练`epochs`为5。我们只需写`for epoch in
    range epochs`，或者我们可以称它为😔，`Num epoch`。
- en: So nu epoch right there。😔，And then we could do print。Just。To print。Slash n and
    then start of training epoch。And then， we could do。I we can do it like this epoch。Now
    it's do F string。And so then we're going to iterate through all of the batches
    in our training。 And so we're going to do for batch index and then。X batch comm
    a Y batch in enumerate。AD train。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 所以就在这里进行`nu epoch`。😔 然后我们可以打印。只需打印。换行，然后开始训练周期。接着，我们可以这样做：`epoch`。现在我们使用F字符串。接下来，我们将遍历训练中的所有批次。我们将使用`for
    batch index`然后`X batch comm a Y batch in enumerate AD train`。
- en: Alright， so we're going to go through the strain for a number of epochs。 So
    right here we're going to first of all， write the width Tf gradient tape。As tape。
    And this is for recording all of the operations that we're going to do in the
    forward propagation so that we can then do back propagation for the the model
    weights。 So we're going to do Y prediction is model。X batch， and then specify
    training is true。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们将进行若干个周期的训练。在这里，我们首先写`with Tf gradient tape`作为`tape`。这用于记录我们在前向传播中要进行的所有操作，以便后续进行模型权重的反向传播。我们将进行`Y
    prediction is model.X batch`，然后指定`training is true`。
- en: Then we're going to do loss is loss function right that we specified over here。And
    we're going to send in the y batch， the true labels， and then the y predictions。
    the one we just calculated for from forward propagation。All right。 so then we
    have those under that tape， then we can do gradients our equal tape dot gradient。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将计算损失，使用我们在这里指定的损失函数。我们将输入`y batch`，真实标签，以及`y predictions`，就是我们刚刚通过前向传播计算得到的。好的，这样我们就有了那些在`tape`下的内容，然后我们可以计算梯度`our
    equal tape dot gradient`。
- en: And then we specify the loss and then model our trainable weights。So we basically
    want the gradients of the loss with respect to trainable parameters。Then or the
    trainable weights rather。 And then we're going to do optimizer。That apply gradients。
    We can do zip gradients， model the trainable weight。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们指定损失，然后是模型我们的可训练权重。所以我们基本上想要损失对可训练参数的梯度。然后或者说是可训练权重。然后我们将进行优化器。应用梯度。我们可以
    zip 梯度，模型可训练权重。
- en: And then we're going to do accuracy metric dot update state。Why batch and then
    why prediction。Just so that we have a sense of what the accuracy was of that epoch。So
    at the end here。 we're going to do training accuracy is equal to accuracy metric
    to result。 and then we could print that so we could do accuracy over。Epoch， and
    then。We can just do。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将进行准确度指标 dot 更新状态。Y batch 和 Y 预测。这样我们就能了解那个 epoch 的准确度。到这里结束。我们将做训练准确度等于准确度指标的结果。然后我们可以打印，这样我们就可以处理
    epoch 的准确度，然后。我们可以直接做。
- en: Train accuracy like that。And then we could reset the accuracy metric so that
    it's going to be zeroed for the next epoch。 So accuracysymmetric dot reset states。And
    that's it for the training loop。 so that's that's how it would look like it's
    very similar to the last video where we went through how to customize model。 fit，
    except now we're just removing the model that fit and we're just adding a loop
    here for the number of epochs that we want to train。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练准确度就是这样。然后我们可以重置准确度指标，以便它在下一个 epoch 时为零。所以 accuracysymmetric dot 重置状态。这就是训练循环的内容。这看起来非常类似于我们在上一个视频中讲解如何自定义模型的过程，只不过现在我们只是去掉了模型的拟合，而是为我们想训练的
    epoch 数添加了一个循环。
- en: And then all we want to do is I guess。So test loop。 so this is for the training
    and then we're going to want to have a test loop to evaluate our model。And then
    we don't need to run it for a couple of epochs。 we could just run through the
    data set once。 so we're going to do batch index and then X batch。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们想做的就是，我想。测试循环。这是用于训练的，然后我们将需要一个测试循环来评估我们的模型。我们不需要运行几个 epoch。我们可以只运行一次数据集。所以我们将做批次索引和
    X batch。
- en: Y batchge enumerate DSs test and I guess right now we're not using the batch
    index。 but I mean you could So I guess you could just iterate through the DSs
    test as well there's no point of doing the enumerate。 but sometimes you want the
    batch index。Anyways。We don't need to do gradient tape。 We're not going to collect
    the gradients。 So we're just going to do y prediction in this model of X batch
    training equals true and then accuracysymmetric dot update。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Y batchge 列举 DSs 测试，我想现在我们并没有使用批次索引。但我的意思是，你可以。所以我想你也可以遍历 DSs 测试，没有必要做 enumerate。不过有时你会想要批次索引。无论如何。我们不需要使用梯度记录。我们不会收集梯度。因此，我们将在这个模型中做
    y 预测，当 X batch 训练等于真时，然后 accuracysymmetric dot 更新。
- en: State Y badge， and then Y prediction。Then in the end we could do train accuracy
    is accuracysymmetric dot result。 right same as we did right here。And then we could，
    I guess we could print accuracy over test。Set。Then we could just write training
    as here。And then in the end， we could again， reset it。We don't have to do this
    though， since that's the last thing we're going to do。But anyways。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 状态 Y badge，然后 Y 预测。最后我们可以做训练准确度等于 accuracysymmetric dot 结果。对，就像我们在这里做的一样。然后我们可以，我想我们可以打印测试集的准确度。然后我们可以像这里一样写训练。最后，我们可以再次重置。虽然我们不必这样做，因为那是我们要做的最后一件事。不过无论如何。
- en: that's how it looks like if you want a training loop and a test loop， of course
    you can also。 I mean， you could put this right here in a function like define
    train or something。 and then you could you know for epoking range of you could
    just call that function。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要一个训练循环和测试循环，它看起来就是这样，当然你也可以。我是说，你可以把这个放在一个像 define train 的函数里。然后你可以，比如说，按范围的
    epoch 只需调用那个函数。
- en: '![](img/38a145700a6404a2026fbca3d7269917_6.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_6.png)'
- en: '![](img/38a145700a6404a2026fbca3d7269917_7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_7.png)'
- en: Train 1 epoch， maybe。And then run run it。So you know you could think of the
    structure of you could think of how you want to structure this。 but this is the
    fundamentals of how you do a training loop。 it's very simple we've done it in
    the most simple way that we can and of course if you're doing something more complicated
    like generative adversary networks or GANS。 then it's going to look more complicated
    than this。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 训练1个周期，也许。然后运行它。所以你知道你可以思考一下你想如何构建这个结构。但是这就是训练循环的基本原理。这非常简单，我们以最简单的方式实现了它，当然，如果你在做一些更复杂的事情，比如生成对抗网络或GAN，那么它看起来会比这个复杂得多。
- en: but it's still going to be a fundamentally the same method and I think if you
    sort of understand this basic layout then and then when do more complicated things
    it's going to help you and understand it general structure。All right， so first
    of all， we should run this and make sure that it works。And it doesn't。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但基本方法仍然是相同的，我认为如果你理解了这个基本框架，那么在处理更复杂的事情时，这将帮助你理解它的整体结构。好的，首先我们应该运行这个并确保它能工作。但它没有。
- en: So it has no attribute gradients。 that's because we want to have a tap dot gradient。All
    right。 and as we can see it makes sense it's training and this works。So yeah。Anyways。
    that's it for this video， hopefully you found this useful if you have any questions
    then leave them in the comment section below。 I think I said thank you for watching
    but thank you for watching and I hope to see you in the next video。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它没有属性梯度。这是因为我们想要一个tap dot梯度。好的。正如我们所看到的，这很有道理，它正在训练并且有效。所以是的。无论如何，这就是本视频的内容，希望你觉得有用，如果你有任何问题，请在下面的评论区留言。我想我之前说过感谢观看，但谢谢你观看，希望在下一个视频中见到你。
- en: '![](img/38a145700a6404a2026fbca3d7269917_9.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38a145700a6404a2026fbca3d7269917_9.png)'
