# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P23ÔºöL4.2- KerasÊûÑÂª∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ§öÁ±ªÂàÜÁ±ªÂπ∂Áî®ROCÂíåAUCËØÑ‰º∞ - ShowMeAI - BV15f4y1w7b8

HiÔºå this is Jeff HeatonÔºå welcomelcome to applications of deep neural networks with Washington University In this video I'm going to show you how to do both binary class and multi class classification„ÄÇ

Neurural networks with Kias for the latest on my AI course and projects„ÄÇ

 click subscribe and the bell next to it to be notified of every new video In the next two videos„ÄÇ

 we're going to look at classification and regression„ÄÇ This video focuses on classification„ÄÇ

 We subdivide this into two parts„ÄÇ There's binary classification„ÄÇ

 and then there's multiclass classification„ÄÇ

![](img/0c3de78b0d0924709e45c8de93aa7c5d_1.png)

We'll start by looking at binary classificationÔºå binary classification„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_3.png)

We're going to look at rock charts and see how to measure false positivesÔºå false negatives„ÄÇ

 and look at the special ways that we evaluate binary classification„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_5.png)

Very often you can think of this as a medical test„ÄÇ

 so we're going to look at the Wisconsin breastreast cancer databaseÔºå it has measurements of tumors„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_7.png)

And then a target column that says if they're malignant or benignÔºå these are all malignant„ÄÇ

 but there's also beesÔºå which are benign„ÄÇ We're going to start by looking at how we would measure the success of a model based on this with ature Now you could just do accuracy you could say I am going to calculate have the neural network predict malignant or benign for each of these„ÄÇ

 and it will simply come back with a percent„ÄÇ It got 90% correct or it got 70% correct„ÄÇ However„ÄÇ

 that's only one side of the of the coin„ÄÇ You might care how many times it was wrong when it said somebody had a cancerous tumor or you might care how many times it was wrong when it said somebody did not because those are two completely different things and you may want to calibrate differently„ÄÇ

 It may be much worse for somebody who falsely was„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_9.png)

Told they did not have cancer to forego medical treatment„ÄÇ

 then simply doing extra medical treatment on somebody who did not have a disease„ÄÇ

Or the flip could be true if the treatment is particularly horrendous for the individual„ÄÇ

 so for rock curvesÔºå we look at false positives and false negatives„ÄÇ

 a false positive is when something came back positive„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_11.png)

But it was not false negative is when something came back negative„ÄÇ

 but it was not then there's also the true positives where the test truly identified positive or true negative where it truly identified negative true positive where it truly identified positive and true negative where it truly identified negative there's other names for these type 1 and type 2 error also sensitivity and specificity sensitivity is how good the model is at predicting that you do have the condition or positives correctly specificity is how good the model is at detecting if you don't have the condition accurately and taken together both of those are just the overall accuracy typically for some of these we need to define a cutoff and this is where rock charts come and come into play a cutoff might be because most of these most of these tests will come back with some sort of number„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_13.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_14.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_15.png)

This is the output from your from your output neuron maybe zero means it's somewhat on the fence„ÄÇ

 maybe a high number means that you are positiveÔºå maybe a negative number means your negative and you have to decide where you're going cut that off you may not cut it off just at zero it may not be it may not be even or if you want to wait towards you prefer false positives or you prefer false negatives obviously prefer neither but if you have to have one would you prefer false positive or false negative then you can optimize your threshold towards sensitivity or specificity so I'm going to run this block of code this block of code is not really that important it's just used to display this diagram now this diagram shows what the output of your neural network might look like maybe this neural network outputs zero if it's really not that sure if your negative or positive for the condition and„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_17.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_18.png)

Puts a negative value if if you're more negative so you don't have the condition and it outputs positive if you more likely do have the condition now these lines specify where you might set your cut point or your threshold when you move that line you're tuning the sensitive of your model that is how you are balancing between false alarms and it actually catching cases where where it truly was positive if you put your line here„ÄÇ

 you're making this very sensitive if you set your line here you're making it very specific the reason that is if you make it sensitive„ÄÇ

 then you're tuning towards false you're tuning towards getting correct positive result So the entire positive curve is over here if you're tuning towards specific then the entire negative curve is over here obviously you probably don't want to put it either here here you want it somewhere in the middle„ÄÇ

Completely balanced is is right here„ÄÇ So that's an important thing to realize on this„ÄÇ

 You can get a perfect sensitivity or a perfect specificityÔºå but you do very„ÄÇüòä„ÄÇ

Bad results to the to the other side of the coinÔºå if you want to be sure that your that your model is completely sensitive and picks up every case where the person would have the disease simply classify everybody as positive you'll never miss anybody and the same thing for negative„ÄÇ

 but obviously that's not particularly usefulÔºå but that shows the extremes of these two„ÄÇ

Of these two ranges by the way the aes of these the X is the output from the neural network or the test and that's how you read the test as far as negative or positive and then the y is simply how many values we have in each of these categories they're not always normally distributed like that but it makes a diagram look good and this is a classic diagram that you see in statistics by the way„ÄÇ

 if you want to read more or see more about this is is a great Khan Academy video that that my diagram here is very much based on this is also a common interview question in machine learning data science we give you that diagram and we ask you to say okay which of these two lines sometimes will not have the middle line„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_20.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_21.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_22.png)

Is a more sensitive versus a more specific test„ÄÇ So now let's go ahead and we're going to load in the binary data for this test„ÄÇ

 I'm going to run this section that simply loads in the data This is important to see down here where we're preparing X and Y's„ÄÇ

 notice how I do the Y's„ÄÇ This is how you do it for a binary classification„ÄÇ

 I'm mapping the malignance to one and the benigns to0„ÄÇ

 Now we're going to define two functions that we're going to use later„ÄÇ

 I'm not going to go too much into these functions or more along the lines of plotting„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_24.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_25.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_26.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_27.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_28.png)

I can do an entire course on plottingÔºå but this is going to basically draw a rock chart and draw a confusion matrix Both of these are very useful for classification neural networks Now let's look at a rock chart example we're going to have to train a neural network for binary classification„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_30.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_31.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_32.png)

Now for binary classificationÔºå we use binary cross entropy„ÄÇ

 very important and we want to have just the one output Norra like like we've had before for for regression but this is not a regression„ÄÇ

 It looks like a regression and it' it's definitely some similarities but this is only use when you're doing classification with a binary outcome and don't do dummy variables„ÄÇ

 you don't want to do two so that's why up here for the x we did not do dummy or for the y I'm sorry we did not do dummies„ÄÇ

 we simply have a column matrix of zeros and ones„ÄÇ we're going to go ahead and run this we'll use early stopping All right we have early stopped and we'll see more about cross validation in the next module it's a way to be able to get out of sample or results that are not in the training set across the entire data set So let's get our predictions and plot the rock chart All right this is the rock chart so this„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_34.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_35.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_36.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_37.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_38.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_39.png)

Showing basically how your model is performing irregardless of where you set that threshold and looking at the rock chart can„ÄÇ

Some let show you the the overall landscape of how you're predicting on false positives because you've got the false positive rate and the true positive rate„ÄÇ

Where you set the threshold at different value now what you usually want to look for in a rock chart is how close this is down to this dashed line„ÄÇ

 the dashed line just shows random predictions„ÄÇ

![](img/0c3de78b0d0924709e45c8de93aa7c5d_41.png)

So that would be a very inefficient model if you're below this and that can happen„ÄÇ

 your model is even worse than random predictions and that's really bad„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_43.png)

The higher it is to this upper point hereÔºå the more accurate the better your model is you measure the area under the curve if the area under the curve is the whole thing then it's 1„ÄÇ

0„ÄÇ So this area under the curve A you see it's typically called is 1„ÄÇ

0 so that's a perfect nearly perfect model This is not it's in the 99% I think on accuracy and sensitivity and specificity both but this is a relatively relatively easy and quick to train data set for breast cancer So that is binary class classification„ÄÇ

 let's look at multiclass classification here we're going to use that simple data set that that I've given before„ÄÇ

 this is a more difficult data setÔºå so it looks a little more interesting because it gets things wrong Here we're going to build a categorical cross entropy So this is very important„ÄÇ

 This is one of the most common questions that students ask me about all the time in previous semesters„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_45.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_46.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_47.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_48.png)

They'll set up a classification neural network when the data is regression or they'll have a multiclass classification like this and they'll use binary cross entropy„ÄÇ

 you want to use categorical cross entropy because you have a multiclass classification problem here„ÄÇ

And you don't want to have one output neuron you want to have as many output neurons as you have classes„ÄÇ

 so now let's let's go ahead and run thisÔºå it'll train as I recall this gets about a 70% accuracy a little it actually did a little bit above so that's that's that's cool it has to do with the random weights accuracy Yeah„ÄÇ

 it's around 70% is usually what this gets Okay so it trains and the accuracy for this is usually around 70% and you can see it's it's more or less there„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_50.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_51.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_52.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_53.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_54.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_55.png)

At early stopsÔºå we'll calculate the accuracy on that„ÄÇ

 which will be the same value that we had up there„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_57.png)

Accuracy is 70%„ÄÇ We'll go ahead and we'll calculate a log loss„ÄÇ Lo loss is different than accuracy„ÄÇ

 Sometimes the output from accuracy is similar to log loss„ÄÇ However„ÄÇ

 the range is quite different accuracy is  zero to1„ÄÇ

 log loss is0 to usually around three or four is about the highest I've seen these„ÄÇ

 I've never really looked at where the actual upper limit was was for that if you're above about one or two and log loss' you're in trouble„ÄÇ

 So let's calculateÔºå let's see how we would actually calculate the log loss„ÄÇ

 we'll do our prediction hereÔºå and we'll use nuumpy to to calculate it„ÄÇ The log loss is 0„ÄÇ74„ÄÇ

 which is not horribleÔºå but it's not perfectÔºå perfectfect as  zeroÔºå of course„ÄÇ

 that's how you calculate it„ÄÇ that's pretty much the same call almost as accuracy except you're doing log loss„ÄÇ

 You're passing in the Ys that you know are correct in your predictions and it calculates it for you„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_59.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_60.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_61.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_62.png)

What is different about log lossÔºå thoughÔºå than accuracy is it takes into account confident the neural network is in wrong answer„ÄÇ

 So here are the outputs from the predictions„ÄÇ So each row is one prediction„ÄÇ

 Each column is one class that it was trying to predict on„ÄÇ

 We can look at the bottom one because I multiplied it by 100„ÄÇ

 And this is essentially the predictions„ÄÇ So it's saying that with 70% likelihood„ÄÇ

 it is the third classÔºå not 100% sure it's it's also thinking it might be the second or the fourth one as well„ÄÇ

 So the way that log loss works is we tally up a bunch of log values for each of these„ÄÇ

 And we look at so here in this caseÔºå if this was the correct valueÔºå it is going to get the log of 0„ÄÇ

7 added to„ÄÇThe accumulator that it's going to eventually take the average of the negative of that log is the logs are negative„ÄÇ

 So if you think about itÔºå if this was in the trainingÔºå this would have been a one„ÄÇ

 we would have put a one here and all these other zerosÔºå that would have been perfect„ÄÇ

 So a log of one is0 the problem with that though if you're wrong„ÄÇ

 And if you're wrong with absolute certainty So if if the first class would have been correct„ÄÇ

 we would have added the log of0 log of0 is negative infinity so you'd be infinitely bad score so it punishes you greatly for overconfidence and a wrong value„ÄÇ

 That is why internally when this is calculated the zeros„ÄÇ

 it's going to move them up a little bit past zero so that your log your score is going to get decimated„ÄÇ

 but it's not going to become an invalid number that's essentially all there is to calculating it„ÄÇ

 you take the correct one and add the negative of that particular log so„ÄÇCloser you get to one„ÄÇ

 the closer your log addition is going to be to zero and zero is good„ÄÇ

 so that's how it punishes you for being overly confident„ÄÇ

 but accuracy is very harsh because there's no partial credit with accuracy if this one can if this next one over here the fourth one was the correct answer and you pick this one inaccur you'd get no points for this and log loss„ÄÇ

 at least you get some points for this because you would add the log of 0„ÄÇ

22 the negative log of that Here's the more formal mathematical equation for how to calculate thatEssential what's happening is all the values going across the entire data set so that's the dividing it by n„ÄÇ

 the negative accounts for the negativeness of log functions„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_64.png)

And then we're essentially looking at using the Y coefficients„ÄÇ

 so the y's are always going to be zero or1Ôºå so the correct one is going to have a one coefficient and all the others is going to have a zero coefficient and cancel out so you basically end up with just one of these and the rest of these canceling out and that does the same thing is effectively taking the log of the correct value„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_66.png)

AgainÔºå this function is not really needed„ÄÇ I meanÔºå you don't need to pay attention to the code„ÄÇ

 We're interested in the graph of the logÔºå so you can see that if you're close to if if you're predicting zero on the correct answer it falls off very„ÄÇ

 very fast so you can see that a negative or that a four is we would take the absolute value„ÄÇ

 a four log loss is really pretty bad you're on your way almost two to the dropoff negative two and I'm sorry2 and one and smaller values below one are the more desirable log results and of course you can't be more correct than one So this this is the entire range of the log function that we use for error evaluation So now let's look at a confusion matrix we previously defined this confusion matrix function here so we're going to plot it now what you want to see in a confusion matrix is„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_68.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_69.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_70.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_71.png)

Strong diagonal so this the diagonal is the cases where it's getting them correct You can see this on the on the confusion matrix down here this is the true label and this is the predicted label where your' and it's a little you usually want to look at the normalized one this other one's just counts but this is the normalized one so this shows you some potential some potential problems with this if the true label is a and it predicted a then that's that's a good thing„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_73.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_74.png)

HoweverÔºå GÔºå for some reasonÔºå was being classified„ÄÇIncorrectly is a a fair amount and you can also see that the predicted values EF and G have considerable problem here„ÄÇ

 so these are some of the things that you would want to look at as you try to optimize this model and your your feature engineering to try to move some of this over to here and that's a confusion matrix confusion matrixes„ÄÇ

 they can be used for binary classification if that's the case then it's just going to be a two by two„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_76.png)

![](img/0c3de78b0d0924709e45c8de93aa7c5d_77.png)

But if you've got multiple classesÔºå then this a good model or a good visualization to look at for your model„ÄÇ

 Thank you for watching this video„ÄÇ In the next part„ÄÇ

 we're going to see how to do the same thing with a regression neural network„ÄÇ



![](img/0c3de78b0d0924709e45c8de93aa7c5d_79.png)

This content changes oftenÔºå so subscribe to the channel to stay up to date on this course and other topics in artificial intelligence„ÄÇ

