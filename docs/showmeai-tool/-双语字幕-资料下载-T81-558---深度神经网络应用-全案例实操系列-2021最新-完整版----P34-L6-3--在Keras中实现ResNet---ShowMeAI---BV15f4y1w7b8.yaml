- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P34ÔºöL6.3- Âú®Keras‰∏≠ÂÆûÁé∞ResNet
    - ShowMeAI - BV15f4y1w7b8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HiÔºå this is Jeff Heaton„ÄÇ Welcome to applications of Deep neural networks with
    Washington University„ÄÇ In this videoÔºå we're going to look at ResnetÔºå which is
    a type of neural network that can be implemented in Carras that makes use of residual
    or what really makes this neural network unique is that it has skip connections
    that don't simply go to the next layer for the latest on my AI course and projects„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Click subscribe and the bell next to it to be notified of every new video„ÄÇ Resnet
    demonstrates really how flexible Keras is„ÄÇ Carras does not have a Resnet layer„ÄÇ
    at least at this point„ÄÇ So we're going to literally construct our own Resnet layer„ÄÇ
    and it's not terribly difficult„ÄÇ There's a function that I found on the Carras
    website that implements that„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: We'll see how Kas can do„ÄÇ This This made a bigÔºå big splash at the I SVC classification
    challenge„ÄÇ This„ÄÇüòä„ÄÇ![](img/c990de25bca059d59d22e195401e0376_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: Use the C far 10 data set and dot just took first placeÔºå beat everything else
    that that was there„ÄÇ This is the paper describing the process„ÄÇ And I took some
    of these images from the paper„ÄÇ First of allÔºå let's just talk about what is a
    residual„ÄÇ So what is a residual neural network„ÄÇ or resnetÔºå residual„ÄÇ If you look
    at Miriam Webster„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: It's a internal artifact of experience or activity that influences later behavior„ÄÇ
    And that's exactly what it is in these these neural networks„ÄÇ It's a skip layer„ÄÇ
    That's another„ÄÇ I like skip layer better than residualÔºå but nonethelessÔºå either
    works equally well to describe it„ÄÇ NowÔºå it's also important to note that it's
    skipping two layers„ÄÇ too normal weighted„ÄÇüòäÔºåRellU layers„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: NowÔºå the re comes in like activation functions are typically applied after the
    weighted layer„ÄÇ So this is pretty normal„ÄÇ It's almost like we take note of what
    the input into this layer was„ÄÇWe fire this other weighted layer„ÄÇBut we don't apply
    the value yet or whatever the nonlinearity is„ÄÇBut we add that X input right into
    here„ÄÇ So whatever was output here gets added to there„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and we have the„ÄÇThe value in some waysÔºå this is a little bit like a„ÄÇ this is
    almost the reverse of a recurrent neural network„ÄÇ And we'll see recurrent neural
    networks very soon„ÄÇ instead of going backwards„ÄÇ like the recurrent neural networks
    doesÔºå this goesÔºå this goes forward„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Why would you want to do such a thingÔºü WellÔºå the short answer is„ÄÇ it gives a
    greater predictive power„ÄÇ and it lets you go muchÔºå muchÔºå much deeper„ÄÇ the paper
    gets into this more„ÄÇ But it shows that as you train deeper and deeper neural networks
    before this„ÄÇYou would get better and better predictive resultsÔºå Then you'd just
    hit a wall„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and your results would start to get worse and worse and worse as you added deeper
    and deeper and deeper layers„ÄÇ This has been experimented with for 100 layerÔºå100
    hidden layers„ÄÇ and beyond„ÄÇ I think there's even been a few of 1 thousand00„ÄÇ that
    has not necessarily shown„ÄÇCompletely promising resultsÔºå but this research changes
    quite rapidly„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: This is what one of these looks like don't worry about the VGG„ÄÇNeural networkÔºå
    that isÔºå I mean„ÄÇ that's more the traditional convolutionÔºå neural network and some
    other„ÄÇKind of tweaks added„ÄÇ added to that„ÄÇ That's basically the competition that
    they were trying to beat for this„ÄÇ this competition„ÄÇ And this is a 34„ÄÇPlainÔºå so
    like we just learned about convolution neural network„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: this is all based on convolutions„ÄÇAnd this is the 34 layer residual„ÄÇ so this
    is really what this looks like„ÄÇYou can see all these skip layersÔºå skip layerÔºå
    skip layer„ÄÇ and so onÔºå and so forth„ÄÇThe different colorsÔºå 64 filtersÔºå 128 filtersÔºå
    256 filters„ÄÇ so on and so forthÔºå and then they finally get into a averaging pool
    SC is fully connected„ÄÇThis„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: the VGG is using several layers of fully connected and the convolutions similar
    to„ÄÇWith pooling„ÄÇ this uses an average pool rather than a max pool kind of towards
    the end„ÄÇ Let's go ahead and look at the code to run this„ÄÇ This is using the Cf
    data set„ÄÇ It needs to download it Now in Google„ÄÇ when you're using Google Coab„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: often you're going to find yourself having to re downloadload this„ÄÇ You want
    to be careful because Google only keeps the stuff that you keep in Google Drive„ÄÇ
    My introductory video on how to use Google Coab explains all of that done with
    that„ÄÇ Now„ÄÇ we're going to grab the data„ÄÇüòäÔºåThat data was stored as a pickle„ÄÇ so
    we're going to„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Extract that data that we just downloaded and prepare it to be trained so now
    that we've downloaded it„ÄÇ let's just go ahead and display it so that we can see
    this is what this code does here„ÄÇ it displays it so that you can see some of the
    samples from this from this data set„ÄÇCarsÔºå dogs„ÄÇ againÔºå predominantly animalsÔºå
    but this isÔºå this is that data set„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: These are some parameters that describe„ÄÇWhat we're doing as far as the implementation
    of this„ÄÇ we're going to use 200 epochs that takes a while to trainÔºå even with
    a GPU„ÄÇ this runs for a couple of hours„ÄÇBtch size of 32 number of classes we pull
    right from the data„ÄÇ it's 10 colors we pull right from the data setÔºå it's three
    channels redÔºå green and blue„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Subtract pixel meaning is that's getting us basically to centering this about
    0„ÄÇ and that helps for predictive accuracy„ÄÇ There are two versions of this of resnet
    Ressonnet version 1 is the original and Resnet version 2 had some improvements„ÄÇ'll
    talk about that later in this video„ÄÇ We are choosing„ÄÇThe depth„ÄÇCalculated on on
    the size of the image and the number of colors„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: We're choosing the depth based on the version and colors„ÄÇ This is a useful function„ÄÇ
    This is following along with the paper„ÄÇ This is the learning rate scheduler„ÄÇThis
    is essentially going to bring the learning rate down as we cross a number of epochs„ÄÇ
    so whenever we change the learning rateÔºå it's reported here„ÄÇThis can be very effective„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: We're using this with the atom training and„ÄÇTypically„ÄÇ you want to decrease
    the learning rate as you go forward„ÄÇ so this demonstrates this technique„ÄÇ you
    might want to make use of this in the Cagle competition or other things„ÄÇ you have
    to experiment with it to see how well it particularly works„ÄÇBy the way„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: all of this data or this code I got from the Kiras website„ÄÇSo this is just examples„ÄÇ
    I've updated it to the latest„ÄÇVersions of Tensorflow and Cars and also reworked
    it a little bit to„ÄÇ I thinkÔºå make it a little more readable and segment it into
    a Jupiter notebook„ÄÇ This essentially creates a resonant layer„ÄÇ So that includes
    the two normal layers and the skip connection„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: It's essentially creating the convolutionÔºå2D layer„ÄÇ It does put a batch normalization
    in there„ÄÇ the batch normalization„ÄÇüòäÔºåIs a good layer that you that you might want
    to use that basically helps to really helps to keep the vanisheding gradient problem
    from being too much„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: too much of an issue„ÄÇ It's normalizing on each batchÔºå each of your mini batches„ÄÇ
    We are also using a special weight initializer called the he normal„ÄÇThis isÔºå again„ÄÇ
    following what the original paper did„ÄÇ We are also using a kernel regularizer
    of L2„ÄÇ also following the paper„ÄÇ This implements a resnet version 1„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: which is primarily what we're dealing with hereÔºå but I included both of those„ÄÇBoth
    the resnet version 1 and 2„ÄÇ this specifies the the input parameterÔºå specify the
    shape„ÄÇ and it is essentially stacking up those layers and culminating with the
    final dense output„ÄÇ It's building those individual resnet blocks„ÄÇ A resnet blocks
    is those two convolution layers stacked between„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So it creates„ÄÇIt creates the two resonnet layers Now„ÄÇ the resonant layers that
    it's talking about above are essentially the two parts of the resonnet block„ÄÇ
    we're keeping track of„ÄÇSo we have Y here„ÄÇ X feeds in„ÄÇ So X is the input„ÄÇ Then
    the second one is feeding to here„ÄÇ This portion here is caught is implementing
    the skip layer„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: FinallyÔºå we do an averaging pool„ÄÇAnd the final dense layerÔºå we do also„ÄÇ I'm
    going to go ahead and run this so that we have it in memory„ÄÇWe do also have a
    second version of ResnetÔºå the primary difference of the full the V2 variant compared
    to V1 is the use of the batch normalization before every layer that„ÄÇCause some
    improvements to it overall„ÄÇ We're dealing mainly with the version one„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but both of them thereÔºå you canÔºå you can try out the two„ÄÇ see the differences
    between the the normalization„ÄÇAt each point or just at the at the end of those
    resnet blocks„ÄÇ Here is where we actually run this„ÄÇ So I get the input shapeÔºå I
    get the train and test„ÄÇIf we want to subtract the pixel mean„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: this is doing that„ÄÇ that centers it about 0 more effectivelyÔºå Typ a good idea„ÄÇ
    We run the ressonnet V1 or V2 depending on what we haveÔºå and we compile it and
    reproduce a summary„ÄÇSo this just builds the neural network„ÄÇ doesn't actually run„ÄÇ
    And it's ready to go„ÄÇ It shows you the entire structure of the network againÔºå
    trying to match the original paper„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: This is where we actually execute and train it„ÄÇ I'm going to run it just so
    that it can be going because this is going to go for a long time„ÄÇ We get the learning
    rate scheduler so this causes it to reduce the learning rate until we plateau„ÄÇ
    So this causes it to reduce the learning rate when we do plateau„ÄÇ If we're not
    using image augmentationÔºå which by the way we areÔºå we do just a normal fit„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Image augmentation can be very useful to letting it learn to not overfit the
    data that it has„ÄÇ This allows it to shift and move about the image somewhat„ÄÇ do
    each of these is just various random sort of transformations that you can do to
    the image to„ÄÇBasically„ÄÇDistord it in various ways as it trains„ÄÇ So it's like it
    gets brand new images each time„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but they're all based on the train set images„ÄÇ It's like you can randomly horizontally
    and vertically flip it„ÄÇ We're not we are flipping it horizontallyÔºå but not vertically
    again„ÄÇ I'm following basically what the Kira's example had set up„ÄÇ So you could
    try some of these other values„ÄÇ It might give you better results„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And you might want to also use the image data generator„ÄÇ which is doing these
    transformations on your own neural networks when you are dealing with image data„ÄÇ
    Then we basically fit it run it„ÄÇ And we re report the lapse time„ÄÇ takes a couple
    of hours„ÄÇ typicallyyÔºå you probably don't even want to try this with a CPU other
    than a GP„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I have not tried running it could be a day„ÄÇ I really have not tried it on CPU„ÄÇ
    Thank you for watching this video in the next video„ÄÇ We're going to look at openC„ÄÇ
    This content changes often„ÄÇ So subscribe to the channel to stay up to date on
    this course and other topics„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c990de25bca059d59d22e195401e0376_3.png)'
  prefs: []
  type: TYPE_IMG
- en: And artificial intelligence„ÄÇ
  prefs: []
  type: TYPE_NORMAL
