- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P34ï¼šL6.3- åœ¨Kerasä¸­å®ç°ResNet
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P34ï¼šL6.3- åœ¨ Keras ä¸­å®ç° ResNet
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonã€‚ Welcome to applications of Deep neural networks with
    Washington Universityã€‚ In this videoï¼Œ we're going to look at Resnetï¼Œ which is
    a type of neural network that can be implemented in Carras that makes use of residual
    or what really makes this neural network unique is that it has skip connections
    that don't simply go to the next layer for the latest on my AI course and projectsã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹ä¸€ä¸‹ ResNetï¼Œè¿™æ˜¯ä¸€ç§å¯ä»¥åœ¨ Keras ä¸­å®ç°çš„ç¥ç»ç½‘ç»œï¼Œå®ƒåˆ©ç”¨äº†æ®‹å·®ï¼ŒçœŸæ­£è®©è¿™ä¸ªç¥ç»ç½‘ç»œç‹¬ç‰¹çš„æ˜¯å®ƒæœ‰è·³è·ƒè¿æ¥ï¼Œä¸ä»…ä»…æ˜¯è¿æ¥åˆ°ä¸‹ä¸€å±‚ï¼Œå…³äºæˆ‘
    AI è¯¾ç¨‹å’Œé¡¹ç›®çš„æœ€æ–°åŠ¨æ€ã€‚
- en: Click subscribe and the bell next to it to be notified of every new videoã€‚ Resnet
    demonstrates really how flexible Keras isã€‚ Carras does not have a Resnet layerã€‚
    at least at this pointã€‚ So we're going to literally construct our own Resnet layerã€‚
    and it's not terribly difficultã€‚ There's a function that I found on the Carras
    website that implements thatã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹å‡»è®¢é˜…å¹¶ç‚¹å‡»æ—è¾¹çš„é“ƒé“›ï¼Œä»¥ä¾¿æ¥æ”¶åˆ°æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚ResNet çœŸçš„å±•ç¤ºäº† Keras çš„çµæ´»æ€§ã€‚Keras ç›®å‰æ²¡æœ‰ ResNet å±‚ã€‚å› æ­¤æˆ‘ä»¬å°†å­—é¢ä¸Šæ„å»ºæˆ‘ä»¬è‡ªå·±çš„
    ResNet å±‚ï¼Œè¿™å¹¶ä¸æ˜¯ç‰¹åˆ«å›°éš¾ã€‚æˆ‘åœ¨ Keras ç½‘ç«™ä¸Šæ‰¾åˆ°ä¸€ä¸ªå®ç°çš„å‡½æ•°ã€‚
- en: We'll see how Kas can doã€‚ This This made a bigï¼Œ big splash at the I SVC classification
    challengeã€‚ Thisã€‚ğŸ˜Šã€‚![](img/c990de25bca059d59d22e195401e0376_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹çœ‹ Keras å¯ä»¥åšåˆ°ä»€ä¹ˆã€‚è¿™åœ¨ I SVC åˆ†ç±»æŒ‘æˆ˜ä¸­å¼•èµ·äº†å¾ˆå¤§çš„è½°åŠ¨ã€‚è¿™ã€‚ğŸ˜Šï¼[](img/c990de25bca059d59d22e195401e0376_1.png)
- en: Use the C far 10 data set and dot just took first placeï¼Œ beat everything else
    that that was thereã€‚ This is the paper describing the processã€‚ And I took some
    of these images from the paperã€‚ First of allï¼Œ let's just talk about what is a
    residualã€‚ So what is a residual neural networkã€‚ or resnetï¼Œ residualã€‚ If you look
    at Miriam Websterã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ C far 10 æ•°æ®é›†å¹¶ä¸”ä»…ä»…å–å¾—ç¬¬ä¸€åï¼Œå‡»è´¥äº†æ‰€æœ‰å…¶ä»–çš„ã€‚è¿™æ˜¯æè¿°è¿™ä¸€è¿‡ç¨‹çš„è®ºæ–‡ã€‚æˆ‘ä»è®ºæ–‡ä¸­æå–äº†ä¸€äº›è¿™äº›å›¾åƒã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬è°ˆè°ˆä»€ä¹ˆæ˜¯æ®‹å·®ã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯æ®‹å·®ç¥ç»ç½‘ç»œï¼Œæˆ–ç§°ä¸º
    ResNetï¼Œæ®‹å·®ã€‚å¦‚æœä½ æŸ¥çœ‹ç±³é‡Œäºšå§†Â·éŸ¦ä¼¯æ–¯ç‰¹ã€‚
- en: It's a internal artifact of experience or activity that influences later behaviorã€‚
    And that's exactly what it is in these these neural networksã€‚ It's a skip layerã€‚
    That's anotherã€‚ I like skip layer better than residualï¼Œ but nonethelessï¼Œ either
    works equally well to describe itã€‚ Nowï¼Œ it's also important to note that it's
    skipping two layersã€‚ too normal weightedã€‚ğŸ˜Šï¼ŒRellU layersã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§ç»éªŒæˆ–æ´»åŠ¨çš„å†…éƒ¨äº§ç‰©ï¼Œå½±å“åç»­è¡Œä¸ºã€‚åœ¨è¿™äº›ç¥ç»ç½‘ç»œä¸­ï¼Œå®ƒå°±æ˜¯è¿™æ ·ã€‚å®ƒæ˜¯ä¸€ä¸ªè·³è·ƒå±‚ã€‚æˆ‘æ›´å–œæ¬¢ç§°ä¹‹ä¸ºè·³è·ƒå±‚ï¼Œè€Œä¸æ˜¯æ®‹å·®ï¼Œä½†æ— è®ºå¦‚ä½•ï¼Œä¸¤ä¸ªæœ¯è¯­éƒ½åŒæ ·æœ‰æ•ˆã€‚ç°åœ¨ï¼ŒåŒæ ·é‡è¦çš„æ˜¯è¦æ³¨æ„å®ƒè·³è¿‡äº†ä¸¤ä¸ªå±‚ï¼Œä¸¤ä¸ªæ­£å¸¸åŠ æƒçš„ã€‚ğŸ˜Š
    RellU å±‚ã€‚
- en: Nowï¼Œ the re comes in like activation functions are typically applied after the
    weighted layerã€‚ So this is pretty normalã€‚ It's almost like we take note of what
    the input into this layer wasã€‚We fire this other weighted layerã€‚But we don't apply
    the value yet or whatever the nonlinearity isã€‚But we add that X input right into
    hereã€‚ So whatever was output here gets added to thereã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæ¿€æ´»å‡½æ•°é€šå¸¸æ˜¯åœ¨åŠ æƒå±‚ä¹‹ååº”ç”¨çš„ã€‚æ‰€ä»¥è¿™å¾ˆæ­£å¸¸ã€‚å‡ ä¹å°±åƒæˆ‘ä»¬æ³¨æ„åˆ°è¿™ä¸€å±‚çš„è¾“å…¥æ˜¯ä»€ä¹ˆã€‚æˆ‘ä»¬æ¿€æ´»è¿™ä¸ªå…¶ä»–çš„åŠ æƒå±‚ã€‚ä½†æˆ‘ä»¬è¿˜ä¸åº”ç”¨è¿™ä¸ªå€¼æˆ–ä»»ä½•éçº¿æ€§ã€‚ä½†æˆ‘ä»¬æŠŠè¿™ä¸ª
    X è¾“å…¥ç›´æ¥åŠ åˆ°è¿™é‡Œã€‚æ‰€ä»¥è¿™é‡Œçš„è¾“å‡ºä¼šåŠ åˆ°é‚£å„¿ã€‚
- en: and we have theã€‚The value in some waysï¼Œ this is a little bit like aã€‚ this is
    almost the reverse of a recurrent neural networkã€‚ And we'll see recurrent neural
    networks very soonã€‚ instead of going backwardsã€‚ like the recurrent neural networks
    doesï¼Œ this goesï¼Œ this goes forwardã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œè¿™ä¸ªå€¼æœ‰ç‚¹åƒã€‚è¿™å‡ ä¹æ˜¯é€’å½’ç¥ç»ç½‘ç»œçš„åé¢ã€‚æˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°é€’å½’ç¥ç»ç½‘ç»œã€‚ä¸é€’å½’ç¥ç»ç½‘ç»œå‘åè¿è¡Œä¸åŒï¼Œå®ƒæ˜¯å‘å‰çš„ã€‚
- en: Why would you want to do such a thingï¼Ÿ Wellï¼Œ the short answer isã€‚ it gives a
    greater predictive powerã€‚ and it lets you go muchï¼Œ muchï¼Œ much deeperã€‚ the paper
    gets into this moreã€‚ But it shows that as you train deeper and deeper neural networks
    before thisã€‚You would get better and better predictive resultsï¼Œ Then you'd just
    hit a wallã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä½ æƒ³è¿™æ ·åšå‘¢ï¼Ÿç®€å•çš„ç­”æ¡ˆæ˜¯ï¼Œå®ƒæä¾›äº†æ›´å¤§çš„é¢„æµ‹èƒ½åŠ›ï¼Œè®©ä½ å¯ä»¥æ›´æ·±æ›´æ·±åœ°è®­ç»ƒã€‚è®ºæ–‡å¯¹æ­¤æœ‰æ›´å¤šè®¨è®ºã€‚ä½†å®ƒæ˜¾ç¤ºå‡ºï¼Œå½“ä½ è®­ç»ƒæ›´æ·±çš„ç¥ç»ç½‘ç»œæ—¶ï¼Œç»“æœä¼šè¶Šæ¥è¶Šå¥½ï¼Œç„¶åä½ ä¼šé‡åˆ°ä¸€ä¸ªç“¶é¢ˆã€‚
- en: and your results would start to get worse and worse and worse as you added deeper
    and deeper and deeper layersã€‚ This has been experimented with for 100 layerï¼Œ100
    hidden layersã€‚ and beyondã€‚ I think there's even been a few of 1 thousand00ã€‚ that
    has not necessarily shownã€‚Completely promising resultsï¼Œ but this research changes
    quite rapidlyã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ä½ æ·»åŠ æ›´æ·±çš„å±‚æ•°ï¼Œä½ çš„ç»“æœä¼šè¶Šæ¥è¶Šå·®ã€‚è¿™å·²ç»åœ¨100å±‚ã€100ä¸ªéšè—å±‚åŠä»¥ä¸Šè¿›è¡Œè¿‡å®éªŒã€‚æˆ‘è®¤ä¸ºç”šè‡³æœ‰è¿‡å‡ æ¬¡å°è¯•è¾¾åˆ°1ä¸‡å±‚çš„æƒ…å†µï¼Œä½†è¿™äº›å¹¶ä¸ä¸€å®šæ˜¾ç¤ºå‡ºå®Œå…¨æœ‰å‰æ™¯çš„ç»“æœï¼Œä¸è¿‡è¿™æ–¹é¢çš„ç ”ç©¶å˜åŒ–å¾ˆå¿«ã€‚
- en: This is what one of these looks like don't worry about the VGGã€‚Neural networkï¼Œ
    that isï¼Œ I meanã€‚ that's more the traditional convolutionï¼Œ neural network and some
    otherã€‚Kind of tweaks addedã€‚ added to thatã€‚ That's basically the competition that
    they were trying to beat for thisã€‚ this competitionã€‚ And this is a 34ã€‚Plainï¼Œ so
    like we just learned about convolution neural networkã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯å…¶ä¸­ä¸€ä¸ªæ ·å­çš„ï¼Œåˆ«æ‹…å¿ƒVGGã€‚ç¥ç»ç½‘ç»œï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ›´å¤šçš„æ˜¯ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œè¿˜æœ‰ä¸€äº›å…¶ä»–çš„è°ƒæ•´ã€‚åŸºæœ¬ä¸Šæ˜¯ä»–ä»¬è¯•å›¾åœ¨è¿™æ¬¡æ¯”èµ›ä¸­è¶…è¶Šçš„ç«äº‰å¯¹æ‰‹ã€‚è¿™æ˜¯ä¸€ä¸ª34å±‚çš„ç®€å•ç½‘ç»œï¼Œå°±åƒæˆ‘ä»¬åˆšåˆšå­¦ä¹ çš„å·ç§¯ç¥ç»ç½‘ç»œä¸€æ ·ã€‚
- en: this is all based on convolutionsã€‚And this is the 34 layer residualã€‚ so this
    is really what this looks likeã€‚You can see all these skip layersï¼Œ skip layerï¼Œ
    skip layerã€‚ and so onï¼Œ and so forthã€‚The different colorsï¼Œ 64 filtersï¼Œ 128 filtersï¼Œ
    256 filtersã€‚ so on and so forthï¼Œ and then they finally get into a averaging pool
    SC is fully connectedã€‚Thisã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€åˆ‡éƒ½æ˜¯åŸºäºå·ç§¯çš„ã€‚è¿™æ˜¯34å±‚æ®‹å·®ç½‘ç»œã€‚ æ‰€ä»¥è¿™å®é™…ä¸Šæ˜¯å®ƒçš„æ ·å­ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™äº›è·³è·ƒå±‚ï¼Œè·³è·ƒå±‚ï¼Œè·³è·ƒå±‚ï¼Œç­‰ç­‰ã€‚ä¸åŒçš„é¢œè‰²ï¼Œ64ä¸ªæ»¤æ³¢å™¨ï¼Œ128ä¸ªæ»¤æ³¢å™¨ï¼Œ256ä¸ªæ»¤æ³¢å™¨ï¼Œç­‰ç­‰ï¼Œç„¶åå®ƒä»¬æœ€ç»ˆè¿›å…¥ä¸€ä¸ªå¹³å‡æ± åŒ–ï¼ŒSCæ˜¯å®Œå…¨è¿æ¥çš„ã€‚è¿™ã€‚
- en: the VGG is using several layers of fully connected and the convolutions similar
    toã€‚With poolingã€‚ this uses an average pool rather than a max pool kind of towards
    the endã€‚ Let's go ahead and look at the code to run thisã€‚ This is using the Cf
    data setã€‚ It needs to download it Now in Googleã€‚ when you're using Google Coabã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: VGGä½¿ç”¨äº†å¤šä¸ªå…¨è¿æ¥å±‚å’Œç±»ä¼¼çš„å·ç§¯ã€‚ç»“åˆæ± åŒ–ï¼Œè¿™ä½¿ç”¨çš„æ˜¯å¹³å‡æ± è€Œä¸æ˜¯æœ€å¤§æ± ï¼Œå°¤å…¶æ˜¯åœ¨æœ€åé˜¶æ®µã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿è¡Œè¿™ä¸ªçš„ä»£ç ã€‚è¿™æ˜¯ä½¿ç”¨Cfæ•°æ®é›†ã€‚å®ƒéœ€è¦ä¸‹è½½ï¼Œå½“å‰åœ¨è°·æ­Œä¸Šä½¿ç”¨Google
    Coabã€‚
- en: often you're going to find yourself having to re downloadload thisã€‚ You want
    to be careful because Google only keeps the stuff that you keep in Google Driveã€‚
    My introductory video on how to use Google Coab explains all of that done with
    thatã€‚ Nowã€‚ we're going to grab the dataã€‚ğŸ˜Šï¼ŒThat data was stored as a pickleã€‚ so
    we're going toã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šå‘ç°è‡ªå·±ç»å¸¸éœ€è¦é‡æ–°ä¸‹è½½è¿™äº›ã€‚ä½ è¦å°å¿ƒï¼Œå› ä¸ºè°·æ­Œåªä¿ç•™ä½ å­˜å‚¨åœ¨è°·æ­Œäº‘ç›˜ä¸­çš„å†…å®¹ã€‚æˆ‘å…³äºå¦‚ä½•ä½¿ç”¨Google Coabçš„ä»‹ç»è§†é¢‘å·²ç»è§£é‡Šäº†è¿™äº›å†…å®¹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¦æŠ“å–æ•°æ®ã€‚ğŸ˜Šï¼Œè¿™äº›æ•°æ®ä»¥pickleæ ¼å¼å­˜å‚¨ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ã€‚
- en: Extract that data that we just downloaded and prepare it to be trained so now
    that we've downloaded itã€‚ let's just go ahead and display it so that we can see
    this is what this code does hereã€‚ it displays it so that you can see some of the
    samples from this from this data setã€‚Carsï¼Œ dogsã€‚ againï¼Œ predominantly animalsï¼Œ
    but this isï¼Œ this is that data setã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æå–æˆ‘ä»¬åˆšä¸‹è½½çš„æ•°æ®å¹¶å‡†å¤‡è¿›è¡Œè®­ç»ƒï¼Œç°åœ¨æˆ‘ä»¬å·²ç»ä¸‹è½½äº†å®ƒã€‚è®©æˆ‘ä»¬å±•ç¤ºä¸€ä¸‹ï¼Œè¿™æ®µä»£ç çš„ä½œç”¨æ˜¯å±•ç¤ºè¿™ä¸ªæ•°æ®é›†ä¸­çš„ä¸€äº›æ ·æœ¬ã€‚æ±½è½¦ã€ç‹—ï¼Œä¾ç„¶ä¸»è¦æ˜¯åŠ¨ç‰©ï¼Œä½†è¿™å°±æ˜¯è¿™ä¸ªæ•°æ®é›†ã€‚
- en: These are some parameters that describeã€‚What we're doing as far as the implementation
    of thisã€‚ we're going to use 200 epochs that takes a while to trainï¼Œ even with
    a GPUã€‚ this runs for a couple of hoursã€‚Btch size of 32 number of classes we pull
    right from the dataã€‚ it's 10 colors we pull right from the data setï¼Œ it's three
    channels redï¼Œ green and blueã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯ä¸€äº›æè¿°æˆ‘ä»¬åœ¨å®ç°ä¸­çš„å‚æ•°ã€‚æˆ‘ä»¬å°†ä½¿ç”¨200ä¸ªè®­ç»ƒå‘¨æœŸï¼Œå³ä½¿ä½¿ç”¨GPUï¼Œä¹Ÿéœ€è¦ä¸€æ®µæ—¶é—´æ¥è®­ç»ƒï¼Œè¿™ä¸ªè¿‡ç¨‹æŒç»­å‡ ä¸ªå°æ—¶ã€‚æ‰¹é‡å¤§å°ä¸º32ï¼Œç±»åˆ«æ•°ç›´æ¥ä»æ•°æ®ä¸­æå–ã€‚å®ƒæœ‰10ç§é¢œè‰²ï¼Œæˆ‘ä»¬ç›´æ¥ä»æ•°æ®é›†ä¸­æå–ï¼ŒåŒ…å«çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé€šé“ã€‚
- en: Subtract pixel meaning is that's getting us basically to centering this about
    0ã€‚ and that helps for predictive accuracyã€‚ There are two versions of this of resnet
    Ressonnet version 1 is the original and Resnet version 2 had some improvementsã€‚'ll
    talk about that later in this videoã€‚ We are choosingã€‚The depthã€‚Calculated on on
    the size of the image and the number of colorsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åƒç´ å‡æ³•çš„æ„æ€æ˜¯è¿™åŸºæœ¬ä¸Šæ˜¯å°†å…¶ä¸­å¿ƒåŒ–åˆ°0ã€‚è¿™æœ‰åŠ©äºæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚ResNetæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼ŒResNetç‰ˆæœ¬1æ˜¯åŸå§‹ç‰ˆæœ¬ï¼ŒResNetç‰ˆæœ¬2æœ‰ä¸€äº›æ”¹è¿›ã€‚æˆ‘ç¨åä¼šåœ¨è¿™ä¸ªè§†é¢‘ä¸­è°ˆåˆ°ã€‚æˆ‘ä»¬åœ¨é€‰æ‹©æ·±åº¦æ—¶ï¼ŒåŸºäºå›¾åƒçš„å¤§å°å’Œé¢œè‰²çš„æ•°é‡è¿›è¡Œè®¡ç®—ã€‚
- en: We're choosing the depth based on the version and colorsã€‚ This is a useful functionã€‚
    This is following along with the paperã€‚ This is the learning rate schedulerã€‚This
    is essentially going to bring the learning rate down as we cross a number of epochsã€‚
    so whenever we change the learning rateï¼Œ it's reported hereã€‚This can be very effectiveã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹æ®ç‰ˆæœ¬å’Œé¢œè‰²é€‰æ‹©æ·±åº¦ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å‡½æ•°ã€‚è¿™æ˜¯éµå¾ªè®ºæ–‡çš„ã€‚è¿™æ˜¯å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚è¿™åŸºæœ¬ä¸Šå°†åœ¨è·¨è¶Šå¤šä¸ªè®­ç»ƒå‘¨æœŸæ—¶é™ä½å­¦ä¹ ç‡ã€‚å› æ­¤ï¼Œæ¯å½“æˆ‘ä»¬æ›´æ”¹å­¦ä¹ ç‡æ—¶ï¼Œéƒ½ä¼šåœ¨è¿™é‡ŒæŠ¥å‘Šã€‚è¿™å¯ä»¥éå¸¸æœ‰æ•ˆã€‚
- en: We're using this with the atom training andã€‚Typicallyã€‚ you want to decrease
    the learning rate as you go forwardã€‚ so this demonstrates this techniqueã€‚ you
    might want to make use of this in the Cagle competition or other thingsã€‚ you have
    to experiment with it to see how well it particularly worksã€‚By the wayã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨åŸå­è®­ç»ƒä¸­ä½¿ç”¨è¿™ä¸ªã€‚é€šå¸¸ï¼Œä½ å¸Œæœ›éšç€è¿›å±•å‡å°‘å­¦ä¹ ç‡ã€‚æ‰€ä»¥è¿™å±•ç¤ºäº†è¿™ä¸€æŠ€æœ¯ã€‚ä½ å¯èƒ½å¸Œæœ›åœ¨Cagleæ¯”èµ›æˆ–å…¶ä»–äº‹æƒ…ä¸­åˆ©ç”¨è¿™ä¸ªã€‚ä½ éœ€è¦è¿›è¡Œå®éªŒï¼Œä»¥æŸ¥çœ‹å®ƒçš„å…·ä½“æ•ˆæœã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ã€‚
- en: all of this data or this code I got from the Kiras websiteã€‚So this is just examplesã€‚
    I've updated it to the latestã€‚Versions of Tensorflow and Cars and also reworked
    it a little bit toã€‚ I thinkï¼Œ make it a little more readable and segment it into
    a Jupiter notebookã€‚ This essentially creates a resonant layerã€‚ So that includes
    the two normal layers and the skip connectionã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»Kerasç½‘ç«™è·å¾—äº†æ‰€æœ‰è¿™äº›æ•°æ®æˆ–ä»£ç ã€‚æ‰€ä»¥è¿™åªæ˜¯ä¸€äº›ç¤ºä¾‹ã€‚æˆ‘å·²å°†å…¶æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬çš„Tensorflowå’ŒKerasï¼Œå¹¶ç¨ä½œè°ƒæ•´ï¼Œä½¿å…¶æ›´æ˜“è¯»ï¼Œå¹¶å°†å…¶åˆ†æ®µåˆ°ä¸€ä¸ªJupyterç¬”è®°æœ¬ä¸­ã€‚è¿™åŸºæœ¬ä¸Šåˆ›å»ºäº†ä¸€ä¸ªResnetå±‚ã€‚å› æ­¤åŒ…æ‹¬ä¸¤ä¸ªæ™®é€šå±‚å’Œè·³è·ƒè¿æ¥ã€‚
- en: It's essentially creating the convolutionï¼Œ2D layerã€‚ It does put a batch normalization
    in thereã€‚ the batch normalizationã€‚ğŸ˜Šï¼ŒIs a good layer that you that you might want
    to use that basically helps to really helps to keep the vanisheding gradient problem
    from being too muchã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåŸºæœ¬ä¸Šåœ¨åˆ›å»ºå·ç§¯2Då±‚ã€‚å®ƒç¡®å®åœ¨å…¶ä¸­æ”¾ç½®äº†ä¸€ä¸ªæ‰¹é‡å½’ä¸€åŒ–å±‚ã€‚æ‰¹é‡å½’ä¸€åŒ–ğŸ˜Šï¼Œæ˜¯ä¸€ä¸ªå¥½çš„å±‚ï¼Œä½ å¯èƒ½æƒ³ä½¿ç”¨ï¼Œå®ƒåŸºæœ¬ä¸Šå¸®åŠ©è§£å†³æ¶ˆå¤±æ¢¯åº¦é—®é¢˜ï¼Œé˜²æ­¢å…¶è¿‡äºä¸¥é‡ã€‚
- en: too much of an issueã€‚ It's normalizing on each batchï¼Œ each of your mini batchesã€‚
    We are also using a special weight initializer called the he normalã€‚This isï¼Œ againã€‚
    following what the original paper didã€‚ We are also using a kernel regularizer
    of L2ã€‚ also following the paperã€‚ This implements a resnet version 1ã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ã€‚å®ƒåœ¨æ¯ä¸ªæ‰¹æ¬¡ã€æ¯ä¸ªå°æ‰¹æ¬¡ä¸Šè¿›è¡Œå½’ä¸€åŒ–ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨äº†ä¸€ç§ç‰¹æ®Šçš„æƒé‡åˆå§‹åŒ–å™¨ï¼Œç§°ä¸ºHeæ­£æ€åˆ†å¸ƒã€‚è¿™åˆæ˜¯ï¼Œéµå¾ªäº†åŸå§‹è®ºæ–‡çš„åšæ³•ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨äº†L2çš„æ ¸æ­£åˆ™åŒ–ï¼ŒåŒæ ·éµå¾ªäº†è®ºæ–‡ã€‚è¿™å®ç°äº†Resnetç‰ˆæœ¬1ã€‚
- en: which is primarily what we're dealing with hereï¼Œ but I included both of thoseã€‚Both
    the resnet version 1 and 2ã€‚ this specifies the the input parameterï¼Œ specify the
    shapeã€‚ and it is essentially stacking up those layers and culminating with the
    final dense outputã€‚ It's building those individual resnet blocksã€‚ A resnet blocks
    is those two convolution layers stacked betweenã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸»è¦æ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†çš„å†…å®¹ï¼Œä½†æˆ‘åŒ…æ‹¬äº†è¿™ä¸¤è€…ã€‚Resnetç‰ˆæœ¬1å’Œç‰ˆæœ¬2ã€‚è¿™æŒ‡å®šäº†è¾“å…¥å‚æ•°ï¼ŒæŒ‡å®šå½¢çŠ¶ã€‚æœ¬è´¨ä¸Šæ˜¯å°†é‚£äº›å±‚å †å åœ¨ä¸€èµ·ï¼Œæœ€ç»ˆå½¢æˆå¯†é›†è¾“å‡ºã€‚å®ƒæ„å»ºäº†é‚£äº›å•ç‹¬çš„Resnetå—ã€‚ä¸€ä¸ªResnetå—æ˜¯ä¸¤ä¸ªå·ç§¯å±‚å †å åœ¨ä¸€èµ·ã€‚
- en: So it createsã€‚It creates the two resonnet layers Nowã€‚ the resonant layers that
    it's talking about above are essentially the two parts of the resonnet blockã€‚
    we're keeping track ofã€‚So we have Y hereã€‚ X feeds inã€‚ So X is the inputã€‚ Then
    the second one is feeding to hereã€‚ This portion here is caught is implementing
    the skip layerã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒåˆ›å»ºäº†ä¸¤ä¸ªResnetå±‚ã€‚ç°åœ¨ï¼Œä¸Šé¢æåˆ°çš„Resnetå±‚åŸºæœ¬ä¸Šæ˜¯Resnetå—çš„ä¸¤ä¸ªéƒ¨åˆ†ã€‚æˆ‘ä»¬åœ¨è·Ÿè¸ªè¿™äº›ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œæœ‰Yã€‚Xä½œä¸ºè¾“å…¥ã€‚ç„¶åç¬¬äºŒä¸ªæ˜¯ä¼ å…¥è¿™é‡Œã€‚è¿™éƒ¨åˆ†å®ç°äº†è·³è·ƒå±‚ã€‚
- en: Finallyï¼Œ we do an averaging poolã€‚And the final dense layerï¼Œ we do alsoã€‚ I'm
    going to go ahead and run this so that we have it in memoryã€‚We do also have a
    second version of Resnetï¼Œ the primary difference of the full the V2 variant compared
    to V1 is the use of the batch normalization before every layer thatã€‚Cause some
    improvements to it overallã€‚ We're dealing mainly with the version oneã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬è¿›è¡Œä¸€ä¸ªå¹³å‡æ± åŒ–ã€‚åœ¨æœ€ç»ˆçš„å¯†é›†å±‚ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿä¼šè¿™æ ·åšã€‚æˆ‘å°†ç»§ç»­è¿è¡Œè¿™ä¸ªï¼Œä»¥ä¾¿æˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨å†…å­˜ä¸­ã€‚æˆ‘ä»¬ä¹Ÿæœ‰Resnetçš„ç¬¬äºŒä¸ªç‰ˆæœ¬ï¼Œå®Œæ•´çš„V2å˜ä½“ä¸V1çš„ä¸»è¦åŒºåˆ«æ˜¯æ¯ä¸€å±‚ä¹‹å‰ä½¿ç”¨æ‰¹é‡å½’ä¸€åŒ–ã€‚è¿™æ€»ä½“ä¸Šå¸¦æ¥äº†ä¸€äº›æ”¹è¿›ã€‚æˆ‘ä»¬ä¸»è¦å¤„ç†ç‰ˆæœ¬ä¸€ã€‚
- en: but both of them thereï¼Œ you canï¼Œ you can try out the twoã€‚ see the differences
    between the the normalizationã€‚At each point or just at the at the end of those
    resnet blocksã€‚ Here is where we actually run thisã€‚ So I get the input shapeï¼Œ I
    get the train and testã€‚If we want to subtract the pixel meanã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä¸¤è€…éƒ½åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥å°è¯•è¿™ä¸¤ä¸ªã€‚çœ‹çœ‹å½’ä¸€åŒ–ä¹‹é—´çš„å·®å¼‚ã€‚åœ¨æ¯ä¸ªç‚¹è¿˜æ˜¯ä»…åœ¨é‚£äº›Resnetå—çš„æœ«å°¾ã€‚è¿™é‡Œæ˜¯æˆ‘ä»¬å®é™…è¿è¡Œçš„åœ°æ–¹ã€‚å› æ­¤æˆ‘è·å–è¾“å…¥å½¢çŠ¶ï¼Œè·å–è®­ç»ƒå’Œæµ‹è¯•ã€‚å¦‚æœæˆ‘ä»¬æƒ³å‡å»åƒç´ å‡å€¼ã€‚
- en: this is doing thatã€‚ that centers it about 0 more effectivelyï¼Œ Typ a good ideaã€‚
    We run the ressonnet V1 or V2 depending on what we haveï¼Œ and we compile it and
    reproduce a summaryã€‚So this just builds the neural networkã€‚ doesn't actually runã€‚
    And it's ready to goã€‚ It shows you the entire structure of the network againï¼Œ
    trying to match the original paperã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ­£åœ¨è¿›è¡Œä¸­ã€‚å®ƒä½¿å…¶æ›´æœ‰æ•ˆåœ°é›†ä¸­åœ¨0é™„è¿‘ï¼Œè¾“å…¥ä¸€ä¸ªå¥½ä¸»æ„ã€‚æˆ‘ä»¬è¿è¡Œresonnet V1æˆ–V2ï¼Œå…·ä½“å–å†³äºæˆ‘ä»¬æœ‰ä»€ä¹ˆï¼Œæˆ‘ä»¬ç¼–è¯‘å®ƒå¹¶ç”Ÿæˆä¸€ä¸ªæ‘˜è¦ã€‚æ‰€ä»¥è¿™åªæ˜¯æ„å»ºç¥ç»ç½‘ç»œï¼Œå¹¶æ²¡æœ‰å®é™…è¿è¡Œã€‚å®ƒå·²ç»å‡†å¤‡å¥½äº†ã€‚å®ƒå†æ¬¡å‘ä½ å±•ç¤ºç½‘ç»œçš„æ•´ä¸ªç»“æ„ï¼Œè¯•å›¾ä¸åŸå§‹è®ºæ–‡ç›¸åŒ¹é…ã€‚
- en: This is where we actually execute and train itã€‚ I'm going to run it just so
    that it can be going because this is going to go for a long timeã€‚ We get the learning
    rate scheduler so this causes it to reduce the learning rate until we plateauã€‚
    So this causes it to reduce the learning rate when we do plateauã€‚ If we're not
    using image augmentationï¼Œ which by the way we areï¼Œ we do just a normal fitã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å®é™…æ‰§è¡Œå’Œè®­ç»ƒå®ƒçš„åœ°æ–¹ã€‚æˆ‘å°†è¿è¡Œå®ƒï¼Œåªæ˜¯ä¸ºäº†è®©å®ƒç»§ç»­ï¼Œå› ä¸ºè¿™å°†éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚æˆ‘ä»¬è·å¾—å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿™ä¼šä½¿å­¦ä¹ ç‡é™ä½ï¼Œç›´åˆ°è¾¾åˆ°å¹³ç¨³çŠ¶æ€ã€‚å½“æˆ‘ä»¬è¾¾åˆ°å¹³ç¨³çŠ¶æ€æ—¶ï¼Œå®ƒä¼šé™ä½å­¦ä¹ ç‡ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬ä¸ä½¿ç”¨å›¾åƒå¢å¼ºï¼Œé¡ºä¾¿æä¸€ä¸‹ï¼Œæˆ‘ä»¬ç¡®å®ä½¿ç”¨äº†ï¼Œæˆ‘ä»¬å°±è¿›è¡Œæ­£å¸¸çš„æ‹Ÿåˆã€‚
- en: Image augmentation can be very useful to letting it learn to not overfit the
    data that it hasã€‚ This allows it to shift and move about the image somewhatã€‚ do
    each of these is just various random sort of transformations that you can do to
    the image toã€‚Basicallyã€‚Distord it in various ways as it trainsã€‚ So it's like it
    gets brand new images each timeã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒå¢å¼ºå¯¹äºè®©æ¨¡å‹å­¦ä¹ ä¸å¯¹è®­ç»ƒæ•°æ®è¿‡æ‹Ÿåˆéå¸¸æœ‰ç”¨ã€‚è¿™å…è®¸å®ƒåœ¨å›¾åƒä¸­ç§»åŠ¨å’Œå˜åŒ–ã€‚æ¯ä¸€ç§å˜æ¢éƒ½æ˜¯ä½ å¯ä»¥å¯¹å›¾åƒè¿›è¡Œçš„å„ç§éšæœºå˜æ¢ï¼ŒåŸºæœ¬ä¸Šæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»¥å„ç§æ–¹å¼æ‰­æ›²å®ƒã€‚æ‰€ä»¥æ¯æ¬¡å®ƒéƒ½ä¼šè·å¾—å…¨æ–°çš„å›¾åƒã€‚
- en: but they're all based on the train set imagesã€‚ It's like you can randomly horizontally
    and vertically flip itã€‚ We're not we are flipping it horizontallyï¼Œ but not vertically
    againã€‚ I'm following basically what the Kira's example had set upã€‚ So you could
    try some of these other valuesã€‚ It might give you better resultsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒä»¬éƒ½æ˜¯åŸºäºè®­ç»ƒé›†å›¾åƒçš„ã€‚ä½ å¯ä»¥éšæœºæ°´å¹³å’Œå‚ç›´ç¿»è½¬å®ƒã€‚æˆ‘ä»¬æ˜¯æ°´å¹³ç¿»è½¬ï¼Œä½†ä¸å†å‚ç›´ç¿»è½¬ã€‚æˆ‘åŸºæœ¬ä¸Šéµå¾ªKiraç¤ºä¾‹çš„è®¾ç½®ã€‚æ‰€ä»¥ä½ å¯ä»¥å°è¯•ä¸€äº›å…¶ä»–çš„å€¼ã€‚è¿™å¯èƒ½ä¼šç»™ä½ æ›´å¥½çš„ç»“æœã€‚
- en: And you might want to also use the image data generatorã€‚ which is doing these
    transformations on your own neural networks when you are dealing with image dataã€‚
    Then we basically fit it run itã€‚ And we re report the lapse timeã€‚ takes a couple
    of hoursã€‚ typicallyyï¼Œ you probably don't even want to try this with a CPU other
    than a GPã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è¿˜æƒ³ä½¿ç”¨å›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œè¿™åœ¨å¤„ç†å›¾åƒæ•°æ®æ—¶ä¼šå¯¹ä½ è‡ªå·±çš„ç¥ç»ç½‘ç»œè¿›è¡Œè¿™äº›å˜æ¢ã€‚ç„¶åæˆ‘ä»¬åŸºæœ¬ä¸Šæ‹Ÿåˆå®ƒå¹¶è¿è¡Œã€‚æˆ‘ä»¬é‡æ–°æŠ¥å‘Šæ—¶é—´é—´éš”ã€‚è¿™éœ€è¦å‡ ä¸ªå°æ—¶ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½æ ¹æœ¬ä¸æƒ³åœ¨CPUä¸Šå°è¯•è¿™ä¸ªï¼Œé™¤éæ˜¯GPUã€‚
- en: I have not tried running it could be a dayã€‚ I really have not tried it on CPUã€‚
    Thank you for watching this video in the next videoã€‚ We're going to look at openCã€‚
    This content changes oftenã€‚ So subscribe to the channel to stay up to date on
    this course and other topicsã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æ²¡æœ‰å°è¯•è¿è¡Œå®ƒï¼Œå¯èƒ½è¦ç­‰ä¸€å¤©ã€‚æˆ‘çœŸçš„è¿˜æ²¡æœ‰åœ¨CPUä¸Šå°è¯•è¿‡ã€‚æ„Ÿè°¢ä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œä¸‹ä¸€ä¸ªè§†é¢‘ä¸­æˆ‘ä»¬å°†çœ‹çœ‹openCã€‚è¿™ä¸ªå†…å®¹ç»å¸¸å˜åŒ–ï¼Œæ‰€ä»¥è¯·è®¢é˜…é¢‘é“ï¼Œä»¥ä¾¿åŠæ—¶äº†è§£è¿™ä¸ªè¯¾ç¨‹å’Œå…¶ä»–ä¸»é¢˜ã€‚
- en: '![](img/c990de25bca059d59d22e195401e0376_3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c990de25bca059d59d22e195401e0376_3.png)'
- en: And artificial intelligenceã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰äººå·¥æ™ºèƒ½ã€‚
