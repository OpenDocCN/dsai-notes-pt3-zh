- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P34：L6.3- 在Keras中实现ResNet
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P34：L6.3- 在 Keras 中实现 ResNet
    - ShowMeAI - BV15f4y1w7b8
- en: Hi， this is Jeff Heaton。 Welcome to applications of Deep neural networks with
    Washington University。 In this video， we're going to look at Resnet， which is
    a type of neural network that can be implemented in Carras that makes use of residual
    or what really makes this neural network unique is that it has skip connections
    that don't simply go to the next layer for the latest on my AI course and projects。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是杰夫·希顿。欢迎来到华盛顿大学的深度神经网络应用。在这个视频中，我们将看一下 ResNet，这是一种可以在 Keras 中实现的神经网络，它利用了残差，真正让这个神经网络独特的是它有跳跃连接，不仅仅是连接到下一层，关于我
    AI 课程和项目的最新动态。
- en: Click subscribe and the bell next to it to be notified of every new video。 Resnet
    demonstrates really how flexible Keras is。 Carras does not have a Resnet layer。
    at least at this point。 So we're going to literally construct our own Resnet layer。
    and it's not terribly difficult。 There's a function that I found on the Carras
    website that implements that。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 点击订阅并点击旁边的铃铛，以便接收到每个新视频的通知。ResNet 真的展示了 Keras 的灵活性。Keras 目前没有 ResNet 层。因此我们将字面上构建我们自己的
    ResNet 层，这并不是特别困难。我在 Keras 网站上找到一个实现的函数。
- en: We'll see how Kas can do。 This This made a big， big splash at the I SVC classification
    challenge。 This。😊。![](img/c990de25bca059d59d22e195401e0376_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看看 Keras 可以做到什么。这在 I SVC 分类挑战中引起了很大的轰动。这。😊！[](img/c990de25bca059d59d22e195401e0376_1.png)
- en: Use the C far 10 data set and dot just took first place， beat everything else
    that that was there。 This is the paper describing the process。 And I took some
    of these images from the paper。 First of all， let's just talk about what is a
    residual。 So what is a residual neural network。 or resnet， residual。 If you look
    at Miriam Webster。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 C far 10 数据集并且仅仅取得第一名，击败了所有其他的。这是描述这一过程的论文。我从论文中提取了一些这些图像。首先，让我们谈谈什么是残差。那么什么是残差神经网络，或称为
    ResNet，残差。如果你查看米里亚姆·韦伯斯特。
- en: It's a internal artifact of experience or activity that influences later behavior。
    And that's exactly what it is in these these neural networks。 It's a skip layer。
    That's another。 I like skip layer better than residual， but nonetheless， either
    works equally well to describe it。 Now， it's also important to note that it's
    skipping two layers。 too normal weighted。😊，RellU layers。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种经验或活动的内部产物，影响后续行为。在这些神经网络中，它就是这样。它是一个跳跃层。我更喜欢称之为跳跃层，而不是残差，但无论如何，两个术语都同样有效。现在，同样重要的是要注意它跳过了两个层，两个正常加权的。😊
    RellU 层。
- en: Now， the re comes in like activation functions are typically applied after the
    weighted layer。 So this is pretty normal。 It's almost like we take note of what
    the input into this layer was。We fire this other weighted layer。But we don't apply
    the value yet or whatever the nonlinearity is。But we add that X input right into
    here。 So whatever was output here gets added to there。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，激活函数通常是在加权层之后应用的。所以这很正常。几乎就像我们注意到这一层的输入是什么。我们激活这个其他的加权层。但我们还不应用这个值或任何非线性。但我们把这个
    X 输入直接加到这里。所以这里的输出会加到那儿。
- en: and we have the。The value in some ways， this is a little bit like a。 this is
    almost the reverse of a recurrent neural network。 And we'll see recurrent neural
    networks very soon。 instead of going backwards。 like the recurrent neural networks
    does， this goes， this goes forward。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，这个值有点像。这几乎是递归神经网络的反面。我们很快就会看到递归神经网络。与递归神经网络向后运行不同，它是向前的。
- en: Why would you want to do such a thing？ Well， the short answer is。 it gives a
    greater predictive power。 and it lets you go much， much， much deeper。 the paper
    gets into this more。 But it shows that as you train deeper and deeper neural networks
    before this。You would get better and better predictive results， Then you'd just
    hit a wall。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么你想这样做呢？简单的答案是，它提供了更大的预测能力，让你可以更深更深地训练。论文对此有更多讨论。但它显示出，当你训练更深的神经网络时，结果会越来越好，然后你会遇到一个瓶颈。
- en: and your results would start to get worse and worse and worse as you added deeper
    and deeper and deeper layers。 This has been experimented with for 100 layer，100
    hidden layers。 and beyond。 I think there's even been a few of 1 thousand00。 that
    has not necessarily shown。Completely promising results， but this research changes
    quite rapidly。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你添加更深的层数，你的结果会越来越差。这已经在100层、100个隐藏层及以上进行过实验。我认为甚至有过几次尝试达到1万层的情况，但这些并不一定显示出完全有前景的结果，不过这方面的研究变化很快。
- en: This is what one of these looks like don't worry about the VGG。Neural network，
    that is， I mean。 that's more the traditional convolution， neural network and some
    other。Kind of tweaks added。 added to that。 That's basically the competition that
    they were trying to beat for this。 this competition。 And this is a 34。Plain， so
    like we just learned about convolution neural network。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是其中一个样子的，别担心VGG。神经网络，也就是说，更多的是传统的卷积神经网络，还有一些其他的调整。基本上是他们试图在这次比赛中超越的竞争对手。这是一个34层的简单网络，就像我们刚刚学习的卷积神经网络一样。
- en: this is all based on convolutions。And this is the 34 layer residual。 so this
    is really what this looks like。You can see all these skip layers， skip layer，
    skip layer。 and so on， and so forth。The different colors， 64 filters， 128 filters，
    256 filters。 so on and so forth， and then they finally get into a averaging pool
    SC is fully connected。This。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是基于卷积的。这是34层残差网络。 所以这实际上是它的样子。你可以看到这些跳跃层，跳跃层，跳跃层，等等。不同的颜色，64个滤波器，128个滤波器，256个滤波器，等等，然后它们最终进入一个平均池化，SC是完全连接的。这。
- en: the VGG is using several layers of fully connected and the convolutions similar
    to。With pooling。 this uses an average pool rather than a max pool kind of towards
    the end。 Let's go ahead and look at the code to run this。 This is using the Cf
    data set。 It needs to download it Now in Google。 when you're using Google Coab。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: VGG使用了多个全连接层和类似的卷积。结合池化，这使用的是平均池而不是最大池，尤其是在最后阶段。让我们来看看运行这个的代码。这是使用Cf数据集。它需要下载，当前在谷歌上使用Google
    Coab。
- en: often you're going to find yourself having to re downloadload this。 You want
    to be careful because Google only keeps the stuff that you keep in Google Drive。
    My introductory video on how to use Google Coab explains all of that done with
    that。 Now。 we're going to grab the data。😊，That data was stored as a pickle。 so
    we're going to。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现自己经常需要重新下载这些。你要小心，因为谷歌只保留你存储在谷歌云盘中的内容。我关于如何使用Google Coab的介绍视频已经解释了这些内容。现在，我们要抓取数据。😊，这些数据以pickle格式存储，所以我们要。
- en: Extract that data that we just downloaded and prepare it to be trained so now
    that we've downloaded it。 let's just go ahead and display it so that we can see
    this is what this code does here。 it displays it so that you can see some of the
    samples from this from this data set。Cars， dogs。 again， predominantly animals，
    but this is， this is that data set。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提取我们刚下载的数据并准备进行训练，现在我们已经下载了它。让我们展示一下，这段代码的作用是展示这个数据集中的一些样本。汽车、狗，依然主要是动物，但这就是这个数据集。
- en: These are some parameters that describe。What we're doing as far as the implementation
    of this。 we're going to use 200 epochs that takes a while to train， even with
    a GPU。 this runs for a couple of hours。Btch size of 32 number of classes we pull
    right from the data。 it's 10 colors we pull right from the data set， it's three
    channels red， green and blue。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些描述我们在实现中的参数。我们将使用200个训练周期，即使使用GPU，也需要一段时间来训练，这个过程持续几个小时。批量大小为32，类别数直接从数据中提取。它有10种颜色，我们直接从数据集中提取，包含红、绿、蓝三个通道。
- en: Subtract pixel meaning is that's getting us basically to centering this about
    0。 and that helps for predictive accuracy。 There are two versions of this of resnet
    Ressonnet version 1 is the original and Resnet version 2 had some improvements。'll
    talk about that later in this video。 We are choosing。The depth。Calculated on on
    the size of the image and the number of colors。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 像素减法的意思是这基本上是将其中心化到0。这有助于提高预测的准确性。ResNet有两个版本，ResNet版本1是原始版本，ResNet版本2有一些改进。我稍后会在这个视频中谈到。我们在选择深度时，基于图像的大小和颜色的数量进行计算。
- en: We're choosing the depth based on the version and colors。 This is a useful function。
    This is following along with the paper。 This is the learning rate scheduler。This
    is essentially going to bring the learning rate down as we cross a number of epochs。
    so whenever we change the learning rate， it's reported here。This can be very effective。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据版本和颜色选择深度。这是一个有用的函数。这是遵循论文的。这是学习率调度器。这基本上将在跨越多个训练周期时降低学习率。因此，每当我们更改学习率时，都会在这里报告。这可以非常有效。
- en: We're using this with the atom training and。Typically。 you want to decrease
    the learning rate as you go forward。 so this demonstrates this technique。 you
    might want to make use of this in the Cagle competition or other things。 you have
    to experiment with it to see how well it particularly works。By the way。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在原子训练中使用这个。通常，你希望随着进展减少学习率。所以这展示了这一技术。你可能希望在Cagle比赛或其他事情中利用这个。你需要进行实验，以查看它的具体效果。顺便说一下。
- en: all of this data or this code I got from the Kiras website。So this is just examples。
    I've updated it to the latest。Versions of Tensorflow and Cars and also reworked
    it a little bit to。 I think， make it a little more readable and segment it into
    a Jupiter notebook。 This essentially creates a resonant layer。 So that includes
    the two normal layers and the skip connection。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我从Keras网站获得了所有这些数据或代码。所以这只是一些示例。我已将其更新到最新版本的Tensorflow和Keras，并稍作调整，使其更易读，并将其分段到一个Jupyter笔记本中。这基本上创建了一个Resnet层。因此包括两个普通层和跳跃连接。
- en: It's essentially creating the convolution，2D layer。 It does put a batch normalization
    in there。 the batch normalization。😊，Is a good layer that you that you might want
    to use that basically helps to really helps to keep the vanisheding gradient problem
    from being too much。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它基本上在创建卷积2D层。它确实在其中放置了一个批量归一化层。批量归一化😊，是一个好的层，你可能想使用，它基本上帮助解决消失梯度问题，防止其过于严重。
- en: too much of an issue。 It's normalizing on each batch， each of your mini batches。
    We are also using a special weight initializer called the he normal。This is， again。
    following what the original paper did。 We are also using a kernel regularizer
    of L2。 also following the paper。 This implements a resnet version 1。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个大问题。它在每个批次、每个小批次上进行归一化。我们还使用了一种特殊的权重初始化器，称为He正态分布。这又是，遵循了原始论文的做法。我们还使用了L2的核正则化，同样遵循了论文。这实现了Resnet版本1。
- en: which is primarily what we're dealing with here， but I included both of those。Both
    the resnet version 1 and 2。 this specifies the the input parameter， specify the
    shape。 and it is essentially stacking up those layers and culminating with the
    final dense output。 It's building those individual resnet blocks。 A resnet blocks
    is those two convolution layers stacked between。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这主要是我们在这里处理的内容，但我包括了这两者。Resnet版本1和版本2。这指定了输入参数，指定形状。本质上是将那些层堆叠在一起，最终形成密集输出。它构建了那些单独的Resnet块。一个Resnet块是两个卷积层堆叠在一起。
- en: So it creates。It creates the two resonnet layers Now。 the resonant layers that
    it's talking about above are essentially the two parts of the resonnet block。
    we're keeping track of。So we have Y here。 X feeds in。 So X is the input。 Then
    the second one is feeding to here。 This portion here is caught is implementing
    the skip layer。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它创建了两个Resnet层。现在，上面提到的Resnet层基本上是Resnet块的两个部分。我们在跟踪这些。所以我们在这里有Y。X作为输入。然后第二个是传入这里。这部分实现了跳跃层。
- en: Finally， we do an averaging pool。And the final dense layer， we do also。 I'm
    going to go ahead and run this so that we have it in memory。We do also have a
    second version of Resnet， the primary difference of the full the V2 variant compared
    to V1 is the use of the batch normalization before every layer that。Cause some
    improvements to it overall。 We're dealing mainly with the version one。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行一个平均池化。在最终的密集层中，我们也会这样做。我将继续运行这个，以便我们将其保存在内存中。我们也有Resnet的第二个版本，完整的V2变体与V1的主要区别是每一层之前使用批量归一化。这总体上带来了一些改进。我们主要处理版本一。
- en: but both of them there， you can， you can try out the two。 see the differences
    between the the normalization。At each point or just at the at the end of those
    resnet blocks。 Here is where we actually run this。 So I get the input shape， I
    get the train and test。If we want to subtract the pixel mean。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但两者都在这里，你可以尝试这两个。看看归一化之间的差异。在每个点还是仅在那些Resnet块的末尾。这里是我们实际运行的地方。因此我获取输入形状，获取训练和测试。如果我们想减去像素均值。
- en: this is doing that。 that centers it about 0 more effectively， Typ a good idea。
    We run the ressonnet V1 or V2 depending on what we have， and we compile it and
    reproduce a summary。So this just builds the neural network。 doesn't actually run。
    And it's ready to go。 It shows you the entire structure of the network again，
    trying to match the original paper。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这正在进行中。它使其更有效地集中在0附近，输入一个好主意。我们运行resonnet V1或V2，具体取决于我们有什么，我们编译它并生成一个摘要。所以这只是构建神经网络，并没有实际运行。它已经准备好了。它再次向你展示网络的整个结构，试图与原始论文相匹配。
- en: This is where we actually execute and train it。 I'm going to run it just so
    that it can be going because this is going to go for a long time。 We get the learning
    rate scheduler so this causes it to reduce the learning rate until we plateau。
    So this causes it to reduce the learning rate when we do plateau。 If we're not
    using image augmentation， which by the way we are， we do just a normal fit。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们实际执行和训练它的地方。我将运行它，只是为了让它继续，因为这将需要很长时间。我们获得学习率调度器，这会使学习率降低，直到达到平稳状态。当我们达到平稳状态时，它会降低学习率。所以如果我们不使用图像增强，顺便提一下，我们确实使用了，我们就进行正常的拟合。
- en: Image augmentation can be very useful to letting it learn to not overfit the
    data that it has。 This allows it to shift and move about the image somewhat。 do
    each of these is just various random sort of transformations that you can do to
    the image to。Basically。Distord it in various ways as it trains。 So it's like it
    gets brand new images each time。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强对于让模型学习不对训练数据过拟合非常有用。这允许它在图像中移动和变化。每一种变换都是你可以对图像进行的各种随机变换，基本上是在训练过程中以各种方式扭曲它。所以每次它都会获得全新的图像。
- en: but they're all based on the train set images。 It's like you can randomly horizontally
    and vertically flip it。 We're not we are flipping it horizontally， but not vertically
    again。 I'm following basically what the Kira's example had set up。 So you could
    try some of these other values。 It might give you better results。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们都是基于训练集图像的。你可以随机水平和垂直翻转它。我们是水平翻转，但不再垂直翻转。我基本上遵循Kira示例的设置。所以你可以尝试一些其他的值。这可能会给你更好的结果。
- en: And you might want to also use the image data generator。 which is doing these
    transformations on your own neural networks when you are dealing with image data。
    Then we basically fit it run it。 And we re report the lapse time。 takes a couple
    of hours。 typicallyy， you probably don't even want to try this with a CPU other
    than a GP。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想使用图像数据生成器，这在处理图像数据时会对你自己的神经网络进行这些变换。然后我们基本上拟合它并运行。我们重新报告时间间隔。这需要几个小时。通常情况下，你可能根本不想在CPU上尝试这个，除非是GPU。
- en: I have not tried running it could be a day。 I really have not tried it on CPU。
    Thank you for watching this video in the next video。 We're going to look at openC。
    This content changes often。 So subscribe to the channel to stay up to date on
    this course and other topics。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我还没有尝试运行它，可能要等一天。我真的还没有在CPU上尝试过。感谢你观看这个视频，下一个视频中我们将看看openC。这个内容经常变化，所以请订阅频道，以便及时了解这个课程和其他主题。
- en: '![](img/c990de25bca059d59d22e195401e0376_3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c990de25bca059d59d22e195401e0376_3.png)'
- en: And artificial intelligence。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 还有人工智能。
