- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P20ï¼šL20-
    RNN & LSTM & GRU - å¾ªç¯ç¥ç»ç½‘ç»œ - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P20ï¼šL20-
    RNN & LSTM & GRU - å¾ªç¯ç¥ç»ç½‘ç»œ - ShowMeAI - BV12m4y1S7ix
- en: Hi and welcome to your new Pytorch tutorialã€‚ Todayã€‚ I show you how we can implement
    a recurrent neural net using the built in R and N moduleã€‚ In the last tutorialï¼Œ
    we implemented the R and N from scratchã€‚ and I highly recommend to watch this
    one first to understand the internal architecture of R Nsã€‚ğŸ˜Šã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæ¬¢è¿æ¥åˆ°ä½ çš„æ–°Pytorchæ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨å†…ç½®çš„RnNæ¨¡å—å®ç°ä¸€ä¸ªé€’å½’ç¥ç»ç½‘ç»œã€‚åœ¨ä¸Šä¸€ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»å¤´å¼€å§‹å®ç°äº†RnNã€‚æˆ‘å¼ºçƒˆå»ºè®®å…ˆè§‚çœ‹è¿™ä¸ªæ•™ç¨‹ï¼Œä»¥äº†è§£RnNçš„å†…éƒ¨ç»“æ„ã€‚ğŸ˜Š
- en: And now todayï¼Œ we focus on the implementation with Pytorch's own moduleã€‚ so
    we don't have to implement everything by ourselvesã€‚ I will show you how to use
    the RnN moduleã€‚ And then at the endï¼Œ I also show you how easily we can switch
    our Rn N model and use special kinds of RNs like LSTM and Gã€‚ So let's startã€‚ and
    we are going to use my tutorial about a simple neural net as starting pointã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Šå¤©ï¼Œæˆ‘ä»¬ä¸“æ³¨äºä½¿ç”¨Pytorchè‡ªå·±çš„æ¨¡å—è¿›è¡Œå®ç°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸å¿…è‡ªå·±å®ç°æ‰€æœ‰å†…å®¹ã€‚æˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨RnNæ¨¡å—ã€‚æœ€åï¼Œæˆ‘è¿˜ä¼šå‘ä½ å±•ç¤ºå¦‚ä½•è½»æ¾åˆ‡æ¢æˆ‘ä»¬çš„RnNæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ç‰¹æ®Šç±»å‹çš„Rnï¼Œå¦‚LSTMå’ŒGRUã€‚æ‰€ä»¥è®©æˆ‘ä»¬å¼€å§‹å§ã€‚æˆ‘ä»¬å°†ä»¥æˆ‘çš„ç®€å•ç¥ç»ç½‘ç»œæ•™ç¨‹ä½œä¸ºèµ·ç‚¹ã€‚
- en: So this is tutorial number 13 from my Pytorch beginner courseã€‚ You can find
    the link to the video and also to the code on Gitub in the description belowã€‚
    So as I saidï¼Œ this is tutorial number 13ã€‚ So I already grab this code and copied
    it to my editorã€‚ And then this exampleï¼Œ we are doing diit classification on the
    Mnes data setsã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘Pytorchåˆå­¦è€…è¯¾ç¨‹çš„ç¬¬13ä¸ªæ•™ç¨‹ã€‚ä½ å¯ä»¥åœ¨ä¸‹é¢çš„æè¿°ä¸­æ‰¾åˆ°è§†é¢‘å’Œä»£ç çš„é“¾æ¥ã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œè¿™æ˜¯ç¬¬13ä¸ªæ•™ç¨‹ã€‚æˆ‘å·²ç»å°†è¿™æ®µä»£ç æŠ“å–å¹¶å¤åˆ¶åˆ°æˆ‘çš„ç¼–è¾‘å™¨ä¸­ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åœ¨Mnesæ•°æ®é›†ä¸Šè¿›è¡Œæ•°å­—åˆ†ç±»ã€‚
- en: And I have to say that image classification is not the typical example for RnNsã€‚
    But what I want to demonstrate here is how we must treat our inputã€‚ğŸ˜Šã€‚![](img/4923e3db142c0d58fa13de82f2b481db_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¿…é¡»è¯´ï¼Œå›¾åƒåˆ†ç±»å¹¶ä¸æ˜¯RnNçš„å…¸å‹ä¾‹å­ã€‚ä½†æˆ‘æƒ³åœ¨è¿™é‡Œæ¼”ç¤ºçš„æ˜¯æˆ‘ä»¬å¿…é¡»å¦‚ä½•å¤„ç†è¾“å…¥ã€‚ğŸ˜Š![](img/4923e3db142c0d58fa13de82f2b481db_1.png)
- en: As a sequence and then set up the correct shapesï¼Œ and it also shows that RnNs
    can indeed be used to get a high accuracy on this classification taskã€‚ So last
    time we learned that the special thing about RnNs is that we work on sequences
    of vectors hereã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å…¶è§†ä¸ºä¸€ä¸ªåºåˆ—ï¼Œç„¶åè®¾ç½®æ­£ç¡®çš„å½¢çŠ¶ï¼Œè¿™ä¹Ÿè¡¨æ˜RnNç¡®å®å¯ä»¥ç”¨äºåœ¨è¿™ä¸ªåˆ†ç±»ä»»åŠ¡ä¸­è·å¾—é«˜å‡†ç¡®åº¦ã€‚æ‰€ä»¥ä¸‹æ¬¡æˆ‘ä»¬äº†è§£åˆ°ï¼ŒRnNçš„ç‰¹æ®Šä¹‹å¤„åœ¨äºæˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†å‘é‡çš„åºåˆ—ã€‚
- en: So we treat our input as a sequenceã€‚ and there can be different types of Rnnsã€‚
    So in this example we used this many to one architectureã€‚ So here we have a sequence
    as a input and then only one output at the endã€‚ and this is our class label in
    this caseã€‚ So let's jump to the codeã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†è¾“å…¥è§†ä¸ºä¸€ä¸ªåºåˆ—ã€‚RnNæœ‰ä¸åŒç±»å‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¿™ç§å¤šå¯¹ä¸€çš„æ¶æ„ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥ï¼Œæœ€ååªæœ‰ä¸€ä¸ªè¾“å‡ºã€‚è¿™ä¸ªå°±æ˜¯æˆ‘ä»¬çš„ç±»æ ‡ç­¾ã€‚æ‰€ä»¥è®©æˆ‘ä»¬è·³åˆ°ä»£ç ã€‚
- en: and the first thing we must change is the hyperparameterã€‚ So the Ms data set
    consists of images of size 28 by 28 pixelsã€‚ and last time we squeeze that into
    one dimensionsã€‚Our input size was 28 times 28 or 784ã€‚ and this timeï¼Œ as I saidï¼Œ
    we treat the image as a sequenceã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆæˆ‘ä»¬å¿…é¡»æ”¹å˜çš„æ˜¯è¶…å‚æ•°ã€‚æ‰€ä»¥Msæ•°æ®é›†ç”±28ä¹˜28åƒç´ çš„å›¾åƒç»„æˆã€‚ä¸Šæ¬¡æˆ‘ä»¬å°†å…¶å‹ç¼©ä¸ºä¸€ç»´ã€‚æˆ‘ä»¬çš„è¾“å…¥å¤§å°ä¸º28ä¹˜28æˆ–784ã€‚è¿™æ¬¡ï¼Œå¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬å°†å›¾åƒè§†ä¸ºä¸€ä¸ªåºåˆ—ã€‚
- en: So what we do here now is we treat one image dimension as one sequence and the
    other image dimension as the input or feature sizeã€‚So you can see this as that
    we are looking at one row at a timeã€‚ So let's comment and this outã€‚ and let's
    create a new oneã€‚ So let's say our input size equalsã€‚ And nowï¼Œ as I saidã€‚ we are
    looking at one row at a timeã€‚ So this is 28ã€‚ And then we also create the sequence
    lengthã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬åšçš„æ˜¯å°†ä¸€ä¸ªå›¾åƒç»´åº¦è§†ä¸ºä¸€ä¸ªåºåˆ—ï¼Œå¦ä¸€ä¸ªå›¾åƒç»´åº¦è§†ä¸ºè¾“å…¥æˆ–ç‰¹å¾å¤§å°ã€‚ä½ å¯ä»¥å°†å…¶è§†ä¸ºæˆ‘ä»¬ä¸€æ¬¡æŸ¥çœ‹ä¸€è¡Œã€‚è®©æˆ‘ä»¬æ³¨é‡Šæ‰è¿™ä¸ªï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°çš„ã€‚å‡è®¾æˆ‘ä»¬çš„è¾“å…¥å¤§å°ç­‰äºã€‚ç°åœ¨ï¼Œå¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬ä¸€æ¬¡æŸ¥çœ‹ä¸€è¡Œã€‚è¿™æ˜¯28ã€‚ç„¶åæˆ‘ä»¬ä¹Ÿåˆ›å»ºåºåˆ—é•¿åº¦ã€‚
- en: And this is also 28ã€‚ And then we change the hidden size to be 128ã€‚ So you can
    try our different sizes hereã€‚ And we add another hyperparmeterã€‚ and this is the
    number of layersã€‚ And here I set this to2ã€‚ So by defaultï¼Œ it is oneã€‚ And this
    means that we are stacking in this caseï¼Œ two R and Ns togetherã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ˜¯28ã€‚ç„¶åæˆ‘ä»¬å°†éšè—å±‚å¤§å°æ›´æ”¹ä¸º128ã€‚æ‰€ä»¥ä½ å¯ä»¥åœ¨è¿™é‡Œå°è¯•ä¸åŒçš„å¤§å°ã€‚æˆ‘ä»¬å†æ·»åŠ ä¸€ä¸ªè¶…å‚æ•°ï¼Œè¿™æ˜¯å±‚æ•°ã€‚è¿™é‡Œæˆ‘è®¾ç½®ä¸º2ã€‚é»˜è®¤æƒ…å†µä¸‹ä¸º1ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨æ­¤æƒ…å†µä¸‹å åŠ ä¸¤ä¸ªRnNã€‚
- en: and the second R and N takes the output from the first R and n as an inputã€‚
    So this can further improve our modelã€‚And now we want to implement the R and N
    classã€‚ So let's change the name to R and Nã€‚ and also in this super methodã€‚And
    then our model down here also now is the R and Nã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªRå’ŒNå°†ç¬¬ä¸€ä¸ªRå’ŒNçš„è¾“å‡ºä½œä¸ºè¾“å…¥ã€‚è¿™å¯ä»¥è¿›ä¸€æ­¥æ”¹å–„æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦å®ç°Rå’ŒNç±»ã€‚æ‰€ä»¥æˆ‘ä»¬å°†åç§°æ”¹ä¸ºRå’ŒNã€‚åœ¨è¿™ä¸ªè¶…ç±»æ–¹æ³•ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç„¶åæˆ‘ä»¬ä¸‹é¢çš„æ¨¡å‹ç°åœ¨ä¹Ÿæ˜¯Rå’ŒNã€‚
- en: And now let's delete all of this to start with a newï¼Œ fresh implementationã€‚So
    now our R and N has still has the input size and the hidden size and the number
    of classes as parametersã€‚ And it also gets the new parameter number of layersã€‚
    So let's put it in hereã€‚ So let's say the number of layers hereã€‚ And thenï¼Œ of
    courseã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬åˆ é™¤æ‰€æœ‰è¿™äº›ï¼Œå¼€å§‹ä¸€ä¸ªæ–°çš„ã€å¹²å‡€çš„å®ç°ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çš„Rå’ŒNä»ç„¶æœ‰è¾“å…¥å¤§å°ã€éšè—å¤§å°å’Œç±»åˆ«æ•°ä½œä¸ºå‚æ•°ã€‚å®ƒè¿˜è·å–æ–°çš„å‚æ•°å±‚æ•°ã€‚æˆ‘ä»¬å°†å…¶æ”¾åœ¨è¿™é‡Œã€‚å› æ­¤ï¼Œå‡è®¾å±‚æ•°åœ¨è¿™é‡Œã€‚é‚£ä¹ˆï¼Œå½“ç„¶ã€‚
- en: we must also pass it to our model when we create itã€‚ So this is our hyperparameterã€‚ğŸ˜Šã€‚And
    then what we want to do here first is we simply want to store the number of layers
    and the hidden sizeã€‚ So let's say self nu layers equals nu layersã€‚And alsoï¼Œ self
    dotã€‚Hiddenã€‚Size equals hidden sizeã€‚And then we create the R and N model and use
    the built in Pytorch R and N moduleã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨åˆ›å»ºæ¨¡å‹æ—¶ä¹Ÿå¿…é¡»å°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚è¿™æ˜¯æˆ‘ä»¬çš„è¶…å‚æ•°ã€‚ğŸ˜Šã€‚ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œé¦–å…ˆæƒ³åšçš„æ˜¯ç®€å•åœ°å­˜å‚¨å±‚æ•°å’Œéšè—å¤§å°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´self nu layersç­‰äºnu
    layersã€‚è¿˜æœ‰ï¼Œself.dot hidden sizeç­‰äºhidden sizeã€‚ç„¶åæˆ‘ä»¬åˆ›å»ºRå’ŒNæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å†…ç½®çš„Pytorch Rå’ŒNæ¨¡å—ã€‚
- en: So you can find this here on the official documentationã€‚ So this is the R and
    N class that Pytorch provides for usã€‚ So we are going to use thisã€‚ So we create
    an R and N and say self R and N equalsã€‚ And now this is in the NN moduleã€‚ So NN
    dot R and Nã€‚![](img/4923e3db142c0d58fa13de82f2b481db_3.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯ä»¥åœ¨å®˜æ–¹æ–‡æ¡£ä¸­æ‰¾åˆ°è¿™ä¸ªã€‚æ‰€ä»¥è¿™æ˜¯Pytorchä¸ºæˆ‘ä»¬æä¾›çš„Rå’ŒNç±»ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªRå’ŒNå¹¶è¯´self Rå’ŒNç­‰äºã€‚ç°åœ¨è¿™åœ¨NNæ¨¡å—ä¸­ã€‚æ‰€ä»¥NN.dot
    Rå’ŒNã€‚![](img/4923e3db142c0d58fa13de82f2b481db_3.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_4.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_4.png)'
- en: And the R and N needs the input sizeã€‚ It needs the hidden sizeã€‚ and it needs
    the number of layers in this orderã€‚ And then we also use a parameter that is called
    batch first and set this to trueã€‚ So this just means that we must have the batch
    as a first dimensionã€‚ So our input needs to have the shapeã€‚Btch sizeã€‚Bch size
    and then the sequence lengthã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Rå’ŒNéœ€è¦è¾“å…¥å¤§å°ã€‚å®ƒéœ€è¦éšè—å¤§å°ï¼Œå¹¶ä¸”éœ€è¦æŒ‰æ­¤é¡ºåºçš„å±‚æ•°ã€‚ç„¶åæˆ‘ä»¬è¿˜ä½¿ç”¨ä¸€ä¸ªå«åšbatch firstçš„å‚æ•°ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºtrueã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»å°†batchä½œä¸ºç¬¬ä¸€ç»´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„è¾“å…¥éœ€è¦å…·æœ‰å½¢çŠ¶ã€‚Batch
    sizeï¼ŒBatch sizeï¼Œç„¶åæ˜¯åºåˆ—é•¿åº¦ã€‚
- en: and then the input or feature sizeã€‚ So this is the shape that we need to have
    for our inputã€‚![](img/4923e3db142c0d58fa13de82f2b481db_6.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ˜¯è¾“å…¥æˆ–ç‰¹å¾å¤§å°ã€‚æ‰€ä»¥è¿™æ˜¯æˆ‘ä»¬è¾“å…¥æ‰€éœ€çš„å½¢çŠ¶ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_6.png)
- en: And againï¼Œ you can find this in the documentationã€‚ So if you set batch first
    to trueã€‚ then here you need this shapeã€‚![](img/4923e3db142c0d58fa13de82f2b481db_8.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œä½ å¯ä»¥åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°è¿™ä¸ªã€‚æ‰€ä»¥å¦‚æœä½ å°†batch firstè®¾ç½®ä¸ºtrueï¼Œé‚£ä¹ˆåœ¨è¿™é‡Œä½ éœ€è¦è¿™ä¸ªå½¢çŠ¶ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_8.png)
- en: So now what we want to do is before we pass the images to our modelã€‚ So last
    time we reshaped it to be this sizeã€‚ So originally our batch or our images have
    the size the batch size than a one and then 28 and then 28 againã€‚ So this time
    we only want to have our batch size and then 28 by 28ã€‚ So here we reshape it to
    be this size and then the 28ã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æƒ³è¦åšçš„æ˜¯åœ¨å°†å›¾åƒä¼ é€’ç»™æˆ‘ä»¬çš„æ¨¡å‹ä¹‹å‰ã€‚æ‰€ä»¥ä¸‹æ¬¡æˆ‘ä»¬å°†å…¶è°ƒæ•´ä¸ºè¿™ä¸ªå¤§å°ã€‚å› æ­¤ï¼Œæœ€åˆæˆ‘ä»¬çš„batchæˆ–å›¾åƒçš„å¤§å°æ˜¯batch sizeï¼Œç„¶åæ˜¯1ï¼Œç„¶åæ˜¯28ï¼Œç„¶åå†28ã€‚å› æ­¤ï¼Œè¿™æ¬¡æˆ‘ä»¬åªæƒ³è¦batch
    sizeï¼Œç„¶åæ˜¯28ä¹˜28ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬å°†å…¶è°ƒæ•´ä¸ºè¿™ä¸ªå¤§å°ï¼Œç„¶åæ˜¯28ã€‚
- en: the first one is our sequence length and the second one is our input sizeã€‚ So
    these are both 28ã€‚ and the same in our so this is in our training loop and then
    later in our evaluation loopã€‚ we do the sameã€‚ So here we also have to reshape
    it toã€‚This sizeã€‚ So now we have our input in the correct shapeã€‚And now we need
    one more layerã€‚ So as I saidã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæ˜¯æˆ‘ä»¬çš„åºåˆ—é•¿åº¦ï¼Œç¬¬äºŒä¸ªæ˜¯æˆ‘ä»¬çš„è¾“å…¥å¤§å°ã€‚æ‰€ä»¥è¿™ä¸¤ä¸ªéƒ½æ˜¯28ã€‚åœ¨æˆ‘ä»¬çš„è®­ç»ƒå¾ªç¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œç„¶ååœ¨æˆ‘ä»¬çš„è¯„ä¼°å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬ä¹ŸåšåŒæ ·çš„äº‹æƒ…ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬è¿˜éœ€è¦å°†å…¶è°ƒæ•´ä¸ºè¿™ä¸ªå¤§å°ã€‚ç°åœ¨æˆ‘ä»¬çš„è¾“å…¥å½¢çŠ¶æ­£ç¡®äº†ã€‚ç°åœ¨æˆ‘ä»¬è¿˜éœ€è¦ä¸€å±‚ã€‚å› æ­¤ï¼Œæ­£å¦‚æˆ‘æ‰€è¯´ã€‚
- en: we are using this many to one architectureã€‚ So in the end we have a classification
    taskã€‚ So this means that we are using a linear layer and then later the soft marks
    and the crossenttropisã€‚ So let's create one more linear layerã€‚ So let's say self
    dot Fc for fully connected equals nn dot linearã€‚ And now here we want to be carefulã€‚
    So for the input sizeã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨è¿™ç§å¤šå¯¹ä¸€çš„æ¶æ„ã€‚æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬æœ‰ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªçº¿æ€§å±‚ï¼Œç„¶åæ˜¯ softmax å’Œäº¤å‰ç†µã€‚å› æ­¤è®©æˆ‘ä»¬å†åˆ›å»ºä¸€ä¸ªçº¿æ€§å±‚ã€‚æˆ‘ä»¬å¯ä»¥è¯´
    self dot Fcï¼Œè¡¨ç¤ºå…¨è¿æ¥å±‚ç­‰äº nn dot linearã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¦å°å¿ƒã€‚å¯¹äºè¾“å…¥å¤§å°ã€‚
- en: we use the hidden size and the output size is the number of classesã€‚ and I will
    explain this later againï¼Œ but basically as we can see in this image or also in
    this image we only use the last time step of ourã€‚ence to do the classificationã€‚
    So we only need the last hidden size as the input size for the linear layerã€‚ So
    this is basically the whole init functionã€‚ And nowï¼Œ of courseã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨éšè—å¤§å°ï¼Œè¾“å‡ºå¤§å°æ˜¯ç±»åˆ«çš„æ•°é‡ã€‚æˆ‘ç¨åä¼šå†æ¬¡è§£é‡Šï¼Œä½†åŸºæœ¬ä¸Šæ­£å¦‚æˆ‘ä»¬åœ¨è¿™å¼ å›¾åƒä¸­çœ‹åˆ°çš„ï¼Œæˆ–è€…åœ¨è¿™å¼ å›¾ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ¥è¿›è¡Œåˆ†ç±»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦æœ€åä¸€ä¸ªéšè—å¤§å°ä½œä¸ºçº¿æ€§å±‚çš„è¾“å…¥å¤§å°ã€‚è¿™åŸºæœ¬ä¸Šå°±æ˜¯æ•´ä¸ªåˆå§‹åŒ–å‡½æ•°ã€‚ç°åœ¨ï¼Œå½“ç„¶ã€‚
- en: we also need to implement the forward passã€‚ So our R and Nã€‚ If we have a look
    at the documentationã€‚![](img/4923e3db142c0d58fa13de82f2b481db_10.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦å®ç°å‰å‘ä¼ æ’­ã€‚å› æ­¤æˆ‘ä»¬çš„ R å’Œ Nã€‚å¦‚æœæˆ‘ä»¬æŸ¥çœ‹æ–‡æ¡£ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_10.png)
- en: Then it needs two inputsï¼Œ and the one is the the first one is the inputã€‚ and
    the second one is the initial hidden stateã€‚ So we need this in the correct shapeã€‚
    And so let's create an a tensor with just0ã€‚ So we say H0 equalsã€‚ And then let's
    say torch dot0sã€‚ And then here the first one is the number of layersã€‚ The second
    one is the batch sizeã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®ƒéœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼Œç¬¬ä¸€ä¸ªæ˜¯è¾“å…¥ï¼Œç¬¬äºŒä¸ªæ˜¯åˆå§‹éšè—çŠ¶æ€ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä»¥æ­£ç¡®çš„å½¢çŠ¶æ¥å¤„ç†è¿™ä¸ªã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª tensorï¼Œå†…å®¹ä¸º just0ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´
    H0 ç­‰äºã€‚ç„¶åæˆ‘ä»¬è¯´ torch dot0sã€‚åœ¨è¿™é‡Œï¼Œç¬¬ä¸€ä¸ªæ˜¯å±‚æ•°ï¼Œç¬¬äºŒä¸ªæ˜¯æ‰¹å¤§å°ã€‚
- en: So we get this by saying x dot size0ã€‚ The next dimension is the hidden sizeã€‚
    So we say self dot hidden sizeã€‚ And then we also want to push it to the deviceã€‚
    If you're using oneã€‚![](img/4923e3db142c0d58fa13de82f2b481db_12.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬é€šè¿‡è¯´ x dot size0 å¾—åˆ°è¿™ä¸ªã€‚ä¸‹ä¸€ä¸ªç»´åº¦æ˜¯éšè—å¤§å°ã€‚å› æ­¤æˆ‘ä»¬è¯´ self dot hidden sizeã€‚ç„¶åæˆ‘ä»¬è¿˜æƒ³å°†å…¶æ¨é€åˆ°è®¾å¤‡ä¸Šã€‚å¦‚æœä½ åœ¨ä½¿ç”¨ä¸€ä¸ªã€‚![](img/4923e3db142c0d58fa13de82f2b481db_12.png)
- en: So now this is our initial hidden stateï¼Œ and now we can call our R and N modelã€‚
    So we say out and then a underscore because we don't need thisã€‚ and then we say
    self dot R and Nã€‚ and this gets x and H0ã€‚ So againï¼Œ let's have a look at the documentationã€‚
    So it delivers two outputsã€‚ and the first tenor contains the output features or
    the hidden states from all the time stepsã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨è¿™æ˜¯æˆ‘ä»¬çš„åˆå§‹éšè—çŠ¶æ€ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥è°ƒç”¨æˆ‘ä»¬çš„ R å’Œ N æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ outï¼Œç„¶ååŠ ä¸‹åˆ’çº¿ï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦è¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬è¯´ self dot
    R å’Œ Nã€‚è¿™ä¼šå¾—åˆ° x å’Œ H0ã€‚æ‰€ä»¥å†æ¬¡æŸ¥çœ‹æ–‡æ¡£ã€‚å®ƒè¿”å›ä¸¤ä¸ªè¾“å‡ºï¼Œç¬¬ä¸€ä¸ª tensor åŒ…å«æ¥è‡ªæ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºç‰¹å¾æˆ–éšè—çŠ¶æ€ã€‚
- en: And the other one is just the hidden state for the step Nã€‚ So we don't need
    this in this caseã€‚ So now we have the output and the output is of sizeã€‚ This is
    batchã€‚![](img/4923e3db142c0d58fa13de82f2b481db_14.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œå¦ä¸€ä¸ªåªæ˜¯æ­¥éª¤ N çš„éšè—çŠ¶æ€ã€‚å› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬ä¸éœ€è¦è¿™ä¸ªã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº†è¾“å‡ºï¼Œè¾“å‡ºçš„å¤§å°æ˜¯ã€‚è¿™æ˜¯æ‰¹æ¬¡ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_14.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_15.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_15.png)'
- en: Btch sizeï¼Œ and then we have the sequence lengthï¼Œ and then we have the hidden
    sizeã€‚ So this is the new shape of our outputã€‚And now what we want to do is we
    want to decocode the hidden state only of the last time stepã€‚So what we have here
    againï¼Œ let's write this in numberã€‚ So this is nã€‚ and then 28ã€‚ and our hidden size
    is 128ã€‚ And now we only want the last time stepã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¹å¤§å°ï¼Œç„¶åæˆ‘ä»¬æœ‰åºåˆ—é•¿åº¦ï¼Œç„¶åæ˜¯éšè—å¤§å°ã€‚è¿™æ˜¯æˆ‘ä»¬è¾“å‡ºçš„æ–°å½¢çŠ¶ã€‚ç°åœ¨æˆ‘ä»¬æƒ³åšçš„æ˜¯ä»…è§£ç æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚å› æ­¤æˆ‘ä»¬è¿™é‡Œå†æ¬¡å†™å‡ºæ•°å­—ã€‚è¿™æ˜¯ nï¼Œå’Œ
    28ï¼Œè€Œæˆ‘ä»¬çš„éšè—å¤§å°æ˜¯ 128ã€‚ç°åœ¨æˆ‘ä»¬åªæƒ³è¦æœ€åä¸€ä¸ªæ—¶é—´æ­¥ã€‚
- en: So we want to have our out to be in n and then 128ã€‚ So we get this by saying
    out equals outã€‚ And then we use this slicing here and take allã€‚The samples in
    our batchã€‚ and then only the last time stepã€‚ So we can say-1ã€‚ And then againã€‚
    a colon for all the features in the hidden sizeã€‚ So now we have our out in this
    sizeã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„è¾“å‡ºåœ¨ n å’Œ 128ã€‚å› æ­¤æˆ‘ä»¬é€šè¿‡è¯´ out equals out å¾—åˆ°è¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨åˆ‡ç‰‡ï¼Œè·å–æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰æ ·æœ¬ï¼Œä¸”ä»…å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥ã€‚æˆ‘ä»¬å¯ä»¥è¯´
    -1ã€‚ç„¶åå†æ¬¡ä½¿ç”¨å†’å·è·å–éšè—å¤§å°ä¸­çš„æ‰€æœ‰ç‰¹å¾ã€‚ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†è¿™ä¸ªå¤§å°çš„è¾“å‡ºã€‚
- en: And now that's why we need the hidden size as the input size for our linear
    layerã€‚ So now we can call thatã€‚ So now we can say out equal self dot fully connected
    with our outã€‚ And then we return the outã€‚ So now this is the whole implementation
    that we need for our R and Nã€‚ Soã€‚Everything else stays the same in our training
    and evaluation loopã€‚ And againã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦éšè—å¤§å°ä½œä¸ºçº¿æ€§å±‚è¾“å…¥å¤§å°çš„åŸå› ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¯ä»¥è°ƒç”¨å®ƒã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è¯´outç­‰äºself.fully_connectedä¸æˆ‘ä»¬çš„outã€‚ç„¶åæˆ‘ä»¬è¿”å›outã€‚è¿™å°±æ˜¯æˆ‘ä»¬ä¸ºRå’ŒNæ‰€éœ€çš„æ•´ä¸ªå®ç°ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ä¸­çš„å…¶ä»–ä¸€åˆ‡ä¿æŒä¸å˜ã€‚å†æ¬¡ã€‚
- en: what we have to be careful here is to treat our input as a sequenceã€‚ And then
    when we use the build in R and N that we use the correct shapeã€‚ and then we need
    the initial hidden state also in the correct shapeã€‚ And then we have to reshape
    it before we pass it to our fully connected layerã€‚ So let's try it outã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦æ³¨æ„çš„æ˜¯å°†è¾“å…¥è§†ä¸ºä¸€ä¸ªåºåˆ—ã€‚å½“æˆ‘ä»¬ä½¿ç”¨å†…ç½®çš„Rå’ŒNæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ­£ç¡®çš„å½¢çŠ¶ã€‚ç„¶åæˆ‘ä»¬è¿˜éœ€è¦å°†åˆå§‹éšè—çŠ¶æ€è®¾ç½®ä¸ºæ­£ç¡®çš„å½¢çŠ¶ã€‚åœ¨å°†å…¶ä¼ é€’ç»™å…¨è¿æ¥å±‚ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»é‡æ–°è°ƒæ•´å®ƒçš„å½¢çŠ¶ã€‚æ‰€ä»¥æˆ‘ä»¬æ¥è¯•è¯•çœ‹ã€‚
- en: So let's say Python main dot piã€‚ğŸ˜Šï¼ŒAl rightï¼Œ so now training is done and as you
    can seeã€‚ we get a accuracy of 93%ã€‚ so our R and N works and you can see that it
    can be applied on this classification taskã€‚![](img/4923e3db142c0d58fa13de82f2b481db_17.png)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¯´Python main.piã€‚ğŸ˜Šï¼Œå¥½çš„ï¼Œç°åœ¨è®­ç»ƒå®Œæˆï¼Œæ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¾—åˆ°äº†93%çš„å‡†ç¡®ç‡ã€‚å› æ­¤æˆ‘ä»¬çš„Rå’ŒNæœ‰æ•ˆï¼Œä½ å¯ä»¥çœ‹åˆ°å®ƒå¯ä»¥åº”ç”¨äºè¿™ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_17.png)
- en: And now at the endï¼Œ I also want to show you two more R and N modulesã€‚ So two
    special kindsã€‚ The first one is the GR U or gated recurrent unitã€‚And the second
    one is the LSTM or long short term memoryã€‚ So both both are also very popular
    R and Nsã€‚ And I will not explain the theory about them right nowã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æœ€åï¼Œæˆ‘è¿˜æƒ³å‘ä½ å±•ç¤ºä¸¤ä¸ªRå’ŒNæ¨¡å—ã€‚æ‰€ä»¥ä¸¤ç§ç‰¹æ®Šç±»å‹ã€‚ç¬¬ä¸€ä¸ªæ˜¯GRUæˆ–é—¨æ§é€’å½’å•å…ƒã€‚ç¬¬äºŒä¸ªæ˜¯LSTMæˆ–é•¿çŸ­æœŸè®°å¿†ã€‚ä¸¤è€…ä¹Ÿæ˜¯éå¸¸æµè¡Œçš„Rå’ŒNã€‚æˆ‘ç°åœ¨ä¸ä¼šè§£é‡Šå®ƒä»¬çš„ç†è®ºã€‚
- en: I will just show you how easily we can use them as well with this implementationã€‚
    So let's use the R U firstã€‚ So we can simply say N N dot G R Uã€‚ And let's also
    call this self dot G R U and down here self dot G R Uã€‚ And everything else stay
    exactly the sameã€‚ So it takes the same input parametersã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†å‘ä½ å±•ç¤ºæˆ‘ä»¬å¦‚ä½•è½»æ¾åœ°ä½¿ç”¨è¿™äº›å®ç°ã€‚æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆä½¿ç”¨RUã€‚æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´nn.GRUã€‚ç„¶åå†ç§°ä¹‹ä¸ºself.GRUï¼Œä¸‹é¢ä¹Ÿç§°ä¸ºself.GRUã€‚å…¶ä»–ä¸€åˆ‡ä¿æŒä¸å˜ã€‚æ‰€ä»¥å®ƒæ¥å—ç›¸åŒçš„è¾“å…¥å‚æ•°ã€‚
- en: It also needs this hidden stateã€‚ And then the output is in the same shapeã€‚ So
    now let's run this with the G R U and test thisã€‚![](img/4923e3db142c0d58fa13de82f2b481db_19.png)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜éœ€è¦è¿™ä¸ªéšè—çŠ¶æ€ã€‚ç„¶åè¾“å‡ºå…·æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨GRUå¹¶æµ‹è¯•ä¸€ä¸‹ã€‚![](img/4923e3db142c0d58fa13de82f2b481db_19.png)
- en: Alrightï¼Œ so now as you can seeï¼Œ the GR U works tooã€‚ So the accuracy was even
    higher hereã€‚ And now as last thingï¼Œ let's also try the LSTMã€‚ So as you might know
    for the LSTMã€‚ we need an initial cell stateã€‚ So let's use the LSTMã€‚ So let's first
    call the cell dot LSTMã€‚ And then here we use Nn dot LSTMã€‚ The input parameters
    are still the sameã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼ŒGRUä¹Ÿèƒ½æ­£å¸¸å·¥ä½œã€‚è¿™é‡Œçš„å‡†ç¡®ç‡ç”šè‡³æ›´é«˜ã€‚æœ€åä¸€ä»¶äº‹ï¼Œè®©æˆ‘ä»¬ä¹Ÿè¯•è¯•LSTMã€‚æ­£å¦‚ä½ å¯èƒ½çŸ¥é“çš„ï¼Œå¯¹äºLSTMï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåˆå§‹å•å…ƒçŠ¶æ€ã€‚æ‰€ä»¥è®©æˆ‘ä»¬ä½¿ç”¨LSTMã€‚é¦–å…ˆè°ƒç”¨cell.LSTMã€‚ç„¶ååœ¨è¿™é‡Œä½¿ç”¨nn.LSTMã€‚è¾“å…¥å‚æ•°ä»ç„¶æ˜¯ç›¸åŒçš„ã€‚
- en: And then here we need an initial tenor for the cell stateã€‚ So let's call this
    C0ã€‚ And this has the same shapeã€‚ And then here we call the self dot LSTMã€‚ And
    this needs the hidden state and the cell state as a as a tuple hereã€‚ğŸ˜Šã€‚![](img/4923e3db142c0d58fa13de82f2b481db_21.png)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåˆå§‹çš„å•å…ƒçŠ¶æ€ã€‚æ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸ºC0ã€‚è¿™å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è°ƒç”¨è‡ªæˆ‘LSTMã€‚è¿™éœ€è¦éšè—çŠ¶æ€å’Œå•å…ƒçŠ¶æ€ä½œä¸ºä¸€ä¸ªå…ƒç»„åœ¨è¿™é‡Œã€‚ğŸ˜Šã€‚![](img/4923e3db142c0d58fa13de82f2b481db_21.png)
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_22.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4923e3db142c0d58fa13de82f2b481db_22.png)'
- en: So now this is all we need to apply the LSTMã€‚ So let's clear this and run it
    one more timeã€‚Alrightã€‚ so this one work 2ã€‚ and you can see the accuracy is 97%ã€‚
    Soï¼Œ yeahã€‚ so now you know how you can implement a R and N in Pyar using the build
    in R and N moduleã€‚ and you also know how you can use the tier U and the LSTMã€‚
    And yeahã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨è¿™å°±æ˜¯æˆ‘ä»¬åº”ç”¨LSTMæ‰€éœ€çš„ä¸€åˆ‡ã€‚è®©æˆ‘ä»¬æ¸…ç†ä¸€ä¸‹ï¼Œå†è¿è¡Œä¸€æ¬¡ã€‚å¥½çš„ï¼Œè¿™ä¸€æ¬¡å·¥ä½œå¾—å¾ˆå¥½ã€‚ä½ å¯ä»¥çœ‹åˆ°å‡†ç¡®ç‡æ˜¯97%ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œç°åœ¨ä½ çŸ¥é“å¦‚ä½•åœ¨Pyarä¸­å®ç°Rå’ŒNï¼Œä½¿ç”¨å†…ç½®çš„Rå’ŒNæ¨¡å—ã€‚ä½ ä¹ŸçŸ¥é“å¦‚ä½•ä½¿ç”¨GRUå’ŒLSTMã€‚å—¯ï¼Œæ˜¯çš„ã€‚
- en: I hope you enjoyed this tutorialã€‚ If you liked itã€‚ Then please consider subscribing
    to the channel and hit the like button and see you next time byeã€‚ğŸ˜Šã€‚![](img/4923e3db142c0d58fa13de82f2b481db_24.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ã€‚å¦‚æœä½ å–œæ¬¢å®ƒï¼Œè¯·è€ƒè™‘è®¢é˜…é¢‘é“å¹¶ç‚¹å‡»ç‚¹èµï¼Œä¸‹æ¬¡è§ï¼Œæ‹œæ‹œã€‚ğŸ˜Šã€‚![](img/4923e3db142c0d58fa13de82f2b481db_24.png)
