- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPyTorch ÊûÅÁÆÄÂÆûÊàòÊïôÁ®ãÔºÅÂÖ®Á®ã‰ª£Á†ÅËÆ≤Ëß£ÔºåÂú®ÂÆûË∑µ‰∏≠ÊéåÊè°Ê∑±Â∫¶Â≠¶‰π†&Êê≠Âª∫ÂÖ®pipelineÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P20ÔºöL20-
    RNN & LSTM & GRU - Âæ™ÁéØÁ•ûÁªèÁΩëÁªú - ShowMeAI - BV12m4y1S7ix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hi and welcome to your new Pytorch tutorial„ÄÇ Today„ÄÇ I show you how we can implement
    a recurrent neural net using the built in R and N module„ÄÇ In the last tutorialÔºå
    we implemented the R and N from scratch„ÄÇ and I highly recommend to watch this
    one first to understand the internal architecture of R Ns„ÄÇüòä„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And now todayÔºå we focus on the implementation with Pytorch's own module„ÄÇ so
    we don't have to implement everything by ourselves„ÄÇ I will show you how to use
    the RnN module„ÄÇ And then at the endÔºå I also show you how easily we can switch
    our Rn N model and use special kinds of RNs like LSTM and G„ÄÇ So let's start„ÄÇ and
    we are going to use my tutorial about a simple neural net as starting point„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So this is tutorial number 13 from my Pytorch beginner course„ÄÇ You can find
    the link to the video and also to the code on Gitub in the description below„ÄÇ
    So as I saidÔºå this is tutorial number 13„ÄÇ So I already grab this code and copied
    it to my editor„ÄÇ And then this exampleÔºå we are doing diit classification on the
    Mnes data sets„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And I have to say that image classification is not the typical example for RnNs„ÄÇ
    But what I want to demonstrate here is how we must treat our input„ÄÇüòä„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: As a sequence and then set up the correct shapesÔºå and it also shows that RnNs
    can indeed be used to get a high accuracy on this classification task„ÄÇ So last
    time we learned that the special thing about RnNs is that we work on sequences
    of vectors here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So we treat our input as a sequence„ÄÇ and there can be different types of Rnns„ÄÇ
    So in this example we used this many to one architecture„ÄÇ So here we have a sequence
    as a input and then only one output at the end„ÄÇ and this is our class label in
    this case„ÄÇ So let's jump to the code„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and the first thing we must change is the hyperparameter„ÄÇ So the Ms data set
    consists of images of size 28 by 28 pixels„ÄÇ and last time we squeeze that into
    one dimensions„ÄÇOur input size was 28 times 28 or 784„ÄÇ and this timeÔºå as I saidÔºå
    we treat the image as a sequence„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So what we do here now is we treat one image dimension as one sequence and the
    other image dimension as the input or feature size„ÄÇSo you can see this as that
    we are looking at one row at a time„ÄÇ So let's comment and this out„ÄÇ and let's
    create a new one„ÄÇ So let's say our input size equals„ÄÇ And nowÔºå as I said„ÄÇ we are
    looking at one row at a time„ÄÇ So this is 28„ÄÇ And then we also create the sequence
    length„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And this is also 28„ÄÇ And then we change the hidden size to be 128„ÄÇ So you can
    try our different sizes here„ÄÇ And we add another hyperparmeter„ÄÇ and this is the
    number of layers„ÄÇ And here I set this to2„ÄÇ So by defaultÔºå it is one„ÄÇ And this
    means that we are stacking in this caseÔºå two R and Ns together„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and the second R and N takes the output from the first R and n as an input„ÄÇ
    So this can further improve our model„ÄÇAnd now we want to implement the R and N
    class„ÄÇ So let's change the name to R and N„ÄÇ and also in this super method„ÄÇAnd
    then our model down here also now is the R and N„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And now let's delete all of this to start with a newÔºå fresh implementation„ÄÇSo
    now our R and N has still has the input size and the hidden size and the number
    of classes as parameters„ÄÇ And it also gets the new parameter number of layers„ÄÇ
    So let's put it in here„ÄÇ So let's say the number of layers here„ÄÇ And thenÔºå of
    course„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we must also pass it to our model when we create it„ÄÇ So this is our hyperparameter„ÄÇüòä„ÄÇAnd
    then what we want to do here first is we simply want to store the number of layers
    and the hidden size„ÄÇ So let's say self nu layers equals nu layers„ÄÇAnd alsoÔºå self
    dot„ÄÇHidden„ÄÇSize equals hidden size„ÄÇAnd then we create the R and N model and use
    the built in Pytorch R and N module„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So you can find this here on the official documentation„ÄÇ So this is the R and
    N class that Pytorch provides for us„ÄÇ So we are going to use this„ÄÇ So we create
    an R and N and say self R and N equals„ÄÇ And now this is in the NN module„ÄÇ So NN
    dot R and N„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_3.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_4.png)'
  prefs: []
  type: TYPE_IMG
- en: And the R and N needs the input size„ÄÇ It needs the hidden size„ÄÇ and it needs
    the number of layers in this order„ÄÇ And then we also use a parameter that is called
    batch first and set this to true„ÄÇ So this just means that we must have the batch
    as a first dimension„ÄÇ So our input needs to have the shape„ÄÇBtch size„ÄÇBch size
    and then the sequence length„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and then the input or feature size„ÄÇ So this is the shape that we need to have
    for our input„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_6.png)
  prefs: []
  type: TYPE_NORMAL
- en: And againÔºå you can find this in the documentation„ÄÇ So if you set batch first
    to true„ÄÇ then here you need this shape„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_8.png)
  prefs: []
  type: TYPE_NORMAL
- en: So now what we want to do is before we pass the images to our model„ÄÇ So last
    time we reshaped it to be this size„ÄÇ So originally our batch or our images have
    the size the batch size than a one and then 28 and then 28 again„ÄÇ So this time
    we only want to have our batch size and then 28 by 28„ÄÇ So here we reshape it to
    be this size and then the 28„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: the first one is our sequence length and the second one is our input size„ÄÇ So
    these are both 28„ÄÇ and the same in our so this is in our training loop and then
    later in our evaluation loop„ÄÇ we do the same„ÄÇ So here we also have to reshape
    it to„ÄÇThis size„ÄÇ So now we have our input in the correct shape„ÄÇAnd now we need
    one more layer„ÄÇ So as I said„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we are using this many to one architecture„ÄÇ So in the end we have a classification
    task„ÄÇ So this means that we are using a linear layer and then later the soft marks
    and the crossenttropis„ÄÇ So let's create one more linear layer„ÄÇ So let's say self
    dot Fc for fully connected equals nn dot linear„ÄÇ And now here we want to be careful„ÄÇ
    So for the input size„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we use the hidden size and the output size is the number of classes„ÄÇ and I will
    explain this later againÔºå but basically as we can see in this image or also in
    this image we only use the last time step of our„ÄÇence to do the classification„ÄÇ
    So we only need the last hidden size as the input size for the linear layer„ÄÇ So
    this is basically the whole init function„ÄÇ And nowÔºå of course„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we also need to implement the forward pass„ÄÇ So our R and N„ÄÇ If we have a look
    at the documentation„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_10.png)
  prefs: []
  type: TYPE_NORMAL
- en: Then it needs two inputsÔºå and the one is the the first one is the input„ÄÇ and
    the second one is the initial hidden state„ÄÇ So we need this in the correct shape„ÄÇ
    And so let's create an a tensor with just0„ÄÇ So we say H0 equals„ÄÇ And then let's
    say torch dot0s„ÄÇ And then here the first one is the number of layers„ÄÇ The second
    one is the batch size„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So we get this by saying x dot size0„ÄÇ The next dimension is the hidden size„ÄÇ
    So we say self dot hidden size„ÄÇ And then we also want to push it to the device„ÄÇ
    If you're using one„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_12.png)
  prefs: []
  type: TYPE_NORMAL
- en: So now this is our initial hidden stateÔºå and now we can call our R and N model„ÄÇ
    So we say out and then a underscore because we don't need this„ÄÇ and then we say
    self dot R and N„ÄÇ and this gets x and H0„ÄÇ So againÔºå let's have a look at the documentation„ÄÇ
    So it delivers two outputs„ÄÇ and the first tenor contains the output features or
    the hidden states from all the time steps„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And the other one is just the hidden state for the step N„ÄÇ So we don't need
    this in this case„ÄÇ So now we have the output and the output is of size„ÄÇ This is
    batch„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_14.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_15.png)'
  prefs: []
  type: TYPE_IMG
- en: Btch sizeÔºå and then we have the sequence lengthÔºå and then we have the hidden
    size„ÄÇ So this is the new shape of our output„ÄÇAnd now what we want to do is we
    want to decocode the hidden state only of the last time step„ÄÇSo what we have here
    againÔºå let's write this in number„ÄÇ So this is n„ÄÇ and then 28„ÄÇ and our hidden size
    is 128„ÄÇ And now we only want the last time step„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So we want to have our out to be in n and then 128„ÄÇ So we get this by saying
    out equals out„ÄÇ And then we use this slicing here and take all„ÄÇThe samples in
    our batch„ÄÇ and then only the last time step„ÄÇ So we can say-1„ÄÇ And then again„ÄÇ
    a colon for all the features in the hidden size„ÄÇ So now we have our out in this
    size„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And now that's why we need the hidden size as the input size for our linear
    layer„ÄÇ So now we can call that„ÄÇ So now we can say out equal self dot fully connected
    with our out„ÄÇ And then we return the out„ÄÇ So now this is the whole implementation
    that we need for our R and N„ÄÇ So„ÄÇEverything else stays the same in our training
    and evaluation loop„ÄÇ And again„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: what we have to be careful here is to treat our input as a sequence„ÄÇ And then
    when we use the build in R and N that we use the correct shape„ÄÇ and then we need
    the initial hidden state also in the correct shape„ÄÇ And then we have to reshape
    it before we pass it to our fully connected layer„ÄÇ So let's try it out„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So let's say Python main dot pi„ÄÇüòäÔºåAl rightÔºå so now training is done and as you
    can see„ÄÇ we get a accuracy of 93%„ÄÇ so our R and N works and you can see that it
    can be applied on this classification task„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_17.png)
  prefs: []
  type: TYPE_NORMAL
- en: And now at the endÔºå I also want to show you two more R and N modules„ÄÇ So two
    special kinds„ÄÇ The first one is the GR U or gated recurrent unit„ÄÇAnd the second
    one is the LSTM or long short term memory„ÄÇ So both both are also very popular
    R and Ns„ÄÇ And I will not explain the theory about them right now„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I will just show you how easily we can use them as well with this implementation„ÄÇ
    So let's use the R U first„ÄÇ So we can simply say N N dot G R U„ÄÇ And let's also
    call this self dot G R U and down here self dot G R U„ÄÇ And everything else stay
    exactly the same„ÄÇ So it takes the same input parameters„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: It also needs this hidden state„ÄÇ And then the output is in the same shape„ÄÇ So
    now let's run this with the G R U and test this„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_19.png)
  prefs: []
  type: TYPE_NORMAL
- en: AlrightÔºå so now as you can seeÔºå the GR U works too„ÄÇ So the accuracy was even
    higher here„ÄÇ And now as last thingÔºå let's also try the LSTM„ÄÇ So as you might know
    for the LSTM„ÄÇ we need an initial cell state„ÄÇ So let's use the LSTM„ÄÇ So let's first
    call the cell dot LSTM„ÄÇ And then here we use Nn dot LSTM„ÄÇ The input parameters
    are still the same„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And then here we need an initial tenor for the cell state„ÄÇ So let's call this
    C0„ÄÇ And this has the same shape„ÄÇ And then here we call the self dot LSTM„ÄÇ And
    this needs the hidden state and the cell state as a as a tuple here„ÄÇüòä„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_21.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4923e3db142c0d58fa13de82f2b481db_22.png)'
  prefs: []
  type: TYPE_IMG
- en: So now this is all we need to apply the LSTM„ÄÇ So let's clear this and run it
    one more time„ÄÇAlright„ÄÇ so this one work 2„ÄÇ and you can see the accuracy is 97%„ÄÇ
    SoÔºå yeah„ÄÇ so now you know how you can implement a R and N in Pyar using the build
    in R and N module„ÄÇ and you also know how you can use the tier U and the LSTM„ÄÇ
    And yeah„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed this tutorial„ÄÇ If you liked it„ÄÇ Then please consider subscribing
    to the channel and hit the like button and see you next time bye„ÄÇüòä„ÄÇ![](img/4923e3db142c0d58fa13de82f2b481db_24.png)
  prefs: []
  type: TYPE_NORMAL
