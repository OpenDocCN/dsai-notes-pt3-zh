# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P2ï¼šL2- Pipelineç®¡é“ - ShowMeAI - BV1cF411v7kC

Inst pytorch or Tensofflow firstã€‚ And then in order to install the Transers libraryã€‚ you just have to say Pip install transformersã€‚ or there's also a Conda installation command that you can find on the installation pageã€‚ So let's install it like thisã€‚ So I already did thisã€‚ And then we can start using thisã€‚ So we can say from transformersã€‚ and then we import a pipeline as first thing and have a look at thisã€‚

 And then we also import some utilities that we need from the Pytorch libraryã€‚ So we import torchã€‚ and we import torch dot N and functional S Fã€‚ So we are going to use this laterã€‚ And now we can start using this pipelineã€‚ So let's say classifier equalsã€‚ And then we create a pipelineã€‚ And we need to specify theã€‚Task that we wantã€‚ So in this caseã€‚

 we want to do sentiment analysisã€‚ So we have to call it like thisã€‚ and you will find the different available tasks on the websiteã€‚ So here we can seeï¼Œ for exampleã€‚ we have this sentiment analysisï¼Œ which is just an alias of text classificationã€‚ but for exampleã€‚ we also have a question answering pipeline or a text generation or a conversational pipelineã€‚

 So yeahï¼Œ this is how we can define a pipelineã€‚ And what a pipeline does is that it gives you a great and easy way to use model for inferenceã€‚ And it abstracts a lot of the things for youã€‚ So you will see what I mean in a momentã€‚ So now we can just use this classifier and classify some text by saying rest for results equalsã€‚ğŸ˜Šã€‚

![](img/d2024fcd457ee0c9f1e1c4d9510eb3b1_1.png)

![](img/d2024fcd457ee0c9f1e1c4d9510eb3b1_2.png)

And then we call this classifier and we want to classify a example textã€‚ So let me copy and paste some example text for youã€‚ So we want to classifyã€‚ we are very happy to show you the smileyface transformers libraryã€‚ And then let's print the result and see how this looks likeã€‚ So let's run the codeã€‚ Alrightã€‚

 and as you can seeï¼Œ we get the label is positive and the score is 0ã€‚99ã€‚ So it's very confident that this is a positive sentenceã€‚ And as you can see it only takes two lines of code with this pipeline to create a sentiment analysis codeã€‚ So yeahï¼Œ this is exactly what we need so we need to see the label of the text if it's negative or positiveã€‚

 and we also get the scoreã€‚ So yeahï¼Œ this is really niceã€‚ And now let's have a look at some more things that we can do with this pipelineã€‚ So first of allã€‚ğŸ˜Šã€‚Can put in more texts at onceï¼Œ so we can not just use oneï¼Œ so we can give it a listã€‚ So let'sã€‚ for exampleï¼Œ use a listã€‚ and then let's use another example textã€‚

 So let me copy and paste this one in here as wellã€‚ So we also want to classify this We hope you don't hate itã€‚ And then we get multiple results backã€‚ So let's call this resultã€‚ and then we can iterate over thisã€‚ So we can say four result in resultsã€‚ and then we want to print the result And now let's run this code and have a look at how this looks likeã€‚

 Alrightï¼Œ and as you can see for the second textã€‚ we get another result backã€‚ So here the label is negativeã€‚ and the score is maybe not that confident in this caseã€‚ So this text might be a little bit confusingã€‚ We hope you don't hate itã€‚ But basically this is how you can pass inã€‚Multiple texts at onceã€‚ And nowï¼Œ so right nowã€‚

 we only use the default pipeline with the default modelã€‚ But now let's have a look at how we can use a concrete modelã€‚ And then also how we can use a concrete tokenizerã€‚ So what we can do is we can specify the model name and say model name equalsã€‚ And in this caseã€‚

 I use dist bird base uncased and then fine tuneund SST to Englishã€‚ So I will show you where I got this string or this name in a momentã€‚ But for nowï¼Œ yeahã€‚ this is basically just a dist bird modelï¼Œ which is a smaller and faster version of birdã€‚ But it was pretrained on the same corpusã€‚ And then you see that it also was fine tuneund and this is just the name of the dataã€‚

 So in this caseï¼Œ it's an English data from theã€‚Standford sentiment 3 bank version 2ã€‚ And yeahã€‚ so now if we have the model nameï¼Œ we can give this to our pipeline with the model argumentã€‚ so we can say model equals and then we use this model nameã€‚ So now in this caseã€‚ I can tell you that the default model for the sentiment analysis task is already this model nameã€‚

 So this should do exactly the sameã€‚ But later we will switch this and then have a look at how we can use different modelsã€‚ So first of allï¼Œ let's run this again and see that this is still the sameã€‚ Alrightã€‚ so we see this is still the same resultã€‚ So this workedã€‚ So now we just use this string to define our modelã€‚

 But now let's have a different approach to define a model and then also a tokenizerã€‚ So this will give us a little bit more flexibility laterã€‚ So in order toã€‚ğŸ˜Šï¼ŒDo thisã€‚ we want to say from transformersã€‚ and then here I import a auto tokenizer class and auto model for sequence classificationã€‚ and this is just a generic class for a tokenizer and this is also a generic classã€‚

 but a little bit more specificsã€‚ in this caseï¼Œ I want to have it for sequence classificationã€‚ And then it will give me a little bit more functionality specifically for this taskã€‚ So don't worry about this right nowï¼Œ you can also find all the model classes available in the documentationã€‚ So if you're interested then have a look at thisã€‚ And also if you use Tensorflowã€‚

 then here you have to say Tf and then the name of this classã€‚ but the rest is actually the sameã€‚ So yeahï¼Œ this is how you use Tensorflowã€‚ And now after importingã€‚ğŸ˜Šã€‚We can create two instances of this so we can do we can say model equals and then we use this classã€‚ so auto model for sequence classification and then we use a function that is called so let's say dot from pretrained and then it also needs the model name and we do the same with the tokenizerã€‚

 So we say tokenizer equals the auto to tokenizer dot from pretrained and then it needs the model name So this dot from pretrained function is a very important function in Haging phase that you will see a lot so you will see this later a few more times So now that we created this we can also just give the actual model and not just the string to the classifierã€‚

or to the pipeline so we can say our model equals our model and our tokenizer equals our tokenizerã€‚ So now if we run thisï¼Œ we should still get the same results because these are the default versions and yeahã€‚ as we seeï¼Œ we still get the same resultsã€‚ But then later if you want to use a different model or tokenizerã€‚ then you know how you can switch thisã€‚ So just by using a different model and tokenizer here for the pipelineã€‚

 So now instead of using this pipelineã€‚![](img/d2024fcd457ee0c9f1e1c4d9510eb3b1_4.png)