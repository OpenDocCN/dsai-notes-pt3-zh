# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P47ï¼šL9.1- Kerasè¿ç§»å­¦ä¹ ç®€ä»‹ - ShowMeAI - BV15f4y1w7b8

![](img/57e575643f505aee4c9c36ac4901f183_0.png)

Hiï¼Œ this is Jeff Heatonã€‚ Welcom to applications of deep neural networks with Washington Universityã€‚

 You know whatï¼Œ It's a lot of work to train a neural networkï¼Œ and it can take a lot of compute timeã€‚

 It's mostly your computer doing the workï¼Œ but still it can take a longï¼Œ long timeã€‚

 especially if you don't have a multi thousand dollar GPUã€‚

 This is where transferfer learning comes in handyã€‚ Transfer learningï¼Œ lets you takeã€‚ğŸ˜Šã€‚

Neurural networks that were developed by larger companies or startups or other people who have a lot of money to blow on GPUsã€‚

 and you can use this training in your own projects for the latest on my AI course and projectsã€‚

 click subscribe in the bell next to it to be notified of every new videoã€‚



![](img/57e575643f505aee4c9c36ac4901f183_2.png)

![](img/57e575643f505aee4c9c36ac4901f183_3.png)

Transfer learning is a very important concept in deep learningã€‚

 This is because it can take a tremendous amount of timeã€‚

 Compute resources and money to train advanced neural networksã€‚

 particularly in the area of computer vision and natural language processingã€‚

 You don't see transfer learning as much with tabular dataã€‚

 because there's just not a lot of actual neural networks out there that are already trained for that sort of thingã€‚

 It depends on your data set for tabular and the tabular dataset sets tend to be very differentã€‚

 Comp imaging and computer vision there tends to be a lot of commonalitiesã€‚

 Some of the elements that you will see like edges and wheels and eyesï¼Œ nosesã€‚

 mouths are common across manyï¼Œ many computer vision tasksã€‚

 So you can take some of the learning that large companies such as Google and Microsoft and others have put into trainingã€‚

 these advanced neural networks and transferã€‚ğŸ˜Šï¼ŒData into your neural network to begin as a basisã€‚

 So if you're going to teach a neural network to recognize a couple of very specific image typesã€‚

 you probably don't want to train the neural network entirely from scratchã€‚

 if you can transfer in a neural network weight system that has already been trained on imagenet or some of the other common computer vision data setsã€‚

 The way that this works is you will typically find a pretrained neural network that will have a variety of layersã€‚

 it doesn't even really matter exactly what these layers areã€‚

 you can definitely display them and we'll see that when we run the programs here for this exampleã€‚

 and you will typically shear off the top partã€‚ So imagenet is very common one and some of the others you'll typically see them trained for 10 different image categoriesã€‚

 So we might want to train it for something much smaller than thatã€‚ We willã€‚

Move that top layer and transfer just these layersã€‚ These layersã€‚

 All of the weights are going to move across into our neural networkã€‚

 and we will train just the new layers that we add for our new neural networkã€‚

 So here we add a dense layer that is going to learn from these lower layers and only these top two layers are going to actually be trainedã€‚

 These bottom layers essentially become feature engineeringï¼Œ especially for computer vision tasksã€‚

 These are learning all of the building blocks that went into imagenet and the other dataset sets that the neural network was trained onã€‚

 Firstï¼Œ we're going to look at a very simple transfer learning exampleã€‚

 and this will be tabular dataã€‚ This lets you look at a very simple will use the iris data setã€‚

 just so that we can see the mechanics of how this all comes togetherã€‚ Typicallyã€‚

 you probably won't be creating transfer learning neural networks that others will transfer into theirs unless you're going to reallyã€‚

ğŸ˜Šï¼ŒCommit to getting a lot of data and building an advanced training set up with GPUs and other things like that and spending some serious money For this oneã€‚

 thoughï¼Œ we will create that initial neural network that we are going to transfer into something elseã€‚

 and we're going to we're going to basically try to learn to classify some additional flowers beyond those three irriss that the data was originally set up forã€‚

 We'll hope that some of the learning for the original iris data set will transfer to this new oneã€‚

 So here the first thing we're going to do is actually get our training data loaded in and build our neural networkã€‚

 So this neural network that we're building here this simulates what the tech companies or researchers are doing using advanced computer rays to really seriously train theseã€‚

 So now we have a iris data setã€‚ We would probably save it at this point so that we could transfer itã€‚

 We'll check the accuracy real quickã€‚ which runs about 98%ã€‚ So that's pretty accurate andã€‚

Print out the summaryã€‚ We use summary a lot to analyze the neural networks that we're transferring in Here we can see that we essentially have some dense layersã€‚

 the 50ï¼Œ25 and3ï¼Œ just like we set up up here for the neural networkã€‚

 So 5025 and 3 summary can be very good for looking at these things and seeing what's going onã€‚

 total parameters So that's how many weights we have in the neural network trainable parameters is the same in this case because everything is trainable Now when we transfer this simple neural network into something elseã€‚

 we're going to mark some of these untrainable and we'll see thatã€‚

 So now I am going to show you that basically we can rebuild this neural networkã€‚

 we're creating model2 sequentialã€‚ and I'm taking all the layers in the original model and adding them when we run thisã€‚

 we see an exact duplicate up here 1603 just like we had up hereã€‚ And just as a sanity checkã€‚

 we're going to evaluate model 2ã€‚SeeHere and see what the accuracy isã€‚

 the accuracy should exactly match the original one that we transferredã€‚

 So we have basically done transfer learning hereã€‚ We've transferred everythingã€‚

 which is typically not what you'll want to doã€‚ We would have a duplicate of this neural network that can classify the same three flowers that the original neural network could not too usefulã€‚

 where it becomes useful is if we have these fake flowers that we want to add to itã€‚

 Now I'm just calling them fake flowersï¼Œ because are hypotheticalã€‚ This shows againã€‚

 the mechanics you would go through if you wanted to truly create your own neural network that others could transferã€‚

 What we're going to do is create now model 3ã€‚ and I'm just going to move those first two layers in and drop off the output layerã€‚

 So these will be feature engineering for the new modelã€‚

 You'll see we have fewer parameters because we've dropped off the top layer that was going to do the top are the final layerã€‚

 depending on your perspectiveï¼Œ but the output layerï¼Œ what we dropped offã€‚ Now we're goingã€‚ğŸ˜Šã€‚

To add on a new softm layer with four output neurons to classify those fourth leg fake flowersã€‚

 We run that And we see that basically now we have the 5025ï¼Œ but we have a four attached to itã€‚ Nowã€‚

 we could have also added some additional dense layers to maybe give some additional processingã€‚

 But for this simple of a networkï¼Œ not reallyï¼Œ not really necessaryã€‚ Nowï¼Œ we alsoã€‚

 when we added these mark the new ones trainable falseã€‚ Nowã€‚

 for the original layers that we transferred inï¼Œ we march trainable is false up hereã€‚

 That's very important for transfer learningï¼Œ because we don't want to train the weights that we already hadã€‚

 that's what we're transferring inã€‚ That's the benefitã€‚

 So here you'll see that the total parameters is 1629ã€‚ But only 1525 of themï¼Œ the first two layersã€‚

 the input and the 5025ï¼Œ those are the only trainable layersã€‚ So those numbers are different hereã€‚

 I create just some contrived valuesã€‚ğŸ˜Šï¼ŒThat we will use for these four flowersã€‚

 I'm only giving two training samples on eachã€‚ But againã€‚

 this is just showing the mechanics that you would go throughã€‚

 Here's the one hot encoding for each of those four flowers that correspond to the X inputs hereã€‚

 We're going to fit the neural network with just training that final output layerã€‚

 and we're going to try to see how well it can classify those four new flower typesã€‚ We run itã€‚

 we see the accuracy the last time I run it was about 88ã€‚ We'll see what this is1ã€‚0ã€‚

 So actually perfect accuracy in this caseã€‚ So it's the stochastic nature of neural networksã€‚

 you'll get different resultsã€‚ So here we've gone through the entire process of thisã€‚

 So this is how you would truly create a neural network that you would want to transferã€‚

 The rest of this courseã€‚ we will be transferring in other people's neural networks to us rather than being the producer of thoseã€‚

 So we'll simply be the consumerï¼Œ which is usually how it goesã€‚

 Thank you for watching this video in the next videoã€‚ we're going to take a look at howã€‚ğŸ˜Šã€‚



![](img/57e575643f505aee4c9c36ac4901f183_5.png)

To actuallyã€‚Find some of theseã€‚Open neural networks that you can put into your own learning for transfer learningã€‚

 This content changes oftenã€‚ so subscribe to the channel to stay up to date on this course and other topics in artificial intelligenceã€‚

