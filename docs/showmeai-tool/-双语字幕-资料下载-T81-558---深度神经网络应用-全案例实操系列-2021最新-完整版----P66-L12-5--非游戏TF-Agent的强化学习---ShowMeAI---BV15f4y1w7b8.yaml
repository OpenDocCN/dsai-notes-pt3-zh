- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P66ï¼šL12.5- éæ¸¸æˆTF-Agentçš„å¼ºåŒ–å­¦ä¹ 
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P66ï¼šL12.5- éæ¸¸æˆTF-Agentçš„å¼ºåŒ–å­¦ä¹ 
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeffine and welcome to App of Deep neural Networks with Washington
    Universityã€‚So reinforcement learningï¼Œ most demos that you've seen of this probably
    lets you play some sort of Atari game or run a mountain car up a hill or balance
    a pole or something fun like thatã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯Jeffineï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚æ‰€ä»¥å¼ºåŒ–å­¦ä¹ ï¼Œä½ è§è¿‡çš„å¤§å¤šæ•°æ¼”ç¤ºå¯èƒ½è®©ä½ ç©æŸç§Atariæ¸¸æˆï¼Œæˆ–è€…æŠŠå±±åœ°è½¦å¼€ä¸Šå±±ï¼Œæˆ–è€…å¹³è¡¡ä¸€ä¸ªæ†å­ä¹‹ç±»çš„æœ‰è¶£äº‹æƒ…ã€‚
- en: What I haven't seen a lot of examples of is how to actually apply this to something
    that is not an Atari game or is not some sort of physics simulationã€‚What I'm going
    to show you in this video is how to actually apply reinforcement learning using
    TF agents to a problem of your own designã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ²¡æœ‰çœ‹åˆ°å¾ˆå¤šå®ä¾‹æ¥è¯´æ˜å¦‚ä½•å°†è¿™ä¸€ç‚¹å®é™…åº”ç”¨äºä¸æ˜¯Atariæ¸¸æˆæˆ–è€…æŸç§ç‰©ç†æ¨¡æ‹Ÿçš„ä¸œè¥¿ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨TF agentså°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºä½ è‡ªå·±è®¾è®¡çš„é—®é¢˜ã€‚
- en: Nowï¼Œ reinforcement learning is outside of the area of normal classification
    and regressionã€‚ really it's something where you're constantly performing actions
    on an environment of some sort and receiving feedback for thisã€‚The example that
    I'm going to show in this section is how to create sort of a financial simulationã€‚
    We're going to look at net wealth building and sort of personal financeã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¼ºåŒ–å­¦ä¹ è¶…å‡ºäº†æ­£å¸¸åˆ†ç±»å’Œå›å½’çš„èŒƒå›´ã€‚å®é™…ä¸Šï¼Œè¿™æ˜¯ä¸€ç§ä½ ä¸æ–­å¯¹æŸç§ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œå¹¶è·å–åé¦ˆçš„è¿‡ç¨‹ã€‚æˆ‘å°†åœ¨æœ¬èŠ‚ä¸­å±•ç¤ºçš„ä¾‹å­æ˜¯å¦‚ä½•åˆ›å»ºä¸€ç§é‡‘èæ¨¡æ‹Ÿã€‚æˆ‘ä»¬å°†å…³æ³¨å‡€è´¢å¯Œçš„ç§¯ç´¯å’Œä¸ªäººç†è´¢ã€‚
- en: This is really a pretty simple financial simulationã€‚ This is not meant to guide
    you and real life or how to do any sort of real financial investingã€‚ but it shows
    you how to actually put something that is not a video game into the context that
    it can be solved and worked with withã€‚Reinforcement learningï¼Œ and you can design
    an agent that can actually learn how to do this to see all my videos about Caleã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªç›¸å½“ç®€å•çš„é‡‘èæ¨¡æ‹Ÿã€‚è¿™å¹¶ä¸æ˜¯ä¸ºäº†æŒ‡å¯¼ä½ åœ¨ç°å®ç”Ÿæ´»ä¸­å¦‚ä½•è¿›è¡Œä»»ä½•å½¢å¼çš„çœŸå®æŠ•èµ„ï¼Œä½†å®ƒå±•ç¤ºäº†å¦‚ä½•å°†ä¸€äº›ä¸æ˜¯è§†é¢‘æ¸¸æˆçš„ä¸œè¥¿æ”¾å…¥å¯ä»¥è¢«è§£å†³å’Œå¤„ç†çš„ä¸Šä¸‹æ–‡ä¸­ã€‚å¼ºåŒ–å­¦ä¹ ï¼Œä½ å¯ä»¥è®¾è®¡ä¸€ä¸ªä»£ç†ï¼ŒçœŸæ­£å­¦ä¼šå¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œçœ‹çœ‹æˆ‘æ‰€æœ‰å…³äºCaleçš„è§†é¢‘ã€‚
- en: neural networks and other AI topicsï¼Œ click the subscribe button and the bell
    next to it and select all to be notified of every new video So now let's try to
    apply reinforcement learning to something that is not just in the open AI gym
    or an Atari game or something like thatã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¥ç»ç½‘ç»œå’Œå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜ï¼Œè¯·ç‚¹å‡»è®¢é˜…æŒ‰é’®åŠæ—è¾¹çš„é“ƒé“›ï¼Œå¹¶é€‰æ‹©å…¨éƒ¨ä»¥ä¾¿æ¥æ”¶æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚é‚£ä¹ˆç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºä¸€äº›ä¸ä»…ä»…æ˜¯åœ¨OpenAI
    gymæˆ–Atariæ¸¸æˆä¸­çš„ä¸œè¥¿ã€‚
- en: I'm going to create this problem literally from scratchã€‚ Now it's not going
    to be the most profound problem that I'm going to apply this toã€‚ It's really the
    idea of this demonstration is to show you how you can create your own environment
    and apply deep reinforcement learning to itã€‚ We're going to also look at the continuous
    action space and see how you can deal with having one or more actions that is
    a numberã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ä»é›¶å¼€å§‹åˆ›å»ºè¿™ä¸ªé—®é¢˜ã€‚ç°åœ¨è¿™å¹¶ä¸æ˜¯æˆ‘å°†è¦åº”ç”¨çš„æœ€æ·±å¥¥çš„é—®é¢˜ã€‚è¿™ä¸ªæ¼”ç¤ºçš„çœŸæ­£ç›®çš„æ˜¯å‘ä½ å±•ç¤ºå¦‚ä½•åˆ›å»ºè‡ªå·±çš„ç¯å¢ƒï¼Œå¹¶å°†æ·±åº¦å¼ºåŒ–å­¦ä¹ åº”ç”¨äºå…¶ä¸­ã€‚æˆ‘ä»¬è¿˜å°†æŸ¥çœ‹è¿ç»­åŠ¨ä½œç©ºé—´ï¼Œå¹¶äº†è§£å¦‚ä½•å¤„ç†ä¸€ä¸ªæˆ–å¤šä¸ªæ•°å€¼åŠ¨ä½œã€‚
- en: like how how far do you want to press down the accelerator pedalã€‚ say in a car
    or how hard to apply the brakesï¼Œ because you can do both of those at the same
    timeã€‚ For this example that I'm going to put togetherã€‚ It's going to be a finance
    kind of personal finance example where you areã€‚ğŸ˜Šã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åƒæ˜¯ä½ æƒ³æŠŠæ²¹é—¨è¸æ¿è¸©å¤šæ·±ï¼Œæ¯”å¦‚åœ¨è½¦é‡Œï¼Œæˆ–è€…åˆ¹è½¦è¦ç”¨å¤šå¤§çš„åŠ›ï¼Œå› ä¸ºä½ å¯ä»¥åŒæ—¶è¿›è¡Œè¿™ä¸¤é¡¹ã€‚å¯¹äºæˆ‘å°†è¦æ•´åˆçš„è¿™ä¸ªä¾‹å­ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªä¸ªäººç†è´¢çš„é‡‘èç¤ºä¾‹ã€‚ğŸ˜Š
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_1.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_1.png)'
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_2.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_2.png)'
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_3.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_3.png)'
- en: Letttting the agent be a person that is trying to invest and save for retirement
    it'll be a pretty simplified example where they can choose between putting their
    money in a tax deferred account like a United States IRA or they could choose
    a taxable account and there's limits you can only put so much in that tax deferred
    account you can also choose do you want to pay for your house you want to pay
    the mortgage off earlyã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è®©ä»£ç†æˆä¸ºä¸€ä¸ªè¯•å›¾æŠ•èµ„å’Œä¸ºé€€ä¼‘å‚¨è“„çš„äººï¼Œè¿™å°†æ˜¯ä¸€ä¸ªç›¸å½“ç®€åŒ–çš„ä¾‹å­ï¼Œä»–ä»¬å¯ä»¥é€‰æ‹©æŠŠé’±æ”¾å…¥ä¸€ä¸ªåƒç¾å›½IRAè¿™æ ·çš„ç¨å»¶è´¦æˆ·ï¼Œæˆ–è€…é€‰æ‹©ä¸€ä¸ªåº”ç¨è´¦æˆ·ï¼Œå¹¶ä¸”æœ‰ä¸€å®šçš„é™åˆ¶ï¼Œä½ åªèƒ½åœ¨é‚£ä¸ªç¨å»¶è´¦æˆ·ä¸­æ”¾å…¥è¿™ä¹ˆå¤šé’±ã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹©ï¼Œä½ æ˜¯æƒ³ä¸ºä½ çš„æˆ¿å­ä»˜æ¬¾ï¼Œè¿˜æ˜¯æƒ³æå‰è¿˜æ¸…æŠµæŠ¼è´·æ¬¾ã€‚
- en: all these kind of things So these are kind of step by step by step actions that
    are really conducive to reinforcement learning if I just wanted to the computer
    to look at a list of stocks and give me the best allocation for investing that
    would be more like a traditional neural network so we're gonna create an environment
    entirely of our own This is a class in TF agents an objectoriented class here
    are the rules you've got to make sure that you accomplish these things or you
    won't be able to use your new class It has to be a child of Jim environment then
    you've got toã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™äº›äº‹æƒ…éƒ½æ˜¯ä¸€æ­¥ä¸€æ­¥çš„åŠ¨ä½œï¼Œå®é™…ä¸Šå¯¹å¼ºåŒ–å­¦ä¹ éå¸¸æœ‰åˆ©ã€‚å¦‚æœæˆ‘åªæ˜¯æƒ³è®©è®¡ç®—æœºæŸ¥çœ‹ä¸€ä»½è‚¡ç¥¨åˆ—è¡¨å¹¶ç»™å‡ºæœ€ä½³æŠ•èµ„åˆ†é…ï¼Œé‚£æ›´åƒæ˜¯ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å®Œå…¨åˆ›å»ºä¸€ä¸ªè‡ªå·±çš„ç¯å¢ƒã€‚è¿™æ˜¯åœ¨TF
    Agentsä¸­çš„ä¸€ä¸ªé¢å‘å¯¹è±¡çš„ç±»ï¼Œä»¥ä¸‹æ˜¯è§„åˆ™ï¼šä½ å¿…é¡»ç¡®ä¿å®Œæˆè¿™äº›äº‹æƒ…ï¼Œå¦åˆ™å°†æ— æ³•ä½¿ç”¨ä½ çš„æ–°ç±»ã€‚å®ƒå¿…é¡»æ˜¯Jimç¯å¢ƒçš„å­ç±»ï¼Œç„¶åä½ å¿…é¡»ã€‚
- en: Iplement a seed function that allows your environment to be seeedã€‚ if you give
    it a constant seedã€‚ then you should get constant resultsã€‚ You need to implement
    a reset function that basically starts your environment over again is this is
    done often by the reinforcement learning algorithmsã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç°ä¸€ä¸ªç§å­å‡½æ•°ï¼Œä½¿ä½ çš„ç¯å¢ƒèƒ½å¤Ÿè¢«è®¾å®šã€‚å¦‚æœä½ ç»™å®ƒä¸€ä¸ªå¸¸é‡ç§å­ï¼Œé‚£ä¹ˆä½ åº”è¯¥å¾—åˆ°æ’å®šçš„ç»“æœã€‚ä½ éœ€è¦å®ç°ä¸€ä¸ªé‡ç½®å‡½æ•°ï¼ŒåŸºæœ¬ä¸Šæ˜¯é‡æ–°å¯åŠ¨ä½ çš„ç¯å¢ƒï¼Œè¿™é€šå¸¸æ˜¯å¼ºåŒ–å­¦ä¹ ç®—æ³•æ‰§è¡Œçš„æ“ä½œã€‚
- en: It's always turning back the clock and hitting reset and starting from the beginning
    This is not as criticalã€‚ but you need to implement a render functionã€‚ This draws
    one frame of your simulationã€‚ Now we're doing a finance simulation hereã€‚ and I
    kept it pretty simpleã€‚ We're just outputting text to a windowã€‚ same sort of thing
    step is a function that will take you through each step in the you apply an action
    to that step and then you see how the environment changes and we'll get to what
    the environment is in a momentã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ€»æ˜¯å›åˆ°èµ·ç‚¹å¹¶é‡ç½®ï¼Œä»å¤´å¼€å§‹ã€‚è¿™å¹¶ä¸æ˜¯ç‰¹åˆ«å…³é”®ï¼Œä½†ä½ éœ€è¦å®ç°ä¸€ä¸ªæ¸²æŸ“å‡½æ•°ã€‚è¿™ç»˜åˆ¶äº†æ¨¡æ‹Ÿçš„ä¸€ä¸ªå¸§ã€‚ç°åœ¨æˆ‘ä»¬åœ¨è¿™é‡Œåšçš„æ˜¯è´¢åŠ¡æ¨¡æ‹Ÿï¼Œæˆ‘ä¿æŒå¾—ç›¸å½“ç®€å•ã€‚æˆ‘ä»¬åªæ˜¯å‘ä¸€ä¸ªçª—å£è¾“å‡ºæ–‡æœ¬ã€‚ç±»ä¼¼çš„æ­¥éª¤æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒä¼šå¸¦ä½ ç»å†æ¯ä¸€æ­¥ï¼Œä½ å¯¹è¯¥æ­¥éª¤åº”ç”¨ä¸€ä¸ªåŠ¨ä½œï¼Œç„¶åä½ ä¼šçœ‹åˆ°ç¯å¢ƒçš„å˜åŒ–ï¼Œæˆ‘ä»¬ç¨åä¼šè®¨è®ºç¯å¢ƒæ˜¯ä»€ä¹ˆã€‚
- en: you also need to register your environment and we see the code to do this as
    well That's so that Tf agents can actually find your environment when when you
    want to spin it upã€‚ So here's the simulation thatã€‚Going to produce Now this is
    a very simple simulationã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜éœ€è¦æ³¨å†Œä½ çš„ç¯å¢ƒï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°ç”¨äºæ­¤çš„ä»£ç ã€‚è¿™æ ·TF Agentsæ‰èƒ½åœ¨ä½ æƒ³è¦å¯åŠ¨æ—¶æ‰¾åˆ°ä½ çš„ç¯å¢ƒã€‚å› æ­¤ï¼Œè¿™é‡Œæ˜¯å°†è¦ç”Ÿæˆçš„æ¨¡æ‹Ÿã€‚ç°åœ¨è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ¨¡æ‹Ÿã€‚
- en: This is just to show you how to get your own environment up and runningã€‚ I was
    tempted to just create my own mini video game or something like thatã€‚ but I might
    save that for a future exampleã€‚ but there's already enough examples of doing this
    I want something where we're playing a financial simulation doing personal finances
    is like the old Milton Bradley game of life a bit not to be confused with Conway's
    game of life which which is something elseã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸ºäº†å‘ä½ å±•ç¤ºå¦‚ä½•è®©è‡ªå·±çš„ç¯å¢ƒå¯åŠ¨å’Œè¿è¡Œã€‚æˆ‘æ›¾æƒ³ç®€å•åœ°åˆ›å»ºä¸€ä¸ªè¿·ä½ è§†é¢‘æ¸¸æˆæˆ–ç±»ä¼¼çš„ä¸œè¥¿ï¼Œä½†æˆ‘å¯èƒ½ä¼šæŠŠè¿™ä¸ªç•™åˆ°æœªæ¥çš„ç¤ºä¾‹ä¸­ã€‚ä¸è¿‡ï¼Œå·²ç»æœ‰è¶³å¤Ÿå¤šçš„ä¾‹å­æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘æƒ³è¦ä¸€äº›æˆ‘ä»¬åœ¨è¿›è¡Œè´¢åŠ¡æ¨¡æ‹Ÿçš„ä¸œè¥¿ï¼Œåšä¸ªäººç†è´¢æœ‰ç‚¹åƒè€è¿ˆå°”é¡¿Â·å¸ƒæ‹‰å¾·åˆ©çš„ã€Šäººç”Ÿæ¸¸æˆã€‹ï¼Œè€Œä¸”ä¸è¦ä¸åº·å¨çš„ã€Šç”Ÿå‘½æ¸¸æˆã€‹æ··æ·†ï¼Œé‚£æ˜¯å¦å¤–ä¸€å›äº‹ã€‚
- en: So you have a random starting salary between 40k and 60k dollars you have a
    home loan that starts out so you have to buy a home's I'm keeping it simple that
    is 1ã€‚5 times and four times you're starting salary so maybe you are very conservative
    or maybe kind of went nuts so this is looking at how much how much house this
    person can potentially afford and they'll need to adjust their strategy depending
    on how crazy they went on real estate purchases The home loan is always an amortized
    30 year fixed loan with a fixed monthly paymentã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ çš„èµ·å§‹è–ªèµ„åœ¨4ä¸‡åˆ°6ä¸‡ç¾å…ƒä¹‹é—´ï¼Œä½ æœ‰ä¸€ä¸ªå¼€å§‹æ—¶çš„æˆ¿è´·ï¼Œæ‰€ä»¥ä½ å¿…é¡»ä¹°æˆ¿ï¼Œæˆ‘æŠŠå®ƒç®€åŒ–ä¸ºæ˜¯1.5åˆ°4å€çš„èµ·å§‹è–ªèµ„ï¼Œæ‰€ä»¥ä¹Ÿè®¸ä½ éå¸¸ä¿å®ˆï¼Œæˆ–è€…æœ‰ç‚¹ç–¯ç‹‚ï¼Œè¿™é‡Œæ˜¯çœ‹è¿™ä¸ªäººå¯èƒ½è´Ÿæ‹…å¾—èµ·å¤šå°‘æˆ¿å­ï¼Œä»–ä»¬éœ€è¦æ ¹æ®åœ¨æˆ¿åœ°äº§è´­ä¹°ä¸ŠèŠ±è´¹çš„ç–¯ç‹‚ç¨‹åº¦è°ƒæ•´ç­–ç•¥ã€‚æˆ¿è´·å§‹ç»ˆæ˜¯ä¸€ä¸ª30å¹´å›ºå®šåˆ©ç‡çš„æ‘Šè¿˜è´·æ¬¾ï¼Œå›ºå®šçš„æœˆä¾›ã€‚
- en: If you don't make that paymentï¼Œ bad things will start to happen to you Pay higher
    than the homes monthly payment pays down the loan quicker Pay below the monthly
    price results in missed payments When you reach a certain number of paymentsã€‚
    I think I set it around 15ã€‚ they take your house away You don't lose the value
    but they sell it at auction and you loseã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸æŒ‰æ—¶ä»˜æ¬¾ï¼Œåäº‹å°±ä¼šå¼€å§‹å‘ç”Ÿã€‚æ”¯ä»˜é«˜äºæˆ¿å±‹æœˆä¾›çš„é‡‘é¢ä¼šæ›´å¿«åœ°å¿è¿˜è´·æ¬¾ï¼Œä½äºæœˆä¾›çš„æ”¯ä»˜ä¼šå¯¼è‡´é”™è¿‡ä»˜æ¬¾ã€‚å½“ä½ è¾¾åˆ°æŸä¸ªä»˜æ¬¾æ¬¡æ•°æ—¶ï¼Œæˆ‘è®°å¾—æˆ‘è®¾ç½®åœ¨15æ¬¡å·¦å³ï¼Œä»–ä»¬ä¼šæ”¶èµ°ä½ çš„æˆ¿å­ã€‚ä½ ä¸ä¼šå¤±å»ä»·å€¼ï¼Œä½†ä»–ä»¬ä¼šåœ¨æ‹å–ä¸­å‡ºå”®ï¼Œä½ ä¼šæŸå¤±ã€‚
- en: I think half of your equityã€‚ you can allocate income between luxury purchasesã€‚
    which in this game does absolutely nothing for you home payments either above
    or below the payment amount as well as a taxable and a tax advantage savings accountã€‚
    It might have been really interesting that if you spent more on luxury or are
    happier and you lived longer therefore you got longer to invest I don't knowã€‚
    might have been an interesting twist on this I'll probably take this game of life
    thing a bit further and do a separate video on it outside of the course where
    we look at a fairly complicated financial simulation So the state the state is
    composed of the following valuesã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºä½ çš„ä¸€åŠèµ„äº§å¯ä»¥åˆ†é…åœ¨å¥¢ä¾ˆæ¶ˆè´¹ä¹‹é—´ï¼Œè€Œåœ¨è¿™ä¸ªæ¸¸æˆä¸­è¿™å¯¹ä½ æ²¡æœ‰ä»»ä½•å¸®åŠ©ï¼Œæˆ¿å±‹æ”¯ä»˜æ— è®ºé«˜äºè¿˜æ˜¯ä½äºæ”¯ä»˜é‡‘é¢ï¼Œä»¥åŠä¸€ä¸ªåº”ç¨å’Œä¸€ä¸ªç¨æ”¶ä¼˜æƒ çš„å‚¨è“„è´¦æˆ·ã€‚å¦‚æœä½ åœ¨å¥¢ä¾ˆå“ä¸ŠèŠ±è´¹æ›´å¤šæˆ–æ›´å¿«ä¹ï¼Œå¹¶å› æ­¤æ´»å¾—æ›´ä¹…ï¼Œå› æ­¤ä½ æœ‰æ›´é•¿çš„æ—¶é—´æŠ•èµ„ï¼Œæˆ‘ä¸çŸ¥é“ã€‚å¯èƒ½è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„è½¬æŠ˜ï¼Œæˆ‘å¯èƒ½ä¼šå°†è¿™ä¸ªç”Ÿå‘½æ¸¸æˆå†æ·±å…¥ä¸€ç‚¹ï¼Œå¹¶åœ¨è¯¾ç¨‹ä¹‹å¤–åšä¸€ä¸ªå•ç‹¬çš„è§†é¢‘ï¼Œçœ‹çœ‹ä¸€ä¸ªç›¸å½“å¤æ‚çš„é‡‘èæ¨¡æ‹Ÿã€‚å› æ­¤ï¼ŒçŠ¶æ€ç”±ä»¥ä¸‹å€¼ç»„æˆã€‚
- en: This is what the program is looking at to determine what it should doã€‚The age
    of the person in monthsï¼Œ the salary Now the salary goes up slowly relative to
    inflationã€‚ no chances for promotions or anything like thatã€‚ So it's pretty simple
    simulationã€‚ the home valueã€‚ This will increase relative to inflationã€‚ This is
    the required home paymentã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç¨‹åºåœ¨æŸ¥çœ‹ä»¥ç¡®å®šå®ƒåº”è¯¥åšä»€ä¹ˆã€‚äººçš„å¹´é¾„ï¼ˆæœˆæ•°ï¼‰ï¼Œè–ªæ°´ã€‚ç°åœ¨è–ªæ°´ç›¸å¯¹äºé€šè´§è†¨èƒ€ç¼“æ…¢å¢é•¿ï¼Œæ²¡æœ‰æ™‹å‡æœºä¼šæˆ–å…¶ä»–ç±»ä¼¼çš„ä¸œè¥¿ã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªç›¸å½“ç®€å•çš„æ¨¡æ‹Ÿã€‚æˆ¿å±‹ä»·å€¼ï¼Œè¿™å°†ç›¸å¯¹äºé€šè´§è†¨èƒ€å¢åŠ ã€‚è¿™æ˜¯æ‰€éœ€çš„æˆ¿å±‹æ”¯ä»˜ã€‚
- en: This will stay the same mostly the only time this will change is when you pay
    off your home then it goes to zeroã€‚ This is the account balance for the tax advantageã€‚
    This is similar to a United States IRA accountã€‚ individual retirement accountã€‚
    and then the taxable accountã€‚ This is similar to just a standard money market
    savings accountã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šä¼šä¿æŒä¸å˜ï¼Œå”¯ä¸€ä¼šæ”¹å˜çš„æƒ…å†µæ˜¯å½“ä½ è¿˜æ¸…æˆ¿è´·æ—¶ï¼Œå®ƒä¼šå˜ä¸ºé›¶ã€‚è¿™æ˜¯ç¨æ”¶ä¼˜æƒ çš„è´¦æˆ·ä½™é¢ï¼Œè¿™ç±»ä¼¼äºç¾å›½çš„ä¸ªäººé€€ä¼‘è´¦æˆ·ï¼ˆIRAï¼‰ï¼Œç„¶åæ˜¯åº”ç¨è´¦æˆ·ï¼Œè¿™ç±»ä¼¼äºæ ‡å‡†çš„è´§å¸å¸‚åœºå‚¨è“„è´¦æˆ·ã€‚
- en: It does pay you some actually pays you pretty good interest compared to what
    a money market would doã€‚ So this assumes you probably have this invested in a
    independent brokerage accountã€‚ selflf-directed brokerage accountã€‚ least that's
    what they call them in in the USã€‚ then the actionã€‚ So the action is floating point
    because we're doing a continuous action spaceã€‚ Unlike previouslyã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒç¡®å®ç»™ä½ ä¸€äº›æ”¶ç›Šï¼Œå®é™…ä¸Šæ¯”è´§å¸å¸‚åœºçš„æ”¶ç›Šè¦å¥½ã€‚å› æ­¤è¿™å‡è®¾ä½ å¯èƒ½å°†å…¶æŠ•èµ„äºä¸€ä¸ªç‹¬ç«‹çš„ç»çºªè´¦æˆ·ï¼Œè‡ªæˆ‘ç®¡ç†çš„ç»çºªè´¦æˆ·ï¼Œè‡³å°‘åœ¨ç¾å›½ä»–ä»¬ç§°ä¹‹ä¸ºè¿™æ ·ã€‚ç„¶åæ˜¯è¡ŒåŠ¨ã€‚å› æ­¤ï¼Œè¡ŒåŠ¨æ˜¯æµ®åŠ¨çš„ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åšä¸€ä¸ªè¿ç»­çš„è¡ŒåŠ¨ç©ºé—´ã€‚ä¸åƒä¹‹å‰ã€‚
- en: The agent puts a number into each of these fourã€‚ And then I normalize them so
    that they someã€‚To to one to get percentsã€‚ So if you put 11ï¼Œ111 on all of theseã€‚
    that would normalize out to 25% into eachã€‚ So this is just letting you pick your
    percents that you want to devote of your salary to the home loan to the savings
    tax advantage account to the normal taxable savings account into luxuriesã€‚ Now
    this doesn't guarantee that you'll get all of these percents in there because
    there's various things going on hereã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç†åœ¨è¿™å››ä¸ªä¸­è¾“å…¥ä¸€ä¸ªæ•°å­—ã€‚ç„¶åæˆ‘å¯¹å®ƒä»¬è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å®ƒä»¬çš„æ€»å’Œä¸º1ï¼Œä»¥ä¾¿å¾—åˆ°ç™¾åˆ†æ¯”ã€‚æ‰€ä»¥å¦‚æœä½ åœ¨æ‰€æœ‰è¿™äº›ä¸Šè¾“å…¥11,111ï¼Œå®ƒå°†å½’ä¸€åŒ–ä¸ºæ¯ä¸ª25%ã€‚æ‰€ä»¥è¿™åªæ˜¯è®©ä½ é€‰æ‹©å¸Œæœ›å°†å·¥èµ„çš„ç™¾åˆ†æ¯”åˆ†é…ç»™æˆ¿è´·ã€ç¨æ”¶ä¼˜æƒ å‚¨è“„è´¦æˆ·ã€æ­£å¸¸åº”ç¨å‚¨è“„è´¦æˆ·å’Œå¥¢ä¾ˆå“ã€‚ç°åœ¨è¿™å¹¶ä¸ä¿è¯ä½ èƒ½å°†æ‰€æœ‰è¿™äº›ç™¾åˆ†æ¯”æŠ•å…¥ï¼Œå› ä¸ºè¿™é‡Œæœ‰å„ç§äº‹æƒ…å‘ç”Ÿã€‚
- en: you do have to pay tax on your salaryã€‚ So thatll decrease the salary sum you
    might still be allocating money towards your home loanã€‚ but you might have paid
    your house offã€‚ So any value that you put in here is basically ignoredã€‚ It's just
    going to go to0ã€‚ You might have run out of of salary before you can even put it
    into the taxable account or the savings accountã€‚ Alsoï¼Œ you can only put so much
    in the tax advantage accountã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„å·¥èµ„ç¡®å®éœ€è¦ç¼´ç¨ã€‚æ‰€ä»¥è¿™ä¼šå‡å°‘ä½ å¯èƒ½ä»åœ¨åˆ†é…ç”¨äºæˆ¿è´·çš„å·¥èµ„æ€»é¢ã€‚ä½†ä½ å¯èƒ½å·²ç»è¿˜æ¸…äº†æˆ¿å­ã€‚å› æ­¤ï¼Œä½ åœ¨è¿™é‡ŒæŠ•å…¥çš„ä»»ä½•ä»·å€¼åŸºæœ¬ä¸Šéƒ½ä¼šè¢«å¿½ç•¥ã€‚å®ƒåªä¼šå˜æˆ0ã€‚ä½ å¯èƒ½åœ¨æŠŠå·¥èµ„æŠ•å…¥åº”ç¨è´¦æˆ·æˆ–å‚¨è“„è´¦æˆ·ä¹‹å‰å°±å·²ç»ç”¨å®Œäº†å·¥èµ„ã€‚æ­¤å¤–ï¼Œä½ åªèƒ½åœ¨ç¨æ”¶ä¼˜æƒ è´¦æˆ·ä¸­æŠ•å…¥æœ‰é™çš„é‡‘é¢ã€‚
- en: at least in the United States that's sort of on the trick with IRAsã€‚ There's
    a limit to how much you can put in there per yearã€‚ There's a limit to how much
    you can put into your 401 any yearï¼Œ all these all theseã€‚Of ramifications and I
    try to put some of those in there as wellã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘åœ¨ç¾å›½ï¼Œè¿™å¯¹IRAæ¥è¯´æ˜¯ä¸€ä¸ªéš¾é¢˜ã€‚æ¯å¹´ä½ å¯ä»¥æŠ•å…¥çš„é‡‘é¢æ˜¯æœ‰é™çš„ã€‚æ¯å¹´ä½ å¯ä»¥æŠ•å…¥åˆ°401(k)çš„é‡‘é¢ä¹Ÿæ˜¯æœ‰é™çš„ï¼Œæ‰€æœ‰è¿™äº›éƒ½æœ‰å„ç§å½±å“ï¼Œæˆ‘ä¹Ÿå°½é‡æŠŠä¸€äº›æ”¾è¿›å»ã€‚
- en: The limit that I actually put in for the tax advantage account is similar to4
    and Kã€‚ So here is the programã€‚ or at least the classã€‚ This is a object oriented
    classã€‚ It inherits from gym environment metadata you must just present that for
    display I went with pretty much what most of the classes in gym go with one video
    frame per second Def not a highend video game there by any stretch and it's going
    to display in RGb formã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ºç¨æ”¶ä¼˜æƒ è´¦æˆ·è®¾å®šçš„é™é¢ç±»ä¼¼äº401(k)ã€‚æ‰€ä»¥è¿™é‡Œæ˜¯ç¨‹åºï¼Œæˆ–è€…è¯´æ˜¯ç±»ã€‚è¿™æ˜¯ä¸€ä¸ªé¢å‘å¯¹è±¡çš„ç±»ã€‚å®ƒç»§æ‰¿è‡ªgymç¯å¢ƒå…ƒæ•°æ®ï¼Œä½ å¿…é¡»ä¸ºæ˜¾ç¤ºå‘ˆç°å®ƒï¼Œæˆ‘å‡ ä¹éµå¾ªäº†gymä¸­å¤§å¤šæ•°ç±»çš„åšæ³•ï¼Œæ¯ç§’ä¸€ä¸ªè§†é¢‘å¸§ï¼Œç»å¯¹ä¸æ˜¯é«˜ç«¯è§†é¢‘æ¸¸æˆï¼ŒæŒ‰ä»»ä½•æ ‡å‡†æ¥è¯´ï¼Œå®ƒå°†ä»¥RGBå½¢å¼æ˜¾ç¤ºã€‚
- en: The number of state elements that we have are 7 and it's the first seven of
    these a few of these are calculated values that I do add to the output just for
    debugging purposesã€‚ you'll find that when you create a complex environment you'll
    spend a lot of time just debugging the environment before you even get around
    to hooking it up to Tf agents So here are the positionsã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„çŠ¶æ€å…ƒç´ æ•°é‡æ˜¯7ï¼Œå‰ä¸ƒä¸ªæ˜¯è¿™äº›ï¼Œå‡ ä¸ªæ˜¯æˆ‘æ·»åŠ åˆ°è¾“å‡ºä¸­çš„è®¡ç®—å€¼ï¼Œä»…ç”¨äºè°ƒè¯•ç›®çš„ã€‚ä½ ä¼šå‘ç°ï¼Œå½“ä½ åˆ›å»ºä¸€ä¸ªå¤æ‚ç¯å¢ƒæ—¶ï¼Œä¼šèŠ±å¾ˆå¤šæ—¶é—´è°ƒè¯•ç¯å¢ƒï¼Œè€Œä¸æ˜¯ç›´æ¥è¿æ¥åˆ°TensorFlowä»£ç†ã€‚æ‰€ä»¥è¿™é‡Œæ˜¯è¿™äº›ä½ç½®ã€‚
- en: So the state is essentially a vectorã€‚ The first element in the vector is age
    than salary and so on and so forthã€‚ This is also another constant I put in there
    for a million' see thatã€‚That for normalizationã€‚ I normalize all the dollar amounts
    to millionsï¼Œ even though salary is muchã€‚ much smaller than that it's still a fractional
    piece of a millionã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒçŠ¶æ€æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå‘é‡ã€‚å‘é‡ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¹´é¾„ï¼Œæ¥ä¸‹æ¥æ˜¯å·¥èµ„ï¼Œä¾æ­¤ç±»æ¨ã€‚è¿™ä¹Ÿæ˜¯æˆ‘æ”¾å…¥çš„å¦ä¸€ä¸ªå¸¸æ•°ï¼Œä»¥ä¾¿äºå½’ä¸€åŒ–ã€‚æˆ‘å°†æ‰€æœ‰ç¾å…ƒé‡‘é¢å½’ä¸€åŒ–ä¸ºç™¾ä¸‡ï¼Œå°½ç®¡å·¥èµ„è¿œè¿œå°äºè¿™ä¸ªï¼Œå®ƒä»ç„¶æ˜¯ç™¾ä¸‡çš„ä¸€å°éƒ¨åˆ†ã€‚
- en: that helps to keep these numbers from bigger than what the neural network would
    necessarily want to deal withã€‚ These are the values that I put in for inflation
    interest tax rateã€‚ Some of these are normalized to're not normalized but divided
    by 12 because they're monthly valuesã€‚ this is expensesã€‚ you have no choice you
    have to pay the expenses that's your food clothingã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰åŠ©äºä¿æŒè¿™äº›æ•°å­—ä¸ä¼šå¤§äºç¥ç»ç½‘ç»œå¯èƒ½æƒ³è¦å¤„ç†çš„æ•°å­—ã€‚è¿™äº›æ˜¯æˆ‘ä¸ºé€šè´§è†¨èƒ€ã€åˆ©ç‡ã€ç¨ç‡è®¾å®šçš„å€¼ã€‚å…¶ä¸­ä¸€äº›æ˜¯å½’ä¸€åŒ–çš„ï¼Œæˆ–è€…è¯´æ˜¯é™¤ä»¥12ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æœˆåº¦å€¼ã€‚è¿™æ˜¯æ”¯å‡ºã€‚ä½ æ²¡æœ‰é€‰æ‹©ï¼Œä½ å¿…é¡»æ”¯ä»˜æ”¯å‡ºï¼Œé‚£æ˜¯ä½ çš„é£Ÿç‰©ã€è¡£ç‰©ã€‚
- en: water internet connection netï¼Œ all the criticalsã€‚ Then your salary range low
    and high starting age and retiring age or essentially age that you die atã€‚ This
    is the constructor I set verbo mode default fall setting ver most mode to true
    just causes my program to print out some logging information so that you can help
    debug it I define the action spaceã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ°´ã€ç”µã€ç½‘ç»œè¿æ¥å’Œæ‰€æœ‰å…³é”®è´¹ç”¨ã€‚ç„¶åæ˜¯ä½ çš„è–ªèµ„èŒƒå›´çš„ä½å€¼å’Œé«˜å€¼ï¼Œèµ·å§‹å¹´é¾„å’Œé€€ä¼‘å¹´é¾„ï¼Œæˆ–è€…è¯´æ˜¯ä½ å»ä¸–çš„å¹´é¾„ã€‚è¿™æ˜¯æ„é€ å‡½æ•°ï¼Œæˆ‘è®¾ç½®äº†verboæ¨¡å¼ï¼Œé»˜è®¤çš„fallè®¾ç½®å°†ver
    mostæ¨¡å¼è®¾ä¸ºtrueï¼Œè¿™åªæ˜¯å¯¼è‡´æˆ‘çš„ç¨‹åºæ‰“å°å‡ºä¸€äº›æ—¥å¿—ä¿¡æ¯ï¼Œä»¥ä¾¿ä½ å¯ä»¥å¸®åŠ©è°ƒè¯•ã€‚æˆ‘å®šä¹‰äº†åŠ¨ä½œç©ºé—´ã€‚
- en: The action spaces between  zero and1ã€‚ It's important that you define this so
    that the reinforcement learning algorithm noã€‚What those ranges are and can assign
    random numbers and other things as wellã€‚ This is the observation spaceã€‚ I set
    the low and high values thereã€‚ It can potentially go higher than2 million it might
    be clipping it that might be a good idea to put that to maybe4 or10 or something
    like that but anyway that's the ranges thereã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ¨ä½œç©ºé—´åœ¨0å’Œ1ä¹‹é—´ã€‚é‡è¦çš„æ˜¯ä½ è¦å®šä¹‰è¿™ä¸ªç©ºé—´ï¼Œä»¥ä¾¿å¼ºåŒ–å­¦ä¹ ç®—æ³•èƒ½å¤Ÿç†è§£è¿™äº›èŒƒå›´ï¼Œå¹¶å¯ä»¥åˆ†é…éšæœºæ•°å’Œå…¶ä»–å†…å®¹ã€‚è¿™å°±æ˜¯è§‚å¯Ÿç©ºé—´ã€‚æˆ‘åœ¨è¿™é‡Œè®¾ç½®äº†ä½å€¼å’Œé«˜å€¼ã€‚å®ƒå¯èƒ½ä¼šè¶…è¿‡200ä¸‡ï¼Œå¯èƒ½ä¼šé™åˆ¶åœ¨é‚£å„¿ï¼Œæœ€å¥½å°†å…¶è®¾ç½®ä¸º4ã€10æˆ–ç±»ä¼¼çš„å€¼ï¼Œä½†æ— è®ºå¦‚ä½•ï¼Œè¿™å°±æ˜¯èŒƒå›´ã€‚
- en: we go ahead and seed and reset I set the log empty the log is my own thing that
    is basically just giving me information that I can convert into a pandas data
    frame later so that I can debug and make sure that the simulation is doing what
    I actually wanted to do This is a handy function that I wrote the calculates the
    person's net worth looking at the home valueã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»§ç»­è¿›è¡Œç§å­å’Œé‡ç½®ï¼Œæˆ‘è®¾ç½®äº†æ—¥å¿—ä¸ºç©ºï¼Œæ—¥å¿—æ˜¯æˆ‘è‡ªå·±çš„ä¸œè¥¿ï¼ŒåŸºæœ¬ä¸Šå°±æ˜¯ç»™æˆ‘æä¾›ä¸€äº›ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥ç¨åå°†å…¶è½¬æ¢ä¸ºpandasæ•°æ®æ¡†ï¼Œä»è€Œè¿›è¡Œè°ƒè¯•ï¼Œç¡®ä¿æ¨¡æ‹Ÿåœ¨æŒ‰æˆ‘æƒ³è¦çš„æ–¹å¼è¿è¡Œã€‚è¿™æ˜¯æˆ‘ç¼–å†™çš„ä¸€ä¸ªæ–¹ä¾¿çš„å‡½æ•°ï¼Œå®ƒè®¡ç®—ä¸ªäººçš„å‡€èµ„äº§ï¼ŒæŸ¥çœ‹æˆ¿å±‹ä»·å€¼ã€‚
- en: the principal amount still on the still owed on the home so you subtract the
    amount that you owe on the home from the value of the home and that that gives
    you that component of the net worth and then we add in the worth also as far as
    the tax advantage account and taxable again I'm making a very simple here you
    mainly save the taxes going into the account not so much coming outã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç„¶æ¬ åœ¨æˆ¿å±‹ä¸Šçš„æœ¬é‡‘ï¼Œæ‰€ä»¥ä½ ä»æˆ¿å±‹çš„ä»·å€¼ä¸­å‡å»ä½ æ‰€æ¬ çš„é‡‘é¢ï¼Œè¿™æ ·å°±å¾—åˆ°å‡€èµ„äº§çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼Œç„¶åæˆ‘ä»¬ä¹ŸåŠ ä¸Šç¨æ”¶ä¼˜æƒ è´¦æˆ·å’Œåº”ç¨è´¦æˆ·çš„ä»·å€¼ã€‚æˆ‘åœ¨è¿™é‡Œåšå¾—å¾ˆç®€å•ï¼Œä¸»è¦æ˜¯åœ¨è´¦æˆ·é‡ŒèŠ‚çœç¨æ”¶ï¼Œè€Œä¸æ˜¯åœ¨å–å‡ºæ—¶ã€‚
- en: Not like in the USA RothRAã€‚ This is where we evaluate the actionã€‚ So remember
    I said that these four action values that you get backã€‚ They're just numbersã€‚
    I can't force that they necessarily all sum up to 1ã€‚0 for 100% So what I'm going
    to do here is apply some of this I'm going to look at the home payment if it's
    approach 0 I am going to calculate so this is the total this is the total amount
    so they requested a number on all of theseã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åƒç¾å›½çš„RothRAã€‚è¿™æ˜¯æˆ‘ä»¬è¯„ä¼°åŠ¨ä½œçš„åœ°æ–¹ã€‚æ‰€ä»¥è®°å¾—æˆ‘è¯´è¿‡ï¼Œè¿™å››ä¸ªè¿”å›çš„åŠ¨ä½œå€¼åªæ˜¯æ•°å­—ã€‚æˆ‘ä¸èƒ½å¼ºè¿«å®ƒä»¬éƒ½å¿…é¡»æ€»å’Œä¸º1.0ï¼ˆ100%ï¼‰ã€‚æ‰€ä»¥æˆ‘åœ¨è¿™é‡Œè¦åšçš„æ˜¯åº”ç”¨ä¸€äº›è¿™ä¸ªï¼Œæˆ‘ä¼šæŸ¥çœ‹å®¶åº­æ”¯ä»˜ï¼Œå¦‚æœæ¥è¿‘0ï¼Œæˆ‘å°†è¿›è¡Œè®¡ç®—ï¼Œè¿™å°±æ˜¯æ€»é¢ï¼Œä»–ä»¬åœ¨è¿™äº›æ‰€æœ‰è¯·æ±‚äº†ä¸€ä¸ªæ•°å­—ã€‚
- en: I need to convert those numbers to percentã€‚ so I sum it up and then I'm going
    to divide each of these by this total account Now I don't want to cause a division
    by zeroã€‚ So if the total account has fallen below or is approaching0 then I just
    return these all to 0ã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘éœ€è¦å°†è¿™äº›æ•°å­—è½¬æ¢ä¸ºç™¾åˆ†æ¯”ã€‚æ‰€ä»¥æˆ‘å°†å®ƒä»¬ç›¸åŠ ï¼Œç„¶åå°†æ¯ä¸ªå€¼é™¤ä»¥è¿™ä¸ªæ€»é‡‘é¢ã€‚ç°åœ¨æˆ‘ä¸æƒ³å¯¼è‡´é™¤ä»¥é›¶çš„æƒ…å†µã€‚å¦‚æœæ€»é‡‘é¢é™åˆ°æˆ–æ¥è¿‘0ï¼Œæˆ‘å°±å°†è¿™äº›å…¨éƒ¨è¿”å›ä¸º0ã€‚
- en: this is kind of an error situationï¼Œ but it does happen when bad strategies are
    evaluatedã€‚ so we have to just quickly set those all to  zero and we're done otherwise
    we divide them all this is how we normalize it into something that sums up to
    1ã€‚0 and then we return these four values and these areã€‚Real percents After we've
    converted these larger numbersï¼Œ the TF agents gives you into percentsã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç®—æ˜¯ä¸€ç§é”™è¯¯æƒ…å†µï¼Œä½†åœ¨è¯„ä¼°ä¸è‰¯ç­–ç•¥æ—¶ç¡®å®ä¼šå‘ç”Ÿã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»è¿…é€Ÿå°†è¿™äº›å…¨éƒ¨è®¾ä¸º0ï¼Œå¦åˆ™æˆ‘ä»¬å°±å°†å®ƒä»¬å…¨éƒ¨é™¤ä»¥ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•å°†å…¶æ ‡å‡†åŒ–ä¸ºæ€»å’Œä¸º1.0ï¼Œç„¶åè¿”å›è¿™å››ä¸ªå€¼ã€‚è¿™äº›æ˜¯çœŸå®çš„ç™¾åˆ†æ¯”ï¼Œåœ¨æˆ‘ä»¬å°†è¿™äº›è¾ƒå¤§çš„æ•°å­—è½¬æ¢ä¸ºç™¾åˆ†æ¯”åï¼ŒTFä»£ç†ç»™å‡ºçš„ç»“æœã€‚
- en: This is the step functionã€‚ What this is doing is basically performing the simulation
    so we've got the actionã€‚ We're going to use the action values that were passed
    in and pass it to that evaluate action function that we just sawã€‚ we're going
    also break apart the values that are in the state vector so that we have then
    I don't want to constantly be looking into a hash map that would be annoying so
    we deal first with expensesã€‚ that's that certain percent that you have to pay
    that's necessities like internet connectionã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ­¥éª¤å‡½æ•°ã€‚åŸºæœ¬ä¸Šï¼Œå®ƒæ‰§è¡Œæ¨¡æ‹Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬æœ‰äº†è¡ŒåŠ¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¼ å…¥çš„è¡ŒåŠ¨å€¼ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æˆ‘ä»¬åˆšæ‰çœ‹åˆ°çš„è¯„ä¼°è¡ŒåŠ¨å‡½æ•°ã€‚æˆ‘ä»¬è¿˜ä¼šåˆ†å¼€çŠ¶æ€å‘é‡ä¸­çš„å€¼ï¼Œè¿™æ ·æˆ‘å°±ä¸éœ€è¦ä¸æ–­æŸ¥æ‰¾å“ˆå¸Œæ˜ å°„ï¼Œè¿™ä¼šå¾ˆçƒ¦äººï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆå¤„ç†æ”¯å‡ºã€‚é‚£æ˜¯ä½ å¿…é¡»æ”¯ä»˜çš„æŸä¸ªç™¾åˆ†æ¯”ï¼Œåƒäº’è”ç½‘è¿æ¥è¿™æ ·çš„å¿…éœ€å“ã€‚
- en: at least it is to meã€‚ But yeahï¼Œ food waterï¼Œ those kind of thingsã€‚ This deals
    with first the tax advantage deposit accountã€‚ We deal with that one first because
    you are limited in how much you can put into that in a given yearã€‚ if you start
    to exceedcc to that then it just decreases you so that you cannotã€‚ This is like
    a 401ã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘å¯¹æˆ‘æ¥è¯´æ˜¯è¿™æ ·ã€‚ä¸è¿‡ï¼Œé£Ÿç‰©ã€æ°´ç­‰è¿™äº›ä¸œè¥¿ã€‚æˆ‘ä»¬é¦–å…ˆå¤„ç†ç¨æ”¶ä¼˜æƒ å­˜æ¬¾è´¦æˆ·ã€‚æˆ‘ä»¬é¦–å…ˆå¤„ç†è¿™ä¸ªè´¦æˆ·ï¼Œå› ä¸ºä½ åœ¨ä¸€å¹´å†…å¯¹å­˜æ¬¾é‡‘é¢æœ‰é™åˆ¶ã€‚å¦‚æœä½ å¼€å§‹è¶…å‡ºè¿™ä¸ªé™é¢ï¼Œé‚£ä¹ˆä½ å°±ä¼šè¢«å‡å°‘ï¼Œç›´åˆ°ä¸èƒ½å†å­˜ã€‚è¿™å°±åƒ401è®¡åˆ’ã€‚
- en: there is a company matchã€‚ We calculate how much tax the person owes deduct that
    the home paymentã€‚Kind of complicated because we are using amortizationã€‚ so I put
    in the amortization formulas so that you basically got that continuously decreasing
    interest payment and continuously increasing principal payment amountã€‚If you had
    a late payment you're in trouble and we count that upã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å…¬å¸é…å¯¹ã€‚æˆ‘ä»¬è®¡ç®—ä¸ªäººæ¬ ç¼´çš„ç¨æ¬¾ï¼Œæ‰£é™¤ä½æˆ¿ä»˜æ¬¾ã€‚å› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†æ‘Šé”€ï¼Œæ‰€ä»¥è¿™æœ‰ç‚¹å¤æ‚ã€‚å› æ­¤ï¼Œæˆ‘æ”¾å…¥äº†æ‘Šé”€å…¬å¼ï¼Œä½¿å¾—ä½ åŸºæœ¬ä¸Šæ‹¥æœ‰æŒç»­å‡å°‘çš„åˆ©æ¯æ”¯ä»˜å’ŒæŒç»­å¢åŠ çš„æœ¬é‡‘æ”¯ä»˜é‡‘é¢ã€‚å¦‚æœä½ æœ‰é€¾æœŸä»˜æ¬¾ï¼Œä½ å°±éº»çƒ¦äº†ï¼Œæˆ‘ä»¬ä¼šå°†å…¶ç»Ÿè®¡èµ·æ¥ã€‚
- en: if it gets more than 15 late paymentsï¼Œ they will foreclose on you and forecloingã€‚
    basically they just sell your house offã€‚ you lose 20000 in fees that they just
    charge for the trouble of selling your house and then so you lose a considerable
    amountã€‚'t you don't really want to go thereã€‚ Otherwiseï¼Œ if it's just a normal
    late paymentã€‚ you're charged a $10% late fee based on the amount of your paymentã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœé€¾æœŸä»˜æ¬¾è¶…è¿‡15æ¬¡ï¼Œä»–ä»¬å°†ä¼šæ­¢èµä½ ï¼Œæ­¢èµåŸºæœ¬ä¸Šæ˜¯ä»–ä»¬æŠŠä½ çš„æˆ¿å­å–æ‰ã€‚ä½ å°†æŸå¤±20000å…ƒçš„è´¹ç”¨ï¼Œè¿™åªæ˜¯ä¸ºäº†å–æ‰æˆ¿å­æ‰€é€ æˆçš„éº»çƒ¦ï¼Œå› æ­¤ä½ å°†æŸå¤±ç›¸å½“å¯è§‚çš„é‡‘é¢ã€‚ä½ ä¸å¸Œæœ›è¿™æ ·å‘ç”Ÿã€‚å¦åˆ™ï¼Œå¦‚æœåªæ˜¯æ­£å¸¸çš„é€¾æœŸä»˜æ¬¾ï¼Œä½ å°†æ ¹æ®ä»˜æ¬¾é‡‘é¢æ”¶å–10%çš„æ»çº³é‡‘ã€‚
- en: not a 10% late fee based on the principal value or house that'd be horrendousã€‚
    And then we update the house value to reflect the paymentã€‚ we make the deposits
    into the taxable account and we make sure to credit investment returnsã€‚ the investment
    returns are pretty similarï¼Œ we do randomly vary those a bitã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦åŸºäºæœ¬é‡‘ä»·å€¼æ”¶å–10%çš„æ»çº³é‡‘ï¼Œå¦åˆ™é‚£å°†æ˜¯å¯æ€•çš„ã€‚ç„¶åæˆ‘ä»¬æ›´æ–°æˆ¿å±‹ä»·å€¼ä»¥åæ˜ ä»˜æ¬¾æƒ…å†µã€‚æˆ‘ä»¬å°†å­˜æ¬¾æ”¾å…¥åº”ç¨è´¦æˆ·ï¼Œå¹¶ç¡®ä¿è®¡ç®—æŠ•èµ„å›æŠ¥ã€‚æŠ•èµ„å›æŠ¥å¤§è‡´ç›¸ä¼¼ï¼Œæˆ‘ä»¬ä¼šéšæœºç¨å¾®è°ƒæ•´ä¸€ä¸‹ã€‚
- en: just like we randomly vary the inflation amountï¼Œ this just put some randomness
    into the gameã€‚ which makes it harder but this is also what reinforcement learning
    is quite good at doing dealing with the random numbersã€‚ we deal with yearly events
    So every time we're at month 12 monthly eventsã€‚Not too much thereã€‚ We're just
    aging the agent by oneã€‚ It's a time to retireã€‚ I meanï¼Œ they retire at 80ã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæˆ‘ä»¬éšæœºè°ƒæ•´é€šè´§è†¨èƒ€é‡‘é¢ä¸€æ ·ï¼Œè¿™åœ¨æ¸¸æˆä¸­å¢åŠ äº†ä¸€äº›éšæœºæ€§ã€‚è¿™ä½¿å¾—æ¸¸æˆæ›´å…·æŒ‘æˆ˜æ€§ï¼Œä½†å¼ºåŒ–å­¦ä¹ åœ¨å¤„ç†éšæœºæ•°å­—æ–¹é¢éå¸¸æ“…é•¿ã€‚æˆ‘ä»¬å¤„ç†å¹´åº¦äº‹ä»¶ï¼Œå› æ­¤æ¯å½“æˆ‘ä»¬åˆ°è¾¾ç¬¬12ä¸ªæœˆæ—¶å°±ä¼šå‘ç”Ÿæ¯æœˆäº‹ä»¶ã€‚æ²¡ä»€ä¹ˆç‰¹åˆ«çš„ã€‚æˆ‘ä»¬åªæ˜¯è®©ä»£ç†äººè€å»ä¸€å¹´ã€‚æ˜¯æ—¶å€™é€€ä¼‘äº†ã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œä»–ä»¬åœ¨80å²æ—¶é€€ä¼‘ã€‚
- en: I guess I probably should have said that this is more like when they died or
    something I'm making everybody quit at the same amountã€‚ but also the person works
    right up to 80 so again this is a simplified simulator and then we normalize and
    finish up So for the state I'm dividing each of these state values your accounts
    by multiples of a million that gets it into much smaller values and it makes it
    easier for the neural network to deal with usually you don't want to be throwing
    in large multimillion dollar numbers into a neural network that just doesn't work
    that well when we perform the yearly we are basically counting the investment
    rate or the inflation rate we're adding some randomness into that we give them
    the salary increase we increase the home value by the amount that inflation dictates
    and so on this is reset it starts it over're reborn so to speak we set the late
    count to0 all all these values to zero so that we are starting over fromã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æˆ‘å¯èƒ½åº”è¯¥è¯´è¿™æ›´åƒæ˜¯ä»–ä»¬å»ä¸–æ—¶çš„æƒ…å†µï¼Œæˆ‘è®©æ¯ä¸ªäººåœ¨åŒæ ·çš„æ—¶é—´ç‚¹é€€å‡ºã€‚ ä½†åŒæ—¶è¿™ä¸ªäººå·¥ä½œåˆ°80å²ï¼Œæ‰€ä»¥è¿™åˆæ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¨¡æ‹Ÿå™¨ï¼Œç„¶åæˆ‘ä»¬å½’ä¸€åŒ–å¹¶ç»“æŸã€‚
    æ‰€ä»¥åœ¨è¿™ä¸ªçŠ¶æ€ä¸­ï¼Œæˆ‘å°†æ¯ä¸ªçŠ¶æ€å€¼é™¤ä»¥ç™¾ä¸‡çš„å€æ•°ï¼Œè¿™æ ·å°±ä¼šå¾—åˆ°æ›´å°çš„å€¼ï¼Œå¹¶ä¸”è¿™ä½¿å¾—ç¥ç»ç½‘ç»œå¤„ç†èµ·æ¥æ›´å®¹æ˜“ã€‚é€šå¸¸ä½ ä¸æƒ³æŠŠå¤§é¢ç™¾ä¸‡ç¾å…ƒçš„æ•°å­—ä¸¢è¿›ç¥ç»ç½‘ç»œï¼Œè¿™æ ·æ•ˆæœä¸å¥½ã€‚æˆ‘ä»¬è¿›è¡Œå¹´åº¦è®¡ç®—æ—¶ï¼ŒåŸºæœ¬ä¸Šæ˜¯åœ¨è®¡ç®—æŠ•èµ„å›æŠ¥ç‡æˆ–é€šè´§è†¨èƒ€ç‡ï¼Œæˆ‘ä»¬åœ¨å…¶ä¸­æ·»åŠ ä¸€äº›éšæœºæ€§ï¼Œç»™ä»–ä»¬è–ªæ°´å¢åŠ ï¼ŒæŒ‰ç…§é€šè´§è†¨èƒ€çš„è§„å®šå¢åŠ æˆ¿å±‹ä»·å€¼ï¼Œç­‰ç­‰ã€‚è¿™ä¸ªæ˜¯é‡ç½®çš„ï¼Œé‡æ–°å¼€å§‹ï¼Œå¯ä»¥è¯´æˆ‘ä»¬å°†è®¡æ•°å™¨é‡ç½®ä¸º0ï¼Œæ‰€æœ‰è¿™äº›å€¼é‡ç½®ä¸º0ï¼Œä»¥ä¾¿ä»å¤´å¼€å§‹ã€‚
- en: Geting we generate a random salary based on between those rangesã€‚ We calculate
    that random house multiple between 1ã€‚5 and 4ã€‚ We calculate the mortgage amount
    so that we know the amount of the principal and there's that famous amortization
    formula and then we set this all into the stateã€‚ Render is pretty simpleã€‚ Rler
    is using pill so it's returning an image basically just display all of these values
    in a green font with a black backgroundã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™äº›èŒƒå›´ä¹‹é—´ç”Ÿæˆéšæœºè–ªæ°´ã€‚ æˆ‘ä»¬è®¡ç®—è¿™ä¸ªéšæœºæˆ¿å±‹çš„å€æ•°ï¼Œä»‹äº1.5å’Œ4ä¹‹é—´ã€‚ æˆ‘ä»¬è®¡ç®—æŠµæŠ¼è´·æ¬¾é‡‘é¢ï¼Œä»¥ä¾¿çŸ¥é“æœ¬é‡‘çš„æ•°é‡ï¼Œé‚£ä¸ªè‘—åçš„æ‘Šé”€å…¬å¼ï¼Œç„¶åæˆ‘ä»¬æŠŠè¿™äº›éƒ½è®¾ç½®åˆ°çŠ¶æ€ä¸­ã€‚
    æ¸²æŸ“ç›¸å½“ç®€å•ã€‚ Rlerä½¿ç”¨Pillowï¼Œæ‰€ä»¥åŸºæœ¬ä¸Šæ˜¯è¿”å›ä¸€å¼ å›¾åƒï¼Œå°†æ‰€æœ‰è¿™äº›å€¼ä»¥ç»¿è‰²å­—ä½“åœ¨é»‘è‰²èƒŒæ™¯ä¸Šæ˜¾ç¤ºå‡ºæ¥ã€‚
- en: '''ll see what that looks like in a moment and print those all outã€‚ And that''s
    it at that point you have an environment Now you need to register your environment
    so that you can see it and I call this just simple game of life again not conway''s
    game of life I''m kind of thinking of the old board game lifeã€‚'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¨åä¼šçœ‹çœ‹é‚£æ˜¯ä»€ä¹ˆæ ·å­ï¼Œå¹¶æ‰“å°å‡ºæ¥ã€‚ åˆ°é‚£æ—¶ï¼Œä½ å°±æœ‰äº†ä¸€ä¸ªç¯å¢ƒã€‚ ç°åœ¨ä½ éœ€è¦æ³¨å†Œä½ çš„ç¯å¢ƒï¼Œä»¥ä¾¿èƒ½çœ‹åˆ°å®ƒï¼Œæˆ‘æŠŠè¿™ä¸ªç§°ä¸ºç®€å•çš„ç”Ÿå‘½æ¸¸æˆï¼Œè€Œä¸æ˜¯åº·å¨çš„ç”Ÿå‘½æ¸¸æˆï¼Œæˆ‘æœ‰ç‚¹æƒ³èµ·è€ç‰Œæ¡Œæ¸¸ã€Šç”Ÿå‘½ã€‹ã€‚
- en: All right so let's test the environmentï¼Œ make sure that it worksã€‚ I instantiate
    it and create it just like this I do a reset and all I'm doing here is just playing
    the game of life so to speak with fixed values So one in one I am basically paying
    off the home loan and investing into the tax advantage account which is actually
    a very good strategy I didn't quite make thisã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬æµ‹è¯•ç¯å¢ƒï¼Œç¡®ä¿å®ƒèƒ½æ­£å¸¸å·¥ä½œã€‚ æˆ‘å®ä¾‹åŒ–å¹¶åˆ›å»ºå®ƒï¼Œå°±åƒè¿™æ ·ï¼Œæˆ‘åšä¸€ä¸ªé‡ç½®ï¼Œè¿™é‡Œæˆ‘åªæ˜¯ç©ç”Ÿå‘½æ¸¸æˆï¼Œç”¨å›ºå®šçš„å€¼ã€‚ æ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘åŸºæœ¬ä¸Šæ˜¯åœ¨å¿è¿˜æˆ¿å±‹è´·æ¬¾å¹¶æŠ•èµ„åˆ°ç¨æ”¶ä¼˜åŠ¿è´¦æˆ·ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªéå¸¸å¥½çš„ç­–ç•¥ï¼Œæˆ‘æ²¡æœ‰åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: Simulator complicated enough that there is a tremendous amount for the deep
    reinforcement learning to learnã€‚ but this alone performs quite wellã€‚ You can see
    that it generates a net worth of about $8 million at the endã€‚ so thats that's
    goodã€‚ Also remember that's not inflation adjusted So over 80 years that might
    not be quite quite as goodã€‚ hyperparaã€‚ I adjusted these a little bit to make it
    so that it it learns relatively wellã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿå™¨æ²¡æœ‰å¤æ‚åˆ°è¶³ä»¥è®©æ·±åº¦å¼ºåŒ–å­¦ä¹ å­¦ä¹ å¤§é‡å†…å®¹ã€‚ ä½†å…‰æ˜¯è¿™ç‚¹å°±è¡¨ç°å¾—ç›¸å½“ä¸é”™ã€‚ ä½ å¯ä»¥çœ‹åˆ°åˆ°æœ€åå®ƒç”Ÿæˆäº†çº¦800ä¸‡ç¾å…ƒçš„å‡€èµ„äº§ï¼Œæ‰€ä»¥è¿™å¾ˆå¥½ã€‚ å¦å¤–ï¼Œè¯·è®°ä½è¿™ä¸æ˜¯é€šè´§è†¨èƒ€è°ƒæ•´åçš„æ•°å€¼ï¼Œå› æ­¤åœ¨80å¹´åè¿™å¯èƒ½å°±æ²¡é‚£ä¹ˆå¥½ã€‚
    æˆ‘ç¨å¾®è°ƒæ•´äº†ä¸€ä¸‹è¶…å‚æ•°ï¼Œä»¥ä½¿å…¶å­¦ä¹ ç›¸å¯¹è¾ƒå¥½ã€‚
- en: You could definitely do some more work hereã€‚ The main thing that I change is
    we do 50000 iterationsã€‚ and we do 50 collection steps on each of those iterationsã€‚
    So that's how many episodes are actually run just so that we have enough data
    each time to work this onã€‚ batch size is 64ã€‚ We log every 2500 and we evaluate
    every 5000 Nowã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç¡®å®å¯ä»¥åœ¨è¿™é‡Œåšæ›´å¤šçš„å·¥ä½œã€‚ æˆ‘æ”¹å˜çš„ä¸»è¦å†…å®¹æ˜¯æˆ‘ä»¬è¿›è¡Œ50000æ¬¡è¿­ä»£ï¼Œå¹¶ä¸”åœ¨æ¯æ¬¡è¿­ä»£ä¸­è¿›è¡Œ50æ¬¡æ”¶é›†æ­¥éª¤ã€‚ æ‰€ä»¥è¿™å®é™…ä¸Šè¿è¡Œäº†å¤šå°‘é›†ï¼Œä»¥ä¾¿æ¯æ¬¡éƒ½æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥å¤„ç†ã€‚æ‰¹é‡å¤§å°ä¸º64ã€‚æˆ‘ä»¬æ¯2500æ¬¡è®°å½•ä¸€æ¬¡ï¼Œæ¯5000æ¬¡è¯„ä¼°ä¸€æ¬¡ã€‚
- en: this is what our environment looks like if we want to just render it so that
    we can see itã€‚ this is what it looks likeã€‚ And later we'll look at the video and
    we can watch this person age to 80 and see what they're doingã€‚ We create the two
    environments so that we can both evaluate this and train it and notã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åªæƒ³æ¸²æŸ“ç¯å¢ƒä»¥ä¾¿çœ‹åˆ°å®ƒï¼Œè¿™å°±æ˜¯æˆ‘ä»¬ç¯å¢ƒçš„æ ·å­ã€‚è¿™çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ã€‚ç¨åæˆ‘ä»¬ä¼šè§‚çœ‹è§†é¢‘ï¼Œçœ‹åˆ°è¿™ä¸ªäººè€åˆ°80å²æ—¶çš„çŠ¶æ€ï¼Œä»¥åŠä»–ä»¬åœ¨åšä»€ä¹ˆã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªç¯å¢ƒï¼Œä»¥ä¾¿åŒæ—¶è¯„ä¼°å’Œè®­ç»ƒå®ƒã€‚
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_5.png)'
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_6.png)'
- en: Step on each otherã€‚ Now we are using not a DQNã€‚ We had a deep Q learning network
    before the problem with a deep QNã€‚ It's not a major problemï¼Œ but in this case
    it isï¼Œ is that the DQN only supports discrete action space So think of a joy stick
    forcing it up down left rightã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: äº’ç›¸è¸©è¸ã€‚ç°åœ¨æˆ‘ä»¬ä¸å†ä½¿ç”¨DQNã€‚ä¹‹å‰æˆ‘ä»¬ä½¿ç”¨äº†æ·±åº¦Qå­¦ä¹ ç½‘ç»œï¼Œæ·±åº¦QNçš„é—®é¢˜åœ¨äºå®ƒåªæ”¯æŒç¦»æ•£åŠ¨ä½œç©ºé—´ã€‚æ‰€ä»¥æƒ³è±¡ä¸€ä¸‹ä¸€ä¸ªæ“çºµæ†ï¼Œæ§åˆ¶ä¸Šä¸‹å·¦å³ã€‚
- en: not how hard you're pressing it we have these four accounts and I would like
    to be able to give a variable amount into each of these four retirement accountsã€‚
    So to do this we need to use a new type of neural networkbased reinforcement learning
    called a DtPg algorithmã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ˜¯ä½ æ–½åŠ çš„å‹åŠ›æœ‰å¤šå¤§ï¼Œæˆ‘ä»¬æœ‰è¿™å››ä¸ªè´¦æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç»™è¿™å››ä¸ªé€€ä¼‘è´¦æˆ·æä¾›ä¸åŒçš„é‡‘é¢ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ç§æ–°çš„åŸºäºç¥ç»ç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ ç±»å‹ï¼Œç§°ä¸ºDtPgç®—æ³•ã€‚
- en: deep deterministic polyc gradients I won't go too deep into how that algorithm
    actually works if you want to read the original paper on itã€‚ It's here it's I
    have not gone through and implemented one of these myself but they do work quite
    well for continuous action space reinforcement learning This is what the structure
    of it sort of looks like your environment isã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œæˆ‘ä¸ä¼šæ·±å…¥è®²è§£è¿™ä¸ªç®—æ³•çš„å·¥ä½œåŸç†ï¼Œå¦‚æœä½ æƒ³é˜…è¯»åŸå§‹è®ºæ–‡ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ã€‚æˆ‘è‡ªå·±è¿˜æ²¡æœ‰å®ç°è¿‡è¿™äº›ï¼Œä½†å®ƒä»¬åœ¨è¿ç»­åŠ¨ä½œç©ºé—´çš„å¼ºåŒ–å­¦ä¹ ä¸­æ•ˆæœå¾ˆå¥½ã€‚è¿™å°±æ˜¯å®ƒçš„ç»“æ„ï¼Œä½ çš„ç¯å¢ƒæ˜¯ã€‚
- en: Giving you back your stateï¼Œ which is Xã€‚ that same state goes into the critic
    and the actorã€‚ So there's two neural networks at play hereã€‚ This is kind of like
    agan where you have basically one neural network that's generating images a second
    one that is discriminating telling it if those images are real or not This is
    similarã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è®©ä½ æ¢å¤ä½ çš„çŠ¶æ€ï¼Œå³Xã€‚é‚£ä¸ªçŠ¶æ€è¿›å…¥è¯„è®ºè€…å’Œè¡ŒåŠ¨è€…ã€‚æ‰€ä»¥è¿™é‡Œæœ‰ä¸¤ä¸ªç¥ç»ç½‘ç»œåœ¨å‘æŒ¥ä½œç”¨ã€‚è¿™æœ‰ç‚¹åƒå¯¹æŠ—ç”Ÿæˆç½‘ç»œï¼ŒåŸºæœ¬ä¸Šæœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œç”Ÿæˆå›¾åƒï¼Œç¬¬äºŒä¸ªåˆ™æ˜¯åœ¨åˆ¤æ–­é‚£äº›å›¾åƒæ˜¯å¦çœŸå®ã€‚è¿™æ˜¯ç›¸ä¼¼çš„ã€‚
- en: you've got two adversarial neural networks you've got the actor the really adversarial
    of each otherã€‚ What it's really doing is the actor is returning in this case for
    the game of life it would return for floating point numbers and those are the
    actions that you're going to getã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ‰ä¸¤ä¸ªå¯¹æŠ—æ€§ç¥ç»ç½‘ç»œï¼Œè¡ŒåŠ¨è€…å’Œå½¼æ­¤çš„çœŸæ­£å¯¹æŠ—è€…ã€‚å®é™…ä¸Šï¼Œè¡ŒåŠ¨è€…åœ¨è¿™ç§æƒ…å†µä¸‹è¿”å›æµ®ç‚¹æ•°ï¼Œè¿™äº›å°±æ˜¯ä½ å°†å¾—åˆ°çš„åŠ¨ä½œã€‚
- en: The reason a deep Q network like that like we had before could not do continuous
    values is you need this nice table where you have where you're potentially getting
    a value for every single one of those actionsã€‚ What we have now is we feed in
    the current state and the actor return the step that wants it to take the action
    and the criticã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åƒä¹‹å‰çš„æ·±åº¦Qç½‘ç»œä¹‹æ‰€ä»¥æ— æ³•å¤„ç†è¿ç»­å€¼ï¼Œæ˜¯å› ä¸ºä½ éœ€è¦ä¸€ä¸ªæ¼‚äº®çš„è¡¨æ ¼ï¼Œåœ¨æ¯ä¸ªåŠ¨ä½œä¸­éƒ½æœ‰ä¸€ä¸ªæ½œåœ¨çš„å€¼ã€‚æˆ‘ä»¬ç°åœ¨åšçš„æ˜¯è¾“å…¥å½“å‰çŠ¶æ€ï¼Œè¡ŒåŠ¨è€…è¿”å›æƒ³è¦é‡‡å–çš„åŠ¨ä½œæ­¥éª¤ï¼Œä»¥åŠè¯„è®ºè€…ã€‚
- en: Evaluates how well the actor did on picking continuous values for the actionã€‚
    So you're picking those four continuous values for the accountsã€‚ You're not picking
    which accountã€‚ you're picking the four continuous valuesã€‚ How well those continuous
    values maximized the eventual reward and that's basically how actor critic reinforcement
    neural network worksã€‚ The TD error is important toã€‚ That's the temporal difference
    error So that's just looking at how different was the actor's estimation of future
    reward versus what the environment actually gave it back as the future rewardã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°è¡ŒåŠ¨è€…åœ¨é€‰æ‹©è¿ç»­å€¼æ—¶çš„è¡¨ç°ã€‚å› æ­¤ï¼Œä½ é€‰æ‹©è¿™å››ä¸ªè¿ç»­å€¼ï¼Œè€Œä¸æ˜¯é€‰æ‹©å“ªä¸ªè´¦æˆ·ã€‚ä½ é€‰æ‹©çš„æ˜¯è¿™å››ä¸ªè¿ç»­å€¼ã€‚è¿™äº›è¿ç»­å€¼å¦‚ä½•æœ€å¤§åŒ–æœ€ç»ˆå¥–åŠ±ï¼Œè¿™åŸºæœ¬ä¸Šå°±æ˜¯è¡ŒåŠ¨è€…-è¯„è®ºè€…å¼ºåŒ–ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†ã€‚æ—¶åºå·®åˆ†è¯¯å·®ä¹Ÿå¾ˆé‡è¦ã€‚è¿™æ˜¯æ—¶é—´å·®åˆ†è¯¯å·®ï¼Œå®ƒåªæ˜¯çœ‹è¡ŒåŠ¨è€…å¯¹æœªæ¥å¥–åŠ±çš„ä¼°è®¡ä¸ç¯å¢ƒå®é™…ç»™äºˆçš„æœªæ¥å¥–åŠ±ä¹‹é—´çš„å·®å¼‚ã€‚
- en: That is what the objective function is trying to minimize These are the hyperparameters
    for these two neural networks we create those two neural networks and then we
    create the so we create the actor firstã€‚ and then we create the critic and then
    we put both of those together into the DDPG agent initialize it and we're basically
    ready to goã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ç›®æ ‡å‡½æ•°è¯•å›¾æœ€å°åŒ–çš„å†…å®¹ã€‚è¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œçš„è¶…å‚æ•°ï¼Œæˆ‘ä»¬åˆ›å»ºè¿™ä¸¤ä¸ªç¥ç»ç½‘ç»œï¼Œç„¶åæˆ‘ä»¬å…ˆåˆ›å»ºæ¼”å‘˜ï¼Œç„¶ååˆ›å»ºè¯„è®ºå‘˜ï¼Œå†å°†è¿™ä¸¤è€…ç»“åˆæˆDDPGä»£ç†ï¼Œåˆå§‹åŒ–å®ƒï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå°±å‡†å¤‡å¥½äº†ã€‚
- en: We're going to use the same metric that we've used in previousã€‚les I've given
    youã€‚ This is where we take a certain number of episodesã€‚ and we look at the average
    return over those episodesã€‚ We do our initial data collectionã€‚ just like previous
    examplesã€‚ We've got to run through the simulator a couple of timesã€‚ and actuallyã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ä¹‹å‰ä¾‹å­ä¸­ä½¿ç”¨çš„ç›¸åŒæŒ‡æ ‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å–ä¸€å®šæ•°é‡çš„å›åˆï¼Œå¹¶æŸ¥çœ‹è¿™äº›å›åˆçš„å¹³å‡å›æŠ¥ã€‚æˆ‘ä»¬è¿›è¡Œåˆæ­¥æ•°æ®æ”¶é›†ï¼Œå°±åƒä¹‹å‰çš„ä¾‹å­ä¸€æ ·ã€‚æˆ‘ä»¬å¿…é¡»é€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œå‡ æ¬¡ã€‚
- en: in this case a thousand times and get some sample environment changes based
    on these actions and actual rewardsã€‚ That's what we will begin to train the neural
    network onã€‚ And againã€‚ this is the same code that I showed you in previous examples
    that we've done a reinforcement learningã€‚ The main point of this example is how
    to create your own environmentã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿›è¡Œä¸€åƒæ¬¡ï¼Œå¹¶æ ¹æ®è¿™äº›åŠ¨ä½œå’Œå®é™…å¥–åŠ±è·å–ä¸€äº›æ ·æœ¬ç¯å¢ƒå˜åŒ–ã€‚è¿™å°±æ˜¯æˆ‘ä»¬å°†å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œçš„å†…å®¹ã€‚è€Œä¸”ï¼Œè¿™æ®µä»£ç ä¸æˆ‘åœ¨ä¹‹å‰å¼ºåŒ–å­¦ä¹ ç¤ºä¾‹ä¸­å±•ç¤ºçš„ç›¸åŒã€‚è¿™ä¸€ä¾‹å­çš„ä¸»è¦ç‚¹æ˜¯å¦‚ä½•åˆ›å»ºä½ è‡ªå·±çš„ç¯å¢ƒã€‚
- en: Now we're going train the agent againï¼Œ this is the same codeã€‚ And by the wayã€‚
    this code changes really so little that you could actually switch out So up hereã€‚
    you could switch out my simple game of life and put in the mountain car continuous
    which is a continuous environment that they have in the gymã€‚ and it would work
    just fineã€‚ It would train the continuous mountain carã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†å†æ¬¡è®­ç»ƒä»£ç†ï¼Œè¿™ä¸ä¹‹å‰çš„ä»£ç ç›¸åŒã€‚é¡ºä¾¿æä¸€ä¸‹ï¼Œè¿™æ®µä»£ç çš„å˜åŒ–éå¸¸å°ï¼Œä»¥è‡³äºä½ å®é™…ä¸Šå¯ä»¥æ›¿æ¢æ‰æˆ‘çš„ç®€å•ç”Ÿå‘½æ¸¸æˆï¼Œæ”¾å…¥å±±åœ°è½¦è¿ç»­ç¯å¢ƒï¼Œè¿™æ˜¯ä»–ä»¬åœ¨å¥èº«æˆ¿é‡Œçš„ä¸€ä¸ªè¿ç»­ç¯å¢ƒï¼Œå®ƒä¹Ÿèƒ½æ­£å¸¸å·¥ä½œã€‚å®ƒä¼šè®­ç»ƒè¿ç»­å±±åœ°è½¦ã€‚
- en: So back down to here where we're training the agentã€‚ It goes through all the
    iterations requestedã€‚ğŸ˜Šã€‚Coects the requested number of data and this is the outputã€‚
    If you want to go through line by line on these my previous examples on Tensorflowlow
    agents learning is shows you exactly how this worksã€‚ but it's just a loop going
    through and printing out the results as as it trains and this is going up to 50000
    steps the visualization looks like this So it learns it really quite quickly and
    then reaches a plateau and this is not that hard of an optimization problem for
    it to learn the videos for this if we play one of these you'll see basically it's
    counting up their aging 2122 and you can see it learned to applyã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å›åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒä»£ç†ã€‚å®ƒå®Œæˆäº†æ‰€æœ‰è¯·æ±‚çš„è¿­ä»£ã€‚ğŸ˜Šã€‚æ”¶é›†è¯·æ±‚çš„æ•°æ®é‡ï¼Œè¿™æ˜¯è¾“å‡ºã€‚å¦‚æœä½ æƒ³é€è¡ŒæŸ¥çœ‹æˆ‘çš„TensorFlowä»£ç†å­¦ä¹ çš„ä»¥å‰ä¾‹å­ï¼Œå®ƒä¼šå‡†ç¡®åœ°å‘Šè¯‰ä½ è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä½†è¿™åªæ˜¯ä¸€ä¸ªå¾ªç¯ï¼Œéå†å¹¶æ‰“å°å‡ºç»“æœï¼Œå› ä¸ºå®ƒåœ¨è®­ç»ƒï¼Œè¿™ä¸ªè¿‡ç¨‹æœ€å¤šè¾¾åˆ°50000æ­¥ï¼Œç»“æœçš„å¯è§†åŒ–çœ‹èµ·æ¥åƒè¿™æ ·ã€‚æ‰€ä»¥å®ƒå­¦ä¹ å¾—éå¸¸å¿«ï¼Œç„¶åè¾¾åˆ°ä¸€ä¸ªå¹³å°ï¼Œè¿™å¯¹å®ƒæ¥è¯´ä¸æ˜¯ä¸€ä¸ªå¾ˆéš¾çš„ä¼˜åŒ–é—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬æ’­æ”¾è¿™äº›è§†é¢‘ä¸­çš„ä¸€ä¸ªï¼Œä½ åŸºæœ¬ä¸Šä¼šçœ‹åˆ°å®ƒåœ¨è®¡æ•°21122ï¼Œå¹¶ä¸”ä½ å¯ä»¥çœ‹åˆ°å®ƒå­¦ä¼šäº†åº”ç”¨ã€‚
- en: this is a pretty boring agent actually it just gives up on the houseã€‚s it be
    confiscated and then it just goes into investing in the tax advantage savings
    it doesn't quite figure out that there's a limit to that it probably should have
    put the rest in the tax textable and as you retrain itã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªä»£ç†å®é™…ä¸Šå¾ˆæ— èŠï¼Œå®ƒåªæ˜¯åœ¨æˆ¿å­è¢«æ²¡æ”¶åæ”¾å¼ƒï¼Œç„¶åå°±å»æŠ•èµ„äºç¨æ”¶ä¼˜æƒ å‚¨è“„ã€‚å®ƒæ²¡æœ‰å¼„æ˜ç™½è¿™ä¸€ç‚¹çš„é™åˆ¶ï¼Œå¯èƒ½åº”è¯¥æŠŠå‰©ä½™éƒ¨åˆ†æ”¾åœ¨åº”ç¨è´¦æˆ·é‡Œï¼Œéšç€ä½ é‡æ–°è®­ç»ƒå®ƒã€‚
- en: it learnsã€‚![](img/bd52a9eda0cfe550681151d31dca6c38_8.png)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå­¦ä¹ ã€‚![](img/bd52a9eda0cfe550681151d31dca6c38_8.png)
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_9.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_9.png)'
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_10.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_10.png)'
- en: Different approaches so I've run this a couple of timesã€‚ there are smarter agents
    that trains this one this one's okayã€‚ I mean it's building up the net worth and
    you can went to zero because it sold it I do hit them with rent or something like
    that but anyway is creating yourã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒçš„æ–¹æ³•ï¼Œæ‰€ä»¥æˆ‘è¿è¡Œäº†å‡ æ¬¡ã€‚æœ‰ä¸€äº›æ›´æ™ºèƒ½çš„ä»£ç†åœ¨è®­ç»ƒï¼Œè¿™ä¸ªè¿˜å¯ä»¥ã€‚æˆ‘æ˜¯è¯´å®ƒåœ¨å¢åŠ å‡€èµ„äº§ï¼Œä½†ä½ å¯èƒ½ä¼šå› ä¸ºå‡ºå”®è€Œé™åˆ°é›¶ã€‚æˆ‘ç¡®å®ç”¨ç§Ÿé‡‘æˆ–è€…å…¶ä»–æ–¹å¼å‡»ä¸­äº†å®ƒï¼Œä½†æ— è®ºå¦‚ä½•ï¼Œå®ƒåœ¨åˆ›é€ ä½ çš„ã€‚
- en: '![](img/bd52a9eda0cfe550681151d31dca6c38_12.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd52a9eda0cfe550681151d31dca6c38_12.png)'
