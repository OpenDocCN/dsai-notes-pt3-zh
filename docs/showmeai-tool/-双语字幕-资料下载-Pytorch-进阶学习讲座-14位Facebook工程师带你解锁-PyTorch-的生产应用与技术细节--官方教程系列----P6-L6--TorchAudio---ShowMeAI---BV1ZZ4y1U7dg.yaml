- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P6ï¼šL6-
    TorchAudio - ShowMeAI - BV1ZZ4y1U7dg
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P6ï¼šL6-
    TorchAudio - ShowMeAI - BV1ZZ4y1U7dg
- en: ğŸ¼ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¼ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_1.png)
- en: Hello everyoneï¼Œ my name is Vincent Kenville Bellair and I'm the tech lead for
    Torduã€‚ which is what I'm going to talk about todayã€‚The goal of Torruio is to provide
    building blocks to other researchers and engineers that allows them to bring research
    to productionã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯Vincent Kenville Bellairï¼Œæˆ‘æ˜¯Torduçš„æŠ€æœ¯è´Ÿè´£äººã€‚è¿™å°±æ˜¯æˆ‘ä»Šå¤©è¦è°ˆè®ºçš„å†…å®¹ã€‚Torruioçš„ç›®æ ‡æ˜¯ä¸ºå…¶ä»–ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆæä¾›æ„å»ºæ¨¡å—ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿå°†ç ”ç©¶å¸¦å…¥ç”Ÿäº§ã€‚
- en: This wayï¼Œ Tortrivio can accelerate the development of other libraries in the
    open sourceurce ecosystemã€‚Toorodo is built around the following core functionalitiesã€‚The
    first functionality is IO to read and save tensors from various file formats like
    MP3ï¼Œ waveã€‚ Fl and Spï¼Œ we can also download and use common audio datasets where
    samples are loaded in parallel using torch multi processingcessing workersã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒTortrivio å¯ä»¥åŠ é€Ÿå…¶ä»–å¼€æºç”Ÿæ€ç³»ç»Ÿåº“çš„å¼€å‘ã€‚Toorodo æ˜¯å›´ç»•ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½æ„å»ºçš„ã€‚ç¬¬ä¸€ä¸ªåŠŸèƒ½æ˜¯IOï¼Œç”¨äºä»å„ç§æ–‡ä»¶æ ¼å¼ï¼ˆå¦‚MP3ã€waveã€FLå’ŒSPï¼‰è¯»å–å’Œä¿å­˜å¼ é‡ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä¸‹è½½å¹¶ä½¿ç”¨å¸¸è§çš„éŸ³é¢‘æ•°æ®é›†ï¼Œæ ·æœ¬åœ¨ä½¿ç”¨torchå¤šè¿›ç¨‹å·¥ä½œæ—¶å¹¶è¡ŒåŠ è½½ã€‚
- en: The second functionality is transforms for audio and signal processing such
    as spectrogram and FCC and resemblingã€‚The transforms are provided as neural network
    modules in Tor2 dot transformsã€‚Since the transforms are written using pure Pytorrch
    operationsã€‚ the computations can be done on the GPU and it can be compiled using
    Trchcrã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªåŠŸèƒ½æ˜¯ç”¨äºéŸ³é¢‘å’Œä¿¡å·å¤„ç†çš„å˜æ¢ï¼Œä¾‹å¦‚è°±å›¾å’ŒFCCã€‚å˜æ¢ä½œä¸ºTor2 dot transformsä¸­çš„ç¥ç»ç½‘ç»œæ¨¡å—æä¾›ã€‚ç”±äºå˜æ¢æ˜¯ä½¿ç”¨çº¯Pytorchæ“ä½œç¼–å†™çš„ï¼Œå› æ­¤è®¡ç®—å¯ä»¥åœ¨GPUä¸Šè¿›è¡Œï¼Œå¹¶å¯ä»¥ä½¿ç”¨Trchcrè¿›è¡Œç¼–è¯‘ã€‚
- en: The third is Sox and Cdi compatibilityã€‚ Sox and Cdi our audio processingces
    library written in C++ for Soxã€‚ we provide an interface to use their transforms
    for CAdiã€‚ we provide reading and writing of CAdi binary filesã€‚ as well as equivalent
    features like spectrogram Ns NF bankã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰ä¸ªæ˜¯Soxå’ŒCdiå…¼å®¹æ€§ã€‚Soxå’ŒCdiæ˜¯ç”¨C++ä¸ºSoxç¼–å†™çš„éŸ³é¢‘å¤„ç†åº“ã€‚æˆ‘ä»¬æä¾›æ¥å£ä»¥ä½¿ç”¨å®ƒä»¬çš„å˜æ¢è¿›è¡ŒCAdiçš„æ“ä½œï¼Œæ”¯æŒè¯»å–å’Œå†™å…¥CAdiäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä»¥åŠæä¾›ä¸è°±å›¾ã€Ns
    NF bankç­‰åŒç­‰åŠŸèƒ½ã€‚
- en: The final functionality is a distribution of modelsã€‚ along with canonical example
    pipelines for distributed training for major tasksã€‚![](img/d47b4dd266be755b011d1bea67152b4b_3.png)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„åŠŸèƒ½æ˜¯æ¨¡å‹çš„åˆ†å‘ï¼Œä»¥åŠç”¨äºä¸»è¦ä»»åŠ¡çš„åˆ†å¸ƒå¼è®­ç»ƒçš„æ ‡å‡†ç¤ºä¾‹ç®¡é“ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_3.png)
- en: As I saidï¼Œ the first set of functionality revolves around IOã€‚![](img/d47b4dd266be755b011d1bea67152b4b_5.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘æ‰€è¯´ï¼Œç¬¬ä¸€ä¸ªåŠŸèƒ½é›†å›´ç»•IOå±•å¼€ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_5.png)
- en: Here's a small snippet using To dualode and transformã€‚The waveform variable
    is a tensorã€‚ which is read from fileï¼Œ and the correspondingpon example rate of
    the file is read as a scalarã€‚The torture to transform spectrogram is given an
    input parameter to configure its behaviorã€‚ It is then past the input tensorï¼Œ which
    computes the spectrogram tensors as outputã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨åŒé‡ç¼–ç å’Œå˜æ¢çš„å°ç‰‡æ®µã€‚æ³¢å½¢å˜é‡æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå®ƒæ˜¯ä»æ–‡ä»¶ä¸­è¯»å–çš„ï¼Œæ–‡ä»¶çš„ç›¸åº”é‡‡æ ·ç‡ä½œä¸ºæ ‡é‡è¯»å–ã€‚å˜æ¢è°±å›¾çš„è¾“å…¥å‚æ•°ç”¨æ¥é…ç½®å…¶è¡Œä¸ºã€‚ç„¶åå°†è¾“å…¥å¼ é‡ä¼ é€’è¿‡å»ï¼Œè®¡ç®—å¾—åˆ°è°±å›¾å¼ é‡ä½œä¸ºè¾“å‡ºã€‚
- en: What's special here that I want to highlight is that not only are the transform
    standard torch and and module and so can be compiled using Jtã€‚ but the loads function
    uses torch minings and so can also be compiled and ported wherever Git is supportedã€‚
    The goal is thus to make it possible to Jit an entire pipeline to be around in
    production easilyã€‚ğŸ˜Šã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å¼ºè°ƒçš„ç‰¹åˆ«ä¹‹å¤„åœ¨äºï¼Œå˜æ¢ä¸ä»…æ˜¯æ ‡å‡†çš„torchæ¨¡å—ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨Jitè¿›è¡Œç¼–è¯‘ï¼Œè€ŒåŠ è½½å‡½æ•°ä½¿ç”¨torch miningsï¼Œå› æ­¤ä¹Ÿå¯ä»¥åœ¨æ”¯æŒGitçš„åœ°æ–¹ç¼–è¯‘å’Œç§»æ¤ã€‚ç›®æ ‡æ˜¯ä½¿æ•´ä¸ªç®¡é“èƒ½å¤Ÿè½»æ¾åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨Jitã€‚ğŸ˜Šã€‚
- en: '![](img/d47b4dd266be755b011d1bea67152b4b_7.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d47b4dd266be755b011d1bea67152b4b_7.png)'
- en: We support several data sets for different tasksï¼Œ for instanceï¼Œ library speechã€‚
    for speech recognitionï¼Œ library TTS for text to speechã€‚![](img/d47b4dd266be755b011d1bea67152b4b_9.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ”¯æŒé’ˆå¯¹ä¸åŒä»»åŠ¡çš„å¤šä¸ªæ•°æ®é›†ï¼Œä¾‹å¦‚ç”¨äºè¯­éŸ³è¯†åˆ«çš„åº“è¯­éŸ³å’Œç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³çš„åº“TTSã€‚![](img/d47b4dd266be755b011d1bea67152b4b_9.png)
- en: The next set of functionalities I mentioned is transformsï¼Œ as I said beforeã€‚
    they're written in pure Pi torch and as such supportï¼Œ batchingï¼Œ torch grip and
    GPUã€‚Here's another exampleï¼Œ since each transform is a torch and a moduleã€‚ they
    can be combined in a standard sequential wrapper for convenient data augmentationã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æåˆ°çš„ä¸‹ä¸€ä¸ªåŠŸèƒ½é›†æ˜¯å˜æ¢ï¼Œæ­£å¦‚æˆ‘ä¹‹å‰æ‰€è¯´ï¼Œå®ƒä»¬æ˜¯ç”¨çº¯Pytorchç¼–å†™çš„ï¼Œå› æ­¤æ”¯æŒæ‰¹å¤„ç†ã€torch gripå’ŒGPUã€‚è¿™é‡Œæ˜¯å¦ä¸€ä¸ªä¾‹å­ï¼Œç”±äºæ¯ä¸ªå˜æ¢éƒ½æ˜¯ä¸€ä¸ªtorchæ¨¡å—ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥ç»„åˆåœ¨ä¸€ä¸ªæ ‡å‡†çš„é¡ºåºåŒ…è£…å™¨ä¸­ï¼Œä»¥æ–¹ä¾¿æ•°æ®å¢å¼ºã€‚
- en: Here we take a spectrogramï¼Œ apply a random time stretchï¼Œ computeute the complex
    normã€‚ apply a random frequency masking and a random time maskingã€‚ and then convert
    the amplitude to decibelã€‚ Frency masking and time masking are part of speckcle
    meantã€‚ which is what I'm illrating in the imageã€‚ A band of frequency and another
    in time are randomly maskedã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è·å–ä¸€ä¸ªå£°è°±å›¾ï¼Œåº”ç”¨éšæœºæ—¶é—´æ‹‰ä¼¸ï¼Œè®¡ç®—å¤æ•°èŒƒæ•°ï¼Œåº”ç”¨éšæœºé¢‘ç‡æ©è”½å’Œéšæœºæ—¶é—´æ©è”½ï¼Œç„¶åå°†å¹…åº¦è½¬æ¢ä¸ºåˆ†è´ã€‚é¢‘ç‡æ©è”½å’Œæ—¶é—´æ©è”½æ˜¯å£°å­¦ä¿¡å·å¤„ç†çš„ä¸€éƒ¨åˆ†ï¼Œè¿™å°±æ˜¯æˆ‘åœ¨å›¾åƒä¸­å±•ç¤ºçš„å†…å®¹ã€‚ä¸€æ®µé¢‘ç‡å’Œå¦ä¸€æ®µæ—¶é—´è¢«éšæœºæ©è”½ã€‚
- en: '![](img/d47b4dd266be755b011d1bea67152b4b_11.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d47b4dd266be755b011d1bea67152b4b_11.png)'
- en: The code is divided in functional that perform the computation and a transformã€‚
    which is an NN module that wraps each functional and keeps their state Here I'm
    listing a few new functional that we added recentlyã€‚ You can seeï¼Œ for instanceï¼Œ
    maone axis that is used within the the frequency and time maskingã€‚ We also have
    several bicode filters that are used in signal processing or voice executeded
    detection operation to detect voiceã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç è¢«åˆ†ä¸ºæ‰§è¡Œè®¡ç®—çš„åŠŸèƒ½å’Œä¸€ä¸ªå˜æ¢ï¼Œåè€…æ˜¯ä¸€ä¸ªNNæ¨¡å—ï¼ŒåŒ…è£…æ¯ä¸ªåŠŸèƒ½å¹¶ä¿æŒå…¶çŠ¶æ€ã€‚è¿™é‡Œæˆ‘åˆ—å‡ºäº†ä¸€äº›æˆ‘ä»¬æœ€è¿‘æ·»åŠ çš„æ–°åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥çœ‹åˆ°ç”¨äºé¢‘ç‡å’Œæ—¶é—´æ©è”½çš„maoneè½´ã€‚æˆ‘ä»¬è¿˜æœ‰å‡ ä¸ªåœ¨ä¿¡å·å¤„ç†æˆ–è¯­éŸ³æ‰§è¡Œæ£€æµ‹æ“ä½œä¸­ä½¿ç”¨çš„åŒé€šé“æ»¤æ³¢å™¨ï¼Œä»¥æ£€æµ‹è¯­éŸ³ã€‚
- en: '![](img/d47b4dd266be755b011d1bea67152b4b_13.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d47b4dd266be755b011d1bea67152b4b_13.png)'
- en: The next functionality is the interface with socks and qualitydiã€‚![](img/d47b4dd266be755b011d1bea67152b4b_15.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªåŠŸèƒ½æ˜¯ä¸sockså’Œqualitydiçš„æ¥å£ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_15.png)
- en: For suckï¼Œ we offer a way of using their efficiency plus operations directly
    within Pytorrch in a torchscriptable mannerã€‚ For instanceï¼Œ here I am applying
    a sequence of gainï¼Œ speedï¼Œ rate changeã€‚ pad and trim using apply effects tensor
    directly on the Pytorrch tensorã€‚For CAdiã€‚ Torrode provides a wrapper for Torrodo
    transforms that mimics the flags provided to CAdi binariesã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºsuckï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§ç›´æ¥åœ¨Pytorrchä¸­ä»¥torchscriptableæ–¹å¼ä½¿ç”¨å…¶æ•ˆç‡åŠ æ“ä½œçš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæˆ‘æ­£åœ¨å¯¹Pytorrchå¼ é‡ç›´æ¥åº”ç”¨å¢ç›Šã€é€Ÿåº¦ã€é€Ÿç‡å˜åŒ–ã€å¡«å……å’Œä¿®å‰ªçš„æ•ˆæœã€‚å¯¹äºCAdiï¼ŒTorrodeä¸ºTorrodoè½¬æ¢æä¾›äº†ä¸€ä¸ªåŒ…è£…å™¨ï¼Œæ¨¡æ‹Ÿæä¾›ç»™CAdiäºŒè¿›åˆ¶æ–‡ä»¶çš„æ ‡å¿—ã€‚
- en: you can also read Arc and SCP files through Torrojiio so that the processed
    output of CAdi can be used within your Torrod program CAdi is used quite a lot
    in the Aio communityã€‚ so we want to make it easy to interface with itã€‚![](img/d47b4dd266be755b011d1bea67152b4b_17.png)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜å¯ä»¥é€šè¿‡Torrojiioè¯»å–Arcå’ŒSCPæ–‡ä»¶ï¼Œä»¥ä¾¿CAdiçš„å¤„ç†è¾“å‡ºå¯ä»¥åœ¨ä½ çš„Torrodç¨‹åºä¸­ä½¿ç”¨ã€‚CAdiåœ¨Aioç¤¾åŒºä¸­ä½¿ç”¨éå¸¸å¹¿æ³›ï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›ç®€åŒ–ä¸å®ƒçš„æ¥å£ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_17.png)
- en: The final set of functionalities that I want to talk about is the addition of
    models within the libraryã€‚![](img/d47b4dd266be755b011d1bea67152b4b_19.png)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è°ˆè®ºçš„æœ€ç»ˆåŠŸèƒ½é›†æ˜¯åº“ä¸­æ¨¡å‹çš„æ·»åŠ ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_19.png)
- en: For speech recognitionï¼Œ we added a training example pipeline for speech recognition
    that uses Lib speech data set and the Wa to letter modelã€‚For text to speechï¼Œ we
    added a vcoder based on the WaR&N modelã€‚ along with an example training pipeline
    in the example folder that uses Libris TTS datasetã€‚For source separationï¼Œ we added
    the COVtizedNe model and an example training pipeline with the Wall Street Journal0
    mixed data setã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¯­éŸ³è¯†åˆ«ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªä½¿ç”¨Libè¯­éŸ³æ•°æ®é›†å’ŒWaåˆ°å­—æ¯æ¨¡å‹çš„è¯­éŸ³è¯†åˆ«è®­ç»ƒç¤ºä¾‹ç®¡é“ã€‚å¯¹äºæ–‡æœ¬åˆ°è¯­éŸ³ï¼Œæˆ‘ä»¬æ·»åŠ äº†åŸºäºWaR&Næ¨¡å‹çš„vcoderï¼Œä»¥åŠåœ¨ç¤ºä¾‹æ–‡ä»¶å¤¹ä¸­ä½¿ç”¨Libris
    TTSæ•°æ®é›†çš„ç¤ºä¾‹è®­ç»ƒç®¡é“ã€‚å¯¹äºæºåˆ†ç¦»ï¼Œæˆ‘ä»¬æ·»åŠ äº†COVtizedNeæ¨¡å‹å’Œä¸€ä¸ªä½¿ç”¨åå°”è¡—æ—¥æŠ¥æ··åˆæ•°æ®é›†çš„ç¤ºä¾‹è®­ç»ƒç®¡é“ã€‚
- en: '![](img/d47b4dd266be755b011d1bea67152b4b_21.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d47b4dd266be755b011d1bea67152b4b_21.png)'
- en: Before finishingï¼Œ I would like to highlight a few features that are on our roadmapã€‚![](img/d47b4dd266be755b011d1bea67152b4b_23.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸä¹‹å‰ï¼Œæˆ‘æƒ³å¼ºè°ƒå‡ ä¸ªåœ¨æˆ‘ä»¬è·¯çº¿å›¾ä¸Šçš„åŠŸèƒ½ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_23.png)
- en: Firstï¼Œ we would like to include the qualityy pitch feature extraction due to
    demand from the communityã€‚Secondï¼Œ we are interested in including a beam surge
    decoder interfaceã€‚ this is especially useful for speech recognition applicationã€‚And
    finallyã€‚ another loss that has been requested by users is the addition of the
    RNN transducer lossã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œç”±äºç¤¾åŒºçš„éœ€æ±‚ï¼Œæˆ‘ä»¬å¸Œæœ›åŒ…å«è´¨é‡éŸ³è°ƒç‰¹å¾æå–ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æœ‰å…´è¶£åŒ…æ‹¬ä¸€ä¸ªæ³¢æŸæ¶Œç°è§£ç å™¨æ¥å£ï¼Œè¿™å¯¹è¯­éŸ³è¯†åˆ«åº”ç”¨å°¤å…¶æœ‰ç”¨ã€‚æœ€åï¼Œç”¨æˆ·è¯·æ±‚çš„å¦ä¸€ä¸ªæŸå¤±æ˜¯æ·»åŠ RNNè½¬å¯¼æŸå¤±ã€‚
- en: '![](img/d47b4dd266be755b011d1bea67152b4b_25.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d47b4dd266be755b011d1bea67152b4b_25.png)'
- en: To use and learn about Pytorchï¼Œ you can visit Pytorchã€‚org/udioã€‚ It contains
    documentation about the APIï¼Œ installation instructionsã€‚ tutorials and links to
    the Gitthub pageã€‚ We also have a new tutorial for the recognition of speech commandã€‚
    have fun playing with itã€‚Torchd is compatible with Linuxï¼Œ Mac OSï¼Œ Windowsï¼Œ and
    supports Python 3ã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨å’Œäº†è§£ Pytorchï¼Œä½ å¯ä»¥è®¿é—® [Pytorch](https://pytorch.org/udio)ã€‚å®ƒåŒ…å«å…³äº API çš„æ–‡æ¡£ã€å®‰è£…è¯´æ˜ã€æ•™ç¨‹ä»¥åŠé“¾æ¥åˆ°
    GitHub é¡µé¢ã€‚æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªæ–°çš„è¯­éŸ³å‘½ä»¤è¯†åˆ«æ•™ç¨‹ï¼Œç©å¾—å¼€å¿ƒï¼Torchd å…¼å®¹ Linuxã€Mac OSã€Windowsï¼Œå¹¶æ”¯æŒ Python 3ã€‚
- en: 6 and upï¼Œ just like Pytororchã€‚![](img/d47b4dd266be755b011d1bea67152b4b_27.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 6 åŠä»¥ä¸Šï¼Œå°±åƒ Pytororch ä¸€æ ·ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_27.png)
- en: Thank you for watchingã€‚![](img/d47b4dd266be755b011d1bea67152b4b_29.png)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹ã€‚![](img/d47b4dd266be755b011d1bea67152b4b_29.png)
