- en: 【双语字幕+资料下载】官方教程来啦！5位 Hugging Face 工程师带你了解 Transformers 原理细节及NLP任务应用！＜官方教程系列＞
    - P23：L3.6- 使用 Accelerate 增强您的 PyTorch 训练流程 - ShowMeAI - BV1Jm4y1X7UL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】官方教程来啦！5位Hugging Face工程师带你了解Transformers原理细节及NLP任务应用！＜官方教程系列＞ - P23：L3.6-
    使用Accelerate增强您的PyTorch训练流程 - ShowMeAI - BV1Jm4y1X7UL
- en: Supercharge your by doch training loop with eggging face accelerate。![](img/4239aa3dbfdd9db19c493b620811aed1_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 用Hugging Face Accelerate为你的训练循环提速。![](img/4239aa3dbfdd9db19c493b620811aed1_1.png)
- en: There are multiple setups on which you can run your training。It could be on
    CPU， GPUus， GPus。Distributed on one machine with several devices or even several
    machines often called nodes with multiplepo devices。On top of that， there are
    new tricks to make your training faster or more efficient。 like mixed precision
    and dip speed。Each of a setup or training trick requires you to change the code
    of your training loop in one way or another and to learn a new API。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在多个环境中运行你的训练。可以是在CPU、GPU、或多个GPU上。分布在一台机器上有多个设备，或者甚至是多台机器，通常称为节点，配备多个设备。此外，还有新技巧可以让你的训练更快或更高效，例如混合精度和动态速度。每种设置或训练技巧都要求你以某种方式修改训练循环的代码，并学习新的API。
- en: '![](img/4239aa3dbfdd9db19c493b620811aed1_3.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4239aa3dbfdd9db19c493b620811aed1_3.png)'
- en: All were setups found all by the trainer API and also have all field party libraries
    that can help。The problem with is that we can feel like a black box and that it
    might not be easy to implement the tweak to the training loop you need。![](img/4239aa3dbfdd9db19c493b620811aed1_5.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的设置都通过训练API找到，并且有所有第三方库可以提供帮助。问题在于我们可能会觉得这是一个黑箱，并且可能不容易实施你需要的训练循环的调整。![](img/4239aa3dbfdd9db19c493b620811aed1_5.png)
- en: Accelrate has been designed specifically to let you retain full control over
    your training loop and be as non intrusive as possible。With just four lines of
    code to add to your training loop。 you have shown us the example of the training
    loop video。Accelerate will install all the setep and training tricks to monoon
    on the first slide。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 加速器专门设计让你对训练循环保持完全控制，并尽可能不干扰。只需在你的训练循环中添加四行代码，你就能展示训练循环视频中的示例。加速器将在第一张幻灯片上安装所有设置和训练技巧。
- en: It's only one API to learn on master instead of 10 different ones。More specifically。
    you have to import an instant sheet an accelerator object that will handle all
    the necessary code for your specific set。Then you have to send it to model， optimizeizer，
    and that you're using in the prepare。This is the main method to remember。Acceleleerate
    on those device placement。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 只需学习一个API，而不是10个不同的。更具体地说，你需要导入一个瞬时表加速器对象，它会处理特定设置所需的所有代码。然后，你需要将其发送到模型、优化器，以及你在准备过程中使用的内容。这是需要记住的主要方法。在这些设备上加速。
- en: so you don't need to put your batchge on the specific device you're using。Finally。
    you have to replace the lost dot back line by accelerate tall dot backward loss。And
    that's all it。Accelator also involves distributed evaluation。You can still use
    the classic evaluation loop such as what we saw in the training group video。 in
    which case all processes well perform the full evaluation。To use a distributed
    evaluation。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你不需要将批次放在你正在使用的特定设备上。最后，你需要将最后一行替换为加速器的反向损失。就这样。加速器还涉及分布式评估。你仍然可以使用经典的评估循环，例如我们在训练组视频中看到的那样，在这种情况下，所有过程都将执行完整评估。要使用分布式评估。
- en: you just have to adapt to a evaluation look like this。That's along the a that
    the adults was the accelerator or per， like training。Then you can dismiss the
    line that places the batch on the proper device。And just before passing your predictions
    and labels through your metric。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需适应一个评估循环，如此。这就是加速器或每次训练的方式。然后，你可以省略将批次放置在正确设备上的那一行。在将预测和标签传递给你的指标之前。
- en: use accelerator Gar to give the predictions and labels from each process。![](img/4239aa3dbfdd9db19c493b620811aed1_7.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速器从每个过程获取预测和标签。![](img/4239aa3dbfdd9db19c493b620811aed1_7.png)
- en: The distributed training script has to be launched several times on different
    processes。 for instance， one per GPU you're using。You can use the Pytoch tools
    to do that if you're familiar with them。The accelerate also provides an easy API
    to configure your setup and launch your training script。In a terminal， run accelerate
    Config and un a small questionnaireer to generate a configuration file with all
    the relevant information。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练脚本必须在不同进程上多次启动。例如，每个你使用的 GPU 启动一次。如果你熟悉 PyTorch 工具，可以用它们来实现。`accelerate`
    还提供了一个简单的 API 来配置你的设置并启动训练脚本。在终端中，运行 `accelerate config`，并完成一个小问卷以生成包含所有相关信息的配置文件。
- en: Then you can just run accelerateerate launch followed by the past or your training
    script。In a notebook， you can use a notebook launcher function to launch your
    training。![](img/4239aa3dbfdd9db19c493b620811aed1_9.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以运行 `accelerate launch`，后接过去的或你的训练脚本。在笔记本中，你可以使用笔记本启动器功能来启动你的训练。![](img/4239aa3dbfdd9db19c493b620811aed1_9.png)
- en: 。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 。
