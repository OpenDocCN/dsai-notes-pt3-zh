# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P2ï¼šL2- å¼ é‡åŸºç¡€ - ShowMeAI - BV1TT4y1m7Xg

![](img/586fb3100dc456f34d9f6d755ea10a07_0.png)

ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ welcome to the second tutorial of the Tensorflow beginner courseã€‚ Todayã€‚ we learn the Tensor basicsã€‚ A Tensor is the central object in the Tensorflowlow librariesã€‚ So all operations are based on Tensorsï¼Œ and a tensor is kind of like a nuy and D arrayã€‚ So you can represent 1 Dï¼Œ2 D or 3 D arrays or arrays of even higher dimensionsã€‚ğŸ˜Šã€‚



![](img/586fb3100dc456f34d9f6d755ea10a07_2.png)

![](img/586fb3100dc456f34d9f6d755ea10a07_3.png)

But so let's write this downã€‚ So let's say we represent N D arraysã€‚ but a tenor is also designed so that it has GP U supportã€‚ So we have GP U supportã€‚![](img/586fb3100dc456f34d9f6d755ea10a07_5.png)

And a tensor is also designed so that we can build a so called computational graph and then later track the compute the back propagationã€‚ So for hereï¼Œ for exampleï¼Œ we multiply two tensors with each otherã€‚ and then we build the so called computational graphã€‚ and then the next operation is a subtractionã€‚ So this is also a operation in our computational graphã€‚ And then laterã€‚

 we can use this to calculate the gradientsã€‚![](img/586fb3100dc456f34d9f6d755ea10a07_7.png)

![](img/586fb3100dc456f34d9f6d755ea10a07_8.png)

![](img/586fb3100dc456f34d9f6d755ea10a07_9.png)

So it's used to build a computational graph and to compute the back propagation laterã€‚ And I already have a tutorial about this in my Pytorch beginner courseã€‚ But the same concepts apply hereï¼Œ tooã€‚ So if you're interested in thisã€‚ Then check out the videoã€‚ I will put the link in the descriptionã€‚And then what's also important about tenszos is that they are immutableã€‚

This means that we can never update the contents of a tenzorã€‚ We can only create a new oneã€‚ So now let's start creating some Tzorã€‚ Soï¼Œ first of allï¼Œ of courseã€‚ we want to import our Tor library S T Fã€‚ğŸ˜Šï¼ŒAnd then in order to create a tenorã€‚ we use the T F dot constant functionã€‚ So we say x equals T F dot constantã€‚

 And then we can give it a valueï¼Œ for exampleï¼Œ only a single scala valueã€‚ And then let's print our tenzorã€‚ andã€‚Let's run this file and see how it looks likeã€‚And then we also get a warningï¼Œ which we shouldn't care about so we can silence this by saying import O S and then set O do environã€‚ And then the variable is called TFCPP Min lockã€‚Levelã€‚Equalsï¼Œ and then as a stringï¼Œ a2ã€‚ So nowã€‚

 if we run this againï¼Œ then this warning should go awayã€‚Yesã€‚ so now we see it only printed the tensorã€‚ So this is a tensor with only one single scala valueã€‚ and we can also specify the shape by giving the shape argumentã€‚ And this is a tupleã€‚ So in this caseï¼Œ we can say it's one by oneã€‚ and then we also canï¼Œ for exampleï¼Œ give it a data typeã€‚

 And here we can say T F dot float 32ã€‚ So now if we run this againã€‚Then we should see the difference hereã€‚So nowï¼Œ yesï¼Œ we also see we have the shape 1 by oneã€‚ So now it's not only a scalar valueï¼Œ but a matrixï¼Œ and we have a different data typeã€‚ This is with only a single valueã€‚ Of courseï¼Œ we can also put in a list in hereã€‚ So we can sayã€‚

 for exampleï¼Œ1 and 2 and 3ã€‚ And now we have a 1 D tenorã€‚So here we see the shape is 3ã€‚ And in this caseï¼Œ we say this is a so called rank 1 tenzorã€‚Andï¼Œ of courseã€‚ we can also put in a list of listsã€‚ So let's create another listsã€‚ And the first one is this oneã€‚ And now let's create another listã€‚ And this has to well use 4ï¼Œ5 and 6ã€‚ And now in this caseã€‚

 this is a rank to tenzorã€‚ So now let's print this againã€‚ And let's have a look at the shapeã€‚ğŸ˜Šã€‚So here we see our tensorï¼Œ and we see the shape is 2 by3ã€‚ So this means we have two rows and three columnsã€‚So now in this caseã€‚ we created the values manuallyï¼Œ but there are also some methods to fill our tensor with some valuesã€‚

 For exampleï¼Œ we can say our tensor is T F dot onceã€‚ and then we can give it the shape as tuplesã€‚ So let's say three by3ã€‚ and this is a3 by3 tensor filled only with onceã€‚So here we have itã€‚ and we see that the default data type here is the float 32ã€‚ If we don't specify anyã€‚ So similar to oncesï¼Œ we can also use zerosã€‚ This will do the same thing except that it fills our tenor with zerosã€‚

So here we see our0 tenorã€‚ Then there is also a method that is called Tf dot Iã€‚ and this only takes a single valueã€‚ So in this caseï¼Œ let's put in a threeã€‚ So this will create the identity matrixã€‚ where the diagonal matrix or the diagonal is filled with once and the rest is filled with zerosã€‚ So this is the I functionã€‚ Then there are also methods to initialize our tenor with random valuesã€‚

 So for thisï¼Œ we canï¼Œ for exampleï¼Œ say Tf dot random and then draw some values from the normal distributionã€‚ So normalã€‚ And then hereï¼Œ againï¼Œ we need the shapeã€‚ So let's use3 by3ã€‚ and here we can specify the meanã€‚ So by defaultï¼Œ this is 0 and the standard deviation by default is oneã€‚So let's print our random tenzorã€‚So here we can see the random values which are somewhere around0 and we can also instead of the normal distributionã€‚

 we can draw values from the uniform distribution by saying Tf do random dot uniformã€‚ and then againã€‚ we need the shapeã€‚ and here we can specify the minveã€‚ So let's say this equals0 and the max value equals 1ã€‚ So this means all of our values are between 0 and1 and they are uniformly distributedã€‚

So here we have our new random tensorã€‚So now we can also use the T F dot range functionã€‚ This is similar to the normal Python range functionã€‚ So now we have values between 0 and 9ã€‚ Ohã€‚ of courseï¼Œ I have to print itã€‚So let's clear this and run this againã€‚So yeahã€‚ this is our range tenorã€‚ And now let's see by defaultã€‚ in this caseï¼Œ this is data type in 32ã€‚

 So let's say we want to change thisã€‚ So we want to cast our tensorã€‚ and we can do this by saying X equals T F dot castã€‚ And then againï¼Œ the tensorï¼Œ we want to castã€‚ and then the data type equalsï¼Œ let's use T F dotã€‚Float 32ã€‚ and let's print our new tenorã€‚ and againã€‚ notice that I assign it again to the new value because the original tensor is immutableã€‚Soã€‚

 let's run thisã€‚And then we see we get the same tensorï¼Œ but now with a different data typeã€‚ So this is how we can cast tensrsã€‚ And now let's talk about operations on tenorosã€‚ and what is important here is that all operations are element yã€‚ So let's create two tens x equals Tf dot constant and then a list 1ï¼Œ2ï¼Œ3ã€‚

 and let's use the same with a new tenor Yï¼Œ and it gets the values4ï¼Œ5ï¼Œ6ã€‚ So nowï¼Œ for exampleã€‚ we can do a elementwise addition by saying we have a new tensor C equalsã€‚ and then we can use T F dot at X and yã€‚ And now if we print our Cã€‚ then let's clear this and run thisã€‚Oh here I have a typo constantï¼Œ of courseã€‚ So againã€‚

 let's clear this and run thisã€‚Then we see heres our new tensor 5ï¼Œ7 and 9ã€‚ And this is because we here we did 1 plus 4 equals 5ï¼Œ2 plus 5 equals 7 and 3 plus 6 equals 9ã€‚ So all the operations are executed element Yã€‚ So this is important hereã€‚ So instead of using this at functionï¼Œ we can also just use C equals x plus yã€‚

 So this is doing the same thingã€‚ So now if we print thisï¼Œ then we should see the same resultã€‚Then instead of the sub additionï¼Œ we can also use subtraction by calling T F dot subtract or just saying x minus Yã€‚ againï¼Œ this is doing the same thingã€‚Then we can do element wise division by saying T F dot divideã€‚ or againï¼Œ we can just use this operator here to divide our Tszorã€‚

Then we can do element wise multiplication by calling T F dot multiply or againã€‚ use the star operatorã€‚Then we can compute the dot product by calling T F dotsã€‚Tensorã€‚Dot and then x and yã€‚ And here we have to specify the x equals one in this caseã€‚ So let's clear this and run thisã€‚ And now I have to remove thisï¼Œ of courseã€‚Soï¼Œ let's run this againã€‚

So this is producing a single valueã€‚ So what we are doing here is we compute the product of these values and then some overall valuesã€‚ So one times 4 plus  two times 5 plus  three times 6ã€‚ So this is a single valueã€‚ Then we can do a element wise exponential product with the double asterisk operatorã€‚ So we can say C equals x star star 3ï¼Œ for exampleã€‚ So let's run thisã€‚

So here we get one times1 times 1 equals1ï¼Œ2 times 2 times 2 equals 8ï¼Œ and3 to the power of 3 is 27ã€‚ So this is the elementwise exponential productã€‚ then let's do matrix multiplicationã€‚ So for this let's create two new tenzos with the random functionsã€‚ So in this caseã€‚ let's use random normal and the shape 2 by 2 and let's use the same for our yã€‚

 and then to do elementwise matrix multiplicationã€‚ we can say C equals Tf dot mapmal and then X and yã€‚ and let's print this againã€‚And then here we see we get the matrix multiplication resultã€‚ And in this caseï¼Œ we must be carefulã€‚ So hereï¼Œ the shapes must matchã€‚ So the number of the columns of our first tenzor must match the number of the rows of our second vectorã€‚

 So this dimensionï¼Œ for exampleï¼Œ if we use a three hereã€‚ must also match this dimensionã€‚ So here we can use a three by4ï¼Œ for exampleï¼Œ the only thing that is important is that these two numbers here matchã€‚ So now let's run this again and see if this is workingã€‚So yeahï¼Œ here we have a resultã€‚ and the resulting shape is 2 by 4ã€‚ So these two numbers stay basicallyã€‚

 So this is matrix multiplicationï¼Œ And we can also overload this with the at symbolsã€‚ So we can say x at yã€‚ and this is doing the same thingã€‚Then let's talk about slicingã€‚ slicing and indexingã€‚ So this is the same with nuy arrays or Python list so we can access them in different waysã€‚ So let's create aã€‚Constant tenzor with aï¼Œ with two dimensionsã€‚ So a list of listsï¼Œ let's say 1ï¼Œ2ï¼Œ3ã€‚

 and 4ï¼Œ and another list 5ï¼Œ6ï¼Œ7ï¼Œ8ã€‚ And nowï¼Œ for exampleï¼Œ we want to access only the first rowã€‚ So we get this by saying xï¼Œ and then the index 0ã€‚ So let's clear this and run thisã€‚And then we see we only get 1ï¼Œ2ï¼Œ3ï¼Œ and 4ã€‚ Then we can also use a colon hereï¼Œ and then a commasã€‚ So this means in the first dimensionï¼Œ we want everythingã€‚ So we want all the rowsã€‚

 but only column 0ã€‚ So let's print thisã€‚And we see we get one and 5ã€‚ and we can also do it the other way aroundã€‚ So we can say only columnã€‚Only row 0 and all the columnsã€‚ So this is basically the sameã€‚ If we are only using a 0 hereã€‚ then we should get 1ï¼Œ2ï¼Œ3ï¼Œ and 4ã€‚So yeahï¼Œ here we have the resultã€‚ And againã€‚

 here we can specify the start and stop indexã€‚ So by defaultã€‚ it's going from all the way from the start to the endã€‚ But of courseï¼Œ we can also specify the startã€‚ So let's say oneã€‚ and let's say3ã€‚ So the last one is not includedã€‚ So now this is only using index 1 and index 2ã€‚ So we should get only2 and 3ã€‚So yeahï¼Œ this worksã€‚

 So here we get only2 and 3ã€‚ And nowï¼Œ if we put in two single values in hereã€‚ then we access a specific elementã€‚ So hereï¼Œ let's say we are in row 0 and we want column 1ã€‚ So this should be the value 2ã€‚ So let's print thisã€‚Alrightï¼Œ so here we see value 2ã€‚ So this workedã€‚ So this is how we can apply indexing and slicingã€‚ And now let's talk about reshaping of tensã€‚

 So againï¼Œ let'sã€‚Create a random tenzor withï¼Œ let's sayï¼Œ T F dot random dot uniformã€‚ And all let's use the normal distributionã€‚ and the shape should be 2 by3ã€‚ So let's print our x firstã€‚ So let's clear this and run thisã€‚Then we see our shape is 2 by 3ã€‚ so let's reshape our tenorã€‚ So we can say our new x should be T F dot reshapeã€‚

 And then the original tensor isï¼Œ againï¼Œ our xã€‚ And then the new shape is 3 by 2 in this caseã€‚ And let's print our xã€‚And then this should workã€‚ Ohï¼Œ I forgot the X hereã€‚ So againï¼Œ let's run thisã€‚ Andï¼Œ of courseï¼Œ we can only use shapes here that areã€‚Matching so that can be applied out of these original shapesã€‚ So in this caseï¼Œ it workedã€‚

 We can alsoï¼Œ for exampleï¼Œ just use a single shape with six valuesã€‚ So two times 3 equals 6ã€‚ This is why 6 is working as well hereã€‚So now we have a tensor width the shape 6ã€‚ So only a 1 D arrayã€‚ And you can also use a-1 hereã€‚ For exampleï¼Œ if we say a -1 and then a 2ã€‚ then it will automatically determine the correct shape for youã€‚ So in this caseã€‚

 this should be a 3 by 2 againã€‚So here we see the shape 3 by 2ã€‚ So this workedã€‚ Soï¼Œ yeahã€‚ and as I saidï¼Œ in the beginning aã€‚Tensor is kind of like a numpy arrayã€‚ so you can convert a tensor to a numpy array and vice versaã€‚ So let's see how we can convert to a nuumpy arrayã€‚ And this is very easyã€‚ So you just say our Xã€‚

 or let's sayï¼Œ in this caseã€‚Yeahï¼Œ let's use X equals x and then call the numpy functionã€‚ So now if we print our xï¼Œ then it should look the sameã€‚ And if we print the type of Xã€‚ then we should see that this is aï¼Œ indeedï¼Œ a nuy arrayã€‚ So let's run thisã€‚So yeahã€‚ we see our x has the same values as the tenorï¼Œ but now we see it is a nuy arrayã€‚

 and to convert it backï¼Œ we can say x equals Tf dot convert and then underscore to tenor and then againã€‚ we put in the numpy arrayã€‚ And now if we print the type of this one print type of X againã€‚ then we should see this should again be a tenorã€‚ So yeahï¼Œ this workedã€‚ And so we see this is a tenor flow eager tenorã€‚ And you shouldn't worry about this nowã€‚

 So what eager tensor means is that it evaluates the operations immediately without building this computational graph that I mentioned in the beginningã€‚ğŸ˜Šï¼ŒSoï¼Œ but yeahï¼Œ as I saidï¼Œ you shouldn't worry about this nowï¼Œ Just know that this is a tenorã€‚ And this is not only because I use this convert to Tor functionsã€‚ So all of these constant valuesã€‚ So if I use T F dot random normal or if I use T F dot constantã€‚And then a value hereã€‚

 So all of these are E tenzo usã€‚So here againï¼Œ we see a eager tenor for this one as wellã€‚ So yeahã€‚ these areã€‚All the functions that I wanted to show youã€‚ And nowã€‚ a couple more things that I want to mentionã€‚ So instead of using numbers hereï¼Œ we can alsoã€‚ for exampleï¼Œ use a string and get a string Tenzoaã€‚ So let's printã€‚Our new string ten onã€‚

 and let's clear this and run thisã€‚So here we see we get a tensor with the data type stringã€‚ And againï¼Œ here we can use a list and produce a1d as string tensorã€‚ Soï¼Œ for exampleã€‚ we can use another name and another nameï¼Œ Max and meã€‚ and now if we run thisã€‚ then we see we have a string tensor with a different shape with multiple valuesã€‚

So this is working as wellã€‚ And then one more thing that I want to mentionã€‚ So hereï¼Œ as I saidã€‚ we used constant tensorï¼Œ so they are immutableï¼Œ but there is also a different kind of tensorã€‚ and this is a tensor flow variableã€‚ So instead of usingï¼Œ for exampleï¼Œ let's use 1ã€‚2 and 3 with this constant functionã€‚ We can do the same thing with T F dot with a capital V and then variableã€‚

 And now if we print thisã€‚So now we see it looks the sameã€‚ but we also get the hint that this is a tensorflow variable and a variable should be used when you want to modify its valueã€‚ Soï¼Œ for exampleï¼Œ a tensorflow variable is used to store the model parameters that we are then updating during trainingã€‚ but you don't need to worry about this nowï¼Œ because we're going to use a higher level APIã€‚

 and this is the Kas APIã€‚ And this is doing all of this stuff for usã€‚ So we don't need to worry about using a variable and then updating the weightsã€‚ So but you should know that this existsã€‚ And this is different than a tenorflow constantã€‚ And yeahã€‚ I think that's all I wanted to show you about the tensorsã€‚

 And I hope that you enjoyed this tutorialã€‚ If you enjoyed itã€‚ then please hit the like button and consider subscribing to the channelã€‚ And I hope to see you in the next video byã€‚ğŸ˜Šã€‚![](img/586fb3100dc456f34d9f6d755ea10a07_11.png)