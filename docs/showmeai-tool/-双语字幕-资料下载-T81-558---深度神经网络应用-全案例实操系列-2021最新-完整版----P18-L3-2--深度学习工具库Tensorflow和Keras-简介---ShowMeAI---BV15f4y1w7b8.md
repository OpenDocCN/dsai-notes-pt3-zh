# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P18ÔºöL3.2- Ê∑±Â∫¶Â≠¶‰π†Â∑•ÂÖ∑Â∫ìTensorflowÂíåKeras ÁÆÄ‰ªã - ShowMeAI - BV15f4y1w7b8

HiÔºå this is Jeff HeatonÔºå Welcome to applications of Deep neural Network with Washington University In this video„ÄÇ we're going to have an introduction to Tensorflowlow and Kes„ÄÇ and we're going to see how Tensorflowlow can be used directly to perform mathematical calculations and Alkis becomes the neural network layer on top of the low levelvel Tensorflowlow compute engine for the latest on my AI course and projects„ÄÇ click subscribe in the bell next to it to be notified of every new video TensorFlow and Kes„ÄÇüòä„ÄÇ



![](img/73f8c430d7aa8a142b3ebee5c5c859cc_1.png)

So TensorFlow is the low level mathematical library that gives you access to CPUÔºå GPU and grid„ÄÇ computing capabilitiesÔºå and CAs is the high level abstraction that lets you think of these mathematical constructs as neural networks„ÄÇI give you some links here that point to the various locations that are useful for dealing with Tensor Flow and Kas„ÄÇOne of the first things that you need to deal with is there's a lot of different versions of Tensorflow„ÄÇ

 and Google is very good or badÔºå as the case may be at breaking changes„ÄÇ There's a lot of very smart people working on Tensorflow who are very opinionated about how the API should be„ÄÇAnd as different factions of them win and lose their respective battles„ÄÇ breaking changes happen to the API„ÄÇ A breaking change means that a new version will basically cause previous code written for previous versions to not work„ÄÇ

 They change the names of things„ÄÇ They change the capitalizations of things„ÄÇLots of lots of little„ÄÇ sometimes just little annoying thingsÔºå sometimes big structural changes„ÄÇSo it's important that you're running the version of Ten flow that is specified for this class„ÄÇThis video was recorded with TensorFlow 2„ÄÇ0„ÄÇWhich was in its dev stages as this video was recorded„ÄÇ

 but as long as you have a version that is 20 or laterÔºå I will be updating the course„ÄÇVideos for the different partsÔºå if something gets broken as a result of newer tensorflow„ÄÇ So you can simply run this and it will show you the version that youÔºå that you have„ÄÇNow installing TensorFlow„ÄÇI have an entire video just on how to install Tensorflow on Windows and another video for Mac„ÄÇ

 Those deal with installing Tensorflow with CPU to get really good performance„ÄÇ you need to use your GPU and your GPU needs to be the right kind of GPU„ÄÇ Some of the assignments and examples that will run in class will require a G run on a CPU„ÄÇ but it's going to be slow„ÄÇAnd installing a GPU is is not the easiest thing in the world„ÄÇ

 I'll probably do a video on that„ÄÇ I mostly personally run„ÄÇGPU deep learning in the cloud„ÄÇ where I don't have to install all the hardware and drivers and and other things„ÄÇ but it can certainly be done„ÄÇWhat I recommend for this class„ÄÇ especially on the assignments and parts of this classÔºå that require a GPU is Google Coab„ÄÇ

 Google Collabab is cloud basedÔºå You don't have to install Python or anything„ÄÇ It comes completely ready to go„ÄÇ I have a video that is linked on the first module on how to use Google Coab with this class„ÄÇ and we probably talked about it in the first class meeting„ÄÇSo this is„ÄÇ this is probably the recommended way to actually run all of the examples and to complete your assignments is Google Coab„ÄÇ

 It's a powerful instance„ÄÇ It is a dual core with„ÄÇI believe 12 gig of Ram and a GPU„ÄÇ you can't beat it„ÄÇ So that's that's my recommended route forÔºå for working on this class„ÄÇ And why did I choose Tensorflowlow for this classÔºå Well„ÄÇ Tensorflowlow is supported by Google has excellent support in Google Google Cloud„ÄÇ

It has great CPU and GPU supportÔºå and it's in Python„ÄÇ Python is very quickly becoming sort of the the high level language for machine learning and AI„ÄÇ So you're well served in learning Python and learning„ÄÇLearning deep learning through Ks and and through Python„ÄÇ NowÔºå you can use Tensorflow directly„ÄÇ

 And if you're writing very custom sort of machine learning modelsÔºå that might be the way to go„ÄÇ But by and largeÔºå the way to the way to access this is through Ks„ÄÇ It makes it makes the deep learning quite a bit easier to„ÄÇTo set up and there's really not much of a downside unless you truly do need complete control over the computation of the underlying neural networks„ÄÇ

 and then you would need Tensorflow„ÄÇAnd there's other deep learning tools„ÄÇ I have a number of them listed here„ÄÇIf you're particularly the end of Java„ÄÇ deep learning for J is definitely one to look at as is H2O„ÄÇTensorflow is„ÄÇAt least in previous versionsÔºå it was very graph oriented so that it would compute later„ÄÇü§¢„ÄÇ

A big thing about Tensorflow 2„ÄÇ0 is eager execution„ÄÇ NowÔºå they made a lot of changes„ÄÇ So this is very much„ÄÇ if you haven't worked with Tensorflow beforeÔºå don't worry„ÄÇ it's completely changed anyway„ÄÇ So this„ÄÇThis will get you ready for the latest version„ÄÇAnd this is just showing tensor boardÔºå which helps you visualize the neural networks that you that you create„ÄÇ

 We're going to look at how to use Tensorflow directly„ÄÇ and we're only going to go through that in in this in this video„ÄÇ the rest of the videos will be completely in Kira„ÄÇ So what this is going to do is do something called a mandlebro plot„ÄÇ you can see it here„ÄÇ

 If you've ever worked with Mandlebrots before you definitely recognize that that very classic looking plot that you have there„ÄÇ EssentialÔºå this is a set of equationsÔºå very simple equations that give a„ÄÇ![](img/73f8c430d7aa8a142b3ebee5c5c859cc_3.png)

You can keep zooming in on regions of thisÔºå and it's almost infinite in the complexity of the very cool sort of landscapes that you could zoom into„ÄÇ![](img/73f8c430d7aa8a142b3ebee5c5c859cc_5.png)

Here I've written the code to basically do a mandlebro plot„ÄÇ Now you can sees it's very simple„ÄÇ that's the code to produce the manelbro„ÄÇ And the the functions„ÄÇ the display fractal that's actually used after it's completely rendered what we're doing actually in Tensorflow is we're defining„ÄÇEssentially„ÄÇIt's like it's a complex numberÔºå it's a complex plane and you plot out the Mandlebrot across the entire plane and this„ÄÇ

 I'm not going to go into the actual math in the MandlebrotÔºå but there's plenty of tutorials on that„ÄÇ![](img/73f8c430d7aa8a142b3ebee5c5c859cc_7.png)

And we're essentially sweeping across this entireÔºå this entire plane„ÄÇ We're doing 200 iterations of it„ÄÇ So this gets drawn 200 times each time it gets drawn a little bit better„ÄÇ And it's very much an iterative iterative process„ÄÇ So each time through this„ÄÇ It's being sent off to tensorflow for processing„ÄÇ It could use the G P or if you wanted to„ÄÇ

 It's so fast that you reallyÔºå you really don't need the„ÄÇYou don't need the actual GP for this„ÄÇ The CPU alone can do it„ÄÇ And this is essentially the equation here that is that has been calculated to actually plot the the mandlebrot as it goes through„ÄÇ![](img/73f8c430d7aa8a142b3ebee5c5c859cc_9.png)

And if you run thisÔºå you can see that it actually goes„ÄÇVery quickly„ÄÇ Now to see a little more exactly what's going onÔºå this is also using Tensorflow directly„ÄÇ I'm creating two matrices here„ÄÇSo these are actually vectors„ÄÇA yeah„ÄÇ I guess youd call this a row matrixÔºå this is a column matrix„ÄÇBecause this goes straight across„ÄÇ

 this is two values that are on top of each otherÔºå and we're going to do a matrix multiply of matrix 1 by matrix 2„ÄÇ and we print it out„ÄÇAnd as you can seeÔºå the results here„ÄÇIt does the matrix multiply and results in 12„ÄÇNow I convert it to a float so that you don't see all the tensor„ÄÇDecorations around it„ÄÇThese were two constantsÔºå so that was constant times constant„ÄÇ

And you can tell this is all very linear algebra oriented„ÄÇ Now we're doing two variables and we're going to subtract well we're subtracting a variable from a constant„ÄÇAnd we do thatÔºå and we can basically see that we get the negative 2Ôºå negative 1 row„ÄÇMatrix„ÄÇWe can now reassign X because x is a variable so we reassign it and we're able to basically recalculate that calculation from up there and get a different value„ÄÇ

 so this this is the building blocks upon which the neural networks are built in TensorF Now Kis lets us start to think about the layers of the neural networks like we had before„ÄÇSo we're going to use a classic data setÔºå the miles per gallon data set„ÄÇThis lets us„ÄÇ

That data set gives us statistics or calculations on various cars and the miles per gallon„ÄÇ so the idea is to build a model that uses cylinder count and displacement and other stats on cars to actually come up with the miles per gallon to produce a model that does that„ÄÇ

So here we are going to basically read in„ÄÇThe auto miles per gallon„ÄÇWe're going to keep the names of the carsÔºå the cars themselves„ÄÇ the names of the cars aren't predictive„ÄÇ they're just the car names„ÄÇHorse power„ÄÇ we do have some missing value„ÄÇ so we're going to fill in the media„ÄÇ

 and just we' we've seen this beforeÔºå so I'm going through this prettyÔºå pretty quickly„ÄÇAnd then we create our x and R Y x is the predictors„ÄÇ so we're predicting on cylinders displayplacement in horsepowerÔºå weightÔºå acceleration„ÄÇ year and originÔºå what country is produced in„ÄÇAnd we're calculating this on„ÄÇ

Or we're trying to predict the miles per gallonÔºå so this is your x„ÄÇ which is your values used to predict and y is what you're actually predicting„ÄÇAnd then this is what„ÄÇKas actually looks like we create a sequentialialÔºå so that's just layers that go in sequence„ÄÇWe create our first dense layerÔºå a dense layerÔºå simply a layer where every neuron in the first layer is connected to the next layer„ÄÇ

 Ands that's very common„ÄÇ That's usually how layers actually work„ÄÇ especially for tabular data like we have now„ÄÇ This will be different when we get into images„ÄÇThe input dimensions are going to be the x shape 1„ÄÇ So that is the number of columns that we have„ÄÇ because X is the input value„ÄÇ Sha 0 would be how many rows„ÄÇ Shape 1 is how many columns„ÄÇ

 Activ is the rectified linear unitÔºå and we have 25 neurons„ÄÇ We have 10 in the next hidden layer„ÄÇ We don't have to tell it how many inputs we have as its„ÄÇ it's basically the 25 from the previous layer„ÄÇ and alsoÔºå activation is re„ÄÇOutput is just one for a regression neural networkÔºå the output is always one„ÄÇ

It's also important that for a regression neural network that you always have the mean squared error as your as your loss optimizer willll usually use atom in this class„ÄÇ there's other ones you can use that we'll see„ÄÇSoon„ÄÇAnd then we fit it„ÄÇ We're going to fit it for 100 epochs„ÄÇEpoex is just how long the neural network trains for„ÄÇ That may or may not be enough„ÄÇ We'll later see how we can determine how many epochs is actually enough„ÄÇ

 Verbose means to print out data as we go„ÄÇ And if we run this„ÄÇ we can see you see the loss shrinks as it continues„ÄÇ So it gets better and better and more effective as it goes„ÄÇ This is what the verbose value up there says to do„ÄÇ So this lets you„ÄÇThat that lets you control how much data is being dumped to the screen on you„ÄÇ Now„ÄÇ it's not doing particularly good here this is„ÄÇThe hundred is probably not enough for it„ÄÇ We'll later see that we get more advancedÔºå and this actually gets quite a bit„ÄÇBetter predictions„ÄÇAnd we calculate our root mean square error„ÄÇ24Ôºå believe me„ÄÇ

 is not particularly good on miles per gallon because that's the range„ÄÇSo you can„ÄÇ in cases like thatÔºå this is not that uncommon„ÄÇ You can retrain it„ÄÇ It might give you a better result„ÄÇ YeahÔºå that's that's a much better result„ÄÇ So it just took a retrain in that case„ÄÇ But we'll see later how we can control automatically the number of epochs that's needed„ÄÇ

 And you can see here this should drop„ÄÇ YeahÔºå that's much better„ÄÇ That' that's about as good as it gets„ÄÇ You'll see it sometimes get as low as3„ÄÇ And then we can print out the various cars and therere miles per gallon or predicted miles per gallon„ÄÇAnd yeahÔºå you can see now there much„ÄÇMuch closer„ÄÇYou can also do classification„ÄÇ

 we'll use the classic IIS data set for thatÔºå that's where you have four measurements that give you any of three different types of iris flour„ÄÇYou're using sepple lengthÔºå Sppple widthÔºå pedal length and pedal width„ÄÇThis is what a curas classification neural network looks like„ÄÇ It's very similar„ÄÇ You have the inputs„ÄÇ That would be four inputs„ÄÇ You have the„ÄÇHidden one or more hidden layers„ÄÇ

 howeverÔºå with a classificationÔºå especially a multi class classification„ÄÇ which means you have more than two classes„ÄÇ you'll do softm and categorical cross entropy„ÄÇIf this was a binary classificationÔºå which we'll see„ÄÇIn the next module„ÄÇThat would„ÄÇ that would be a little different„ÄÇ You would have a binary„ÄÇALo function here„ÄÇ

But we'll see that when we get to that„ÄÇTraining this oneÔºå it trains and decreases the loss„ÄÇYou can also print out the speciesÔºå Those are the types of iris that we're trying to classify„ÄÇ And this is what the output from it looks like„ÄÇ It's in scientific notation„ÄÇ which makes that a little bit difficult to read„ÄÇ You can tell it not to use„ÄÇ

You can suppress the scientific notationÔºå but essentially„ÄÇThese three values are the three irisees in whichever ones the biggestÔºå which is this one„ÄÇ It was classified to be that first irisÔºå which was Satosa„ÄÇ You can also suppress the scientific notationÔºå And then you see the values that are one„ÄÇ

 or at least very close to one„ÄÇThat means it's all that first class„ÄÇ Now the Iis file is sorted by by the individual irisesÔºå so that's why at the top of the file„ÄÇ they're all the same and you can also turn these predictions into just numeric value so0 means the first Iis1 is the second and two is is the third„ÄÇ So that's if you just want literally a number that tells you which of the classes was actually predicted„ÄÇ

You can also print out using this array notationÔºå you can print out the actual textual name of the irisees the classes that were chosen„ÄÇ and you can see the accuracy is 98%Ôºå so it's it's very„ÄÇVery good„ÄÇYou can also feed in just ad hoc values and have a prediction„ÄÇ so this is how you'd feed in one value and it predicts Iis Vi Jenica for these measurements„ÄÇ



![](img/73f8c430d7aa8a142b3ebee5c5c859cc_11.png)

And you can feed a bunch of them at once„ÄÇ This is how you'd feed too„ÄÇThank you for watching this video„ÄÇ In the next video„ÄÇ we're going to see how to load and save Kira's neural networks„ÄÇ This content changes often„ÄÇ so subscribe to the channel to stay up to date on this course and other topics in artificial intelligence„ÄÇ

üòä„ÄÇ