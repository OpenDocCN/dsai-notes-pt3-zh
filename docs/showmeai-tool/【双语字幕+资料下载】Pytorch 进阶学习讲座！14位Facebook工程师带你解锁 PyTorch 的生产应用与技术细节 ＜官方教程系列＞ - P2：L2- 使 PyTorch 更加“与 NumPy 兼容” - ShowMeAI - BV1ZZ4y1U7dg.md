# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P2ï¼šL2- ä½¿ PyTorch æ›´åŠ â€œä¸ NumPy å…¼å®¹â€ - ShowMeAI - BV1ZZ4y1U7dg

ğŸ¼ã€‚

![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_1.png)

Hi everyoneï¼Œ I'm Mike Ruberryï¼Œ an engineer at Facebook working on Pytorrchã€‚

 and I'm going to be talking to you about how we're making Pytorrch more nupy compatible In this short talkã€‚

 there'll be three partsã€‚Firstï¼Œ I'll describe what it means for Pytorrch to be nu P compatible and what our goals areã€‚

In the second partï¼Œ I'll talk about the many new and updated operators we have in Pytororch 1ã€‚

7 that make it the most nuy compatible release of Pytorch yetã€‚And in the third partã€‚

 I'll talk briefly about where we're going in P towards 1ã€‚8 and beyondã€‚

So let's get started by talking about what it means for Pytorch to be numpy compatibleã€‚

 For those of you who don't knowï¼Œ Numpy is a popular Python package for working on arrays or what Pytorch would call tensorsã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_3.png)

Its API is well known and that makes it familiar to many users coming to PyTtororch for the first timeã€‚

By making Pytorch compatible with Numpyï¼Œ which means it implements the same functions that Numpy doesã€‚

 and that the behavior of those functions is pretty much the same in Pytorch and in Numpyã€‚

This means that people familiar with nuy will already be familiar with Pytorchã€‚

 making it intuitive and easy to useã€‚This should let people spend less time looking at documentation and more time developing their programsã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_5.png)

The idea of nuy compatible pieytorch is not newã€‚From the beginningã€‚

 Pyedtort was designed to be like Numpyï¼Œ and as these code snippets showã€‚

 both packages are extremely similar todayã€‚There are small differences between Pytorch and nuumpyã€‚

 howeverã€‚For exampleï¼Œ as previously mentionedã€‚What Numpy calls asï¼Œ Pytorch calls tensorsã€‚

In this snippet we also see that Pytorch is a little more explicit about data typesã€‚

 requiring that the Tensor B be specified as containing floating point values before the exponential function can be called on itã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_7.png)

Nowï¼Œ we might think that the goal of Numpy compatibility is to eliminate all differences between Pytorrch and Numpyã€‚

That's actually not the caseã€‚There will always be differences between Pytorrch and nupy because they focus on different scenariosã€‚

Pytorchï¼Œ for exampleï¼Œ is designed to run on multiple devicesï¼Œ not just on the CPUã€‚It also runsã€‚

 for exampleï¼Œ on GPUsï¼Œ TUsï¼Œ mobile devicesï¼Œ and custom Asicsã€‚

Pyitetorch is also designed to run neural networksã€‚

And neural networks typically run in a lower floating point precision than scientific programs doã€‚

Finallyï¼Œ Pytorch is designed to support autogradï¼Œ which has its own specific set of requirementsã€‚

For exampleï¼Œ to compute a backwards pass properlyï¼Œ Pytorch has to save intermediate computationsã€‚

 Foing on scenarios like this means that Pytorch and numpy will never be exactly the sameã€‚

 but we can still strive to make pytorch as similar to nuy as possibleã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_9.png)

Now let's talk about how we've done that in PyTtororch 1ã€‚

7 and why it's the most nuumpy compatible version of PyTtororch we've ever releasedã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_11.png)

It's because we've added a ton of new operators that Numpy hadã€‚

 but Pytororch was missing and even updated some older Pytorch operators whose behavior was different than their corresponding counterparts in Numpyã€‚

 For exampleï¼Œ we've added a slew of functionality related to fast Fourier transformsã€‚

We have new functions for computing statistics like Torcht Quantileã€‚

 We have helper functions for manipulating tensors like Htacï¼Œ Vt and Dtã€‚

 We even have the zeroth order modified besel function of the first kindã€‚

 We also updated some operatorsï¼Œ like divisionï¼Œ for exampleã€‚

 in Pytorrch is now compatible with division in numppyy and Python 3ã€‚

 always performing a true division instead of sometimes performing an integer divisionã€‚ğŸ˜Šï¼ŒIn totalã€‚

 we modified over 65 operators in PyTtororch 1ã€‚7ã€‚

![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_13.png)

![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_14.png)

Nowï¼Œ where are we going Wellï¼Œ in Piyr 1ã€‚8ã€‚We expect to add or modify another 38 operatorsã€‚

We expect to expand on two new modules tooã€‚The Torch dot F of T moduleã€‚

 which contains the fast Fourier functionality that I already mentioned and the Torchdot lineal moduleã€‚

 which will contain linear algebra functionalityã€‚And we also plan to keep our community engagedã€‚

At the time of writingï¼Œ we had 14 active community contributorsã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_16.png)

And since thenï¼Œ we've already added several moreã€‚This is a great opportunity for you to get involved tooã€‚

If there is a function in nuumpy or s pie that you'd like to see in Pytororchã€‚

 let us know by filing an issue on our GitHubã€‚And if you'd like to get involved by contributing an operator to Pytorchã€‚

 see the link to issue to get startedã€‚

![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_18.png)

![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_19.png)

A huge thank you again to our community contributorsã€‚This slide is already out of dateã€‚

 which is unfortunateã€‚But it's been a great experience working with our fantastic Pytorch community to make Pytorch more nuumppy compatible and ultimately to make it easier to useã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_21.png)

So thank you again for all our active contributors as of October of this year for their help and supportã€‚

ğŸ¼And thank you for listening to this talk about how we're making pieytorch more nup compatibleã€‚



![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_23.png)