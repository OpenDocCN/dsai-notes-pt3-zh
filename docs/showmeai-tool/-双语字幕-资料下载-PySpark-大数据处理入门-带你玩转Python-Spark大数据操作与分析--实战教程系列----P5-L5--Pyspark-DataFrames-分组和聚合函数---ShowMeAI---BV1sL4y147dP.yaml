- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPySpark Â§ßÊï∞ÊçÆÂ§ÑÁêÜÂÖ•Èó®ÔºåÂ∏¶‰Ω†Áé©ËΩ¨Python+SparkÂ§ßÊï∞ÊçÆÊìç‰Ωú‰∏éÂàÜÊûêÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P5ÔºöL5- Pyspark
    DataFrames ÂàÜÁªÑÂíåËÅöÂêàÂáΩÊï∞ - ShowMeAI - BV1sL4y147dP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: „ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_1.png)'
  prefs: []
  type: TYPE_IMG
- en: Hello allÔºå my name is Krisnaak and welcome to my YouTube channel„ÄÇ So guys we
    will be continuing the Pipar series and in this particular video we are going
    to see group by an aggregate function„ÄÇüòäÔºåAlready I have actually created somewhere
    around four tutorials on Pipar„ÄÇ this is basically the fit tutorial„ÄÇ And againÔºå
    this is a part of a data frame„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: why we should actually use group by aggregate functions again for doing some
    kind of data preprosing„ÄÇ So let's begin for this particular data for this particular
    problem I created a data which has three features like name departments and salary
    and you have some of the data like Kris data science salary„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: rightÔºå something like this„ÄÇ So over here in short„ÄÇ if I want to basically understand
    about this particular data they are some departments probably where Krisish and
    other people teach and based on different different departments„ÄÇ they get a different
    different salaryÔºå So let's see how we can perform different different group by
    an aggregate functions and see how we can preproces or how we can get some or
    retrieve some kind of results from this particular data„ÄÇ So to begin with what
    we are going to do we are a first of all going to import Pipar„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_3.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_4.png)'
  prefs: []
  type: TYPE_IMG
- en: SQL import„ÄÇSpark sessionÔºå as usualÔºå we have to create a spark session„ÄÇ So after
    this„ÄÇ what we have to doÔºå I'll create a spark variable„ÄÇ So I'll use spark sessionÔºå
    dot builder dot„ÄÇAp nameÔºå I think everybody must be familiar with this„ÄÇ but againÔºå
    I'm trying to show you this one„ÄÇ So let me write it as aggregate„ÄÇDot„ÄÇGet or create„ÄÇ
    So now I've actually created a spark session„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: OkayÔºå probably this will take some time now if I go and check out my spark variable„ÄÇ
    so here is your entire information okay„ÄÇWith respect to this particular spark
    very well„ÄÇ Now„ÄÇ let's go ahead and try to read the data set„ÄÇ NowÔºå I will just
    write D F underscore pi spark„ÄÇAnd then here I'll write Sp dot read„ÄÇDot CSvÔºå the
    CV file name is basically test„ÄÇ3 dot Csv„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And rememberÔºå I'll be giving this particular CV file in the Github also„ÄÇ and
    then I'll be using header is equal to true„ÄÇComa infer schema is equal to2„ÄÇNow„ÄÇ
    this is my dear underscoreosscope by spark„ÄÇNowÔºå what I'll do in the next statement„ÄÇ
    I will write Df underscorecope pipar dot show„ÄÇRight now here you'll be able to
    see that I am actually being able to see all the data sets here I have name„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: departments and salary on all this particular information„ÄÇIf I really want to
    see the schema or the columns like which all columns where it belongs to„ÄÇ just
    like a data typesÔºå I can definitely use DF underscorecope Ipar„ÄÇDot print schema
    right and now here you can see name is a string department is string and salary
    is basically an in teacher okay„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: NowÔºå let's perform some group by operation„ÄÇ FirstÔºå we'll start by group by operation„ÄÇProbably
    I want to group by name and probably try to see what will be the mean average
    salary„ÄÇYou know what suppose let's let's take a specific example over here„ÄÇ So
    I'll write Pf dot underscorecope bypar dot group by„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: supposeupp I want to go and check who is having the maximum salary out of all
    these people that are present in this particular data set„ÄÇ So I'll first of all
    group by name if I execute this you can see that we will be getting a return type
    of group data at some specific memory location„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And you should always know that guys group by aggregate functions works together„ÄÇ
    That basically limits is first of allÔºå we we need to apply a group by functionality„ÄÇ
    and then we need to apply an aggregate function„ÄÇ So aggregate function here really
    want to check just press dot and press tab So here you'll be able to see a lot
    of different different function examples like aggregate average count max mean
    pi and many mode right now what I'm going to do I'm just going to use this dot
    sum because I really need to find which is the maximum salary„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: üòäÔºåHoweverFrom out of all these particular employeesÔºå who is having the maximum
    salary„ÄÇ So here I'll say dot sum„ÄÇ And if I execute itÔºå you'll be able to see that
    we are getting a sQL dot data frame„ÄÇ which has name and sum of salary„ÄÇ This is
    very much important as sum of salary because I really want to have the sum of
    the salary„ÄÇ rememberÔºå we cannot apply sum on the string„ÄÇ So that is the reason
    it has not done over here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: it is just giving you the name because we have group by name„ÄÇ And this dot sum
    will just get applied on this particular salary„ÄÇ Now„ÄÇ if I go and write dot show
    here you will be able to see„ÄÇüòä„ÄÇSudanhu over here is having the highest salary
    of 35000„ÄÇ Sunny has 12000„ÄÇ Krissh has 19000„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Mahesh has 7000„ÄÇ So if you go and see over hereÔºå Sudanhu is basically present
    here„ÄÇ here and in big data„ÄÇ So overallÔºå his salary should be 35000 if you compute
    it Similarlyly„ÄÇ you can go and compute my salary over here„ÄÇü§ßOver here by just
    calculating this„ÄÇ and then you can also compute sunny salary„ÄÇ and you can also
    see my H„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So this is one just an example„ÄÇ So here I'll just write„ÄÇ we have grouped„ÄÇDo
    fine„ÄÇThe maximum salary„ÄÇAndDefinite over here from this entire observation„ÄÇ we
    can retrieve that Sudanhi is having the highest salary„ÄÇ OkayÔºå now let's go to
    one step ahead„ÄÇ one more step ahead„ÄÇ now we will try to group by departments to
    find out which department gives maximum salary Okay„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we are going to do a group by„ÄÇDepartments„ÄÇWhich gives maximum salary„ÄÇ Suppose
    this is my„ÄÇThis is my requirement„ÄÇ OkayÔºå and different different types of requirement
    makeup up„ÄÇ I'm just trying to show you some examples„ÄÇ So I'm just going to copy
    this„ÄÇÂçó going do„ÄÇUse this department„ÄÇOkayÔºå and then I'm basically going to say
    dot sum dot show„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: If I execute it let me see department is a wrong column name so I'll write department
    it is department So let me write S now if I go and see Iot over here gives some
    salary around115000 to this employees to all the employees right combined because
    we are doing the sum big data gives somewhere around 15000 data science gifts
    Im around 4300 Now suppose if I go and see big data over here 404080008000 and
    13000„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 130015000 so I hope I'm getting yesÔºå big data is actually giving us 15000 so
    you can go and calculate it suppose if you want to find out the mean you can also
    find out the mean okay„ÄÇ so let me just write it over hereÔºå just copy this entire
    thing paste it over here and write me write instead of instead of sum I'll write
    to write mean so by default the mean salary„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Here you can see that for a particular employee somewhere for I O T to 7500„ÄÇ
    because this mean will be based on how many number of people are working in the
    departmentÔºå right„ÄÇ So like thisÔºå you can actually find out NowÔºå I can also check
    one more thing„ÄÇ guysÔºå I can copy this„ÄÇ I can try to find out how many number of„ÄÇEmployees
    are actually working based on the department„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so I can use dot count„ÄÇ And then if I go and execute thisÔºå probably this is
    a method„ÄÇOkay„ÄÇNow here you will be seeing that in Io there are two people in big
    data there are four people in data science they are four people„ÄÇ so4 plus 4 plus8
    total employees that are present over here is basically 10„ÄÇNow„ÄÇ one more way that
    I can basically apply a directly aggregate function also to see„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: these are all some of the examples and againÔºå you can do different different
    group by let me use Df Ppar„ÄÇ suppose I say dot aggregate okayÔºå and inside this
    I will just give my key value pairs like this„ÄÇ suppose I say let me say that salaryÔºå
    I want to find out the sum of the salaries„ÄÇThe overall salary that is basically
    given to the entire total expenditure insert„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So the total expenditure that you will be able to see somewhere around 73000
    alright„ÄÇ so we can also apply direct aggregate functionÔºå otherwise this all are
    also aggregate function which we basically apply after after you know applying
    a group by function now suppose this are probably the salary I want to find out
    suppose I'll take this example I want to find out the maximum salary that the
    person is basically getting who is getting the maximum salary sorry„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So here instead of writing dot sum now I'll write max dot show now here you
    can see Sudansha is basically getting 20000 over here10000 Krisish is getting
    10000 my is getting for 4000 right so all this particular data is theyy Kris is
    basically getting with respect to data science over here 10000 so it has basically
    picked up it is not picking up both the records but at least when it is grouping
    by name and then it is showing this particular data that time you will be able
    to see it let's see whether Ill be also able to see this or not„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So group byÔºå if I score and write min„ÄÇSo here you will be able to see minimum
    value with respect to different different records when Im grouping by here you
    will be able to see that Suanhu sorry„ÄÇ Sudanhu is getting a minimum salary of
    50002000 Kris is getting a minimum salary of 4000 right„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we can also get that particular information„ÄÇ Now let's see what all different
    different types of operation are there„ÄÇAverage is also there„ÄÇ So if I write A
    V GÔºå it's just like mean only guys„ÄÇ So this is basically the mean salary that
    probably again„ÄÇAgain„ÄÇ you can check out different different functionalities why
    these all things are basically required„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Under one thing is that you really need to do a lot of data preprosing a lot
    of retrieving skills that you basically do„ÄÇ You can check it out this one and
    you can do different different functionalities as you like„ÄÇ So I hope you like
    this particular video Probably in the next video I'm going to start with spark
    Mlib libraries where we'll be solving some machine learning algorithm problems„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_6.png)'
  prefs: []
  type: TYPE_IMG
- en: So I hope you like this particular video I'll see you all in the next week„ÄÇ
    Have a great day thank you baba„ÄÇ
  prefs: []
  type: TYPE_NORMAL
