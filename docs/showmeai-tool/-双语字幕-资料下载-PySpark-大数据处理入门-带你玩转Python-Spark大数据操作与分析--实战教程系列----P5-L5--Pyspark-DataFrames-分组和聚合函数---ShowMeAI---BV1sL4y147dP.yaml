- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P5ï¼šL5- Pyspark
    DataFrames åˆ†ç»„å’Œèšåˆå‡½æ•° - ShowMeAI - BV1sL4y147dP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬ Python + Spark å¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P5ï¼šL5- Pyspark
    DataFrames åˆ†ç»„å’Œèšåˆå‡½æ•° - ShowMeAI - BV1sL4y147dP
- en: ã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ã€‚
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1babe07f0737b77a8ca240e4a3c70599_1.png)'
- en: Hello allï¼Œ my name is Krisnaak and welcome to my YouTube channelã€‚ So guys we
    will be continuing the Pipar series and in this particular video we are going
    to see group by an aggregate functionã€‚ğŸ˜Šï¼ŒAlready I have actually created somewhere
    around four tutorials on Piparã€‚ this is basically the fit tutorialã€‚ And againï¼Œ
    this is a part of a data frameã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ï¼Œæˆ‘çš„åå­—æ˜¯ Krisnaakï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„ YouTube é¢‘é“ã€‚æ‰€ä»¥ä¼™è®¡ä»¬ï¼Œæˆ‘ä»¬å°†ç»§ç»­ Pipar ç³»åˆ—ï¼Œåœ¨è¿™æ®µè§†é¢‘ä¸­æˆ‘ä»¬å°†çœ‹åˆ°åˆ†ç»„å’Œèšåˆå‡½æ•°ã€‚ğŸ˜Šï¼Œæˆ‘å®é™…ä¸Šå·²ç»åˆ›å»ºäº†å¤§çº¦å››ä¸ªå…³äº
    Pipar çš„æ•™ç¨‹ï¼Œè¿™åŸºæœ¬ä¸Šæ˜¯ç¬¬ä¸€ä¸ªæ•™ç¨‹ã€‚è¿™åˆæ˜¯æ•°æ®æ¡†çš„ä¸€éƒ¨åˆ†ã€‚
- en: why we should actually use group by aggregate functions again for doing some
    kind of data preprosingã€‚ So let's begin for this particular data for this particular
    problem I created a data which has three features like name departments and salary
    and you have some of the data like Kris data science salaryã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ºä»€ä¹ˆè¦å†æ¬¡ä½¿ç”¨åˆ†ç»„èšåˆå‡½æ•°è¿›è¡ŒæŸç§æ•°æ®é¢„å¤„ç†ã€‚è®©æˆ‘ä»¬å¼€å§‹å¤„ç†è¿™ä¸ªç‰¹å®šçš„æ•°æ®ï¼Œä¸ºè¿™ä¸ªç‰¹å®šçš„é—®é¢˜æˆ‘åˆ›å»ºäº†ä¸€äº›å…·æœ‰ä¸‰ä¸ªç‰¹å¾çš„æ•°æ®ï¼Œæ¯”å¦‚åç§°ã€éƒ¨é—¨å’Œå·¥èµ„ï¼Œä½ æœ‰ä¸€äº›æ•°æ®ï¼Œæ¯”å¦‚
    Kris æ•°æ®ç§‘å­¦çš„å·¥èµ„ã€‚
- en: rightï¼Œ something like thisã€‚ So over here in shortã€‚ if I want to basically understand
    about this particular data they are some departments probably where Krisish and
    other people teach and based on different different departmentsã€‚ they get a different
    different salaryï¼Œ So let's see how we can perform different different group by
    an aggregate functions and see how we can preproces or how we can get some or
    retrieve some kind of results from this particular dataã€‚ So to begin with what
    we are going to do we are a first of all going to import Piparã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ï¼Œç±»ä¼¼è¿™æ ·çš„å†…å®¹ã€‚å› æ­¤åœ¨è¿™é‡Œç®€è€Œè¨€ä¹‹ã€‚å¦‚æœæˆ‘æƒ³åŸºæœ¬äº†è§£è¿™ä¸ªç‰¹å®šæ•°æ®ï¼Œå¯èƒ½ä¼šæœ‰ä¸€äº›éƒ¨é—¨ï¼Œå…¶ä¸­ Kris å’Œå…¶ä»–äººæˆè¯¾ï¼ŒåŸºäºä¸åŒçš„éƒ¨é—¨ï¼Œä»–ä»¬è·å¾—ä¸åŒçš„å·¥èµ„ã€‚æ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ‰§è¡Œä¸åŒçš„åˆ†ç»„å’Œèšåˆå‡½æ•°ï¼Œä»¥åŠæˆ‘ä»¬å¦‚ä½•è¿›è¡Œé¢„å¤„ç†æˆ–è·å–ä¸€äº›ä»è¿™ä¸ªç‰¹å®šæ•°æ®ä¸­æ£€ç´¢çš„ç»“æœã€‚é¦–å…ˆæˆ‘ä»¬è¦åšçš„å°±æ˜¯å¯¼å…¥
    Piparã€‚
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1babe07f0737b77a8ca240e4a3c70599_3.png)'
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1babe07f0737b77a8ca240e4a3c70599_4.png)'
- en: SQL importã€‚Spark sessionï¼Œ as usualï¼Œ we have to create a spark sessionã€‚ So after
    thisã€‚ what we have to doï¼Œ I'll create a spark variableã€‚ So I'll use spark sessionï¼Œ
    dot builder dotã€‚Ap nameï¼Œ I think everybody must be familiar with thisã€‚ but againï¼Œ
    I'm trying to show you this oneã€‚ So let me write it as aggregateã€‚Dotã€‚Get or createã€‚
    So now I've actually created a spark sessionã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: SQL å¯¼å…¥ã€‚Spark ä¼šè¯ï¼Œå’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª Spark ä¼šè¯ã€‚é‚£ä¹ˆåœ¨è¿™ä¹‹åï¼Œæˆ‘ä»¬è¦åšä»€ä¹ˆå‘¢ï¼Ÿæˆ‘å°†åˆ›å»ºä¸€ä¸ª Spark å˜é‡ã€‚æ‰€ä»¥æˆ‘ä¼šä½¿ç”¨
    Spark ä¼šè¯ï¼Œç‚¹æ„å»ºå™¨ç‚¹ã€‚åº”ç”¨åç§°ï¼Œæˆ‘æƒ³å¤§å®¶ä¸€å®šå¯¹æ­¤å¾ˆç†Ÿæ‚‰ã€‚ä½†æˆ‘å†è¯•ç€ç»™ä½ å±•ç¤ºä¸€ä¸‹ã€‚æ‰€ä»¥è®©æˆ‘æŠŠå®ƒå†™ä¸º aggregateã€‚ç‚¹ã€‚è·å–æˆ–åˆ›å»ºã€‚æ‰€ä»¥ç°åœ¨æˆ‘å®é™…ä¸Šå·²ç»åˆ›å»ºäº†ä¸€ä¸ª
    Spark ä¼šè¯ã€‚
- en: Okayï¼Œ probably this will take some time now if I go and check out my spark variableã€‚
    so here is your entire information okayã€‚With respect to this particular spark
    very wellã€‚ Nowã€‚ let's go ahead and try to read the data setã€‚ Nowï¼Œ I will just
    write D F underscore pi sparkã€‚And then here I'll write Sp dot readã€‚Dot CSvï¼Œ the
    CV file name is basically testã€‚3 dot Csvã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œå¦‚æœæˆ‘å»æ£€æŸ¥æˆ‘çš„ Spark å˜é‡ï¼Œè¿™å¯èƒ½ä¼šèŠ±ä¸€äº›æ—¶é—´ã€‚æ‰€ä»¥è¿™é‡Œæ˜¯ä½ æ‰€æœ‰çš„ä¿¡æ¯ã€‚å…³äºè¿™ä¸ªç‰¹å®šçš„ Spark å˜é‡ã€‚ç°åœ¨ã€‚è®©æˆ‘ä»¬ç»§ç»­å°è¯•è¯»å–æ•°æ®é›†ã€‚ç°åœ¨ï¼Œæˆ‘å°†å†™
    D F ä¸‹åˆ’çº¿ pi sparkã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä¼šå†™ Sp ç‚¹è¯»ã€‚ç‚¹ CSVï¼ŒCSV æ–‡ä»¶ååŸºæœ¬ä¸Šæ˜¯ testã€‚3 ç‚¹ CSVã€‚
- en: And rememberï¼Œ I'll be giving this particular CV file in the Github alsoã€‚ and
    then I'll be using header is equal to trueã€‚Coma infer schema is equal to2ã€‚Nowã€‚
    this is my dear underscoreosscope by sparkã€‚Nowï¼Œ what I'll do in the next statementã€‚
    I will write Df underscorecope pipar dot showã€‚Right now here you'll be able to
    see that I am actually being able to see all the data sets here I have nameã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œæˆ‘ä¼šåœ¨ Github ä¸Šæä¾›è¿™ä¸ªç‰¹å®šçš„ CSV æ–‡ä»¶ã€‚ç„¶åæˆ‘ä¼šä½¿ç”¨ header ç­‰äº trueã€‚é€—å·æ¨æ–­æ¨¡å¼ç­‰äº2ã€‚ç°åœ¨ã€‚è¿™æ˜¯æˆ‘çš„ dear ä¸‹åˆ’çº¿
    osscope by sparkã€‚æ¥ä¸‹æ¥æˆ‘å°†åœ¨ä¸‹ä¸€æ¡è¯­å¥ä¸­å†™ Df ä¸‹åˆ’çº¿ cope pipar ç‚¹ showã€‚æ­¤æ—¶ä½ å°†èƒ½å¤Ÿçœ‹åˆ°æˆ‘å®é™…ä¸Šå¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„æ•°æ®é›†ï¼Œè¿™é‡Œæˆ‘æœ‰åç§°ã€‚
- en: departments and salary on all this particular informationã€‚If I really want to
    see the schema or the columns like which all columns where it belongs toã€‚ just
    like a data typesï¼Œ I can definitely use DF underscorecope Iparã€‚Dot print schema
    right and now here you can see name is a string department is string and salary
    is basically an in teacher okayã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: éƒ¨é—¨å’Œå·¥èµ„åœ¨æ‰€æœ‰è¿™äº›ç‰¹å®šä¿¡æ¯ä¸Šã€‚å¦‚æœæˆ‘çœŸçš„æƒ³æŸ¥çœ‹æ¨¡å¼æˆ–åˆ—ï¼Œä¾‹å¦‚å“ªäº›åˆ—å±äºä»€ä¹ˆã€‚å°±åƒæ•°æ®ç±»å‹ï¼Œæˆ‘å¯ä»¥ä½¿ç”¨ DF ä¸‹åˆ’çº¿ cope Iparã€‚ç‚¹æ‰“å°æ¨¡å¼ï¼Œç°åœ¨ä½ å¯ä»¥çœ‹åˆ°åç§°æ˜¯å­—ç¬¦ä¸²ï¼Œéƒ¨é—¨æ˜¯å­—ç¬¦ä¸²ï¼Œå·¥èµ„åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªæ•´æ•°ã€‚
- en: Nowï¼Œ let's perform some group by operationã€‚ Firstï¼Œ we'll start by group by operationã€‚Probably
    I want to group by name and probably try to see what will be the mean average
    salaryã€‚You know what suppose let's let's take a specific example over hereã€‚ So
    I'll write Pf dot underscorecope bypar dot group byã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ‰§è¡Œä¸€äº›åˆ†ç»„æ“ä½œã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä»åˆ†ç»„æ“ä½œå¼€å§‹ã€‚å¯èƒ½æˆ‘æƒ³æŒ‰åç§°åˆ†ç»„ï¼Œå¹¶å°è¯•æŸ¥çœ‹å¹³å‡è–ªæ°´æ˜¯å¤šå°‘ã€‚ä½ çŸ¥é“å—ï¼Œå‡è®¾æˆ‘ä»¬åœ¨è¿™é‡Œæ‹¿ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ã€‚æ‰€ä»¥æˆ‘ä¼šå†™
    Pf dot underscorecope bypar dot group byã€‚
- en: supposeupp I want to go and check who is having the maximum salary out of all
    these people that are present in this particular data setã€‚ So I'll first of all
    group by name if I execute this you can see that we will be getting a return type
    of group data at some specific memory locationã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘æƒ³å»æ£€æŸ¥åœ¨è¿™ä¸ªç‰¹å®šæ•°æ®é›†ä¸­ï¼Œè°çš„è–ªæ°´æ˜¯æœ€é«˜çš„ã€‚æ‰€ä»¥æˆ‘é¦–å…ˆæŒ‰åå­—åˆ†ç»„ã€‚å¦‚æœæˆ‘æ‰§è¡Œè¿™ä¸ªï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªè¿”å›ç±»å‹ä¸ºç»„æ•°æ®çš„æŸä¸ªç‰¹å®šå†…å­˜ä½ç½®ã€‚
- en: And you should always know that guys group by aggregate functions works togetherã€‚
    That basically limits is first of allï¼Œ we we need to apply a group by functionalityã€‚
    and then we need to apply an aggregate functionã€‚ So aggregate function here really
    want to check just press dot and press tab So here you'll be able to see a lot
    of different different function examples like aggregate average count max mean
    pi and many mode right now what I'm going to do I'm just going to use this dot
    sum because I really need to find which is the maximum salaryã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åº”è¯¥å§‹ç»ˆçŸ¥é“ï¼Œä¼™è®¡ä»¬ï¼Œgroup by èšåˆå‡½æ•°æ˜¯ä¸€èµ·å·¥ä½œçš„ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åº”ç”¨ group by åŠŸèƒ½ã€‚ç„¶åæˆ‘ä»¬éœ€è¦åº”ç”¨èšåˆå‡½æ•°ã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œèšåˆå‡½æ•°æˆ‘çœŸçš„æƒ³è¦æ£€æŸ¥ï¼Œåªéœ€æŒ‰
    dot ç„¶åæŒ‰ tabã€‚åœ¨è¿™é‡Œï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°å¾ˆå¤šä¸åŒçš„å‡½æ•°ç¤ºä¾‹ï¼Œæ¯”å¦‚èšåˆã€å¹³å‡ã€è®¡æ•°ã€æœ€å¤§å€¼ã€å¹³å‡å€¼ã€Ï€ ä»¥åŠå¾ˆå¤šæ¨¡å¼ã€‚ç°åœ¨æˆ‘å°†åšçš„æ˜¯ä½¿ç”¨è¿™ä¸ª dot sumï¼Œå› ä¸ºæˆ‘çœŸçš„éœ€è¦æ‰¾å‡ºå“ªä¸ªæ˜¯æœ€é«˜çš„è–ªæ°´ã€‚
- en: ğŸ˜Šï¼ŒHoweverFrom out of all these particular employeesï¼Œ who is having the maximum
    salaryã€‚ So here I'll say dot sumã€‚ And if I execute itï¼Œ you'll be able to see that
    we are getting a sQL dot data frameã€‚ which has name and sum of salaryã€‚ This is
    very much important as sum of salary because I really want to have the sum of
    the salaryã€‚ rememberï¼Œ we cannot apply sum on the stringã€‚ So that is the reason
    it has not done over hereã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œç„¶è€Œåœ¨æ‰€æœ‰è¿™äº›å‘˜å·¥ä¸­ï¼Œè°çš„è–ªæ°´æ˜¯æœ€é«˜çš„ã€‚æ‰€ä»¥æˆ‘ä¼šè¯´ dot sumã€‚å¦‚æœæˆ‘æ‰§è¡Œå®ƒï¼Œä½ å°†èƒ½çœ‹åˆ°æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ª sQL dot data frameã€‚é‡Œé¢æœ‰å§“åå’Œè–ªæ°´çš„æ€»å’Œã€‚è¿™éå¸¸é‡è¦ï¼Œå› ä¸ºæˆ‘çœŸçš„æƒ³è¦è–ªæ°´çš„æ€»å’Œã€‚è®°ä½ï¼Œæˆ‘ä»¬ä¸èƒ½å¯¹å­—ç¬¦ä¸²åº”ç”¨
    sumã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒåœ¨è¿™é‡Œæ²¡æœ‰æ‰§è¡Œçš„åŸå› ã€‚
- en: it is just giving you the name because we have group by nameã€‚ And this dot sum
    will just get applied on this particular salaryã€‚ Nowã€‚ if I go and write dot show
    here you will be able to seeã€‚ğŸ˜Šã€‚Sudanhu over here is having the highest salary
    of 35000ã€‚ Sunny has 12000ã€‚ Krissh has 19000ã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåªæ˜¯ç»™ä½ åå­—ï¼Œå› ä¸ºæˆ‘ä»¬æŒ‰åå­—åˆ†ç»„ã€‚è¿™ä¸ª dot sum å°†åªåº”ç”¨äºè¿™ä¸ªç‰¹å®šçš„è–ªæ°´ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘å»å†™ dot showï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ã€‚ğŸ˜ŠSudanhu
    åœ¨è¿™é‡Œçš„è–ªæ°´æ˜¯æœ€é«˜çš„ 35000ã€‚Sunny æœ‰ 12000ã€‚Krissh æœ‰ 19000ã€‚
- en: Mahesh has 7000ã€‚ So if you go and see over hereï¼Œ Sudanhu is basically present
    hereã€‚ here and in big dataã€‚ So overallï¼Œ his salary should be 35000 if you compute
    it Similarlylyã€‚ you can go and compute my salary over hereã€‚ğŸ¤§Over here by just
    calculating thisã€‚ and then you can also compute sunny salaryã€‚ and you can also
    see my Hã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Mahesh çš„è–ªæ°´æ˜¯ 7000ã€‚æ‰€ä»¥å¦‚æœä½ å»çœ‹è¿™é‡Œï¼ŒSudanhu åŸºæœ¬ä¸Šåœ¨è¿™é‡Œã€‚åœ¨å¤§æ•°æ®ä¸­ã€‚æ‰€ä»¥å¦‚æœä½ è®¡ç®—ï¼Œæ€»ä½“ä»–çš„è–ªæ°´åº”è¯¥æ˜¯ 35000ã€‚ç±»ä¼¼åœ°ï¼Œä½ å¯ä»¥è®¡ç®—æˆ‘åœ¨è¿™é‡Œçš„è–ªæ°´ã€‚ğŸ¤§åœ¨è¿™é‡Œé€šè¿‡ç®€å•è®¡ç®—è¿™ä¸€ç‚¹ã€‚ä½ è¿˜å¯ä»¥è®¡ç®—
    Sunny çš„è–ªæ°´ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹åˆ°æˆ‘çš„ Hã€‚
- en: So this is one just an exampleã€‚ So here I'll just writeã€‚ we have groupedã€‚Do
    fineã€‚The maximum salaryã€‚AndDefinite over here from this entire observationã€‚ we
    can retrieve that Sudanhi is having the highest salaryã€‚ Okayï¼Œ now let's go to
    one step aheadã€‚ one more step aheadã€‚ now we will try to group by departments to
    find out which department gives maximum salary Okayã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™åªæ˜¯ä¸€ä¸ªä¾‹å­ã€‚åœ¨è¿™é‡Œæˆ‘ä¼šå†™ä¸€äº›å†…å®¹ã€‚æˆ‘ä»¬å·²ç»è¿›è¡Œäº†åˆ†ç»„ã€‚åšå¾—å¾ˆå¥½ã€‚æœ€é«˜è–ªæ°´ã€‚å¹¶ä¸”åœ¨æ•´ä¸ªè§‚å¯Ÿä¸­å¯ä»¥ç¡®å®šã€‚æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼ŒSudanhi çš„è–ªæ°´æ˜¯æœ€é«˜çš„ã€‚å¥½å§ï¼Œç°åœ¨è®©æˆ‘ä»¬å‘å‰è¿ˆä¸€æ­¥ã€‚å†å‘å‰ä¸€æ­¥ã€‚ç°åœ¨æˆ‘ä»¬å°†å°è¯•æŒ‰éƒ¨é—¨åˆ†ç»„ï¼Œä»¥æ‰¾å‡ºå“ªä¸ªéƒ¨é—¨æä¾›æœ€é«˜è–ªæ°´ã€‚å¥½çš„ã€‚
- en: we are going to do a group byã€‚Departmentsã€‚Which gives maximum salaryã€‚ Suppose
    this is myã€‚This is my requirementã€‚ Okayï¼Œ and different different types of requirement
    makeup upã€‚ I'm just trying to show you some examplesã€‚ So I'm just going to copy
    thisã€‚å— going doã€‚Use this departmentã€‚Okayï¼Œ and then I'm basically going to say
    dot sum dot showã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿›è¡Œä¸€ä¸ªæŒ‰éƒ¨é—¨åˆ†ç»„çš„æ“ä½œã€‚å“ªä¸ªéƒ¨é—¨æä¾›æœ€é«˜è–ªæ°´ã€‚å‡è®¾è¿™æ˜¯æˆ‘çš„ã€‚è¿™ä¸ªæ˜¯æˆ‘çš„éœ€æ±‚ã€‚å¥½çš„ï¼Œå’Œä¸åŒçš„éœ€æ±‚ç»„åˆåœ¨ä¸€èµ·ã€‚æˆ‘åªæ˜¯æƒ³ç»™ä½ å±•ç¤ºä¸€äº›ä¾‹å­ã€‚æ‰€ä»¥æˆ‘å°†å¤åˆ¶è¿™ä¸ªã€‚å—å°†ä¼šåšã€‚ä½¿ç”¨è¿™ä¸ªéƒ¨é—¨ã€‚å¥½çš„ï¼Œç„¶åæˆ‘åŸºæœ¬ä¸Šå°†è¯´
    dot sum dot showã€‚
- en: If I execute it let me see department is a wrong column name so I'll write department
    it is department So let me write S now if I go and see Iot over here gives some
    salary around115000 to this employees to all the employees right combined because
    we are doing the sum big data gives somewhere around 15000 data science gifts
    Im around 4300 Now suppose if I go and see big data over here 404080008000 and
    13000ã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘æ‰§è¡Œå®ƒï¼Œè®©æˆ‘çœ‹çœ‹ï¼Œéƒ¨é—¨æ˜¯ä¸€ä¸ªé”™è¯¯çš„åˆ—åï¼Œæ‰€ä»¥æˆ‘ä¼šå†™éƒ¨é—¨ï¼Œå®ƒæ˜¯éƒ¨é—¨ã€‚æ‰€ä»¥è®©æˆ‘ç°åœ¨å†™ Sã€‚å¦‚æœæˆ‘å»çœ‹çœ‹ï¼ŒIOT åœ¨è¿™é‡Œç»™è¿™æ‰€æœ‰å‘˜å·¥çš„è–ªèµ„å¤§çº¦æ˜¯ 115000ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è¿›è¡Œæ€»å’Œï¼Œå¤§æ•°æ®ç»™çš„è–ªèµ„å¤§çº¦æ˜¯
    15000ï¼Œæ•°æ®ç§‘å­¦çš„è–ªèµ„æ˜¯ 4300ã€‚ç°åœ¨å‡è®¾æˆ‘å»çœ‹çœ‹å¤§æ•°æ®è¿™é‡Œæ˜¯ 404080008000 å’Œ 13000ã€‚
- en: 130015000 so I hope I'm getting yesï¼Œ big data is actually giving us 15000 so
    you can go and calculate it suppose if you want to find out the mean you can also
    find out the mean okayã€‚ so let me just write it over hereï¼Œ just copy this entire
    thing paste it over here and write me write instead of instead of sum I'll write
    to write mean so by default the mean salaryã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 130015000ï¼Œæ‰€ä»¥æˆ‘å¸Œæœ›æˆ‘å¾—åˆ°çš„ç­”æ¡ˆæ˜¯ï¼Œæ˜¯çš„ï¼Œå¤§æ•°æ®å®é™…ä¸Šç»™æˆ‘ä»¬ 15000ï¼Œæ‰€ä»¥ä½ å¯ä»¥å»è®¡ç®—ï¼Œå‡è®¾ä½ æƒ³æ‰¾å‡ºå¹³å‡å€¼ï¼Œä½ ä¹Ÿå¯ä»¥æ‰¾åˆ°å¹³å‡å€¼ã€‚å¥½å§ï¼Œè®©æˆ‘åœ¨è¿™é‡Œå†™ï¼Œåªéœ€å¤åˆ¶è¿™ä¸ªæ•´ä½“å†…å®¹ï¼Œç²˜è´´åœ¨è¿™é‡Œï¼Œå†™æˆ‘ï¼Œå†™è€Œä¸æ˜¯æ€»å’Œï¼Œæˆ‘ä¼šå†™å¹³å‡å€¼ï¼Œæ‰€ä»¥é»˜è®¤çš„å¹³å‡è–ªèµ„ã€‚
- en: Here you can see that for a particular employee somewhere for I O T to 7500ã€‚
    because this mean will be based on how many number of people are working in the
    departmentï¼Œ rightã€‚ So like thisï¼Œ you can actually find out Nowï¼Œ I can also check
    one more thingã€‚ guysï¼Œ I can copy thisã€‚ I can try to find out how many number ofã€‚Employees
    are actually working based on the departmentã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºæŸä¸ªç‰¹å®šå‘˜å·¥ï¼ŒI O T çš„è–ªèµ„å¤§çº¦æ˜¯ 7500ã€‚å› ä¸ºè¿™ä¸ªå¹³å‡å€¼å°†åŸºäºåœ¨è¯¥éƒ¨é—¨å·¥ä½œçš„äººå‘˜æ•°é‡ï¼Œå¯¹å§ã€‚æ‰€ä»¥è¿™æ ·ä½ å®é™…ä¸Šå¯ä»¥æ‰¾åˆ°ã€‚ç°åœ¨ï¼Œæˆ‘è¿˜å¯ä»¥æ£€æŸ¥ä¸€ä»¶äº‹ã€‚ä¼™è®¡ä»¬ï¼Œæˆ‘å¯ä»¥å¤åˆ¶è¿™ä¸ªã€‚æˆ‘å¯ä»¥å°è¯•æ‰¾å‡ºæœ‰å¤šå°‘å‘˜å·¥å®é™…ä¸Šæ˜¯åŸºäºéƒ¨é—¨å·¥ä½œçš„ã€‚
- en: so I can use dot countã€‚ And then if I go and execute thisï¼Œ probably this is
    a methodã€‚Okayã€‚Now here you will be seeing that in Io there are two people in big
    data there are four people in data science they are four peopleã€‚ so4 plus 4 plus8
    total employees that are present over here is basically 10ã€‚Nowã€‚ one more way that
    I can basically apply a directly aggregate function also to seeã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å¯ä»¥ä½¿ç”¨ dot countã€‚å¦‚æœæˆ‘å»æ‰§è¡Œè¿™ä¸ªï¼Œå¯èƒ½è¿™å°±æ˜¯ä¸€ä¸ªæ–¹æ³•ã€‚å¥½çš„ã€‚ç°åœ¨ä½ ä¼šçœ‹åˆ°åœ¨ I O ä¸­æœ‰ä¸¤ä¸ªäººï¼Œåœ¨å¤§æ•°æ®ä¸­æœ‰å››ä¸ªäººï¼Œåœ¨æ•°æ®ç§‘å­¦ä¸­ä¹Ÿæœ‰å››ä¸ªäººã€‚æ‰€ä»¥
    4 åŠ  4 åŠ  8ï¼Œæ€»å…±æœ‰çš„å‘˜å·¥åœ¨è¿™é‡ŒåŸºæœ¬ä¸Šæ˜¯ 10ã€‚ç°åœ¨ï¼Œæˆ‘è¿˜å¯ä»¥ç›´æ¥åº”ç”¨èšåˆå‡½æ•°æ¥æŸ¥çœ‹ã€‚
- en: these are all some of the examples and againï¼Œ you can do different different
    group by let me use Df Pparã€‚ suppose I say dot aggregate okayï¼Œ and inside this
    I will just give my key value pairs like thisã€‚ suppose I say let me say that salaryï¼Œ
    I want to find out the sum of the salariesã€‚The overall salary that is basically
    given to the entire total expenditure insertã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›éƒ½æ˜¯ä¸€äº›ç¤ºä¾‹ï¼Œå†æ¬¡å¼ºè°ƒï¼Œä½ å¯ä»¥é€šè¿‡è®©æˆ‘ä½¿ç”¨ Df Ppar è¿›è¡Œä¸åŒçš„åˆ†ç»„ã€‚å‡è®¾æˆ‘è¯´ dot aggregateï¼Œå¥½å§ï¼Œåœ¨é‡Œé¢æˆ‘åªéœ€æä¾›æˆ‘çš„é”®å€¼å¯¹ã€‚å‡è®¾æˆ‘è¯´ï¼Œè®©æˆ‘æ‰¾å‡ºå·¥èµ„çš„æ€»å’Œã€‚æˆ‘æƒ³è¦æ‰¾å‡ºæ•´ä½“çš„è–ªèµ„æ€»æ”¯å‡ºã€‚
- en: So the total expenditure that you will be able to see somewhere around 73000
    alrightã€‚ so we can also apply direct aggregate functionï¼Œ otherwise this all are
    also aggregate function which we basically apply after after you know applying
    a group by function now suppose this are probably the salary I want to find out
    suppose I'll take this example I want to find out the maximum salary that the
    person is basically getting who is getting the maximum salary sorryã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å°†çœ‹åˆ°æ€»æ”¯å‡ºå¤§çº¦åœ¨ 73000 å·¦å³ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥åº”ç”¨èšåˆå‡½æ•°ï¼Œæ­¤å¤–ï¼Œè¿™äº›éƒ½æ˜¯åœ¨åº”ç”¨åˆ†ç»„å‡½æ•°åæˆ‘ä»¬åŸºæœ¬ä¸Šåº”ç”¨çš„èšåˆå‡½æ•°ã€‚ç°åœ¨å‡è®¾è¿™äº›å¯èƒ½æ˜¯è–ªèµ„ï¼Œæˆ‘æƒ³è¦æ‰¾å‡ºå‡è®¾æˆ‘ä¸¾è¿™ä¸ªä¾‹å­ï¼Œæˆ‘æƒ³æ‰¾å‡ºè·å¾—æœ€é«˜è–ªèµ„çš„äººçš„è–ªèµ„ï¼ŒæŠ±æ­‰ã€‚
- en: So here instead of writing dot sum now I'll write max dot show now here you
    can see Sudansha is basically getting 20000 over here10000 Krisish is getting
    10000 my is getting for 4000 right so all this particular data is theyy Kris is
    basically getting with respect to data science over here 10000 so it has basically
    picked up it is not picking up both the records but at least when it is grouping
    by name and then it is showing this particular data that time you will be able
    to see it let's see whether Ill be also able to see this or notã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡Œï¼Œæˆ‘å°†å†™ max dot showï¼Œè€Œä¸æ˜¯ dot sumã€‚ç°åœ¨ä½ å¯ä»¥çœ‹åˆ° Sudansha åœ¨è¿™é‡Œè·å¾— 20000ï¼ŒKrisish è·å¾— 10000ï¼Œæˆ‘è·å¾—
    4000ï¼Œå¯¹å§ã€‚æ‰€ä»¥æ‰€æœ‰è¿™äº›ç‰¹å®šæ•°æ®æ˜¯ Kris åœ¨æ•°æ®ç§‘å­¦ä¸­è·å¾—çš„è–ªèµ„ä¸º 10000ï¼Œæ‰€ä»¥å®ƒåŸºæœ¬ä¸ŠæŒ‘é€‰äº†ï¼Œå¹¶æ²¡æœ‰é€‰æ‹©ä¸¤ä¸ªè®°å½•ï¼Œä½†è‡³å°‘å½“å®ƒæŒ‰åç§°åˆ†ç»„å¹¶æ˜¾ç¤ºè¿™ä¸ªç‰¹å®šæ•°æ®æ—¶ï¼Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘æ˜¯å¦ä¹Ÿèƒ½çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚
- en: So group byï¼Œ if I score and write minã€‚So here you will be able to see minimum
    value with respect to different different records when Im grouping by here you
    will be able to see that Suanhu sorryã€‚ Sudanhu is getting a minimum salary of
    50002000 Kris is getting a minimum salary of 4000 rightã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åˆ†ç»„ï¼Œå¦‚æœæˆ‘è¯„åˆ†å¹¶å†™ä¸‹æœ€å°å€¼ã€‚è¿™é‡Œä½ å°†èƒ½å¤Ÿçœ‹åˆ°ä¸åŒè®°å½•ä¸‹çš„æœ€å°å€¼ã€‚å½“æˆ‘åˆ†ç»„æ—¶ï¼Œä½ å°†çœ‹åˆ°Suanhuçš„æœ€ä½è–ªèµ„æ˜¯5000ï¼Œè€ŒKrisçš„æœ€ä½è–ªèµ„æ˜¯4000ã€‚
- en: we can also get that particular informationã€‚ Now let's see what all different
    different types of operation are thereã€‚Average is also thereã€‚ So if I write A
    V Gï¼Œ it's just like mean only guysã€‚ So this is basically the mean salary that
    probably againã€‚Againã€‚ you can check out different different functionalities why
    these all things are basically requiredã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥è·å–é‚£ä¸ªç‰¹å®šçš„ä¿¡æ¯ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æœ‰å“ªäº›ä¸åŒç±»å‹çš„æ“ä½œã€‚å¹³å‡å€¼ä¹Ÿåœ¨å…¶ä¸­ã€‚æ‰€ä»¥å¦‚æœæˆ‘å†™AVGï¼Œè¿™å°±å’Œå¹³å‡æ•°ä¸€æ ·ã€‚åŸºæœ¬ä¸Šè¿™æ˜¯å¯èƒ½çš„å¹³å‡è–ªèµ„ã€‚ä½ å¯ä»¥æŸ¥çœ‹è¿™äº›åŠŸèƒ½ï¼Œäº†è§£è¿™äº›æ“ä½œçš„å¿…è¦æ€§ã€‚
- en: Under one thing is that you really need to do a lot of data preprosing a lot
    of retrieving skills that you basically doã€‚ You can check it out this one and
    you can do different different functionalities as you likeã€‚ So I hope you like
    this particular video Probably in the next video I'm going to start with spark
    Mlib libraries where we'll be solving some machine learning algorithm problemsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä»¶é‡è¦çš„äº‹æƒ…æ˜¯ï¼Œä½ ç¡®å®éœ€è¦è¿›è¡Œå¤§é‡çš„æ•°æ®é¢„å¤„ç†å’Œæ£€ç´¢æŠ€èƒ½ã€‚ä½ å¯ä»¥æŸ¥çœ‹è¿™ä¸ªï¼Œå¹¶æ ¹æ®è‡ªå·±çš„éœ€è¦æ‰§è¡Œä¸åŒçš„åŠŸèƒ½ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªç‰¹å®šçš„è§†é¢‘ã€‚å¯èƒ½åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å¼€å§‹ä»‹ç»Spark
    Mlibåº“ï¼Œæˆ‘ä»¬å°†è§£å†³ä¸€äº›æœºå™¨å­¦ä¹ ç®—æ³•é—®é¢˜ã€‚
- en: '![](img/1babe07f0737b77a8ca240e4a3c70599_6.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1babe07f0737b77a8ca240e4a3c70599_6.png)'
- en: So I hope you like this particular video I'll see you all in the next weekã€‚
    Have a great day thank you babaã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªç‰¹å®šçš„è§†é¢‘ï¼Œä¸‹å‘¨è§ã€‚ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼Œè°¢è°¢ã€‚
