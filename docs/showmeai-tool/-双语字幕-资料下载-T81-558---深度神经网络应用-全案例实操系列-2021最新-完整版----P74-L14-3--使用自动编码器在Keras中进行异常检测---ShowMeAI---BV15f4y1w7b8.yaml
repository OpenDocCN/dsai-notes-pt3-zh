- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P74：L14.3- 使用自动编码器在Keras中进行异常检测
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P74：L14.3- 使用自动编码器在Keras中进行异常检测
    - ShowMeAI - BV15f4y1w7b8
- en: Hi， this is Jeff Heaton。 Wecom to applications of deep neural networks with
    Washington University。 In this video， we're going to look at anomaly detection。
    How can you detect something that is not the way it should be。This has great application
    in computer security， but in other fields as well。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是杰夫·希顿。欢迎来到华盛顿大学的深度神经网络应用。在这个视频中，我们将讨论异常检测。你如何检测不符合预期的情况。这在计算机安全方面有很大的应用，但在其他领域也一样。
- en: We'll have a look at that in this video for the latest on my AI course and projects。
    click subscribe and the bell next to it to be notified of every new video。 So
    now let's look at a use of autoencors。 We're going to see how an autoencor can
    be applied to anomaly detection。 I have a link to a couple of other tutorials
    on the internet that talk about various ways to do anomaly detection in Kes。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这个视频中查看它，获取我AI课程和项目的最新动态。点击订阅并点击旁边的铃铛，以便接收每个新视频的通知。所以现在让我们看看自动编码器的用法。我们将看到如何将自动编码器应用于异常检测。我有几个关于在Keras中进行异常检测的其他教程的链接。
- en: Some of these might be useful to you。 The approach that I'm using here is using
    an autoencor and looking at the error of the autoencor to determine if the data
    are unusual compared to the previous data that we've seen。 We're going to make
    use of something called the KDd99 data set。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些可能对你有用。我在这里使用的方法是使用自动编码器，并查看自动编码器的误差，以确定数据与我们之前看到的数据相比是否异常。我们将利用一个叫做KDd99数据集的东西。
- en: We'll use this in two parts of this course。 We'll use it to create an intrusion
    detection system in the next part。 This is an older dataset at 2019。😊。![](img/231301739b63fc07324b14a0fb6dafd4_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本课程的两个部分中使用它。我们将在下一部分创建一个入侵检测系统。这是2019年的一个旧数据集。😊。![](img/231301739b63fc07324b14a0fb6dafd4_1.png)
- en: is now going on 20 years old。 So this is this is an older security data。 It's
    got enough columns and whatnot that it is useful。 I don't know that I would base
    anything on current research。 meaning trying to create systems that detect current
    intrusion detections or current anomaly detection based on 20 year old data。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经快20年了。所以这是一个较旧的安全数据。它有足够的列和其他内容，使其有用。我不知道我是否会基于当前的研究，意味着试图创建基于20年旧数据的当前入侵检测或异常检测系统。
- en: but it is a good sort of hello world for security， and it's not trivial。 It's
    a decent amount。 It's not big data by any stretch of the imagination， but it's
    useful。 So we'll see it here。 It's good for examples。 I wouldn't use it for current
    research。 That means said I see papers published with it frequently， but of of
    varying quality。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但这对于安全来说是一个不错的“你好，世界”，而且它并不简单。这是相当可观的。绝对不是所谓的大数据，但它很有用。所以我们在这里会看到它。这对示例来说很好。我不会把它用于当前研究。话虽如此，我看到有论文频繁使用它，但质量各异。
- en: I don't include it with the Github repository because it's decently large。 but
    this command here will allow you to download it I'll go ahead and run this。 it
    lets you know where you download it to fearing coab。 You may need to put it on
    your。riive somewhere I'll try to put specific instructions for coabab in here。
    So now we've got the data。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有把它包含在Github仓库中，因为它相对较大。不过这个命令可以让你下载它，我会先运行这个。它让你知道下载到哪里，担心coab。你可能需要把它放在你的某个驱动器上。我会尽量在这里提供具体的coabab指令。所以现在我们得到了数据。
- en: And I displayed the first five rows。 You can see what this looks like。 This
    is network type data。 This was created in a simulated environment for a competition
    K kind of an early tagle and doesn't show all the data。 There's quite quite a
    bit of it。 But what I am going to do is let's take this data and grouped by the
    outcome。 So these are the outcomes buffer overflow FTP right guess password。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我展示了前五行。你可以看到这是什么样的。这是网络类型数据。这是在一个模拟环境中为一个比赛创建的K种早期标签，并没有显示所有数据。其实还有相当多。但我将要做的是将这些数据按结果分组。所以这些结果包括缓冲区溢出、FTP、正确猜测密码。
- en: Those are all different types of attacks that were simulated in this。 Some of
    these are still attack types today。 Some of these are probably pretty uncommon
    20 years later。 definitely be be aware of that normal is one we're particularly
    interested in because that means nothing is happening。 So we're going to train
    it that the normal or well normal and the others are the anomalies。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是在这个过程中模拟的不同类型的攻击。其中一些在今天仍然是攻击类型。有些在20年后可能已经相当罕见。我们特别关注的正常数据意味着没有任何事情发生。因此，我们将训练它，将正常数据视为正常，将其他数据视为异常。
- en: So we're going to train a neural network to detect。Things that are not like
    normal。 We're going to do this completely with a autoencoder。 I create two functions
    to help us preproces this， one that encodes the z scores and one that encodes
    dummy variables。 and this is my preprocessing form。 You can see there's a lot
    of columns here。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们将训练一个神经网络来检测那些不像正常的数据。我们将完全通过自编码器来实现这一点。我创建了两个函数来帮助我们预处理，一个用于编码z分数，一个用于编码虚拟变量。这是我的预处理表单。你可以看到这里有很多列。
- en: and I'm encoding basically in Z scores and dummies。 Those are the only two transformation
    types that I'm doing So I'm keeping things relatively simple。 and we drop any
    Ns。 rows that have Ns。 There's not really that many。 and you can see the rows
    here。 You can clearly see the effects of the Z scores。 Now。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我基本上在编码z分数和虚拟变量。这是我仅进行的两种转换类型，所以我保持事情相对简单。我们去掉任何包含NaN的行。包含NaN的行并不多。你可以看到这些行。你可以清楚地看到z分数的影响。
- en: what we're going to do is create a mask that has the normal and the attacks。
    that way we're able to segregate this data。 We're going to drop the outcome because
    we're not really training on the outcome。 that's essentially the target。 really，
    this is unsupervised learning once you get it separated into into these two groups。
    such as the nature of autoenderrs。 We'll go ahead and run that。 and you can see。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的是创建一个包含正常和攻击的掩码。这样我们能够将这些数据隔离开来。我们将去掉结果，因为我们并不是真的在结果上训练。这本质上是无监督学习，一旦你将数据分成这两个组。这样的自编码器的性质。我们将继续运行它，你可以看到。
- en: Normal counts about 97 k attacks are much more common in this dataset set。 We
    separate it out so that we have the x for the attack and the x4 normal and then
    we're going to break this into a train test split we're breaking normal up is
    we're going to use normal to evaluate it。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正常计数大约是97K，攻击在这个数据集中更为常见。我们将其分开，以便我们拥有攻击的x和正常的x，然后我们将把这分成训练测试集，我们将使用正常数据来评估它。
- en: we're going to see if the normal looks like normal data to it9 anomaly Now we're
    going to use an autoencoder for this and we've talked about autoencors before。
    but just so these videos somewhat stand alone just to give you a quick overview
    of this。 an autoencoder is essentially a neural network that has sort of a skinny
    hidden layer structure。 the idea is you have a number of inputs now you're going
    to have all the Kdv99 inputs for this particular one you do have the bias neurons
    like you do in most networks and you have an output count equal to the input count。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要看看正常数据在它看来是否像正常数据，接下来我们将使用自编码器来完成这一点，我们之前讨论过自编码器。但为了让这些视频能够相对独立，我给你快速概述一下。自编码器本质上是一个具有“瘦”隐藏层结构的神经网络。它的想法是你有多个输入，对于这个特定的自编码器，你将拥有所有KDD99的输入，像大多数网络一样，你有偏置神经元，输出数量等于输入数量。
- en: and what we're going to do is basically train the auto encoder so that。It is
    able to produce the same input as output Now that seems useless。 but that is teaching
    it essentially to do feature reduction and simplification so it teaches it to
    take all of these inputs。 these five inputs are 100 as we will have probably with
    KDD99 and represents them as just the two numbers being output to the hidden one
    and hidden2 Now all the weights leading into here are the encoding weights and
    these are the decoding weights so those are what it learns。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的基本上是训练自编码器，使其能够生成相同的输入作为输出。现在这似乎没什么用，但这本质上是在教它进行特征减少和简化，因此它教会它将所有这些输入，这五个输入是100，因为我们将可能使用KDD99，将其表示为输出到隐藏层1和隐藏层2的两个数字。现在，所有进入这里的权重都是编码权重，这些是解码权重，因此这些是它所学习的。
- en: For how to decompress it Here， we're going to build our autoencoder。 We are
    going to have a little more complicated autoencoder than here。 So we're going
    to have essentially 25，25，3。 We still have this very thinning area but we have
    a little bit of sort of an hourglass。 So it's almost like we have three hidden
    layers here to actually give us our compression capabilities。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将构建我们的自编码器。我们的自编码器将比这里更复杂。因此，我们将基本上有25，25，3。我们仍然有这个非常细的区域，但有点像沙漏的形状。所以这里几乎有三个隐藏层，实际上为我们提供压缩能力。
- en: So I'm going to go ahead and run this。 It will actually fit it。 So it's going
    to take it a little bit to fit this neural network。 I will fast forward this part。
    Okay， it's trained just to explain sort of the theory of what's going on here。
    We trained this just on the normal data。 and it is being trained un superupervised。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我将继续运行这个程序。它实际上会适应这个神经网络。所以它需要一点时间来适应。我会快进这部分。好的，它训练完了，主要是为了阐述这里发生的理论。我们只在正常数据上进行训练，并且是无监督训练。
- en: So we're not even giving it the outcomes。 There'd be no point to give it the
    outcomes because they're all normal。 So the outcome would be the same。 Since it's
    learning to compress to reduce the dimensions。 the way the dimension reduction
    or compression in general works。By using patterns to represent common portions
    of the data。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们甚至不提供结果。给出结果是没有意义的，因为它们都是正常的。因此，结果会是一样的。由于它正在学习压缩以减少维度。维度减少或压缩的工作方式就是通过使用模式来表示数据的常见部分。
- en: So it's simplifying it that will only work on cases where the data coming in
    is pretty similar to that。 Now， I'll give you a perfect example of a unintended
    anomaly detector。 Now。 cell phones are a lot better about this。 but earlier cell
    phones。 the way that they would compress is they knew a lot about the human voice
    that would normally go through there so they used the ranges that the human voice
    was normally in。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它在简化，只有在输入数据与之非常相似的情况下才能工作。现在，我将给你一个意外的异常检测器的完美例子。现在，手机在这方面做得好多了，但早期的手机。它们压缩的方式是因为它们对人声的特性了解很多，因此使用了人声通常在的音域。
- en: they only compressed it and degraded quality in such a way so that it would
    not be annoying for human voices you'd still recognize the voice you would still
    be able to understand it。 However， if you tried to play music through a cell phone
    or other other tones that the compression algorithms simply were not designed
    for。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它们只是压缩了数据，并以一种不会让人类声音感到烦恼的方式降低了质量，你仍然可以识别声音，仍然能够理解。然而，如果你尝试通过手机播放音乐或其他压缩算法根本不适合的音调，那就不行了。
- en: they would not be reproduced as well。 there would be static and other distortions
    in that。Becauseuse those different tones other than what the compression algorithms
    were built for are different。 They're anomalies。 and the cell phone detected the
    anomaly。 Not rather designed for。 It's just an example， but it detected the anomaly
    by distorting it。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的重现效果不会很好。会有静电和其他失真。因为使用这些与压缩算法构建时不同的音调就是不同的。它们是异常。而手机则检测到了这种异常。并不是特别设计的。这只是一个例子，但它通过失真来检测异常。
- en: That's what we're going to see here。 We'll put data into the input and look
    at how similar the data is in the output to the input。 because the autoencor is
    meant to be a straight pass through， but it compresses in the process。 So it compresses
    and then expands。 and we want to make sure that we're not seen too much distortion
    in that process。 because if we are， then the data coming in are probably different。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们将在这里看到的内容。我们将数据输入，并查看输出数据与输入数据的相似程度。因为自编码器是为了直接传递而设计，但在过程中会进行压缩。所以它先压缩再扩展。我们希望确保在这个过程中没有太多的失真。如果有，那么输入的数据可能就是不同的。
- en: then the data that this was originally trained for。 Now we saw earlier in this
    course that you could use chaos statistics and other things to determine if your
    data have changed to the point that your neural network might need to be retrained。
    This is another great way to do this。 Anomaly detection and detecting。If your
    data is sufficiently like the training data to know when to update your neural
    network are all very similar。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最初训练数据的基础。我们在课程早些时候看到，你可以使用混沌统计和其他方法来确定数据是否发生了变化，以至于你的神经网络可能需要重新训练。这是另一种很好的方法。异常检测和识别。如果你的数据与训练数据足够相似，就能知道何时更新你的神经网络。
- en: let's go ahead and run it and do just that test。 So let's run this cell now
    and we'll see the results。 first I'm going to ask it to predict on the normal
    test and then I'm going to score it basically seeing how well these predictions
    lined up to the normal test that it was trained on。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续运行它并进行测试。因此，现在运行这个单元，我们将看到结果。首先，我会让它在正常测试上进行预测，然后我会评分，基本上是查看这些预测与它训练过的正常测试的吻合程度。
- en: so we're literally seen。 So if you look at it here。 the two in sample now the
    ens samplele normal attack。 this is essentially the data that it was trained on。
    So you have to take that with a green assault。 these are normal data that were
    not part of the training set。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们字面上看到了这一点。如果你看看这里，样本中的两个现在的正常攻击。这本质上是它所训练的数据。因此，你必须对这些保持警惕。这些是正常的数据，不在训练集中。
- en: but you can see that the RMSse for both of these two is right around 0。3 notice
    the RMSE is higher for attacks because they are anomalies and these are all pretty
    simple。 We're doing predictions on the X normal test and then we evaluate the
    error based on the same thing。 So we're seeing how well can this。To flow through
    the auto encoder with minimal distortion。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 但是你可以看到这两个的RMSse大约是0.3。注意到攻击的RMSE较高，因为它们是异常，这些都相对简单。我们在X正常测试上进行预测，然后根据相同的内容评估误差。所以我们在看这能否通过自动编码器以最小失真流动。
- en: the more distortion you see， the more likely it's an anomaly this content changes
    often so subscribe to the channel to stay up to date on this course and other
    topics and artificial intelligence。![](img/231301739b63fc07324b14a0fb6dafd4_3.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到的失真越多，越可能是异常。该内容经常变化，所以请订阅频道以保持对该课程和其他人工智能主题的最新了解。![](img/231301739b63fc07324b14a0fb6dafd4_3.png)
