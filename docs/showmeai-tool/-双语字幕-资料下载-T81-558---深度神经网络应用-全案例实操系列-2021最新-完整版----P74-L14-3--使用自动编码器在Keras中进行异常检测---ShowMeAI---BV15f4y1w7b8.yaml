- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P74ï¼šL14.3- ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨åœ¨Kerasä¸­è¿›è¡Œå¼‚å¸¸æ£€æµ‹
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P74ï¼šL14.3- ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨åœ¨Kerasä¸­è¿›è¡Œå¼‚å¸¸æ£€æµ‹
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonã€‚ Wecom to applications of deep neural networks with
    Washington Universityã€‚ In this videoï¼Œ we're going to look at anomaly detectionã€‚
    How can you detect something that is not the way it should beã€‚This has great application
    in computer securityï¼Œ but in other fields as wellã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¼‚å¸¸æ£€æµ‹ã€‚ä½ å¦‚ä½•æ£€æµ‹ä¸ç¬¦åˆé¢„æœŸçš„æƒ…å†µã€‚è¿™åœ¨è®¡ç®—æœºå®‰å…¨æ–¹é¢æœ‰å¾ˆå¤§çš„åº”ç”¨ï¼Œä½†åœ¨å…¶ä»–é¢†åŸŸä¹Ÿä¸€æ ·ã€‚
- en: We'll have a look at that in this video for the latest on my AI course and projectsã€‚
    click subscribe and the bell next to it to be notified of every new videoã€‚ So
    now let's look at a use of autoencorsã€‚ We're going to see how an autoencor can
    be applied to anomaly detectionã€‚ I have a link to a couple of other tutorials
    on the internet that talk about various ways to do anomaly detection in Kesã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨è¿™ä¸ªè§†é¢‘ä¸­æŸ¥çœ‹å®ƒï¼Œè·å–æˆ‘AIè¯¾ç¨‹å’Œé¡¹ç›®çš„æœ€æ–°åŠ¨æ€ã€‚ç‚¹å‡»è®¢é˜…å¹¶ç‚¹å‡»æ—è¾¹çš„é“ƒé“›ï¼Œä»¥ä¾¿æ¥æ”¶æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹è‡ªåŠ¨ç¼–ç å™¨çš„ç”¨æ³•ã€‚æˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†è‡ªåŠ¨ç¼–ç å™¨åº”ç”¨äºå¼‚å¸¸æ£€æµ‹ã€‚æˆ‘æœ‰å‡ ä¸ªå…³äºåœ¨Kerasä¸­è¿›è¡Œå¼‚å¸¸æ£€æµ‹çš„å…¶ä»–æ•™ç¨‹çš„é“¾æ¥ã€‚
- en: Some of these might be useful to youã€‚ The approach that I'm using here is using
    an autoencor and looking at the error of the autoencor to determine if the data
    are unusual compared to the previous data that we've seenã€‚ We're going to make
    use of something called the KDd99 data setã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€äº›å¯èƒ½å¯¹ä½ æœ‰ç”¨ã€‚æˆ‘åœ¨è¿™é‡Œä½¿ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨ï¼Œå¹¶æŸ¥çœ‹è‡ªåŠ¨ç¼–ç å™¨çš„è¯¯å·®ï¼Œä»¥ç¡®å®šæ•°æ®ä¸æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„æ•°æ®ç›¸æ¯”æ˜¯å¦å¼‚å¸¸ã€‚æˆ‘ä»¬å°†åˆ©ç”¨ä¸€ä¸ªå«åšKDd99æ•°æ®é›†çš„ä¸œè¥¿ã€‚
- en: We'll use this in two parts of this courseã€‚ We'll use it to create an intrusion
    detection system in the next partã€‚ This is an older dataset at 2019ã€‚ğŸ˜Šã€‚![](img/231301739b63fc07324b14a0fb6dafd4_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æœ¬è¯¾ç¨‹çš„ä¸¤ä¸ªéƒ¨åˆ†ä¸­ä½¿ç”¨å®ƒã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†åˆ›å»ºä¸€ä¸ªå…¥ä¾µæ£€æµ‹ç³»ç»Ÿã€‚è¿™æ˜¯2019å¹´çš„ä¸€ä¸ªæ—§æ•°æ®é›†ã€‚ğŸ˜Šã€‚![](img/231301739b63fc07324b14a0fb6dafd4_1.png)
- en: is now going on 20 years oldã€‚ So this is this is an older security dataã€‚ It's
    got enough columns and whatnot that it is usefulã€‚ I don't know that I would base
    anything on current researchã€‚ meaning trying to create systems that detect current
    intrusion detections or current anomaly detection based on 20 year old dataã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å·²ç»å¿«20å¹´äº†ã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªè¾ƒæ—§çš„å®‰å…¨æ•°æ®ã€‚å®ƒæœ‰è¶³å¤Ÿçš„åˆ—å’Œå…¶ä»–å†…å®¹ï¼Œä½¿å…¶æœ‰ç”¨ã€‚æˆ‘ä¸çŸ¥é“æˆ‘æ˜¯å¦ä¼šåŸºäºå½“å‰çš„ç ”ç©¶ï¼Œæ„å‘³ç€è¯•å›¾åˆ›å»ºåŸºäº20å¹´æ—§æ•°æ®çš„å½“å‰å…¥ä¾µæ£€æµ‹æˆ–å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿã€‚
- en: but it is a good sort of hello world for securityï¼Œ and it's not trivialã€‚ It's
    a decent amountã€‚ It's not big data by any stretch of the imaginationï¼Œ but it's
    usefulã€‚ So we'll see it hereã€‚ It's good for examplesã€‚ I wouldn't use it for current
    researchã€‚ That means said I see papers published with it frequentlyï¼Œ but of of
    varying qualityã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¯¹äºå®‰å…¨æ¥è¯´æ˜¯ä¸€ä¸ªä¸é”™çš„â€œä½ å¥½ï¼Œä¸–ç•Œâ€ï¼Œè€Œä¸”å®ƒå¹¶ä¸ç®€å•ã€‚è¿™æ˜¯ç›¸å½“å¯è§‚çš„ã€‚ç»å¯¹ä¸æ˜¯æ‰€è°“çš„å¤§æ•°æ®ï¼Œä½†å®ƒå¾ˆæœ‰ç”¨ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œä¼šçœ‹åˆ°å®ƒã€‚è¿™å¯¹ç¤ºä¾‹æ¥è¯´å¾ˆå¥½ã€‚æˆ‘ä¸ä¼šæŠŠå®ƒç”¨äºå½“å‰ç ”ç©¶ã€‚è¯è™½å¦‚æ­¤ï¼Œæˆ‘çœ‹åˆ°æœ‰è®ºæ–‡é¢‘ç¹ä½¿ç”¨å®ƒï¼Œä½†è´¨é‡å„å¼‚ã€‚
- en: I don't include it with the Github repository because it's decently largeã€‚ but
    this command here will allow you to download it I'll go ahead and run thisã€‚ it
    lets you know where you download it to fearing coabã€‚ You may need to put it on
    yourã€‚riive somewhere I'll try to put specific instructions for coabab in hereã€‚
    So now we've got the dataã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ²¡æœ‰æŠŠå®ƒåŒ…å«åœ¨Githubä»“åº“ä¸­ï¼Œå› ä¸ºå®ƒç›¸å¯¹è¾ƒå¤§ã€‚ä¸è¿‡è¿™ä¸ªå‘½ä»¤å¯ä»¥è®©ä½ ä¸‹è½½å®ƒï¼Œæˆ‘ä¼šå…ˆè¿è¡Œè¿™ä¸ªã€‚å®ƒè®©ä½ çŸ¥é“ä¸‹è½½åˆ°å“ªé‡Œï¼Œæ‹…å¿ƒcoabã€‚ä½ å¯èƒ½éœ€è¦æŠŠå®ƒæ”¾åœ¨ä½ çš„æŸä¸ªé©±åŠ¨å™¨ä¸Šã€‚æˆ‘ä¼šå°½é‡åœ¨è¿™é‡Œæä¾›å…·ä½“çš„coababæŒ‡ä»¤ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†æ•°æ®ã€‚
- en: And I displayed the first five rowsã€‚ You can see what this looks likeã€‚ This
    is network type dataã€‚ This was created in a simulated environment for a competition
    K kind of an early tagle and doesn't show all the dataã€‚ There's quite quite a
    bit of itã€‚ But what I am going to do is let's take this data and grouped by the
    outcomeã€‚ So these are the outcomes buffer overflow FTP right guess passwordã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å±•ç¤ºäº†å‰äº”è¡Œã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™æ˜¯ä»€ä¹ˆæ ·çš„ã€‚è¿™æ˜¯ç½‘ç»œç±»å‹æ•°æ®ã€‚è¿™æ˜¯åœ¨ä¸€ä¸ªæ¨¡æ‹Ÿç¯å¢ƒä¸­ä¸ºä¸€ä¸ªæ¯”èµ›åˆ›å»ºçš„Kç§æ—©æœŸæ ‡ç­¾ï¼Œå¹¶æ²¡æœ‰æ˜¾ç¤ºæ‰€æœ‰æ•°æ®ã€‚å…¶å®è¿˜æœ‰ç›¸å½“å¤šã€‚ä½†æˆ‘å°†è¦åšçš„æ˜¯å°†è¿™äº›æ•°æ®æŒ‰ç»“æœåˆ†ç»„ã€‚æ‰€ä»¥è¿™äº›ç»“æœåŒ…æ‹¬ç¼“å†²åŒºæº¢å‡ºã€FTPã€æ­£ç¡®çŒœæµ‹å¯†ç ã€‚
- en: Those are all different types of attacks that were simulated in thisã€‚ Some of
    these are still attack types todayã€‚ Some of these are probably pretty uncommon
    20 years laterã€‚ definitely be be aware of that normal is one we're particularly
    interested in because that means nothing is happeningã€‚ So we're going to train
    it that the normal or well normal and the others are the anomaliesã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›éƒ½æ˜¯åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿçš„ä¸åŒç±»å‹çš„æ”»å‡»ã€‚å…¶ä¸­ä¸€äº›åœ¨ä»Šå¤©ä»ç„¶æ˜¯æ”»å‡»ç±»å‹ã€‚æœ‰äº›åœ¨20å¹´åå¯èƒ½å·²ç»ç›¸å½“ç½•è§ã€‚æˆ‘ä»¬ç‰¹åˆ«å…³æ³¨çš„æ­£å¸¸æ•°æ®æ„å‘³ç€æ²¡æœ‰ä»»ä½•äº‹æƒ…å‘ç”Ÿã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è®­ç»ƒå®ƒï¼Œå°†æ­£å¸¸æ•°æ®è§†ä¸ºæ­£å¸¸ï¼Œå°†å…¶ä»–æ•°æ®è§†ä¸ºå¼‚å¸¸ã€‚
- en: So we're going to train a neural network to detectã€‚Things that are not like
    normalã€‚ We're going to do this completely with a autoencoderã€‚ I create two functions
    to help us preproces thisï¼Œ one that encodes the z scores and one that encodes
    dummy variablesã€‚ and this is my preprocessing formã€‚ You can see there's a lot
    of columns hereã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥æ£€æµ‹é‚£äº›ä¸åƒæ­£å¸¸çš„æ•°æ®ã€‚æˆ‘ä»¬å°†å®Œå…¨é€šè¿‡è‡ªç¼–ç å™¨æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘åˆ›å»ºäº†ä¸¤ä¸ªå‡½æ•°æ¥å¸®åŠ©æˆ‘ä»¬é¢„å¤„ç†ï¼Œä¸€ä¸ªç”¨äºç¼–ç zåˆ†æ•°ï¼Œä¸€ä¸ªç”¨äºç¼–ç è™šæ‹Ÿå˜é‡ã€‚è¿™æ˜¯æˆ‘çš„é¢„å¤„ç†è¡¨å•ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰å¾ˆå¤šåˆ—ã€‚
- en: and I'm encoding basically in Z scores and dummiesã€‚ Those are the only two transformation
    types that I'm doing So I'm keeping things relatively simpleã€‚ and we drop any
    Nsã€‚ rows that have Nsã€‚ There's not really that manyã€‚ and you can see the rows
    hereã€‚ You can clearly see the effects of the Z scoresã€‚ Nowã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åŸºæœ¬ä¸Šåœ¨ç¼–ç zåˆ†æ•°å’Œè™šæ‹Ÿå˜é‡ã€‚è¿™æ˜¯æˆ‘ä»…è¿›è¡Œçš„ä¸¤ç§è½¬æ¢ç±»å‹ï¼Œæ‰€ä»¥æˆ‘ä¿æŒäº‹æƒ…ç›¸å¯¹ç®€å•ã€‚æˆ‘ä»¬å»æ‰ä»»ä½•åŒ…å«NaNçš„è¡Œã€‚åŒ…å«NaNçš„è¡Œå¹¶ä¸å¤šã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™äº›è¡Œã€‚ä½ å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°zåˆ†æ•°çš„å½±å“ã€‚
- en: what we're going to do is create a mask that has the normal and the attacksã€‚
    that way we're able to segregate this dataã€‚ We're going to drop the outcome because
    we're not really training on the outcomeã€‚ that's essentially the targetã€‚ reallyï¼Œ
    this is unsupervised learning once you get it separated into into these two groupsã€‚
    such as the nature of autoenderrsã€‚ We'll go ahead and run thatã€‚ and you can seeã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦åšçš„æ˜¯åˆ›å»ºä¸€ä¸ªåŒ…å«æ­£å¸¸å’Œæ”»å‡»çš„æ©ç ã€‚è¿™æ ·æˆ‘ä»¬èƒ½å¤Ÿå°†è¿™äº›æ•°æ®éš”ç¦»å¼€æ¥ã€‚æˆ‘ä»¬å°†å»æ‰ç»“æœï¼Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸æ˜¯çœŸçš„åœ¨ç»“æœä¸Šè®­ç»ƒã€‚è¿™æœ¬è´¨ä¸Šæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œä¸€æ—¦ä½ å°†æ•°æ®åˆ†æˆè¿™ä¸¤ä¸ªç»„ã€‚è¿™æ ·çš„è‡ªç¼–ç å™¨çš„æ€§è´¨ã€‚æˆ‘ä»¬å°†ç»§ç»­è¿è¡Œå®ƒï¼Œä½ å¯ä»¥çœ‹åˆ°ã€‚
- en: Normal counts about 97 k attacks are much more common in this dataset setã€‚ We
    separate it out so that we have the x for the attack and the x4 normal and then
    we're going to break this into a train test split we're breaking normal up is
    we're going to use normal to evaluate itã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¸¸è®¡æ•°å¤§çº¦æ˜¯97Kï¼Œæ”»å‡»åœ¨è¿™ä¸ªæ•°æ®é›†ä¸­æ›´ä¸ºå¸¸è§ã€‚æˆ‘ä»¬å°†å…¶åˆ†å¼€ï¼Œä»¥ä¾¿æˆ‘ä»¬æ‹¥æœ‰æ”»å‡»çš„xå’Œæ­£å¸¸çš„xï¼Œç„¶åæˆ‘ä»¬å°†æŠŠè¿™åˆ†æˆè®­ç»ƒæµ‹è¯•é›†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ­£å¸¸æ•°æ®æ¥è¯„ä¼°å®ƒã€‚
- en: we're going to see if the normal looks like normal data to it9 anomaly Now we're
    going to use an autoencoder for this and we've talked about autoencors beforeã€‚
    but just so these videos somewhat stand alone just to give you a quick overview
    of thisã€‚ an autoencoder is essentially a neural network that has sort of a skinny
    hidden layer structureã€‚ the idea is you have a number of inputs now you're going
    to have all the Kdv99 inputs for this particular one you do have the bias neurons
    like you do in most networks and you have an output count equal to the input countã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦çœ‹çœ‹æ­£å¸¸æ•°æ®åœ¨å®ƒçœ‹æ¥æ˜¯å¦åƒæ­£å¸¸æ•°æ®ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†ä½¿ç”¨è‡ªç¼–ç å™¨æ¥å®Œæˆè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡è‡ªç¼–ç å™¨ã€‚ä½†ä¸ºäº†è®©è¿™äº›è§†é¢‘èƒ½å¤Ÿç›¸å¯¹ç‹¬ç«‹ï¼Œæˆ‘ç»™ä½ å¿«é€Ÿæ¦‚è¿°ä¸€ä¸‹ã€‚è‡ªç¼–ç å™¨æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå…·æœ‰â€œç˜¦â€éšè—å±‚ç»“æ„çš„ç¥ç»ç½‘ç»œã€‚å®ƒçš„æƒ³æ³•æ˜¯ä½ æœ‰å¤šä¸ªè¾“å…¥ï¼Œå¯¹äºè¿™ä¸ªç‰¹å®šçš„è‡ªç¼–ç å™¨ï¼Œä½ å°†æ‹¥æœ‰æ‰€æœ‰KDD99çš„è¾“å…¥ï¼Œåƒå¤§å¤šæ•°ç½‘ç»œä¸€æ ·ï¼Œä½ æœ‰åç½®ç¥ç»å…ƒï¼Œè¾“å‡ºæ•°é‡ç­‰äºè¾“å…¥æ•°é‡ã€‚
- en: and what we're going to do is basically train the auto encoder so thatã€‚It is
    able to produce the same input as output Now that seems uselessã€‚ but that is teaching
    it essentially to do feature reduction and simplification so it teaches it to
    take all of these inputsã€‚ these five inputs are 100 as we will have probably with
    KDD99 and represents them as just the two numbers being output to the hidden one
    and hidden2 Now all the weights leading into here are the encoding weights and
    these are the decoding weights so those are what it learnsã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¦åšçš„åŸºæœ¬ä¸Šæ˜¯è®­ç»ƒè‡ªç¼–ç å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆç›¸åŒçš„è¾“å…¥ä½œä¸ºè¾“å‡ºã€‚ç°åœ¨è¿™ä¼¼ä¹æ²¡ä»€ä¹ˆç”¨ï¼Œä½†è¿™æœ¬è´¨ä¸Šæ˜¯åœ¨æ•™å®ƒè¿›è¡Œç‰¹å¾å‡å°‘å’Œç®€åŒ–ï¼Œå› æ­¤å®ƒæ•™ä¼šå®ƒå°†æ‰€æœ‰è¿™äº›è¾“å…¥ï¼Œè¿™äº”ä¸ªè¾“å…¥æ˜¯100ï¼Œå› ä¸ºæˆ‘ä»¬å°†å¯èƒ½ä½¿ç”¨KDD99ï¼Œå°†å…¶è¡¨ç¤ºä¸ºè¾“å‡ºåˆ°éšè—å±‚1å’Œéšè—å±‚2çš„ä¸¤ä¸ªæ•°å­—ã€‚ç°åœ¨ï¼Œæ‰€æœ‰è¿›å…¥è¿™é‡Œçš„æƒé‡éƒ½æ˜¯ç¼–ç æƒé‡ï¼Œè¿™äº›æ˜¯è§£ç æƒé‡ï¼Œå› æ­¤è¿™äº›æ˜¯å®ƒæ‰€å­¦ä¹ çš„ã€‚
- en: For how to decompress it Hereï¼Œ we're going to build our autoencoderã€‚ We are
    going to have a little more complicated autoencoder than hereã€‚ So we're going
    to have essentially 25ï¼Œ25ï¼Œ3ã€‚ We still have this very thinning area but we have
    a little bit of sort of an hourglassã€‚ So it's almost like we have three hidden
    layers here to actually give us our compression capabilitiesã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ„å»ºæˆ‘ä»¬çš„è‡ªç¼–ç å™¨ã€‚æˆ‘ä»¬çš„è‡ªç¼–ç å™¨å°†æ¯”è¿™é‡Œæ›´å¤æ‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åŸºæœ¬ä¸Šæœ‰25ï¼Œ25ï¼Œ3ã€‚æˆ‘ä»¬ä»ç„¶æœ‰è¿™ä¸ªéå¸¸ç»†çš„åŒºåŸŸï¼Œä½†æœ‰ç‚¹åƒæ²™æ¼çš„å½¢çŠ¶ã€‚æ‰€ä»¥è¿™é‡Œå‡ ä¹æœ‰ä¸‰ä¸ªéšè—å±‚ï¼Œå®é™…ä¸Šä¸ºæˆ‘ä»¬æä¾›å‹ç¼©èƒ½åŠ›ã€‚
- en: So I'm going to go ahead and run thisã€‚ It will actually fit itã€‚ So it's going
    to take it a little bit to fit this neural networkã€‚ I will fast forward this partã€‚
    Okayï¼Œ it's trained just to explain sort of the theory of what's going on hereã€‚
    We trained this just on the normal dataã€‚ and it is being trained un superupervisedã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†ç»§ç»­è¿è¡Œè¿™ä¸ªç¨‹åºã€‚å®ƒå®é™…ä¸Šä¼šé€‚åº”è¿™ä¸ªç¥ç»ç½‘ç»œã€‚æ‰€ä»¥å®ƒéœ€è¦ä¸€ç‚¹æ—¶é—´æ¥é€‚åº”ã€‚æˆ‘ä¼šå¿«è¿›è¿™éƒ¨åˆ†ã€‚å¥½çš„ï¼Œå®ƒè®­ç»ƒå®Œäº†ï¼Œä¸»è¦æ˜¯ä¸ºäº†é˜è¿°è¿™é‡Œå‘ç”Ÿçš„ç†è®ºã€‚æˆ‘ä»¬åªåœ¨æ­£å¸¸æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”æ˜¯æ— ç›‘ç£è®­ç»ƒã€‚
- en: So we're not even giving it the outcomesã€‚ There'd be no point to give it the
    outcomes because they're all normalã€‚ So the outcome would be the sameã€‚ Since it's
    learning to compress to reduce the dimensionsã€‚ the way the dimension reduction
    or compression in general worksã€‚By using patterns to represent common portions
    of the dataã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ç”šè‡³ä¸æä¾›ç»“æœã€‚ç»™å‡ºç»“æœæ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œå› ä¸ºå®ƒä»¬éƒ½æ˜¯æ­£å¸¸çš„ã€‚å› æ­¤ï¼Œç»“æœä¼šæ˜¯ä¸€æ ·çš„ã€‚ç”±äºå®ƒæ­£åœ¨å­¦ä¹ å‹ç¼©ä»¥å‡å°‘ç»´åº¦ã€‚ç»´åº¦å‡å°‘æˆ–å‹ç¼©çš„å·¥ä½œæ–¹å¼å°±æ˜¯é€šè¿‡ä½¿ç”¨æ¨¡å¼æ¥è¡¨ç¤ºæ•°æ®çš„å¸¸è§éƒ¨åˆ†ã€‚
- en: So it's simplifying it that will only work on cases where the data coming in
    is pretty similar to thatã€‚ Nowï¼Œ I'll give you a perfect example of a unintended
    anomaly detectorã€‚ Nowã€‚ cell phones are a lot better about thisã€‚ but earlier cell
    phonesã€‚ the way that they would compress is they knew a lot about the human voice
    that would normally go through there so they used the ranges that the human voice
    was normally inã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒåœ¨ç®€åŒ–ï¼Œåªæœ‰åœ¨è¾“å…¥æ•°æ®ä¸ä¹‹éå¸¸ç›¸ä¼¼çš„æƒ…å†µä¸‹æ‰èƒ½å·¥ä½œã€‚ç°åœ¨ï¼Œæˆ‘å°†ç»™ä½ ä¸€ä¸ªæ„å¤–çš„å¼‚å¸¸æ£€æµ‹å™¨çš„å®Œç¾ä¾‹å­ã€‚ç°åœ¨ï¼Œæ‰‹æœºåœ¨è¿™æ–¹é¢åšå¾—å¥½å¤šäº†ï¼Œä½†æ—©æœŸçš„æ‰‹æœºã€‚å®ƒä»¬å‹ç¼©çš„æ–¹å¼æ˜¯å› ä¸ºå®ƒä»¬å¯¹äººå£°çš„ç‰¹æ€§äº†è§£å¾ˆå¤šï¼Œå› æ­¤ä½¿ç”¨äº†äººå£°é€šå¸¸åœ¨çš„éŸ³åŸŸã€‚
- en: they only compressed it and degraded quality in such a way so that it would
    not be annoying for human voices you'd still recognize the voice you would still
    be able to understand itã€‚ Howeverï¼Œ if you tried to play music through a cell phone
    or other other tones that the compression algorithms simply were not designed
    forã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬åªæ˜¯å‹ç¼©äº†æ•°æ®ï¼Œå¹¶ä»¥ä¸€ç§ä¸ä¼šè®©äººç±»å£°éŸ³æ„Ÿåˆ°çƒ¦æ¼çš„æ–¹å¼é™ä½äº†è´¨é‡ï¼Œä½ ä»ç„¶å¯ä»¥è¯†åˆ«å£°éŸ³ï¼Œä»ç„¶èƒ½å¤Ÿç†è§£ã€‚ç„¶è€Œï¼Œå¦‚æœä½ å°è¯•é€šè¿‡æ‰‹æœºæ’­æ”¾éŸ³ä¹æˆ–å…¶ä»–å‹ç¼©ç®—æ³•æ ¹æœ¬ä¸é€‚åˆçš„éŸ³è°ƒï¼Œé‚£å°±ä¸è¡Œäº†ã€‚
- en: they would not be reproduced as wellã€‚ there would be static and other distortions
    in thatã€‚Becauseuse those different tones other than what the compression algorithms
    were built for are differentã€‚ They're anomaliesã€‚ and the cell phone detected the
    anomalyã€‚ Not rather designed forã€‚ It's just an exampleï¼Œ but it detected the anomaly
    by distorting itã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬çš„é‡ç°æ•ˆæœä¸ä¼šå¾ˆå¥½ã€‚ä¼šæœ‰é™ç”µå’Œå…¶ä»–å¤±çœŸã€‚å› ä¸ºä½¿ç”¨è¿™äº›ä¸å‹ç¼©ç®—æ³•æ„å»ºæ—¶ä¸åŒçš„éŸ³è°ƒå°±æ˜¯ä¸åŒçš„ã€‚å®ƒä»¬æ˜¯å¼‚å¸¸ã€‚è€Œæ‰‹æœºåˆ™æ£€æµ‹åˆ°äº†è¿™ç§å¼‚å¸¸ã€‚å¹¶ä¸æ˜¯ç‰¹åˆ«è®¾è®¡çš„ã€‚è¿™åªæ˜¯ä¸€ä¸ªä¾‹å­ï¼Œä½†å®ƒé€šè¿‡å¤±çœŸæ¥æ£€æµ‹å¼‚å¸¸ã€‚
- en: That's what we're going to see hereã€‚ We'll put data into the input and look
    at how similar the data is in the output to the inputã€‚ because the autoencor is
    meant to be a straight pass throughï¼Œ but it compresses in the processã€‚ So it compresses
    and then expandsã€‚ and we want to make sure that we're not seen too much distortion
    in that processã€‚ because if we areï¼Œ then the data coming in are probably differentã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬å°†åœ¨è¿™é‡Œçœ‹åˆ°çš„å†…å®¹ã€‚æˆ‘ä»¬å°†æ•°æ®è¾“å…¥ï¼Œå¹¶æŸ¥çœ‹è¾“å‡ºæ•°æ®ä¸è¾“å…¥æ•°æ®çš„ç›¸ä¼¼ç¨‹åº¦ã€‚å› ä¸ºè‡ªç¼–ç å™¨æ˜¯ä¸ºäº†ç›´æ¥ä¼ é€’è€Œè®¾è®¡ï¼Œä½†åœ¨è¿‡ç¨‹ä¸­ä¼šè¿›è¡Œå‹ç¼©ã€‚æ‰€ä»¥å®ƒå…ˆå‹ç¼©å†æ‰©å±•ã€‚æˆ‘ä»¬å¸Œæœ›ç¡®ä¿åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æ²¡æœ‰å¤ªå¤šçš„å¤±çœŸã€‚å¦‚æœæœ‰ï¼Œé‚£ä¹ˆè¾“å…¥çš„æ•°æ®å¯èƒ½å°±æ˜¯ä¸åŒçš„ã€‚
- en: then the data that this was originally trained forã€‚ Now we saw earlier in this
    course that you could use chaos statistics and other things to determine if your
    data have changed to the point that your neural network might need to be retrainedã€‚
    This is another great way to do thisã€‚ Anomaly detection and detectingã€‚If your
    data is sufficiently like the training data to know when to update your neural
    network are all very similarã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ€åˆè®­ç»ƒæ•°æ®çš„åŸºç¡€ã€‚æˆ‘ä»¬åœ¨è¯¾ç¨‹æ—©äº›æ—¶å€™çœ‹åˆ°ï¼Œä½ å¯ä»¥ä½¿ç”¨æ··æ²Œç»Ÿè®¡å’Œå…¶ä»–æ–¹æ³•æ¥ç¡®å®šæ•°æ®æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ï¼Œä»¥è‡³äºä½ çš„ç¥ç»ç½‘ç»œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒã€‚è¿™æ˜¯å¦ä¸€ç§å¾ˆå¥½çš„æ–¹æ³•ã€‚å¼‚å¸¸æ£€æµ‹å’Œè¯†åˆ«ã€‚å¦‚æœä½ çš„æ•°æ®ä¸è®­ç»ƒæ•°æ®è¶³å¤Ÿç›¸ä¼¼ï¼Œå°±èƒ½çŸ¥é“ä½•æ—¶æ›´æ–°ä½ çš„ç¥ç»ç½‘ç»œã€‚
- en: let's go ahead and run it and do just that testã€‚ So let's run this cell now
    and we'll see the resultsã€‚ first I'm going to ask it to predict on the normal
    test and then I'm going to score it basically seeing how well these predictions
    lined up to the normal test that it was trained onã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­è¿è¡Œå®ƒå¹¶è¿›è¡Œæµ‹è¯•ã€‚å› æ­¤ï¼Œç°åœ¨è¿è¡Œè¿™ä¸ªå•å…ƒï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ç»“æœã€‚é¦–å…ˆï¼Œæˆ‘ä¼šè®©å®ƒåœ¨æ­£å¸¸æµ‹è¯•ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œç„¶åæˆ‘ä¼šè¯„åˆ†ï¼ŒåŸºæœ¬ä¸Šæ˜¯æŸ¥çœ‹è¿™äº›é¢„æµ‹ä¸å®ƒè®­ç»ƒè¿‡çš„æ­£å¸¸æµ‹è¯•çš„å»åˆç¨‹åº¦ã€‚
- en: so we're literally seenã€‚ So if you look at it hereã€‚ the two in sample now the
    ens samplele normal attackã€‚ this is essentially the data that it was trained onã€‚
    So you have to take that with a green assaultã€‚ these are normal data that were
    not part of the training setã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å­—é¢ä¸Šçœ‹åˆ°äº†è¿™ä¸€ç‚¹ã€‚å¦‚æœä½ çœ‹çœ‹è¿™é‡Œï¼Œæ ·æœ¬ä¸­çš„ä¸¤ä¸ªç°åœ¨çš„æ­£å¸¸æ”»å‡»ã€‚è¿™æœ¬è´¨ä¸Šæ˜¯å®ƒæ‰€è®­ç»ƒçš„æ•°æ®ã€‚å› æ­¤ï¼Œä½ å¿…é¡»å¯¹è¿™äº›ä¿æŒè­¦æƒ•ã€‚è¿™äº›æ˜¯æ­£å¸¸çš„æ•°æ®ï¼Œä¸åœ¨è®­ç»ƒé›†ä¸­ã€‚
- en: but you can see that the RMSse for both of these two is right around 0ã€‚3 notice
    the RMSE is higher for attacks because they are anomalies and these are all pretty
    simpleã€‚ We're doing predictions on the X normal test and then we evaluate the
    error based on the same thingã€‚ So we're seeing how well can thisã€‚To flow through
    the auto encoder with minimal distortionã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸¤ä¸ªçš„RMSseå¤§çº¦æ˜¯0.3ã€‚æ³¨æ„åˆ°æ”»å‡»çš„RMSEè¾ƒé«˜ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å¼‚å¸¸ï¼Œè¿™äº›éƒ½ç›¸å¯¹ç®€å•ã€‚æˆ‘ä»¬åœ¨Xæ­£å¸¸æµ‹è¯•ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œç„¶åæ ¹æ®ç›¸åŒçš„å†…å®¹è¯„ä¼°è¯¯å·®ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨çœ‹è¿™èƒ½å¦é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ä»¥æœ€å°å¤±çœŸæµåŠ¨ã€‚
- en: the more distortion you seeï¼Œ the more likely it's an anomaly this content changes
    often so subscribe to the channel to stay up to date on this course and other
    topics and artificial intelligenceã€‚![](img/231301739b63fc07324b14a0fb6dafd4_3.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çœ‹åˆ°çš„å¤±çœŸè¶Šå¤šï¼Œè¶Šå¯èƒ½æ˜¯å¼‚å¸¸ã€‚è¯¥å†…å®¹ç»å¸¸å˜åŒ–ï¼Œæ‰€ä»¥è¯·è®¢é˜…é¢‘é“ä»¥ä¿æŒå¯¹è¯¥è¯¾ç¨‹å’Œå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜çš„æœ€æ–°äº†è§£ã€‚![](img/231301739b63fc07324b14a0fb6dafd4_3.png)
