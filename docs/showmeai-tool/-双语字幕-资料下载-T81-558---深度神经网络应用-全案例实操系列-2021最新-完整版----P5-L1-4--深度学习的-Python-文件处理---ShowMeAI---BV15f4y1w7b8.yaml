- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P5：L1.4- 深度学习的 Python 文件处理
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P5：L1.4- 深度学习的 Python 文件处理
    - ShowMeAI - BV15f4y1w7b8
- en: Hi， this is Jeff Heaton， welcomel to applications of deep neural networks with
    Washington University In this video。 we're going to look at how to handle files
    in Python。 This gets us ready for doing much more complicated things with Ks and
    Tensorflow We'll see in particular how to deal with text files and image files
    because these are the primary types of files that we'll be dealing with in this
    course For the latest on my AI course and projects click subscribe in the bell
    next to it to be notified of every new video let's have a look at Python file
    handling In this course on neural networks we're going to deal with essentially
    three types of files we're going to deal with CSV files image files and text files
    CSv files usually of the CSv extension you can think of those as looking like
    Microsoft Excel files In fact on most computers you double click a CSV file in
    Excel will pop open。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是 Jeff Heaton，欢迎来到华盛顿大学的深度神经网络应用课程。在这个视频中，我们将研究如何在 Python 中处理文件。这为我们在 Keras
    和 TensorFlow 中进行更复杂的操作做好准备。我们特别会看到如何处理文本文件和图像文件，因为这些是我们在本课程中主要处理的文件类型。要获取我 AI
    课程和项目的最新信息，请点击旁边的铃铛订阅，以便在每个新视频发布时收到通知。让我们来看看 Python 文件处理。在这个神经网络课程中，我们将处理三种类型的文件，分别是
    CSV 文件、图像文件和文本文件。CSV 文件通常带有 CSV 扩展名，你可以把它们想象成 Microsoft Excel 文件。事实上，在大多数计算机上，你双击
    CSV 文件时，Excel 会弹出打开。
- en: '![](img/ded2748bf56fd1a0965825e0ddc84ca6_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ded2748bf56fd1a0965825e0ddc84ca6_1.png)'
- en: Image files will deal mostly with P&G or JPEG， there's also GF files and others。Images
    are one of the things that neural networks do particularly well so we'll see a
    lot of different images in this in this class and then text files have the TXT
    extension。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像文件主要是 P&G 或 JPEG 格式，还有 GF 文件等。图像是神经网络特别擅长处理的内容，所以在这节课中我们将看到很多不同的图像，文本文件则有
    TXT 扩展名。
- en: Those are usually just raw text， and that has to do often with natural language
    processing other types of files that we'll see briefly in this class are JSON
    and H5。These files will come from three primary locations， your hard drive。 Now
    this is important if you're using Windows， you'll see paths like this。 if you're
    using a Mac。 you'll see files like this。Most of you I assume will be using Google
    Coabab。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些通常只是原始文本，往往与自然语言处理有关。在这节课中我们将简要看到其他类型的文件，如 JSON 和 H5。这些文件将来自三个主要位置，你的硬盘。如果你使用
    Windows，你会看到像这样的路径。如果你使用 Mac，你会看到这样的文件。我假设你们大多数人会使用 Google Coabab。
- en: so watch through the tutorial on how to read those from Google Collab。 you'll
    basically have a path just like this like this that'll be close to Macintosh。CSV
    files can be read with pandas。 We'll deal with pandas a lot in the next class。
    Now another thing to note here that is the way that I'm doing this。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 所以请观看关于如何从 Google Collab 阅读这些内容的教程。基本上你会有一条类似于 Macintosh 的路径。CSV 文件可以通过 pandas
    阅读。在下节课中我们会大量使用 pandas。现在需要注意的是我这样做的方法。
- en: I am giving you web addresses for most of the CSv files that will load this
    is on data。heatinresearch。com。 that's my own URL。Which is unique to this class。And
    I have all the data files there， this way if you're running in Google Coab or
    Mac or Windows or whatever。It will work just fine。The above command loads Fisher's
    I data set straight from the internet。Okay。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我给你提供大多数 CSV 文件的网页地址，这在 data.heatinresearch.com。这是我自己的网址，独特于这节课。我在那里有所有数据文件，这样无论你是在
    Google Coab、Mac、Windows 或其他设备上运行，它都能正常工作。上面的命令直接从互联网加载 Fisher 的 I 数据集。好的。
- en: it's loaded， you can display the first five records of that。And this is a very
    classic dataset set if you haven't seen it before。 it is basically four measurements
    from flowers and it defines the species here。 there's actually three different
    species at the very beginning since the file is sorted。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 文件已加载，你可以显示前五条记录。这是一个非常经典的数据集，如果你以前没有见过，它基本上是关于花朵的四个测量值，并定义了物种。由于文件是按顺序排列的，所以一开始实际上有三种不同的物种。
- en: you're only seeing the first iris which is sattosa This is a classic classification
    data where you try to use these values to classify what type of iris flower it
    is reading an image requires the PIL library but it works similar to reading CSV
    files。 you're basically going to do this and。Run it， and it will load this image
    from。From this URL。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你只看到第一个鸢尾花，它是sattosa。这是一个经典的分类数据集，你试图利用这些值来分类它是什么类型的鸢尾花。读取图像需要使用PIL库，但它的工作方式类似于读取CSV文件。你基本上会这样做。运行它，它会从这个URL加载图像。
- en: And this is one of the buildings from Washington University。Doesn't actually
    look like that anymore。 thanks to all the construction， but。Or at least the grass
    in front of it。But this is this is a way that you load a JPEG Now when we do some
    of these exercises。 we're going to have lots and lots and lots of images。You may
    literally harvest the images this way。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是华盛顿大学的一栋建筑。现在看起来并不是这样，多亏了所有的建筑，但至少前面的草坪如此。但这就是加载JPEG的一种方式。现在当我们进行一些练习时，我们将会有很多很多的图像。你可能会真的以这种方式获取图像。
- en: but you'll want to put them on a folder on your Google Drive。 And I show you
    how to do that in the introduction to Google Collabab video。 So make sure you
    watch that if you're using。If you're using Google Coabab and believe me。 for some
    of the image processing that we'll do in this class。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但你需要将它们放在你的Google Drive的一个文件夹中。我在Google Colab视频的介绍中向你展示了如何做到这一点。所以如果你使用Google
    Colab，请确保观看那个视频。相信我，对于我们在这门课上进行的一些图像处理来说，这是必要的。
- en: you'll want Google CoAab because it has a GPU。You can also read or stream large
    CSV files。What's good about streaming them is you don't actually load the whole
    CSV file into memory at once if you're just reading a CSV file and calculating
    statistics on each row。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你会需要Google Colab，因为它有GPU。你也可以读取或流式处理大型CSV文件。流式处理的好处在于，你并不会一次性将整个CSV文件加载到内存中，如果你只是读取CSV文件并计算每一行的统计数据。
- en: you really don't need to load the whole thing into memory。 you can simply read
    each row and process it。So here。I am taking the I data set。I am opening it up
    for streaming， that means the whole thing is not loaded into memory at once。 and
    I'm going to sum each of those four values that we saw in there。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你真的不需要将整个内容加载到内存中。你可以简单地读取每一行并进行处理。因此，在这里，我正在使用I数据集。我将其打开以进行流处理，这意味着整个内容不会一次性加载到内存中。我将对我们看到的那四个值进行求和。
- en: I create a array of four zeros and lumpumpy。And I keep count of how many rows
    I've read。And then I run this。And you'll see this is this is essentially the average
    of each of those four values。 I am going to loop over the line， so each each line
    I basically have to I convert that line into we'll see more of this when we when
    we deal with nuumpy。 but this is how you create a lumpumpy array。I'm taking locations
    zero to four only I don't want the species。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了一个包含四个零的数组和NumPy。我记录了我读取的行数。然后我运行这个。你会看到这基本上是那四个值的平均数。我将遍历这一行，所以对于每一行，我基本上都要将那一行转换为NumPy数组。当我们处理NumPy时，你会看到更多这个的内容。但这就是如何创建NumPy数组的方法。我只取位置零到四，我不需要物种信息。
- en: the species is the fifth。And I convert them into floating point。Because they're
    integers and because they could potentially come in as integers or strings or
    other values。 I want them as floating points if the line is the right length。I
    skip any empty lines。 I believe there's an empty line at the end。I sum it up。
    This is a vector summation。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 物种是第五个。我将它们转换为浮点数。因为它们是整数，并且可能会以整数或字符串或其他值的形式出现。如果这一行的长度合适，我会跳过任何空行。我相信最后会有一行空行。我进行求和。这是一个向量求和。
- en: so this is basically taking everything that's in that line too。 so the array。Of
    those four values。 And I'm adding it to that other array that I have。 and I keep
    the count incremented。 So that's a vector addition that's adding four numbers。
    just like this is a vector division。 this returns a vector or an array back， but
    it divides each element by count vector mathematics is very useful in this this
    course because we're often dealing with vectors。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这基本上是将第两行中的所有内容提取出来。因此，数组中的那四个值。我将其添加到我拥有的另一个数组中，并保持计数递增。所以这就是向量加法，它是将四个数字相加。就像这就是向量除法。这返回一个向量或数组，但它将每个元素除以计数。在这门课程中，向量数学非常有用，因为我们经常处理向量。
- en: which are a low dimension form of a tensor。 So we we deal anytime that we can
    perform math across an entire tensor at once。It's a great optimization。Reading
    a text file。This is the United States Declaration of Independence。 this is just
    a text file that I was able to find that had a URL and it was a pure text file。You
    can run it and it basically prints out the raw text of the Declaration of Independence
    of the United States of America Thank you for watching this video this concludes
    file handling and Python in the next video we're going to look functions Ladas
    and mapR content changes often so subscribe to the to stay up to date on this
    and other topics in artificial intelligence。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种低维形式的张量。所以我们可以在任何时候进行整个张量的数学运算。这是一个很好的优化。读取一个文本文件。这是《美国独立宣言》。这只是一个我找到的文本文件，它有一个网址，并且是一个纯文本文件。你可以运行它，它基本上会打印出《美利坚合众国独立宣言》的原始文本。感谢观看这个视频，这部分结束了文件处理和Python。在下一个视频中，我们将查看函数Ladas和mapR，内容常常会变化，所以请订阅以便及时了解人工智能的相关主题。
- en: '![](img/ded2748bf56fd1a0965825e0ddc84ca6_3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ded2748bf56fd1a0965825e0ddc84ca6_3.png)'
