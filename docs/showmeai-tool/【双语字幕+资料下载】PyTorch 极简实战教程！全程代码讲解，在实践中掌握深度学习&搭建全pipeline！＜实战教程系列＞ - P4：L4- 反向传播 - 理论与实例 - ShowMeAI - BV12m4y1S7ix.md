# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- åå‘ä¼ æ’­ - ç†è®ºä¸å®ä¾‹ - ShowMeAI - BV12m4y1S7ix

Hiï¼Œ everybodyã€‚ Welcome to a new Pytorch tutorialã€‚ In this videoã€‚

 I am going to explain the famous Beck propagation algorithm and how we can calculate gradients with itã€‚

ğŸ˜Šï¼ŒI explain the necessary concepts of this techniqueã€‚

 and then I will walk you through a concrete example with some numbersã€‚And at the endã€‚

 we will then see how easy it is to apply back propagation in Pytorarchã€‚ So let's startã€‚

And the first concept we must know is the chain ruleã€‚

 So let's say we have two operations or two functionsã€‚So firstï¼Œ we have the input Xã€‚

 and then we apply a function A and get an output Yã€‚

 And then we use this output as the input for our second functionã€‚ So the second function Bã€‚

 And then we get the final output Cã€‚And now we want to minimize our Cã€‚

 So we want to know the derivative of C with respect to our x here in the beginningã€‚

And we can do this using the so called chain ruleã€‚ So for thisã€‚

 we first compute the derivative of C with respect to y and multiply this with the derivative or of y with respect to Xã€‚

 And then we get the final derivative we wantã€‚So firstï¼Œ hereã€‚

 we compute the derivative at this positionã€‚So the derivative of this output with respect to this inputã€‚

 And then hereï¼Œ the derivative of this output with respect to this inputã€‚

 And then we multiply them together and get the final gradient we are interested inã€‚

 So that's the chain ruleã€‚And now the next concept is the so called computational graphã€‚

So for every operation we do with our tens sourceï¼Œ Pyto will create a graph for usã€‚

 So where at each noteï¼Œ we apply one operation or one function with some inputs and then get an outputã€‚

So here in this caseï¼Œ in this exampleï¼Œ we use a multiplication operationã€‚

 So we multiply x and y and then get Cã€‚And now at these notesã€‚

 we can calculate so called local gradientsï¼Œ and we can use them later in the chain rule to get the final gradientã€‚

 So hereï¼Œ the local gradientsï¼Œ we can compute two gradientsï¼Œ the gradient of C with respect to xã€‚

 And this is simpleã€‚ since we know this function hereã€‚

 So this is the gradient gradient of x times y with respect to xï¼Œ which is yã€‚ And here in the bottomã€‚

 we compute the derivative of x times y with respect to yï¼Œ which is xã€‚

So local gradients are easy because we know this functionã€‚ And why do we want themã€‚

 Because typically our graph has more operationsã€‚ And at the very endã€‚

 we calculate a loss function that we want to minimizeã€‚

 So we have to calculate the gradient of this loss with respect to our parameter X in the beginningã€‚

Andã€‚Nowï¼Œ let's suppose at this positionï¼Œ we already know the derivative of the loss with respect to our Cã€‚

 and then we can get the final gradient we wantã€‚ So the with the chain ruleã€‚

 So the gradient of the loss with respect to X is then the gradient of loss with respect to Cã€‚

Times our local gradientã€‚ So the derivative of C with respect to xã€‚And yeahã€‚

 this is how we get the final gradient thenï¼Œ andã€‚Nowï¼Œ the whole concept consists of three stepsã€‚

 So firstï¼Œ we do a forward pass where we apply all the functions and compute the lossã€‚

Then at each noteï¼Œ we calculate the local gradientsã€‚

 and then we do a so called backward pass where we compute the gradient of the loss with respect to our weights or parameters using the chain ruleã€‚

So these are the three steps we are going doã€‚ And now we look at a concrete exampleã€‚

 So here we want to use linear regressionã€‚And if you don't know how this worksã€‚

 then I highly recommend my machine learning from scratch tutorial about linear regressionã€‚

I will put the link in the descriptionã€‚So basicallyã€‚

 we model our output with a linear combination of some weights and an inputã€‚

 So our y hat or y predicted is w times xã€‚And then we formulate some loss functionã€‚ So in this caseã€‚

 this is the squared errorã€‚ Actuallyï¼Œ it should be the mean squared errorï¼Œ but for simplicityã€‚

 we just use the squared errorã€‚ Otherwiseï¼Œ we would have another operation to get the meanã€‚

 So the loss is the difference of the predicted y minus the actual yï¼Œ and then we square itã€‚

And now we want to minimize our lossã€‚ So we want to know the derivative of the loss with respect to our weightsã€‚

 And how do we get thatï¼Œ So we apply our three stepsã€‚ Firstã€‚

 we do a forward pass and put in the x and the Wã€‚ And then here we put in the yã€‚

And apply our functions hereã€‚ And then we get the lossã€‚

 Then we calculate the the local gradients at each noteã€‚ So hereã€‚

 the gradient of the loss with respect to our Sã€‚ Then hereã€‚

 the gradient of the S with respect to our y hatã€‚And here at this noteã€‚

 the gradient of Y hat with respect to our Wã€‚And then we do a backward passã€‚ So we start at the endã€‚

 And here we have the firstï¼Œ we have the derivative of the loss with respect to our Sã€‚

And then we use themï¼Œ and we also use the chain rule to get the derivative of the loss with respect of the Y hatã€‚

And then againï¼Œ we use this and the chain rule to get the final gradient of the loss with respect to our Wã€‚

So let's do this with some concrete numbersã€‚ So let's say we have x and y is givenã€‚ So x is  oneã€‚

 and y is 2 in the beginningã€‚And so these are our training samplesã€‚ and we initialize our weightã€‚

 So let's sayï¼Œ for exampleï¼Œ we say our w is one in the beginningã€‚And then we do the forward passã€‚

 So here at the first nodeï¼Œ we multiply x and Wã€‚ So we get Y hat equals oneã€‚Then at the next noteã€‚

 we do a subionã€‚ So y hat y is 1-2 equals -1ã€‚And at the very endï¼Œ so we square our Sã€‚

 So we have have S squaredï¼Œ soã€‚Our lossï¼Œ thenï¼Œ is oneã€‚And now we calculate the local gradientã€‚

 So at the last noteï¼Œ we have the gradient of the loss with respect to Sã€‚

 And this is simple because we know the functionã€‚ So this is the gradient of S squaredã€‚

 So this is just 2 Sã€‚And then at the next noteï¼Œ we have the gradient of S with respect to Y hatã€‚

 which is the gradient of the function Y hat minus y with respect to Y hatï¼Œ which is just oneã€‚

And then here at the last nodeï¼Œ we have the derivative of Y hat with respect to Wã€‚

 So this is the derivative ofã€‚W times x with respect to wï¼Œ which is xã€‚And alsoã€‚

 notice that we don't need to goã€‚ Don't need to know the derivatives in thisã€‚Graph linesã€‚

 so we don'tã€‚Need to know what is the derivative of S with respect to Yã€‚ And also hereã€‚

 we don't need this because our x and our y are fixedã€‚

 So we are only interested in our parameters that we want to update hereã€‚And yeahã€‚

 and then we do the backward passã€‚ So firstï¼Œ now we use our local gradientsã€‚

So we want to compute the derivative of the loss with respect to Y hatã€‚

 And here we use the chain rule with our two local gradients that we just computedã€‚

 which is 2 S times 1ã€‚ and S is -1ï¼Œ which we calculated up hereã€‚ And then so this is  -2ã€‚

And now we use this derivative and also this local gradient to then get the final gradientã€‚

 the gradient of the loss with respect to our Wï¼Œ which is the gradient of the loss with respect to Y hat times the gradient of Y hat with respect to Wã€‚

 which is -2 times x and x is 1ã€‚ So the final gradient is -2ã€‚

So this is the final gradient then that we not want to knowã€‚ And yeahã€‚

 that's all how back propagation worksã€‚ And let's jump over to our code and verify that Pyto get these exact numbersã€‚

 So let's remember x is 1 Y is 2 and w is 1ã€‚ And then our first gradient should be -2ã€‚



![](img/84bf83ae2a8c01617b4cf06b2bc402cb_1.png)

Soã€‚

![](img/84bf83ae2a8c01617b4cf06b2bc402cb_3.png)

Let's see how we can use this in pie torchã€‚ Andï¼Œ first of allï¼Œ we import torchï¼Œ of courseã€‚

Then we create our vector or tenorã€‚ So we say x equals torch dot tenorã€‚ and this is1ã€‚

 and then our y equals torch dot tenorã€‚With twoã€‚And then our initial weight is a tenzorã€‚Alsoã€‚

 with oneã€‚So 1ã€‚0 to make it a floatã€‚ And hereï¼Œ and with our weightã€‚

 we are interested in the gradientã€‚ So we need to specify require Sc equals trueã€‚

And then we do the forward passã€‚And gets and compute the lossã€‚So we simply sayï¼Œ why hat equalsã€‚

W times xï¼Œ which is our functionã€‚ And then we say loss equals yã€‚Hatsã€‚Minusã€‚The actual yã€‚

 And then we square thisï¼Œ So we sayã€‚This to the power of twoã€‚And nowï¼Œ let's print our lossã€‚And seeã€‚

This is one in the beginningã€‚ And now we want to do the backward passã€‚ So let's do the backward passã€‚

 and pi touch will compute the local gradients automatically for us and also computes the backward pass automatically for usã€‚

 So the only thing that we have to call is say loss backwardã€‚

 So this is the whole gradient computationã€‚ And now our w has this dot Gr attributeã€‚

 And we can print thisã€‚ And now this is the first gradientã€‚

 in the after the first forward and backward passã€‚ And rememberï¼Œ this should be-2 in the beginningã€‚

 And here we see we have a tensor with -2ã€‚ So this is workingã€‚And the next steps would beã€‚

 for exampleï¼Œ Now we update our weightsï¼Œ and then we do the next forward and backward pass and do this for a couple of iterationsã€‚

And yeahï¼Œ that's how Beck propagation works and howï¼Œ and also how easy it is to use it in Pytorchã€‚

 And I hope you enjoyed this tutorialã€‚ Please subscribe to the channel and see you next timeï¼Œ byeã€‚ğŸ˜Šã€‚



![](img/84bf83ae2a8c01617b4cf06b2bc402cb_5.png)