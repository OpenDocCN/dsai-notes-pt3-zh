- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- åŸºäºPyTorchçš„åˆ†ç±»å®ç°
    - ShowMeAI - BV1cF411v7kC
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- åŸºäºPyTorchçš„åˆ†ç±»å®ç°
    - ShowMeAI - BV1cF411v7kC
- en: Let's do this manually and see how we can call our modelsã€‚ So in Pytorrchã€‚ when
    we do inferenceã€‚ we also want to say with torch dot no graã€‚ So this will disable
    the gradient trackingã€‚ I explain this in a lot of my tutorialsã€‚ So you can just
    have a look at them if you want to learn more about thisã€‚ And then we can call
    our model by saying outputs equalsã€‚ And then we call the modelã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ‰‹åŠ¨è¿›è¡Œæ­¤æ“ä½œï¼Œçœ‹çœ‹å¦‚ä½•è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨Pytorchä¸­ï¼Œå½“æˆ‘ä»¬è¿›è¡Œæ¨ç†æ—¶ï¼Œæˆ‘ä»¬è¿˜æƒ³è¯´ä½¿ç”¨torchç‚¹no gradã€‚è¿™å°†ç¦ç”¨æ¢¯åº¦è·Ÿè¸ªã€‚æˆ‘åœ¨å¾ˆå¤šæ•™ç¨‹ä¸­è§£é‡Šè¿‡è¿™ä¸€ç‚¹ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šï¼Œå¯ä»¥çœ‹çœ‹å®ƒä»¬ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´outputsç­‰äºæ¥è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚æ¥ç€æˆ‘ä»¬è°ƒç”¨æ¨¡å‹ã€‚
- en: And then here we use two asteriskã€‚ and then we unpack this batchã€‚ So if you
    remember hereã€‚ this is a dictionaryã€‚ And here basically with thisï¼Œ we just unpack
    these values in our dictionaryã€‚ So for tens offlowï¼Œ you don't do thisã€‚ So you
    just pass in the batch like thisã€‚ But for pytorrchã€‚ you have to unpack thisã€‚ And
    now we get the outputs of our modelã€‚ So let'sã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªæ˜Ÿå·ï¼Œç„¶åè§£åŒ…è¿™ä¸ªæ‰¹æ¬¡ã€‚å¦‚æœä½ è®°å¾—ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªå­—å…¸ã€‚åŸºæœ¬ä¸Šï¼Œé€šè¿‡è¿™ä¸ªï¼Œæˆ‘ä»¬åªæ˜¯è§£åŒ…äº†å­—å…¸ä¸­çš„å€¼ã€‚å¯¹äºTensorFlowï¼Œä½ ä¸éœ€è¦è¿™æ ·åšã€‚ä½ åªéœ€åƒè¿™æ ·ä¼ å…¥æ‰¹æ¬¡ã€‚ä½†å¯¹äºPytorchï¼Œä½ å¿…é¡»è§£åŒ…ã€‚ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†æ¨¡å‹çš„è¾“å‡ºã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬ç»§ç»­ã€‚
- en: '![](img/6f843910cc38c033063518b8167635a3_1.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_1.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_2.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_3.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_3.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_4.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_5.png)'
- en: Print the outputsã€‚ And as you might know thisï¼Œ these are just the raw valuesã€‚
    So to get the actual probabilities and the predictionsï¼Œ we can apply the soft
    maxã€‚ So let's say predictions equals torch or we also have this in F dot soft
    max and then here we say outputs dot logics and we want to do this along dimension
    equals1ã€‚ and let's also print the predictions and then let's do one more thingã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“å°è¾“å‡ºã€‚æ­£å¦‚ä½ æ‰€çŸ¥é“çš„ï¼Œè¿™äº›åªæ˜¯åŸå§‹å€¼ã€‚å› æ­¤ï¼Œä¸ºäº†è·å¾—å®é™…çš„æ¦‚ç‡å’Œé¢„æµ‹ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨soft maxã€‚å‡è®¾é¢„æµ‹ç­‰äºtorchï¼Œæˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨Fç‚¹soft
    maxä¸­ä½¿ç”¨ï¼Œç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬è¯´outputsç‚¹logicsï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ç»´åº¦ç­‰äº1ä¸Šè¿›è¡Œæ­¤æ“ä½œã€‚æ¥ç€æˆ‘ä»¬ä¹Ÿæ‰“å°é¢„æµ‹ï¼Œç„¶åå†åšä¸€ä»¶äº‹ã€‚
- en: So let's also get the labels labels equals and we just get this by taking the
    prediction with the the index with the highest probabilitiesã€‚ So we get this by
    saying torch dot arc max and we can either put in the predictions orã€‚![](img/6f843910cc38c033063518b8167635a3_7.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬ä¹Ÿè·å–æ ‡ç­¾ï¼Œlabelsç­‰äºï¼Œæˆ‘ä»¬åªéœ€é€šè¿‡è·å–å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç´¢å¼•çš„é¢„æµ‹æ¥è·å–è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥æˆ‘ä»¬é€šè¿‡è¯´torchç‚¹argmaxæ¥è·å¾—è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©è¾“å…¥é¢„æµ‹æˆ–ã€‚![](img/6f843910cc38c033063518b8167635a3_7.png)
- en: '![](img/6f843910cc38c033063518b8167635a3_8.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_8.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_9.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_9.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_10.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_10.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_11.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_11.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_12.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_12.png)'
- en: We can put in the outputs and actually don't need thisã€‚ but just for demonstration
    let's use the predictions and then again dimension equals one and then let's print
    the labels as well and now let's actually do one more thing So let's convert the
    labels by saying labels equals and then we use list comprehension and call model
    dot config dot I to label and then it needs the actual label ID and then we iterate
    so we say four label ID in labels to list and now what this does you will see
    this when we print this So we print the labels and now let's actuallyã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ”¾å…¥è¾“å‡ºï¼Œå®é™…ä¸Šä¸éœ€è¦è¿™ä¸ªï¼Œä½†ä¸ºäº†æ¼”ç¤ºæˆ‘ä»¬ä½¿ç”¨é¢„æµ‹ï¼Œç„¶åå†æ¬¡è®¾ç½®ç»´åº¦ç­‰äº1ï¼Œç„¶åä¹Ÿæ‰“å°æ ‡ç­¾ã€‚ç°åœ¨æˆ‘ä»¬å®é™…ä¸Šå†åšä¸€ä»¶äº‹ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬é€šè¿‡è¯´labelsç­‰äºæ¥è½¬æ¢æ ‡ç­¾ï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¹¶è°ƒç”¨modelç‚¹configç‚¹Iåˆ°labelï¼Œç„¶åå®ƒéœ€è¦å®é™…çš„æ ‡ç­¾IDï¼Œæˆ‘ä»¬è¿­ä»£ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´for
    label ID in labels to listã€‚ç°åœ¨ä½ ä¼šçœ‹åˆ°è¿™åœ¨æ‰“å°æ—¶å‘ç”Ÿäº†ä»€ä¹ˆã€‚æˆ‘ä»¬æ‰“å°æ ‡ç­¾ï¼Œç°åœ¨è®©æˆ‘ä»¬å®é™…ä¸Šã€‚
- en: '![](img/6f843910cc38c033063518b8167635a3_14.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_14.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_15.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_15.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_16.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_16.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_17.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_17.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_18.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_18.png)'
- en: R this and see if this worksã€‚ Alrightï¼Œ so this worksã€‚ So as you can see hereï¼Œ
    we print the outputã€‚ So these are our outputã€‚ This is a sequence classifier outputã€‚
    And as you seeã€‚ it has the launchets argumentã€‚ So that's why we used outputs dot
    launchetã€‚ğŸ˜Šã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Rè¿™ä¸ªçœ‹çœ‹æ˜¯å¦æœ‰æ•ˆã€‚å¥½çš„ï¼Œè¿™ä¸ªæœ‰æ•ˆã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬æ‰“å°äº†è¾“å‡ºã€‚è¿™æ˜¯æˆ‘ä»¬çš„è¾“å‡ºã€‚è¿™æ˜¯ä¸€ä¸ªåºåˆ—åˆ†ç±»å™¨çš„è¾“å‡ºã€‚æ­£å¦‚ä½ æ‰€è§ï¼Œå®ƒæœ‰launchetså‚æ•°ã€‚è¿™å°±æ˜¯æˆ‘ä»¬ä¸ºä»€ä¹ˆä½¿ç”¨outputs.dot.launchetã€‚ğŸ˜Šã€‚
- en: '![](img/6f843910cc38c033063518b8167635a3_20.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_20.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_21.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_21.png)'
- en: And then we get the actual probabilitiesã€‚ and then to get the labelsã€‚ we used
    Arcmã€‚ So this is a tensza with the label1 and the label 0ã€‚ And then we converted
    each label to the actual class name and then we get positive and negativeã€‚ So
    by the wayï¼Œ this functionï¼Œ I think is only dedicated to a auto model for sequence
    classificationã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¾—åˆ°äº†å®é™…çš„æ¦‚ç‡ã€‚ä¸ºäº†è·å–æ ‡ç­¾ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†Arcmã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ ‡ç­¾1å’Œæ ‡ç­¾0çš„tensorã€‚ç„¶åæˆ‘ä»¬å°†æ¯ä¸ªæ ‡ç­¾è½¬æ¢ä¸ºå®é™…çš„ç±»åï¼Œç„¶åå¾—åˆ°äº†æ­£å’Œè´Ÿã€‚é¡ºä¾¿æä¸€ä¸‹ï¼Œè¿™ä¸ªå‡½æ•°ï¼Œæˆ‘è®¤ä¸ºåªé€‚ç”¨äºåºåˆ—åˆ†ç±»çš„è‡ªåŠ¨æ¨¡å‹ã€‚
- en: For exampleï¼Œ if we just use a auto modelï¼Œ Then I think it won't be availableã€‚
    So that's what these more concrete classes will do for youã€‚ it gives you a little
    bit more functionality for the dedicated taskã€‚ So we see that the loss is none
    in this caseã€‚ So if you also want to have a loss that we want to inspectã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åªä½¿ç”¨ä¸€ä¸ªè‡ªåŠ¨æ¨¡å‹ï¼Œé‚£ä¹ˆæˆ‘è®¤ä¸ºå®ƒå°†ä¸å¯ç”¨ã€‚è¿™å°±æ˜¯è¿™äº›æ›´å…·ä½“çš„ç±»ä¼šä¸ºä½ åšçš„äº‹æƒ…ã€‚å®ƒä¸ºç‰¹å®šä»»åŠ¡æä¾›äº†æ›´å¤šçš„åŠŸèƒ½ã€‚å› æ­¤æˆ‘ä»¬çœ‹åˆ°åœ¨è¿™ç§æƒ…å†µä¸‹æŸå¤±ä¸ºé›¶ã€‚å¦‚æœä½ è¿˜æƒ³æœ‰ä¸€ä¸ªæŸå¤±å¯ä»¥æ£€æŸ¥ã€‚
- en: Then we can give the loss or theã€‚ğŸ˜Šã€‚![](img/6f843910cc38c033063518b8167635a3_23.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥ç»™å‡ºæŸå¤±æˆ–è€…ã€‚ğŸ˜Šã€‚![](img/6f843910cc38c033063518b8167635a3_23.png)
- en: '![](img/6f843910cc38c033063518b8167635a3_24.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_24.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_25.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_25.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_26.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_26.png)'
- en: Not the lossï¼Œ but the labels argument to our model that it knows how to compute
    the lossã€‚ So we say labelsã€‚ and then we create a torch dot tenor by saying torch
    dot tenorã€‚ And then as a listï¼Œ we give it the labels1 and 0ã€‚ And now let's run
    this againã€‚ And then you should see that we should see a loss hereã€‚ And yetï¼Œ now
    here we see the lossã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ˜¯æŸå¤±ï¼Œè€Œæ˜¯æˆ‘ä»¬æ¨¡å‹çš„æ ‡ç­¾å‚æ•°ï¼Œå®ƒçŸ¥é“å¦‚ä½•è®¡ç®—æŸå¤±ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´æ ‡ç­¾ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡torch.dot.tenoråˆ›å»ºä¸€ä¸ªtorch.tensorã€‚ç„¶åä½œä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œæˆ‘ä»¬ç»™å®ƒæ ‡ç­¾1å’Œ0ã€‚ç°åœ¨è®©æˆ‘ä»¬å†æ¬¡è¿è¡Œè¿™ä¸ªã€‚ç„¶åä½ åº”è¯¥çœ‹åˆ°æˆ‘ä»¬åœ¨è¿™é‡Œåº”è¯¥çœ‹åˆ°ä¸€ä¸ªæŸå¤±ã€‚ç°åœ¨ï¼Œè¿™é‡Œæˆ‘ä»¬çœ‹åˆ°äº†æŸå¤±ã€‚
- en: And againï¼Œ this labels argument isï¼Œ I think special to this automod for sequence
    classificationã€‚![](img/6f843910cc38c033063518b8167635a3_28.png)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¼ºè°ƒï¼Œè¿™ä¸ªæ ‡ç­¾å‚æ•°ï¼Œæˆ‘è®¤ä¸ºæ˜¯ä¸“é—¨é’ˆå¯¹è¿™ä¸ªåºåˆ—åˆ†ç±»çš„automodã€‚![](img/6f843910cc38c033063518b8167635a3_28.png)
- en: '![](img/6f843910cc38c033063518b8167635a3_29.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_29.png)'
- en: Soï¼Œ yeahï¼Œ this workedã€‚ And now if we have a careful look at the probabilitiesã€‚
    So first of allã€‚ we see we get label positive and negativeã€‚ and here for the first
    oneã€‚ This is the highest probabilã€‚ So 9ã€‚997ã€‚ And here for the second oneï¼Œ this
    is the largest numberã€‚ So it took this oneã€‚ And this is 5ã€‚30ã€‚ So if we compare
    them with the results that we got from our pipelineã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™æ ·åšæœ‰æ•ˆã€‚ç°åœ¨å¦‚æœä»”ç»†çœ‹çœ‹æ¦‚ç‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬çœ‹åˆ°æ ‡ç­¾ä¸ºæ­£å’Œè´Ÿã€‚è¿™é‡Œç¬¬ä¸€ä¸ªçš„æ¦‚ç‡æ˜¯æœ€é«˜çš„ã€‚æ˜¯9.997ã€‚ç¬¬äºŒä¸ªçš„æ¦‚ç‡æ˜¯æœ€å¤§çš„ã€‚æ‰€ä»¥é€‰æ‹©äº†è¿™ä¸ªã€‚å®ƒæ˜¯5.30ã€‚å¦‚æœæˆ‘ä»¬å°†å®ƒä»¬ä¸æˆ‘ä»¬ä»ç®¡é“ä¸­è·å¾—çš„ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚
- en: Then we see these are exactly the same numbersã€‚ So now you might see what's
    the difference between a pipeline and using tokenizer and model directlyã€‚ So with
    the pipelineï¼Œ we only need two lines of codeã€‚ And then we actually get what we
    wantã€‚ So we get the label and we get the score we are interested inã€‚ So this might
    be just fineï¼Œ butã€‚ğŸ˜Šã€‚Yeah if you want to do it manually you can do it like I showed
    you and you will get the same results that you can then useã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å‘ç°è¿™äº›æ•°å­—å®Œå…¨ç›¸åŒã€‚ç°åœ¨ä½ å¯èƒ½ä¼šçœ‹åˆ°ç®¡é“å’Œç›´æ¥ä½¿ç”¨åˆ†è¯å™¨ä¸æ¨¡å‹ä¹‹é—´çš„åŒºåˆ«ã€‚ä½¿ç”¨ç®¡é“æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸¤è¡Œä»£ç ã€‚ç„¶åæˆ‘ä»¬å®é™…ä¸Šå¾—åˆ°äº†æˆ‘ä»¬æƒ³è¦çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æ ‡ç­¾å’Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„åˆ†æ•°ã€‚è¿™å¯èƒ½æ˜¯å¯ä»¥çš„ï¼Œä½†æ˜¯ã€‚ğŸ˜Šã€‚å¦‚æœä½ æƒ³æ‰‹åŠ¨æ“ä½œï¼Œä½ å¯ä»¥åƒæˆ‘å±•ç¤ºçš„é‚£æ ·åšï¼Œä½ å°†å¾—åˆ°ç›¸åŒçš„ç»“æœï¼Œç„¶åå¯ä»¥ä½¿ç”¨ã€‚
- en: So yeahï¼Œ that's how you can use a model and a tokenizer and yeah so using the
    model and the tokenizer will be important when you for example want to find tune
    in your model so I will show you roughly how to do this later but yeah so this
    is how you use model and tokenizer and let's just assume we did find tune in our
    modelã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™å°±æ˜¯ä½ å¦‚ä½•ä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚æ‰€ä»¥åœ¨ä½ æƒ³è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨æ˜¯éå¸¸é‡è¦çš„ã€‚å› æ­¤ï¼Œæˆ‘ç¨åä¼šå‘Šè¯‰ä½ å¤§è‡´å¦‚ä½•åšï¼Œä½†æ˜¯ï¼Œæ˜¯çš„ï¼Œè¿™å°±æ˜¯ä½ å¦‚ä½•ä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚æˆ‘ä»¬å‡è®¾æˆ‘ä»¬åœ¨æ¨¡å‹ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚
- en: '![](img/6f843910cc38c033063518b8167635a3_31.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_31.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_32.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_32.png)'
- en: '![](img/6f843910cc38c033063518b8167635a3_33.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f843910cc38c033063518b8167635a3_33.png)'
