- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P19ï¼šL19-
    ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œåç§°åˆ†ç±» - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P19ï¼šL19-
    ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œåç§°åˆ†ç±» - ShowMeAI - BV12m4y1S7ix
- en: Heyï¼Œ guysï¼Œ welcomee to your new Pytorch tutorialã€‚ Todayã€‚ we will be talking
    about recurrent neural nets or short Rn Nsã€‚ I will briefly explain the theory
    behind Rn Ns and the different kind of applicationsã€‚ and then we will implement
    a Rn N from scratch in Pytorarch to do name classificationã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°ä½ ä»¬æ–°çš„ Pytorch æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¾ªç¯ç¥ç»ç½‘ç»œï¼Œç®€ç§° RnNsã€‚æˆ‘å°†ç®€è¦è§£é‡Š RnNs èƒŒåçš„ç†è®ºå’Œä¸åŒçš„åº”ç”¨ï¼Œç„¶åæˆ‘ä»¬å°†åœ¨
    Pytorch ä¸­ä»å¤´å¼€å§‹å®ç°ä¸€ä¸ª RnN æ¥è¿›è¡Œåç§°åˆ†ç±»ã€‚
- en: This should give you a good understanding of how Rn Ns work internallyã€‚ So let's
    startã€‚ Rn Ns are a class of neural networks that allow previous outputs to be
    used as inputs while having hidden statesã€‚ Here's an image that shows the architecture
    of Rn Ns in the simplest wayã€‚ So we have an input and then internally do some
    operations and get hidden statesã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åº”è¯¥èƒ½è®©ä½ å¾ˆå¥½åœ°ç†è§£ RnNs çš„å†…éƒ¨å·¥ä½œåŸç†ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚RnNs æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå…è®¸å°†ä¹‹å‰çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼ŒåŒæ—¶æ‹¥æœ‰éšè—çŠ¶æ€ã€‚è¿™é‡Œæœ‰ä¸€å¼ ä»¥æœ€ç®€å•çš„æ–¹å¼å±•ç¤º
    RnNs æ¶æ„çš„å›¾åƒã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥ï¼Œç„¶ååœ¨å†…éƒ¨è¿›è¡Œä¸€äº›æ“ä½œï¼Œå¾—åˆ°éšè—çŠ¶æ€ã€‚
- en: And then we take those hidden states and put them back into the next stepã€‚ğŸ˜Šã€‚So
    we can use the previous knowledge to update our new stateã€‚ And then at the endã€‚
    we also get an outputã€‚ So we can also unfold this graph to get a better understanding
    and basically we are working with a sequence hereã€‚ Soï¼Œ for exampleï¼Œ if we have
    a whole sentenceï¼Œ then we might use every single word as one inputã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è¿™äº›éšè—çŠ¶æ€æ”¾å›åˆ°ä¸‹ä¸€æ­¥ã€‚ğŸ˜Š æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ä¹‹å‰çš„çŸ¥è¯†æ›´æ–°æˆ‘ä»¬çš„æ–°çŠ¶æ€ã€‚æœ€åï¼Œæˆ‘ä»¬ä¹Ÿä¼šå¾—åˆ°ä¸€ä¸ªè¾“å‡ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å±•å¼€è¿™ä¸ªå›¾ï¼Œè·å¾—æ›´å¥½çš„ç†è§£ï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†çš„æ˜¯ä¸€ä¸ªåºåˆ—ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªå®Œæ•´çš„å¥å­ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå°†æ¯ä¸€ä¸ªå•è¯ä½œä¸ºä¸€ä¸ªè¾“å…¥ã€‚
- en: So we have the first input and some initial hiddenã€‚ and then we do our operations
    and get the output and a new hidden state and then we use this hidden state and
    then put it into the next inputã€‚ So we take the next input and use the previous
    hidden states and againã€‚ do our operations and get a new output and the new updated
    hidden stateã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æœ‰ç¬¬ä¸€ä¸ªè¾“å…¥å’Œä¸€äº›åˆå§‹éšè—çŠ¶æ€ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œæ“ä½œï¼Œå¾—åˆ°è¾“å‡ºå’Œæ–°çš„éšè—çŠ¶æ€ï¼Œå†å°†è¿™ä¸ªéšè—çŠ¶æ€æ”¾å…¥ä¸‹ä¸€ä¸ªè¾“å…¥ä¸­ã€‚æ¥ç€ï¼Œæˆ‘ä»¬è·å–ä¸‹ä¸€ä¸ªè¾“å…¥ï¼Œåˆ©ç”¨ä¹‹å‰çš„éšè—çŠ¶æ€ï¼Œå†æ¬¡è¿›è¡Œæ“ä½œï¼Œå¾—åˆ°æ–°çš„è¾“å‡ºå’Œæ›´æ–°åçš„éšè—çŠ¶æ€ã€‚
- en: And then we take the next input and so onã€‚ So this is basically the architecture
    ofã€‚RNAnd now why are R&N so important And for this there is a nice article by
    And Carpathyã€‚ The article is called the unreasonable effectiveness of recurrent
    neural networks and I highly recommend to give this a readã€‚ so I will put the
    link in the descriptionã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ç»§ç»­è·å–ä¸‹ä¸€ä¸ªè¾“å…¥ï¼Œå¦‚æ­¤åå¤ã€‚è¿™åŸºæœ¬ä¸Šå°±æ˜¯ RnN çš„æ¶æ„ã€‚é‚£ä¹ˆ RnN ä¸ºä»€ä¹ˆå¦‚æ­¤é‡è¦å‘¢ï¼Ÿå¯¹æ­¤æœ‰ä¸€ç¯‡ç”± And Carpathy æ’°å†™çš„ç²¾å½©æ–‡ç« ã€‚æ–‡ç« åä¸ºã€Šå¾ªç¯ç¥ç»ç½‘ç»œçš„ä¸åˆç†æœ‰æ•ˆæ€§ã€‹ï¼Œæˆ‘å¼ºçƒˆå»ºè®®å¤§å®¶é˜…è¯»ä¸€ä¸‹ï¼Œå› æ­¤æˆ‘ä¼šå°†é“¾æ¥æ”¾åœ¨æè¿°ä¸­ã€‚
- en: '![](img/67851926e9649c02f2608968bb25321d_1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67851926e9649c02f2608968bb25321d_1.png)'
- en: But the core takeaway is that R and ends are so exciting because they allow
    us to operate over sequences of vectorsã€‚ So with traditional neural netsï¼Œ we have
    just a one to one relationshipï¼Œ for exampleã€‚ when we do image classificationã€‚ğŸ˜Šï¼ŒThen
    our inputã€‚ So our image is of fixed lengthã€‚ and our also our output is of fixed
    lengthã€‚And now with R and endsï¼Œ we can work with sequencesã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ ¸å¿ƒè¦ç‚¹æ˜¯ RnN éå¸¸ä»¤äººå…´å¥‹ï¼Œå› ä¸ºå®ƒä»¬å…è®¸æˆ‘ä»¬åœ¨å‘é‡åºåˆ—ä¸Šè¿›è¡Œæ“ä½œã€‚ä¸ä¼ ç»Ÿç¥ç»ç½‘ç»œä»…å…·æœ‰ä¸€å¯¹ä¸€å…³ç³»ä¸åŒï¼Œä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬è¿›è¡Œå›¾åƒåˆ†ç±»æ—¶ã€‚ğŸ˜Š é‚£æ—¶æˆ‘ä»¬çš„è¾“å…¥ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬çš„å›¾åƒï¼Œæ˜¯å›ºå®šé•¿åº¦çš„ï¼Œè¾“å‡ºä¹Ÿæ˜¯å›ºå®šé•¿åº¦çš„ã€‚è€Œç°åœ¨é€šè¿‡
    RnNï¼Œæˆ‘ä»¬å¯ä»¥å¤„ç†åºåˆ—ã€‚
- en: and there are a lot of different typesã€‚ So basicallyï¼Œ we can have a sequence
    in our inputã€‚ and we can also have a sequence in our output or also in both input
    and outputã€‚ Soï¼Œ for exampleã€‚ we can have a one to many relationship where we have
    only one inputï¼Œ for exampleã€‚ this is used in image captioning when we have one
    in image and then we want to describe what we see in the image and get multiple
    outputsã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰å¾ˆå¤šä¸åŒç±»å‹çš„å…³ç³»ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¾“å…¥ä¸­æœ‰ä¸€ä¸ªåºåˆ—ï¼Œåœ¨è¾“å‡ºä¸­ä¹Ÿæœ‰ä¸€ä¸ªåºåˆ—ï¼Œæˆ–è€…åœ¨è¾“å…¥å’Œè¾“å‡ºä¸­éƒ½æœ‰ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ä¸€ä¸ªå¯¹å¤šçš„å…³ç³»ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªè¾“å…¥ï¼Œä¾‹å¦‚ï¼Œè¿™åœ¨å›¾åƒæè¿°ä¸­ä½¿ç”¨ï¼Œå½“æˆ‘ä»¬æœ‰ä¸€å¼ å›¾åƒæ—¶ï¼Œç„¶åæƒ³è¦æè¿°æˆ‘ä»¬åœ¨å›¾åƒä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œå¹¶å¾—åˆ°å¤šä¸ªè¾“å‡ºã€‚
- en: Then we can also have a many to one relationshipã€‚ So we have this isï¼Œ for exampleã€‚
    the case in sentiment classificationï¼Œ or what we are doing later with our name
    classificationã€‚ So we have a sequence as inputsï¼Œ and then apply our R and Nã€‚ and
    then we use the last output and do some classification with thisã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¹Ÿå¯ä»¥æœ‰å¤šå¯¹ä¸€çš„å…³ç³»ã€‚ä¾‹å¦‚ï¼Œåœ¨æƒ…æ„Ÿåˆ†ç±»ä¸­å°±æ˜¯è¿™ç§æƒ…å†µï¼Œæˆ–è€…æˆ‘ä»¬ç¨ååœ¨åç§°åˆ†ç±»ä¸­æ‰€åšçš„ã€‚å› æ­¤æˆ‘ä»¬å°†åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œç„¶ååº”ç”¨æˆ‘ä»¬çš„ RnNï¼Œæ¥ç€ä½¿ç”¨æœ€åçš„è¾“å‡ºè¿›è¡Œåˆ†ç±»ã€‚
- en: Then we can also have a many to many relationshipã€‚ This isï¼Œ for exampleã€‚ used
    in machine translation where we have a whole sentenceï¼Œ for exampleï¼Œ in English
    as an inputã€‚ And then we put out a whole sentence in Frenchï¼Œ for exampleã€‚Then
    we can also have a many to many relationship with a synct wayï¼Œ for exampleã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¹Ÿå¯ä»¥æœ‰å¤šå¯¹å¤šçš„å…³ç³»ã€‚è¿™æ˜¯åœ¨æœºå™¨ç¿»è¯‘ä¸­ä½¿ç”¨çš„ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå®Œæ•´çš„å¥å­ï¼Œå‡è®¾æ˜¯è‹±è¯­ä½œä¸ºè¾“å…¥ã€‚ç„¶åæˆ‘ä»¬è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„æ³•è¯­å¥å­ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»¥åŒæ­¥æ–¹å¼å»ºç«‹å¤šå¯¹å¤šçš„å…³ç³»ã€‚
- en: in video classificationï¼Œ where we want to classify each single frameã€‚ So yeahã€‚
    these are our possible applications of R andNsã€‚ So they are mostly used in the
    fields of natural language processing and speech recognitionã€‚ but they couldï¼Œ
    for exampleï¼Œ also used for image classificationã€‚ So yeahã€‚ that's what makes RnNs
    so powerfulã€‚ And now let's have a brief look at some pros and consã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è§†é¢‘åˆ†ç±»ä¸­ï¼Œæˆ‘ä»¬æƒ³å¯¹æ¯ä¸€å¸§è¿›è¡Œåˆ†ç±»ã€‚è¿™äº›å°±æ˜¯ R å’Œ RNN çš„å¯èƒ½åº”ç”¨ã€‚å› æ­¤ï¼Œå®ƒä»¬ä¸»è¦ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«é¢†åŸŸï¼Œä½†å®ƒä»¬ä¹Ÿå¯ä»¥ç”¨äºå›¾åƒåˆ†ç±»ã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯
    RNN çš„å¼ºå¤§ä¹‹å¤„ã€‚ç°åœ¨æˆ‘ä»¬ç®€å•çœ‹ä¸€ä¸‹å®ƒçš„ä¸€äº›ä¼˜ç¼ºç‚¹ã€‚
- en: So the advantages are that we have the possibility of processing inputs of any
    lengthã€‚Then our model size is not increasing with the size of the inputã€‚ Then
    the computation takes into account historical informationã€‚ So the previous dataã€‚And
    our weights are shared across timeã€‚And some drawbacks are that the computation
    might be slowered and with normal neural netsã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜åŠ¿åœ¨äºæˆ‘ä»¬å¯ä»¥å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥ã€‚ç„¶åæˆ‘ä»¬çš„æ¨¡å‹å¤§å°ä¸ä¼šéšç€è¾“å…¥å¤§å°çš„å¢åŠ è€Œå¢åŠ ã€‚è®¡ç®—è€ƒè™‘äº†å†å²ä¿¡æ¯ã€‚å› æ­¤ï¼Œå…ˆå‰çš„æ•°æ®ã€‚æˆ‘ä»¬çš„æƒé‡åœ¨æ—¶é—´ä¸Šæ˜¯å…±äº«çš„ã€‚ä¸€äº›ç¼ºç‚¹æ˜¯ï¼Œè®¡ç®—å¯èƒ½ä¼šæ¯”æ™®é€šç¥ç»ç½‘ç»œæ…¢ã€‚
- en: and it can be difficult to access information from a long time agoã€‚ and we are
    also not able to consider any future input for the current stateã€‚ So yeahã€‚ that's
    basically the theory behind R andNsã€‚ And now we can directly jump to the codeã€‚
    So in our exampleï¼Œ we want to do name classificationsã€‚ So I downloaded the dataã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å¾ˆä¹…ä»¥å‰è·å–ä¿¡æ¯å¯èƒ½ä¼šå¾ˆå›°éš¾ã€‚è€Œä¸”æˆ‘ä»¬ä¹Ÿæ— æ³•è€ƒè™‘ä»»ä½•å¯¹å½“å‰çŠ¶æ€çš„æœªæ¥è¾“å…¥ã€‚æ‰€ä»¥ï¼ŒåŸºæœ¬ä¸Šè¿™å°±æ˜¯ R å’Œ RNN çš„ç†è®ºã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ç›´æ¥è·³åˆ°ä»£ç éƒ¨åˆ†ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æƒ³è¿›è¡Œå§“ååˆ†ç±»ã€‚å› æ­¤æˆ‘ä¸‹è½½äº†æ•°æ®ã€‚
- en: and I will also put the link in the descriptionã€‚ So basically we have different
    files with different namesã€‚ So these are all last names from different countriesï¼Œ
    for exampleã€‚ We have Arabic Chinese C Dutch English and so onã€‚ So I think these
    are 18 different countriesã€‚ And now we whatã€‚We want to do is we want to classify
    this and detect from which country the name is and what we are going to do here
    is we take the whole name as a sequence and then we use each single letter and
    put it in our R&N as one inputã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹Ÿä¼šæŠŠé“¾æ¥æ”¾åœ¨æè¿°ä¸­ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬æœ‰ä¸åŒæ–‡ä»¶ï¼Œæ–‡ä»¶åä¹Ÿä¸åŒã€‚è¿™äº›éƒ½æ˜¯æ¥è‡ªä¸åŒå›½å®¶çš„å§“æ°ï¼Œä¾‹å¦‚ï¼šé˜¿æ‹‰ä¼¯ã€ä¸­æ–‡ã€è·å…°æ–‡ã€è‹±æ–‡ç­‰ç­‰ã€‚æˆ‘è®¤ä¸ºè¿™äº›æ¥è‡ª18ä¸ªä¸åŒå›½å®¶ã€‚ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯åˆ†ç±»å¹¶æ£€æµ‹è¿™ä¸ªåå­—æ¥è‡ªå“ªä¸ªå›½å®¶ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡ŒæŠŠæ•´ä¸ªåå­—ä½œä¸ºä¸€ä¸ªåºåˆ—ï¼Œç„¶åä½¿ç”¨æ¯ä¸ªå•ç‹¬çš„å­—æ¯ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªè¾“å…¥æ”¾å…¥æˆ‘ä»¬çš„
    RNN ä¸­ã€‚
- en: And for thisï¼Œ we need some help of functionsã€‚ So I already implemented them
    hereã€‚ and I will only go briefly through this codeã€‚ So what we want to do here
    firstã€‚ we want to have a help of function to convert our data to ASIã€‚ for exampleã€‚
    if we have this name with some special charactersã€‚ and then we process thisã€‚ So
    let's run this fileã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›å‡½æ•°çš„å¸®åŠ©ã€‚æˆ‘å·²ç»åœ¨è¿™é‡Œå®ç°äº†å®ƒä»¬ï¼Œæˆ‘å°†ç®€è¦ä»‹ç»è¿™æ®µä»£ç ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œé¦–å…ˆè¦åšçš„æ˜¯ä½¿ç”¨ä¸€ä¸ªè¾…åŠ©å‡½æ•°å°†æˆ‘ä»¬çš„æ•°æ®è½¬æ¢ä¸º ASCIIã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰è¿™ä¸ªå¸¦æœ‰ç‰¹æ®Šå­—ç¬¦çš„åå­—ï¼Œç„¶åæˆ‘ä»¬å¤„ç†å®ƒã€‚è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªæ–‡ä»¶ã€‚
- en: Then we see it remove the special characters and we only have ASI characters
    leftã€‚ and basicallyã€‚ we also print all the possible lettersã€‚ So this is from a
    to C and also in capital lettersã€‚ and we also allow these signsã€‚ğŸ˜Šï¼ŒAnd then we
    have a helper function to load the dataã€‚ So this basically loads all those filesï¼Œ
    and then it loads all the namesã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬çœ‹åˆ°å®ƒå»é™¤äº†ç‰¹æ®Šå­—ç¬¦ï¼Œå‰©ä¸‹çš„åªæœ‰ ASCII å­—ç¬¦ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬è¿˜æ‰“å°äº†æ‰€æœ‰å¯èƒ½çš„å­—æ¯ã€‚è¿™æ˜¯ä» a åˆ° c ä»¥åŠå¤§å†™å­—æ¯ã€‚æˆ‘ä»¬è¿˜å…è®¸è¿™äº›ç¬¦å·ã€‚ğŸ˜Šç„¶åæˆ‘ä»¬æœ‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥åŠ è½½æ•°æ®ã€‚è¿™åŸºæœ¬ä¸ŠåŠ è½½äº†æ‰€æœ‰è¿™äº›æ–‡ä»¶ï¼Œç„¶ååŠ è½½äº†æ‰€æœ‰çš„åå­—ã€‚
- en: and it gets the country from the file nameã€‚ So this is what the load data function
    will doã€‚And then we have some functions to turn our data to Tenzoã€‚ So we have
    letter to index and letter to Tzo and also a line to atenzoã€‚ And what we are doing
    here is we are using a technique that is called one hot encodingã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»æ–‡ä»¶åä¸­è·å–å›½å®¶åã€‚è¿™å°±æ˜¯ load data å‡½æ•°çš„åŠŸèƒ½ã€‚ç„¶åæˆ‘ä»¬æœ‰ä¸€äº›å‡½æ•°å°†æ•°æ®è½¬æ¢ä¸ºå¼ é‡ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰å­—æ¯åˆ°ç´¢å¼•ã€å­—æ¯åˆ°å¼ é‡å’Œè¡Œåˆ°å¼ é‡çš„è½¬æ¢ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨äº†ä¸€ç§å«åšç‹¬çƒ­ç¼–ç çš„æŠ€æœ¯ã€‚
- en: So we need a way to display our data that can be used for trainingã€‚ And for
    thisã€‚ we use one hot encodingã€‚ So if you've watched my tutorial about the chatbot
    in Pyrã€‚ then you might already know thisã€‚So a one hot back vector is filled with
    zerosã€‚ except for a one at the index of the current letterã€‚ For exampleã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ç§æ˜¾ç¤ºæ•°æ®çš„æ–¹å¼ï¼Œä»¥ä¾¿ç”¨äºè®­ç»ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨**ç‹¬çƒ­ç¼–ç **ã€‚å¦‚æœä½ çœ‹è¿‡æˆ‘å…³äºPyrä¸­èŠå¤©æœºå™¨äººçš„æ•™ç¨‹ï¼Œä½ å¯èƒ½å·²ç»çŸ¥é“äº†è¿™ä¸€ç‚¹ã€‚ä¸€ä¸ªç‹¬çƒ­å‘é‡ç”¨é›¶å¡«å……ï¼Œé™¤äº†åœ¨å½“å‰å­—æ¯çš„ç´¢å¼•å¤„æœ‰ä¸€ä¸ª1ã€‚ä¾‹å¦‚ã€‚
- en: if we have only five possible charactersï¼Œ ABC D and Eã€‚ So our a would be a vector
    of length 5ã€‚ and we have a one at the position where a isã€‚ and the same for Bã€‚
    a vector of length 5 and the second index is a 1 and the rest zerosã€‚ So this is
    one hot encodingã€‚ So if we go back to our file for exampleï¼Œ I can show you how
    the load data function looksã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åªæœ‰äº”ä¸ªå¯èƒ½çš„å­—ç¬¦ï¼šAã€Bã€Cã€Då’ŒEã€‚é‚£ä¹ˆæˆ‘ä»¬çš„Aå°†æ˜¯é•¿åº¦ä¸º5çš„å‘é‡ï¼Œåœ¨Aæ‰€åœ¨çš„ä½ç½®ä¸Šæœ‰ä¸€ä¸ª1ï¼ŒBä¹Ÿæ˜¯åŒæ ·ï¼Œé•¿åº¦ä¸º5çš„å‘é‡ï¼Œç¬¬äºŒä¸ªç´¢å¼•ä¸º1ï¼Œå…¶ä½™ä¸º0ã€‚è¿™å°±æ˜¯ç‹¬çƒ­ç¼–ç ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬å›åˆ°æˆ‘ä»¬çš„æ–‡ä»¶ä¸­ï¼Œæˆ‘å¯ä»¥ç»™ä½ å±•ç¤º`load
    data`å‡½æ•°çš„æ ·å­ã€‚
- en: So this will return a dictionary with the country is keyã€‚ and then theã€‚Corresponding
    names as theã€‚Valueï¼Œ Soï¼Œ for exampleï¼Œ if we run this and have a look at the key
    Italian and only take the first five entriesã€‚ then we see we have five different
    Italian names hereã€‚Thenï¼Œ as I saidï¼Œ we do this one hot encodingã€‚ So for thisï¼Œ
    we can use the letter to tenor functionã€‚ So now if we run thisã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­å›½å®¶æ˜¯é”®ï¼Œç›¸åº”çš„åç§°æ˜¯å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªå¹¶æŸ¥çœ‹é”®`Italian`ï¼Œåªå–å‰äº”ä¸ªæ¡ç›®ï¼Œé‚£ä¹ˆæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œæœ‰äº”ä¸ªä¸åŒçš„æ„å¤§åˆ©åå­—ã€‚ç„¶åï¼Œæ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œæˆ‘ä»¬åšç‹¬çƒ­ç¼–ç ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`letter
    to tenor`å‡½æ•°ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªã€‚
- en: So let's save this and run this and then print the tenzo for chã€‚ Then we see
    it has this sizeã€‚ So this is of shape 1 by 57ï¼Œ because we have 57ã€‚Possible charactersã€‚
    This is what I printed hereã€‚ These are all the lettersã€‚ and then we have a cha
    at the position where the capital J isã€‚ So this is how our input will look like
    like laterã€‚ andï¼Œ of courseã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªå¹¶è¿è¡Œï¼Œç„¶åæ‰“å°`tenzo`ç»™`ch`ã€‚æˆ‘ä»¬çœ‹åˆ°å®ƒçš„å¤§å°ã€‚è¿™æ˜¯å½¢çŠ¶ä¸º1x57ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰57ä¸ªå¯èƒ½çš„å­—ç¬¦ã€‚è¿™æ˜¯æˆ‘åœ¨è¿™é‡Œæ‰“å°çš„ã€‚è¿™äº›éƒ½æ˜¯å­—æ¯ï¼Œç„¶åæˆ‘ä»¬åœ¨å¤§å†™Jçš„ä½ç½®æœ‰ä¸€ä¸ª`cha`ã€‚æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬çš„è¾“å…¥ç¨åä¼šæ˜¯ä»€ä¹ˆæ ·å­ï¼Œå½“ç„¶ã€‚
- en: we do this not only for a single characterï¼Œ but for the whole nameã€‚ So for thisã€‚
    we have the line to tensor functionã€‚ And now if we here we print the sizeã€‚ So
    this will be of size5 by  one by 57ã€‚ And the one is because our model expects
    it to be in this shapeã€‚And the5 is because of the number of characters and the
    57 is because of the number of all different charactersã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ä»…ä¸ºå•ä¸ªå­—ç¬¦åšè¿™ä¸ªï¼Œè€Œæ˜¯ä¸ºæ•´ä¸ªåç§°åšè¿™ä¸ªã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æœ‰`line to tensor`å‡½æ•°ã€‚ç°åœ¨å¦‚æœæˆ‘ä»¬åœ¨è¿™é‡Œæ‰“å°å¤§å°ã€‚è¿™å°†æ˜¯5x1x57çš„å¤§å°ã€‚1æ˜¯å› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹å¸Œæœ›å®ƒå‘ˆç°è¿™ç§å½¢çŠ¶ï¼Œè€Œ5æ˜¯å­—ç¬¦çš„æ•°é‡ï¼Œ57æ˜¯æ‰€æœ‰ä¸åŒå­—ç¬¦çš„æ•°é‡ã€‚
- en: Allrightï¼Œ so these are all the help or functions that we needã€‚ Andï¼Œ of courseã€‚
    I will put the code on Githubã€‚ and I also provide the link to the data so you
    can download these filesã€‚ So now we can start writing our R and Nã€‚ So for thisï¼Œ
    of courseï¼Œ we import the things we needã€‚ So we import torchã€‚ We import torch dot
    N N as N Nã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™äº›æ˜¯æˆ‘ä»¬éœ€è¦çš„æ‰€æœ‰å¸®åŠ©å‡½æ•°ã€‚å½“ç„¶ï¼Œæˆ‘ä¼šæŠŠä»£ç æ”¾åœ¨Githubä¸Šã€‚æˆ‘è¿˜æä¾›æ•°æ®çš„é“¾æ¥ï¼Œä»¥ä¾¿ä½ å¯ä»¥ä¸‹è½½è¿™äº›æ–‡ä»¶ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹ç¼–å†™æˆ‘ä»¬çš„**Rå’ŒN**ã€‚æ‰€ä»¥ä¸ºæ­¤ï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬å¯¼å…¥æˆ‘ä»¬éœ€è¦çš„ä¸œè¥¿ã€‚æˆ‘ä»¬å¯¼å…¥`torch`ã€‚æˆ‘ä»¬å¯¼å…¥`torch.nn`ä½œä¸º`NN`ã€‚
- en: Then I also want to import map plot Li dot pi plot S P L T because I want to
    show you a plot later mapã€‚Potã€‚Lipï¼Œ then we import our utility functionsã€‚ So I
    say from usã€‚ import all the different letters and also the number of different
    lettersã€‚ So this is 57ã€‚ Then we also say from uï¼Œ we want to import these helper
    functionsã€‚ So load dataã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘è¿˜æƒ³å¯¼å…¥`mapplotlib`å’Œ`plot`ï¼Œå› ä¸ºæˆ‘æƒ³ç¨åç»™ä½ å±•ç¤ºä¸€ä¸ªå›¾ã€‚æ¥ç€æˆ‘ä»¬å¯¼å…¥æˆ‘ä»¬çš„å®ç”¨å‡½æ•°ã€‚æˆ‘è¯´ä»`us`ä¸­å¯¼å…¥æ‰€æœ‰ä¸åŒçš„å­—æ¯ï¼Œä»¥åŠä¸åŒå­—æ¯çš„æ•°é‡ã€‚æ‰€ä»¥è¿™æ˜¯57ã€‚ç„¶åæˆ‘ä»¬è¿˜è¯´ä»`u`ä¸­å¯¼å…¥è¿™äº›å¸®åŠ©å‡½æ•°ã€‚æ‰€ä»¥åŠ è½½æ•°æ®ã€‚
- en: then letter to tenor and line to tensor and random trainingx exampleã€‚ So this
    is basically a functionã€‚That will do a random choice from those names and return
    the corresponding countryã€‚So now that we have thatï¼Œ we can start implementing
    our R and Nã€‚ So we need to have a class and call this R and Nã€‚ And this should
    inherit from Nã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå°†å­—æ¯è½¬æ¢ä¸ºå¼ é‡ï¼Œè¡Œè½¬æ¢ä¸ºå¼ é‡ä»¥åŠéšæœºè®­ç»ƒç¤ºä¾‹ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå°†ä»è¿™äº›åç§°ä¸­éšæœºé€‰æ‹©ï¼Œå¹¶è¿”å›ç›¸åº”çš„å›½å®¶ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å®ç°æˆ‘ä»¬çš„**Rå’ŒN**ã€‚æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªç±»ï¼Œç§°ä¸º**Rå’ŒN**ã€‚è¿™åº”è¯¥ä»**N**ç»§æ‰¿ã€‚
- en: N dot module as all of our Pytor modelsã€‚And by the wayã€‚ there is already a R
    andN module available in Pytch so you can directly use thisã€‚ but this is what
    we are doing in the next tutorialã€‚ So for now we want to implement this from scratch
    to get a better understanding So let's have a look at our model architecture again
    So this is what our R andN for name classification will look likeã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: N.dot moduleä½œä¸ºæˆ‘ä»¬æ‰€æœ‰çš„Pytoræ¨¡å‹ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼ŒPytchä¸­å·²ç»æœ‰ä¸€ä¸ªRå’ŒNæ¨¡å—å¯ç”¨ï¼Œæ‰€ä»¥ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªã€‚ä½†è¿™æ˜¯æˆ‘ä»¬åœ¨ä¸‹ä¸€ä¸ªæ•™ç¨‹ä¸­è¦åšçš„ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æƒ³ä»å¤´å¼€å§‹å®ç°è¿™ä¸ªï¼Œä»¥æ›´å¥½åœ°ç†è§£ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å†çœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹æ¶æ„ã€‚è¿™å°±æ˜¯æˆ‘ä»¬çš„Rå’ŒNç”¨äºåç§°åˆ†ç±»çš„æ ·å­ã€‚
- en: So we have an input and a hidden stateï¼Œ and then internally So this is what
    we are doing here internallyã€‚ so we combine them and then we process our combined
    Tensor and we apply two different hidden layersã€‚ so we have our input to a output
    and our input to a hidden layerã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥å’Œä¸€ä¸ªéšè—çŠ¶æ€ï¼Œç„¶ååœ¨å†…éƒ¨å¤„ç†ã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨å†…éƒ¨æ‰€åšçš„ã€‚æˆ‘ä»¬å°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œç„¶åå¤„ç†æˆ‘ä»¬çš„ç»„åˆå¼ é‡ï¼Œå¹¶åº”ç”¨ä¸¤ä¸ªä¸åŒçš„éšè—å±‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„è¾“å…¥è¿æ¥åˆ°è¾“å‡ºï¼Œæˆ‘ä»¬çš„è¾“å…¥è¿æ¥åˆ°ä¸€ä¸ªéšè—å±‚ã€‚
- en: '![](img/67851926e9649c02f2608968bb25321d_3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67851926e9649c02f2608968bb25321d_3.png)'
- en: '![](img/67851926e9649c02f2608968bb25321d_4.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67851926e9649c02f2608968bb25321d_4.png)'
- en: These are just two normal linear layers and then we get one hidden output and
    then we use this for the next input and we also get a output and since we are
    doing classificationã€‚ so a multiclass classification task we apply the softmax
    layer and then get the outputã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åªæ˜¯ä¸¤ä¸ªæ™®é€šçš„çº¿æ€§å±‚ï¼Œç„¶åæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªéšè—è¾“å‡ºï¼Œç„¶åæˆ‘ä»¬å°†å…¶ç”¨äºä¸‹ä¸€ä¸ªè¾“å…¥ï¼Œæˆ‘ä»¬è¿˜å¾—åˆ°ä¸€ä¸ªè¾“å‡ºï¼Œç”±äºæˆ‘ä»¬æ­£åœ¨è¿›è¡Œåˆ†ç±»ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªå¤šç±»åˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬åº”ç”¨softmaxå±‚ç„¶åå¾—åˆ°è¾“å‡ºã€‚
- en: So now this is what we want to implementã€‚So nowï¼Œ first of allï¼Œ of courseã€‚ we
    define our init functionã€‚ This will get selfã€‚ Then it gets the input sizeã€‚ It
    also gets the hidden sizeã€‚ this is going to be a hyperparmeter that we can specifyã€‚
    And we also get the output sizeã€‚ and in our in functionã€‚ Firstã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨è¿™æ˜¯æˆ‘ä»¬æƒ³è¦å®ç°çš„ã€‚å› æ­¤ï¼Œé¦–å…ˆï¼Œå½“ç„¶ã€‚æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„åˆå§‹åŒ–å‡½æ•°ã€‚è¿™å°†è·å¾—selfã€‚ç„¶åå®ƒè·å–è¾“å…¥å¤§å°ã€‚å®ƒè¿˜è·å–éšè—å¤§å°ï¼Œè¿™å°†æ˜¯æˆ‘ä»¬å¯ä»¥æŒ‡å®šçš„è¶…å‚æ•°ã€‚æˆ‘ä»¬è¿˜è·å–è¾“å‡ºå¤§å°ã€‚åœ¨æˆ‘ä»¬çš„åˆå§‹åŒ–å‡½æ•°ä¸­ï¼Œé¦–å…ˆã€‚
- en: we want to call the super R and N and selfã€‚ And then the in itã€‚ğŸ˜Šï¼ŒSorryã€‚In itã€‚Then
    here we want to store our hidden sizeã€‚ So we say self dot hidden size equals hidden
    sizeã€‚ Then we define our two different linear layersã€‚ So we call this input to
    hidden I to H equals N N dot linear and the size is the input size plus the hidden
    size because we combine themã€‚ And for thisï¼Œ the output size is still the hidden
    sizeã€‚ Then we do the same with our outputã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è°ƒç”¨super Rå’ŒNä»¥åŠselfã€‚ç„¶ååˆå§‹åŒ–ã€‚ğŸ˜Šï¼ŒæŠ±æ­‰ã€‚åˆå§‹åŒ–ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬æƒ³å­˜å‚¨æˆ‘ä»¬çš„éšè—å¤§å°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´self.dot hidden sizeç­‰äºhidden
    sizeã€‚ç„¶åæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬ä¸¤ä¸ªä¸åŒçš„çº¿æ€§å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸ºè¾“å…¥åˆ°éšè—Iåˆ°Hç­‰äºNN.dot linearï¼Œå¤§å°æ˜¯è¾“å…¥å¤§å°åŠ ä¸Šéšè—å¤§å°ï¼Œå› ä¸ºæˆ‘ä»¬å°†å®ƒä»¬ç»“åˆèµ·æ¥ã€‚å¯¹äºè¿™ä¸ªï¼Œè¾“å‡ºå¤§å°ä»ç„¶æ˜¯éšè—å¤§å°ã€‚ç„¶åæˆ‘ä»¬å¯¹è¾“å‡ºåšåŒæ ·çš„äº‹æƒ…ã€‚
- en: So we say input to outputã€‚ and this is going to be a linear layer as wellã€‚ So
    the input size is the sameã€‚ And here we use the output sizeã€‚ And then we also
    need a soft max layerã€‚ So we say self dot soft max equals N N dotã€‚Soft maxã€‚ And
    then we say that dimension equals long dimension 1ï¼Œ cause our inputï¼Œ for exampleã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´è¾“å…¥åˆ°è¾“å‡ºã€‚è¿™ä¹Ÿå°†æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ã€‚å› æ­¤è¾“å…¥å¤§å°æ˜¯ç›¸åŒçš„ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è¾“å‡ºå¤§å°ã€‚ç„¶åæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªsoftmaxå±‚ã€‚å› æ­¤æˆ‘ä»¬è¯´self.dot
    softmaxç­‰äºNN.dot softmaxã€‚ç„¶åæˆ‘ä»¬è¯´è¯¥ç»´åº¦ç­‰äºé•¿ç»´åº¦1ï¼Œå› ä¸ºæˆ‘ä»¬çš„è¾“å…¥ï¼Œä¾‹å¦‚ã€‚
- en: just test the shape 1 by 57ã€‚ We need the second dimensionã€‚So this is our init
    functionã€‚ Then weã€‚ of courseï¼Œ also have to define the forward passã€‚ So we say
    define the forward functionã€‚ and this gets selfã€‚ and then it gets an input tensorã€‚
    And as you should know nowã€‚ this also gets the hidden tensorã€‚ So we use the hidden
    tensor for the forward passã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€æµ‹è¯•å½¢çŠ¶ä¸º1 x 57ã€‚æˆ‘ä»¬éœ€è¦ç¬¬äºŒä¸ªç»´åº¦ã€‚è¿™æ˜¯æˆ‘ä»¬çš„åˆå§‹åŒ–å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬ï¼Œå½“ç„¶ï¼Œè¿˜éœ€è¦å®šä¹‰å‰å‘ä¼ æ’­ã€‚å› æ­¤æˆ‘ä»¬å®šä¹‰å‰å‘å‡½æ•°ã€‚å®ƒæ¥æ”¶selfï¼Œç„¶åè·å–ä¸€ä¸ªè¾“å…¥å¼ é‡ã€‚æ­£å¦‚ä½ ç°åœ¨åº”è¯¥çŸ¥é“çš„ï¼Œè¿™ä¹Ÿä¼šè·å–éšè—å¼ é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨éšè—å¼ é‡è¿›è¡Œå‰å‘ä¼ æ’­ã€‚
- en: And then here we process thisã€‚ So first thingï¼Œ let's have a look at this againã€‚
    we combine our input and our hidden tensorã€‚ And then we apply those linear layers
    and the soft marksã€‚ And then we return two different tensorã€‚ So the output tensor
    and the new hidden tensorã€‚So let's do thisã€‚ So let's call this combined equalsã€‚
    And for thisï¼Œ we can use torch dot catã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬å¤„ç†è¿™ä¸ªã€‚æ‰€ä»¥é¦–å…ˆï¼Œè®©æˆ‘ä»¬å†çœ‹ä¸€ä¸‹è¿™ä¸ªã€‚æˆ‘ä»¬å°†è¾“å…¥å’Œéšè—å¼ é‡ç»“åˆèµ·æ¥ã€‚ç„¶åæˆ‘ä»¬åº”ç”¨è¿™äº›çº¿æ€§å±‚å’Œsoftmaxã€‚ç„¶åæˆ‘ä»¬è¿”å›ä¸¤ä¸ªä¸åŒçš„å¼ é‡ã€‚æ‰€ä»¥è¾“å‡ºå¼ é‡å’Œæ–°çš„éšè—å¼ é‡ã€‚æˆ‘ä»¬æ¥åšè¿™ä¸ªã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºcombinedç­‰äºã€‚å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨torch.dot
    catã€‚
- en: And then as a tupleï¼Œ we want to combine the input tensor and the hidden tensorã€‚
    And here againã€‚ along dimension 1ã€‚ Then we apply our linear layerã€‚ So we say hidden
    equal self dot I to Hã€‚ And then here we put in the combinedã€‚Tensarï¼Œ then we say
    our output equals self dot I to Oã€‚O with our combined tensor as wellã€‚ And for
    the outputï¼Œ we also apply the soft maxã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½œä¸ºä¸€ä¸ªå…ƒç»„ï¼Œæˆ‘ä»¬æƒ³è¦ç»„åˆè¾“å…¥å¼ é‡å’Œéšè—å¼ é‡ã€‚åœ¨è¿™é‡Œå†æ¬¡æ²¿ç€ç»´åº¦1ã€‚ç„¶åæˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„çº¿æ€§å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´éšè—ç­‰äºself dot I to Hã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬æ”¾å…¥ç»„åˆåçš„å¼ é‡ï¼Œç„¶åæˆ‘ä»¬è¯´æˆ‘ä»¬çš„è¾“å‡ºç­‰äºself
    dot I to Oï¼ŒOä¸æˆ‘ä»¬çš„ç»„åˆå¼ é‡ã€‚å¯¹äºè¾“å‡ºï¼Œæˆ‘ä»¬ä¹Ÿåº”ç”¨soft maxã€‚
- en: So we say output equals self dot soft max with the outputã€‚ And at the endã€‚ we
    return the output first and then the new hidden stateã€‚And so this is basically
    all we need for our R and N implementationã€‚ And I'm also going to add a newã€‚ a
    little helper functionã€‚ And I call this in itã€‚Hiddenã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¯´outputç­‰äºself dot soft maxä¸è¾“å‡ºã€‚æœ€åï¼Œæˆ‘ä»¬å…ˆè¿”å›è¾“å‡ºï¼Œç„¶åè¿”å›æ–°çš„éšè—çŠ¶æ€ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯æˆ‘ä»¬Rå’ŒNå®ç°æ‰€éœ€çš„ä¸€åˆ‡ã€‚æˆ‘è¿˜è¦æ·»åŠ ä¸€ä¸ªæ–°çš„è¾…åŠ©å‡½æ•°ï¼Œæˆ‘ç§°ä¹‹ä¸ºinit
    hiddenã€‚
- en: so I need some initial hidden state in the beginningã€‚ And what I want to do
    here simply is I want to return an empty tensorã€‚ So I say torch dot zerosã€‚ And
    this has the shape 1 by self dot hidden sizeã€‚ And yeahï¼Œ so now we can start applying
    thisã€‚ So now let's load the dataã€‚ So let's say our categories lines and our all
    possible categories equals load dataã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘éœ€è¦ä¸€ä¸ªåˆå§‹çš„éšè—çŠ¶æ€ã€‚è¿™é‡Œæˆ‘æƒ³åšçš„å¾ˆç®€å•ï¼Œå°±æ˜¯è¿”å›ä¸€ä¸ªç©ºçš„å¼ é‡ã€‚æ‰€ä»¥æˆ‘è¯´torch dot zerosã€‚è¿™ä¸ªå¼ é‡çš„å½¢çŠ¶æ˜¯1ä¹˜ä»¥self dot
    hidden sizeã€‚æ˜¯çš„ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹åº”ç”¨å®ƒã€‚æ¥ä¸‹æ¥æˆ‘ä»¬åŠ è½½æ•°æ®ã€‚å‡è®¾æˆ‘ä»¬çš„ç±»åˆ«è¡Œå’Œæ‰€æœ‰å¯èƒ½çš„ç±»åˆ«ç­‰äºåŠ è½½æ•°æ®ã€‚
- en: So this is a dictionary with the country as key and the names as valuesã€‚ And
    this is just a list of all the different countriesã€‚ And then the number of categoryã€‚![](img/67851926e9649c02f2608968bb25321d_6.png)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªä»¥å›½å®¶ä¸ºé”®ã€åç§°ä¸ºå€¼çš„å­—å…¸ã€‚è¿™åªæ˜¯æ‰€æœ‰ä¸åŒå›½å®¶çš„åˆ—è¡¨ã€‚ç„¶åæ˜¯ç±»åˆ«çš„æ•°é‡ã€‚![](img/67851926e9649c02f2608968bb25321d_6.png)
- en: Gorries equals the length of all categoriesã€‚ For exampleï¼Œ we can print the number
    of categoriesã€‚ and let's save this for now and see if everything is workingã€‚ So
    let's say Python are an end on piã€‚And now this is workingã€‚ So we see we have8
    different categoriesã€‚ so this is because we have8 different files hereã€‚And now
    we need to define or set up our R and Nã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Gorriesç­‰äºæ‰€æœ‰ç±»åˆ«çš„é•¿åº¦ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰“å°ç±»åˆ«çš„æ•°é‡ã€‚æˆ‘ä»¬å…ˆä¿å­˜è¿™ä¸ªï¼Œçœ‹çœ‹ä¸€åˆ‡æ˜¯å¦æ­£å¸¸ã€‚å‡è®¾æˆ‘ä»¬ç”¨Pythonè¿è¡ŒRå’ŒNã€‚ç°åœ¨è¿™ä¸ªæ˜¯å¯è¡Œçš„ï¼Œæˆ‘ä»¬çœ‹åˆ°æœ‰8ä¸ªä¸åŒçš„ç±»åˆ«ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬æœ‰8ä¸ªä¸åŒçš„æ–‡ä»¶ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦å®šä¹‰æˆ–è®¾ç½®æˆ‘ä»¬çš„Rå’ŒNã€‚
- en: So we say R and Nã€‚Equalsï¼Œ and then we use our R and N classï¼Œ and this gets the
    input sizeã€‚ which is the number of possible lettersã€‚ Then it needs the hidden
    sizeã€‚ So N hiddenã€‚ and it needs the output sizeï¼Œ and this is the number of categoriesã€‚
    And now our hidden sizeã€‚ So N hidden is an hyperparmeter that we can defineã€‚ So
    hereï¼Œ let's try 128ã€‚And nowï¼Œ as an exampleã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´Rå’ŒNç­‰äºï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„Rå’ŒNç±»ï¼Œè¿™è·å–è¾“å…¥å¤§å°ï¼Œä¹Ÿå°±æ˜¯å¯èƒ½çš„å­—æ¯æ•°é‡ã€‚ç„¶åå®ƒéœ€è¦éšè—å¤§å°ã€‚æ‰€ä»¥N hiddenã€‚å®ƒéœ€è¦è¾“å‡ºå¤§å°ï¼Œä¹Ÿå°±æ˜¯ç±»åˆ«çš„æ•°é‡ã€‚ç°åœ¨æˆ‘ä»¬çš„éšè—å¤§å°ã€‚å› æ­¤ï¼ŒN
    hiddenæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°è¯•128ã€‚ç°åœ¨ï¼Œä½œä¸ºä¸€ä¸ªç¤ºä¾‹ã€‚
- en: let's do one single stepã€‚So we canï¼Œ for exampleï¼Œ say our input tensor equalsã€‚
    and then we use the letter to tensor function forï¼Œ let's sayï¼Œ for a and ourã€‚ then
    we need a hidden tensorã€‚ So hidden tensor equals R and N dot in it hidden and
    then we process thisã€‚ So we say output and next hidden equals R and N with the
    input tensor and the initial hidden tensorã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åšä¸€ä¸ªå•ç‹¬çš„æ­¥éª¤ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬çš„è¾“å…¥å¼ é‡ç­‰äºã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨å­—æ¯åˆ°å¼ é‡çš„å‡½æ•°ï¼Œæ¯”å¦‚è¯´å­—æ¯aï¼Œç„¶åæˆ‘ä»¬éœ€è¦ä¸€ä¸ªéšè—å¼ é‡ã€‚æ‰€ä»¥éšè—å¼ é‡ç­‰äºRå’ŒN dot
    init hiddenï¼Œç„¶åæˆ‘ä»¬å¤„ç†è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬è¯´outputå’Œä¸‹ä¸€ä¸ªéšè—çŠ¶æ€ç­‰äºRå’ŒNä¸è¾“å…¥å¼ é‡å’Œåˆå§‹éšè—å¼ é‡ã€‚
- en: And nowï¼Œ for exampleï¼Œ we could print the output size or shapeã€‚ And let's also
    print the next hidden shape or sizeã€‚ And let's run this and see if this is workingã€‚So
    yeahï¼Œ we see our N R and N applied the forward pass and we get a new output with
    this shape and a new hidden state with this shapeã€‚ So it's still the size of the
    defined hidden sizeã€‚ So this is how it works for only one characterã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰“å°è¾“å‡ºçš„å¤§å°æˆ–å½¢çŠ¶ã€‚æˆ‘ä»¬è¿˜æ‰“å°ä¸‹ä¸€ä¸ªéšè—çŠ¶æ€çš„å½¢çŠ¶æˆ–å¤§å°ã€‚è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œçœ‹çœ‹æ˜¯å¦æ­£å¸¸ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„N Rå’ŒNåº”ç”¨äº†å‰å‘ä¼ é€’ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæ–°è¾“å‡ºå’Œè¿™ä¸ªå½¢çŠ¶ï¼Œä»¥åŠä¸€ä¸ªæ–°çš„éšè—çŠ¶æ€å’Œè¿™ä¸ªå½¢çŠ¶ã€‚å› æ­¤ï¼Œè¿™ä»ç„¶æ˜¯å®šä¹‰çš„éšè—å¤§å°çš„å¤§å°ã€‚è¿™å°±æ˜¯å®ƒå¯¹äºå•ä¸ªå­—ç¬¦çš„å·¥ä½œæ–¹å¼ã€‚
- en: and now if we go backã€‚ So now basically we want to treat our name as one sequence
    and then each single character is one inputã€‚ So we repeatedly apply the R andNs
    for all the characters in the nameã€‚ And then at the very endã€‚ we take the last
    output and apply the soft mark and then take the one with the highest probabilityã€‚
    So this is what we want to do for one nameã€‚ So now we say we have the whole sequenceã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¦‚æœæˆ‘ä»¬å›å»ã€‚å› æ­¤åŸºæœ¬ä¸Šæˆ‘ä»¬æƒ³æŠŠæˆ‘ä»¬çš„åå­—å½“ä½œä¸€ä¸ªåºåˆ—ï¼Œç„¶åæ¯ä¸ªå•ç‹¬çš„å­—ç¬¦æ˜¯ä¸€ä¸ªè¾“å…¥ã€‚å› æ­¤æˆ‘ä»¬å¯¹åå­—ä¸­çš„æ‰€æœ‰å­—ç¬¦é‡å¤åº”ç”¨Rå’ŒNã€‚ç„¶ååœ¨æœ€åã€‚æˆ‘ä»¬è·å–æœ€åçš„è¾“å‡ºï¼Œåº”ç”¨è½¯æ ‡è®°ï¼Œç„¶åé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ªã€‚è¿™å°±æ˜¯æˆ‘ä»¬æƒ³ä¸ºä¸€ä¸ªåå­—åšçš„ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬è¯´æˆ‘ä»¬æœ‰æ•´ä¸ªåºåˆ—ã€‚
- en: The whole name and here we say our input tensor equals and then we use line
    to tensor and hereã€‚ for exampleï¼Œ we use the name Albertã€‚And then our hidden tensor
    is the sameã€‚ And alsoã€‚ this call is the sameã€‚So we grab this and copy thisã€‚ And
    then here we use slicingã€‚ So we only use the very first letter now for this simple
    exampleã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ•´ä¸ªåç§°ï¼Œè¿™é‡Œæˆ‘ä»¬è¯´æˆ‘ä»¬çš„è¾“å…¥å¼ é‡ç­‰äºï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨çº¿æ€§åˆ°å¼ é‡ï¼Œè¿™é‡Œã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬ç”¨åå­—é˜¿å°”ä¼¯ç‰¹ã€‚ç„¶åæˆ‘ä»¬çš„éšè—å¼ é‡æ˜¯ä¸€æ ·çš„ã€‚å¹¶ä¸”ä¹Ÿæ˜¯ã€‚è¿™æ¬¡è°ƒç”¨æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥æˆ‘ä»¬æŠ“ä½è¿™ä¸ªå¹¶å¤åˆ¶å®ƒã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨åˆ‡ç‰‡ã€‚æ‰€ä»¥æˆ‘ä»¬ç°åœ¨åªä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ¯ä½œä¸ºè¿™ä¸ªç®€å•ä¾‹å­ã€‚
- en: So let's try this and run it and see if this is workingã€‚Soï¼Œ yeahï¼Œ So this is
    workingã€‚ And now hereã€‚ what we have to do is we have to repeatedly apply these
    charactersã€‚ So for thisï¼Œ let'sã€‚Write some help of functions firstã€‚ So let meã€‚Comment
    our the print statements out againã€‚ So now let's define a functionã€‚ and let's
    call this category to category from outputã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬å°è¯•è¿™ä¸ªå¹¶è¿è¡Œå®ƒï¼Œçœ‹çœ‹æ˜¯å¦æœ‰æ•ˆã€‚å—¯ï¼Œæ˜¯çš„ã€‚æ‰€ä»¥è¿™ä¸ªæœ‰æ•ˆã€‚è€Œä¸”ç°åœ¨åœ¨è¿™é‡Œã€‚æˆ‘ä»¬å¿…é¡»é‡å¤åº”ç”¨è¿™äº›å­—ç¬¦ã€‚å› æ­¤ï¼Œä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬å…ˆå†™ä¸€äº›å¸®åŠ©å‡½æ•°ã€‚æ‰€ä»¥è®©æˆ‘ã€‚å†å°†æ‰“å°è¯­å¥æ³¨é‡Šæ‰ã€‚æ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ã€‚å¹¶ç§°ä¹‹ä¸ºä»è¾“å‡ºè½¬æ¢ç±»åˆ«åˆ°ç±»åˆ«ã€‚
- en: And this gets the outputã€‚ And as I saidï¼Œ we applied the soft marks at the very
    endã€‚ So this is basically a likelihood of each character of each categoryã€‚ So
    we want to return the index of the greatest valueã€‚ So we can get thisã€‚ So category
    index equalsã€‚ And here we can use torch dot arcã€‚ğŸ˜Šï¼ŒMaxï¼Œ and then here we put in
    the outputã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·å°±å¾—åˆ°äº†è¾“å‡ºã€‚æ­£å¦‚æˆ‘æ‰€è¯´ï¼Œæˆ‘ä»¬åœ¨æœ€ååº”ç”¨äº†è½¯æ ‡è®°ã€‚æ‰€ä»¥è¿™åŸºæœ¬ä¸Šæ˜¯æ¯ä¸ªç±»åˆ«ä¸­æ¯ä¸ªå­—ç¬¦çš„å¯èƒ½æ€§ã€‚å› æ­¤æˆ‘ä»¬æƒ³è¦è¿”å›æœ€å¤§å€¼çš„ç´¢å¼•ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ°è¿™ä¸ªã€‚å› æ­¤ç±»åˆ«ç´¢å¼•ç­‰äºã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨torch.dot.arcã€‚ğŸ˜Šï¼ŒMaxï¼Œç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬æ”¾å…¥è¾“å‡ºã€‚
- en: and then we can call the dot item because this is only one valueã€‚ and then we
    can return all categoriesï¼Œ theã€‚List with this index category indexã€‚ So this is
    oneã€‚Hel a functionï¼Œ for exampleï¼Œ Nowï¼Œ if we print the category from output and
    then hear our output from this nameã€‚ then if we run itã€‚Then we getï¼Œ nowï¼Œ this
    is Irishã€‚ andï¼Œ of courseï¼Œ this is not trained yetã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥è°ƒç”¨ç‚¹é¡¹ç›®ï¼Œå› ä¸ºè¿™åªæœ‰ä¸€ä¸ªå€¼ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è¿”å›æ‰€æœ‰ç±»åˆ«ï¼Œè¿™ä¸ªã€‚ä½¿ç”¨è¿™ä¸ªç´¢å¼•ç±»åˆ«ç´¢å¼•çš„åˆ—è¡¨ã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾æˆ‘ä»¬ç°åœ¨æ‰“å°è¾“å‡ºçš„ç±»åˆ«ï¼Œç„¶åä»è¿™ä¸ªåç§°å¬åˆ°æˆ‘ä»¬çš„è¾“å‡ºã€‚ç„¶åå¦‚æœæˆ‘ä»¬è¿è¡Œå®ƒã€‚ç„¶åæˆ‘ä»¬å¾—åˆ°ï¼Œç°åœ¨ï¼Œè¿™æ˜¯çˆ±å°”å…°çš„ã€‚è€Œä¸”ï¼Œå½“ç„¶ï¼Œè¿™è¿˜æ²¡æœ‰è®­ç»ƒè¿‡ã€‚
- en: So this doesn't look like an Irish name to meã€‚So now what we want to do is we
    want to train our R and Nã€‚ of courseã€‚ So hereï¼Œ as alwaysï¼Œ we want to set up a
    criterion and a optrã€‚ So we say criterion equalsã€‚ And here we use N N dot N L
    L lossã€‚ This is the negative lock likelihood lossã€‚ Then we need to specify a learning
    rateã€‚ And here we have to be careful So In this caseã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™åœ¨æˆ‘çœ‹æ¥ä¸åƒæ˜¯çˆ±å°”å…°çš„åå­—ã€‚å› æ­¤ç°åœ¨æˆ‘ä»¬æƒ³è¦åšçš„æ˜¯è®­ç»ƒæˆ‘ä»¬çš„Rå’ŒNï¼Œå½“ç„¶ã€‚å› æ­¤è¿™é‡Œï¼Œå’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬æƒ³è¦è®¾ç½®ä¸€ä¸ªæ ‡å‡†å’Œä¸€ä¸ªä¼˜åŒ–å™¨ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´æ ‡å‡†ç­‰äºã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨N
    N.dot N L LæŸå¤±ã€‚è¿™æ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ã€‚ç„¶åæˆ‘ä»¬éœ€è¦æŒ‡å®šå­¦ä¹ ç‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»å°å¿ƒã€‚
- en: I try point005ã€‚ and the learning rate is very important hereã€‚ So you might want
    to play around with this a little bitã€‚ And then we say our optr equals torch dot
    optim dot S G Dï¼Œ so stochastic gradientã€‚Descentã€‚ and then we want to optimize
    R N N dot parametersã€‚ And as a learning rateã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°è¯•point005ã€‚å­¦ä¹ ç‡åœ¨è¿™é‡Œéå¸¸é‡è¦ã€‚æ‰€ä»¥ä½ å¯èƒ½æƒ³åœ¨è¿™æ–¹é¢ç©å¾—å¤šä¸€ç‚¹ã€‚ç„¶åæˆ‘ä»¬è¯´æˆ‘ä»¬çš„ä¼˜åŒ–å™¨ç­‰äºtorch.dot.optim.dot S G
    Dï¼Œå› æ­¤éšæœºæ¢¯åº¦ã€‚ä¸‹é™ã€‚ç„¶åæˆ‘ä»¬æƒ³è¦ä¼˜åŒ–R N N.dotå‚æ•°ã€‚ä½œä¸ºå­¦ä¹ ç‡ã€‚
- en: we use the defined learning rateã€‚So now we have our loss and criterion and let's
    define another help a function and call this trainingã€‚ So this is going to be
    one training stepï¼Œ and this gets a line tenorã€‚ So the whole name as a tenorã€‚ and
    it also gets the categoryã€‚Category tenorã€‚ So this is the actual class label or
    the index of the class labelã€‚ And now here we want to get a initial hidden stateã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨å®šä¹‰çš„å­¦ä¹ ç‡ã€‚å› æ­¤ç°åœ¨æˆ‘ä»¬æœ‰æˆ‘ä»¬çš„æŸå¤±å’Œæ ‡å‡†ï¼Œå¹¶ä¸”è®©æˆ‘ä»¬å®šä¹‰å¦ä¸€ä¸ªå¸®åŠ©å‡½æ•°å¹¶ç§°ä¹‹ä¸ºè®­ç»ƒã€‚è¿™å°†æ˜¯ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼Œå¹¶ä¸”è¿™å¾—åˆ°ä¸€ä¸ªè¡Œå¼ é‡ã€‚å› æ­¤æ•´ä¸ªåç§°ä½œä¸ºå¼ é‡ã€‚å®ƒä¹Ÿå¾—åˆ°ç±»åˆ«ã€‚ç±»åˆ«å¼ é‡ã€‚æ‰€ä»¥è¿™æ˜¯å®é™…çš„ç±»æ ‡ç­¾æˆ–ç±»æ ‡ç­¾çš„ç´¢å¼•ã€‚ç°åœ¨åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³è¦è·å¾—åˆå§‹éšè—çŠ¶æ€ã€‚
- en: So we say hidden equals R and N dot in it hiddenã€‚ And thenï¼Œ as I saidã€‚We want
    to do this repeatedlyã€‚ so we need a four loopsã€‚ we say4 I in range and then the
    length of the line tensorã€‚ So we say line tensor dot size and then index0ã€‚ So
    this is the length of the name basicallyã€‚ and then we apply this So we say output
    and hidden equals R and N with the line tensor of the current index or the current
    character and the previous hidden state So note that we put in the hidden state
    and then assign it also to the same variableã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´éšè—ç­‰äºRå’ŒNç‚¹åˆå§‹åŒ–éšè—ã€‚ç„¶åï¼Œæ­£å¦‚æˆ‘æ‰€è¯´ã€‚æˆ‘ä»¬æƒ³é‡å¤è¿™æ ·åšã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå››ä¸ªå¾ªç¯ã€‚æˆ‘ä»¬è¯´4 Iåœ¨èŒƒå›´å†…ï¼Œç„¶åæ˜¯è¡Œå¼ é‡çš„é•¿åº¦ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¡Œå¼ é‡ç‚¹å¤§å°ï¼Œç„¶åç´¢å¼•0ã€‚æ‰€ä»¥è¿™åŸºæœ¬ä¸Šæ˜¯åç§°çš„é•¿åº¦ã€‚ç„¶åæˆ‘ä»¬åº”ç”¨è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¾“å‡ºå’Œéšè—ç­‰äºRå’ŒNä¸å½“å‰ç´¢å¼•æˆ–å½“å‰å­—ç¬¦çš„è¡Œå¼ é‡ä»¥åŠä¹‹å‰çš„éšè—çŠ¶æ€ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ”¾å…¥éšè—çŠ¶æ€å¹¶å°†å…¶ä¹Ÿåˆ†é…ç»™ç›¸åŒçš„å˜é‡ã€‚
- en: So the new hidden state will be the output from the R andnã€‚ and then we do this
    for the whole name and then forï¼ŒThe very last characterã€‚ we get the final outputï¼Œ
    and then we use this to calculate our lossã€‚ So we say loss equals Here we apply
    our criterion with the output and the category tenorã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ–°çš„éšè—çŠ¶æ€å°†æ˜¯æ¥è‡ªRå’ŒNçš„è¾“å‡ºã€‚ç„¶åæˆ‘ä»¬å¯¹æ•´ä¸ªåç§°æ‰§è¡Œæ­¤æ“ä½œï¼Œç„¶åå¯¹äºæœ€åä¸€ä¸ªå­—ç¬¦ã€‚æˆ‘ä»¬å¾—åˆ°æœ€ç»ˆè¾“å‡ºï¼Œç„¶åæˆ‘ä»¬ç”¨å®ƒæ¥è®¡ç®—æŸå¤±ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´æŸå¤±ç­‰äºåœ¨è¿™é‡Œæˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„æ ‡å‡†ä¸è¾“å‡ºå’Œç±»åˆ«éŸ³è°ƒã€‚
- en: and then as alwaysï¼Œ we do our optimizer stepã€‚ So firstï¼Œ we say optimizer0 gradientsã€‚
    Then we say loss dot backward and then we say optimizer dot stepã€‚ And then at
    the end of each training stepã€‚ let's return the outputã€‚ and let's also return
    the loss dot itemï¼Œ So not as tenorï¼Œ but as float valueã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååƒå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬è¿›è¡Œä¼˜åŒ–å™¨æ­¥éª¤ã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘ä»¬è¯´ä¼˜åŒ–å™¨0æ¢¯åº¦ã€‚ç„¶åæˆ‘ä»¬è¯´æŸå¤±ç‚¹åå‘ä¼ æ’­ï¼Œç„¶åæˆ‘ä»¬è¯´ä¼˜åŒ–å™¨ç‚¹æ­¥éª¤ã€‚ç„¶ååœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤ç»“æŸæ—¶ã€‚è®©æˆ‘ä»¬è¿”å›è¾“å‡ºã€‚ä¹Ÿè®©æˆ‘ä»¬è¿”å›æŸå¤±ç‚¹é¡¹ç›®ï¼Œæ‰€ä»¥ä¸æ˜¯ä½œä¸ºéŸ³è°ƒï¼Œè€Œæ˜¯ä½œä¸ºæµ®ç‚¹å€¼ã€‚
- en: And now we have this helper function for the training stepã€‚ And now we can do
    our typical typical training loopã€‚ So for thisï¼Œ let's track somethingã€‚ So let's
    say the current loss equals 0 in the beginningã€‚ Then all losses equals an empty
    listã€‚ So here we want to put in all the lossesã€‚ So we can plot them laterã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰è¿™ä¸ªè®­ç»ƒæ­¥éª¤çš„è¾…åŠ©å‡½æ•°ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›è¡Œå…¸å‹çš„è®­ç»ƒå¾ªç¯ã€‚æ‰€ä»¥ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬è·Ÿè¸ªä¸€äº›ä¸œè¥¿ã€‚è®©æˆ‘ä»¬è¯´å½“å‰æŸå¤±ä¸€å¼€å§‹ç­‰äº0ã€‚ç„¶åæ‰€æœ‰æŸå¤±ç­‰äºä¸€ä¸ªç©ºåˆ—è¡¨ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³æ”¾å…¥æ‰€æœ‰çš„æŸå¤±ã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥ç¨åç»˜åˆ¶å®ƒä»¬ã€‚
- en: Then let's say our plot steps and also our print steps equalsã€‚ Let's say1000
    and5000ã€‚ and the number of iterations equalsï¼Œ let's say100000ã€‚ And then we say
    4 I in range andã€‚Eersã€‚ and now what we want to do is we want to get a random training
    sampleã€‚ So we have this as a helper functionã€‚And this returns the categoryã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¯´æˆ‘ä»¬çš„ç»˜å›¾æ­¥éª¤å’Œæ‰“å°æ­¥éª¤ç­‰äºã€‚æˆ‘ä»¬è¯´1000å’Œ5000ã€‚è¿­ä»£æ¬¡æ•°ç­‰äºï¼Œè®©æˆ‘ä»¬è¯´100000ã€‚ç„¶åæˆ‘ä»¬è¯´4 Iåœ¨èŒƒå›´å†…å’Œã€‚Eersã€‚ç°åœ¨æˆ‘ä»¬æƒ³è¦åšçš„æ˜¯è·å–ä¸€ä¸ªéšæœºè®­ç»ƒæ ·æœ¬ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰è¿™ä¸ªä½œä¸ºè¾…åŠ©å‡½æ•°ã€‚å®ƒè¿”å›ç±»åˆ«ã€‚
- en: Then it returns the actual line or the nameã€‚ Then the category is tenorï¼Œ and
    also the line as tenorã€‚ and we get this by calling the random training example
    function from the utility classã€‚ and this needs the category lines as input and
    all categoriesã€‚ and then we call the training functionã€‚ So we say output and loss
    equals training and this gets the line tenorã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®ƒè¿”å›å®é™…çš„è¡Œæˆ–åç§°ã€‚ç„¶åç±»åˆ«æ˜¯éŸ³è°ƒï¼Œä¹Ÿä½œä¸ºéŸ³è°ƒçš„è¡Œã€‚æˆ‘ä»¬é€šè¿‡è°ƒç”¨å®ç”¨ç±»ä¸­çš„éšæœºè®­ç»ƒç¤ºä¾‹å‡½æ•°æ¥è·å–è¿™ä¸€ç‚¹ã€‚è¿™éœ€è¦ç±»åˆ«è¡Œä½œä¸ºè¾“å…¥å’Œæ‰€æœ‰ç±»åˆ«ã€‚ç„¶åæˆ‘ä»¬è°ƒç”¨è®­ç»ƒå‡½æ•°ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¾“å‡ºå’ŒæŸå¤±ç­‰äºè®­ç»ƒï¼Œè¿™ä¼šå¾—åˆ°è¡ŒéŸ³è°ƒã€‚
- en: and it gets the category tenorï¼Œ then we add the loss to our current lossã€‚ So
    we say current loss plus equals lossã€‚ and then we want to print some informationã€‚
    So we say if I plusã€‚One modoã€‚Ploot stepsã€‚ So every thousand stepã€‚ If this equals
    0ã€‚ So here we want to calculate the current running loss and append it to all
    lossesã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®ƒè·å–ç±»åˆ«éŸ³è°ƒï¼Œæˆ‘ä»¬å°†æŸå¤±åŠ åˆ°å½“å‰æŸå¤±ä¸­ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å½“å‰æŸå¤±åŠ ç­‰äºæŸå¤±ã€‚ç„¶åæˆ‘ä»¬æƒ³æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å¦‚æœæˆ‘åŠ ã€‚ä¸€ç§æ¨¡å¼ã€‚Plootæ­¥éª¤ã€‚æ‰€ä»¥æ¯åƒæ­¥ã€‚å¦‚æœè¿™ç­‰äº0ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³è®¡ç®—å½“å‰çš„è¿è¡ŒæŸå¤±å¹¶å°†å…¶é™„åŠ åˆ°æ‰€æœ‰æŸå¤±ä¸­ã€‚
- en: we say all losses dot appendã€‚ And here we say current loss divided by the number
    of plot stepsã€‚ and then we set our current loss back to 0ã€‚ because here we add
    it up for every iterationã€‚ and then only every thousand stepï¼Œ we append itã€‚ So
    we have to divide it by the numberã€‚ and then we get the averageã€‚And now we do
    the same with the print stepã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¯´æ‰€æœ‰æŸå¤±ç‚¹é™„åŠ ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¯´å½“å‰æŸå¤±é™¤ä»¥ç»˜å›¾æ­¥éª¤çš„æ•°é‡ã€‚ç„¶åæˆ‘ä»¬å°†å½“å‰æŸå¤±é‡ç½®ä¸º0ã€‚å› ä¸ºåœ¨è¿™é‡Œæˆ‘ä»¬ä¸ºæ¯æ¬¡è¿­ä»£ç´¯åŠ å®ƒã€‚ç„¶åæ¯åƒæ­¥æˆ‘ä»¬æ‰é™„åŠ å®ƒã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»å°†å…¶é™¤ä»¥æ•°é‡ã€‚ç„¶åæˆ‘ä»¬å¾—åˆ°å¹³å‡å€¼ã€‚ç°åœ¨æˆ‘ä»¬å¯¹æ‰“å°æ­¥éª¤åšåŒæ ·çš„äº‹æƒ…ã€‚
- en: So we say if I plus one modularã€‚Print steps equals equals 0ã€‚ Then we want some
    print some informationã€‚ So firstï¼Œ we want to get the guessã€‚ So we say guess equals
    category from output and we put in the outputï¼Œ of courseã€‚ Then we check if this
    is correctã€‚ So we say correct equalsã€‚ and then we sayã€‚Correctã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¯´å¦‚æœæˆ‘åŠ ä¸€æ¨¡ã€‚æ‰“å°æ­¥éª¤ç­‰äºç­‰äº0ã€‚é‚£ä¹ˆæˆ‘ä»¬æƒ³æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘ä»¬æƒ³è¦è·å–çŒœæµ‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´çŒœæµ‹ç­‰äºä»è¾“å‡ºä¸­è·å–ç±»åˆ«ï¼Œå½“ç„¶æˆ‘ä»¬æ”¾å…¥è¾“å‡ºä¸­ã€‚ç„¶åæˆ‘ä»¬æ£€æŸ¥è¿™æ˜¯å¦æ­£ç¡®ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´æ­£ç¡®ç­‰äºã€‚ç„¶åæˆ‘ä»¬è¯´ã€‚æ­£ç¡®ã€‚
- en: and this is correctã€‚ If the guess equals equals the actual category that we
    get from the random training exampleã€‚And if this is not correctï¼Œ then we print
    wrongã€‚ And we also want to print the actual categoryã€‚ So let's use this as an
    F string hereã€‚ And here let's print the actual categoryã€‚ And then we print as
    an F string againï¼Œ we want to print the current iteration stepã€‚Then we alsoã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”è¿™æ˜¯æ­£ç¡®çš„ã€‚å¦‚æœçŒœæµ‹ç­‰äºæˆ‘ä»¬ä»éšæœºè®­ç»ƒç¤ºä¾‹ä¸­å¾—åˆ°çš„å®é™…ç±»åˆ«ã€‚å¦‚æœè¿™ä¸æ­£ç¡®ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ‰“å°é”™è¯¯ã€‚æˆ‘ä»¬è¿˜æƒ³æ‰“å°å®é™…ç±»åˆ«ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨Få­—ç¬¦ä¸²ã€‚ç„¶åæˆ‘ä»¬æ‰“å°å®é™…ç±»åˆ«ã€‚æ¥ç€æˆ‘ä»¬å†æ¬¡ä»¥Få­—ç¬¦ä¸²çš„å½¢å¼æ‰“å°å½“å‰è¿­ä»£æ­¥éª¤ã€‚ç„¶åæˆ‘ä»¬è¿˜ã€‚
- en: let's print I divided by the number of iters times 100ã€‚ Then let's also print
    the current lossã€‚ So we say lossã€‚ and let's print only four decimal valuesã€‚And
    let's also print the current lineã€‚ So basicallyï¼Œ this is the nameã€‚ And then let's
    print the guessã€‚And let's also print theã€‚ if it's correct or notã€‚ And now we are
    doneã€‚ So this is basically all that we needã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ‰“å°æˆ‘é™¤ä»¥è¿­ä»£æ¬¡æ•°ä¹˜ä»¥100ã€‚ç„¶åæˆ‘ä»¬ä¹Ÿæ‰“å°å½“å‰æŸå¤±ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´æŸå¤±ã€‚å¹¶ä¸”æˆ‘ä»¬åªæ‰“å°å››ä¸ªå°æ•°å€¼ã€‚æˆ‘ä»¬è¿˜æ‰“å°å½“å‰è¡Œã€‚æ‰€ä»¥åŸºæœ¬ä¸Šï¼Œè¿™æ˜¯åç§°ã€‚ç„¶åæˆ‘ä»¬æ‰“å°çŒœæµ‹ã€‚æˆ‘ä»¬è¿˜æ‰“å°æ˜¯å¦æ­£ç¡®ã€‚ç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚æ‰€ä»¥è¿™åŸºæœ¬ä¸Šå°±æ˜¯æˆ‘ä»¬éœ€è¦çš„å…¨éƒ¨ã€‚
- en: And now when we are doneï¼Œ let's plot our lossesã€‚ So let's trade a figure with
    mapplotlipã€‚ So P L D L T dot figure and P L T dot plot and here we want to plot
    all the losses and then say plot show and now we could already start our trainingã€‚
    And now what weï¼Œ for exampleï¼Œ what we can do is we can save our model here and
    then use it later for for whatever we wantã€‚ But in this caseï¼Œ I simply want to
    try it myselfã€‚ So I say while trueã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å½“æˆ‘ä»¬å®Œæˆæ—¶ï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶æˆ‘ä»¬çš„æŸå¤±ã€‚æ‰€ä»¥è®©æˆ‘ä»¬ç”¨matplotlibç»˜åˆ¶ä¸€ä¸ªå›¾å½¢ã€‚æ‰€ä»¥PLDT.figureå’ŒPLT.plotï¼Œè¿™é‡Œæˆ‘ä»¬æƒ³è¦ç»˜åˆ¶æ‰€æœ‰çš„æŸå¤±ï¼Œç„¶åè¯´plot
    showï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹æˆ‘ä»¬çš„è®­ç»ƒäº†ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥åšçš„äº‹æƒ…æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œä¿å­˜æˆ‘ä»¬çš„æ¨¡å‹ï¼Œç„¶åç¨åç”¨äºæˆ‘ä»¬æƒ³è¦çš„ä»»ä½•äº‹æƒ…ã€‚ä½†åœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼Œæˆ‘åªæ˜¯æƒ³è‡ªå·±è¯•è¯•ã€‚æ‰€ä»¥æˆ‘è¯´while
    trueã€‚
- en: And then I say I get an sentence as input andã€‚å—¯ã€‚Let's sayã€‚Inputã€‚And then I put
    this to a functionã€‚Or I firstï¼Œ let's say if sentence equals equals quitï¼Œ then
    I breakkeã€‚ and otherwise I want to predict the sentenceã€‚ So for thisã€‚ let's create
    another little helper functionï¼Œ let's call thisã€‚Predictã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘è¯´æˆ‘è·å¾—ä¸€ä¸ªå¥å­ä½œä¸ºè¾“å…¥ã€‚å—¯ã€‚è®©æˆ‘ä»¬è¯´ã€‚è¾“å…¥ã€‚ç„¶åæˆ‘æŠŠè¿™ä¸ªæ”¾å…¥ä¸€ä¸ªå‡½æ•°ä¸­ã€‚æˆ–è€…æˆ‘é¦–å…ˆè¯´å¦‚æœå¥å­ç­‰äºç­‰äºé€€å‡ºï¼Œé‚£ä¹ˆæˆ‘ä¸­æ–­ã€‚å¦åˆ™ï¼Œæˆ‘æƒ³é¢„æµ‹è¿™ä¸ªå¥å­ã€‚æ‰€ä»¥ä¸ºæ­¤ã€‚è®©æˆ‘ä»¬åˆ›å»ºå¦ä¸€ä¸ªå°åŠ©æ‰‹å‡½æ•°ï¼Œç§°ä¹‹ä¸ºã€‚é¢„æµ‹ã€‚
- en: and this gets the input lines of a raw textã€‚ So first of allï¼Œ I printã€‚Let's
    print a new lineã€‚ and then let's print the input lineï¼Œ as wellã€‚So for thisï¼Œ of
    courseï¼Œ we need an F stringã€‚And nowã€‚ here in our predictionï¼Œ we should use torch
    dotã€‚ No grasã€‚ We can turn off the gradients nowã€‚ And then what we want to do is
    we want to say our line tensor equals line to tenor from the raw input lineã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šè·å–åŸå§‹æ–‡æœ¬çš„è¾“å…¥è¡Œã€‚æ‰€ä»¥é¦–å…ˆï¼Œæˆ‘æ‰“å°ã€‚è®©æˆ‘ä»¬æ‰“å°ä¸€ä¸ªæ–°è¡Œã€‚ç„¶åæˆ‘ä»¬ä¹Ÿæ‰“å°è¾“å…¥è¡Œã€‚æ‰€ä»¥ä¸ºæ­¤ï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªFå­—ç¬¦ä¸²ã€‚ç°åœ¨ã€‚åœ¨æˆ‘ä»¬çš„é¢„æµ‹ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨torch.no_gradã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥å…³é—­æ¢¯åº¦ã€‚ç„¶åæˆ‘ä»¬æƒ³è¦åšçš„æ˜¯è¯´æˆ‘ä»¬çš„è¡Œå¼ é‡ç­‰äºä»åŸå§‹è¾“å…¥è¡Œè·å–è¡Œå¼ é‡ã€‚
- en: And now we want to do the same as we are doing in our training stepã€‚ So we have
    the initial hidden states and then repeatedly apply our R and Nã€‚ And let's do
    thisã€‚ So let me copy this and put it hereã€‚ So we have the initial hidden stateã€‚
    Then we say4 I in line tens or size 0ã€‚ and then we get the new output and the
    new hidden state by applying the R and Nã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æƒ³è¦åšä¸è®­ç»ƒæ­¥éª¤ä¸­ç›¸åŒçš„äº‹æƒ…ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰åˆå§‹éšè—çŠ¶æ€ï¼Œç„¶ååå¤åº”ç”¨æˆ‘ä»¬çš„Rå’ŒNã€‚è®©æˆ‘ä»¬è¿™æ ·åšã€‚è®©æˆ‘å¤åˆ¶è¿™ä¸ªå¹¶æ”¾åœ¨è¿™é‡Œã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰åˆå§‹éšè—çŠ¶æ€ã€‚ç„¶åæˆ‘ä»¬è¯´4æˆ‘åœ¨è¡Œæ•°åæˆ–å¤§å°0ä¸­ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡åº”ç”¨Rå’ŒNæ¥è·å–æ–°çš„è¾“å‡ºå’Œæ–°çš„éšè—çŠ¶æ€ã€‚
- en: And then at the very endï¼Œ we want to get the guessã€‚ So we say guess equalsã€‚
    and then we say category from outputã€‚ And we use the last output from the last
    stepã€‚ and then we simply want to print the guess hereã€‚ So in this exampleã€‚ I don't
    calculate the accuracy or anythingã€‚ I just print theã€‚Guess and see if it's correct
    or notã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æœ€åï¼Œæˆ‘ä»¬æƒ³è¦è·å–çŒœæµ‹ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´çŒœæµ‹ç­‰äºã€‚ç„¶åæˆ‘ä»¬è¯´ä»è¾“å‡ºä¸­è·å–ç±»åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸Šä¸€æ­¥çš„æœ€åè¾“å‡ºã€‚ç„¶åæˆ‘ä»¬ç®€å•åœ°åœ¨è¿™é‡Œæ‰“å°çŒœæµ‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ã€‚æˆ‘æ²¡æœ‰è®¡ç®—å‡†ç¡®æ€§æˆ–å…¶ä»–ä»»ä½•ä¸œè¥¿ã€‚æˆ‘åªæ˜¯æ‰“å°çŒœæµ‹ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æ­£ç¡®ã€‚
- en: So yeahï¼Œ so let'sã€‚Save thisã€‚ And let's run this and hope that everything is
    workingã€‚ So this might take a few seconds or minutesã€‚ So this is from the first
    exampleã€‚That I showed youï¼Ÿ
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªã€‚ç„¶åè®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå¸Œæœ›ä¸€åˆ‡æ­£å¸¸ã€‚è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿæˆ–å‡ åˆ†é’Ÿã€‚è¿™æ˜¯æˆ‘ç»™ä½ å±•ç¤ºçš„ç¬¬ä¸€ä¸ªä¾‹å­ï¼Ÿ
- en: Andã€‚Now we see we have stepã€‚ This should be 5000ï¼Œ actuallyã€‚ and this should
    be 5% of the training is doneã€‚ and then we have the lossã€‚ and we have the name
    and we see that the guess is wrong because this is actually Poã€‚![](img/67851926e9649c02f2608968bb25321d_8.png)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çœ‹åˆ°æœ‰æ­¥éª¤ã€‚è¿™åº”è¯¥æ˜¯5000ï¼Œå®é™…ä¸Šã€‚è¿™åº”è¯¥æ˜¯è®­ç»ƒçš„5%ã€‚ç„¶åæˆ‘ä»¬æœ‰æŸå¤±ï¼Œè¿˜æœ‰åå­—ï¼Œæˆ‘ä»¬çœ‹åˆ°çŒœæµ‹æ˜¯é”™è¯¯çš„ï¼Œå› ä¸ºè¿™å®é™…ä¸Šæ˜¯Poã€‚![](img/67851926e9649c02f2608968bb25321d_8.png)
- en: All rightï¼Œ so now it's doneï¼Œ and it's plotting the lossesã€‚ And you see that
    it's decreasing very quicklyã€‚ And then it's trying or jumping around a little
    bitã€‚ but still decreasingã€‚ I think this is a pretty good resultã€‚ So let's have
    a look at someã€‚![](img/67851926e9649c02f2608968bb25321d_10.png)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨å®Œæˆäº†ï¼Œå®ƒæ­£åœ¨ç»˜åˆ¶æŸå¤±å›¾ã€‚ä½ ä¼šçœ‹åˆ°æŸå¤±å€¼è¿…é€Ÿä¸‹é™ã€‚ç„¶åå®ƒæœ‰äº›æ³¢åŠ¨ï¼Œä½†ä»åœ¨ä¸‹é™ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªç›¸å½“ä¸é”™çš„ç»“æœã€‚é‚£ä¹ˆæˆ‘ä»¬æ¥çœ‹ä¸€äº›ã€‚![](img/67851926e9649c02f2608968bb25321d_10.png)
- en: Random guesses during the trainingã€‚ So we see that in the beginningï¼Œ almost
    every guess is wrongã€‚ And then it's starting to learn something thingsã€‚ So now
    it's starting to do correct predictionsã€‚ Butï¼Œ of courseï¼Œ it's still not perfectã€‚
    So they are still wrong correctionsã€‚ But yeahã€‚ at the very endï¼Œ we have this lossã€‚
    So this is pretty goodã€‚ And now we can try it ourselvesã€‚ So nowã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒæœŸé—´çš„éšæœºçŒœæµ‹ã€‚æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°åœ¨å¼€å§‹æ—¶ï¼Œå‡ ä¹æ¯ä¸ªçŒœæµ‹éƒ½æ˜¯é”™è¯¯çš„ã€‚ç„¶åå®ƒå¼€å§‹å­¦ä¹ ä¸€äº›ä¸œè¥¿ã€‚ç°åœ¨å®ƒå¼€å§‹è¿›è¡Œæ­£ç¡®çš„é¢„æµ‹ã€‚ä½†å½“ç„¶ï¼Œå®ƒä»ç„¶ä¸æ˜¯å®Œç¾çš„ã€‚æ‰€ä»¥ä»ç„¶æœ‰é”™è¯¯çš„ä¿®æ­£ã€‚ä½†åœ¨æœ€åï¼Œæˆ‘ä»¬å¾—åˆ°äº†è¿™ä¸ªæŸå¤±ã€‚è¿™ç›¸å½“ä¸é”™ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è‡ªå·±å°è¯•ã€‚ç°åœ¨ã€‚
- en: for exampleï¼Œ we could go and try some names from those filesã€‚ So for exampleã€‚
    let's start with some German namesã€‚ So let's try ackerã€‚ And we see it says Germanã€‚
    So let's try Olerï¼Œ for exampleï¼Œ and this is also correctã€‚ So let's try some Italian
    namesã€‚ I think these are pretty clear to detectã€‚ So let's try Abba Dhiã€‚ and it
    saysã€‚Italianã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä¸€äº›æ¥è‡ªé‚£äº›æ–‡ä»¶çš„åå­—ã€‚æ¯”å¦‚è¯´ï¼Œè®©æˆ‘ä»¬ä»ä¸€äº›å¾·å›½åå­—å¼€å§‹ã€‚è®©æˆ‘ä»¬è¯•è¯•ackerã€‚æˆ‘ä»¬çœ‹åˆ°å®ƒè¯´æ˜¯å¾·å›½çš„ã€‚å†è¯•è¯•Olerï¼Œè¿™ä¹Ÿæ˜¯æ­£ç¡®çš„ã€‚å†æ¥è¯•ä¸€äº›æ„å¤§åˆ©åå­—ã€‚æˆ‘è§‰å¾—è¿™äº›å¾ˆå®¹æ˜“è¯†åˆ«ã€‚è®©æˆ‘ä»¬è¯•è¯•Abba
    Dhiï¼Œå®ƒè¯´æ˜¯æ„å¤§åˆ©çš„ã€‚
- en: so this is correctã€‚ So let's try some Russianï¼Œ for exampleï¼Œ Let's say a ba offã€‚
    and it says Russianã€‚ Yeahï¼Œ greatã€‚ So let's try something more difficultã€‚ For exampleï¼Œ
    Chineseã€‚ So let's try Baoã€‚ and it says correct Baoã€‚ Let's try baiã€‚Still Chineseã€‚
    So it looks like it'sã€‚ it's working pretty nice in this exampleã€‚ Of courseï¼Œ it's
    still not perfectã€‚ But for nowã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ­£ç¡®çš„ã€‚å†è¯•ä¸€äº›ä¿„è¯­åå­—ï¼Œæ¯”å¦‚è¯´a ba offã€‚å®ƒè¯´æ˜¯ä¿„è¯­ã€‚å¥½æäº†ã€‚å†è¯•ä¸€äº›æ›´å›°éš¾çš„ï¼Œä¾‹å¦‚ä¸­æ–‡ã€‚è®©æˆ‘ä»¬è¯•è¯•Baoï¼Œå®ƒè¯´æ˜¯æ­£ç¡®çš„Baoã€‚å†è¯•è¯•baiã€‚ä»ç„¶æ˜¯ä¸­æ–‡ã€‚æ‰€ä»¥çœ‹èµ·æ¥å®ƒåœ¨è¿™ä¸ªä¾‹å­ä¸­è¿è¡Œå¾—ç›¸å½“ä¸é”™ã€‚å½“ç„¶ï¼Œå®ƒä»ç„¶ä¸æ˜¯å®Œç¾çš„ã€‚ä½†ç°åœ¨ã€‚
- en: all the guesses are correctã€‚ So now you see how we can train a R and N to do
    name classificationã€‚ And yeahï¼Œ I hope you enjoyed this tutorialã€‚ And now know
    how R and ends can be implemented in Pytorchã€‚ If you like this tutorialï¼Œ and please
    consider subscribing to the channel and leave me alike and see you next time byeã€‚ğŸ˜Šã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰çš„çŒœæµ‹éƒ½æ˜¯æ­£ç¡®çš„ã€‚æ‰€ä»¥ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¦‚ä½•è®­ç»ƒRå’ŒNè¿›è¡Œåå­—åˆ†ç±»ã€‚å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œç°åœ¨çŸ¥é“å¦‚ä½•åœ¨Pytorchä¸­å®ç°Rå’ŒNã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œè¯·è€ƒè™‘è®¢é˜…é¢‘é“å¹¶ç»™æˆ‘ä¸€ä¸ªç‚¹èµï¼Œä¸‹æ¬¡å†è§ï¼Œæ‹œã€‚ğŸ˜Š
- en: '![](img/67851926e9649c02f2608968bb25321d_12.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/67851926e9649c02f2608968bb25321d_12.png)'
