- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- å…·æœ‰é¡ºåºå’ŒåŠŸèƒ½ API
    çš„å·ç§¯ç¥ç»ç½‘ç»œ - ShowMeAI - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- å…·æœ‰é¡ºåºå’ŒåŠŸèƒ½ API
    çš„å·ç§¯ç¥ç»ç½‘ç»œ - ShowMeAI - BV1em4y1U7ib
- en: '![](img/1090d091c86a18e1ad139b92203046b6_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1090d091c86a18e1ad139b92203046b6_0.png)'
- en: Welcome back guysï¼Œ hope you're doing awesome and in this video we will continue
    and now build a convolutional neural network and as usual there are resources
    of video lectures in the description to find more about the concepts for this
    video So with that saidã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿å›æ¥ï¼Œå¤§å®¶å¸Œæœ›ä½ ä»¬ä¸€åˆ‡éƒ½å¥½ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­å¹¶æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå’Œå¾€å¸¸ä¸€æ ·ï¼Œè§†é¢‘æè¿°ä¸­æœ‰èµ„æºé“¾æ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥äº†è§£æœ¬è§†é¢‘çš„æ¦‚å¿µã€‚æ‰€ä»¥è¯ä¸å¤šè¯´ã€‚
- en: let's get started we're going first import OS and we're going to do OS dot environment
    and do Tf CPP Min log level and again this is just for ignoring information messages
    from Tensorflowlow that can be a little bit annoyingã€‚And then we're going to do
    import Tensorflow as Tfã€‚From Tensorflowï¼Œ import ksã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ã€‚æˆ‘ä»¬é¦–å…ˆå¯¼å…¥ OSï¼Œç„¶åæˆ‘ä»¬å°†ä½¿ç”¨ OS dot environment è®¾ç½® Tf CPP Min log levelï¼Œè¿™åªæ˜¯ä¸ºäº†å¿½ç•¥
    Tensorflow çš„ä¸€äº›ä¿¡æ¯æ¶ˆæ¯ï¼Œè¿™äº›æ¶ˆæ¯å¯èƒ½ä¼šè®©äººæœ‰ç‚¹çƒ¦ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†å¯¼å…¥ Tensorflowï¼Œä½¿ç”¨ Tfã€‚ä» Tensorflow å¯¼å…¥ ksã€‚
- en: From Tensorflow dot ks import layers and then from Tensorflow dot Cars do data
    setsã€‚ we're going to import Cypher 10ã€‚ So in this video we're going to take a
    look at the Cypher 10 data set and it's basically more natural images of of 10
    different classes from airplaneã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä» Tensorflow dot ks å¯¼å…¥ layersï¼Œç„¶åä» Tensorflow dot Cars å¯¼å…¥æ•°æ®é›†ã€‚æˆ‘ä»¬å°†å¯¼å…¥ Cypher 10ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹
    Cypher 10 æ•°æ®é›†ï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯æ¥è‡ª 10 ä¸ªä¸åŒç±»åˆ«ï¼ˆå¦‚é£æœºï¼‰çš„æ›´å¤šè‡ªç„¶å›¾åƒã€‚
- en: automobile mobile bird truckï¼Œ etc ceteraã€‚ and the images areã€‚![](img/1090d091c86a18e1ad139b92203046b6_2.png)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ±½è½¦ã€æ‰‹æœºã€é¸Ÿã€å¡è½¦ç­‰ç­‰ã€‚å›¾åƒå¦‚ä¸‹ã€‚![](img/1090d091c86a18e1ad139b92203046b6_2.png)
- en: we have 50ï¼Œ000 training images and then we have 10ï¼Œ000 test imagesï¼Œ total of
    60ã€‚000 where each image is 32 by 32 pixels so they are relatively small and then
    we have RGB colored so they have three channels I found this pretty interesting
    blog post by Andrea Kpathy that where he actually trained himself on Cypher 10
    and he came to the conclusion let's see that Cypher 10 human level accuracy is
    approximately 94% and if you actually check the most recent models trained on
    Cypher10 they go beyond this so the more recent models are much much better than
    human level performance on this dataset setã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ 50,000 å¼ è®­ç»ƒå›¾åƒï¼Œ10,000 å¼ æµ‹è¯•å›¾åƒï¼Œæ€»å…± 60,000 å¼ ï¼Œæ¯å¼ å›¾åƒæ˜¯ 32 x 32 åƒç´ ï¼Œæ‰€ä»¥å®ƒä»¬ç›¸å¯¹è¾ƒå°ï¼Œè€Œä¸”æ˜¯ RGB
    å½©è‰²çš„ï¼Œå› æ­¤å®ƒä»¬æœ‰ä¸‰ä¸ªé€šé“ã€‚æˆ‘å‘ç°äº† Andrea Kpathy çš„ä¸€ç¯‡å¾ˆæœ‰è¶£çš„åšå®¢æ–‡ç« ï¼Œä»–å®é™…ä¸Šè‡ªå·±åœ¨ Cypher 10 ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶å¾—å‡ºç»“è®ºï¼Œçœ‹çœ‹
    Cypher 10 çš„äººç±»æ°´å¹³å‡†ç¡®ç‡çº¦ä¸º 94%ï¼Œå¦‚æœä½ æŸ¥çœ‹æœ€è¿‘åœ¨ Cypher 10 ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œå®ƒä»¬çš„æ€§èƒ½è¶…è¶Šäº†è¿™ä¸€ç‚¹ï¼Œå› æ­¤æ›´è¿‘æœŸçš„æ¨¡å‹åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¿œè¿œè¶…è¿‡äººç±»çš„è¡¨ç°ã€‚
- en: '![](img/1090d091c86a18e1ad139b92203046b6_4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1090d091c86a18e1ad139b92203046b6_4.png)'
- en: Now I'm going to copy in two lines and most likely you don't need themã€‚ but
    if you're running on GPU and you're run into any troubleã€‚ then most likely these
    two lines here are going to help you outã€‚Al rightã€‚ so let's go back to sort of
    what we actually want to do in this videoã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å°†å¤åˆ¶ä¸¤è¡Œä»£ç ï¼Œä½ å¯èƒ½å¹¶ä¸éœ€è¦å®ƒä»¬ï¼Œä½†å¦‚æœä½ åœ¨ GPU ä¸Šè¿è¡Œå¹¶é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œé‚£ä¹ˆè¿™ä¸¤è¡Œå¯èƒ½ä¼šå¸®åŠ©ä½ ã€‚å¥½çš„ï¼Œå›åˆ°æˆ‘ä»¬åœ¨è¿™ä¸ªè§†é¢‘ä¸­å®é™…æƒ³åšçš„äº‹æƒ…ã€‚
- en: which is first we want to load the Cypher 10 data setã€‚ and this is very similar
    to how we loaded MNISã€‚In the last videoã€‚ and then so we're going to do x trainï¼Œ
    Y trainï¼Œ X testï¼Œ Y testã€‚And then Cypher 10 dot load dataã€‚Andã€‚Againï¼Œ we want to
    convert it into F 32 because efficiency essentially computing it in F 64 is a
    bit of unnecessary necessary computationã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆæƒ³è¦åŠ è½½ Cypher 10 æ•°æ®é›†ï¼Œè¿™ä¸æˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªè§†é¢‘ä¸­åŠ è½½ MNIS çš„æ–¹æ³•éå¸¸ç›¸ä¼¼ã€‚æ‰€ä»¥æˆ‘ä»¬å°†æ‰§è¡Œ x trainã€Y trainã€X
    testã€Y testï¼Œç„¶åè°ƒç”¨ Cypher 10 dot load dataã€‚æˆ‘ä»¬å†æ¬¡å¸Œæœ›å°†å…¶è½¬æ¢ä¸º F 32ï¼Œå› ä¸ºåœ¨ F 64 ä¸­è®¡ç®—æ•ˆç‡ä¸é«˜ï¼Œå±äºä¸å¿…è¦çš„è®¡ç®—ã€‚
- en: so what we can do is we can do xtrain equals xtrain s type and then float 32
    and then for normalization we can also divide by 255 so that the pixel values
    are between 0 and1ã€‚And then similarly for X testï¼Œ we can do x test equals x test
    as type float 32ã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åšçš„æ˜¯å°† xtrain èµ‹å€¼ä¸º xtrain çš„ç±»å‹ï¼Œç„¶åä¸º float 32ï¼Œç„¶åä¸ºäº†å½’ä¸€åŒ–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å°†å…¶é™¤ä»¥ 255ï¼Œä½¿åƒç´ å€¼åœ¨ 0 å’Œ
    1 ä¹‹é—´ã€‚åŒæ ·å¯¹äº X testï¼Œæˆ‘ä»¬å¯ä»¥å°† x test èµ‹å€¼ä¸º x test çš„ç±»å‹ float 32ã€‚
- en: and then we're just going divide by 255ã€‚ Allrightã€‚ so for our actual model let's
    start out with a sequential model and then we're going to build and make that
    a little bit more advancedã€‚ so we're going to do model equals Kas that sequential
    and we're going to start with Kas that input specifying the input shape in this
    caseã€‚Since we're using convolutional neural networksï¼Œ we are not going to reshape
    it so that we don't flatten it in the beginningã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åªéœ€é™¤ä»¥255ã€‚å¥½çš„ã€‚æ‰€ä»¥å¯¹äºæˆ‘ä»¬çš„å®é™…æ¨¡å‹ï¼Œè®©æˆ‘ä»¬ä»ä¸€ä¸ªé¡ºåºæ¨¡å‹å¼€å§‹ï¼Œç„¶åæˆ‘ä»¬å°†æ„å»ºå¹¶ä½¿å…¶æ›´é«˜çº§ä¸€ç‚¹ã€‚æˆ‘ä»¬å°†æ‰§è¡Œmodel = K.as.Sequentialï¼Œå¹¶æŒ‡å®šè¾“å…¥å½¢çŠ¶ã€‚ç”±äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬ä¸ä¼šåœ¨å¼€å§‹æ—¶è¿›è¡Œé‡å¡‘ã€‚
- en: so that means we're going to maintain the heightï¼Œ so 32 in heightã€‚ 32 and width
    and then three channels for RGB so that they are colored so that's the input shape
    of each image then we're going to do layersã€‚ co2 d and we're going to do I don't
    knowï¼Œ 32 out channels so the firstã€‚First argument here of comm 2 do is that how
    many channels we want this convolutional layer to output so in the beginning we
    have three channels we want the output to then be 32 then we're going to specify
    the kernel size we're just going to set that to three and so if we set just a
    single integer here that's going to be expanded to be the same kernel size for
    the height and the width so that's essentially writing this just more I guess
    less of verbo just writing the integerã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æˆ‘ä»¬å°†ä¿æŒé«˜åº¦ä¸º32ï¼Œå®½åº¦ä¸º32ï¼Œå¹¶ä¸”æœ‰ä¸‰ä¸ªRGBé€šé“ï¼Œæ‰€ä»¥è¿™å°±æ˜¯æ¯ä¸ªå›¾åƒçš„è¾“å…¥å½¢çŠ¶ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†æ‰§è¡Œlayers.co2dï¼Œæˆ‘ä¸å¤ªç¡®å®šï¼Œ32ä¸ªè¾“å‡ºé€šé“æ˜¯ç¬¬ä¸€ä¸ªã€‚è¿™é‡Œçš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªå·ç§¯å±‚è¾“å‡ºå¤šå°‘ä¸ªé€šé“ï¼Œæ‰€ä»¥ä¸€å¼€å§‹æˆ‘ä»¬æœ‰ä¸‰ä¸ªé€šé“ï¼Œæˆ‘ä»¬å¸Œæœ›è¾“å‡ºä¸º32ã€‚æ¥ç€æˆ‘ä»¬å°†æŒ‡å®šå·ç§¯æ ¸å¤§å°ï¼Œæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸º3ï¼Œå¦‚æœåœ¨è¿™é‡Œè®¾ç½®ä¸€ä¸ªæ•´æ•°ï¼Œå®ƒå°†æ‰©å±•ä¸ºé«˜åº¦å’Œå®½åº¦ç›¸åŒçš„å·ç§¯æ ¸å¤§å°ï¼Œæ‰€ä»¥æœ¬è´¨ä¸Šæ˜¯æ›´ç®€æ´åœ°å†™å‡ºè¿™ä¸ªã€‚
- en: And then we can specify padding so here you can specify valid or same so valid
    here is the default and then so what's going to happen is that these pixel values
    hereã€‚ if we use same convolution then theyre going to be maintained so after this
    layer they're still going to be 32 pixels height and then 32 pixels widthã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥æŒ‡å®šå¡«å……æ–¹å¼ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥é€‰æ‹©æœ‰æ•ˆæˆ–ç›¸åŒï¼Œå› æ­¤æœ‰æ•ˆæ˜¯é»˜è®¤çš„ã€‚é‚£ä¹ˆå‘ç”Ÿçš„æƒ…å†µæ˜¯ï¼Œè¿™äº›åƒç´ å€¼ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„å·ç§¯ï¼Œé‚£ä¹ˆå®ƒä»¬å°†è¢«ä¿æŒï¼Œå› æ­¤åœ¨è¿™ä¸€å±‚ä¹‹åï¼Œå®ƒä»¬ä»å°†æ˜¯32åƒç´ çš„é«˜åº¦å’Œ32åƒç´ çš„å®½åº¦ã€‚
- en: but if we use valid then that's going to change depending on our kernel sizeã€‚
    so in this case they're actually going to become 30 by 30 pixelsã€‚So this is essentially
    just a hyperparameter that you can play around withã€‚ I'm just going to set it
    to validï¼Œ although there's really no point since this is the default argumentã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœæˆ‘ä»¬ä½¿ç”¨æœ‰æ•ˆçš„å¡«å……ï¼Œé‚£ä¹ˆè¿™å°†æ ¹æ®æˆ‘ä»¬çš„å·ç§¯æ ¸å¤§å°è€Œå˜åŒ–ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒä»¬å®é™…ä¸Šå°†å˜æˆ30ä¹˜30åƒç´ ã€‚æ‰€ä»¥è¿™æœ¬è´¨ä¸Šåªæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œä½ å¯ä»¥éšæ„è°ƒæ•´ã€‚æˆ‘ä¼šå°†å…¶è®¾ç½®ä¸ºæœ‰æ•ˆï¼Œè™½ç„¶è¿™æ ·åšæ²¡æœ‰æ„ä¹‰ï¼Œå› ä¸ºè¿™æ˜¯é»˜è®¤å‚æ•°ã€‚
- en: And then we can set the activation similarly to how we did for our neural network
    to REã€‚And then let's do a max pooling to Dã€‚And so here we can specify the pool
    sizeã€‚ let's say two by two so that it's halfd in the inputï¼Œ so for exampleã€‚ if
    we use a valid convolution hereï¼Œ this is going to be 30 by 30 and of course you
    can do print model summary to actually see these changesã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥è®¾ç½®æ¿€æ´»å‡½æ•°ï¼Œç±»ä¼¼äºæˆ‘ä»¬ä¸ºç¥ç»ç½‘ç»œæ‰€åšçš„è®¾ç½®ä¸ºREã€‚æ¥ç€è¿›è¡Œæœ€å¤§æ± åŒ–åˆ°Dã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ± å¤§å°ï¼Œå‡è®¾ä¸º2ä¹˜2ï¼Œè¿™æ ·è¾“å…¥å°±ä¼šå‡åŠã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨æœ‰æ•ˆå·ç§¯ï¼Œé‚£ä¹ˆç»“æœå°†æ˜¯30ä¹˜30ï¼Œå½“ç„¶ä½ å¯ä»¥æ‰“å°æ¨¡å‹æ‘˜è¦æ¥å®é™…æŸ¥çœ‹è¿™äº›å˜åŒ–ã€‚
- en: Maybe we can do that actuallyï¼Œ so let's do print model that summaryã€‚And let's
    seeã€‚ So as we can see here nowï¼Œ after the first comeï¼Œ it's going to be 30 by 30
    and then we have 32 channels and then after the max pullingingã€‚ it's going to
    have the input size pixelï¼Œ so they're going to be 15 by 15ã€‚And then we could do
    just another couple of layersã€‚ So layers come to Dã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸æˆ‘ä»¬çœŸçš„å¯ä»¥è¿™æ ·åšï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ‰“å°æ¨¡å‹æ‘˜è¦ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ã€‚æ­£å¦‚æˆ‘ä»¬ç°åœ¨æ‰€çœ‹åˆ°çš„ï¼Œç¬¬ä¸€æ¬¡è¿‡åï¼Œå°†æ˜¯30ä¹˜30ï¼Œç„¶åæˆ‘ä»¬æœ‰32ä¸ªé€šé“ï¼Œæœ€å¤§æ± åŒ–åï¼Œè¾“å…¥å¤§å°åƒç´ å°†æ˜¯15ä¹˜15ã€‚æ¥ç€æˆ‘ä»¬å¯ä»¥å†æ·»åŠ å‡ å±‚ï¼Œæ‰€ä»¥å±‚æ•°æ˜¯Dã€‚
- en: let's say 64 out channels and then sameã€‚ I meanï¼Œ kernel size 3ã€‚ and then let's
    just use valid again and activation reã€‚å—¯ã€‚Let's do another max poolingã€‚And thenã€‚Againã€‚
    we're going to have 128 channels we just double it and then three and activation
    equals relative againã€‚ so then for our actual output we're going to do layers
    do flatten we're going to have let's say one intermediate so we're going to have
    64 nodes in this fully connected and activation equals relative and then for our
    output we're just going to do layer dense and then 10 output nodesã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æœ‰64ä¸ªè¾“å‡ºé€šé“ï¼Œå†…æ ¸å¤§å°ä¸º3ã€‚ç„¶åæˆ‘ä»¬å†æ¬¡ä½¿ç”¨æœ‰æ•ˆçš„å¡«å……å’Œæ¿€æ´»å‡½æ•°ã€‚å—¯ã€‚å†è¿›è¡Œä¸€æ¬¡æœ€å¤§æ± åŒ–ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æœ‰128ä¸ªé€šé“ï¼Œæˆ‘ä»¬åªéœ€å°†å…¶ç¿»å€ï¼Œå†åŠ ä¸Š3ï¼Œæ¿€æ´»å‡½æ•°ä¸ºç›¸å¯¹ã€‚ç„¶åå¯¹äºæˆ‘ä»¬çš„å®é™…è¾“å‡ºï¼Œæˆ‘ä»¬å°†è¿›è¡Œå±‚å±•å¹³ï¼Œå‡è®¾æœ‰ä¸€ä¸ªä¸­é—´å±‚ï¼Œå› æ­¤æˆ‘ä»¬å°†åœ¨è¿™ä¸ªå…¨è¿æ¥å±‚ä¸­æœ‰64ä¸ªèŠ‚ç‚¹ï¼Œæ¿€æ´»å‡½æ•°ä¸ºç›¸å¯¹ï¼Œæœ€åæˆ‘ä»¬åªéœ€è¿›è¡Œå¯†é›†å±‚ï¼Œæœ‰10ä¸ªè¾“å‡ºèŠ‚ç‚¹ã€‚
- en: So that's for our actual modelã€‚ then we're going to compile our modelã€‚ So model
    that compile specify the loss function to be CAs that losses that sparsã€‚Categorical
    cross entropyï¼Œ so the same that we use in the last video from logics equals true
    because we're not having a softmax activation on our outputã€‚And then let's say
    optimizerï¼Œ let's use atã€‚So if we're going to set also the learning rateã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬çš„å®é™…æ¨¡å‹ã€‚ç„¶åæˆ‘ä»¬å°†ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œç¼–è¯‘æ¨¡å‹æ—¶æŒ‡å®šæŸå¤±å‡½æ•°ä¸ºCAsï¼Œè¯¥æŸå¤±å‡½æ•°æ˜¯ç¨€ç–çš„åˆ†ç±»äº¤å‰ç†µï¼Œä¸æˆ‘ä»¬åœ¨ä¸Šä¸ªè§†é¢‘ä¸­ä½¿ç”¨çš„ç›¸åŒï¼Œå› ä¸ºæˆ‘ä»¬çš„è¾“å‡ºæ²¡æœ‰softmaxæ¿€æ´»ã€‚ç„¶åå‡è®¾ä¼˜åŒ–å™¨ä½¿ç”¨Adamï¼Œå› æ­¤æˆ‘ä»¬è¿˜éœ€è¦è®¾ç½®å­¦ä¹ ç‡ã€‚
- en: let's set it to 3 e minus4ã€‚And then metricsï¼Œ let's keep track of accuracyã€‚Alrightã€‚
    so that's where a model compile now to actually train the modelã€‚ let's just do
    model that fit x trainï¼Œ y trainï¼Œ batch sizeï¼Œ let's sayï¼Œ 264ã€‚And then let's run
    for 10 epochs and let's say verbose equals 2 so that it prints after each epoch
    in this way you won't get a progress barã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾ç½®ä¸º3e-4ï¼Œç„¶åæŒ‡æ ‡ä¿æŒè·Ÿè¸ªå‡†ç¡®ç‡ã€‚å¥½çš„ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ¨¡å‹çš„ç¼–è¯‘ï¼Œç°åœ¨å®é™…ä¸Šè®­ç»ƒæ¨¡å‹ã€‚è®©æˆ‘ä»¬è¿›è¡Œæ¨¡å‹æ‹Ÿåˆx_trainï¼Œy_trainï¼Œæ‰¹å¤§å°å‡è®¾ä¸º264ã€‚ç„¶åè¿è¡Œ10ä¸ªå‘¨æœŸï¼Œè®¾ç½®verboseç­‰äº2ï¼Œè¿™æ ·æ¯ä¸ªå‘¨æœŸåä¼šæ‰“å°è¾“å‡ºï¼Œä»¥ä¾¿ä½ ä¸ä¼šçœ‹åˆ°è¿›åº¦æ¡ã€‚
- en: but it's going to print information about the training every epochã€‚And then
    after trainingã€‚ let's do model dot evaluate on the test setã€‚And then also againã€‚
    let's set the batch size to the same and no epochs because we're just going to
    run at once and then verboos equals2ã€‚ Allrightï¼Œ so let's run this and hopefully
    we should still have okayã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å®ƒå°†åœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸæ‰“å°æœ‰å…³è®­ç»ƒçš„ä¿¡æ¯ã€‚è®­ç»ƒåï¼Œè®©æˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ã€‚ç„¶ååŒæ ·ï¼Œè®¾ç½®æ‰¹å¤§å°ç›¸åŒï¼Œæ²¡æœ‰å‘¨æœŸï¼Œå› ä¸ºæˆ‘ä»¬åªä¼šè¿è¡Œä¸€æ¬¡ï¼Œverboseç­‰äº2ã€‚å¥½çš„ï¼Œè®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªï¼Œå¸Œæœ›ä¸€åˆ‡æ­£å¸¸ã€‚
- en: so let' let's do also print model that summary hereã€‚And then we can inspect
    thatã€‚ğŸ˜”ï¼ŒSoã€‚Alrightã€‚ so we're letting a trainã€‚ So we can see here thatã€‚We can sort
    of see the number parametersã€‚ let's seeã€‚ it's here are the most of the parameters
    of the model andã€‚So as we can see here we can see sort of the total number of
    parametersï¼Œ 1225ï¼Œ000ã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œæ‰“å°æ¨¡å‹æ‘˜è¦ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ä¸€ä¸‹ã€‚ğŸ˜” å¥½å§ï¼Œæ‰€ä»¥æˆ‘ä»¬å¼€å§‹è®­ç»ƒäº†ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„å¤§éƒ¨åˆ†å‚æ•°ã€‚æ€»å‚æ•°æ•°é‡ä¸º1225,000ã€‚
- en: and that's actually a veryï¼Œ very small networkï¼Œ so we're not expecting to get
    veryã€‚ very high accuracy on this but sort of just to illustrate how to build convolutions
    and then using Mac pullinging and so onã€‚I believe that Alexnettã€‚I believe that
    AlexNeï¼Œ which was sort of the first convolutional neural network that really revolutionized
    computer visionã€‚ had about 60 million parametersï¼Œ so just to get a perspective
    on how small 225ï¼Œ000 actually isã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªéå¸¸éå¸¸å°çš„ç½‘ç»œï¼Œå› æ­¤æˆ‘ä»¬å¹¶ä¸æœŸå¾…å¾—åˆ°éå¸¸éå¸¸é«˜çš„å‡†ç¡®ç‡ï¼Œè€Œåªæ˜¯ä¸ºäº†è¯´æ˜å¦‚ä½•æ„å»ºå·ç§¯å±‚ï¼Œç„¶åä½¿ç”¨æœ€å¤§æ± åŒ–ç­‰ç­‰ã€‚æˆ‘ç›¸ä¿¡ AlexNetï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªçœŸæ­£é©å‘½æ€§åœ°æ”¹å˜è®¡ç®—æœºè§†è§‰çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¤§çº¦æœ‰6000ä¸‡ä¸ªå‚æ•°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¥çœ‹çœ‹225,000ç©¶ç«Ÿæœ‰å¤šå°ã€‚
- en: Alrightï¼Œ so let's see it's done training and then it's printing the model of
    summary again okay so let's remove thatã€‚ğŸ˜”ï¼ŒAnd then let's see sort of what we get
    so we get 72% training accuracy at end and then 68% test accuracyã€‚ Now as you
    can see we have a lot of room for improvement So if you train this for longã€‚ you
    would probably get a better accuracy but we're not really interested in that So
    what we're going to do now is take a look at how we can build a functional using
    the functional API and sort of build a very similar convolution in neural network
    but we're going to add some more advanced things soã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è®­ç»ƒæ˜¯å¦å®Œæˆï¼Œç„¶åå†æ‰“å°æ¨¡å‹æ‘˜è¦ã€‚å¥½çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å»æ‰é‚£ä¸ªã€‚ğŸ˜” ç„¶åçœ‹çœ‹æˆ‘ä»¬å¾—åˆ°äº†ä»€ä¹ˆï¼Œæœ€åè®­ç»ƒå‡†ç¡®ç‡ä¸º72%ï¼Œæµ‹è¯•å‡†ç¡®ç‡ä¸º68%ã€‚ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚å¦‚æœä½ è®­ç»ƒæ›´ä¹…ï¼Œå¯èƒ½ä¼šå¾—åˆ°æ›´å¥½çš„å‡†ç¡®ç‡ï¼Œä½†æˆ‘ä»¬å¹¶ä¸å¤ªå…³æ³¨è¿™ä¸ªã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å‡½æ•°å¼APIæ„å»ºåŠŸèƒ½ï¼Œå¹¶æ„å»ºä¸€ä¸ªéå¸¸ç›¸ä¼¼çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œä½†æˆ‘ä»¬ä¼šæ·»åŠ ä¸€äº›æ›´é«˜çº§çš„å†…å®¹ã€‚
- en: Let's doï¼Œ let's actually do a functionã€‚ So let's do define my modelã€‚ and then
    inside thisã€‚ let's do input equalsã€‚Kas input and then shape let's seeï¼Œ 32ï¼Œ32ï¼Œ3ã€‚And
    then let's do x equals layersã€‚com2 dï¼Œ let's do the same channels with 32 and then
    kernel size 3ã€‚ and then we're going to send the input through that layerã€‚And thenã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åšä¸€ä¸ªå‡½æ•°ã€‚é¦–å…ˆå®šä¹‰æˆ‘çš„æ¨¡å‹ã€‚ç„¶ååœ¨é‡Œé¢ï¼Œè®©æˆ‘ä»¬è®¾å®šè¾“å…¥ä¸º`Kas input`ï¼Œå½¢çŠ¶ä¸º32ï¼Œ32ï¼Œ3ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬è®¾å®š`x`ç­‰äº`layers.com2d`ï¼Œä½¿ç”¨32ä¸ªé€šé“ï¼Œå·ç§¯æ ¸å¤§å°ä¸º3ã€‚ç„¶åæˆ‘ä»¬å°†è¾“å…¥ä¼ å…¥è¯¥å±‚ã€‚
- en: We're going to use batch normalization and so that's going to be in the video
    description if you if you're unfamiliar with batch norm so batch normalization
    and we're going to initialize that and then we're just going to send in x through
    that one and then as you might have noticed here we're not using a activation
    function here that's because if we're using batch norm we want to sort of send
    it through the convolutional area first and then through the batch norm and then
    we want to send it through the activation function so how we can do that is by
    doing caresã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨æ‰¹å½’ä¸€åŒ–ï¼Œè§†é¢‘æè¿°ä¸­ä¼šæœ‰ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰æ‰¹å½’ä¸€åŒ–ï¼Œæˆ‘ä»¬å°†åˆå§‹åŒ–å®ƒï¼Œç„¶åå°†`x`ä¼ å…¥ã€‚ä½ å¯èƒ½æ³¨æ„åˆ°è¿™é‡Œæ²¡æœ‰ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Œè¿™æ˜¯å› ä¸ºå¦‚æœæˆ‘ä»¬ä½¿ç”¨æ‰¹å½’ä¸€åŒ–ï¼Œæˆ‘ä»¬å¸Œæœ›å…ˆé€šè¿‡å·ç§¯å±‚ï¼Œç„¶åå†é€šè¿‡æ‰¹å½’ä¸€åŒ–ï¼Œæœ€åé€šè¿‡æ¿€æ´»å‡½æ•°ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·å®ç°ã€‚
- en: That activation start re than of xã€‚And yeahï¼Œ so let's add some max pullingingï¼Œ
    max pullinging to Dã€‚And we actually don't have to specify the pool sizeï¼Œ so let's
    seeï¼Œ yeah I did it hereã€‚ but we don't have to such probably mentioned that when
    we did this oneã€‚ but you don't have to specify the pool size to be 2 by 2ï¼Œ that's
    the default argumentã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ¿€æ´»å‡½æ•°æ˜¯`x`çš„`re`ã€‚å¯¹äº†ï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€äº›æœ€å¤§æ± åŒ–ã€‚å®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦æŒ‡å®šæ± åŒ–å¤§å°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹ï¼Œæ˜¯çš„ï¼Œæˆ‘åœ¨è¿™é‡Œåšåˆ°äº†ã€‚ä½†æˆ‘ä»¬å®é™…ä¸Šä¸éœ€è¦åœ¨è¿™æ—¶æŒ‡å®šæ± åŒ–å¤§å°ä¸º2ä¹˜2ï¼Œè¿™æ˜¯é»˜è®¤å‚æ•°ã€‚
- en: but of course you can change it to whatever you wantã€‚ it's just that 2 by  two
    is what you most frequently useã€‚So let's just do max pulling and then send it
    through that one and then let's create another oneã€‚ so let's do layers column
    to d 64 and I don't knowã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä½ å¯ä»¥æ›´æ”¹ä¸ºä½ æƒ³è¦çš„ä»»ä½•ä¸œè¥¿ï¼Œåªæ˜¯2ä¹˜2æ˜¯ä½ æœ€å¸¸ç”¨çš„ã€‚æ‰€ä»¥æˆ‘ä»¬å…ˆåšæœ€å¤§æ± åŒ–ï¼Œç„¶åé€šè¿‡è¿™ä¸ªè¿›è¡Œå¤„ç†ï¼Œå†åˆ›å»ºå¦ä¸€ä¸ªå±‚ã€‚è®©æˆ‘ä»¬åš`layers.column2d`
    64ï¼Œæˆ‘ä¸çŸ¥é“ã€‚
- en: let's do a kernel size of 5 and let's do padding equals same and just for one
    and then let's doã€‚AndAnother batch normï¼Œ so batch normalizationã€‚Of xã€‚And then
    cares that activations dot reluã€‚Of Xã€‚And then after thisï¼Œ let's do one moreï¼Œ so
    let's do layers come to D 128ï¼Œ3ã€‚And then of xã€‚Of Xã€‚ and thenã€‚Another batch wormã€‚Of
    X activationã€‚Relloã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®¾å®šå·ç§¯æ ¸å¤§å°ä¸º5ï¼Œå¡«å……ä¸ºç›¸åŒï¼Œç„¶ååšä¸€ä¸ª`Another batch norm`ï¼Œä¹Ÿå°±æ˜¯æ‰¹å½’ä¸€åŒ–ï¼Œä½œç”¨äº`x`ã€‚ç„¶åæ˜¯æ¿€æ´»å‡½æ•°`activations.relu`ï¼Œä½œç”¨äº`x`ã€‚åœ¨è¿™ä¹‹åï¼Œè®©æˆ‘ä»¬å†æ¥ä¸€æ¬¡ï¼Œè®¾ç½®`layers.com2d`
    128ï¼Œ3ï¼Œç„¶åæ˜¯`x`ã€‚ç„¶åæ˜¯å¦ä¸€ä¸ªæ‰¹å½’ä¸€åŒ–ï¼Œä½œç”¨äº`x`çš„æ¿€æ´»ã€‚
- en: And then we're going to now send it through a a dense layerã€‚ So we're going
    to do layers that denseã€‚64 nodesã€‚And activation is reã€‚And then the outputs is
    going to be just layers dense of 10 nodes of xã€‚And then to create our modelï¼Œ we're
    going to do model equalsã€‚Cas that modelã€‚ and then we need to specify the inputs
    and the outputsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨`layers.dense`ï¼Œ64ä¸ªèŠ‚ç‚¹ï¼Œæ¿€æ´»å‡½æ•°ä¸º`re`ã€‚è¾“å‡ºå°†æ˜¯`layers.dense`çš„10ä¸ªèŠ‚ç‚¹ï¼Œä½œç”¨äº`x`ã€‚ç„¶åä¸ºäº†åˆ›å»ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†è®¾å®š`model
    = Cas model`ï¼Œæ¥ç€éœ€è¦æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºã€‚
- en: and it's going to create the model from thoseã€‚ So we're going to do outputs
    and rather inputs equals inputsã€‚ outputs equals outputsã€‚And then we're just going
    to return our model right so this is this is now our model very similar looking
    to the previous one just that we added batch norm and what we can do now is we
    can do model equals my model we can call that and then we can use the same compile
    and fit and evaluate as we did for the sequential one so let's run this nowã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æ ¹æ®è¿™äº›å†…å®¹åˆ›å»ºæ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¾“å‡ºå’Œè¾“å…¥åˆ†åˆ«ç­‰äºè¾“å…¥å’Œè¾“å‡ºã€‚ç„¶åæˆ‘ä»¬å°†è¿”å›æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ç°åœ¨è¿™æ˜¯æˆ‘ä»¬çš„æ¨¡å‹ï¼Œçœ‹èµ·æ¥ä¸ä¹‹å‰çš„æ¨¡å‹éå¸¸ç›¸ä¼¼ï¼Œåªæ˜¯æˆ‘ä»¬æ·»åŠ äº†æ‰¹é‡å½’ä¸€åŒ–ã€‚æˆ‘ä»¬å¯ä»¥åšçš„æ˜¯ç”¨
    `my_model` æ¥è¡¨ç¤ºæ¨¡å‹ï¼Œç„¶åå¯ä»¥ä½¿ç”¨ä¸é¡ºåºæ¨¡å‹ç›¸åŒçš„ç¼–è¯‘ã€æ‹Ÿåˆå’Œè¯„ä¼°æ–¹æ³•ï¼Œæ‰€ä»¥ç°åœ¨è®©æˆ‘ä»¬æ¥è¿è¡Œå®ƒã€‚
- en: Alrightï¼Œ we get an errorã€‚ Let's see what is the problemã€‚All rightã€‚ so I think
    I know what the problem is we need to do a flatten layer in between because the
    shapes aren't going to match when we send it through the fully connected layerã€‚
    so we're just going to do layers that flatten and then of X and hopefully it should
    work nowã€‚Alrightï¼Œ so one thing we can see here is that after 10 epos using these
    batch normalization it's much faster to train so I think before it had 72% training
    accuracy now it's almost 93%ã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘ä»¬å‡ºç°äº†ä¸€ä¸ªé”™è¯¯ã€‚è®©æˆ‘ä»¬çœ‹çœ‹é—®é¢˜å‡ºåœ¨å“ªé‡Œã€‚å¥½çš„ï¼Œæˆ‘æƒ³æˆ‘çŸ¥é“é—®é¢˜æ‰€åœ¨ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ä¸­é—´æ·»åŠ ä¸€ä¸ªæ‰å¹³åŒ–å±‚ï¼Œå› ä¸ºå½“æˆ‘ä»¬é€šè¿‡å…¨è¿æ¥å±‚æ—¶ï¼Œå½¢çŠ¶å°†ä¸åŒ¹é…ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨
    `layers.Flatten()`ï¼Œç„¶åå¯¹Xè¿›è¡Œå¤„ç†ï¼Œå¸Œæœ›è¿™æ¬¡å¯ä»¥æ­£å¸¸å·¥ä½œã€‚å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°çš„ä¸€ä»¶äº‹æ˜¯ï¼Œåœ¨ä½¿ç”¨è¿™äº›æ‰¹é‡å½’ä¸€åŒ–åï¼Œç»è¿‡10ä¸ªè®­ç»ƒå‘¨æœŸï¼Œè®­ç»ƒé€Ÿåº¦æ˜æ˜¾åŠ å¿«ã€‚æˆ‘è®°å¾—ä¹‹å‰çš„è®­ç»ƒå‡†ç¡®ç‡ä¸º72%ï¼Œç°åœ¨å‡ ä¹è¾¾åˆ°äº†93%ã€‚
- en: although the test set accuracy hasn't actually improved that muchï¼Œ I think it's
    actually gone worseã€‚ which is a obvious sign of the model overfitting to the training
    data and so what we need to when the model is overfitting we need to use regularization
    in different ways so that's actually what we're going to take a look at in the
    next video to try to see how we can improve this to make this gap a little bit
    closer to each other so that there's not this wide of a gapã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æµ‹è¯•é›†çš„å‡†ç¡®ç‡å¹¶æ²¡æœ‰æ˜¾è‘—æé«˜ï¼Œæˆ‘è®¤ä¸ºå®é™…ä¸Šæœ‰æ‰€ä¸‹é™ã€‚è¿™æ˜¾ç„¶æ˜¯æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿‡æ‹Ÿåˆçš„è¿¹è±¡ã€‚å› æ­¤ï¼Œå½“æ¨¡å‹è¿‡æ‹Ÿåˆæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸åŒçš„æ–¹å¼ä½¿ç”¨æ­£åˆ™åŒ–ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­æŸ¥çœ‹å¦‚ä½•æ”¹å–„è¿™ä¸ªé—®é¢˜ï¼Œä»¥ä½¿è¿™ä¸¤ä¸ªç»“æœçš„å·®è·ç¼©å°ä¸€äº›ï¼Œè€Œä¸æ˜¯å¦‚æ­¤ä¹‹å¤§ã€‚
- en: Here are a couple of suggestions to play around with the code and try to get
    some more experience The first thing is check what kind of accuracy you can get
    on the test set by you training for longer increasing the model sizeã€‚ maybe changing
    kernel sizes play around with padding and so on the second thing is that in the
    last video we trained a fully connected neural network on Eminist what can you
    get by in using a COvnet on that instead on that data set but anyways that is
    how but anyways in this video you saw how to train a basic neural network using
    the sequential and the functional API if you have any questions leaving them in
    the comments below Thank you so much for watching the video and I hope to see
    you in the next oneã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å‡ ä¸ªå»ºè®®ï¼Œå¯ä»¥å°è¯•å¯¹ä»£ç è¿›è¡Œä¿®æ”¹ï¼Œä»¥è·å–æ›´å¤šçš„ç»éªŒã€‚é¦–å…ˆæ˜¯æ£€æŸ¥ä½ åœ¨æµ‹è¯•é›†ä¸Šå¯ä»¥è·å¾—æ€æ ·çš„å‡†ç¡®ç‡ï¼Œé€šè¿‡å»¶é•¿è®­ç»ƒæ—¶é—´æˆ–å¢åŠ æ¨¡å‹å¤§å°ï¼Œå¯èƒ½è¿˜å¯ä»¥é€šè¿‡æ”¹å˜å†…æ ¸å¤§å°ã€è°ƒæ•´å¡«å……ç­‰æ–¹å¼æ¥å°è¯•ã€‚ç¬¬äºŒç‚¹æ˜¯åœ¨ä¸Šä¸€æ®µè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬åœ¨Eministä¸Šè®­ç»ƒäº†ä¸€ä¸ªå…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œä½¿ç”¨COvnetå¤„ç†è¯¥æ•°æ®é›†ä¼šå¾—åˆ°æ€æ ·çš„ç»“æœã€‚ä¸è¿‡ä¸ç®¡æ€æ ·ï¼Œåœ¨è¿™ä¸ªè§†é¢‘ä¸­ä½ çœ‹åˆ°çš„æ˜¯å¦‚ä½•ä½¿ç”¨é¡ºåºå’ŒåŠŸèƒ½APIæ¥è®­ç»ƒä¸€ä¸ªåŸºæœ¬çš„ç¥ç»ç½‘ç»œã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·åœ¨ä¸‹é¢çš„è¯„è®ºä¸­ç•™è¨€ã€‚éå¸¸æ„Ÿè°¢ä½ è§‚çœ‹è¿™ä¸ªè§†é¢‘ï¼Œå¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚
- en: '![](img/1090d091c86a18e1ad139b92203046b6_6.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1090d091c86a18e1ad139b92203046b6_6.png)'
