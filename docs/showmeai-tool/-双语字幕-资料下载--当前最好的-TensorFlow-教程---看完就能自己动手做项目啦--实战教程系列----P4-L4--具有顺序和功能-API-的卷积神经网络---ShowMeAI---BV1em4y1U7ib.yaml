- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„Äë‚ÄúÂΩìÂâçÊúÄÂ•ΩÁöÑ TensorFlow ÊïôÁ®ãÔºÅ‚ÄùÔºåÁúãÂÆåÂ∞±ËÉΩËá™Â∑±Âä®ÊâãÂÅöÈ°πÁõÆÂï¶ÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P4ÔºöL4- ÂÖ∑ÊúâÈ°∫Â∫èÂíåÂäüËÉΩ API
    ÁöÑÂç∑ÁßØÁ•ûÁªèÁΩëÁªú - ShowMeAI - BV1em4y1U7ib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](img/1090d091c86a18e1ad139b92203046b6_0.png)'
  prefs: []
  type: TYPE_IMG
- en: Welcome back guysÔºå hope you're doing awesome and in this video we will continue
    and now build a convolutional neural network and as usual there are resources
    of video lectures in the description to find more about the concepts for this
    video So with that said„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's get started we're going first import OS and we're going to do OS dot environment
    and do Tf CPP Min log level and again this is just for ignoring information messages
    from Tensorflowlow that can be a little bit annoying„ÄÇAnd then we're going to do
    import Tensorflow as Tf„ÄÇFrom TensorflowÔºå import ks„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: From Tensorflow dot ks import layers and then from Tensorflow dot Cars do data
    sets„ÄÇ we're going to import Cypher 10„ÄÇ So in this video we're going to take a
    look at the Cypher 10 data set and it's basically more natural images of of 10
    different classes from airplane„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: automobile mobile bird truckÔºå etc cetera„ÄÇ and the images are„ÄÇ![](img/1090d091c86a18e1ad139b92203046b6_2.png)
  prefs: []
  type: TYPE_NORMAL
- en: we have 50Ôºå000 training images and then we have 10Ôºå000 test imagesÔºå total of
    60„ÄÇ000 where each image is 32 by 32 pixels so they are relatively small and then
    we have RGB colored so they have three channels I found this pretty interesting
    blog post by Andrea Kpathy that where he actually trained himself on Cypher 10
    and he came to the conclusion let's see that Cypher 10 human level accuracy is
    approximately 94% and if you actually check the most recent models trained on
    Cypher10 they go beyond this so the more recent models are much much better than
    human level performance on this dataset set„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1090d091c86a18e1ad139b92203046b6_4.png)'
  prefs: []
  type: TYPE_IMG
- en: Now I'm going to copy in two lines and most likely you don't need them„ÄÇ but
    if you're running on GPU and you're run into any trouble„ÄÇ then most likely these
    two lines here are going to help you out„ÄÇAl right„ÄÇ so let's go back to sort of
    what we actually want to do in this video„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: which is first we want to load the Cypher 10 data set„ÄÇ and this is very similar
    to how we loaded MNIS„ÄÇIn the last video„ÄÇ and then so we're going to do x trainÔºå
    Y trainÔºå X testÔºå Y test„ÄÇAnd then Cypher 10 dot load data„ÄÇAnd„ÄÇAgainÔºå we want to
    convert it into F 32 because efficiency essentially computing it in F 64 is a
    bit of unnecessary necessary computation„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so what we can do is we can do xtrain equals xtrain s type and then float 32
    and then for normalization we can also divide by 255 so that the pixel values
    are between 0 and1„ÄÇAnd then similarly for X testÔºå we can do x test equals x test
    as type float 32„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and then we're just going divide by 255„ÄÇ Allright„ÄÇ so for our actual model let's
    start out with a sequential model and then we're going to build and make that
    a little bit more advanced„ÄÇ so we're going to do model equals Kas that sequential
    and we're going to start with Kas that input specifying the input shape in this
    case„ÄÇSince we're using convolutional neural networksÔºå we are not going to reshape
    it so that we don't flatten it in the beginning„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so that means we're going to maintain the heightÔºå so 32 in height„ÄÇ 32 and width
    and then three channels for RGB so that they are colored so that's the input shape
    of each image then we're going to do layers„ÄÇ co2 d and we're going to do I don't
    knowÔºå 32 out channels so the first„ÄÇFirst argument here of comm 2 do is that how
    many channels we want this convolutional layer to output so in the beginning we
    have three channels we want the output to then be 32 then we're going to specify
    the kernel size we're just going to set that to three and so if we set just a
    single integer here that's going to be expanded to be the same kernel size for
    the height and the width so that's essentially writing this just more I guess
    less of verbo just writing the integer„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And then we can specify padding so here you can specify valid or same so valid
    here is the default and then so what's going to happen is that these pixel values
    here„ÄÇ if we use same convolution then theyre going to be maintained so after this
    layer they're still going to be 32 pixels height and then 32 pixels width„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but if we use valid then that's going to change depending on our kernel size„ÄÇ
    so in this case they're actually going to become 30 by 30 pixels„ÄÇSo this is essentially
    just a hyperparameter that you can play around with„ÄÇ I'm just going to set it
    to validÔºå although there's really no point since this is the default argument„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And then we can set the activation similarly to how we did for our neural network
    to RE„ÄÇAnd then let's do a max pooling to D„ÄÇAnd so here we can specify the pool
    size„ÄÇ let's say two by two so that it's halfd in the inputÔºå so for example„ÄÇ if
    we use a valid convolution hereÔºå this is going to be 30 by 30 and of course you
    can do print model summary to actually see these changes„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Maybe we can do that actuallyÔºå so let's do print model that summary„ÄÇAnd let's
    see„ÄÇ So as we can see here nowÔºå after the first comeÔºå it's going to be 30 by 30
    and then we have 32 channels and then after the max pullinging„ÄÇ it's going to
    have the input size pixelÔºå so they're going to be 15 by 15„ÄÇAnd then we could do
    just another couple of layers„ÄÇ So layers come to D„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's say 64 out channels and then same„ÄÇ I meanÔºå kernel size 3„ÄÇ and then let's
    just use valid again and activation re„ÄÇÂóØ„ÄÇLet's do another max pooling„ÄÇAnd then„ÄÇAgain„ÄÇ
    we're going to have 128 channels we just double it and then three and activation
    equals relative again„ÄÇ so then for our actual output we're going to do layers
    do flatten we're going to have let's say one intermediate so we're going to have
    64 nodes in this fully connected and activation equals relative and then for our
    output we're just going to do layer dense and then 10 output nodes„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So that's for our actual model„ÄÇ then we're going to compile our model„ÄÇ So model
    that compile specify the loss function to be CAs that losses that spars„ÄÇCategorical
    cross entropyÔºå so the same that we use in the last video from logics equals true
    because we're not having a softmax activation on our output„ÄÇAnd then let's say
    optimizerÔºå let's use at„ÄÇSo if we're going to set also the learning rate„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's set it to 3 e minus4„ÄÇAnd then metricsÔºå let's keep track of accuracy„ÄÇAlright„ÄÇ
    so that's where a model compile now to actually train the model„ÄÇ let's just do
    model that fit x trainÔºå y trainÔºå batch sizeÔºå let's sayÔºå 264„ÄÇAnd then let's run
    for 10 epochs and let's say verbose equals 2 so that it prints after each epoch
    in this way you won't get a progress bar„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but it's going to print information about the training every epoch„ÄÇAnd then
    after training„ÄÇ let's do model dot evaluate on the test set„ÄÇAnd then also again„ÄÇ
    let's set the batch size to the same and no epochs because we're just going to
    run at once and then verboos equals2„ÄÇ AllrightÔºå so let's run this and hopefully
    we should still have okay„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so let' let's do also print model that summary here„ÄÇAnd then we can inspect
    that„ÄÇüòîÔºåSo„ÄÇAlright„ÄÇ so we're letting a train„ÄÇ So we can see here that„ÄÇWe can sort
    of see the number parameters„ÄÇ let's see„ÄÇ it's here are the most of the parameters
    of the model and„ÄÇSo as we can see here we can see sort of the total number of
    parametersÔºå 1225Ôºå000„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and that's actually a veryÔºå very small networkÔºå so we're not expecting to get
    very„ÄÇ very high accuracy on this but sort of just to illustrate how to build convolutions
    and then using Mac pullinging and so on„ÄÇI believe that Alexnett„ÄÇI believe that
    AlexNeÔºå which was sort of the first convolutional neural network that really revolutionized
    computer vision„ÄÇ had about 60 million parametersÔºå so just to get a perspective
    on how small 225Ôºå000 actually is„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: AlrightÔºå so let's see it's done training and then it's printing the model of
    summary again okay so let's remove that„ÄÇüòîÔºåAnd then let's see sort of what we get
    so we get 72% training accuracy at end and then 68% test accuracy„ÄÇ Now as you
    can see we have a lot of room for improvement So if you train this for long„ÄÇ you
    would probably get a better accuracy but we're not really interested in that So
    what we're going to do now is take a look at how we can build a functional using
    the functional API and sort of build a very similar convolution in neural network
    but we're going to add some more advanced things so„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Let's doÔºå let's actually do a function„ÄÇ So let's do define my model„ÄÇ and then
    inside this„ÄÇ let's do input equals„ÄÇKas input and then shape let's seeÔºå 32Ôºå32Ôºå3„ÄÇAnd
    then let's do x equals layers„ÄÇcom2 dÔºå let's do the same channels with 32 and then
    kernel size 3„ÄÇ and then we're going to send the input through that layer„ÄÇAnd then„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: We're going to use batch normalization and so that's going to be in the video
    description if you if you're unfamiliar with batch norm so batch normalization
    and we're going to initialize that and then we're just going to send in x through
    that one and then as you might have noticed here we're not using a activation
    function here that's because if we're using batch norm we want to sort of send
    it through the convolutional area first and then through the batch norm and then
    we want to send it through the activation function so how we can do that is by
    doing cares„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: That activation start re than of x„ÄÇAnd yeahÔºå so let's add some max pullingingÔºå
    max pullinging to D„ÄÇAnd we actually don't have to specify the pool sizeÔºå so let's
    seeÔºå yeah I did it here„ÄÇ but we don't have to such probably mentioned that when
    we did this one„ÄÇ but you don't have to specify the pool size to be 2 by 2Ôºå that's
    the default argument„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but of course you can change it to whatever you want„ÄÇ it's just that 2 by  two
    is what you most frequently use„ÄÇSo let's just do max pulling and then send it
    through that one and then let's create another one„ÄÇ so let's do layers column
    to d 64 and I don't know„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's do a kernel size of 5 and let's do padding equals same and just for one
    and then let's do„ÄÇAndAnother batch normÔºå so batch normalization„ÄÇOf x„ÄÇAnd then
    cares that activations dot relu„ÄÇOf X„ÄÇAnd then after thisÔºå let's do one moreÔºå so
    let's do layers come to D 128Ôºå3„ÄÇAnd then of x„ÄÇOf X„ÄÇ and then„ÄÇAnother batch worm„ÄÇOf
    X activation„ÄÇRello„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And then we're going to now send it through a a dense layer„ÄÇ So we're going
    to do layers that dense„ÄÇ64 nodes„ÄÇAnd activation is re„ÄÇAnd then the outputs is
    going to be just layers dense of 10 nodes of x„ÄÇAnd then to create our modelÔºå we're
    going to do model equals„ÄÇCas that model„ÄÇ and then we need to specify the inputs
    and the outputs„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and it's going to create the model from those„ÄÇ So we're going to do outputs
    and rather inputs equals inputs„ÄÇ outputs equals outputs„ÄÇAnd then we're just going
    to return our model right so this is this is now our model very similar looking
    to the previous one just that we added batch norm and what we can do now is we
    can do model equals my model we can call that and then we can use the same compile
    and fit and evaluate as we did for the sequential one so let's run this now„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: AlrightÔºå we get an error„ÄÇ Let's see what is the problem„ÄÇAll right„ÄÇ so I think
    I know what the problem is we need to do a flatten layer in between because the
    shapes aren't going to match when we send it through the fully connected layer„ÄÇ
    so we're just going to do layers that flatten and then of X and hopefully it should
    work now„ÄÇAlrightÔºå so one thing we can see here is that after 10 epos using these
    batch normalization it's much faster to train so I think before it had 72% training
    accuracy now it's almost 93%„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: although the test set accuracy hasn't actually improved that muchÔºå I think it's
    actually gone worse„ÄÇ which is a obvious sign of the model overfitting to the training
    data and so what we need to when the model is overfitting we need to use regularization
    in different ways so that's actually what we're going to take a look at in the
    next video to try to see how we can improve this to make this gap a little bit
    closer to each other so that there's not this wide of a gap„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Here are a couple of suggestions to play around with the code and try to get
    some more experience The first thing is check what kind of accuracy you can get
    on the test set by you training for longer increasing the model size„ÄÇ maybe changing
    kernel sizes play around with padding and so on the second thing is that in the
    last video we trained a fully connected neural network on Eminist what can you
    get by in using a COvnet on that instead on that data set but anyways that is
    how but anyways in this video you saw how to train a basic neural network using
    the sequential and the functional API if you have any questions leaving them in
    the comments below Thank you so much for watching the video and I hope to see
    you in the next one„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1090d091c86a18e1ad139b92203046b6_6.png)'
  prefs: []
  type: TYPE_IMG
