# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- Pyspark DataFrames è¿‡æ»¤æ“ä½œ - ShowMeAI - BV1sL4y147dP

ã€‚

![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_1.png)

Hello allã€‚ my name is Kushak and welcome to my YouTube channelã€‚ So guys we will be continuing the Pispar playlist series and when I started this particular series guysã€‚ they were request for many people to please also complete the MysQL with Python playlist also don't worry about it guys now since you have that specific request also what I'll do is that every day one Pipar video1 SQL videos at least I'll try to do it I also wanted to complete that particular playlistã€‚

 but because of time I was not able to create much more materials So because of that it laggged but don't worry againã€‚ the main aim is to upload more and more videos for you all so that you'll be able to follow them properly you'll be able to utilize them for your successful transition in any career that you're going ahead so please make sure that just be patient I'll try to upload parallelly both of this and I will try to complete the playlistã€‚

 So yes enjoy this particular videos guysello my name is Krna and welcome to my YouTubetu channelã€‚![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_3.png)

Guysï¼Œ today we are in the tutorial for of Pi Park data frames and here in this particular video we are going to discuss about filter operationã€‚ğŸ˜Šï¼ŒAF up operation is pretty much important for data preprosing techniqueã€‚ If you want to retrieve some of the records based on some kind of conditionsã€‚ some kind of boolean conditionsï¼Œ we can definitely do that with the help of filter operationã€‚

 Now guysï¼Œ please make sure that you follow this particular playlist with respect to Pipar I will be uploading more and more videos as we go ahead and remember one more thing there was a lot of complaint from people telling to upload sql with Pythonã€‚ don't worry parallel I'll start uploading sql with Pythonã€‚

 I make sure me sorry because of some delay because I was doing some kind of work busy with something but I'll make sure that I'll try to upload all the videosã€‚ So parallel Sql with Python will also get uploadedã€‚ So let's proceedã€‚ Now first of allã€‚ let me go and make some cellã€‚ Now today for thisï¼Œ Ive taken a data setï¼Œ a small data setã€‚ which is called a test1 do csv Here I have some data set like name age experience and salary and I'm just going to use this and try to show you some of the example with respect to filter operation initially whenever you want to work with Pipar you have to make sure that you install allã€‚

ğŸ˜Šï¼ŒLibrariesï¼Œ so I'm going to use pass spicepar dot sql import spark session and this will actually help us to create a spark session right and that is the first step whenever we want to basically work with Pipar right so we will be using spark session dot builder dot app nameã€‚

Then I'm just going to create my app name as data frame and basically write get or create functionã€‚ which will actually help me to quickly create a spark sessionã€‚ I think this is pretty much familiar with every one of youã€‚ Now let's proceed and let's try to read a specific data setã€‚

 So over here what I'm going to do I'm just going to create a variable Df underscoreosco I spark and I'm going to use this spark variable dot read or dot csv And here I'm just going to consider my data set test oneã€‚ğŸ˜Šï¼ŒDot csvã€‚And here I'm just going to make sure that we have this particular option selected Hesical to true and in for schemaã€‚

 physical to trueã€‚ I think this all I've actually explained youã€‚ then if I write D F dot pricepar dot showã€‚ here you'll be able to see your data setã€‚ Okayã€‚ so it is readingï¼Œ let's see how will get the outputã€‚ So this is my entire outputã€‚ Nowï¼Œ guysã€‚ as I showed you that we will be working onã€‚ğŸ˜Šï¼ŒFilter operationã€‚

 I will try to retrieve some of the records based on some conditionsã€‚ Rememberã€‚ filters also are available in pandasï¼Œ but there you try to write in a different wayã€‚ Let me just show you how we can perform filter operation by using pie sparkã€‚ Okayã€‚ so filter operationsã€‚ Let me make this as a markdownã€‚ So it looks bigã€‚ It looks amazingã€‚

 let me make some more cells perfectã€‚ Nowï¼Œ first stepï¼Œ how do I do a filter operationã€‚ Supp I want to find out salary of the people who less than probably 20000ã€‚ Okayã€‚ less than or equal to 20000ã€‚ I can write like thatã€‚ less than or equal to 20000ã€‚ğŸ˜Šï¼ŒNow for thisã€‚ there are two ways how we can write it first wayã€‚ I'll just try to use the filter operationã€‚

 So you have like dot filter and here you just have to specify the condition that you wantã€‚ supposeupp I'll write salary is less than or equal to 20000ã€‚ remember this salary should be the same name of the column over here right and when I write dot show you will be able to see this specific records and you'll be able to see okay less than or equal to 20000 is this form four people Sunny Paul Herun Subumm here you'll be able to see all these things along with the experience right now this is one way probably I just want to pick up after putting this particular condition I want to pick up two columns So what I can do I can use this and then I can basically write dot select and here I'm going to specify my name probably I want the name and Hã€‚

Name comma Hã€‚ So dot shopã€‚I do thisã€‚Nowï¼Œ this is how you can actually do it againã€‚here you can see that name underscore age is actually there and you are able to get that specific information After thisã€‚ probably I want to do some of the operationã€‚ you can actually do less than greater than whatever things you wantã€‚ Probably I want to put two different conditionsã€‚ Then how should I put itã€‚

 Let's see let's see for that alsoï¼Œ So I'll write D D F Ppar dotã€‚ğŸ˜Šï¼ŒFterã€‚ And here I am going to specify my first conditionã€‚ Suppose this is one wayã€‚ this is one way by using filter operationã€‚ Alsoï¼Œ guysï¼Œ and this conditions that I'm writingã€‚ I can also write something like thisã€‚ see thisã€‚ Supp if I write D F pie spark of salaryã€‚

 suppose salary isã€‚ğŸ˜Šï¼ŒLess than or equal to 20000ã€‚ I can also write like thisã€‚ I will also be able to get the same outputã€‚ So here you'll be able to see the same output over hereã€‚ Nowï¼Œ suppose I want to write multiple conditionsã€‚ How do I writeï¼Œ it's very simpleã€‚ I will take thisã€‚ This is first this is one of my conditionã€‚

 So I'm just going to use this conditionã€‚ and I can also use an and operationï¼Œ you knowã€‚ So I'll say and or or any kind of operation that you want probably I want to say that Df underscorecope pi for salary is great less than or equal to 2000 20000 and probably I want a Df ppar of salaryã€‚

ğŸ˜Šï¼ŒSalaryã€‚Greater than or equal to 15000ã€‚ So I'll be able to get all those specific recordsã€‚ Okayã€‚ and againï¼Œ I'll try to put this in another bracketsã€‚ Make sure that you do thisã€‚ otherwiseã€‚ you will be getting an error okayã€‚ğŸ˜Šï¼ŒVeryï¼Œ very simple guysã€‚ So let's see how Ive actually returnã€‚ It is something like this Df underscore Pi dot filterã€‚

 Df Pipar of sal less than or equal to 20000 greater equal to 150 If I executeã€‚ you'll be able to see between 15000 to 20000 you'll be able to find outã€‚ you can also write or Then you'll be able to get all the different different valuesã€‚ Now this is a kind of filter operation that you can basically specify rememberã€‚

 this will be pretty much handy when you are probably retrieving some of the records with respect to any kind of data setsã€‚ and you can try different different thingsã€‚ this is one way where you are actually directly providing your column name and putting a condition internally this Pi spark actually Pipar data frameã€‚

 understand thatï¼Œ and you'll be able to get the output rightï¼Œ So yesã€‚ this was it all about this particular videoã€‚ I hope you like itã€‚ I hope you like this particular filter operationã€‚ Just try to do it from your sideã€‚ Okay one more operation is basically pendingã€‚ I can also write like this Cã€‚

 everybody I can basicallyã€‚ğŸ˜Šï¼ŒSay thatï¼Œ okayã€‚Probably I can use this operationã€‚ which is called as not operationï¼Œ let's seeã€‚How this not operation will be comingã€‚ Okayï¼Œ basicallyã€‚ the inverse condition operationï¼Œ we basically sayï¼Œ So I'll be using thisã€‚Okayã€‚And thisã€‚ and inside thisï¼Œ I can put a not conditionï¼Œ which like thisã€‚

 So I'll say this is a not of Df of5par salaries less than equal equal to 200ã€‚ So anything that is greater than 20000 will be given over hereã€‚ Okayï¼Œ so inverse operationã€‚ you can say inverse filter operationã€‚ So yesï¼Œ this was one of the thing I'll say inverse filter operationã€‚ And I've actually shown you what things we have actually discussed over hereã€‚

 So I hope you like this particular videoï¼Œ please to subscribe the channel if you are not subscribeã€‚ I'll see in the next videoã€‚ Have have a great dayã€‚ Thank you bye byeã€‚ğŸ˜Šã€‚![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_5.png)