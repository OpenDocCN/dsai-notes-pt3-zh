# 【双语字幕+资料下载】PySpark 大数据处理入门，带你玩转 Python+Spark 大数据操作与分析！＜实战教程系列＞ - P4：L4- Pyspark DataFrames 过滤操作 - ShowMeAI - BV1sL4y147dP

。

![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_1.png)

大家好，我的名字是 Kushak，欢迎来到我的 YouTube 频道。所以我们将继续这个 Pipar 播放列表系列。当我开始这个系列时，有很多人请求我完成 MysQL 与 Python 的播放列表，别担心。现在既然你们有这个特定的请求，我每天至少会尝试上传一个 Pipar 视频和一个 SQL 视频。我也想完成这个播放列表。

但由于时间原因，我没能创建更多的材料，因此有些滞后，但别担心。主要目的是为你们上传更多的视频，这样你们就能更好地跟随，能够在未来的职业转型中利用这些内容。所以请确保耐心等待，我会并行上传这两个系列，并尽力完成这个播放列表。

是的，大家好，我的名字是 Krna，欢迎来到我的 YouTube 频道。![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_3.png)

大家好，今天我们在 Pi Park 数据框的教程中，这个视频我们将讨论过滤操作。😊，过滤操作对于数据预处理技术非常重要。如果你想根据某些条件，某些布尔条件来检索一些记录，我们绝对可以通过过滤操作来实现。

现在大家，请确保你们跟随这个 Pipar 的播放列表，我会随着进展上传更多视频。另外，还有很多人抱怨希望上传 SQL 与 Python 的内容，别担心，我会并行开始上传 SQL 与 Python 的视频。

我很抱歉因为一些延误，我一直忙于某些工作，但我会确保尽量上传所有视频。所以并行的 SQL 与 Python 也会被上传。那么我们开始吧。首先，让我创建一些单元格。今天我使用了一个数据集，一个小数据集，叫做 test1.csv。在这里，我有一些数据，比如姓名、年龄、经验和薪水，我将用这些数据展示一些关于过滤操作的示例。首先，每当你想使用 Pipar 时，必须确保安装所有必要的库。

😊，库，我将使用 `from pyspark.sql import SparkSession`，这将帮助我们创建一个 Spark 会话，这是我们基本上在使用 Pipar 时的第一步。因此我们将使用 `SparkSession.builder.appName`。

然后我将我的应用程序命名为data frame，并基本上编写get或create函数。这实际上将帮助我快速创建一个spark会话。我想这对你们每个人来说都是非常熟悉的。现在让我们继续，尝试读取特定的数据集。

所以在这里我要做的就是创建一个变量Df underscoreosco I spark，我将使用这个spark变量.dot read或.dot csv。在这里，我将考虑我的数据集test one。😊，Dot csv。在这里，我将确保选中了这个特定的选项Hesical为true，并在模式中。

physical为true。我想这就是我实际上向你解释的全部内容。然后如果我写D F dot pricepar dot show。在这里你将能够看到你的数据集。好的。它正在读取，我们来看看输出。这个是我的全部输出。现在，伙计们。正如我所展示的，我们将进行。😊，过滤操作。

我将尝试根据一些条件检索一些记录。记住，过滤器在pandas中也是可用的，但在那里你尝试用不同的方式来写。让我向你展示如何使用pie spark进行过滤操作。好的。所以过滤操作。让我把这个做成markdown。这样看起来更大。看起来很棒。

让我再做一些完美的单元。现在，第一步，我该如何进行过滤操作。假设我想找出工资低于20000的人。好的。小于或等于20000。我可以这样写。小于或等于20000。😊，现在为此。我们有两种写法，第一种方式。我将尝试使用过滤操作。

所以你有像.dot filter，这里你只需指定你想要的条件。假设我写工资小于或等于20000。记住，这个工资应该是这里列的同名。当我写.dot show时，你将能够看到这些特定的记录，你会看到小于或等于20000的有四个人Sunny Paul Herun Subumm，在这里你能够看到所有这些信息以及经验，现在这是其中一种方式，可能我只想在设置了这个特定条件后挑选两列。那么我可以这样做，我可以使用这个，然后基本上写.dot select，在这里我将指定我的名字，可能我想要名字和H。

Name comma H。所以.dot shop。我这样做。现在，这就是你可以实际做到的，再次。在这里你可以看到name underscore age实际上是存在的，你能够获取那个特定的信息。在此之后。可能我想做一些操作。你可以实际做小于大于等你想要的任何事情。可能我想放两个不同的条件。那么我应该怎么做。

让我们看看，好的，我会写D D F Ppar点。😊，Fter。这里我将指定我的第一个条件。假设这是一个方法。这是使用过滤操作的一种方式。还有，伙计们，我正在写的这些条件，我也可以写成这样。看这个。如果我写D F pie spark的工资。

假设工资是。😊，小于或等于20000。我也可以这样写。我也会得到相同的输出。所以在这里你会看到相同的输出。现在，假设我想写多个条件。我该怎么写，实际上很简单。我会这样做。这是第一个，这是我的一个条件。

所以我只是要使用这个条件。我也可以使用与操作，你知道的。所以我会说和或任何你想要的操作。可能我想说Df underscorecope pi的工资大于等于2000 20000，而且我可能想要Df ppar的工资。

😊，工资。大于等于15000。所以我将能够获取所有这些特定记录。好的，然后，我会尝试将其放在另一个括号中。确保你这样做。否则你会收到错误信息。好的。😊，非常非常简单，伙计们。让我们看看我实际是如何写的。它是这样的 Df underscore Pi 点过滤器。

Df Pipar的工资小于或等于20000且大于等于150。如果我执行，你将能看到在15000到20000之间的记录。你也可以写或，然后你将能够得到所有不同的值。这是一种你可以基本上指定的过滤操作，请记住。

当你检索与任何数据集相关的一些记录时，这将非常方便。你可以尝试不同的方式。这是你实际提供列名并在内部放置条件的一种方式，这个Pi spark实际上是Pipar数据框。

理解这一点，你就能正确获取输出。所以，是的。这就是这段视频的全部内容。希望你喜欢它。希望你喜欢这个过滤操作。试着从你这边做一下。好的，还有一个操作基本上是未完成的。我也可以写成这样C。

每个人我基本上可以。😊，说，好吧。也许我可以使用这个操作，称为非操作，让我们看看。这个非操作将如何出现。好的，基本上。逆条件操作，我们基本上这样说。所以我会使用这个。好的。在里面，我可以放一个非条件，就像这样。

所以我会说这是一个不等于Df of5par的工资小于等于200的情况。所以任何大于20000的将会在这里给出。好的，所以这是逆操作。你可以说是逆过滤操作。所以，是的，这就是我会说的逆过滤操作。我实际上向你展示了我们在这里讨论的内容。

希望你喜欢这个视频，如果你还没有订阅，请订阅频道。我会在下一个视频中见到你。祝你有个美好的一天。谢谢，再见。😊！![](img/0ca5dfbb4a99ff7c74026b7b4989e47f_5.png)
