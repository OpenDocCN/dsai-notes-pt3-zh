- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPytorch ËøõÈò∂Â≠¶‰π†ËÆ≤Â∫ßÔºÅ14‰ΩçFacebookÂ∑•Á®ãÂ∏àÂ∏¶‰Ω†Ëß£ÈîÅ PyTorch ÁöÑÁîü‰∫ßÂ∫îÁî®‰∏éÊäÄÊúØÁªÜËäÇ ÔºúÂÆòÊñπÊïôÁ®ãÁ≥ªÂàóÔºû - P2ÔºöL2-
    ‰Ωø PyTorch Êõ¥Âä†‚Äú‰∏é NumPy ÂÖºÂÆπ‚Äù - ShowMeAI - BV1ZZ4y1U7dg
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: üéº„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: Hi everyoneÔºå I'm Mike RuberryÔºå an engineer at Facebook working on Pytorrch„ÄÇ
    and I'm going to be talking to you about how we're making Pytorrch more nupy compatible
    In this short talk„ÄÇ there'll be three parts„ÄÇFirstÔºå I'll describe what it means
    for Pytorrch to be nu P compatible and what our goals are„ÄÇIn the second partÔºå
    I'll talk about the many new and updated operators we have in Pytororch 1„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 7 that make it the most nuy compatible release of Pytorch yet„ÄÇAnd in the third
    part„ÄÇ I'll talk briefly about where we're going in P towards 1„ÄÇ8 and beyond„ÄÇSo
    let's get started by talking about what it means for Pytorch to be numpy compatible„ÄÇ
    For those of you who don't knowÔºå Numpy is a popular Python package for working
    on arrays or what Pytorch would call tensors„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_3.png)'
  prefs: []
  type: TYPE_IMG
- en: Its API is well known and that makes it familiar to many users coming to PyTtororch
    for the first time„ÄÇBy making Pytorch compatible with NumpyÔºå which means it implements
    the same functions that Numpy does„ÄÇ and that the behavior of those functions is
    pretty much the same in Pytorch and in Numpy„ÄÇThis means that people familiar with
    nuy will already be familiar with Pytorch„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: making it intuitive and easy to use„ÄÇThis should let people spend less time looking
    at documentation and more time developing their programs„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_5.png)
  prefs: []
  type: TYPE_NORMAL
- en: The idea of nuy compatible pieytorch is not new„ÄÇFrom the beginning„ÄÇ Pyedtort
    was designed to be like NumpyÔºå and as these code snippets show„ÄÇ both packages
    are extremely similar today„ÄÇThere are small differences between Pytorch and nuumpy„ÄÇ
    however„ÄÇFor exampleÔºå as previously mentioned„ÄÇWhat Numpy calls asÔºå Pytorch calls
    tensors„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: In this snippet we also see that Pytorch is a little more explicit about data
    types„ÄÇ requiring that the Tensor B be specified as containing floating point values
    before the exponential function can be called on it„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_7.png)
  prefs: []
  type: TYPE_NORMAL
- en: NowÔºå we might think that the goal of Numpy compatibility is to eliminate all
    differences between Pytorrch and Numpy„ÄÇThat's actually not the case„ÄÇThere will
    always be differences between Pytorrch and nupy because they focus on different
    scenarios„ÄÇPytorchÔºå for exampleÔºå is designed to run on multiple devicesÔºå not just
    on the CPU„ÄÇIt also runs„ÄÇ for exampleÔºå on GPUsÔºå TUsÔºå mobile devicesÔºå and custom
    Asics„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Pyitetorch is also designed to run neural networks„ÄÇAnd neural networks typically
    run in a lower floating point precision than scientific programs do„ÄÇFinallyÔºå Pytorch
    is designed to support autogradÔºå which has its own specific set of requirements„ÄÇFor
    exampleÔºå to compute a backwards pass properlyÔºå Pytorch has to save intermediate
    computations„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Foing on scenarios like this means that Pytorch and numpy will never be exactly
    the same„ÄÇ but we can still strive to make pytorch as similar to nuy as possible„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_9.png)
  prefs: []
  type: TYPE_NORMAL
- en: Now let's talk about how we've done that in PyTtororch 1„ÄÇ7 and why it's the
    most nuumpy compatible version of PyTtororch we've ever released„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_11.png)
  prefs: []
  type: TYPE_NORMAL
- en: It's because we've added a ton of new operators that Numpy had„ÄÇ but Pytororch
    was missing and even updated some older Pytorch operators whose behavior was different
    than their corresponding counterparts in Numpy„ÄÇ For exampleÔºå we've added a slew
    of functionality related to fast Fourier transforms„ÄÇWe have new functions for
    computing statistics like Torcht Quantile„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: We have helper functions for manipulating tensors like HtacÔºå Vt and Dt„ÄÇ We even
    have the zeroth order modified besel function of the first kind„ÄÇ We also updated
    some operatorsÔºå like divisionÔºå for example„ÄÇ in Pytorrch is now compatible with
    division in numppyy and Python 3„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: always performing a true division instead of sometimes performing an integer
    division„ÄÇüòäÔºåIn total„ÄÇ we modified over 65 operators in PyTtororch 1„ÄÇ7„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_13.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_14.png)'
  prefs: []
  type: TYPE_IMG
- en: NowÔºå where are we going WellÔºå in Piyr 1„ÄÇ8„ÄÇWe expect to add or modify another
    38 operators„ÄÇWe expect to expand on two new modules too„ÄÇThe Torch dot F of T module„ÄÇ
    which contains the fast Fourier functionality that I already mentioned and the
    Torchdot lineal module„ÄÇ which will contain linear algebra functionality„ÄÇAnd we
    also plan to keep our community engaged„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writingÔºå we had 14 active community contributors„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_16.png)
  prefs: []
  type: TYPE_NORMAL
- en: And since thenÔºå we've already added several more„ÄÇThis is a great opportunity
    for you to get involved too„ÄÇIf there is a function in nuumpy or s pie that you'd
    like to see in Pytororch„ÄÇ let us know by filing an issue on our GitHub„ÄÇAnd if
    you'd like to get involved by contributing an operator to Pytorch„ÄÇ see the link
    to issue to get started„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_18.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_19.png)'
  prefs: []
  type: TYPE_IMG
- en: A huge thank you again to our community contributors„ÄÇThis slide is already out
    of date„ÄÇ which is unfortunate„ÄÇBut it's been a great experience working with our
    fantastic Pytorch community to make Pytorch more nuumppy compatible and ultimately
    to make it easier to use„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_21.png)'
  prefs: []
  type: TYPE_IMG
- en: So thank you again for all our active contributors as of October of this year
    for their help and support„ÄÇüéºAnd thank you for listening to this talk about how
    we're making pieytorch more nup compatible„ÄÇ![](img/34c6afcf80c3f94fb9e6fa9f06c8c00d_23.png)
  prefs: []
  type: TYPE_NORMAL
