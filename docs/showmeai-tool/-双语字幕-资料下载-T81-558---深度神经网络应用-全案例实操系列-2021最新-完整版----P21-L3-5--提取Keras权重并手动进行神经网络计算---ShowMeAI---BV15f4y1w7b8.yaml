- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P21ï¼šL3.5- æå–Kerasæƒé‡å¹¶æ‰‹åŠ¨è¿›è¡Œç¥ç»ç½‘ç»œè®¡ç®—
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P21ï¼šL3.5- æå–Kerasæƒé‡å¹¶æ‰‹åŠ¨è¿›è¡Œç¥ç»ç½‘ç»œè®¡ç®—
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeffineã€‚ Welcome to applications of deep neural networks with Washington
    Universityã€‚ In this videoï¼Œ we're going to see how to actually extract the weights
    from a neural network created by Kes and put those weights into an equation so
    that we can actually calculate the output from the neural network and see that
    this there's really no magic to this processã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯Jeffineã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å®é™…æå–Kesåˆ›å»ºçš„ç¥ç»ç½‘ç»œä¸­çš„æƒé‡ï¼Œå¹¶å°†è¿™äº›æƒé‡æ”¾å…¥æ–¹ç¨‹ä¸­ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å®é™…è®¡ç®—ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œå¹¶çœ‹åˆ°è¿™ä¸ªè¿‡ç¨‹å¹¶æ²¡æœ‰ä»€ä¹ˆé­”æ³•ã€‚
- en: ğŸ˜Šï¼ŒThat it is simply weights multiplied against the inputs that produces a final
    output for the latest on my AI course and projectsã€‚ click subscribe in the bell
    next to it to be notified of every new videoã€‚ This is code from Ks and Tensorflowlowï¼Œ
    But this applies to really just about anythingã€‚ I am going to show you how to
    actually extract the weights from the neural networkã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œè¿™ä»…ä»…æ˜¯æƒé‡ä¸è¾“å…¥ç›¸ä¹˜ï¼Œäº§ç”Ÿæˆ‘çš„AIè¯¾ç¨‹å’Œé¡¹ç›®çš„æœ€ç»ˆè¾“å‡ºã€‚ç‚¹å‡»æ—è¾¹çš„é“ƒé“›è®¢é˜…ï¼Œä»¥ä¾¿æ¥æ”¶æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚è¿™æ˜¯Kså’ŒTensorflowlowçš„ä»£ç ï¼Œä½†è¿™å®é™…ä¸Šé€‚ç”¨äºå‡ ä¹ä»»ä½•ä¸œè¥¿ã€‚æˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•å®é™…æå–ç¥ç»ç½‘ç»œä¸­çš„æƒé‡ã€‚
- en: so that we can then put them onto a diagram and actually actually calculate
    it and come up with the same number that Tensorflowlow would haveã€‚ğŸ˜Šã€‚![](img/99c863804a8e2678a48ffb4d5482d3aa_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å°†å®ƒä»¬æ”¾å…¥å›¾è¡¨ä¸­ï¼Œå®é™…è¿›è¡Œè®¡ç®—ï¼Œå¾—å‡ºä¸Tensorflowlowç›¸åŒçš„æ•°å­—ã€‚ğŸ˜Šã€‚![](img/99c863804a8e2678a48ffb4d5482d3aa_1.png)
- en: For thisï¼Œ we're going to use an exclusive or neural networkï¼Œ that's the XOR
    functionã€‚These are the inputs to itï¼Œ0ï¼Œ0ï¼Œ the usual truth table for any sort of
    an and or an orã€‚ This is the expected outputã€‚ The thing to remember with X O R
    is if the two inputs are the sameã€‚ it's going to be 0ã€‚If the two outputs are differentï¼Œ
    zero and 1 versus 10ï¼Œ it's going to be oneã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå¼‚æˆ–ç¥ç»ç½‘ç»œï¼Œå³XORå‡½æ•°ã€‚è¿™æ˜¯å®ƒçš„è¾“å…¥ï¼Œ0ï¼Œ0ï¼Œä»»ä½•ä¸ä¸æˆ–ç›¸å…³çš„çœŸå€¼è¡¨ã€‚é¢„æœŸçš„è¾“å‡ºæ˜¯ã€‚è®°ä½XORçš„è¦ç‚¹æ˜¯ï¼Œå¦‚æœä¸¤ä¸ªè¾“å…¥ç›¸åŒï¼Œè¾“å‡ºå°±æ˜¯0ã€‚å¦‚æœä¸¤ä¸ªè¾“å‡ºä¸åŒï¼Œé›¶å’Œ1ä¸1å’Œ0ç›¸æ¯”ï¼Œè¾“å‡ºå°±æ˜¯1ã€‚
- en: Here we set up a neural networkã€‚ It has two inputs and a hidden layer of twoã€‚
    We're going for the absolute smallest neural network just to show that you don't
    really need that much to calculate an excluvoã€‚Alsoï¼Œ since we are going to calculate
    this by hand or just being lazyã€‚ we don't I don't want to give you a truly deepï¼Œ
    deep neural network and then calculate it by handã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬è®¾ç½®äº†ä¸€ä¸ªç¥ç»ç½‘ç»œã€‚å®ƒæœ‰ä¸¤ä¸ªè¾“å…¥å’Œä¸€ä¸ªéšè—å±‚ï¼Œå±‚ä¸­æœ‰ä¸¤ä¸ªç¥ç»å…ƒã€‚æˆ‘ä»¬è¿½æ±‚ç»å¯¹æœ€å°çš„ç¥ç»ç½‘ç»œï¼Œåªæ˜¯ä¸ºäº†è¡¨æ˜ä½ å®é™…ä¸Šå¹¶ä¸éœ€è¦å¤ªå¤šå°±èƒ½è®¡ç®—ä¸€ä¸ªå¼‚æˆ–ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬å°†æ‰‹åŠ¨è®¡ç®—è¿™ä¸ªï¼Œæˆ–è€…è¯´æ‡’æƒ°ä¸€äº›ï¼Œæˆ‘ä¸æƒ³ç»™ä½ ä¸€ä¸ªçœŸæ­£æ·±ã€æ·±çš„ç¥ç»ç½‘ç»œï¼Œç„¶åå†æ‰‹åŠ¨è®¡ç®—ã€‚
- en: that would not be fineã€‚So we're going to optimize it with mean square errorã€‚
    and the final output is going to be one neural networkï¼Œ it's a regression neural
    networkã€‚ you can do XOR as classification or regression in this caseï¼Œ I'm doing
    it as regressionã€‚I basically train it hereã€‚ I am training it for100ï¼Œ000 epochsã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·åšæ˜¯ä¸è¡Œçš„ã€‚æ‰€ä»¥æˆ‘ä»¬å°†ç”¨å‡æ–¹è¯¯å·®æ¥ä¼˜åŒ–å®ƒï¼Œæœ€ç»ˆè¾“å‡ºå°†æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§å›å½’ç¥ç»ç½‘ç»œã€‚ä½ å¯ä»¥å°†XORç”¨ä½œåˆ†ç±»æˆ–å›å½’ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘å°†å…¶ä½œä¸ºå›å½’æ¥å¤„ç†ã€‚æˆ‘åŸºæœ¬ä¸Šåœ¨è¿™é‡Œè®­ç»ƒå®ƒã€‚æˆ‘è®­ç»ƒäº†100,000ä¸ªå‘¨æœŸã€‚
- en: It may take longer because there's so few weights in this that your initial
    random values or your weights are really going to have a lot of determination
    on the success of your trainingã€‚ We could do this in way fewer than this many
    epochsã€‚ This is basically grilling a cheese sandwich with a gen engineï¼Œ butã€‚I
    am really not trying to show you how to tune these things right nowã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½ä¼šèŠ±æ›´é•¿çš„æ—¶é—´ï¼Œå› ä¸ºè¿™é‡Œçš„æƒé‡å¾ˆå°‘ï¼Œä½ çš„åˆå§‹éšæœºå€¼æˆ–æƒé‡å°†å¯¹ä½ çš„è®­ç»ƒæˆåŠŸæœ‰å¾ˆå¤§å½±å“ã€‚æˆ‘ä»¬å¯ä»¥ç”¨è¿œå°‘äºè¿™ä¸ªæ•°é‡çš„å‘¨æœŸæ¥å®Œæˆè¿™é¡¹å·¥ä½œã€‚è¿™åŸºæœ¬ä¸Šå°±åƒç”¨å‘ç”µæœºçƒ¤å¥¶é…ªä¸‰æ˜æ²»ï¼Œä½†æˆ‘ç°åœ¨å¹¶ä¸æƒ³å‘ä½ å±•ç¤ºå¦‚ä½•è°ƒæ•´è¿™äº›ä¸œè¥¿ã€‚
- en: I just want to get the weights set up so that they're good for a exclusive or
    networkã€‚ we're going to put those on a diagram and show you that basically you
    can then calculate the same output so you can see the weights behind what Kis
    gives youã€‚I train itï¼Œ I predict itï¼Œ this is good for the neural network becauseã€‚Each
    of these four correspond to these four up here in the inputã€‚ This is scientific
    notationã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åªæ˜¯æƒ³è®¾ç½®æƒé‡ï¼Œä»¥ä¾¿å®ƒä»¬é€‚åˆä¸€ä¸ªå¼‚æˆ–ç½‘ç»œã€‚æˆ‘ä»¬å°†æŠŠè¿™äº›æ”¾åœ¨å›¾è¡¨ä¸Šï¼Œå‘ä½ å±•ç¤ºåŸºæœ¬ä¸Šä½ å¯ä»¥è®¡ç®—ç›¸åŒçš„è¾“å‡ºï¼Œè¿™æ ·ä½ å°±å¯ä»¥çœ‹åˆ°Kisç»™ä½ çš„æƒé‡ã€‚æˆ‘è®­ç»ƒå®ƒï¼Œæˆ‘é¢„æµ‹å®ƒï¼Œè¿™å¯¹ç¥ç»ç½‘ç»œæ¥è¯´æ˜¯å¥½çš„ï¼Œå› ä¸ºã€‚è¿™å››ä¸ªæƒé‡å¯¹åº”äºè¾“å…¥ä¸­çš„è¿™å››ä¸ªã€‚è¿™æ˜¯ç§‘å­¦è®°æ•°æ³•ã€‚
- en: So to the negative 4ï¼Œ that's 0ã€‚000ã€‚ That numberã€‚ So these two are effectively0ã€‚
    and these two in the middle are effectively oneã€‚ So this may look weird if you're
    not used to seeing numbers like thisã€‚ but this is a great outputã€‚ the neural network
    has trained quite wellã€‚So then what we're able to do is I writeï¼Œ I wrote this
    little program hereï¼Œ this dumps the weightsã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è´Ÿ4æ˜¯0.000ã€‚é‚£ä¸ªæ•°å­—ã€‚å› æ­¤è¿™ä¸¤ä¸ªå®é™…ä¸Šæ˜¯0ï¼Œè€Œä¸­é—´çš„è¿™ä¸¤ä¸ªå®é™…ä¸Šæ˜¯1ã€‚æ‰€ä»¥å¦‚æœä½ ä¸ä¹ æƒ¯çœ‹åˆ°è¿™æ ·çš„æ•°å­—ï¼Œè¿™å¯èƒ½çœ‹èµ·æ¥å¾ˆå¥‡æ€ªï¼Œä½†è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è¾“å‡ºï¼Œç¥ç»ç½‘ç»œè®­ç»ƒå¾—ç›¸å½“å¥½ã€‚ç„¶åæˆ‘ä»¬èƒ½åšçš„æ˜¯ï¼Œæˆ‘å†™äº†è¿™ä¸ªå°ç¨‹åºï¼Œå®ƒä¼šè½¬å‚¨æƒé‡ã€‚
- en: so you're seeing that the layer0 counting starting at zeroã€‚Weight from the bias
    to the next layer layer 1ã€‚ againï¼Œ we're counting with 0ã€‚ neuron 1ã€‚ neuron neuron
    0ï¼Œ neuron 1ã€‚ These are the biasesã€‚And these are the actual weightsã€‚So there's
    not a lot of weights and biases in this neural networkï¼Œ it's a fairly small oneã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ çœ‹åˆ°å±‚0çš„è®¡æ•°æ˜¯ä»é›¶å¼€å§‹çš„ã€‚åç½®åˆ°ä¸‹ä¸€å±‚1çš„æƒé‡ã€‚å†ä¸€æ¬¡ï¼Œæˆ‘ä»¬æ˜¯ä»0å¼€å§‹è®¡æ•°ã€‚ç¥ç»å…ƒ1ï¼Œç¥ç»å…ƒ0ï¼Œç¥ç»å…ƒ1ã€‚è¿™äº›æ˜¯åç½®ã€‚è¿™äº›æ˜¯çœŸæ­£çš„æƒé‡ã€‚å› æ­¤ï¼Œè¿™ä¸ªç¥ç»ç½‘ç»œä¸­æ²¡æœ‰å¾ˆå¤šæƒé‡å’Œåç½®ï¼Œå®ƒç›¸å¯¹è¾ƒå°ã€‚
- en: So I'm going to show draw a diagram here in just a minuteã€‚ and we're going to
    copy all of these values up onto the diagramã€‚ Then we're going to calculate it
    by handã€‚ I give you the code down here to calculate it by hand as wellã€‚ if you
    want to do itï¼Œ you set the input to 1 and 0ï¼Œ So1 in 0 and an X O Rã€‚ Those are
    differentã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†åœ¨è¿™é‡Œç¨åç”»ä¸€ä¸ªå›¾ï¼Œæˆ‘ä»¬å°†æŠŠè¿™äº›å€¼å¤åˆ¶åˆ°å›¾ä¸Šã€‚ç„¶åæˆ‘ä»¬å°†æ‰‹åŠ¨è®¡ç®—ã€‚å¦‚æœä½ æƒ³è¿™æ ·åšï¼Œæˆ‘åœ¨è¿™é‡Œç»™ä½ ä»£ç ï¼Œä½ æŠŠè¾“å…¥è®¾ç½®ä¸º1å’Œ0ï¼ŒSo1åœ¨0å’ŒX O Rã€‚è¿™æ˜¯ä¸åŒçš„ã€‚
- en: So it should be 1ã€‚ So it outputs a 0ã€‚96ã€‚ Nowï¼Œ since we're calculating this by
    handã€‚ I truncated quite a few of these numbersã€‚ So 1ã€‚29 becomes 1ã€‚3ï¼Œ and we'll
    do that when we diagram itã€‚ So we lose a little bit of accuracyï¼Œ butã€‚These are
    the two input neuronsã€‚We are going to feed this values 0 and  oneã€‚ So that's what
    we're calculating forã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒåº”è¯¥æ˜¯1ã€‚å®ƒè¾“å‡ºçš„æ˜¯0.96ã€‚ç°åœ¨ï¼Œç”±äºæˆ‘ä»¬æ˜¯æ‰‹åŠ¨è®¡ç®—çš„ï¼Œæˆ‘æˆªæ–­äº†ç›¸å½“å¤šçš„æ•°å­—ã€‚æ‰€ä»¥1.29å˜æˆäº†1.3ï¼Œå½“æˆ‘ä»¬ç”»å›¾æ—¶ä¼šè¿™æ ·åšã€‚å› æ­¤æˆ‘ä»¬å¤±å»äº†ä¸€äº›å‡†ç¡®æ€§ï¼Œä½†è¿™ä¸¤ä¸ªè¾“å…¥ç¥ç»å…ƒï¼Œæˆ‘ä»¬å°†ç»™å®ƒä»¬è¾“å…¥å€¼0å’Œ1ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦è®¡ç®—çš„ã€‚
- en: You could calculate itï¼Œ reallyï¼Œ forã€‚Just about any other value that you wanted
    toã€‚ But for the other four that you would have in the exclusive  fourã€‚ we're also
    going to have the bias neuronã€‚ So like we saw in earlier class videosã€‚ you're
    essentially calculatingã€‚A weighted sum over and over and over again for a neural
    networkã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœŸçš„è®¡ç®—å®ƒï¼Œä»»ä½•ä½ æƒ³è¦çš„å…¶ä»–å€¼ã€‚ä½†å¯¹äºé‚£å››ä¸ªç‹¬å çš„å€¼ï¼Œæˆ‘ä»¬è¿˜å°†æœ‰åç½®ç¥ç»å…ƒã€‚æ‰€ä»¥åƒæˆ‘ä»¬åœ¨ä¹‹å‰çš„è¯¾ç¨‹è§†é¢‘ä¸­çœ‹åˆ°çš„ï¼Œä½ å®é™…ä¸Šæ˜¯åœ¨ä¸æ–­è®¡ç®—ä¸€ä¸ªåŠ æƒå’Œï¼Œç”¨äºç¥ç»ç½‘ç»œã€‚
- en: So we're going to calculate the value for hidden neuron0ã€‚H0ã€‚Each zero has inputs
    from those previous threeã€‚These all have weightsã€‚ as we saw from the output from
    the program beforeï¼Œ so I'm just going to copy those inã€‚So this is going to become
    essentially a weighted sum that we're going to use to calculate what hidden 0
    is actually what its value actually isã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†è®¡ç®—éšè—ç¥ç»å…ƒ0çš„å€¼ã€‚H0ã€‚æ¯ä¸ªé›¶éƒ½æœ‰æ¥è‡ªå‰é¢ä¸‰ä¸ªçš„è¾“å…¥ã€‚è¿™äº›éƒ½æœ‰æƒé‡ï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰ç¨‹åºè¾“å‡ºæ‰€çœ‹åˆ°çš„ï¼Œæˆ‘å°†æŠŠå®ƒä»¬å¤åˆ¶è¿‡æ¥ã€‚å› æ­¤ï¼Œè¿™å°†æˆä¸ºæˆ‘ä»¬ç”¨äºè®¡ç®—éšè—0çš„å€¼çš„åŠ æƒå’Œã€‚
- en: So to do thatï¼Œ we're going to multiply the input 0 times its weightï¼Œ which is
    1ã€‚3ã€‚æˆ‘æ˜¯ã€‚1 times 1ã€‚3ã€‚That one is from the firstï¼Œ which is actually the second input
    neuronã€‚ And then we have to add the biasã€‚ and we basically perform thatã€‚Calculationï¼Œ
    which ends up being 0ã€‚ So the value for hidden in hidden neuron 0 is 0ã€‚ Nextï¼Œ
    we're going to calculate the value forã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†è¾“å…¥0ä¹˜ä»¥å®ƒçš„æƒé‡ï¼Œå³1.3ã€‚æˆ‘æ˜¯1ä¹˜ä»¥1.3ã€‚é‚£ä¸ªæ˜¯æ¥è‡ªç¬¬ä¸€ä¸ªï¼Œå®é™…ä¸Šæ˜¯ç¬¬äºŒä¸ªè¾“å…¥ç¥ç»å…ƒã€‚ç„¶åæˆ‘ä»¬å¿…é¡»åŠ ä¸Šåç½®ã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šæ‰§è¡Œè¿™ä¸ªè®¡ç®—ï¼Œç»“æœæ˜¯0ã€‚å› æ­¤éšè—ç¥ç»å…ƒ0çš„å€¼æ˜¯0ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¡ç®—ã€‚
- en: Hid neuroron 1ï¼Œ which is the second oneã€‚ It has a similar sort of thing going
    onã€‚ It has three weights coming into itã€‚Is going to copy those values from the
    output that we had from the Kiras programã€‚So that is simplyã€‚1ã€‚2ï¼Œ we are calculating
    basically the weighted sum againã€‚The first input I0 drops outï¼Œ second one contributes
    that one pointã€‚1ã€‚2 to itã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: éšè—ç¥ç»å…ƒ1ï¼Œå³ç¬¬äºŒä¸ªç¥ç»å…ƒã€‚å®ƒä¹Ÿæœ‰ç±»ä¼¼çš„æƒ…å†µã€‚å®ƒæœ‰ä¸‰ä¸ªæƒé‡è¿›å…¥ã€‚å°†ä»Kerasç¨‹åºçš„è¾“å‡ºä¸­å¤åˆ¶è¿™äº›å€¼ã€‚å› æ­¤è¿™å°±æ˜¯ç®€å•çš„1.2ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå†æ¬¡è®¡ç®—åŠ æƒå’Œã€‚ç¬¬ä¸€ä¸ªè¾“å…¥I0æ¶ˆå¤±ï¼Œç¬¬äºŒä¸ªè¾“å…¥è´¡çŒ®äº†1.1.2ã€‚
- en: and then the intercept or the bias forã€‚For thisï¼Œ for the second hidden neuron
    is zeroã€‚This whole thingï¼Œ togetherã€‚Is basically equal to 1ã€‚2ã€‚ Then this valueã€‚
    we have to pass it through the through the activation functionã€‚ Both of these
    needed to go through the activation functionã€‚ That is the rectified linear unitã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªéšè—ç¥ç»å…ƒçš„æˆªè·æˆ–åç½®ä¸ºé›¶ã€‚è¿™æ•´ä¸ªå†…å®¹ï¼ŒåŠ èµ·æ¥ï¼ŒåŸºæœ¬ä¸Šç­‰äº 1ã€‚2ã€‚ç„¶åè¿™ä¸ªå€¼ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡æ¿€æ´»å‡½æ•°ã€‚ä¸¤ä¸ªéƒ½éœ€è¦ç»è¿‡æ¿€æ´»å‡½æ•°ã€‚é‚£å°±æ˜¯ä¿®æ­£çº¿æ€§å•å…ƒã€‚
- en: So that is basically going to be the maxã€‚Of 0 and 1ã€‚2ã€‚Which is also 1ã€‚2ã€‚So the
    output from this hidden neuron here is 1ã€‚2ã€‚Same sort of deal up here to apply
    its activation functionã€‚ It's going to be maxed because it's also the valueã€‚ the
    max 0ï¼Œ0 is 0ã€‚activation functions that you can useï¼Œ I may give you a different
    one for for the midterm examination on this oneã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œè¿™å°†æ˜¯æœ€å¤§å€¼ã€‚0 å’Œ 1ã€‚2ã€‚ä¹Ÿå°±æ˜¯ 1ã€‚2ã€‚æ‰€ä»¥è¿™é‡Œçš„éšè—ç¥ç»å…ƒçš„è¾“å‡ºæ˜¯ 1ã€‚2ã€‚ä¸Šé¢çš„å¤„ç†æ–¹å¼ç±»ä¼¼ï¼Œç”¨å®ƒçš„æ¿€æ´»å‡½æ•°ã€‚å®ƒå°†è¢«æœ€å¤§åŒ–ï¼Œå› ä¸ºå®ƒä¹Ÿæ˜¯è¿™ä¸ªå€¼ã€‚æœ€å¤§å€¼
    0ï¼Œ0 æ˜¯ 0ã€‚å¯ä»¥ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œæˆ‘å¯èƒ½ä¼šåœ¨æœŸä¸­è€ƒè¯•ä¸­ç»™ä½ ä¸€ä¸ªä¸åŒçš„ã€‚
- en: The only other ones that you will ever seeï¼Œ at least in this classï¼Œ are sigmoidã€‚Pollic
    tangentã€‚There are othersï¼Œ but these are for regressionã€‚If you're doing a classificationã€‚
    you might also see the softm butã€‚Focus primarily on theseã€‚Now the outputã€‚ the
    final layer so that we actually get what this neural network is providing for
    usã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é—¨è¯¾ä¸Šä½ ä¼šè§åˆ°çš„å…¶ä»–æ¿€æ´»å‡½æ•°åªæœ‰ sigmoid å’ŒåŒæ›²æ­£åˆ‡ã€‚è¿˜æœ‰å…¶ä»–çš„ï¼Œä½†è¿™äº›æ˜¯ç”¨äºå›å½’çš„ã€‚å¦‚æœä½ åœ¨åšåˆ†ç±»ï¼Œä½ å¯èƒ½è¿˜ä¼šçœ‹åˆ° softmaxã€‚ä½†ä¸»è¦å…³æ³¨è¿™äº›ã€‚ç°åœ¨è¾“å‡ºæ˜¯æœ€ç»ˆå±‚ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½å®é™…è·å¾—è¿™ä¸ªç¥ç»ç½‘ç»œä¸ºæˆ‘ä»¬æä¾›çš„å†…å®¹ã€‚
- en: This is going to have similar to beforeã€‚ We do have another bias connectionã€‚
    So you're going to have essentially three and bound connections againã€‚And we're
    essentially going to just copy the weights that we had from the output in Carasã€‚There
    is 0ã€‚And this results in the final equation that ties this whole thing togetherã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ä¸ä¹‹å‰ç±»ä¼¼ã€‚æˆ‘ä»¬ç¡®å®æœ‰å¦ä¸€ä¸ªåç½®è¿æ¥ã€‚æ‰€ä»¥ä½ å°†åŸºæœ¬ä¸Šå†æ¬¡æ‹¥æœ‰ä¸‰æ¡æœ‰ç•Œè¿æ¥ã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šä¼šå¤åˆ¶åœ¨ Caras ä¸­çš„è¾“å‡ºæƒé‡ã€‚è¿™é‡Œæ˜¯ 0ã€‚æœ€ç»ˆçš„æ–¹ç¨‹å°†æ•´ä¸ªå†…å®¹è”ç³»åœ¨ä¸€èµ·ã€‚
- en: And that is going to basically beã€‚Is the output from from hidden hidden 0ã€‚Times
    1ã€‚6ã€‚Plusï¼Œ 1ã€‚2ã€‚Times 0ã€‚8ã€‚You can see the 1ã€‚2 times the 0ã€‚8 and then plus the plus
    theã€‚The bias or the interceptã€‚ which is zeroã€‚And then this whole thing equals
    0ã€‚96ã€‚That's your final output that is approximately equal to 1ã€‚0ã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šå°±æ˜¯ä»éšè—ç¥ç»å…ƒ 0 è¾“å‡ºçš„å†…å®¹ã€‚ä¹˜ä»¥ 1ã€‚6ï¼ŒåŠ ä¸Š 1ã€‚2 ä¹˜ä»¥ 0ã€‚8ã€‚ä½ å¯ä»¥çœ‹åˆ° 1ã€‚2 ä¹˜ä»¥ 0ã€‚8ï¼Œç„¶ååŠ ä¸Šåç½®æˆ–æˆªè·ï¼Œè¿™é‡Œæ˜¯é›¶ã€‚ç„¶åæ•´ä¸ªå†…å®¹ç­‰äº
    0ã€‚96ã€‚è¿™æ˜¯ä½ çš„æœ€ç»ˆè¾“å‡ºï¼Œçº¦ç­‰äº 1ã€‚0ã€‚
- en: which is what you would have expected from a exclusive orã€‚Ofã€‚Zero and whatã€‚There
    you have itã€‚ That is the calculation for this neural network done using the weights
    that Kiro is actually trained for usã€‚ So we can see that there is really no magic
    thereã€‚ğŸ˜Šï¼ŒThis simple of a neural networkã€‚ you could have actually just hand coded
    these weights that would have not been difficultã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä½ ä»å¼‚æˆ–è¿ç®—ä¸­é¢„æœŸçš„ç»“æœã€‚é›¶å’Œä»€ä¹ˆã€‚å°±æ˜¯è¿™æ ·ã€‚è¿™æ˜¯ä½¿ç”¨ Kiro ä¸ºæˆ‘ä»¬è®­ç»ƒçš„æƒé‡è®¡ç®—å‡ºæ¥çš„ç¥ç»ç½‘ç»œã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¿™é‡ŒçœŸçš„æ²¡æœ‰ä»€ä¹ˆé­”æ³•ã€‚ğŸ˜Š
    è¿™ä¹ˆç®€å•çš„ç¥ç»ç½‘ç»œï¼Œä½ å®é™…ä¸Šå¯ä»¥æ‰‹åŠ¨ç¼–ç è¿™äº›æƒé‡ï¼Œéš¾åº¦ä¸å¤§ã€‚
- en: I'll probably do a video on that as well so that you can see how to actually
    hand code one of theseã€‚ You do need about this size of neural networkã€‚ You definitely
    need the hidden layerã€‚![](img/99c863804a8e2678a48ffb4d5482d3aa_3.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯èƒ½è¿˜ä¼šåšä¸€ä¸ªè§†é¢‘ï¼Œè¿™æ ·ä½ å¯ä»¥çœ‹åˆ°å¦‚ä½•å®é™…æ‰‹åŠ¨ç¼–å†™å…¶ä¸­ä¸€ä¸ªã€‚ä½ ç¡®å®éœ€è¦è¿™ä¸ªå¤§å°çš„ç¥ç»ç½‘ç»œã€‚ä½ ç»å¯¹éœ€è¦éšè—å±‚ã€‚![](img/99c863804a8e2678a48ffb4d5482d3aa_3.png)
- en: Thank you for watching this videoã€‚ In the next videoã€‚ we're going to see more
    advanced training techniques that we can use with a neural network toã€‚ğŸ˜Šã€‚To get
    better results and to measure or error in a variety of different waysã€‚ this content
    changes oftenã€‚ so subscribe to the channel to stay up to date on this course and
    other topics in artificial intelligenceã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹è¿™ä¸ªè§†é¢‘ã€‚åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¯ä»¥ä¸ç¥ç»ç½‘ç»œä¸€èµ·ä½¿ç”¨çš„æ›´é«˜çº§çš„è®­ç»ƒæŠ€æœ¯ã€‚ğŸ˜Š ä»¥è·å¾—æ›´å¥½çš„ç»“æœï¼Œå¹¶ä»¥å„ç§ä¸åŒçš„æ–¹å¼æµ‹é‡æˆ‘ä»¬çš„é”™è¯¯ã€‚å†…å®¹ç»å¸¸å˜åŒ–ï¼Œæ‰€ä»¥è¯·è®¢é˜…é¢‘é“ï¼Œä»¥ä¾¿éšæ—¶äº†è§£æœ¬è¯¾ç¨‹å’Œå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜ã€‚
