- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P3ï¼šL3- Pyspark
    DataFrames å¤„ç†ç¼ºå¤±å€¼ - ShowMeAI - BV1sL4y147dP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e973b83e1babc963d0d6504ca497ee4d_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Helloã€‚ my name is Krisnaã€‚ and welcome to my UD channelã€‚ So guysã€‚ we will be
    continuing the Pipar seriesï¼Œ and I've already uploaded two videos on Pi Spã€‚ we
    had actually started the understanding of Pipar data frames today we are going
    to continueã€‚ and probably this is the tutorial3ï¼Œ which is the part3 with respect
    to data frame operations in this particular video we are going to see how we can
    handle missing valuesã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: null values know So in shortï¼Œ this many things will actually try to do we'll
    see how to drop columns we'll see how to drop rows then we'll see when when we
    are dropping rowsã€‚ probably based on null values will try to drop a rows and then
    we'll try to see what are the various parameters in dropping functionalities and
    handling missing value by mean median or mode so here I'm just going to write
    it as mean median and more probably So all these things we are actually going
    to see againã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: the main thing is that I really want to show you that how we can handle the
    missingã€‚ğŸ˜Šã€‚![](img/e973b83e1babc963d0d6504ca497ee4d_3.png)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Valsï¼Œ this is pretty much important because in pandas and also we try to do
    this in a skillã€‚ And we have some kind of imp functionã€‚ So let's proceedã€‚Whenever
    we usually start a Pi parkã€‚ When we are working with Pi parkï¼Œ we really need to
    start a Pi park sessionã€‚ So I hope till now you all are familiarã€‚ So I write for
    Pi park dot S Q Lã€‚ I'm going to importã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Spark sessionã€‚Okayï¼Œ and then I'm going to create a variable with sparkã€‚ And
    then here I'm going to write spark session dotã€‚Build aã€‚North Aã€‚Okayï¼Œ dot app nameã€‚
    let me just keep this app name as practiceã€‚ Okayï¼Œ because I'm just practicing
    thingsã€‚ and then I write get or create and just execute thisã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: So probably it will take some time to get executedã€‚ Yesï¼Œ it has got executed
    fineã€‚ Now for thisã€‚ I've just created a very simple dataset set which looks like
    thisã€‚ I have a column like name age experience salary So these are all my names
    all the candidate names and probably they are some values which are left blank
    here you can see some values are left blank So we'll try to see how to probably
    drop an nu values or how to handle this particular missing values and nu okayã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: so let's proceed so first of allï¼Œ in order to read the data set I'll just write
    spark dot readã€‚ğŸ˜Šã€‚Dot CSsv And here Im just going to use the CSsv file name test2
    dot cv and it is saved in the same location where this particular file is anyhow
    I'll be providing the in this Github also and I'm going to use header is equal
    to true and probably there is also infer schemeche is equal to true so thatã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: I'll be able to get the data set properly so probably when I am reading this
    you will be able to see this is my data frame that I'm actually getting if you
    want to see the entire data set this will be like use dot showã€‚And this is your
    entire data set hereã€‚ You are having null values and are perfectã€‚ So whatã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: let me do one thingã€‚ Let me just save this in a variableã€‚ So I'll write D F
    underscoreco I sparkã€‚ So if I go and now checkã€‚Dot showã€‚This is my entire data
    setã€‚ Okayï¼Œ perfectã€‚ we are pretty much good till hereã€‚ We are working fine with
    respect to thisã€‚ We know we have actually read some kind of data set also nowï¼Œ
    probably firstã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: let's start how do we drop the columnsã€‚ droppinging the columns is veryï¼Œ very
    simpleã€‚ guysã€‚ Suppose I want to drop name columnã€‚ Then I just use D F dot drop
    and provide my column name like thisã€‚ rightï¼Ÿ So columnã€‚ğŸ˜Šï¼ŒRightï¼Œ column nameï¼Œ suppose
    I'll write Df dot price sparkã€‚ and here column name will be nameã€‚So let me write
    it as nameã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: And I can basically go and check out my dot showã€‚ then you'll be able to see
    all the features that are actually writtenã€‚ this is pretty simpleï¼Œ which I also
    showed you probably in the previous session also okayã€‚ and this is how it is basically
    done basically dropping your feature or columnsã€‚ but our main focus is dropping
    the nonvalueã€‚ So right nowã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: let me just write Df dot by spark dot showã€‚ So this is my data set right now
    let's see how to drop this specific rows based on the null valuesã€‚ So over hereï¼Œ
    I'll just use D dot by spark dot na Okayï¼Œ there is something called as Nã€‚ And
    then you have drop fill and replaceã€‚ So first of allï¼Œ I'll start with dropã€‚Nowã€‚
    inside this particular dropï¼Œ always remember if I don't give anythingã€‚Okayï¼Œ and
    just execute itã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Hereã€‚ you'll be able to see wherever there is a null valuesã€‚ those all rows
    will get deletedã€‚ So here you'll be seeing that this last three rows are not presentï¼Œ
    rightã€‚ So here you can see till shubumï¼Œ this particular values presentã€‚ remaining
    all the rows has been removedã€‚ perfectï¼Œ rightï¼Œ So not a problem at allã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: So here you in shortï¼Œ what you' are doing is that whenever you use dot and a
    dot dropã€‚ it is just going to drop wherever it is going to drop those rows wherever
    na values are actually present or null values are actually presentã€‚ Okayï¼Œ perfectã€‚
    This much is fineã€‚ If I go and search in the dropï¼Œ there are two main featuresã€‚
    One is how and one is thresholdã€‚ And then one is subsetã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: So let's try to understand this particular featuresã€‚ Nowï¼Œ firstï¼Œ I will start
    with howã€‚ğŸ˜Šã€‚Any is equal to how I'll just write like thisã€‚ Okayã€‚ so suppose if
    I write D F dot Pipar dot any dot dropã€‚ and if myã€‚How the how value can have two
    valuesï¼Œ1 is anyï¼Œ1 is allã€‚Okayï¼Œ one is anyã€‚1 is allã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Any if the value selected as any drop or row if it contains any nullsã€‚ like
    even though there is just one nullï¼Œ okayï¼Œ one null or there is two nulls or there
    is entire nullsã€‚ you knowï¼Œ then by defaultï¼Œ it is going to get dropped okayã€‚But
    how is equal to all When do we use all that basically means suppose if in your
    featureï¼Œ you haveã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: suppose if in your rowï¼Œ you have all the values as nullã€‚In this caseï¼Œ you have
    361 valueã€‚ this will not get droppedï¼Œ but if in a record you have all the values
    and wellã€‚ then only it will get droppedã€‚ Okayï¼Œ so lets see whether this will work
    or notã€‚Definitely not going to work because I know all at least one values are
    at least the CO1 valuesã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 11 valueï¼Œ1 none non null values is always there right If I am using how is to
    allã€‚ it is going to drop those recordsï¼Œ which is having completely not by defaultã€‚
    this how value should be having any right so by defaultã€‚ it is any any basically
    says that whether there is one null or2nalã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: you are just going to drop it drop those specific records right pretty much
    simpleã€‚ This was what how was Now let's go ahead and try to understand with respect
    to threshold What is this thresholdã€‚I'll tell you what is this threshold shotã€‚Nowï¼Œ
    let me just use thisï¼Œ okayã€‚I know how is anyã€‚ but there is another one more option
    called as threshã€‚ Nowï¼Œ in thshã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: what we do is that suppose if I writeï¼Œ let's keep the threshold or as2ã€‚It basically
    says thatã€‚Suppose over here in this particular caseï¼Œ if the threshold values 2ï¼Œ
    okayï¼Œ lets let's first of allã€‚ execute itã€‚You'll be able to see thatã€‚The last
    column has got deleted over hereã€‚Okayã€‚ the sorry last row has got deleted why
    it has got deleted because we have kept the threshold value S2 it says that at
    least two non null values should be presentã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ˜Šï¼ŒOkayï¼Œ at least two non null valuesã€‚ Nowï¼Œ here you have two non null valuesï¼Œ
    like Maian 40000ã€‚ Okayã€‚ hereï¼Œ you just have one non null valuesã€‚So because of
    thatï¼Œ it got deletedã€‚ Sose if you had two non nu values over hereã€‚ see 34 and
    10ï¼Œ this is not got deletedã€‚ This is same over hereï¼Œ3410ï¼Œ rightï¼Œ34ï¼Œ10 you have
    if I go and show you 3410 over here and 38000 at least here you add three non
    nu values here you add two non nu valuesã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: So hereï¼Œ whenever we give some threshold value as2ã€‚ that basically itll go and
    check whether in that specific rowï¼Œ at least two non nu values are thereã€‚ if it
    is thereï¼Œ it is just going to keep that row otherwiseã€‚ it is just going to delete
    that is what you can you can also check out with oneã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: So if I go and see oneï¼Œ then you can see that all this particular rows are there
    because itll just go and checkã€‚ here1 non non values are there hereï¼Œ it is there
    if I make it as threeï¼Œ Okayã€‚ that's see what it will comeã€‚ğŸ˜Šï¼ŒNowï¼Œ here you can
    see at least this is the remaining all has been deletedã€‚ rightï¼Ÿ See over hereï¼Œ
    you had only two non non values here alsoï¼Œ you here you add  threeã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: So this is the 3410ï¼Œ38000 an nuã€‚ So here you can see the valueã€‚ That is a understanding
    with respect to thresholdã€‚ Nowï¼Œ let's go ahead with the the another oneã€‚ which
    is called as subã€‚So here I'm just going to write it as subset because this is
    the third parameter inside my draw featureã€‚ And rememberï¼Œ these all features are
    pretty much simple with respect to if you have worked with pans the same thing
    we are working away subsetã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯3410ï¼Œ38000å’Œnuã€‚æ‰€ä»¥åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªå€¼ã€‚è¿™æ˜¯å…³äºé˜ˆå€¼çš„ç†è§£ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»§ç»­ä¸‹ä¸€ä¸ªï¼Œç§°ä¸ºå­é›†ã€‚æ‰€ä»¥æˆ‘å°†åœ¨è¿™é‡Œå†™ä¸ºsubsetï¼Œå› ä¸ºè¿™æ˜¯æˆ‘draw
    featureä¸­çš„ç¬¬ä¸‰ä¸ªå‚æ•°ã€‚è¯·è®°ä½ï¼Œè¿™äº›ç‰¹å¾å¦‚æœä½ æ›¾åœ¨pandasä¸­å·¥ä½œè¿‡ï¼Œéƒ½æ˜¯ç›¸å½“ç®€å•çš„ï¼Œæˆ‘ä»¬æ­£åœ¨å¤„ç†çš„ä¹Ÿæ˜¯å­é›†ã€‚
- en: In the subsetï¼Œ we can actually provideã€‚Suppose I'll say in the subjectï¼Œ let's
    remove thresholdã€‚ I don't want to keep any thresholdã€‚Let's say I just want to
    drop N values only from a specific columnã€‚ probably only from experience columnã€‚Then
    I can basically give it as a subset so from the experience column you can see
    that wherever there was na values in the recordsã€‚ all those that whole record
    has been deleted right so like this you can apply with respect to thisã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å­é›†ä¸­ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥æä¾›ã€‚å‡è®¾æˆ‘åœ¨å­é›†é‡Œè¯´ï¼Œå»æ‰é˜ˆå€¼ã€‚æˆ‘ä¸æƒ³ä¿ç•™ä»»ä½•é˜ˆå€¼ã€‚å‡è®¾æˆ‘åªæƒ³ä»ç‰¹å®šåˆ—ä¸­åˆ é™¤Nå€¼ï¼Œå¯èƒ½åªä»ç»éªŒåˆ—ä¸­ã€‚ç„¶åæˆ‘å¯ä»¥å°†å…¶ä½œä¸ºå­é›†ï¼Œä»ç»éªŒåˆ—ä¸­ä½ å¯ä»¥çœ‹åˆ°åœ¨è®°å½•ä¸­æ‰€æœ‰çš„naå€¼ã€‚æ‰€æœ‰è¿™äº›è®°å½•éƒ½è¢«åˆ é™¤äº†ï¼Œæ‰€ä»¥ä½ å¯ä»¥è¿™æ ·åº”ç”¨ã€‚
- en: suppose you want to apply it in age you can also apply this right wherever there
    was non values that whole record has got deleted in the age columnsã€‚So this is
    with respect to subset So I hope you are getting an idea guysã€‚ this is pretty
    much good because the same thing we are trying to do right we we are actually
    trying to apply whatever things we actually did in pandas and this is veryã€‚ very
    handy when you are working with missing data okayã€‚ğŸ˜Šï¼ŒLet's go with the next thingã€‚
    Nowã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ æƒ³åœ¨å¹´é¾„ä¸­åº”ç”¨å®ƒï¼Œä½ ä¹Ÿå¯ä»¥åœ¨å¹´é¾„åˆ—ä¸­åº”ç”¨è¿™ä¸ªï¼Œä»»ä½•æ²¡æœ‰å€¼çš„è®°å½•éƒ½ä¼šè¢«åˆ é™¤ã€‚æ‰€ä»¥è¿™æ˜¯å…³äºå­é›†çš„å†…å®¹ã€‚æˆ‘å¸Œæœ›ä½ ä»¬èƒ½ç†è§£ï¼Œä¼™è®¡ä»¬ã€‚è¿™éå¸¸å¥½ï¼Œå› ä¸ºæˆ‘ä»¬å®é™…ä¸Šæ­£åœ¨å°è¯•åº”ç”¨æˆ‘ä»¬åœ¨pandasä¸­æ‰€åšçš„äº‹æƒ…ï¼Œè¿™åœ¨å¤„ç†ç¼ºå¤±æ•°æ®æ—¶éå¸¸æ–¹ä¾¿ï¼Œå¥½çš„ã€‚ğŸ˜Šï¼Œæˆ‘ä»¬ç»§ç»­ä¸‹ä¸€ä¸ªå†…å®¹ã€‚
- en: let's go and fill the missing valueï¼Œ filling the missing valueã€‚Nowã€‚ in order
    to fill the missing value againï¼Œ I' will be using the Ipar dot fillã€‚ğŸ¤§ã€‚Dot okayï¼Œ
    sorryã€‚ any dot fillã€‚Okayï¼Œ and inside thisï¼Œ this fill will take two parametersã€‚
    One is valueã€‚ and the one is subsetã€‚ Okayï¼Œ now suppose if I go and give value
    like thisã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å»å¡«è¡¥ç¼ºå¤±å€¼ï¼Œå¡«è¡¥ç¼ºå¤±å€¼ã€‚ç°åœ¨ã€‚ä¸ºäº†å¡«è¡¥ç¼ºå¤±å€¼ï¼Œæˆ‘å°†ä½¿ç”¨Ipar.dot fillã€‚ğŸ¤§ã€‚å¥½çš„ï¼ŒæŠ±æ­‰ï¼Œany.dot fillã€‚å¥½çš„ï¼Œé‡Œé¢è¿™ä¸ªfillå°†æ¥å—ä¸¤ä¸ªå‚æ•°ã€‚ä¸€ä¸ªæ˜¯å€¼ï¼Œå¦ä¸€ä¸ªæ˜¯å­é›†ã€‚å¥½çš„ï¼Œç°åœ¨å‡è®¾æˆ‘è¿™æ ·ç»™å‡ºå€¼ã€‚
- en: suppose I say missing valueã€‚And if I go and write dot showã€‚Then what it is going
    to do wherever there is an n value is just going to replace with missing valuesã€‚
    So here you can see here the null value is thereã€‚ So missing valueï¼Œ missing valueã€‚
    missing value missingã€‚ Suppose if you really want to perform this missing value
    handling in only a specific columnã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘è¯´ç¼ºå¤±å€¼ã€‚å¦‚æœæˆ‘å†™.dot showã€‚é‚£ä¹ˆå®ƒå°†æŠŠæ‰€æœ‰çš„nå€¼æ›¿æ¢ä¸ºç¼ºå¤±å€¼ã€‚æ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸€ä¸ªnullå€¼ã€‚æ‰€ä»¥ç¼ºå¤±å€¼ï¼Œç¼ºå¤±å€¼ï¼Œç¼ºå¤±å€¼ç¼ºå¤±ã€‚å‡è®¾ä½ çœŸçš„æƒ³åœ¨ç‰¹å®šåˆ—ä¸­æ‰§è¡Œç¼ºå¤±å€¼å¤„ç†ã€‚
- en: then you can basically write your column name also like thisã€‚So this will be
    my X subsetã€‚ Okayã€‚ I can also give multiple records like thisã€‚Seeï¼Œ I can also
    give multiple exsï¼Œ like experienceã€‚ commarmaï¼Œ probably ageã€‚Gomaã€‚Hã€‚In call in list
    right when I give like thisã€‚ then it this kind of functionality will happen in
    two columns rightï¼Œ pretty much simpleã€‚ So guysã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥åƒè¿™æ ·å†™ä½ çš„åˆ—åã€‚è¿™å°†æ˜¯æˆ‘çš„X subsetã€‚å¥½çš„ã€‚æˆ‘ä¹Ÿå¯ä»¥è¿™æ ·æä¾›å¤šä¸ªè®°å½•ã€‚çœ‹ï¼Œæˆ‘è¿˜å¯ä»¥æä¾›å¤šä¸ªexsï¼Œæ¯”å¦‚ç»éªŒï¼Œcommarmaï¼Œå¯èƒ½æ˜¯å¹´é¾„ã€‚Gomaã€‚Hã€‚åœ¨åˆ—è¡¨ä¸­ï¼Œå½“æˆ‘è¿™æ ·æä¾›æ—¶ï¼Œè¿™ç§åŠŸèƒ½å°†åœ¨ä¸¤åˆ—ä¸­å‘ç”Ÿï¼Œç®€å•å¾—å¤šã€‚æ‰€ä»¥ä¼™è®¡ä»¬ã€‚
- en: now next stepï¼Œ what we are going to do is that we are going to take a specific
    column and probably we are going to handle the missing values with the help of
    mean of that specific column or medium of that specific columnã€‚ So right now if
    I go and check out my D dot spice spark here if I go and see my dot show valueã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬è¦åšçš„æ˜¯é€‰æ‹©ä¸€ä¸ªç‰¹å®šçš„åˆ—ï¼Œå¯èƒ½ä¼šé€šè¿‡è¯¥ç‰¹å®šåˆ—çš„å‡å€¼æˆ–ä¸­ä½æ•°æ¥å¤„ç†ç¼ºå¤±å€¼ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘æŸ¥çœ‹æˆ‘çš„D.dot spice sparkï¼Œçœ‹çœ‹æˆ‘çš„.dot
    showå€¼ã€‚
- en: This is my entire data set over hereã€‚ Now what I'm going to do is that I'm going
    to take this particular experience column and probably replace the null values
    with the mean of the experience itselfã€‚ So in order to do thisï¼Œ I'm going to use
    an impter functionã€‚ And guysã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: if you know about impter function we basically use that with the help of a scale
    learn also in Pipar also we have an imputer functionã€‚ So I'm just going to copy
    and paste the code over here to make it very very simple from Pipar do Ml dot
    feature input impter here I'm just going to give my input columns that is age
    experience salary probably I want to apply for every column over here and then
    I'm just saying that for age experience salary I'm just going to find out this
    dot format do C output columns and then I'm going to keep the strategy as mean
    you can also change the strategy as median mode and everythingã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: So I'll execute this this is got execute fine and then we are just going to
    write fit and transform So impter dot fit D for Pipar dot transformã€‚ So once I
    executeã€‚ğŸ˜Šï¼ŒGys here you'll be able to see that we are going to create multiple
    columns with underscoreco imputed as this name So here you can see age underscoreco
    imputed in short what we have done we have tried some kind of mean functionality
    over here that basically means the null values is been replaced by mean so over
    here you can see this null values is replaced by 28 similarly this to null value
    is replaced with 10 and sorry5 this is what is the experience imputed column over
    here you'll be seeing that wherever there is a null value is being replaced by
    the mean of the experience column the mean of the h column and mean of the salary
    column and this way you'll be able to do it if you really want to go ahead with
    median just go and change this mean to median and just try to execute it here
    now you'll be able to see the median value and here is your initial null columns
    which sorry here are the columns which has null values and here are all the columns
    which has basically the imputed values right with respectã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: To mean media So I hope you like this particular video guys this was with respect
    to tutorial3 And in this video we are tried to see how to drop columnsã€‚ how to
    drop rowsï¼Œ how to check out various parameters with respect to dropping functional
    and handling missing values by mean media and modeã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: You can also try out modeã€‚ It is up to you and you can definitely just try it
    out and try to see whether you are able to do it or notã€‚ So I hope you like this
    particular videoã€‚ please just subscribe the channel if youre not subscribe I'll
    see all in the next video Have a great dayã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Thank you and bye byeã€‚ğŸ˜Šã€‚![](img/e973b83e1babc963d0d6504ca497ee4d_5.png)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
