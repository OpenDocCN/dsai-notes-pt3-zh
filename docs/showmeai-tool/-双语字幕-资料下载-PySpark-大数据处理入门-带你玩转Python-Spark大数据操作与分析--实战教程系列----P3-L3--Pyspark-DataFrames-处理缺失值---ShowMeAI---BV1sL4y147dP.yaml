- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPySpark Â§ßÊï∞ÊçÆÂ§ÑÁêÜÂÖ•Èó®ÔºåÂ∏¶‰Ω†Áé©ËΩ¨Python+SparkÂ§ßÊï∞ÊçÆÊìç‰Ωú‰∏éÂàÜÊûêÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P3ÔºöL3- Pyspark
    DataFrames Â§ÑÁêÜÁº∫Â§±ÂÄº - ShowMeAI - BV1sL4y147dP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: „ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e973b83e1babc963d0d6504ca497ee4d_1.png)'
  prefs: []
  type: TYPE_IMG
- en: Hello„ÄÇ my name is Krisna„ÄÇ and welcome to my UD channel„ÄÇ So guys„ÄÇ we will be
    continuing the Pipar seriesÔºå and I've already uploaded two videos on Pi Sp„ÄÇ we
    had actually started the understanding of Pipar data frames today we are going
    to continue„ÄÇ and probably this is the tutorial3Ôºå which is the part3 with respect
    to data frame operations in this particular video we are going to see how we can
    handle missing values„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: null values know So in shortÔºå this many things will actually try to do we'll
    see how to drop columns we'll see how to drop rows then we'll see when when we
    are dropping rows„ÄÇ probably based on null values will try to drop a rows and then
    we'll try to see what are the various parameters in dropping functionalities and
    handling missing value by mean median or mode so here I'm just going to write
    it as mean median and more probably So all these things we are actually going
    to see again„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: the main thing is that I really want to show you that how we can handle the
    missing„ÄÇüòä„ÄÇ![](img/e973b83e1babc963d0d6504ca497ee4d_3.png)
  prefs: []
  type: TYPE_NORMAL
- en: ValsÔºå this is pretty much important because in pandas and also we try to do
    this in a skill„ÄÇ And we have some kind of imp function„ÄÇ So let's proceed„ÄÇWhenever
    we usually start a Pi park„ÄÇ When we are working with Pi parkÔºå we really need to
    start a Pi park session„ÄÇ So I hope till now you all are familiar„ÄÇ So I write for
    Pi park dot S Q L„ÄÇ I'm going to import„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Spark session„ÄÇOkayÔºå and then I'm going to create a variable with spark„ÄÇ And
    then here I'm going to write spark session dot„ÄÇBuild a„ÄÇNorth A„ÄÇOkayÔºå dot app name„ÄÇ
    let me just keep this app name as practice„ÄÇ OkayÔºå because I'm just practicing
    things„ÄÇ and then I write get or create and just execute this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So probably it will take some time to get executed„ÄÇ YesÔºå it has got executed
    fine„ÄÇ Now for this„ÄÇ I've just created a very simple dataset set which looks like
    this„ÄÇ I have a column like name age experience salary So these are all my names
    all the candidate names and probably they are some values which are left blank
    here you can see some values are left blank So we'll try to see how to probably
    drop an nu values or how to handle this particular missing values and nu okay„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so let's proceed so first of allÔºå in order to read the data set I'll just write
    spark dot read„ÄÇüòä„ÄÇDot CSsv And here Im just going to use the CSsv file name test2
    dot cv and it is saved in the same location where this particular file is anyhow
    I'll be providing the in this Github also and I'm going to use header is equal
    to true and probably there is also infer schemeche is equal to true so that„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I'll be able to get the data set properly so probably when I am reading this
    you will be able to see this is my data frame that I'm actually getting if you
    want to see the entire data set this will be like use dot show„ÄÇAnd this is your
    entire data set here„ÄÇ You are having null values and are perfect„ÄÇ So what„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let me do one thing„ÄÇ Let me just save this in a variable„ÄÇ So I'll write D F
    underscoreco I spark„ÄÇ So if I go and now check„ÄÇDot show„ÄÇThis is my entire data
    set„ÄÇ OkayÔºå perfect„ÄÇ we are pretty much good till here„ÄÇ We are working fine with
    respect to this„ÄÇ We know we have actually read some kind of data set also nowÔºå
    probably first„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's start how do we drop the columns„ÄÇ droppinging the columns is veryÔºå very
    simple„ÄÇ guys„ÄÇ Suppose I want to drop name column„ÄÇ Then I just use D F dot drop
    and provide my column name like this„ÄÇ rightÔºü So column„ÄÇüòäÔºåRightÔºå column nameÔºå suppose
    I'll write Df dot price spark„ÄÇ and here column name will be name„ÄÇSo let me write
    it as name„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And I can basically go and check out my dot show„ÄÇ then you'll be able to see
    all the features that are actually written„ÄÇ this is pretty simpleÔºå which I also
    showed you probably in the previous session also okay„ÄÇ and this is how it is basically
    done basically dropping your feature or columns„ÄÇ but our main focus is dropping
    the nonvalue„ÄÇ So right now„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let me just write Df dot by spark dot show„ÄÇ So this is my data set right now
    let's see how to drop this specific rows based on the null values„ÄÇ So over hereÔºå
    I'll just use D dot by spark dot na OkayÔºå there is something called as N„ÄÇ And
    then you have drop fill and replace„ÄÇ So first of allÔºå I'll start with drop„ÄÇNow„ÄÇ
    inside this particular dropÔºå always remember if I don't give anything„ÄÇOkayÔºå and
    just execute it„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Here„ÄÇ you'll be able to see wherever there is a null values„ÄÇ those all rows
    will get deleted„ÄÇ So here you'll be seeing that this last three rows are not presentÔºå
    right„ÄÇ So here you can see till shubumÔºå this particular values present„ÄÇ remaining
    all the rows has been removed„ÄÇ perfectÔºå rightÔºå So not a problem at all„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So here you in shortÔºå what you' are doing is that whenever you use dot and a
    dot drop„ÄÇ it is just going to drop wherever it is going to drop those rows wherever
    na values are actually present or null values are actually present„ÄÇ OkayÔºå perfect„ÄÇ
    This much is fine„ÄÇ If I go and search in the dropÔºå there are two main features„ÄÇ
    One is how and one is threshold„ÄÇ And then one is subset„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So let's try to understand this particular features„ÄÇ NowÔºå firstÔºå I will start
    with how„ÄÇüòä„ÄÇAny is equal to how I'll just write like this„ÄÇ Okay„ÄÇ so suppose if
    I write D F dot Pipar dot any dot drop„ÄÇ and if my„ÄÇHow the how value can have two
    valuesÔºå1 is anyÔºå1 is all„ÄÇOkayÔºå one is any„ÄÇ1 is all„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Any if the value selected as any drop or row if it contains any nulls„ÄÇ like
    even though there is just one nullÔºå okayÔºå one null or there is two nulls or there
    is entire nulls„ÄÇ you knowÔºå then by defaultÔºå it is going to get dropped okay„ÄÇBut
    how is equal to all When do we use all that basically means suppose if in your
    featureÔºå you have„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: suppose if in your rowÔºå you have all the values as null„ÄÇIn this caseÔºå you have
    361 value„ÄÇ this will not get droppedÔºå but if in a record you have all the values
    and well„ÄÇ then only it will get dropped„ÄÇ OkayÔºå so lets see whether this will work
    or not„ÄÇDefinitely not going to work because I know all at least one values are
    at least the CO1 values„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 11 valueÔºå1 none non null values is always there right If I am using how is to
    all„ÄÇ it is going to drop those recordsÔºå which is having completely not by default„ÄÇ
    this how value should be having any right so by default„ÄÇ it is any any basically
    says that whether there is one null or2nal„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: you are just going to drop it drop those specific records right pretty much
    simple„ÄÇ This was what how was Now let's go ahead and try to understand with respect
    to threshold What is this threshold„ÄÇI'll tell you what is this threshold shot„ÄÇNowÔºå
    let me just use thisÔºå okay„ÄÇI know how is any„ÄÇ but there is another one more option
    called as thresh„ÄÇ NowÔºå in thsh„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: what we do is that suppose if I writeÔºå let's keep the threshold or as2„ÄÇIt basically
    says that„ÄÇSuppose over here in this particular caseÔºå if the threshold values 2Ôºå
    okayÔºå lets let's first of all„ÄÇ execute it„ÄÇYou'll be able to see that„ÄÇThe last
    column has got deleted over here„ÄÇOkay„ÄÇ the sorry last row has got deleted why
    it has got deleted because we have kept the threshold value S2 it says that at
    least two non null values should be present„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: üòäÔºåOkayÔºå at least two non null values„ÄÇ NowÔºå here you have two non null valuesÔºå
    like Maian 40000„ÄÇ Okay„ÄÇ hereÔºå you just have one non null values„ÄÇSo because of
    thatÔºå it got deleted„ÄÇ Sose if you had two non nu values over here„ÄÇ see 34 and
    10Ôºå this is not got deleted„ÄÇ This is same over hereÔºå3410Ôºå rightÔºå34Ôºå10 you have
    if I go and show you 3410 over here and 38000 at least here you add three non
    nu values here you add two non nu values„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So hereÔºå whenever we give some threshold value as2„ÄÇ that basically itll go and
    check whether in that specific rowÔºå at least two non nu values are there„ÄÇ if it
    is thereÔºå it is just going to keep that row otherwise„ÄÇ it is just going to delete
    that is what you can you can also check out with one„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So if I go and see oneÔºå then you can see that all this particular rows are there
    because itll just go and check„ÄÇ here1 non non values are there hereÔºå it is there
    if I make it as threeÔºå Okay„ÄÇ that's see what it will come„ÄÇüòäÔºåNowÔºå here you can
    see at least this is the remaining all has been deleted„ÄÇ rightÔºü See over hereÔºå
    you had only two non non values here alsoÔºå you here you add  three„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So this is the 3410Ôºå38000 an nu„ÄÇ So here you can see the value„ÄÇ That is a understanding
    with respect to threshold„ÄÇ NowÔºå let's go ahead with the the another one„ÄÇ which
    is called as sub„ÄÇSo here I'm just going to write it as subset because this is
    the third parameter inside my draw feature„ÄÇ And rememberÔºå these all features are
    pretty much simple with respect to if you have worked with pans the same thing
    we are working away subset„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: In the subsetÔºå we can actually provide„ÄÇSuppose I'll say in the subjectÔºå let's
    remove threshold„ÄÇ I don't want to keep any threshold„ÄÇLet's say I just want to
    drop N values only from a specific column„ÄÇ probably only from experience column„ÄÇThen
    I can basically give it as a subset so from the experience column you can see
    that wherever there was na values in the records„ÄÇ all those that whole record
    has been deleted right so like this you can apply with respect to this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: suppose you want to apply it in age you can also apply this right wherever there
    was non values that whole record has got deleted in the age columns„ÄÇSo this is
    with respect to subset So I hope you are getting an idea guys„ÄÇ this is pretty
    much good because the same thing we are trying to do right we we are actually
    trying to apply whatever things we actually did in pandas and this is very„ÄÇ very
    handy when you are working with missing data okay„ÄÇüòäÔºåLet's go with the next thing„ÄÇ
    Now„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's go and fill the missing valueÔºå filling the missing value„ÄÇNow„ÄÇ in order
    to fill the missing value againÔºå I' will be using the Ipar dot fill„ÄÇü§ß„ÄÇDot okayÔºå
    sorry„ÄÇ any dot fill„ÄÇOkayÔºå and inside thisÔºå this fill will take two parameters„ÄÇ
    One is value„ÄÇ and the one is subset„ÄÇ OkayÔºå now suppose if I go and give value
    like this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: suppose I say missing value„ÄÇAnd if I go and write dot show„ÄÇThen what it is going
    to do wherever there is an n value is just going to replace with missing values„ÄÇ
    So here you can see here the null value is there„ÄÇ So missing valueÔºå missing value„ÄÇ
    missing value missing„ÄÇ Suppose if you really want to perform this missing value
    handling in only a specific column„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: then you can basically write your column name also like this„ÄÇSo this will be
    my X subset„ÄÇ Okay„ÄÇ I can also give multiple records like this„ÄÇSeeÔºå I can also
    give multiple exsÔºå like experience„ÄÇ commarmaÔºå probably age„ÄÇGoma„ÄÇH„ÄÇIn call in list
    right when I give like this„ÄÇ then it this kind of functionality will happen in
    two columns rightÔºå pretty much simple„ÄÇ So guys„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: now next stepÔºå what we are going to do is that we are going to take a specific
    column and probably we are going to handle the missing values with the help of
    mean of that specific column or medium of that specific column„ÄÇ So right now if
    I go and check out my D dot spice spark here if I go and see my dot show value„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: This is my entire data set over here„ÄÇ Now what I'm going to do is that I'm going
    to take this particular experience column and probably replace the null values
    with the mean of the experience itself„ÄÇ So in order to do thisÔºå I'm going to use
    an impter function„ÄÇ And guys„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: if you know about impter function we basically use that with the help of a scale
    learn also in Pipar also we have an imputer function„ÄÇ So I'm just going to copy
    and paste the code over here to make it very very simple from Pipar do Ml dot
    feature input impter here I'm just going to give my input columns that is age
    experience salary probably I want to apply for every column over here and then
    I'm just saying that for age experience salary I'm just going to find out this
    dot format do C output columns and then I'm going to keep the strategy as mean
    you can also change the strategy as median mode and everything„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So I'll execute this this is got execute fine and then we are just going to
    write fit and transform So impter dot fit D for Pipar dot transform„ÄÇ So once I
    execute„ÄÇüòäÔºåGys here you'll be able to see that we are going to create multiple
    columns with underscoreco imputed as this name So here you can see age underscoreco
    imputed in short what we have done we have tried some kind of mean functionality
    over here that basically means the null values is been replaced by mean so over
    here you can see this null values is replaced by 28 similarly this to null value
    is replaced with 10 and sorry5 this is what is the experience imputed column over
    here you'll be seeing that wherever there is a null value is being replaced by
    the mean of the experience column the mean of the h column and mean of the salary
    column and this way you'll be able to do it if you really want to go ahead with
    median just go and change this mean to median and just try to execute it here
    now you'll be able to see the median value and here is your initial null columns
    which sorry here are the columns which has null values and here are all the columns
    which has basically the imputed values right with respect„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: To mean media So I hope you like this particular video guys this was with respect
    to tutorial3 And in this video we are tried to see how to drop columns„ÄÇ how to
    drop rowsÔºå how to check out various parameters with respect to dropping functional
    and handling missing values by mean media and mode„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: You can also try out mode„ÄÇ It is up to you and you can definitely just try it
    out and try to see whether you are able to do it or not„ÄÇ So I hope you like this
    particular video„ÄÇ please just subscribe the channel if youre not subscribe I'll
    see all in the next video Have a great day„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Thank you and bye bye„ÄÇüòä„ÄÇ![](img/e973b83e1babc963d0d6504ca497ee4d_5.png)
  prefs: []
  type: TYPE_NORMAL
