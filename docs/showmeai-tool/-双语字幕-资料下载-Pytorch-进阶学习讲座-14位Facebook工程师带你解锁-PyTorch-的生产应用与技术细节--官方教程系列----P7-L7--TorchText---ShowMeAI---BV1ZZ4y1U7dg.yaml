- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPytorch ËøõÈò∂Â≠¶‰π†ËÆ≤Â∫ßÔºÅ14‰ΩçFacebookÂ∑•Á®ãÂ∏àÂ∏¶‰Ω†Ëß£ÈîÅ PyTorch ÁöÑÁîü‰∫ßÂ∫îÁî®‰∏éÊäÄÊúØÁªÜËäÇ ÔºúÂÆòÊñπÊïôÁ®ãÁ≥ªÂàóÔºû - P7ÔºöL7-
    TorchText - ShowMeAI - BV1ZZ4y1U7dg
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: üéº„ÄÇ![](img/aaa011e1dc72912baa590f68c0c043cd_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: Hello everyoneÔºå welcome to PyTchDeveloper Day for 2020„ÄÇMy name is George„ÄÇ I'm
    a software engineer at FacebookÔºå I work for the text domain in Pytot„ÄÇMy job at
    Facebook is to support the PyToch userÔºå especially in the text domain for research
    to production„ÄÇ so in this talk I will go over some major update in 2020 and help
    you understand how our work can facilitate your research and production for the
    PyToch„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_3.png)'
  prefs: []
  type: TYPE_IMG
- en: So why we want to have a text domain in addition to Pyth„ÄÇFirst„ÄÇWe want to accelerate
    NLP research and provide some reusful orthogonal and correct building block for
    cutting edge research„ÄÇBased on our knowledge for the text domain and the research
    community„ÄÇWe want to work with the both internal team and external open source
    community to build a pipeline like can better support„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Both the Facebook products and external research„ÄÇSecond„ÄÇüòä„ÄÇWe want to provide
    a solution to transfer from research to production„ÄÇWhat we mean here is we integrate
    those pipeline and module with a wide range of py capabilities such as touchscript
    quantization„ÄÇ distribute data parallel and mobile with this goal we want to have
    a better support for research to production transition for most end an NLP pipeline
    thirdly we want to engage with the community and Disc novel technology„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: As people notesÔºå the NRP domain„ÄÇMove very fast„ÄÇ So the text domain in Pyth team
    want to develop a good technology understanding„ÄÇIn the NLP area and build a new
    research collaboration„ÄÇFor the future community„ÄÇWith those go in mindÔºå we provide
    those easy access to data sets„ÄÇText processing pipeline„ÄÇAnd some NLP related module„ÄÇSo
    if you have timeÔºå please go over those one by one„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: our row text data setÔºå the transform„ÄÇAnd our more some NP related moduleÔºå I
    will go„ÄÇ go over this one by one with you„ÄÇ![](img/aaa011e1dc72912baa590f68c0c043cd_5.png)
  prefs: []
  type: TYPE_NORMAL
- en: OkayÔºå so the new data set in To text„ÄÇWe have also rewrite a few existing data
    set in To text nightly release„ÄÇSo here„ÄÇFor the nightly releaseÔºå we consider those
    new stuff as a prototype„ÄÇ So we will release those new data sets with our„ÄÇüòäÔºåBetter
    release very soon„ÄÇSo the new data set show here are fully compatible with data
    loader in Py„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: User will have the flexibility to build the data processing pipeline with some
    standard tokenizer and vocabulary blocks„ÄÇOkayÔºå here I list all the new data set
    available to our user in our beta release„ÄÇ at same„ÄÇ you may wonderingÔºå once I
    have those raw dataÔºå what should I do to convert this raw data into„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_7.png)'
  prefs: []
  type: TYPE_IMG
- en: A tensor like can be used to train a model okayÔºå so here we provide some improved
    performance we provide some data pipeline with improved performance„ÄÇWith some
    C+ plus extension„ÄÇSo the goal here is we want to have an easy transfer to production„ÄÇHere's
    the overview of some end to end pipeline with Ptoch and Torch text„ÄÇThe row data
    string read and send to a field transform here here you can see like tokenizer„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: vocabularyÔºå vector took up and convertive cancerÔºå rightÔºü
  prefs: []
  type: TYPE_NORMAL
- en: So currently we are rewriting this data processing transform as an orthogonal
    building block with the G port„ÄÇSo after this after this stepÔºå we call this a pre
    processing„ÄÇ The data are sent to data loader and samplerÔºå where we generate„ÄÇThey
    have bachelor„ÄÇThen the data are ready for the model„ÄÇSo we are do our best to write
    those a building block„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: individual building blockÔºå like so you will have the full flexibility to combine
    them together„ÄÇAnd with the C++ extensionÔºå we are able to support the Gt for all
    this transform„ÄÇAnd we believe that's a better support for the production„ÄÇOkayÔºå
    so now we go to the„ÄÇThe NLP related moduleÔºå so we released a new multiha attention
    module in Tor text„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so in addition to the dropping replacementÔºå if you are using the multiha attention
    in Pytoch co library„ÄÇ we support the dropping replacement so you can easily switch
    from a Pytoch multiha attention to To text multiha attention„ÄÇIn addition„ÄÇThe new
    multi attention container also for touch script„ÄÇBased on the feedback from our
    userÔºå we add the incremental decoding and the broadcasting support„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: The idea for this new multi high attention container is to facilitate user with
    some novel research idea under the transformer architecture„ÄÇRight nowÔºå the transformer
    architecture is very popular across the textÔºå audio and vision domain„ÄÇWe hope
    here like we can provide a very flexible multiha attention module so our user
    can apply this with different idea here I give you an example like how you switch
    from the Pych multiha attention to our Tosh text multiha attention container„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_9.png)'
  prefs: []
  type: TYPE_IMG
- en: Just with this a few lines„ÄÇUser has more flexibility to try different custom
    component with the concept multi attention„ÄÇYou can put„ÄÇCustom in projection containerÔºå
    multihaitation container„ÄÇO skilled dog products„ÄÇ you can apply different idea
    with this multi hair attention container„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_11.png)'
  prefs: []
  type: TYPE_IMG
- en: OkayÔºå lastÔºå but not least„ÄÇOn our websiteÔºå we have several text related tutorials„ÄÇIncluding
    the one to show how to use the new data set for text classification analysis„ÄÇPlease
    check out those tutorial and have some idea about how to write those into an NLP
    pipeline„ÄÇKeep in mindÔºå like we will also update this tutorial and to show how
    to build the N to N pipeline with the„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: With the new Tosht library for different NLP task at the endÔºå thank you for
    watching this video„ÄÇ and I hope you enjoy the Pytor Develop day for this yearÔºå
    and I will see you around„ÄÇ![](img/aaa011e1dc72912baa590f68c0c043cd_13.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_14.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/aaa011e1dc72912baa590f68c0c043cd_15.png)'
  prefs: []
  type: TYPE_IMG
