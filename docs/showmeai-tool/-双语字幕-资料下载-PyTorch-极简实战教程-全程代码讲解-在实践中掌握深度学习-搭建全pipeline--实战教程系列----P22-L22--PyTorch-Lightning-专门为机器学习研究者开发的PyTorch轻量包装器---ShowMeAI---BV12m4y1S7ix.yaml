- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P22ï¼šL22-
    PyTorch Lightningï¼šä¸“é—¨ä¸ºæœºå™¨å­¦ä¹ ç ”ç©¶è€…å¼€å‘çš„PyTorchè½»é‡åŒ…è£…å™¨ - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P22ï¼šL22-
    PyTorch Lightningï¼šä¸“é—¨ä¸ºæœºå™¨å­¦ä¹ ç ”ç©¶è€…å¼€å‘çš„PyTorchè½»é‡åŒ…è£…å™¨ - ShowMeAI - BV12m4y1S7ix
- en: Heyï¼Œ guysï¼Œ welcomel to your new Pytor tutorialã€‚ Todayï¼Œ we'll be talking about
    Pytor lightningã€‚ Pytorch lightning is a lightweight pytor wrapperã€‚ It aims to
    reduce boiler plate codes so that implementing the algorithm and also improving
    your modelã€‚ So tweaking and optimizing it can be way fasterã€‚ You don't have to
    remember all the tiny details of the Pytor frameworkã€‚ because lightning takes
    care of all thatã€‚ğŸ˜Šï¼ŒAnd another great feature is that it prints out warnings and
    gives you helpful machine learning tips or hintsã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å˜¿ï¼Œå¤§å®¶ï¼Œæ¬¢è¿æ¥åˆ°ä½ ä»¬çš„æ–°Pytoræ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†è®¨è®ºPytor Lightningã€‚Pytorch Lightningæ˜¯ä¸€ä¸ªè½»é‡çº§çš„PytoråŒ…è£…å™¨ã€‚å®ƒæ—¨åœ¨å‡å°‘æ ·æ¿ä»£ç ï¼Œä»¥ä¾¿å®ç°ç®—æ³•å’Œæ”¹è¿›æ¨¡å‹ã€‚å› æ­¤ï¼Œè°ƒæ•´å’Œä¼˜åŒ–å¯ä»¥æ›´å¿«ã€‚ä½ ä¸éœ€è¦è®°ä½Pytoræ¡†æ¶çš„æ‰€æœ‰ç»†èŠ‚ï¼Œå› ä¸ºLightningä¼šå¤„ç†è¿™äº›ã€‚ğŸ˜Šï¼Œå¦ä¸€ä¸ªå¾ˆæ£’çš„ç‰¹ç‚¹æ˜¯å®ƒä¼šæ‰“å°è­¦å‘Šï¼Œå¹¶ç»™ä½ æœ‰ç”¨çš„æœºå™¨å­¦ä¹ æç¤ºæˆ–å»ºè®®ã€‚
- en: if you make mistakesã€‚ So we will see all that laterã€‚ So usually I'm skeptical
    when it comes to wrapper frameworks that abstract away a lot of thingsã€‚ But this
    timeï¼Œ I can really recommend itã€‚ I still advise that you learn the underlying
    basics firstã€‚ and if you haven't yetï¼Œ then you can check out my free Pytor course
    here on YouTubeã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çŠ¯é”™è¯¯ã€‚æˆ‘ä»¬ç¨åä¼šçœ‹åˆ°è¿™ä¸€åˆ‡ã€‚é€šå¸¸ï¼Œå½“æ¶‰åŠåˆ°æŠ½è±¡å¾ˆå¤šå†…å®¹çš„åŒ…è£…æ¡†æ¶æ—¶ï¼Œæˆ‘æŒæ€€ç–‘æ€åº¦ã€‚ä½†è¿™æ¬¡ï¼Œæˆ‘çœŸçš„å¯ä»¥æ¨èå®ƒã€‚æˆ‘ä»ç„¶å»ºè®®ä½ é¦–å…ˆå­¦ä¹ åŸºç¡€çŸ¥è¯†ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å­¦ä¹ è¿‡ï¼Œå¯ä»¥åœ¨YouTubeä¸ŠæŸ¥çœ‹æˆ‘çš„å…è´¹Pytorchè¯¾ç¨‹ã€‚
- en: The link is in the descriptionã€‚ But if you are already familiar with Pytorchã€‚
    then you can check out Pytoch lightning and see if you like it or notã€‚ So todayã€‚
    I'll be converting one of the codes from my Pytor course to Pytorch lightningã€‚
    So you can get a feel how this framework works and how you can use itã€‚ Allrightï¼Œ
    let's jump into itã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: é“¾æ¥åœ¨æè¿°ä¸­ã€‚ä½†å¦‚æœä½ å·²ç»ç†Ÿæ‚‰Pytorchï¼Œé‚£ä¹ˆä½ å¯ä»¥æŸ¥çœ‹Pytorch Lightningï¼Œçœ‹çœ‹ä½ æ˜¯å¦å–œæ¬¢å®ƒã€‚å› æ­¤ä»Šå¤©ï¼Œæˆ‘å°†æŠŠæˆ‘çš„Pytorè¯¾ç¨‹ä¸­çš„ä¸€æ®µä»£ç è½¬æ¢ä¸ºPytorch
    Lightningã€‚è¿™æ ·ä½ å°±èƒ½æ„Ÿå—åˆ°è¿™ä¸ªæ¡†æ¶çš„å·¥ä½œåŸç†ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒã€‚å¥½çš„ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: So first of allï¼Œ Pytorch lightning is open sourceã€‚ So you can find it here on
    Githubã€‚ And they also have a website with a nice documentation that you get you
    startedã€‚ I will putã€‚ğŸ˜Šã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_1.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼ŒPytorch Lightningæ˜¯å¼€æºçš„ã€‚ä½ å¯ä»¥åœ¨Githubä¸Šæ‰¾åˆ°å®ƒã€‚ä»–ä»¬è¿˜æœ‰ä¸€ä¸ªç½‘ç«™ï¼Œæä¾›è‰¯å¥½çš„æ–‡æ¡£ï¼Œå¸®åŠ©ä½ å…¥é—¨ã€‚æˆ‘ä¼šæ”¾ä¸Šã€‚ğŸ˜Šï¼[](img/8f1dbba751e44013b8cee2c7d55082c5_1.png)
- en: The links in the description as wellã€‚ And now here are some of the details that
    you no longer have to worry about with Pytorch lightningã€‚ so you no longer have
    to worry about when to set your model to training or evaluation mode you don't
    have to worry about using a device for GPU support and then push your model and
    all your tenss to the device you can easily turn off GPu or even GPU support with
    lightning and you can easily scale it up then you also have to no longer care
    about the zero grad or calling backward and optimize a step you no longer have
    to worry about using torch no grad or detach and as a bonus you have integrate
    a tenor or supportã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æè¿°ä¸­çš„é“¾æ¥ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è€Œç°åœ¨ï¼Œè¿™é‡Œæœ‰ä¸€äº›å…³äºPytorch Lightningçš„ç»†èŠ‚ï¼Œä½ ä¸å†éœ€è¦æ‹…å¿ƒçš„ã€‚å› æ­¤ï¼Œä½ ä¸å†éœ€è¦æ‹…å¿ƒä½•æ—¶å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæˆ–è¯„ä¼°æ¨¡å¼ï¼Œä½ ä¹Ÿä¸å¿…æ‹…å¿ƒä½¿ç”¨è®¾å¤‡è¿›è¡ŒGPUæ”¯æŒï¼Œç„¶åå°†æ¨¡å‹å’Œæ‰€æœ‰å¼ é‡æ¨é€åˆ°è®¾å¤‡ä¸Šã€‚ä½ å¯ä»¥è½»æ¾å…³é—­GPUæˆ–ç”šè‡³ä¸ä½¿ç”¨GPUæ”¯æŒï¼Œä½¿ç”¨Lightningå¯ä»¥è½»æ¾æ‰©å±•ã€‚æ­¤å¤–ï¼Œä½ ä¹Ÿä¸å†éœ€è¦å…³å¿ƒé›¶æ¢¯åº¦æˆ–è°ƒç”¨åå‘ä¼ æ’­å’Œä¼˜åŒ–æ­¥éª¤ï¼Œä½ ä¹Ÿä¸éœ€è¦æ‹…å¿ƒä½¿ç”¨torch.no_gradæˆ–detachï¼Œä½œä¸ºé¢å¤–å¥–åŠ±ï¼Œä½ è¿˜æœ‰å¼ é‡æˆ–æ”¯æŒé›†æˆã€‚
- en: And it also prints out tips or hintsï¼Œ which we will see laterã€‚ So let's jump
    to the codeã€‚ And for this exampleï¼Œ we'll be taking one of the codes from my Pytoch
    tutorialã€‚ So you can find it on Githubã€‚ and then in this caseï¼Œ we take tutorial
    number 13ã€‚ So this is a simple feed forward neural netï¼Œ which is applied to the
    Mist data set to do diit classificationã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜ä¼šæ‰“å°æç¤ºæˆ–æç¤ºï¼Œæˆ‘ä»¬ç¨åä¼šçœ‹åˆ°ã€‚è®©æˆ‘ä»¬è·³åˆ°ä»£ç ã€‚è¿™æ¬¡ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»æˆ‘çš„Pytorchæ•™ç¨‹ä¸­æå–ä¸€æ®µä»£ç ã€‚ä½ å¯ä»¥åœ¨Githubä¸Šæ‰¾åˆ°å®ƒï¼Œç„¶ååœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å–æ•™ç¨‹ç¼–å·13ã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œåº”ç”¨äºMNISTæ•°æ®é›†è¿›è¡Œæ•°å­—åˆ†ç±»ã€‚
- en: So now let's grab some of the code and write a new code with Pytoch lightningã€‚
    So first of allã€‚ so let me delete thisã€‚ and now let's start with a fresh Python
    scriptã€‚ And by the wayã€‚ when you want to install Pytoch lightningï¼Œ you have two
    common optionsã€‚ The first one is to use Pipã€‚ So you just say Pip install Pytoch
    lightningã€‚ Or if you use in Condaã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æŠ“å–ä¸€äº›ä»£ç ï¼Œå¹¶ç”¨Pytorch Lightningç¼–å†™æ–°ä»£ç ã€‚é¦–å…ˆï¼Œæˆ‘æ¥åˆ é™¤è¿™ä¸ªï¼Œç°åœ¨æˆ‘ä»¬ä»ä¸€ä¸ªæ–°çš„Pythonè„šæœ¬å¼€å§‹ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œå½“ä½ æƒ³å®‰è£…Pytorch
    Lightningæ—¶ï¼Œæœ‰ä¸¤ä¸ªå¸¸è§çš„é€‰æ‹©ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä½¿ç”¨Pipã€‚æ‰€ä»¥ä½ åªéœ€è¯´Pip install Pytorch Lightningã€‚æˆ–è€…å¦‚æœä½ åœ¨Condaä¸­ä½¿ç”¨ã€‚
- en: then you can grab this commandã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_3.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥æŠ“å–è¿™ä¸ªå‘½ä»¤ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_3.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_4.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_4.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_5.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_5.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_6.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_6.png)'
- en: So I already did this in my terminalã€‚ So Pytoch lightning is already insult
    hereã€‚ So let's go back to the code and copy and paste some of the thingsã€‚ So we
    want to have all the same import statementsã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_8.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»åœ¨æˆ‘çš„ç»ˆç«¯ä¸­å®Œæˆäº†è¿™ä¸ªæ“ä½œã€‚æ‰€ä»¥Pytorch lightningå·²ç»åœ¨è¿™é‡Œå¯¼å…¥äº†ã€‚ç°åœ¨è®©æˆ‘ä»¬å›åˆ°ä»£ç ä¸­ï¼Œå¤åˆ¶ç²˜è´´ä¸€äº›å†…å®¹ã€‚æˆ‘ä»¬å¸Œæœ›æœ‰æ‰€æœ‰ç›¸åŒçš„å¯¼å…¥è¯­å¥ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_8.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_9.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_9.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_10.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_10.png)'
- en: And as an addition nowï¼Œ we also import Pytorch lightningã€‚ So we say import Pytorrch
    lightning with an underscore S Pï¼Œ Lã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_12.png)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºè¡¥å……ï¼Œæˆ‘ä»¬ç°åœ¨è¿˜å¯¼å…¥äº†Pytorch lightningã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å¯¼å…¥å¸¦ä¸‹åˆ’çº¿çš„Pytorch lightningã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_12.png)
- en: And now we want to convert our modelï¼Œ our neural net to a lightning modelã€‚ So
    we grab this codeã€‚ and then we copy and paste it in here And now instead of deriving
    from N and dot moduleã€‚ we now derive from P dot lightning moduleã€‚ This will give
    us the same functions as the original modelã€‚ but it will also give us some more
    functionsï¼Œ which we will see in a secondã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æƒ³å°†æˆ‘ä»¬çš„æ¨¡å‹ã€ç¥ç»ç½‘ç»œè½¬æ¢ä¸ºä¸€ä¸ªlightningæ¨¡å‹ã€‚æ‰€ä»¥æˆ‘ä»¬æŠ“å–è¿™æ®µä»£ç ï¼Œç„¶åæŠŠå®ƒå¤åˆ¶ç²˜è´´åˆ°è¿™é‡Œã€‚ç°åœ¨æˆ‘ä»¬ä¸å†ä»Nå’Œdotæ¨¡å—æ´¾ç”Ÿï¼Œè€Œæ˜¯ä»P
    dot lightningæ¨¡å—æ´¾ç”Ÿã€‚è¿™å°†ç»™æˆ‘ä»¬åŸå§‹æ¨¡å‹çš„ç›¸åŒåŠŸèƒ½ï¼Œä½†è¿˜ä¼šæä¾›ä¸€äº›æ›´å¤šçš„åŠŸèƒ½ï¼Œæˆ‘ä»¬ç¨åå°†çœ‹åˆ°ã€‚
- en: So now the in it function is still the sameï¼Œ and the forward function also is
    still the sameã€‚ So we then need all the hyperparametersã€‚ So let's grab them as
    wellã€‚ So let's grab these hyperparameters and paste them in hereã€‚ğŸ˜Šã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_14.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨in itå‡½æ•°ä»ç„¶æ˜¯ç›¸åŒçš„ï¼Œforwardå‡½æ•°ä¹Ÿä»ç„¶æ˜¯ç›¸åŒçš„ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰€æœ‰çš„è¶…å‚æ•°ã€‚è®©æˆ‘ä»¬æŠ“å–è¿™äº›è¶…å‚æ•°å¹¶ç²˜è´´åˆ°è¿™é‡Œã€‚ğŸ˜Šã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_14.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_15.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_15.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_16.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_16.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_17.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_17.png)'
- en: HereAnd now we need to implement some more functionsã€‚ So let's quickly go to
    the official website Hereã€‚ you see a step by step guideï¼Œ by the wayã€‚ And you also
    have a nice comparison how Pytch code looks versus Pytoch lightning and what it
    abstracts awayã€‚ So as you can seeï¼Œ we also need to define a training stepã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬éœ€è¦å®ç°ä¸€äº›æ›´å¤šçš„å‡½æ•°ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å¿«é€Ÿè®¿é—®ä¸€ä¸‹å®˜æ–¹ç½‘ç«™ã€‚åœ¨è¿™é‡Œï¼Œä½ ä¼šçœ‹åˆ°ä¸€æ­¥ä¸€æ­¥çš„æŒ‡å—ï¼Œé¡ºä¾¿æä¸€ä¸‹ï¼Œä½ è¿˜æœ‰ä¸€ä¸ªå¾ˆå¥½çš„æ¯”è¾ƒï¼ŒPytorchä»£ç ä¸Pytorch
    lightningçš„åŒºåˆ«ï¼Œä»¥åŠå®ƒæŠ½è±¡äº†ä»€ä¹ˆã€‚å› æ­¤ï¼Œå¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®šä¹‰ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ã€‚
- en: a configure optimizes function and a train data loaderã€‚ So let's copy all of
    these in hereã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_19.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé…ç½®ä¼˜åŒ–å™¨å‡½æ•°å’Œä¸€ä¸ªè®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æŠŠè¿™äº›å…¨éƒ¨å¤åˆ¶åˆ°è¿™é‡Œã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_19.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_20.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_20.png)'
- en: And now for theï¼Œ let's start with the simplest oneã€‚ So the configure optimizers
    there you simply put in the optimizer that you createdã€‚ So in our original scriptï¼Œ
    we set up the optimizer hereã€‚ So this is the atom optimizerã€‚ And then you return
    itã€‚ So we can return this one in one lineã€‚ So this will be our optimizerã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¯¹äºæœ€ç®€å•çš„é…ç½®ä¼˜åŒ–å™¨ï¼Œä½ åªéœ€æ”¾å…¥ä½ åˆ›å»ºçš„ä¼˜åŒ–å™¨ã€‚æ‰€ä»¥åœ¨æˆ‘ä»¬åŸå§‹è„šæœ¬ä¸­ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè®¾ç½®äº†ä¼˜åŒ–å™¨ã€‚è¿™æ˜¯åŸå­ä¼˜åŒ–å™¨ã€‚ç„¶åè¿”å›å®ƒã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä¸­è¿”å›è¿™ä¸ªã€‚è¿™å°†æ˜¯æˆ‘ä»¬çš„ä¼˜åŒ–å™¨ã€‚
- en: our atom optimizer with the learning rate from our hyperparmetersã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_22.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„åŸå­ä¼˜åŒ–å™¨ä¸è¶…å‚æ•°ä¸­çš„å­¦ä¹ ç‡ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_22.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_23.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_23.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_24.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_24.png)'
- en: And then we want to in implement the training stepã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_26.png)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³è¦å®ç°è®­ç»ƒæ­¥éª¤ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_26.png)
- en: So for the training stepï¼Œ we are doing exactly what we are doing in our training
    loopã€‚ and now we don't have no longer have to worry about our fall loops about
    unpackking our images and labels and then hear the optimizer0 grabs the backward
    and the stepã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè®­ç»ƒæ­¥éª¤ï¼Œæˆ‘ä»¬æ­£åœ¨åšçš„æ­£æ˜¯æˆ‘ä»¬åœ¨è®­ç»ƒå¾ªç¯ä¸­æ‰€åšçš„ã€‚ç°åœ¨æˆ‘ä»¬ä¸å†éœ€è¦æ‹…å¿ƒå…³äºè§£åŒ…å›¾åƒå’Œæ ‡ç­¾çš„å¾ªç¯ï¼Œä»¥åŠä¼˜åŒ–å™¨å¦‚ä½•è¿›è¡Œåå‘ä¼ æ’­å’Œæ­¥éª¤ã€‚
- en: So we simply grab this partã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_28.png)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ç®€å•åœ°æŠ“å–è¿™ä¸€éƒ¨åˆ†ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_28.png)
- en: And paste it in hereã€‚ And as you see in the training step functionï¼Œ we get a
    batch and a batch indexã€‚ So we unpack our batch into x and yã€‚ and then let me
    copy the codeã€‚ Soã€‚This is now our images and our labelsã€‚ And then we have to reshape
    our imagesã€‚ and we no longer have to push it to the deviceã€‚ So we remove all of
    those thingsã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ç²˜è´´åˆ°è¿™é‡Œã€‚å¦‚ä½ æ‰€è§ï¼Œåœ¨è®­ç»ƒæ­¥éª¤å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬è·å¾—ä¸€ä¸ªæ‰¹æ¬¡å’Œä¸€ä¸ªæ‰¹æ¬¡ç´¢å¼•ã€‚å› æ­¤æˆ‘ä»¬å°†æ‰¹æ¬¡è§£åŒ…ä¸ºxå’Œyã€‚è®©æˆ‘å¤åˆ¶ä»£ç ã€‚å› æ­¤ã€‚è¿™å°±æ˜¯æˆ‘ä»¬çš„å›¾åƒå’Œæ ‡ç­¾ã€‚ç„¶åæˆ‘ä»¬éœ€è¦é‡æ–°è°ƒæ•´å›¾åƒçš„å½¢çŠ¶ã€‚å¹¶ä¸”æˆ‘ä»¬ä¸å†éœ€è¦å°†å…¶æ¨é€åˆ°è®¾å¤‡ã€‚å› æ­¤æˆ‘ä»¬ç§»é™¤æ‰€æœ‰è¿™äº›å†…å®¹ã€‚
- en: And then we do the forward passã€‚ And here we can actually use self because we
    are inside of our model classã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_30.png)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿›è¡Œå‰å‘ä¼ é€’ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥ä½¿ç”¨selfï¼Œå› ä¸ºæˆ‘ä»¬åœ¨æ¨¡å‹ç±»å†…éƒ¨ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_30.png)
- en: And then we apply the criterionã€‚ and in our original codeã€‚ we set up the criterion
    here as N and dot cross entropisã€‚ But we can also use it instead if we use the
    functional moduleã€‚ So for thisï¼Œ we sayã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_32.png)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åº”ç”¨æ ‡å‡†ã€‚ åœ¨æˆ‘ä»¬åŸæ¥çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å°†æ ‡å‡†è®¾ç½®ä¸ºNå’Œdotäº¤å‰ç†µã€‚ä½†å¦‚æœä½¿ç”¨åŠŸèƒ½æ¨¡å—ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨å®ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_32.png)
- en: Import torch dot Nï¼Œ Nï¼Œ dot funkã€‚Channel S Fã€‚And then down hereï¼Œ we say our loss
    equalsã€‚ and now we can callã€‚F dot cross entropy with our outputs and the labelsã€‚
    And these are all the thingsã€‚ And for nowï¼Œ we only want to return a dictionary
    with this lossã€‚ So Pyto lightning needs this dictionary so that it can show you
    the loss during the trainingã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥torchçš„Nï¼ŒNï¼Œdot funkã€‚Channel S Fã€‚ç„¶ååœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¯´æˆ‘ä»¬çš„æŸå¤±ç­‰äºã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è°ƒç”¨F dotäº¤å‰ç†µä¸æˆ‘ä»¬çš„è¾“å‡ºå’Œæ ‡ç­¾ã€‚è¿™äº›éƒ½æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ã€‚è€Œç°åœ¨ï¼Œæˆ‘ä»¬åªæƒ³è¿”å›ä¸€ä¸ªåŒ…å«è¿™ä¸ªæŸå¤±çš„å­—å…¸ã€‚å› æ­¤PyTorch
    Lightningéœ€è¦è¿™ä¸ªå­—å…¸ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºæŸå¤±ã€‚
- en: And this is all we need in our training stepã€‚ And then we also have to implement
    the train data loader functionã€‚ So what we want to do here is we want to do what
    we did in the beginning here we set up the training data set and the training
    data loaderã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬è®­ç»ƒæ­¥éª¤ä¸­æ‰€éœ€çš„ä¸€åˆ‡ã€‚ç„¶åæˆ‘ä»¬è¿˜å¿…é¡»å®ç°è®­ç»ƒæ•°æ®åŠ è½½å™¨å‡½æ•°ã€‚æˆ‘ä»¬æƒ³åœ¨è¿™é‡Œåšçš„å°±æ˜¯å›åˆ°å¼€å§‹æ—¶è®¾ç½®è®­ç»ƒæ•°æ®é›†å’Œè®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚
- en: So let's copy this and paste this in the function hereã€‚ So first our training
    data setã€‚ So this is this oneã€‚ And then the train data loaderã€‚ So this oneã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_34.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å¤åˆ¶è¿™ä¸ªå¹¶ç²˜è´´åˆ°è¿™ä¸ªå‡½æ•°é‡Œã€‚å› æ­¤é¦–å…ˆæ˜¯æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ã€‚è¿™å°±æ˜¯è¿™ä¸ªã€‚ç„¶åæ˜¯è®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚è¿™ä¸€ä¸ªã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_34.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_35.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_35.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_36.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_36.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_37.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_37.png)'
- en: And then we want to return the train data loader or train loaderã€‚ And now this
    is all we need to start a trainingã€‚ And now what we want to do is we say ifã€‚Name
    equals equalsï¼Œ underscore underscore mainã€‚Then we have to set up a lightning trainerã€‚
    So for thisï¼Œ we import a trainerã€‚ So we say from Pytorch lightning import trainerã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³è¦è¿”å›è®­ç»ƒæ•°æ®åŠ è½½å™¨æˆ–è®­ç»ƒåŠ è½½å™¨ã€‚ç°åœ¨è¿™å°±æ˜¯æˆ‘ä»¬å¼€å§‹è®­ç»ƒæ‰€éœ€çš„ä¸€åˆ‡ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è¦åšçš„æ˜¯ï¼Œå¦‚æœ`__name__`ç­‰äº`__main__`ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€ä¸ªLightningè®­ç»ƒå™¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯¼å…¥ä¸€ä¸ªè®­ç»ƒå™¨ã€‚æˆ‘ä»¬è¯´ä»Pytorch
    Lightningå¯¼å…¥è®­ç»ƒå™¨ã€‚
- en: Then we want to set up a trainerã€‚ So here we say our trainer equals our lightning
    trainerã€‚ And for nowï¼Œ I can show you a trick that is very helpful during developmentã€‚
    So you say fast defron equals trueã€‚ This will run a single batch through trainã€‚
    And also through validationã€‚ if we have a validation stepã€‚ And with thisã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æƒ³è®¾ç½®ä¸€ä¸ªè®­ç»ƒå™¨ã€‚å› æ­¤åœ¨è¿™é‡Œæˆ‘ä»¬è¯´æˆ‘ä»¬çš„è®­ç»ƒå™¨ç­‰äºæˆ‘ä»¬çš„Lightningè®­ç»ƒå™¨ã€‚ç°åœ¨ï¼Œæˆ‘å¯ä»¥ç»™ä½ å±•ç¤ºä¸€ä¸ªåœ¨å¼€å‘è¿‡ç¨‹ä¸­éå¸¸æœ‰ç”¨çš„æŠ€å·§ã€‚å› æ­¤ä½ è¯´`fast_dev_run`ç­‰äº`True`ã€‚è¿™å°†é€šè¿‡è®­ç»ƒå’ŒéªŒè¯è¿è¡Œä¸€ä¸ªæ‰¹æ¬¡ã€‚å¦‚æœæˆ‘ä»¬æœ‰éªŒè¯æ­¥éª¤ã€‚é€šè¿‡è¿™ä¸ªã€‚
- en: you can test if your model worksã€‚ So now we also have to set up our modelã€‚ So
    we say model equalsã€‚ And let's call this lit model to make it clear that this
    is a lightning modelã€‚ So litã€‚ğŸ˜Šã€‚uralNeAnd here we say let neural net with the hyperparameterã€‚
    So it needs the input sizeã€‚ It needs the hidden sizeï¼Œ and it needs the number
    of classesã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æµ‹è¯•ä½ çš„æ¨¡å‹æ˜¯å¦æœ‰æ•ˆã€‚å› æ­¤ç°åœ¨æˆ‘ä»¬è¿˜å¿…é¡»è®¾ç½®æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¯´æ¨¡å‹ç­‰äºã€‚è®©æˆ‘ä»¬ç§°å…¶ä¸ºlitæ¨¡å‹ï¼Œä»¥æ¸…æ¥šåœ°è¡¨æ˜è¿™æ˜¯ä¸€ä¸ªLightningæ¨¡å‹ã€‚å› æ­¤litã€‚ğŸ˜Šã€‚uralNeã€‚è¿™é‡Œæˆ‘ä»¬è¯´è®©ç¥ç»ç½‘ç»œå…·æœ‰è¶…å‚æ•°ã€‚å› æ­¤å®ƒéœ€è¦è¾“å…¥å¤§å°ã€‚å®ƒéœ€è¦éšè—å¤§å°ï¼Œå¹¶ä¸”éœ€è¦ç±»åˆ«æ•°ã€‚
- en: which we all have here for our hyperparametersã€‚ Then we have to fit it to our
    trainerã€‚ So we say trainer dot fit our modelã€‚ And now we can already run it and
    see if this is workingã€‚ So nowã€‚Let's go to the consoleã€‚ And now let's run this
    fileã€‚ So we say Python lightning dot piã€‚Here we get a errorã€‚ Soï¼Œ of courseï¼Œ I
    rename the lital netã€‚ So I also have to sayã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œéƒ½æœ‰è¶…å‚æ•°ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»å°†å…¶é€‚é…åˆ°æˆ‘ä»¬çš„è®­ç»ƒå™¨ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´trainer.dot fitæˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ç›´æ¥è¿è¡Œå®ƒå¹¶çœ‹çœ‹è¿™æ˜¯å¦æœ‰æ•ˆã€‚æ‰€ä»¥ç°åœ¨ï¼Œè®©æˆ‘ä»¬å»æ§åˆ¶å°ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œè¿™ä¸ªæ–‡ä»¶ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´Python
    lightning.dot piã€‚è¿™é‡Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªé”™è¯¯ã€‚æ‰€ä»¥ï¼Œå½“ç„¶ï¼Œæˆ‘é‡å‘½åäº†lital netã€‚æ‰€ä»¥æˆ‘ä¹Ÿå¿…é¡»è¯´æ˜ã€‚
- en: Let neural net hereã€‚ And now againï¼Œ let's run itã€‚And now we see it startingã€‚
    so we see that we have no GP supportã€‚ We also get an overview of our different
    layers and the parametersã€‚ Then since I'm running it the first timeï¼Œ it's downloading
    the data setã€‚And then here is the trainingã€‚ So it workedã€‚ So it only did one batch
    because we set fast defffron equals trueã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ç¥ç»ç½‘ç»œå‘½åä¸ºè¿™é‡Œã€‚ç°åœ¨å†æ¬¡è¿è¡Œå®ƒã€‚ç°åœ¨æˆ‘ä»¬çœ‹åˆ°å®ƒå¼€å§‹äº†ã€‚æˆ‘ä»¬çœ‹åˆ°æ²¡æœ‰GPUæ”¯æŒã€‚æˆ‘ä»¬è¿˜å¾—åˆ°äº†ä¸åŒå±‚å’Œå‚æ•°çš„æ¦‚è¿°ã€‚ç„¶åå› ä¸ºæˆ‘æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œæ‰€ä»¥å®ƒæ­£åœ¨ä¸‹è½½æ•°æ®é›†ã€‚ç„¶åè¿™é‡Œæ˜¯è®­ç»ƒã€‚æ‰€ä»¥å®ƒæˆåŠŸäº†ã€‚å› ä¸ºæˆ‘ä»¬è®¾ç½®fast
    defffronç­‰äºtrueï¼Œæ‰€ä»¥åªå¤„ç†äº†ä¸€æ‰¹ã€‚
- en: So let's clear it and test it one more timeã€‚ So now it shouldn't download it
    anymoreã€‚And this was way fasterã€‚ And now hereï¼Œ for exampleï¼Œ we get one warningï¼Œ
    so it saysã€‚The data loader train data loader does not have many workersï¼Œ which
    may be a bottleneckã€‚ Consider increasing the value of nu workers argumentã€‚ Try
    4ã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬æ¸…é™¤å®ƒå¹¶å†æµ‹è¯•ä¸€æ¬¡ã€‚æ‰€ä»¥ç°åœ¨å®ƒä¸åº”è¯¥å†ä¸‹è½½äº†ã€‚è¿™å¿«å¾—å¤šäº†ã€‚ç°åœ¨è¿™é‡Œï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªè­¦å‘Šï¼Œæ‰€ä»¥å®ƒè¯´ã€‚æ•°æ®åŠ è½½å™¨è®­ç»ƒæ•°æ®åŠ è½½å™¨æ²¡æœ‰å¾ˆå¤šå·¥ä½œè¿›ç¨‹ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªç“¶é¢ˆã€‚è€ƒè™‘å¢åŠ nu
    workerså‚æ•°çš„å€¼ã€‚è¯•è¯•4ã€‚
- en: So this is actually the first tip that can help us to speed up our codeã€‚ So
    hereã€‚ what we want to do is in our train loaderã€‚ We can also give it the argumentã€‚
    nu workers equals 4ã€‚ And now let's clear this and run it againã€‚And now our warning
    is goneï¼Œ So nowã€‚Here we see the overviewã€‚ We now only used one epochã€‚ and here
    we have the lossã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å®é™…ä¸Šæ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥å¸®åŠ©æˆ‘ä»¬åŠ é€Ÿä»£ç çš„æç¤ºã€‚åœ¨æˆ‘ä»¬çš„è®­ç»ƒåŠ è½½å™¨ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç»™å®ƒçš„å‚æ•°è®¾ç½®ä¸ºnu workersç­‰äº4ã€‚ç°åœ¨æˆ‘ä»¬æ¸…é™¤è¿™ä¸ªå¹¶å†æ¬¡è¿è¡Œï¼Œç°åœ¨æˆ‘ä»¬çš„è­¦å‘Šæ¶ˆå¤±äº†ã€‚è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°äº†æ¦‚è§ˆã€‚æˆ‘ä»¬ç°åœ¨åªä½¿ç”¨äº†ä¸€ä¸ªepochï¼Œè¿™é‡Œæœ‰æŸå¤±å€¼ã€‚
- en: So now if you want to have a full trainingï¼Œ we can also give our trainerã€‚ the
    argument max epoch equalsã€‚ and then the number of epochs that we definedã€‚ epochsã€‚
    So this is one of the hyperparametersã€‚And now let's set this to false againã€‚ So
    now this should do a full trainingã€‚ And nowï¼Œ let's see if this is workingã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨å¦‚æœä½ æƒ³è¿›è¡Œå®Œæ•´çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç»™æˆ‘ä»¬çš„è®­ç»ƒå™¨å‚æ•°max epochç­‰äºå®šä¹‰çš„epochæ•°é‡ã€‚æ‰€ä»¥è¿™æ˜¯è¶…å‚æ•°ä¹‹ä¸€ã€‚ç°åœ¨è®©æˆ‘ä»¬å†æ¬¡å°†å…¶è®¾ç½®ä¸ºfalseã€‚è¿™åº”è¯¥è¿›è¡Œå®Œæ•´çš„è®­ç»ƒã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦æœ‰æ•ˆã€‚
- en: And now this should takeã€‚Max eposï¼Œ sorryã€‚Now this should take a little longerã€‚And
    yeahï¼Œ we seeã€‚ So we get a nice progress barï¼Œ and we see our training worksï¼Œ and
    our loss should slowly decreaseã€‚ So this is workingã€‚ğŸ˜Šï¼ŒSo nowï¼Œ let me stop this
    for nowã€‚ And now the next thing we want to do is to do our evaluation or testingã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿™åº”è¯¥éœ€è¦ã€‚Max eposï¼ŒæŠ±æ­‰ã€‚ç°åœ¨è¿™åº”è¯¥ç¨å¾®é•¿ä¸€ç‚¹ã€‚æ˜¯çš„ï¼Œæˆ‘ä»¬çœ‹åˆ°ã€‚æ‰€ä»¥æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªä¸é”™çš„è¿›åº¦æ¡ï¼Œæˆ‘ä»¬çœ‹åˆ°è®­ç»ƒæ­£å¸¸è¿è¡Œï¼ŒæŸå¤±å€¼åº”è¯¥æ…¢æ…¢å‡å°‘ã€‚æ‰€ä»¥è¿™æœ‰æ•ˆã€‚ğŸ˜Šï¼Œæ‰€ä»¥ç°åœ¨è®©æˆ‘æš‚æ—¶åœæ­¢è¿™ä¸ªã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æƒ³è¦åšçš„æ˜¯è¿›è¡Œè¯„ä¼°æˆ–æµ‹è¯•ã€‚
- en: So similar to the training step and training data loaderã€‚ We now also want to
    add a validation step and a validation data loaderã€‚ So let me copy thisã€‚ And let
    me paste it in hereã€‚ And this has to be called validation stepã€‚And here we are
    doing the same thing actuallyã€‚ So as in the test train training stepã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç±»ä¼¼äºè®­ç»ƒæ­¥éª¤å’Œè®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚æˆ‘ä»¬ç°åœ¨ä¹Ÿæƒ³æ·»åŠ ä¸€ä¸ªéªŒè¯æ­¥éª¤å’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ã€‚æ‰€ä»¥è®©æˆ‘å¤åˆ¶è¿™ä¸ªã€‚å¹¶åœ¨è¿™é‡Œç²˜è´´ã€‚å®ƒå¿…é¡»è¢«ç§°ä¸ºéªŒè¯æ­¥éª¤ã€‚å®é™…ä¸Šæˆ‘ä»¬åœ¨è¿™é‡ŒåšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥åœ¨æµ‹è¯•è®­ç»ƒæ­¥éª¤ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
- en: So we reshape our imagesï¼Œ then we do the forward pass and calculate the lossã€‚
    And this time we use the key well loss or validation lossã€‚ and now let's set our
    fast defron to true againã€‚ and let me run it againã€‚ So now if we run itã€‚ we should
    get an errorã€‚ And yeahï¼Œ here we get the exceptionã€‚ you have defined validation
    stepã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬é‡æ–°è°ƒæ•´äº†å›¾åƒï¼Œç„¶åè¿›è¡Œå‰å‘ä¼ æ’­å¹¶è®¡ç®—æŸå¤±ã€‚è¿™æ¬¡æˆ‘ä»¬ä½¿ç”¨å…³é”®æŸå¤±æˆ–éªŒè¯æŸå¤±ã€‚ç°åœ¨æˆ‘ä»¬å†æ¬¡å°†fast defronè®¾ç½®ä¸ºtrueã€‚è®©æˆ‘å†è¿è¡Œä¸€æ¬¡ã€‚æ‰€ä»¥ç°åœ¨å¦‚æœæˆ‘ä»¬è¿è¡Œå®ƒï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ä¸€ä¸ªé”™è¯¯ã€‚æ˜¯çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¾—åˆ°äº†å¼‚å¸¸ï¼Œä½ å·²å®šä¹‰éªŒè¯æ­¥éª¤ã€‚
- en: but have not passed in a validation data loaderã€‚ So now we know what we have
    to doã€‚ We also have to use a validation data loaderã€‚ So let me copy and paste
    thisã€‚And this has to be called well data loaddownã€‚ So if you're not sure you can
    go to the officialã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å°šæœªä¼ å…¥éªŒè¯æ•°æ®åŠ è½½å™¨ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çŸ¥é“è¯¥æ€ä¹ˆåšã€‚æˆ‘ä»¬è¿˜å¿…é¡»ä½¿ç”¨éªŒè¯æ•°æ®åŠ è½½å™¨ã€‚æ‰€ä»¥è®©æˆ‘å¤åˆ¶å¹¶ç²˜è´´è¿™ä¸ªã€‚å¹¶ä¸”è¿™å¿…é¡»è¢«ç§°ä¸ºwell data loaddownã€‚å¦‚æœä½ ä¸ç¡®å®šï¼Œå¯ä»¥å»å®˜æ–¹æ–‡æ¡£ã€‚
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_39.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_39.png)'
- en: Documentationï¼Œ and then scroll to the validation loopã€‚ Thereã€‚ you see theã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_41.png)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡æ¡£ï¼Œç„¶åæ»šåŠ¨åˆ°éªŒè¯å¾ªç¯ã€‚åœ¨é‚£é‡Œã€‚ä½ ä¼šçœ‹åˆ°ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_41.png)
- en: 3 functions that you needï¼Œ soã€‚Nowï¼Œ first of allï¼Œ now we have ourã€‚Validation
    data setã€‚ So here we want to sayï¼Œ or we want to grabã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_43.png)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦çš„ä¸‰ä¸ªå‡½æ•°ï¼Œæ‰€ä»¥ã€‚ç°åœ¨ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬æœ‰æˆ‘ä»¬çš„ã€‚éªŒè¯æ•°æ®é›†ã€‚å› æ­¤åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³è¯´ï¼Œæˆ–è€…æˆ‘ä»¬æƒ³æŠ“å–ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_43.png)
- en: The next or the test data setã€‚ So in this caseï¼Œ I call the test data setã€‚ but
    actuallyã€‚ you want to haveã€‚A split of your data to a training data setã€‚ a validation
    data set and a test data setã€‚ So the validation data set is used to get an unbiased
    evaluation of the model performance while tuning the hyperparametersã€‚And then
    the test dataset set is used at the very end to provide an unbiased evaluation
    with data that the model has never seen beforeã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªæˆ–æµ‹è¯•æ•°æ®é›†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ç§°ä¹‹ä¸ºæµ‹è¯•æ•°æ®é›†ã€‚ä½†å®é™…ä¸Šã€‚ä½ éœ€è¦å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒæ•°æ®é›†ã€éªŒè¯æ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ã€‚éªŒè¯æ•°æ®é›†ç”¨äºåœ¨è°ƒæ•´è¶…å‚æ•°æ—¶å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œæ— åè¯„ä¼°ã€‚è€Œæµ‹è¯•æ•°æ®é›†åˆ™æ˜¯åœ¨æœ€åæä¾›å¯¹æ¨¡å‹ä»æœªè§è¿‡çš„æ•°æ®çš„æ— åè¯„ä¼°ã€‚
- en: So in this exampleï¼Œ weï¼Œ let's say we only have two splits of our data setã€‚ Nowã€‚
    we only use the first two steps training and validationã€‚ So let me copy this and
    paste it in hereã€‚ And let's rename this to a validation data setã€‚ And then let's
    grab the validation data loaderã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾åªæœ‰ä¸¤ä¸ªæ•°æ®é›†çš„åˆ’åˆ†ã€‚ç°åœ¨ã€‚æˆ‘ä»¬åªä½¿ç”¨å‰ä¸¤ä¸ªæ­¥éª¤è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚æ‰€ä»¥è®©æˆ‘å¤åˆ¶è¿™ä¸ªå¹¶ç²˜è´´åˆ°è¿™é‡Œã€‚ç„¶åè®©æˆ‘ä»¬å°†å…¶é‡å‘½åä¸ºéªŒè¯æ•°æ®é›†ã€‚æ¥ç€æˆ‘ä»¬è·å–éªŒè¯æ•°æ®åŠ è½½å™¨ã€‚
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_45.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_45.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_46.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_46.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_47.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_47.png)'
- en: And rename it to Val loader and then return the v loaderã€‚And now let's run it
    againã€‚ So let's say Python lightning dot piã€‚And we get anarrowã€‚ So data set equals
    well data setã€‚ of courseã€‚ And let's clear this and run it again and then it should
    do one pass through training and validationã€‚ and we see it workedã€‚ And now we
    againï¼Œ get the same warningã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶å°†å…¶é‡å‘½åä¸ºéªŒè¯åŠ è½½å™¨ï¼Œç„¶åè¿”å›våŠ è½½å™¨ã€‚ç°åœ¨è®©æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚å‡è®¾Python lightning dot piã€‚æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªé”™è¯¯ã€‚å› æ­¤æ•°æ®é›†ç­‰äºå¥½çš„æ•°æ®é›†ã€‚
    å½“ç„¶ã€‚è®©æˆ‘ä»¬æ¸…é™¤è¿™ä¸ªå¹¶å†æ¬¡è¿è¡Œï¼Œç„¶åå®ƒåº”è¯¥é€šè¿‡è®­ç»ƒå’ŒéªŒè¯è¿›è¡Œä¸€æ¬¡ä¼ é€’ã€‚æˆ‘ä»¬çœ‹åˆ°å®ƒæˆåŠŸäº†ã€‚ç°åœ¨æˆ‘ä»¬å†æ¬¡å¾—åˆ°äº†ç›¸åŒçš„è­¦å‘Šã€‚
- en: So here we use the nu workers equals 4ã€‚ So let's clear it and try it againã€‚
    So you see it already starts giving us hints when we make some mistakesã€‚ And now
    we see it workedã€‚ And now it's also to suggesting to define a validation epoch
    and method for accumulating statsã€‚ So let's go to the documentation and grab this
    function to see how it looks like Soã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨nu workersç­‰äº4ã€‚å› æ­¤è®©æˆ‘ä»¬æ¸…é™¤å¹¶å†æ¬¡å°è¯•ã€‚å› æ­¤ï¼Œä½ ä¼šçœ‹åˆ°ï¼Œå½“æˆ‘ä»¬çŠ¯é”™è¯¯æ—¶ï¼Œå®ƒå·²ç»å¼€å§‹ç»™æˆ‘ä»¬æç¤ºã€‚ç°åœ¨æˆ‘ä»¬çœ‹åˆ°å®ƒæˆåŠŸäº†ã€‚ç°åœ¨å®ƒä¹Ÿå»ºè®®å®šä¹‰ä¸€ä¸ªéªŒè¯å‘¨æœŸå’Œæ–¹æ³•æ¥ç´¯ç§¯ç»Ÿè®¡æ•°æ®ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å»æ–‡æ¡£ä¸­è·å–è¿™ä¸ªå‡½æ•°ï¼Œçœ‹çœ‹å®ƒçš„æ ·å­ã€‚
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_49.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_49.png)'
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_50.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_50.png)'
- en: We copy and paste thisã€‚ So this is the function that is executed after each
    validation epochã€‚ And here we want to calculate the average lossã€‚ So actuallyï¼Œ
    in our exampleã€‚ we want to do exactly the sameã€‚ So we want to callã€‚ calculate
    the average loss by saying this is torch stackã€‚ And then since weã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¤åˆ¶å¹¶ç²˜è´´è¿™ä¸ªã€‚å› æ­¤è¿™æ˜¯åœ¨æ¯ä¸ªéªŒè¯å‘¨æœŸåæ‰§è¡Œçš„å‡½æ•°ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³è®¡ç®—å¹³å‡æŸå¤±ã€‚å®é™…ä¸Šï¼Œåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ã€‚æˆ‘ä»¬æƒ³åšçš„æ­£æ˜¯è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬æƒ³è°ƒç”¨ã€‚é€šè¿‡è¯´è¿™æ˜¯torch
    stackæ¥è®¡ç®—å¹³å‡æŸå¤±ã€‚ç„¶åå› ä¸ºæˆ‘ä»¬ã€‚
- en: Called the key validation lossã€‚ We can access it here and then calculate the
    mean over all theã€‚Lossesï¼Œ and nowï¼Œ for nowï¼Œ let's not worry about thisã€‚ And then
    we return the average loss as a dictionaryã€‚And then we are doneã€‚ So nowï¼Œ if we
    clear itã€‚Thenï¼Œ we should get aã€‚1 pass now no more warningã€‚And now we have everything
    that we need for our coatã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¢«ç§°ä¸ºå…³é”®éªŒè¯æŸå¤±ã€‚æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œè®¿é—®å®ƒï¼Œç„¶åè®¡ç®—æ‰€æœ‰æŸå¤±çš„å‡å€¼ï¼Œç°åœ¨ï¼Œæš‚æ—¶å…ˆä¸æ‹…å¿ƒè¿™ä¸ªã€‚ç„¶åæˆ‘ä»¬å°†å¹³å‡æŸå¤±ä½œä¸ºå­—å…¸è¿”å›ã€‚è¿™æ ·æˆ‘ä»¬å°±å®Œæˆäº†ã€‚æ‰€ä»¥ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬æ¸…é™¤å®ƒã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ä¸€ä¸ªã€‚1æ¬¡é€šè¿‡ï¼Œç°åœ¨æ²¡æœ‰æ›´å¤šçš„è­¦å‘Šã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡æ¥å¤„ç†æˆ‘ä»¬çš„ä»£ç ã€‚
- en: So this is all we need with pie touch lightningã€‚And nowï¼Œ let me show you one
    more hintã€‚ what we can getã€‚ Soï¼Œ for exampleï¼Œ in our validation loaderã€‚ if we accidentally
    set shuffle equals true and then try to run itã€‚ we should get a warning or a hintã€‚So
    yeahï¼Œ here we see user warningã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬åœ¨PyTorch Lightningä¸­æ‰€éœ€çš„å…¨éƒ¨ã€‚ç°åœ¨ï¼Œè®©æˆ‘ç»™ä½ å±•ç¤ºä¸€ä¸ªæç¤ºã€‚æˆ‘ä»¬å¯ä»¥è·å¾—çš„å†…å®¹ã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘ä»¬çš„éªŒè¯åŠ è½½å™¨ä¸­ã€‚å¦‚æœæˆ‘ä»¬ä¸å°å¿ƒå°†shuffleè®¾ç½®ä¸ºtrueå¹¶å°è¯•è¿è¡Œå®ƒã€‚æˆ‘ä»¬åº”è¯¥å¾—åˆ°ä¸€ä¸ªè­¦å‘Šæˆ–æç¤ºã€‚æ‰€ä»¥æ˜¯çš„ï¼Œè¿™é‡Œæˆ‘ä»¬çœ‹åˆ°äº†ç”¨æˆ·è­¦å‘Šã€‚
- en: Yourve data loader has shuffle equals trueã€‚ It is best practice to turn this
    off for validation and test data loadusã€‚ So you seeï¼Œ we can actually already improve
    our code with this frameworkã€‚And nowã€‚ let's compare this with ourã€‚Original codeã€‚
    So if we have a look at this code in Githubã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„æ•°æ®åŠ è½½å™¨æœ‰`shuffle equals true`ã€‚åœ¨éªŒè¯å’Œæµ‹è¯•æ•°æ®åŠ è½½æ—¶ï¼Œæœ€ä½³åšæ³•æ˜¯å°†å…¶å…³é—­ã€‚æ‰€ä»¥ä½ çœ‹ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥ç”¨è¿™ä¸ªæ¡†æ¶æ”¹è¿›æˆ‘ä»¬çš„ä»£ç ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒå’Œæˆ‘ä»¬çš„åŸå§‹ä»£ç è¿›è¡Œæ¯”è¾ƒã€‚å¦‚æœæˆ‘ä»¬åœ¨Githubä¸ŠæŸ¥çœ‹è¿™æ®µä»£ç ã€‚
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_52.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_52.png)'
- en: Then we no longer need this device functionalityã€‚And we no longer needs to have
    the manual for loop over all epochs and over all the batchesã€‚ we no longer have
    to care about these two device callsã€‚ we no longer have to care about the optimizer
    and the backward pass and also we can leave out the whole validation loop because
    we can calculate this with this validation step and nowã€‚ for exampleï¼Œ if you also
    want a training stepï¼Œ we can easily edit the same way as we are doing with this
    function and with this function and nowã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¸å†éœ€è¦è¿™ä¸ªè®¾å¤‡åŠŸèƒ½ã€‚æˆ‘ä»¬ä¹Ÿä¸å†éœ€è¦æ‰‹åŠ¨éå†æ‰€æœ‰çš„è½®æ¬¡å’Œæ‰€æœ‰çš„æ‰¹æ¬¡ã€‚æˆ‘ä»¬ä¸å†éœ€è¦å…³å¿ƒè¿™ä¸¤ä¸ªè®¾å¤‡è°ƒç”¨ã€‚æˆ‘ä»¬ä¹Ÿä¸å†éœ€è¦å…³å¿ƒä¼˜åŒ–å™¨å’Œåå‘ä¼ æ’­ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯ä»¥çœç•¥æ•´ä¸ªéªŒè¯å¾ªç¯ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªéªŒè¯æ­¥éª¤æ¥è®¡ç®—ï¼Œç°åœ¨ï¼Œä¾‹å¦‚ï¼Œå¦‚æœä½ è¿˜æƒ³è¦ä¸€ä¸ªè®­ç»ƒæ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥åŒæ ·çš„æ–¹å¼è½»æ¾ç¼–è¾‘ï¼Œå°±åƒæˆ‘ä»¬ç”¨è¿™ä¸ªå‡½æ•°å’Œè¿™ä¸ªå‡½æ•°ä¸€æ ·ï¼Œç°åœ¨ã€‚
- en: for exampleï¼Œ if you want to use GPusï¼Œ then we can easily do this by giving our
    trainer the argumentã€‚ GPus equalsï¼Œ for exampleï¼Œ one and when you want to scale
    it up and have more GPus availableã€‚ you can also useã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_54.png)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³ä½¿ç”¨GPUï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç»™æˆ‘ä»¬çš„è®­ç»ƒå™¨ä¼ é€’å‚æ•°`GPus equals`ï¼Œä¾‹å¦‚`one`æ¥è½»æ¾å®ç°ï¼Œå½“ä½ æƒ³æ‰©å¤§è§„æ¨¡å¹¶ä¸”æœ‰æ›´å¤šGPUå¯ç”¨æ—¶ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_54.png)
- en: 2 or let's say4ï¼Œ or you can use even T supportã€‚ So it's really easy to switch
    from CPU to GP and then scale it upã€‚ And you can also have a distributed backendã€‚
    So DPï¼Œ for exampleã€‚You can also easily switch to 16 bit precisionã€‚You can lock
    the GP memoryã€‚ So a lot of features that you can now very easily test with this
    frameworkã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¼Œæˆ–è€…æˆ‘ä»¬è¯´4ï¼Œæˆ–è€…ä½ ç”šè‡³å¯ä»¥ä½¿ç”¨Tæ”¯æŒã€‚æ‰€ä»¥ä»CPUåˆ‡æ¢åˆ°GPUï¼Œç„¶åæ‰©å±•è§„æ¨¡çœŸçš„å¾ˆç®€å•ã€‚ä½ è¿˜å¯ä»¥æ‹¥æœ‰ä¸€ä¸ªåˆ†å¸ƒå¼åç«¯ã€‚æ‰€ä»¥DPï¼Œä¾‹å¦‚ã€‚ä½ ä¹Ÿå¯ä»¥è½»æ¾åˆ‡æ¢åˆ°16ä½ç²¾åº¦ã€‚ä½ å¯ä»¥é”å®šGPUå†…å­˜ã€‚å› æ­¤ï¼Œä½ ç°åœ¨å¯ä»¥éå¸¸è½»æ¾åœ°æµ‹è¯•å¾ˆå¤šåŠŸèƒ½ï¼Œè¿™ä¸ªæ¡†æ¶éå¸¸é€‚åˆã€‚
- en: You just have to use all the different arguments for the trainerã€‚ Andï¼Œ for exampleã€‚
    one more helpful function that you can try is auto L Rã€‚Find equals trueã€‚ This
    will run aã€‚Algorithm to find the best learning rateã€‚ So you can try this oneã€‚You
    can also setï¼Œ for exampleã€‚ deterministic equals trueã€‚ So this allows it to reproduce
    your resultsã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åªéœ€ä½¿ç”¨æ‰€æœ‰ä¸åŒçš„è®­ç»ƒå™¨å‚æ•°ã€‚æ¯”å¦‚è¯´ï¼Œè¿˜æœ‰ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„åŠŸèƒ½ä½ å¯ä»¥å°è¯•ï¼Œå°±æ˜¯`auto L R`ã€‚`Find equals true`ã€‚è¿™å°†è¿è¡Œä¸€ä¸ªç®—æ³•æ¥å¯»æ‰¾æœ€ä½³å­¦ä¹ ç‡ã€‚æ‰€ä»¥ä½ å¯ä»¥å°è¯•è¿™ä¸ªã€‚ä½ ä¹Ÿå¯ä»¥è®¾ç½®ï¼Œä¾‹å¦‚ï¼Œ`deterministic
    equals true`ã€‚è¿™æ ·å¯ä»¥ä½¿ä½ çš„ç»“æœå¯é‡ç°ã€‚
- en: or you can apply gradient clipping very easily by just passing in the argument
    Claient gripve equalsã€‚ and then some value between 0 and oneï¼Œ I guessï¼Œ So for
    thisï¼Œ you againã€‚ have to check out the official documentationã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_56.png)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ä½ å¯ä»¥é€šè¿‡ç®€å•åœ°ä¼ å…¥å‚æ•°`Claient gripve equals`å’Œä¸€ä¸ªä»‹äº0åˆ°1ä¹‹é—´çš„å€¼æ¥è½»æ¾åº”ç”¨æ¢¯åº¦è£å‰ªï¼Œæˆ‘æƒ³ï¼Œè¿™æ ·çš„è¯ï¼Œä½ ä»ç„¶éœ€è¦æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_56.png)
- en: There you find all the different features and use casesã€‚ And now let me show
    you the full training and validationã€‚ So let's remove thisã€‚ And now let's set
    the argument fast defffron to false againã€‚ So againã€‚ I'm not having a high number
    of epochsã€‚ So it's only two because it takes a long time here without the GPã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‚£é‡Œä½ å¯ä»¥æ‰¾åˆ°æ‰€æœ‰ä¸åŒçš„åŠŸèƒ½å’Œç”¨ä¾‹ã€‚ç°åœ¨è®©æˆ‘ç»™ä½ å±•ç¤ºå®Œæ•´çš„è®­ç»ƒå’ŒéªŒè¯ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å»æ‰è¿™ä¸ªã€‚ç°åœ¨è®©æˆ‘ä»¬å°†å‚æ•°`fast defffron`é‡æ–°è®¾ç½®ä¸º`false`ã€‚æ‰€ä»¥å†æ¬¡å¼ºè°ƒï¼Œæˆ‘æ²¡æœ‰è®¾ç½®å¾ˆå¤šçš„è½®æ¬¡ï¼Œæ‰€ä»¥åªæœ‰ä¸¤ä¸ªï¼Œå› ä¸ºåœ¨æ²¡æœ‰GPUçš„æƒ…å†µä¸‹ï¼Œè¿™é‡Œä¼šèŠ±è´¹å¾ˆé•¿æ—¶é—´ã€‚
- en: But let's run it anywayã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_58.png)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬è¿˜æ˜¯è¿è¡Œä¸€ä¸‹ã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_58.png)
- en: So againï¼Œ we see the progress in our first epoch here and how our loss is decreasingã€‚
    And when this is doneï¼Œ we should a faster progress bar for the validation loopã€‚So
    now be carefulã€‚ Now here we see the validation loopã€‚ and now our second training
    epoch startsã€‚ Soï¼Œ yeahã€‚ this is workingã€‚And now the second validation and now
    it's doneã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å†æ¬¡çœ‹åˆ°è¿™é‡Œç¬¬ä¸€è½®çš„è¿›å±•ï¼Œä»¥åŠæˆ‘ä»¬çš„æŸå¤±æ˜¯å¦‚ä½•é™ä½çš„ã€‚å½“è¿™ä¸€åˆ‡å®Œæˆæ—¶ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨éªŒè¯å¾ªç¯ä¸­çœ‹åˆ°ä¸€ä¸ªæ›´å¿«çš„è¿›åº¦æ¡ã€‚ç°åœ¨å°å¿ƒã€‚ç°åœ¨æˆ‘ä»¬çœ‹åˆ°éªŒè¯å¾ªç¯ã€‚ç°åœ¨æˆ‘ä»¬çš„ç¬¬äºŒä¸ªè®­ç»ƒè½®å¼€å§‹äº†ã€‚æ‰€ä»¥ï¼Œæ²¡é”™ï¼Œè¿™åœ¨å·¥ä½œã€‚ç°åœ¨ç¬¬äºŒæ¬¡éªŒè¯ï¼Œä¹Ÿå®Œæˆäº†ã€‚
- en: and we can see and inspect the final lossã€‚ So this workedã€‚ And now as the last
    thingã€‚ let me show you the integrated tenor board supportã€‚ So as you can seeã€‚
    there is all already a folderï¼Œ which is called lightning lockã€‚ So it's already
    automatically saving some checkpointã€‚ğŸ˜Šï¼ŒSo and nowã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹å¹¶æ£€æŸ¥æœ€ç»ˆçš„æŸå¤±ã€‚å› æ­¤è¿™æœ‰æ•ˆã€‚ç°åœ¨æœ€åä¸€ä»¶äº‹ï¼Œè®©æˆ‘ç»™ä½ å±•ç¤ºé›†æˆçš„å¤©çº¿æ¿æ”¯æŒã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå·²ç»æœ‰ä¸€ä¸ªåä¸º lightning lock çš„æ–‡ä»¶å¤¹ï¼Œæ‰€ä»¥å®ƒå·²ç»è‡ªåŠ¨ä¿å­˜äº†ä¸€äº›æ£€æŸ¥ç‚¹ã€‚ğŸ˜Šï¼Œæ‰€ä»¥ç°åœ¨ã€‚
- en: if we want to inspect the different losses during in the tensor boardï¼Œ then
    what we have to do isã€‚ for exampleï¼Œ if you want to inspect the trainingã€‚ Then
    in our training stepã€‚ we create another dictionaryã€‚ and let's call this tenor
    board locks equalsã€‚ and this is an againã€‚ a dictionaryã€‚ and here let's call this
    train loss as a key and as valueï¼Œ it's the same lossã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³æ£€æŸ¥å¤©çº¿æ¿ä¸­çš„ä¸åŒæŸå¤±ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦åšçš„æ˜¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³æ£€æŸ¥è®­ç»ƒã€‚é‚£ä¹ˆåœ¨æˆ‘ä»¬çš„è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºå¦ä¸€ä¸ªå­—å…¸ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºå¤©çº¿æ¿é”ï¼Œç­‰äºã€‚å†ä¸€æ¬¡ï¼Œè¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè¿™é‡Œæˆ‘ä»¬æŠŠè®­ç»ƒæŸå¤±ä½œä¸ºé”®ï¼Œå€¼æ˜¯ç›¸åŒçš„æŸå¤±ã€‚
- en: And then we also append the tensor board loss to our dictionaryã€‚ And we have
    to give it the key lock and then lockã€‚ And this is our tensor board locksã€‚And
    now the same in our validation epoch endã€‚ So here we create the tensboard locksã€‚
    And here let's call it average validation lossã€‚ And this is the averageã€‚Average
    lossã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜å°†å¤©çº¿æ¿æŸå¤±é™„åŠ åˆ°æˆ‘ä»¬çš„å­—å…¸ä¸­ã€‚æˆ‘ä»¬å¿…é¡»ç»™å®ƒé’¥åŒ™é”ï¼Œç„¶åæ˜¯é”ã€‚è¿™æ˜¯æˆ‘ä»¬çš„å¤©çº¿æ¿é”ã€‚ç°åœ¨åœ¨æˆ‘ä»¬çš„éªŒè¯å‘¨æœŸç»“æŸæ—¶ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬åˆ›å»ºå¤©çº¿æ¿é”ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºå¹³å‡éªŒè¯æŸå¤±ã€‚è¿™æ˜¯å¹³å‡çš„ï¼Œå¹³å‡æŸå¤±ã€‚
- en: And then here againï¼Œ we used the key lock and then the tenzo board locksã€‚ And
    now let's run it one more time to save all those thingsã€‚So now we have to wait
    until this is doneã€‚So now our training and validation is doneã€‚ So now it should
    haveã€‚Save all of those to the lock directoryã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é’¥åŒ™é”å’Œå¤©çº¿æ¿é”ã€‚ç°åœ¨æˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ä»¥ä¿å­˜æ‰€æœ‰å†…å®¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ç­‰åˆ°è¿™ä¸ªå®Œæˆã€‚ç°åœ¨æˆ‘ä»¬çš„è®­ç»ƒå’ŒéªŒè¯éƒ½å®Œæˆäº†ã€‚æ‰€ä»¥ç°åœ¨åº”è¯¥ä¿å­˜æ‰€æœ‰è¿™äº›åˆ°é”ç›®å½•ã€‚
- en: And now we can start the tensor board by saying tensor board minus minus lockã€‚D
    equalsã€‚ and then light ning locksã€‚ And by the wayï¼Œ I also have a full tutorial
    about how you can work with the Tensor boardã€‚ I will also put the link in the
    descriptionã€‚And with lightningã€‚ you don't have to install it manually become because
    it comes with the requirements of lightningã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡è¾“å…¥ tensor board minus minus lock æ¥å¯åŠ¨å¤©çº¿æ¿ã€‚D ç­‰äºï¼Œç„¶åæ˜¯ lightning locksã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œæˆ‘ä¹Ÿæœ‰ä¸€ä¸ªå®Œæ•´çš„æ•™ç¨‹ï¼Œè®²è¿°å¦‚ä½•ä½¿ç”¨
    Tensor boardã€‚æˆ‘ä¼šåœ¨æè¿°ä¸­æ”¾ä¸Šé“¾æ¥ã€‚ä½¿ç”¨ lightningï¼Œä½ ä¸å¿…æ‰‹åŠ¨å®‰è£…ï¼Œå› ä¸ºå®ƒåŒ…å«åœ¨ lightning çš„è¦æ±‚ä¸­ã€‚
- en: So this should automatically work nowã€‚ So now if we hit runã€‚ and sorryï¼Œ this
    was no underscoreã€‚inus minus loar equals lightning locksã€‚And now it worksã€‚ So
    now our tensor board is running hereã€‚ So now if we open up thisã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_60.png)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ç°åœ¨åº”è¯¥è‡ªåŠ¨å·¥ä½œã€‚ç°åœ¨å¦‚æœæˆ‘ä»¬ç‚¹å‡»è¿è¡Œï¼ŒæŠ±æ­‰ï¼Œè¿™é‡Œæ²¡æœ‰ä¸‹åˆ’çº¿ã€‚inus minus loar ç­‰äº lightning locksã€‚ç°åœ¨å®ƒå¯ä»¥å·¥ä½œã€‚ç°åœ¨æˆ‘ä»¬çš„å¤©çº¿æ¿åœ¨è¿™é‡Œè¿è¡Œã€‚å¦‚æœæˆ‘ä»¬æ‰“å¼€è¿™ä¸ªã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_60.png)
- en: Then we should inspect the epochsã€‚ Then we have the average validation lossã€‚
    So since we only use twoã€‚Epochsï¼Œ we don't see a lot of difference hereã€‚ So it's
    only a one lineã€‚ But for the training lossï¼Œ this is what we looked after eachã€‚Training
    stepã€‚ So here we see a nice graph how our training loss decreasedã€‚ So yeahï¼Œ you
    seeã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åº”è¯¥æ£€æŸ¥å‘¨æœŸã€‚ç„¶åæˆ‘ä»¬æœ‰å¹³å‡éªŒè¯æŸå¤±ã€‚ç”±äºæˆ‘ä»¬åªä½¿ç”¨äº†ä¸¤ä¸ªå‘¨æœŸï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œçœ‹ä¸åˆ°å¤ªå¤§çš„å·®å¼‚ï¼Œæ‰€ä»¥åªæœ‰ä¸€è¡Œã€‚ä½†å¯¹äºè®­ç»ƒæŸå¤±ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨æ¯ä¸ªè®­ç»ƒæ­¥éª¤åæŸ¥çœ‹çš„ã€‚å› æ­¤è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°ä¸€ä¸ªå¾ˆå¥½çš„å›¾è¡¨ï¼Œæ˜¾ç¤ºæˆ‘ä»¬çš„è®­ç»ƒæŸå¤±æ˜¯å¦‚ä½•å‡å°‘çš„ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œä½ çœ‹åˆ°äº†ã€‚
- en: we have automatic tensor board integrationï¼Œ and it's very easy to work with
    this toolã€‚ So yeahã€‚ these are most of the features I wanted to show youã€‚ and let
    me know in the comments if you like this frameworkã€‚ And if you also think that
    it can simplify your development processã€‚ And if you like this videoã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰è‡ªåŠ¨çš„å¤©çº¿æ¿é›†æˆï¼Œä½¿ç”¨è¿™ä¸ªå·¥å…·éå¸¸ç®€å•ã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼Œè¿™äº›æ˜¯æˆ‘æƒ³å±•ç¤ºçš„å¤§éƒ¨åˆ†åŠŸèƒ½ã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªæ¡†æ¶ï¼Œè¯·åœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘ã€‚å¦‚æœä½ ä¹Ÿè®¤ä¸ºå®ƒå¯ä»¥ç®€åŒ–ä½ çš„å¼€å‘è¿‡ç¨‹ã€‚å¦‚æœä½ å–œæ¬¢è¿™ä¸ªè§†é¢‘ã€‚
- en: then please hit the like button and consider subscribing to the channelã€‚ this
    helps me a lot and see next time byã€‚![](img/8f1dbba751e44013b8cee2c7d55082c5_62.png)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·ç‚¹å‡»å–œæ¬¢æŒ‰é’®ï¼Œå¹¶è€ƒè™‘è®¢é˜…é¢‘é“ã€‚è¿™å¯¹æˆ‘å¸®åŠ©å¾ˆå¤§ï¼Œä¸‹æ¬¡å†è§ï¼![](img/8f1dbba751e44013b8cee2c7d55082c5_62.png)
- en: '![](img/8f1dbba751e44013b8cee2c7d55082c5_63.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f1dbba751e44013b8cee2c7d55082c5_63.png)'
