# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P31ÔºöL5.5- boostrapping‰∏éÂü∫ÂáÜË∂ÖÂèÇÊï∞ - ShowMeAI - BV15f4y1w7b8

HiÔºå this is Jeff Heaton„ÄÇ welcomel to applications of deep neural networks with Washington University„ÄÇ In this videoÔºå we're going to talk about L1 L2 and dropout together„ÄÇ You might be thinking great„ÄÇ I had to figure out how many layers to have in a neural network„ÄÇ how many neurons to put in each of those layers„ÄÇ Now„ÄÇ

 I've got all these regularization techniques to figure out as well„ÄÇ It's getting complicated to architect and neural network„ÄÇ Later in this course we'll see that we can use Bayesian optimization to help us figure this out„ÄÇ But for nowÔºå I'm going to give you some practical tips in this video for the latest on my AI course and projects„ÄÇ

 click subscribe in the bell next to it to be notified of every new video„ÄÇ So we've vet on quite a few hyperpara as we've made our way through this course up to this point„ÄÇüòä„ÄÇ![](img/7030d8ee32d0baa28197ef0d0c7cdbba_1.png)

There's the number of layers in a neural networkÔºå adjusting these hyperparameters can definitely have an impact on the performance of your neural network„ÄÇThere's also how many neurons you have in each layer„ÄÇ there's what activation functions you're using on each layer„ÄÇNow we've added dropout percent per layer and the L1 and L2 regularization values per layer„ÄÇ

And you know what we're not done yet„ÄÇ We're going to add even more on as we make our way through the rest of the course„ÄÇ These are a lot of hyperparametersÔºå and it can be difficult to determine exactly how you should set these„ÄÇIn this videoÔºå I'm not going to show you any techniques for particularly optimizing any of these hyperparameter„ÄÇ but I am going to show you a way that you can evaluate what effect your changes are actually having„ÄÇ

As you saw in previous parts of this module leading up to this point„ÄÇ if you rerun the neural network a couple of timesÔºå even with a fivefold cross validation„ÄÇ you're going to get various results from your final accuracy RMSE„ÄÇ depending on if your classification or regression„ÄÇ

 this can make it very difficult since your accuracy or your predictive power of the neural network somewhat bounces around naturally before you even change anything„ÄÇ it can be very difficult to know if the change that you just made to one of these hyperparameters has actually had an effect or if you're just seeing normal variation in the neural network as a result of the random weights that that neural network starts with in this section„ÄÇ

 we're going to look at something called bootstping Now„ÄÇ bootstping is similar to cross validationation in that it is a technique that you can use to get training„ÄÇ„ÅØ„ÅÑ„ÄÇAnd validation sets to work with your neural network on„ÄÇ But it's different because it's not a set number of folds„ÄÇ

 You simply keep re grabbing a training and validation set from your initial data set over and over and over again„ÄÇ and you do this with replacement„ÄÇ NowÔºå when you say with replacement„ÄÇ that means that the first time you pull these elements out of the data set„ÄÇ you put them all right back in and the next time you pull from the same group„ÄÇ

So you could end up with exactly the same training and validation set on multiple polls from„ÄÇFrom your datasetÔºå But that's fine„ÄÇ we are going to average all of the accuracy or rooting square errors together to get an average performance for the neural network and will simply keep pulling more and more and more runs from the data set as we keep going and we'll look at how many runs„ÄÇ

 how many splits of your data it takes before your average error starts to really converge to a consistent value„ÄÇ We're also going to use early stopping so we will stop training the neural network when the validation set no longer improves„ÄÇ This will also allow us to report on an average number of epochs that is needed for this particular data and neural network so that you can start to get an idea of how many epochs you should really train with Now„ÄÇ since we are using this for benchmarking„ÄÇWe are going to want to report the time that certain things took because we might want to run this on Google CoLab or some other cloud based resource that will let us have more compute power„ÄÇ

I'm just going to define that function„ÄÇ It's easy enough„ÄÇ Let's look at how we'll bootstrap for regression„ÄÇ So I'm going to show you a regression and a classification example of bootstrapping first„ÄÇ and then we'll look at the actual benchmarking program for thisÔºå since its regression„ÄÇ we are attempting to predict the age„ÄÇThis is the simple dataset set that we've used a number of times throughout this course„ÄÇ

 I'll go ahead and run that„ÄÇ It'll simply load itÔºå and it's done loading„ÄÇ Now I'm going to bootstrap it„ÄÇ So let me just go ahead and tick this off because it takes it a little while to run„ÄÇ and start to explain it HereÔºå we're defining the number of splits„ÄÇ This is how many runs through this„ÄÇ We're going to go„ÄÇ So I chose 50„ÄÇ

50 would be a bit big for a cross validation because you would end up with a validation set„ÄÇ There's one 50th of the data set and on smaller data that that would potentially be problem„ÄÇ But here we're doingÔºå So we're doing a shuffle split„ÄÇJust like with cross validation„ÄÇ we will use a stratified split when we get to classification because we don't want to accidentally change the class balances because that would introduce bias that would give us potentially an incorrectly trained model„ÄÇ

 at least it would be slightly off because it would have been trained on the wrong balances„ÄÇ portions of the classes that is to be classified„ÄÇThe 0„ÄÇ1 tells me that I am taking 10% of the data set for a validation set„ÄÇ and we're using 42 so that we have consistently random results from sampling them„ÄÇ

 It's not as important to do a random state for bootstrapping because each time you run through it„ÄÇ I don't know that you necessarily care that split one is going to be the same as split one again when you run it„ÄÇ but in cross validationÔºå it can be nice to have those consistent folds„ÄÇ We're going to split it„ÄÇ Run through with each of these train and tests„ÄÇAnd we're going to construct the neural network„ÄÇ

 So these are your hyperparameters that you'd want to be experimenting with„ÄÇ You will want to change these to different values and run it and try to get an idea of how effective this particular set of hyperparameters are„ÄÇ We'll look at this later in this video„ÄÇ we'll see how we actually construct a benchmark„ÄÇ we are going to use early stopping„ÄÇ So since we're using early stopping and our validation data are also from the early stop„ÄÇ

 we can't use that validation set as a true indicator of the actual effectiveness of the neural network because we're using that same validation set both to stop the neural network and evaluate„ÄÇ but it doesn't matter„ÄÇ we're more looking just for relative values of those from run to run„ÄÇ

 not the true predictive power of this neural network„ÄÇ We're simply trying to optimize hyperparametersÔºå really at this„ÄÇSo we will fit it on how remaining many steps is neededÔºå then we will do our prediction„ÄÇAnd we'll track the average error and also the average number of epochs needed„ÄÇApoox epochÔºå however„ÄÇ

You want to pronounce that word„ÄÇ and we also track the standard deviation of the error because the standard deviation gives us an idea of how much variance the particular set of hyperparameters is giving us„ÄÇ howÔºå how much the neural network accuracy or R messy varies from one particular run to another„ÄÇ

 Now you can see hereÔºå we've done quite a few splits„ÄÇ So at the beginning„ÄÇWe got a score of 0„ÄÇ688„ÄÇ And obviouslyÔºå that's still the mean score because there's only one of them„ÄÇ No standard deviation on the first one because it didn't deviate from anything„ÄÇ And we continue to get our scores„ÄÇ You'll notice there is quite a bit of jumping around Sc equals 0„ÄÇ

88 score equals 0„ÄÇ56 and so on and so forth„ÄÇ We continue this process„ÄÇ And by the time we get to 36„ÄÇ which is how far it made it„ÄÇ We can see the standard deviation is is decent for for this one„ÄÇ So it's jumping around by about plus or minus 0„ÄÇ18„ÄÇ And we can see that the mean score„ÄÇ it has somewhat converge„ÄÇ It's right around 74„ÄÇ I meanÔºå it it's still jumping around in in the 10s„ÄÇ

 but you can see really how how many of these you want to average together before these start to get pretty„ÄÇ pretty convergent„ÄÇ The epoch„ÄÇ It looks like somewhere around now 113 to 130„ÄÇ2„ÄÇ these are jumping around quite a bit„ÄÇ but the mean epochs really has converged1Ôºå1Ôºå8Ôºå11Ôºå7„ÄÇ So mean epochÔºå it looks like 117 to 118„ÄÇ That's the number of epochs to really be training this thing on„ÄÇ

 And then the meanÔºå the mean score„ÄÇ It said thereÔºå it'sÔºå it's not converged a whole lot„ÄÇ it's„ÄÇ it's in around 0„ÄÇ75 to 0„ÄÇ74„ÄÇ So we're in the pretty high7„ÄÇ4sÔºå low 7„ÄÇ5„ÄÇ So it's„ÄÇ it's somewhere around 0„ÄÇ75„ÄÇ But you can see if you look just at the the mean scores here„ÄÇ There's a lot of variance in the mean as it'sÔºå as it's going through„ÄÇ That was regression„ÄÇ Now„ÄÇ

 if you want to do classification„ÄÇ it's pretty similarÔºå really except„ÄÇWell you'll load in the data set we'll be predicting on product because it's the classification form„ÄÇHereÔºå thoughÔºå we'll use a stratified shuffle split„ÄÇ That is going to make sure that those classes stay balanced for classification„ÄÇ We're using 10%„ÄÇ

 just like before and also a random state of 42„ÄÇ Then we're going to split it„ÄÇ But notice we have to pass in in addition to X the products so that we know what the classes are so we can„ÄÇEvenly split thatÔºå then we we do the same splitting just like before„ÄÇ the rest of this is really prettyÔºå pretty much the same thing„ÄÇ

We have categorical cross entropy and we set the final output neuron count to the number of classes„ÄÇ so it's the typical classification sort of thing„ÄÇAnd we print out the same results that we had before„ÄÇ So we're tracking the mean epochs and the mean score so that we can get an idea of how long we should train this and also„ÄÇLet us know relative to another setting of hyperparameters„ÄÇ

 how effective the current set of hyperparameters are„ÄÇ NowÔºå to use this the benchmark„ÄÇ we'll do a regression problem„ÄÇ So here I'm setting up the data set to„ÄÇ So for benchmarking„ÄÇ we're going to do a classification problem So I am setting this up basically so that it creates the dummies on the product column„ÄÇ We'll evaluate it with log loss„ÄÇ I'll go ahead run that so that we have it„ÄÇ

 I am going to start the benchmarking and explain it as go„ÄÇ So you'll notice this is pretty similar„ÄÇ we're doing the stratified shuffle split just like before„ÄÇ number of splits„ÄÇ This time is 100 because that gives me„ÄÇüòäÔºåGives me a more converged score to actually evaluate this with using a test set size of 10%„ÄÇ So we loop through just like before„ÄÇ The big difference hereÔºå though„ÄÇ

 is I did spend some time trying to tune these„ÄÇYou'll notice I'm using a different activation function„ÄÇ We'll see more about this Prelu„ÄÇ It's like a leaky relu„ÄÇ except the amount of leakiness is a parameter that is optimized by the neural network as well„ÄÇ We'll see some more modern activation functions when we get into the kagle module and talk about how to really automatically tune these hyperparameter„ÄÇ

 So I'm using that type of activation function„ÄÇ I do have 50% dropout on the first two hidden layers„ÄÇ but not the third„ÄÇ And that is mostly what I had tried„ÄÇ I had tried a couple of different ones„ÄÇ And this was truly giving me the lowest or the best best results for log loss„ÄÇ because usually want a low log loss„ÄÇ These are some of the other attempts that I got and the various mean scores that I got„ÄÇ

 So I was getting this right around it about 0„ÄÇ65Ôºå which is somewhat what the the mean score is converging to„ÄÇStandard deviation is a little bit lower„ÄÇ I attribute that to using dropout and you can let this run„ÄÇ It takes it a little while„ÄÇSo this can be a very lengthy procedure I will often have my regular computer going and my Google Coab account both working on different sides of a particular problem so this will go on„ÄÇ you'll see this score converge to somewhere about 0„ÄÇ65„ÄÇ

 Thank you for watching this video up to this point in this course we've dealt primarily with tabular data and neural networks work fine with this„ÄÇ HoweverÔºå now we're going to start to get into the things that make neural networks really a model type that has gained a lot of attention„ÄÇ



![](img/7030d8ee32d0baa28197ef0d0c7cdbba_3.png)

SpecificallyÔºå we're going to start with imagesÔºå but we'll also get into time series„ÄÇHow to actually have images be the output of neural network and other things as wellÔºü

This content changes oftenÔºå so subscribe to the channel to stay up to date on this course and other topics in artificial intelligence„ÄÇ This content changes often„ÄÇ so subscribe to the channel to stay up to date on this course and other topics in artificial intelligence„ÄÇ

