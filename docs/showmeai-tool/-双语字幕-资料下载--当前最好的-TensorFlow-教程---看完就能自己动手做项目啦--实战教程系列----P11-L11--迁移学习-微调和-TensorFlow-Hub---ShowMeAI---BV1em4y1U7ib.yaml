- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P11ï¼šL11- è¿ç§»å­¦ä¹ ã€å¾®è°ƒå’Œ
    TensorFlow Hub - ShowMeAI - BV1em4y1U7ib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P11ï¼šL11- è¿ç§»å­¦ä¹ ã€å¾®è°ƒå’Œ
    TensorFlow Hub - ShowMeAI - BV1em4y1U7ib
- en: In this video I will show you how to use pretrain modelsã€‚ including how to freeze
    layers and do fine tuningã€‚ so let's get to it right after this beautiful introã€‚![](img/e49a5edbd4e401e53208da1309187c97_1.png)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…æ‹¬å¦‚ä½•å†»ç»“å±‚å’Œè¿›è¡Œå¾®è°ƒã€‚æ‰€ä»¥åœ¨è¿™æ®µç²¾å½©çš„ä»‹ç»ä¹‹åï¼Œæˆ‘ä»¬å¼€å§‹å§ï¼![](img/e49a5edbd4e401e53208da1309187c97_1.png)
- en: '![](img/e49a5edbd4e401e53208da1309187c97_2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_2.png)'
- en: Alrightï¼Œ so the code in front of us right now should hopefully feel very familiarã€‚
    We've been using these for pretty much all of the videos except this command right
    hereã€‚ Tensorflowlow hubã€‚ So I'm going go into what that is a little bit later
    in the tutorial but first of allã€‚ if you if you don't have it just Google Conda
    Tensorflowlow hubub and you'll get to this page it's also gonna to be in the description
    and you can download it with this command if you're using Conda if you're using
    Pip you're just going to do Pip install Tensorflowlow hub that's itã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬é¢å‰çš„ä»£ç åº”è¯¥ä¼šè®©ä½ æ„Ÿåˆ°å¾ˆç†Ÿæ‚‰ã€‚æˆ‘ä»¬å‡ ä¹åœ¨æ‰€æœ‰è§†é¢‘ä¸­éƒ½ä½¿ç”¨è¿‡è¿™äº›ä»£ç ï¼Œé™¤äº†è¿™ä¸€è¡Œå‘½ä»¤ï¼šTensorflow Hubã€‚ç¨åæˆ‘ä¼šè¯¦ç»†è§£é‡Šè¿™ä¸ªå‘½ä»¤ï¼Œä½†é¦–å…ˆï¼Œå¦‚æœä½ æ²¡æœ‰å®‰è£…ï¼Œå¯ä»¥è°·æ­Œæœç´¢
    Conda Tensorflow Hubï¼Œä½ ä¼šæ‰¾åˆ°è¿™ä¸ªé¡µé¢ï¼Œé“¾æ¥ä¹Ÿä¼šåœ¨æè¿°ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ä¸‹è½½å®ƒã€‚å¦‚æœä½ ä½¿ç”¨ Condaï¼Œå°±è¿è¡Œè¿™ä¸ªå‘½ä»¤ï¼›å¦‚æœä½ ä½¿ç”¨
    Pipï¼Œåˆ™åªéœ€è¿è¡Œ `Pip install Tensorflow Hub`ï¼Œå°±è¿™æ ·ã€‚
- en: '![](img/e49a5edbd4e401e53208da1309187c97_4.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_4.png)'
- en: '![](img/e49a5edbd4e401e53208da1309187c97_5.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_5.png)'
- en: '![](img/e49a5edbd4e401e53208da1309187c97_6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_6.png)'
- en: And so so what I want to do in this video is essentially three thingsã€‚ I'm going
    to first show you if you have a pretrain model that you've previously trainedã€‚
    so check out my previous video on saving and loading models if you're unfamiliar
    with thatã€‚And thenã€‚I'm going to show you how to use a Pret Kas modelï¼Œ so KRS has
    a bunch of pretrain models that you can just easily importã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä¸»è¦æƒ³åšä¸‰ä»¶äº‹ã€‚é¦–å…ˆï¼Œå¦‚æœä½ æœ‰ä¹‹å‰è®­ç»ƒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä¼šå‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®ƒã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰ä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„å†…å®¹ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘ä¹‹å‰çš„è§†é¢‘ã€‚æ¥ç€ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨
    Keras æ¨¡å‹ï¼ŒKeras æœ‰è®¸å¤šå¯ä»¥è½»æ¾å¯¼å…¥çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚
- en: And then lastlyï¼Œ I'm going to show youã€‚How to load pretrain models from Tensorflowlow
    hubã€‚ So Tensorflowlow hub has a bunch of pretrain modelsã€‚ And I'm going toï¼Œ as
    I saidã€‚ I'm going to go into that a little bit laterã€‚ So first of allã€‚ for this
    pretrain for our own pretrain modelï¼Œ I'm just going copy in sort of the data dataset
    loadingã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä» Tensorflow Hub åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ã€‚Tensorflow Hub æœ‰å¾ˆå¤šé¢„è®­ç»ƒæ¨¡å‹ã€‚æ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œæˆ‘ç¨åä¼šè¯¦ç»†ä»‹ç»è¿™ä¸€ç‚¹ã€‚é¦–å…ˆï¼Œå¯¹äºæˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘å°†å¤åˆ¶æ•°æ®é›†åŠ è½½çš„ç›¸å…³å†…å®¹ã€‚
- en: So the Ms data set right hereã€‚And so we've done this multiple videosã€‚ And then
    I'm just gonna load a pretrain modelã€‚ So model is care thatmod do load modelã€‚
    and this could beï¼Œ I meanï¼Œ if you've trained itï¼Œ So it's in the pretrained folderã€‚
    So So this could be sort of a model that you've trained or I guess it could be
    a model that you've found on Github or something like thatã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ Ms æ•°æ®é›†ã€‚æˆ‘ä»¬å·²ç»åˆ¶ä½œäº†å¤šä¸ªè§†é¢‘ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹ã€‚å› æ­¤æ¨¡å‹ä¼šåŠ è½½ã€‚è¿™ä¸ªæ¨¡å‹å¯èƒ½æ˜¯ä½ è®­ç»ƒçš„ï¼Œæˆ–è€…æ˜¯ä½ åœ¨ GitHub ä¸Šæ‰¾åˆ°çš„æŸä¸ªæ¨¡å‹ã€‚
- en: So you would just load that model and then you could do print model dot summaryã€‚And
    thenã€‚ and then what you would do is you would check which of the parts you wantï¼Œ
    rightï¼Œ if youã€‚ if this isï¼Œ if you want entire modelï¼Œ then that's just loading
    the model you can continue trainingã€‚ But normally when we're doing transfer learningï¼Œ
    we're gonna pick out a couple of layersã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åªéœ€åŠ è½½è¯¥æ¨¡å‹ï¼Œç„¶åå¯ä»¥ä½¿ç”¨ `print(model.summary)`ã€‚æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦æŸ¥çœ‹ä½ æƒ³è¦çš„éƒ¨åˆ†ã€‚å¦‚æœä½ æƒ³è¦æ•´ä¸ªæ¨¡å‹ï¼Œé‚£ä¹ˆå°±åŠ è½½è¯¥æ¨¡å‹ï¼Œç»§ç»­è®­ç»ƒã€‚ä½†æ˜¯é€šå¸¸åœ¨è¿›è¡Œè¿ç§»å­¦ä¹ æ—¶ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©å‡ ä¸ªå±‚è¿›è¡Œè®­ç»ƒã€‚
- en: So let's say we wantã€‚So let's say we want everything except the last one right
    let's say we have we have let's say that this number of classes would be 1000
    for imagenet or something like thatã€‚ But for Ms we would have 10 classes so then
    we would have to replace this last dense layer with our own but we could use sort
    of the previous layers from that particular model So how we would do that is we
    would do sort of base inputs we would do model dot layers we would take the layer
    that we want for it to start in and that's the first one so we're going to do
    model layers 0 and then dot input then we're gonna to do base outputs and why
    I'm calling it base is because we're going use this pre chain model as our base
    model and then we're gonna sort of make a layer on top of that one So what we
    do here is that we sort of check which either by just checking sort zero1 toã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æƒ³è¦ã€‚å‡è®¾æˆ‘ä»¬æƒ³è¦é™¤äº†æœ€åä¸€ä¸ªä»¥å¤–çš„æ‰€æœ‰å†…å®¹ï¼Œå¯¹å§ï¼Ÿå‡è®¾æˆ‘ä»¬æœ‰ï¼Œå‡è®¾è¿™ä¸ªç±»åˆ«æ•°æ˜¯ 1000ï¼Œå¯¹äº imagenet æˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚ä½†å¯¹äº Msï¼Œæˆ‘ä»¬å°†æœ‰
    10 ä¸ªç±»åˆ«ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»ç”¨è‡ªå·±çš„æœ€åä¸€å±‚æ›¿æ¢è¿™ä¸€å±‚ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‚£ä¸ªç‰¹å®šæ¨¡å‹çš„å‰é¢å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹æ˜¯ï¼Œæˆ‘ä»¬ä¼šè¿™æ ·åšï¼Œsort of åŸºç¡€è¾“å…¥ï¼Œæˆ‘ä»¬ä¼šåš
    model çš„å±‚ï¼Œæˆ‘ä»¬å°†å–æˆ‘ä»¬æƒ³è¦å¼€å§‹çš„å±‚ï¼Œé‚£æ˜¯ç¬¬ä¸€å±‚ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦åš model layers 0 ç„¶åç‚¹è¾“å…¥ã€‚ç„¶åæˆ‘ä»¬è¦åšåŸºç¡€è¾“å‡ºï¼Œæˆ‘ç§°ä¹‹ä¸ºåŸºç¡€æ˜¯å› ä¸ºæˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªé¢„é“¾æ¨¡å‹ä½œä¸ºæˆ‘ä»¬çš„åŸºç¡€æ¨¡å‹ï¼Œç„¶åæˆ‘ä»¬å°†
    sort of åœ¨é‚£ä¹‹ä¸Šæ„å»ºä¸€ä¸ªå±‚ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œåšçš„æ˜¯ï¼Œsort of æ£€æŸ¥å“ªä¸ªï¼Œé€šè¿‡æ£€æŸ¥ sort zero1 åˆ°ã€‚
- en: 3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ã€‚ So you want the output from theã€‚Seventh oneã€‚ or you could count on
    from backwards so you could doï¼Œ this is minus1 and then minus2ã€‚So what we're going
    to do here is we're going to do model that layers and then minus2ã€‚And then dot
    outputã€‚ So we want to output from this flatten layer hereã€‚ In other wordsï¼Œ we'reã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ã€‚æ‰€ä»¥ä½ æƒ³è¦ä»ç¬¬ä¸ƒä¸ªè¾“å‡ºã€‚æˆ–è€…ä½ å¯ä»¥ä»åå¾€å‰æ•°ï¼Œæ‰€ä»¥ä½ å¯ä»¥è¿™æ ·åšï¼Œè¿™æ˜¯ minus1ï¼Œç„¶å minus2ã€‚æ‰€ä»¥æˆ‘ä»¬è¦åšçš„æ˜¯ model
    çš„å±‚ï¼Œç„¶å minus2ã€‚ç„¶åç‚¹è¾“å‡ºã€‚æ‰€ä»¥æˆ‘ä»¬æƒ³è¦ä»è¿™ä¸ªå±•å¹³å±‚è¾“å‡ºã€‚åœ¨å…¶ä»–è¯ä¸­ï¼Œæˆ‘ä»¬ã€‚
- en: we're removing this layerã€‚The dense last layerã€‚ So there are other ways to do
    this as wellã€‚ You could also do it with get layer and then sort of take the nameã€‚
    Butã€‚ we're just gonna stick with the indexã€‚ That's fineã€‚ And then we're gonna
    doã€‚Output we're going to build our ownã€‚ so this could be a modelã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ç§»é™¤è¿™ä¸ªå±‚ã€‚æœ€åçš„å¯†é›†å±‚ã€‚æ‰€ä»¥ä¹Ÿæœ‰å…¶ä»–æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ get layerï¼Œç„¶å sort of å–åå­—ã€‚ä½†æˆ‘ä»¬åªä¼šåšæŒä½¿ç”¨ç´¢å¼•ã€‚è¿™æ ·å°±å¯ä»¥äº†ã€‚ç„¶åæˆ‘ä»¬è¦åšã€‚è¾“å‡ºï¼Œæˆ‘ä»¬å°†æ„å»ºè‡ªå·±çš„ã€‚æ‰€ä»¥è¿™å¯ä»¥æ˜¯ä¸€ä¸ªæ¨¡å‹ã€‚
- en: a sequential model or something like thatã€‚ We're just going to add a single
    layerã€‚ So all we're going to do is layers then 10 10 output nodes and then of
    base outputs right so we're gonna first run it through here and then the output
    of base outputs is going be sent into this this final outputã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé¡ºåºæ¨¡å‹æˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚æˆ‘ä»¬åªä¼šæ·»åŠ ä¸€ä¸ªå•ç‹¬çš„å±‚ã€‚æ‰€ä»¥æˆ‘ä»¬è¦åšçš„å°±æ˜¯å±‚ï¼Œç„¶å10ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œç„¶åæ˜¯åŸºç¡€è¾“å‡ºï¼Œå¯¹å§ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆé€šè¿‡è¿™é‡Œè¿è¡Œï¼Œç„¶ååŸºç¡€è¾“å‡ºçš„è¾“å‡ºå°†è¢«å‘é€åˆ°è¿™ä¸ªæœ€ç»ˆè¾“å‡ºã€‚
- en: And then so I guess we could call it that final outputsã€‚And then we're gonna
    do model equals ks thatã€‚ noï¼Œ waitï¼Œ we're gonna doï¼Œ yeahï¼Œ Ks that model base inputã€‚Inputs
    is equal to base inputã€‚ outputs is equal to final outputã€‚Outputsï¼Œ I guessï¼Œ'cause
    it'sï¼Œ I have multipleã€‚So thenã€‚We could do printã€‚model that summaryã€‚And perhaps
    this should also be called something else then model so we couldã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘æƒ³æˆ‘ä»¬å¯ä»¥ç§°ä¹‹ä¸ºæœ€ç»ˆè¾“å‡ºã€‚ç„¶åæˆ‘ä»¬å°†åš model ç­‰äº ks é‚£ä¸ªã€‚ä¸ï¼Œç­‰ç­‰ï¼Œæˆ‘ä»¬è¦åšï¼Œæ˜¯çš„ï¼ŒKs é‚£ä¸ªæ¨¡å‹åŸºç¡€è¾“å…¥ã€‚è¾“å…¥ç­‰äºåŸºç¡€è¾“å…¥ã€‚è¾“å‡ºç­‰äºæœ€ç»ˆè¾“å‡ºã€‚è¾“å‡ºï¼Œæˆ‘æƒ³ï¼Œå› ä¸ºæœ‰å¤šä¸ªã€‚æ‰€ä»¥æ¥ä¸‹æ¥ã€‚æˆ‘ä»¬å¯ä»¥æ‰“å°æ¨¡å‹çš„æ€»ç»“ã€‚ä¹Ÿè®¸è¿™ä¹Ÿåº”è¯¥å«åˆ«çš„ä»€ä¹ˆï¼Œè€Œä¸æ˜¯æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ã€‚
- en: you know we could call this new model since we've changed the the other one
    interesting interestinglyã€‚ we didn't actually change anythingã€‚ We just replaced
    it since the previous model that we had pretrained it had this exact layerã€‚ but
    you sort of get the point that you could replace this with whatever you want with
    different number of classes and so onã€‚So this is just a sort of a simple example
    to illustrate how you would actually do itã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çŸ¥é“ï¼Œæˆ‘ä»¬å¯ä»¥ç§°è¿™ä¸ªæ–°æ¨¡å‹ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ”¹å˜äº†å¦ä¸€ä¸ªæœ‰è¶£çš„æ˜¯ã€‚æˆ‘ä»¬å®é™…ä¸Šæ²¡æœ‰æ”¹å˜ä»»ä½•ä¸œè¥¿ã€‚æˆ‘ä»¬åªæ˜¯æ›¿æ¢äº†ï¼Œå› ä¸ºæˆ‘ä»¬ä¹‹å‰é¢„è®­ç»ƒçš„æ¨¡å‹æœ‰è¿™ä¸€å±‚ã€‚ä½†ä½ å¤§è‡´æ˜ç™½è¿™ä¸ªç‚¹ï¼Œä½ å¯ä»¥ç”¨ä¸åŒçš„ç±»åˆ«æ•°ç­‰æ›¿æ¢å®ƒã€‚æ‰€ä»¥è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œè¯´æ˜ä½ å®é™…ä¸Šæ˜¯å¦‚ä½•åšåˆ°çš„ã€‚
- en: And so if we now print the new model that summary we'll yeah so as I saidã€‚ we'll
    get the exact say modelï¼Œ but this one here is is now a different one so if we
    for exampleã€‚ would change this to 15 then the sort of the final layer would now
    have 15 output nodes right here but of course we want 10 in this caseã€‚And then
    you would do as normal so you would I'm gonna copy in the compile and the fitã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘ä»¬ç°åœ¨æ‰“å°æ–°æ¨¡å‹çš„æ‘˜è¦ï¼Œæ˜¯çš„ï¼Œæ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°å®Œå…¨ç›¸åŒçš„æ¨¡å‹ï¼Œä½†è¿™é‡Œçš„æ¨¡å‹ç°åœ¨æ˜¯ä¸åŒçš„ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬ä¾‹å¦‚å°†å…¶æ›´æ”¹ä¸º15ï¼Œé‚£ä¹ˆæœ€åçš„å±‚å°†ä¼šæœ‰15ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬æƒ³è¦10ä¸ªã€‚ç„¶åä½ ä¼šåƒå¹³å¸¸ä¸€æ ·è¿›è¡Œæ“ä½œï¼Œæˆ‘å°†å¤åˆ¶ç¼–è¯‘å’Œæ‹Ÿåˆçš„éƒ¨åˆ†ã€‚
- en: I don't think it's very relevantã€‚ we've seen that in previous videosã€‚ so you
    would just do in this caseï¼Œ new model thatt compile and the new model thatt fit
    so we could now run thisã€‚Alrightï¼Œ so after just a single epochï¼Œ we can see that
    it has over 97% accuracy and this is only so this sort of suggests that the pre
    tradinging had some effect now alsoã€‚ so we can see here that yeahï¼Œ after three
    epochsï¼Œ it has almost 99%ã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºè¿™å¹¶ä¸æ˜¯éå¸¸ç›¸å…³ã€‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„è§†é¢‘ä¸­å·²ç»çœ‹è¿‡äº†ã€‚æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ åªéœ€åˆ›å»ºä¸€ä¸ªæ–°æ¨¡å‹å¹¶ç¼–è¯‘ï¼Œç„¶åæ‹Ÿåˆæ–°æ¨¡å‹ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥è¿è¡Œè¿™ä¸ªã€‚å¥½å§ï¼Œåœ¨ä»…ä»…ä¸€ä¸ªå‘¨æœŸåï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒçš„å‡†ç¡®ç‡è¶…è¿‡äº†97%ï¼Œè¿™æš—ç¤ºäº†é¢„è®­ç»ƒç¡®å®æœ‰ä¸€äº›æ•ˆæœã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç»è¿‡ä¸‰ä¸ªå‘¨æœŸåï¼Œå®ƒçš„å‡†ç¡®ç‡å‡ ä¹è¾¾åˆ°äº†99%ã€‚
- en: And what you could also do is let's say that this pretrain modelã€‚ you don't
    want to actually train the entire thingï¼Œ whichï¼Œ you knowã€‚ would be the case if
    you want to do fine tuningã€‚ So what we would have to do is we would have to freeze
    the layer from this pretrain model and how you could do that very simply is do
    model that trainableã€‚Trainable equals falseã€‚ So that's gonna freeze all of the
    layers andã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜å¯ä»¥åšçš„æ˜¯ï¼Œå‡è®¾è¿™ä¸ªé¢„è®­ç»ƒæ¨¡å‹ä½ ä¸æƒ³å®é™…è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œè¿™å°±æ˜¯ä½ æƒ³è¿›è¡Œå¾®è°ƒçš„æƒ…å†µã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å†»ç»“è¿™ä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„å±‚ï¼Œè€Œä½ å¯ä»¥å¾ˆç®€å•åœ°åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°±æ˜¯æ‰§è¡Œ`model.trainable
    = False`ã€‚è¿™æ ·ä¼šå†»ç»“æ‰€æœ‰çš„å±‚ã€‚
- en: One other thing you could also do is you could iterate through the layers of
    the modelã€‚ so for layer in model dot layersã€‚And then you could doï¼Œ yeahï¼Œ in this
    caseã€‚ we've already set every layer to not be trainable so we could do something
    like assert La trainable is falseã€‚ but what you could also do is if we hadn't
    done this one liner right hereï¼Œ for exampleã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¿˜å¯ä»¥åšçš„å¦ä¸€ä»¶äº‹æ˜¯è¿­ä»£æ¨¡å‹çš„å±‚ã€‚å› æ­¤ï¼Œ`for layer in model.layers:`ã€‚ç„¶åä½ å¯ä»¥ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å·²ç»å°†æ¯ä¸€å±‚éƒ½è®¾ç½®ä¸ºä¸å¯è®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åšä¸€äº›åƒ`assert
    layer.trainable == False`çš„æ“ä½œã€‚ä½†å¦‚æœæˆ‘ä»¬æ²¡æœ‰åœ¨è¿™é‡Œæ‰§è¡Œè¿™ä¸€è¡Œä»£ç ï¼Œä¾‹å¦‚ã€‚
- en: if you wanted to just change specific layersï¼Œ you could also iterate through
    specific layers like doing one to5 or something like that and then you could do
    layers do trainable is falseã€‚Yeahï¼Œ so just two different ways of doing the same
    thing hereã€‚ Yeahã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åªæƒ³æ›´æ”¹ç‰¹å®šçš„å±‚ï¼Œä½ ä¹Ÿå¯ä»¥è¿­ä»£ç‰¹å®šçš„å±‚ï¼Œæ¯”å¦‚ä»1åˆ°5ï¼Œç„¶åä½ å¯ä»¥å°†å±‚è®¾ç½®ä¸ºä¸å¯è®­ç»ƒã€‚æ˜¯çš„ï¼Œè¿™é‡Œæœ‰ä¸¤ç§ä¸åŒçš„æ–¹æ³•æ¥åšåŒæ ·çš„äº‹æƒ…ã€‚æ˜¯çš„ã€‚
- en: so I noticed one error and when editing the videoï¼Œ I wrote layers that trainable
    is false andã€‚Yeahã€‚ I'm not sure really sure what that that does exactlyã€‚ but we
    want to do a layer dot trainable is false so that was just a typo right there
    some for some reason it still ran and I'm not sure what difference it made but
    this is what we you know what we want to do and and that is already done in this
    one liner so it doesn't really matterã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘æ³¨æ„åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œåœ¨ç¼–è¾‘è§†é¢‘æ—¶ï¼Œæˆ‘å†™çš„æ˜¯å¯è®­ç»ƒå±‚ä¸ºfalseã€‚å—¯ï¼Œæˆ‘ä¸å¤ªç¡®å®šè¿™åˆ°åº•æ˜¯ä»€ä¹ˆæ„æ€ï¼Œä½†æˆ‘ä»¬æƒ³è¦çš„åº”è¯¥æ˜¯å°†æŸå±‚çš„å¯è®­ç»ƒæ€§è®¾ç½®ä¸ºfalseï¼Œæ‰€ä»¥è¿™åªæ˜¯ä¸€ä¸ªæ‰“å­—é”™è¯¯ï¼Œå‡ºäºæŸç§åŸå› å®ƒä»ç„¶è¿è¡Œäº†ï¼Œæˆ‘ä¸ç¡®å®šè¿™æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Œä½†è¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦åšçš„ï¼Œè€Œè¿™å·²ç»åœ¨è¿™ä¸€è¡Œä»£ç ä¸­å®Œæˆï¼Œæ‰€ä»¥å…¶å®æ²¡å…³ç³»ã€‚
- en: but if you would iterate your layers this is how you would do itã€‚The the benefit
    of doing this is if we would now run thisã€‚ rerun it and now I don't know if you
    if you saw itã€‚ but it took about 15 seconds or 16 seconds or something like that
    to run one epoch and so if we now run it without we'll see that it's almost half
    the actual time so the benefit of doing this fine tuning and freezing layers is
    that it's going to run much faster and sort of this is the I guess the common
    use case of pretrain models is that you would take this gigantic model freeze
    the layers up to some certain point and then just add a couple of linear layers
    at the end for your specific for your specific use case andã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¦‚æœä½ æƒ³è¦è¿­ä»£ä½ çš„å±‚ï¼Œè¿™å°±æ˜¯ä½ åº”è¯¥æ€ä¹ˆåšã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ç°åœ¨è¿è¡Œå®ƒï¼Œé‡æ–°è¿è¡Œï¼Œæˆ‘ä¸çŸ¥é“ä½ æ˜¯å¦çœ‹åˆ°è¿‡ï¼Œä½†è¿è¡Œä¸€ä¸ªå‘¨æœŸå¤§çº¦èŠ±è´¹äº†15ç§’æˆ–16ç§’ï¼Œå› æ­¤å¦‚æœæˆ‘ä»¬ç°åœ¨è¿è¡Œå®ƒè€Œä¸è¿™æ ·åšï¼Œæˆ‘ä»¬ä¼šå‘ç°å®é™…æ—¶é—´å‡ ä¹å‡åŠã€‚æ‰€ä»¥ï¼Œè¿›è¡Œå¾®è°ƒå’Œå†»ç»“å±‚çš„å¥½å¤„åœ¨äºï¼Œå®ƒçš„è¿è¡Œé€Ÿåº¦ä¼šå¿«å¾—å¤šï¼Œæˆ‘æƒ³è¿™å°±æ˜¯é¢„è®­ç»ƒæ¨¡å‹çš„å¸¸è§ä½¿ç”¨æ¡ˆä¾‹ï¼Œä½ ä¼šæ‹¿è¿™ä¸ªå·¨å‹æ¨¡å‹ï¼Œå°†æŸäº›å±‚å†»ç»“åˆ°ç‰¹å®šç‚¹ï¼Œç„¶ååªåœ¨æœ€åæ·»åŠ å‡ ä¸ªçº¿æ€§å±‚ä»¥é€‚åº”ä½ çš„å…·ä½“ç”¨ä¾‹ã€‚
- en: Yeahï¼Œ so actually we can see here also is that its it actually got better performance
    in this caseã€‚ sort of the sameã€‚ And that's because these these layers that have
    imported had already been trained on Ms previouslyã€‚ So I guess that's one scenario
    when you're just you have your own model or you've loaded your own model I'm gonna
    remove the code for this right now and we're gonna move on to the next oneã€‚ So
    that's if you want to use a pretrained ks modelã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå®é™…ä¸Šæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒçš„æ€§èƒ½ç¡®å®æ›´å¥½ã€‚åŸºæœ¬ä¸Šæ˜¯ç›¸åŒçš„ã€‚è¿™æ˜¯å› ä¸ºè¿™äº›å¯¼å…¥çš„å±‚ä¹‹å‰å·²ç»åœ¨Msä¸Šè®­ç»ƒè¿‡ã€‚æ‰€ä»¥æˆ‘æƒ³è¿™æ˜¯ä¸€ä¸ªåœºæ™¯ï¼Œå½“ä½ æœ‰è‡ªå·±çš„æ¨¡å‹æˆ–åŠ è½½äº†è‡ªå·±çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ç°åœ¨è¦å»æ‰ä»£ç ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä¸‹ä¸€ä¸ªéƒ¨åˆ†ã€‚æ‰€ä»¥å¦‚æœä½ æƒ³ä½¿ç”¨é¢„è®­ç»ƒçš„ksæ¨¡å‹çš„è¯ã€‚
- en: So so the ks library has a lot of models that you can import very easily and
    I'm going show you just just a use case of thatã€‚ and it's gonna to be very similar
    to what we did but using the the CAs API for those modelsã€‚ so let's just create
    some random data just for demonstration to run the model So we're gonna do Tf
    random do normal and then shape we're gonna do let's say three example five examples299ã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œksåº“æœ‰å¾ˆå¤šå¯ä»¥å¾ˆå®¹æ˜“å¯¼å…¥çš„æ¨¡å‹ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºä¸€ä¸ªç”¨ä¾‹ã€‚å®ƒå°†ä¸æˆ‘ä»¬ä¹‹å‰æ‰€åšçš„éå¸¸ç›¸ä¼¼ï¼Œä½†ä½¿ç”¨è¿™äº›æ¨¡å‹çš„CA APIã€‚æ‰€ä»¥è®©æˆ‘ä»¬åˆ›å»ºä¸€äº›éšæœºæ•°æ®ï¼Œä»…ç”¨äºæ¼”ç¤ºä»¥è¿è¡Œæ¨¡å‹ã€‚æ‰€ä»¥æˆ‘ä»¬å°†åšTféšæœºæ­£æ€ï¼Œç„¶åå½¢çŠ¶æˆ‘ä»¬å°†åšï¼Œæ¯”å¦‚è¯´ä¸‰ä¸ªç¤ºä¾‹ï¼Œäº”ä¸ªç¤ºä¾‹299ã€‚
- en: '![](img/e49a5edbd4e401e53208da1309187c97_8.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_8.png)'
- en: '![](img/e49a5edbd4e401e53208da1309187c97_9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_9.png)'
- en: and9 by threeã€‚ And this is just that it's gonna fit the model that we're gonna
    importã€‚ So I'll show you in just a secondã€‚ but those are for the the X label or
    sort of the the featuresã€‚So they are images of 299 and then three channels for
    RGBã€‚ and then we have TF constant and let's say 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ9ä¹˜ä»¥3ã€‚è¿™åªæ˜¯ä¸ºäº†é€‚åº”æˆ‘ä»¬å°†è¦å¯¼å…¥çš„æ¨¡å‹ã€‚æˆ‘é©¬ä¸Šä¼šç»™ä½ å±•ç¤ºï¼Œä½†è¿™äº›æ˜¯Xæ ‡ç­¾æˆ–ç‰¹å¾ã€‚å®ƒä»¬æ˜¯299çš„å›¾åƒï¼Œç„¶åæ˜¯RGBçš„ä¸‰ä¸ªé€šé“ã€‚ç„¶åæˆ‘ä»¬æœ‰TFå¸¸é‡ï¼Œå¯ä»¥è¯´æ˜¯0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ã€‚
- en: so five classes and they are all of a different unique classã€‚And then model
    is Kas that applicationsã€‚ And then here there are a bunch of different models
    you can useã€‚ And so I'm gonna pick inception V3ã€‚ And then there are a bunch of
    arguments that you can send in hereã€‚ and you can read the more of the official
    documentationsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æœ‰äº”ä¸ªç±»åˆ«ï¼Œå®ƒä»¬éƒ½æ˜¯ä¸åŒçš„ç‹¬ç‰¹ç±»åˆ«ã€‚ç„¶åæ¨¡å‹æ˜¯Kasåº”ç”¨ç¨‹åºã€‚åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥ä½¿ç”¨è®¸å¤šä¸åŒçš„æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘å°†é€‰æ‹©inception V3ã€‚ç„¶åæœ‰è®¸å¤šå‚æ•°å¯ä»¥åœ¨è¿™é‡Œä¼ å…¥ï¼Œä½ å¯ä»¥é˜…è¯»æ›´å¤šå®˜æ–¹æ–‡æ¡£ã€‚
- en: But one of the most important ones are thatã€‚You can do this include top equals
    true or falseã€‚ And essentially what you can do here is that for the for the last
    final fully connected layersã€‚ you could remove those and just obtain sort of feature
    vectors that you can then send into your own sequential model or something like
    thatã€‚ So this is probably one of the most important argumentsã€‚ And we could just
    do that first of allã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æœ€é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œä½ å¯ä»¥å°†include topè®¾ç½®ä¸ºtrueæˆ–falseã€‚åŸºæœ¬ä¸Šï¼Œåœ¨æœ€åçš„å…¨è¿æ¥å±‚ä¸­ï¼Œä½ å¯ä»¥å»æ‰è¿™äº›ï¼Œåªè·å–ç‰¹å¾å‘é‡ï¼Œç„¶åå°†å…¶è¾“å…¥åˆ°ä½ è‡ªå·±çš„é¡ºåºæ¨¡å‹ä¸­æˆ–ç±»ä¼¼çš„ä¸œè¥¿ã€‚æ‰€ä»¥è¿™å¯èƒ½æ˜¯æœ€é‡è¦çš„å‚æ•°ä¹‹ä¸€ã€‚æˆ‘ä»¬å¯ä»¥å…ˆè¿™æ ·åšã€‚
- en: And then let's do modeled a summary just toã€‚See what it looks likeã€‚Yeahã€‚ so
    what we can see here is that in this caseï¼Œ actually for the inception V3ã€‚ there's
    only a fully connected at the absolute endã€‚ So I'm not assuming you're familiar
    with the inception moduleã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè®©æˆ‘ä»¬åšæ¨¡å‹æ‘˜è¦ï¼Œçœ‹çœ‹å®ƒæ˜¯ä»€ä¹ˆæ ·çš„ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®é™…ä¸Šå¯¹äºinception V3ï¼Œæœ€ååªæœ‰ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚æ‰€ä»¥æˆ‘å‡è®¾ä½ ç†Ÿæ‚‰inceptionæ¨¡å—ã€‚
- en: but essentially it has these concatetnations of different convolutionaryary
    networks at this layer and then it's doing a global average pooling and then at
    the endã€‚ it's doing a fully connectedã€‚ So if you would do include top falsesã€‚
    it would just remove this fully connected layer at the endã€‚But let's say we just
    want to start with this oneã€‚ So what we're gonna do now is we could do very similar
    to what we did previouslyã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æœ¬è´¨ä¸Šï¼Œå®ƒåœ¨è¿™ä¸€å±‚æœ‰ä¸åŒå·ç§¯ç½‘ç»œçš„è¿æ¥ï¼Œç„¶åè¿›è¡Œå…¨å±€å¹³å‡æ± åŒ–ï¼Œæœ€åè¿›è¡Œå…¨è¿æ¥ã€‚æ‰€ä»¥å¦‚æœä½ è®¾ç½®include topä¸ºfalseï¼Œå®ƒå°†å»æ‰æœ€åçš„å…¨è¿æ¥å±‚ã€‚ä½†å‡è®¾æˆ‘ä»¬åªæ˜¯æƒ³ä»è¿™ä¸ªå¼€å§‹ã€‚é‚£ä¹ˆæˆ‘ä»¬ç°åœ¨è¦åšçš„ä¸ä¹‹å‰éå¸¸ç›¸ä¼¼ã€‚
- en: You could do base input is a model that layers 0 dot inputã€‚ And then you could
    do base output isã€‚These outputs is modeled that layersã€‚ And then let's sayï¼Œ againã€‚
    we just want to remove the last fully connectedï¼Œ but of courseã€‚ if it would be
    several fully connected at the endã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°†åŸºæœ¬è¾“å…¥è®¾ç½®ä¸ºæ¨¡å‹çš„layers 0 .inputã€‚ç„¶ååŸºæœ¬è¾“å‡ºæ˜¯è¿™äº›è¾“å‡ºæ˜¯æ¨¡å‹çš„å±‚ã€‚ç„¶åæˆ‘ä»¬å‡è®¾å†æ¬¡ï¼Œæˆ‘ä»¬åªæƒ³å»æ‰æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œä½†å½“ç„¶ï¼Œå¦‚æœæœ€åæœ‰å¤šä¸ªå…¨è¿æ¥å±‚çš„è¯ã€‚
- en: you could do-3-4 sort of removing the exact amount that you wantã€‚ In this caseã€‚
    we just want to remove the last oneã€‚And then dot outputã€‚ And then we're gonna
    do sort of our last So we're do final outputsã€‚ Againã€‚ we're just doing a single
    layer So let layer stands then five nodescause we have five classesã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ‰§è¡Œ-3-4ï¼Œåˆ é™¤ä½ æƒ³è¦çš„ç¡®åˆ‡æ•°é‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªæƒ³åˆ é™¤æœ€åä¸€ä¸ªã€‚ç„¶åæ˜¯ dot outputã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è¦åšçš„æ˜¯æœ€ç»ˆè¾“å‡ºã€‚å†æ¬¡å¼ºè°ƒï¼Œæˆ‘ä»¬åªè¿›è¡Œä¸€å±‚ï¼Œå› æ­¤è®©æˆ‘ä»¬è®¾ç½®äº”ä¸ªèŠ‚ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰äº”ä¸ªç±»åˆ«ã€‚
- en: And then base outputsã€‚ So very similar to what we did previouslyã€‚ And then new
    model is Kas that model inputs equals base inputsã€‚AndThen outputs equals final
    outputsã€‚ Then againï¼Œ you would just sort of get the compileã€‚ So I'm just gonna
    copy that in just to save some timeã€‚So the compileï¼Œ So we' just using atomã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæ˜¯åŸºç¡€è¾“å‡ºã€‚è¿™ä¸æˆ‘ä»¬ä¹‹å‰æ‰€åšçš„éå¸¸ç›¸ä¼¼ã€‚æ¥ç€æ–°æ¨¡å‹æ˜¯ Kasï¼Œæ¨¡å‹è¾“å…¥ç­‰äºåŸºç¡€è¾“å…¥ï¼Œè¾“å‡ºç­‰äºæœ€ç»ˆè¾“å‡ºã€‚ç„¶åä½ å°±å¯ä»¥ç¼–è¯‘ã€‚å› æ­¤ï¼Œæˆ‘å°†å¤åˆ¶è¿™æ®µä»¥èŠ‚çœä¸€äº›æ—¶é—´ã€‚ç¼–è¯‘ï¼Œæˆ‘ä»¬å°±ç”¨
    atomã€‚
- en: Spish categoricalï¼Œ nothingã€‚Nothing newã€‚ And then we're gonna do new model dot
    fitã€‚ So let's do new model dot fitã€‚X and Yï¼Œ and then epox are say 15ã€‚ and then
    verbose equals 2ã€‚ And this should be very quickï¼Œ rightï¼Œ We just have five examplesï¼Œ5
    random data pointsã€‚So let's see if it can overfit 5 data points using this gigantic
    inception V3 networkã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»å¤„ç†ï¼Œæ²¡ä»€ä¹ˆã€‚æ²¡æœ‰æ–°å†…å®¹ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è¦åšçš„æ˜¯ new model dot fitã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ‰§è¡Œ new model dot fitã€‚X å’Œ Yï¼Œç„¶å
    epox è®¾ä¸º 15ï¼Œverbose è®¾ä¸º 2ã€‚è¿™åº”è¯¥éå¸¸å¿«ï¼Œå¯¹å§ï¼Œæˆ‘ä»¬åªæœ‰äº”ä¸ªç¤ºä¾‹ï¼Œ5 ä¸ªéšæœºæ•°æ®ç‚¹ã€‚æ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹å®ƒèƒ½å¦ä½¿ç”¨è¿™ä¸ªå·¨å¤§çš„ Inception
    V3 ç½‘ç»œè¿‡æ‹Ÿåˆ 5 ä¸ªæ•°æ®ç‚¹ã€‚
- en: Base input is not definedï¼Œ allright soã€‚ğŸ˜”ï¼ŒA base inputs right thereã€‚Alrightã€‚
    so training on these 15 epos went pretty quicklyã€‚ and as we can seeã€‚ it's got
    100% accuracy and the loss is very low soã€‚But of courseã€‚ this was just a demonstration
    of how you would import stuff using this ks that applications models and so what
    I want to show you now is how to use the Tensorflow hub And so Tensorflowlow hub
    essentially and it just Tf hubub dev It's essentially where you can get a lot
    of different models pretrain models for different scenarios So let's say we just
    want images that you can sort of so there's a lot of models here that you can
    just you can go through and just check in this caseã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºç¡€è¾“å…¥æœªå®šä¹‰ï¼Œå¥½å§ã€‚ğŸ˜”ï¼ŒåŸºç¡€è¾“å…¥å°±åœ¨é‚£å„¿ã€‚å¥½å§ï¼Œæ‰€ä»¥åœ¨è¿™ 15 ä¸ªå›åˆçš„è®­ç»ƒè¿›è¡Œå¾—ç›¸å½“å¿«ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œå‡†ç¡®ç‡è¾¾åˆ°äº† 100%ï¼ŒæŸå¤±éå¸¸ä½ã€‚ä¸è¿‡ï¼Œå½“ç„¶ï¼Œè¿™åªæ˜¯ä¸€ä¸ªæ¼”ç¤ºï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è¿™ä¸ª
    ks åº”ç”¨ç¨‹åºæ¨¡å‹å¯¼å…¥å†…å®¹ã€‚æ‰€ä»¥æˆ‘ç°åœ¨æƒ³å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Tensorflow hubã€‚Tensorflow hub å®é™…ä¸Šå°±æ˜¯ Tf hubub devï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªä½ å¯ä»¥è·å–è®¸å¤šä¸åŒé¢„è®­ç»ƒæ¨¡å‹çš„åœ°æ–¹ï¼Œé€‚ç”¨äºä¸åŒåœºæ™¯ã€‚å‡è®¾æˆ‘ä»¬åªæƒ³è¦ä¸€äº›å›¾åƒï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°å¾ˆå¤šæ¨¡å‹ï¼Œå¯ä»¥æµè§ˆå¹¶æŸ¥çœ‹ã€‚
- en: let's say we want the inception v3 again so we can just go to this one right
    hereã€‚ and then it has this is for the feature vector So this is similarly to the
    kis one where you could include top equals false that would give you a feature
    vector and that's exactly what this doesã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æƒ³è¦å†æ¬¡ä½¿ç”¨ Inception V3ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥å»è¿™ä¸ªæ¨¡å‹ã€‚å®ƒæ˜¯ä¸ºç‰¹å¾å‘é‡è€Œè®¾è®¡çš„ï¼Œè¿™ä¸ kis æ¨¡å‹ç±»ä¼¼ï¼Œå…¶ä¸­ä½ å¯ä»¥è®¾ç½® top ç­‰äº
    falseï¼Œè¿™æ ·å°±ä¼šç»™ä½ ä¸€ä¸ªç‰¹å¾å‘é‡ï¼Œè¿™æ­£æ˜¯è¿™ä¸ªæ¨¡å‹çš„ä½œç”¨ã€‚
- en: So they've separated the inception V3 for a model that has the top of the fully
    connected ones and then one that just returns the feature vectorã€‚![](img/e49a5edbd4e401e53208da1309187c97_11.png)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬å°† Inception V3 åˆ†ç¦»ä¸ºä¸€ä¸ªåŒ…å«å…¨è¿æ¥å±‚çš„æ¨¡å‹å’Œä¸€ä¸ªä»…è¿”å›ç‰¹å¾å‘é‡çš„æ¨¡å‹ã€‚![](img/e49a5edbd4e401e53208da1309187c97_11.png)
- en: And then what you do is you just copy the URLã€‚And when you have the URLã€‚![](img/e49a5edbd4e401e53208da1309187c97_13.png)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ åšçš„å°±æ˜¯å¤åˆ¶ URLã€‚å½“ä½ æœ‰äº† URLã€‚![](img/e49a5edbd4e401e53208da1309187c97_13.png)
- en: And then you can go back to the codeã€‚ So againï¼Œ let's do some random dataã€‚ So
    let's do TF random normal shape is 5ï¼Œ2ï¼Œ99ï¼Œ2ï¼Œ99ï¼Œ3ã€‚ sort of exactly what we just
    did for theã€‚Loading from the ksã€‚ And againï¼Œ we're loading the exact same modelã€‚
    So this is not going to be anything new just showing you how to do it with Tensorflow
    hubã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥è¿”å›ä»£ç ã€‚æ‰€ä»¥ï¼Œå†æ¬¡è®©æˆ‘ä»¬ç”Ÿæˆä¸€äº›éšæœºæ•°æ®ã€‚æˆ‘ä»¬ç”Ÿæˆçš„ TF éšæœºæ­£æ€åˆ†å¸ƒå½¢çŠ¶ä¸º 5ï¼Œ2ï¼Œ99ï¼Œ2ï¼Œ99ï¼Œ3ã€‚è¿™å‡ ä¹æ­£æ˜¯æˆ‘ä»¬ä¹‹å‰ä¸ºåŠ è½½ ks
    æ‰€åšçš„ã€‚å†ä¸€æ¬¡ï¼Œæˆ‘ä»¬æ­£åœ¨åŠ è½½å®Œå…¨ç›¸åŒçš„æ¨¡å‹ã€‚æ‰€ä»¥è¿™ä¸ä¼šæœ‰ä»€ä¹ˆæ–°ä¸œè¥¿ï¼Œåªæ˜¯å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Tensorflow hubã€‚
- en: So then you would do URL equalsï¼Œ and then you would paste the URL right hereã€‚And
    thenã€‚You would do base modelï¼Œ and thenã€‚Uub equals ksã€‚Layerã€‚Uã€‚And thenï¼Œ input shapeã€‚299ï¼Œ2ï¼Œ99ï¼Œ3ã€‚
    And then what you would do is you would do model equals kas sequentialã€‚And you
    wouldï¼Œ thenã€‚Do the base modelï¼Œ rightï¼Œ which is not including the fully connected
    layersã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ è¦åšçš„æ˜¯ URL è®¾ä¸ºï¼Œç„¶åä½ å°† URL ç²˜è´´åˆ°è¿™é‡Œã€‚æ¥ç€ï¼Œä½ è¦åšçš„æ˜¯åŸºæœ¬æ¨¡å‹ï¼Œç„¶å Uub ç­‰äº ks.Layer.Uã€‚ç„¶åï¼Œè¾“å…¥å½¢çŠ¶ä¸º 299ï¼Œ2ï¼Œ99ï¼Œ3ã€‚æ¥ä¸‹æ¥ï¼Œä½ è¦åšçš„æ˜¯
    model ç­‰äº kas sequentialã€‚ç„¶åå†åšåŸºæœ¬æ¨¡å‹ï¼Œå¯¹å§ï¼Œè¿™ä¸åŒ…æ‹¬å…¨è¿æ¥å±‚ã€‚
- en: And then you can add whatever layers you wantã€‚ So layer standss1 hundred28 nodesã€‚Actation
    equalsã€‚Not reã€‚Our layer standsï¼Œ64 activation equals reluã€‚ And then yeahã€‚ let's
    do one final layer stands of 10 upï¼Œ10 up 5 output nodesã€‚ We just have five classesã€‚And
    then againï¼Œ you will do model that compile and model that fitã€‚ So I'm just gonna
    copy those inã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åä½ å¯ä»¥æ·»åŠ ä½ æƒ³è¦çš„ä»»ä½•å±‚ã€‚å› æ­¤å±‚çš„èŠ‚ç‚¹æ•°ä¸ºä¸€ç™¾äºŒåå…«ã€‚æ¿€æ´»å‡½æ•°ç­‰äºã€‚ä¸å†ã€‚æˆ‘ä»¬çš„å±‚æ•°ä¸º64ï¼Œæ¿€æ´»ç­‰äºreluã€‚ç„¶åæ˜¯çš„ã€‚è®©æˆ‘ä»¬åšä¸€ä¸ªæœ€ç»ˆçš„å±‚ï¼Œ10ä¸ªä¸Šå‡ï¼Œ5ä¸ªè¾“å‡ºèŠ‚ç‚¹ã€‚æˆ‘ä»¬åªæœ‰äº”ä¸ªç±»åˆ«ã€‚ç„¶åå†æ¬¡ï¼Œä½ å°†è¿›è¡Œæ¨¡å‹ç¼–è¯‘å’Œæ¨¡å‹æ‹Ÿåˆã€‚æ‰€ä»¥æˆ‘åªæ˜¯è¦æŠŠè¿™äº›å¤åˆ¶è¿‡æ¥ã€‚
- en: And then I guess sort of one thing I missed to do for the KRS model is thatï¼Œ
    of courseã€‚ you can do as the exact first example that we did so you could do base
    model that trainable equals false so that you're you're doing fine tuningã€‚I should
    have probably showed that also for the other one because this is something you
    can do for all modelsã€‚And yeahï¼Œ just for the exampleï¼Œ let's try and run this and
    see what it looks likeã€‚Alrightã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘æƒ³æˆ‘æ¼æ‰äº†KRSæ¨¡å‹çš„ä¸€ä»¶äº‹ï¼Œå½“ç„¶ã€‚ä½ å¯ä»¥åšæˆ‘ä»¬åšçš„ç¬¬ä¸€ä¸ªç¤ºä¾‹ï¼Œæ‰€ä»¥ä½ å¯ä»¥è®¾ç½®åŸºç¡€æ¨¡å‹çš„å¯è®­ç»ƒæ€§ä¸ºfalseï¼Œè¿™æ ·ä½ å°±å¯ä»¥è¿›è¡Œå¾®è°ƒã€‚æˆ‘å¯èƒ½ä¹Ÿåº”è¯¥ä¸ºå¦ä¸€ä¸ªæ¨¡å‹å±•ç¤ºè¿™ä¸€ç‚¹ï¼Œå› ä¸ºè¿™æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥åšçš„äº‹æƒ…ã€‚æ˜¯çš„ï¼Œä½œä¸ºç¤ºä¾‹ï¼Œè®©æˆ‘ä»¬å°è¯•è¿è¡Œè¿™ä¸ªå¹¶çœ‹çœ‹å®ƒçš„æ ·å­ã€‚å¥½çš„ã€‚
- en: so in this scenario it didn't actually overfit too muchã€‚ so we would have to
    probably run it for longerï¼Œ but as we can see at least it obtained a 100% accuracyã€‚And
    yeahï¼Œ that's pretty much itã€‚ Those are the examples I wanted to show you sort
    of different ways you can do pretraining and fine tuning freezing layers and so
    onã€‚ Hopefully this video was useful for you if you have any questions then leave
    them in the comment and hope to see you in the next videoã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå®é™…ä¸Šå¹¶æ²¡æœ‰è¿‡æ‹Ÿåˆå¤ªå¤šã€‚å› æ­¤æˆ‘ä»¬å¯èƒ½éœ€è¦è¿è¡Œæ›´é•¿æ—¶é—´ï¼Œä½†æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè‡³å°‘å®ƒè¾¾åˆ°äº†100%çš„å‡†ç¡®ç‡ã€‚å·®ä¸å¤šå°±æ˜¯è¿™æ ·ã€‚è¿™äº›æ˜¯æˆ‘æƒ³å‘ä½ å±•ç¤ºçš„ä¸åŒé¢„è®­ç»ƒå’Œå¾®è°ƒã€å†»ç»“å±‚çš„æ–¹å¼ã€‚å¸Œæœ›è¿™ä¸ªè§†é¢‘å¯¹ä½ æœ‰ç”¨ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·åœ¨è¯„è®ºä¸­ç•™ä¸‹ï¼Œæˆ‘å¸Œæœ›åœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­è§åˆ°ä½ ã€‚
- en: '![](img/e49a5edbd4e401e53208da1309187c97_15.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e49a5edbd4e401e53208da1309187c97_15.png)'
