- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P16ï¼šL16-
    å¦‚ä½•ä½¿ç”¨ TensorBoard - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P16ï¼šL16-
    å¦‚ä½•ä½¿ç”¨ TensorBoard - ShowMeAI - BV12m4y1S7ix
- en: Heyï¼Œ guysï¼Œ welcome to a new Pytorch tutorialã€‚ In this videoã€‚ we will learn how
    to use the Tenzo board to visualize and analyze our model and training pipelineã€‚
    Tenszoboard is a visualization toolkit in order to experiment with our modelsã€‚
    It is actually developed by the Tenorflow guysï¼Œ but it can be used with Pytorch
    as wellã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æ–°çš„ PyTorch æ•™ç¨‹ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ TensorBoard æ¥å¯è§†åŒ–å’Œåˆ†ææˆ‘ä»¬çš„æ¨¡å‹å’Œè®­ç»ƒç®¡é“ã€‚TensorBoard
    æ˜¯ä¸€ä¸ªå¯è§†åŒ–å·¥å…·åŒ…ï¼Œç”¨äºå®éªŒæˆ‘ä»¬çš„æ¨¡å‹ã€‚å®ƒå®é™…ä¸Šæ˜¯ç”± TensorFlow çš„å›¢é˜Ÿå¼€å‘çš„ï¼Œä½†åŒæ ·å¯ä»¥ä¸ PyTorch ä¸€èµ·ä½¿ç”¨ã€‚
- en: So here on the official websiteã€‚ We can do a few thingsã€‚ we see a few things
    that we can do with Tenszobarã€‚ Soï¼Œ for exampleã€‚ we can track and visualize metrics
    such as the loss and the accuracyã€‚ We can visualize our model graphã€‚ We can view
    histogramsã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®˜æ–¹ç½‘ç«™ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥åšå‡ ä»¶äº‹æƒ…ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›å¯ä»¥åœ¨ TensorBoard ä¸­æ‰§è¡Œçš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è·Ÿè¸ªå’Œå¯è§†åŒ–æŒ‡æ ‡ï¼Œæ¯”å¦‚æŸå¤±å’Œå‡†ç¡®ç‡ã€‚æˆ‘ä»¬å¯ä»¥å¯è§†åŒ–æˆ‘ä»¬çš„æ¨¡å‹å›¾ï¼ŒæŸ¥çœ‹ç›´æ–¹å›¾ã€‚
- en: We can project embeddings to a lower dimensional spaceï¼Œ and we can display imagesã€‚
    text and audio dataï¼Œ and we can profile our programs and much moreã€‚ğŸ˜Šã€‚So now I
    want to show you how we can use this in our codeã€‚ So I'm going to use the code
    from tutorial number 13 hereã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†åµŒå…¥æŠ•å½±åˆ°è¾ƒä½ç»´ç©ºé—´ï¼Œå¹¶å¯ä»¥æ˜¾ç¤ºå›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘æ•°æ®ï¼Œè¿˜å¯ä»¥åˆ†ææˆ‘ä»¬çš„ç¨‹åºç­‰ç­‰ã€‚ğŸ˜Šæ‰€ä»¥ç°åœ¨æˆ‘æƒ³å‘ä½ å±•ç¤ºæˆ‘ä»¬å¦‚ä½•åœ¨ä»£ç ä¸­ä½¿ç”¨è¿™ä¸ªã€‚æˆ‘å°†ä½¿ç”¨ç¬¬ 13
    ä¸ªæ•™ç¨‹ä¸­çš„ä»£ç ã€‚
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_1.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_1.png)'
- en: All rightã€‚ So here is the codeã€‚ So this is the exact code from tutorial number
    13ã€‚ And if you haven't watched this oneï¼Œ and I recommend that you watch this one
    firstã€‚ So I will briefly explain the code again nowã€‚So in this tutorialï¼Œ we used
    the Mnes data setã€‚ So we did diit classification hereã€‚ So here we are loading
    the Mnis data setã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™é‡Œæ˜¯ä»£ç ã€‚è¿™æ˜¯æ¥è‡ªç¬¬ 13 ä¸ªæ•™ç¨‹çš„ç¡®åˆ‡ä»£ç ã€‚å¦‚æœä½ è¿˜æ²¡çœ‹è¿‡è¿™ä¸ªï¼Œæˆ‘å»ºè®®ä½ å…ˆè§‚çœ‹è¿™ä¸ªã€‚å› æ­¤ï¼Œæˆ‘ç°åœ¨å°†ç®€è¦å†æ¬¡è§£é‡Šä»£ç ã€‚åœ¨è¿™ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†
    MNIST æ•°æ®é›†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè¿›è¡Œäº†æ•°å­—åˆ†ç±»ã€‚ç°åœ¨æˆ‘ä»¬æ­£åœ¨åŠ è½½ MNIST æ•°æ®é›†ã€‚
- en: Then we are plotting some of the imagesã€‚ and then we create a simple feet forward
    neural netã€‚ So this is a fully connected neural network with one hidden layerã€‚
    So we see we have one linear layer firstï¼Œ Then we have a relu activationctuaation
    functionã€‚ and then another linear layerã€‚ and that's our whole forward passã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ç»˜åˆ¶äº†ä¸€äº›å›¾åƒã€‚æ¥ç€æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚è¿™æ˜¯ä¸€ä¸ªå…·æœ‰ä¸€ä¸ªéšè—å±‚çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬çœ‹åˆ°ï¼Œé¦–å…ˆæœ‰ä¸€ä¸ªçº¿æ€§å±‚ï¼Œç„¶åæ˜¯ä¸€ä¸ª ReLU
    æ¿€æ´»å‡½æ•°ï¼Œå†ç„¶åæ˜¯å¦ä¸€ä¸ªçº¿æ€§å±‚ã€‚è¿™å°±æ˜¯æˆ‘ä»¬çš„æ•´ä¸ªå‰å‘ä¼ æ’­ã€‚
- en: Then we set up our training pipelineã€‚ So we have our loss and optimizerã€‚ Then
    we do the trainingã€‚So hereï¼Œ as alwaysï¼Œ we do a forward passï¼Œ a backward parï¼Œ and
    then update our weightsã€‚ And then at the endï¼Œ we evaluate our model and plot the
    accuracyã€‚ So now let's use the tennor board for this code to analyze our model
    a little bit moreã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„è®­ç»ƒç®¡é“ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰æˆ‘ä»¬çš„æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚æ¥ç€æˆ‘ä»¬è¿›è¡Œè®­ç»ƒã€‚å’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬è¿›è¡Œå‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ï¼Œç„¶åæ›´æ–°æƒé‡ã€‚æœ€åï¼Œæˆ‘ä»¬è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹å¹¶ç»˜åˆ¶å‡†ç¡®ç‡ã€‚å› æ­¤ï¼Œç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨
    TensorBoard å¯¹è¿™æ®µä»£ç è¿›è¡Œåˆ†æï¼Œä»¥è¿›ä¸€æ­¥åˆ†ææˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: And the firstï¼Œ first thing we want to do is to install tensor boardã€‚ So for
    thisï¼Œ we can do Pipã€‚Installã€‚Tenensil boardã€‚And this will install all the things
    that we needã€‚ So in my caseã€‚ I've already installed thisã€‚ So this was fastã€‚ And
    we don't have to install the whole Tens of flow libraryã€‚ So Tenzzo board is enough
    hereã€‚And now we can start the tensor board by saying tenor boardã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å®‰è£… TensorBoardã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `pip install tensorboard`ã€‚è¿™å°†å®‰è£…æˆ‘ä»¬æ‰€éœ€çš„æ‰€æœ‰å†…å®¹ã€‚åœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œæˆ‘å·²ç»å®‰è£…å¥½äº†ï¼Œæ‰€ä»¥è¿™ä¸ªè¿‡ç¨‹å¾ˆå¿«ã€‚è€Œä¸”æˆ‘ä»¬ä¸éœ€è¦å®‰è£…æ•´ä¸ª
    TensorFlow åº“ï¼Œåœ¨è¿™é‡Œä»…å®‰è£… TensorBoard å°±è¶³å¤Ÿäº†ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡è¾“å…¥ `tensorboard` æ¥å¯åŠ¨ TensorBoardã€‚
- en: And then we have to specify the path where we save the lock filesã€‚ and we do
    this by giving it the argument minus minus loer equalsã€‚ and by defaultã€‚ this is
    called in the runs directoryã€‚ So let's hit enterã€‚And then it will start up the
    Tensor board at local horse 60ï¼Œ06ã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ç€æˆ‘ä»¬éœ€è¦æŒ‡å®šä¿å­˜æ—¥å¿—æ–‡ä»¶çš„è·¯å¾„ï¼Œæˆ‘ä»¬é€šè¿‡ç»™å®šå‚æ•° `--logdir=` æ¥å®ç°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™ä¸ªè·¯å¾„åœ¨ runs ç›®å½•ä¸­ã€‚è®©æˆ‘ä»¬æŒ‰å›è½¦é”®ã€‚ç„¶åå®ƒå°†åœ¨æœ¬åœ°ä¸»æœº
    6006 å¯åŠ¨ TensorBoardã€‚
- en: And here we have a warning that it doesn't find Tensorflow and it will run it
    with a reduced feature setã€‚ but that is fineã€‚ So let's open up the tensor boardã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_3.png)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬ä¼šæ”¶åˆ°ä¸€ä¸ªè­¦å‘Šï¼Œæç¤ºæ‰¾ä¸åˆ° TensorFlowï¼Œå¹¶ä¸”å°†ä»¥å‡å°‘åŠŸèƒ½é›†çš„æ–¹å¼è¿è¡Œã€‚ä½†è¿™æ²¡å…³ç³»ã€‚ç°åœ¨æˆ‘ä»¬æ‰“å¼€ TensorBoardã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_3.png)
- en: And now here we have the tensor partã€‚ And right nowï¼Œ we see that no dash ports
    are activeã€‚ And this is because we haven't written any dataã€‚ So let's do thisã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_5.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥åˆ°äº†å¼ é‡éƒ¨åˆ†ã€‚æ­¤åˆ»ï¼Œæˆ‘ä»¬çœ‹åˆ°æ²¡æœ‰æ´»åŠ¨çš„ç ´æŠ˜å·ç«¯å£ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬è¿˜æ²¡æœ‰å†™å…¥ä»»ä½•æ•°æ®ã€‚é‚£æˆ‘ä»¬æ¥åšä¸€ä¸‹å§ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_5.png)
- en: So let's jump to the code againã€‚And now the first thing we want to do is to
    import the Tenzo boardã€‚ Soï¼Œ and for thisï¼Œ we say from torch dot us dot Tenzobarã€‚We
    importï¼Œ and this is called summary ridã€‚ So we import a summary ridï¼Œ andã€‚So here
    I have a typoã€‚And now let's create a riderã€‚ So let's say rider equals summary
    riderã€‚ And then let's give it aã€‚Diectctoryã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†è·³å›ä»£ç ã€‚ç°åœ¨æˆ‘ä»¬æƒ³åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å¯¼å…¥Tensoræ¿ã€‚æ‰€ä»¥ï¼Œå¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬è¯´ä»torchçš„usä¸­å¯¼å…¥Tensoræ¿ã€‚æˆ‘ä»¬å¯¼å…¥çš„å«åšsummary
    riderã€‚è¿™é‡Œæˆ‘æœ‰ä¸€ä¸ªæ‹¼å†™é”™è¯¯ã€‚ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå†™å…¥å™¨ã€‚å‡è®¾å†™å…¥å™¨ç­‰äºsummary riderã€‚ç„¶åç»™å®ƒä¸€ä¸ªç›®å½•ã€‚
- en: where it should save the log files and the default directory isï¼Œ as I saidï¼Œ
    the runs folderã€‚ But let's be more specific hereã€‚ So let's call this runs and
    then M Nã€‚And now we have our writer set upã€‚ And now the first thing we want to
    do is hereã€‚ So here in the codeï¼Œ we plotted some imagesã€‚ And nowï¼Œ instead of plottingã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåº”è¯¥ä¿å­˜æ—¥å¿—æ–‡ä»¶ï¼Œé»˜è®¤ç›®å½•æ˜¯ï¼Œæˆ‘è¯´è¿‡çš„ï¼Œè¿è¡Œæ–‡ä»¶å¤¹ã€‚ä½†è®©æˆ‘ä»¬åœ¨è¿™é‡Œæ›´å…·ä½“ä¸€ç‚¹ã€‚æˆ‘ä»¬å«è¿™ä¸ªè¿è¡Œï¼Œç„¶åM Nã€‚ç°åœ¨æˆ‘ä»¬å·²ç»è®¾ç½®å¥½å†™å…¥å™¨ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æƒ³åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯åœ¨è¿™é‡Œã€‚åœ¨ä»£ç ä¸­ï¼Œæˆ‘ä»¬ç»˜åˆ¶äº†ä¸€äº›å›¾åƒã€‚ç°åœ¨ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯ç»˜å›¾ã€‚
- en: let's add the image to our tensor boardã€‚ And for thisã€‚ the only thing we have
    to do is we want to create a gritã€‚ And then call the writer at image methodã€‚ So
    let's do thisã€‚ So let's say our image grit equalsã€‚ And we also get this from torch
    vision dot usã€‚Dot makeï¼Œ make gritã€‚ And then let's give it the dataã€‚ So here we
    have one batch of our example dataã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°†å›¾åƒæ·»åŠ åˆ°æˆ‘ä»¬çš„å¼ é‡æ¿ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦åˆ›å»ºä¸€ä¸ªç½‘æ ¼ã€‚ç„¶åè°ƒç”¨å›¾åƒæ–¹æ³•çš„å†™å…¥å™¨ã€‚é‚£æˆ‘ä»¬æ¥åšä¸€ä¸‹å§ã€‚å‡è®¾æˆ‘ä»¬çš„å›¾åƒç½‘æ ¼ç­‰äºã€‚æˆ‘ä»¬ä¹Ÿä»torch visionä¸­è·å–è¿™ä¸ªã€‚Dot
    makeï¼Œåˆ›å»ºç½‘æ ¼ã€‚ç„¶åç»™å®ƒæ•°æ®ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰ä¸€æ‰¹ç¤ºä¾‹æ•°æ®ã€‚
- en: So let's put this in hereã€‚ And then let's callã€‚Rrierï¼Œ dot atã€‚Imageã€‚And then
    here we give the image gridã€‚And we also have to provide a label for this image
    in the beginningã€‚ So let's call thisï¼Œ for exampleï¼Œ M Nistã€‚Imagesã€‚And nowã€‚å—¯ã€‚I want
    to exit hereï¼Œ so I useã€‚ I import cis or systemã€‚ And then here I use an early exit
    because I don't want to run the whole training pipeline right nowã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŠŠè¿™ä¸ªæ”¾åœ¨è¿™é‡Œã€‚ç„¶åè°ƒç”¨å†™å…¥å™¨çš„å›¾åƒæ–¹æ³•ã€‚è¿™é‡Œæˆ‘ä»¬ç»™å›¾åƒç½‘æ ¼ï¼Œå¹¶ä¸”ä¸€å¼€å§‹æˆ‘ä»¬è¿˜éœ€è¦æä¾›è¿™ä¸ªå›¾åƒçš„æ ‡ç­¾ã€‚æ¯”å¦‚æˆ‘ä»¬å«è¿™ä¸ªï¼ŒM Nistå›¾åƒã€‚ç°åœ¨ã€‚å—¯ã€‚æˆ‘æƒ³åœ¨è¿™é‡Œé€€å‡ºï¼Œæ‰€ä»¥æˆ‘ä½¿ç”¨ã€‚æˆ‘å¯¼å…¥cisæˆ–ç³»ç»Ÿã€‚ç„¶åæˆ‘åœ¨è¿™é‡Œä½¿ç”¨æå‰é€€å‡ºï¼Œå› ä¸ºæˆ‘ç°åœ¨ä¸æƒ³è¿è¡Œæ•´ä¸ªè®­ç»ƒç®¡é“ã€‚
- en: So here I call cis dot exitã€‚ and I want to make sure that all the events are
    written hereã€‚ So that's why I also call Rderã€‚Dot closeã€‚ So this makes sure that
    all the outputs are being flushed hereã€‚And now let's save thisã€‚ and let's go to
    the terminalï¼Œ and let's run thisã€‚So let's say Pythonã€‚ and then our file was feet
    forward dot P and hit enterã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘è°ƒç”¨cis.exitã€‚æˆ‘æƒ³ç¡®ä¿æ‰€æœ‰äº‹ä»¶éƒ½åœ¨è¿™é‡Œå†™å…¥ã€‚æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä¹Ÿè°ƒç”¨å†™å…¥å™¨.closeçš„åŸå› ã€‚è¿™ç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åœ¨è¿™é‡Œè¢«åˆ·æ–°ã€‚ç°åœ¨è®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªã€‚ç„¶åå»ç»ˆç«¯ï¼Œè¿è¡Œè¿™ä¸ªã€‚å‡è®¾æˆ‘ä»¬è¯´Pythonï¼Œç„¶åæˆ‘ä»¬çš„æ–‡ä»¶æ˜¯feet
    forward.Pï¼ŒæŒ‰å›è½¦ã€‚
- en: And now let's go to our Tensor board again and let's reload thisã€‚ And then we
    see we have our images hereã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_7.png)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å†æ¬¡è¿›å…¥Tensoræ¿å¹¶é‡æ–°åŠ è½½å®ƒã€‚ç„¶åæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œæœ‰æˆ‘ä»¬çš„å›¾åƒã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_7.png)
- en: And here we have our grid that we just createdã€‚And this is 60ã€‚ this is 8 by
    8 because we specified our batch size to be 64ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_9.png)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯æˆ‘ä»¬åˆšåˆ›å»ºçš„ç½‘æ ¼ã€‚è¿™æ˜¯60ã€‚è¿™æ˜¯8ä¹˜8ï¼Œå› ä¸ºæˆ‘ä»¬æŒ‡å®šæˆ‘ä»¬çš„æ‰¹é‡å¤§å°ä¸º64ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_9.png)
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_10.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_10.png)'
- en: And yeahï¼Œ so now we can analyze our dataã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_12.png)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ†ææˆ‘ä»¬çš„æ•°æ®ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_12.png)
- en: And let's go ahead and do something more with our Tzor boardã€‚So the next thing
    we want to do is to add a graphã€‚ So to analyze our modelã€‚ So if we scroll down
    furtherï¼Œ then we see that here we create ourã€‚Neural netsã€‚ So let's comment this
    thisis exit out againã€‚And then here we create our modelã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»§ç»­åœ¨æˆ‘ä»¬çš„Tzoræ¿ä¸Šåšæ›´å¤šäº‹æƒ…ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æƒ³åšçš„æ˜¯æ·»åŠ ä¸€ä¸ªå›¾ã€‚ç”¨äºåˆ†ææˆ‘ä»¬çš„æ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬å‘ä¸‹æ»šåŠ¨ï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œåˆ›å»ºäº†æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œã€‚è®©æˆ‘ä»¬å¯¹æ­¤è¿›è¡Œæ³¨é‡Šï¼Œç„¶ååœ¨è¿™é‡Œåˆ›å»ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: and then here our loss and optimizerã€‚ And now down hereã€‚ let's add our model
    graph So we can do this by saying rider at graphã€‚ And then here we give it the
    modelã€‚And then we also can give it an input so we can sayï¼Œ againã€‚ we have our
    example dataã€‚ So this is one batchã€‚ And then we have to reshape the same way that
    we are doing it hereã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨è¿™é‡Œæ˜¯æˆ‘ä»¬çš„æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚ç°åœ¨åœ¨è¿™é‡Œï¼Œè®©æˆ‘ä»¬æ·»åŠ æˆ‘ä»¬çš„æ¨¡å‹å›¾ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´`rider.at_graph()`æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬ä¼ é€’æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ç»™å®ƒä¸€ä¸ªè¾“å…¥ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å†æ¬¡è¯´ï¼Œæˆ‘ä»¬æœ‰æˆ‘ä»¬çš„ç¤ºä¾‹æ•°æ®ã€‚è¿™æ˜¯ä¸€ä¸ªæ‰¹æ¬¡ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»ä»¥ä¸è¿™é‡Œç›¸åŒçš„æ–¹å¼é‡æ–°è°ƒæ•´ã€‚
- en: So let's reshape our batch dataã€‚Andã€‚Then againï¼Œ let's call Rer dot close and
    writerer exitã€‚insist system exitsã€‚ And againï¼Œ let's run ourã€‚Fileã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_14.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬é‡æ–°è°ƒæ•´æˆ‘ä»¬çš„æ‰¹é‡æ•°æ®ã€‚ç„¶åï¼Œå†æ¬¡è°ƒç”¨`Rer.close()`å’Œ`writer.exit()`ã€‚ç„¶åç³»ç»Ÿé€€å‡ºã€‚å†ä¸€æ¬¡ï¼Œè®©æˆ‘ä»¬è¿è¡Œæˆ‘ä»¬çš„æ–‡ä»¶ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_14.png)
- en: And now let's head over to our tensor board againã€‚ and let's reload thisã€‚ And
    then we see here up hereã€‚ we also have the graphs tabã€‚ So let's go to the graphã€‚
    And here we see our modelã€‚So we have the input and then the neural netã€‚ And now
    if we do a double clickï¼Œ then we see more detailsã€‚ So here we see our whole modelã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å†æ¬¡å»TensorBoardã€‚è®©æˆ‘ä»¬é‡æ–°åŠ è½½å®ƒã€‚ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°ä¸Šæ–¹ä¹Ÿæœ‰å›¾è¡¨é€‰é¡¹å¡ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å»å›¾è¡¨ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬æœ‰è¾“å…¥ï¼Œç„¶åæ˜¯ç¥ç»ç½‘ç»œã€‚ç°åœ¨å¦‚æœæˆ‘ä»¬åŒå‡»ï¼Œå°±å¯ä»¥çœ‹åˆ°æ›´å¤šç»†èŠ‚ã€‚è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„æ•´ä¸ªæ¨¡å‹ã€‚
- en: And so now we see we have the first linear layerã€‚ Then we have the relu activationctuaation
    functionã€‚ And then we have the second linear layerã€‚And we also see the weights
    and the biases for each linear layerã€‚ Soï¼Œ yeahï¼Œ so now we can inspect this furtherï¼Œ
    if we wantã€‚And yeahã€‚ this is really helpful to analyze the structure of our modelã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬æœ‰ç¬¬ä¸€ä¸ªçº¿æ€§å±‚ã€‚ç„¶åæ˜¯ReLUæ¿€æ´»å‡½æ•°ã€‚æ¥ç€æ˜¯ç¬¬äºŒä¸ªçº¿æ€§å±‚ã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°æ¯ä¸ªçº¿æ€§å±‚çš„æƒé‡å’Œåå·®ã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥æ£€æŸ¥ã€‚è¿™ç¡®å®æœ‰åŠ©äºåˆ†ææˆ‘ä»¬æ¨¡å‹çš„ç»“æ„ã€‚
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_16.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_16.png)'
- en: Soï¼Œ yeahï¼Œ now we have our modelã€‚ and now let's analyze some metricsï¼Œ soã€‚What
    we did in the original script is we simplyï¼Œ during the trainingï¼Œ we printed every
    100th stepã€‚ We print the current lossã€‚So nowï¼Œ instead of just printing did thisã€‚
    let's add this to our teno boardã€‚ So let's add the training loss and also the
    accuracy for thisã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨è®©æˆ‘ä»¬åˆ†æä¸€äº›æŒ‡æ ‡ã€‚æˆ‘ä»¬åœ¨åŸå§‹è„šæœ¬ä¸­æ‰€åšçš„æ˜¯ï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬æ¯100æ­¥æ‰“å°ä¸€æ¬¡ã€‚æˆ‘ä»¬æ‰“å°å½“å‰çš„æŸå¤±ã€‚ç°åœ¨ï¼Œä¸åªæ˜¯æ‰“å°è¿™ä¸ªã€‚è®©æˆ‘ä»¬æŠŠå®ƒæ·»åŠ åˆ°æˆ‘ä»¬çš„TensorBoardä¸­ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬æ·»åŠ è®­ç»ƒæŸå¤±å’Œå‡†ç¡®ç‡ã€‚
- en: And for thisï¼Œ we want to have the mean loss during this batch trainingã€‚ So let's
    add a two values up here before we start our loopã€‚ So the first one is our running
    lossã€‚And this is 0 in the beginningã€‚ And then let's also sayï¼Œ the runningã€‚Correctã€‚Predictions
    equals 0 in the beginningã€‚ And nowï¼Œ every hundredth stepã€‚Weã€‚Noã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨è¿™ä¸€æ‰¹è®­ç»ƒä¸­å¾—åˆ°å¹³å‡æŸå¤±ã€‚æ‰€ä»¥åœ¨å¼€å§‹å¾ªç¯ä¹‹å‰ï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œæ·»åŠ ä¸¤ä¸ªå€¼ã€‚ç¬¬ä¸€ä¸ªæ˜¯æˆ‘ä»¬çš„è¿è¡ŒæŸå¤±ã€‚è¿™ä¸€å¼€å§‹æ˜¯0ã€‚ç„¶åæˆ‘ä»¬è¿˜è¦è¯´ï¼Œè¿è¡Œçš„æ­£ç¡®é¢„æµ‹åœ¨ä¸€å¼€å§‹ä¹Ÿæ˜¯0ã€‚ç°åœ¨ï¼Œæ¯100æ­¥ï¼Œæˆ‘ä»¬â€¦â€¦
- en: sorry before for in each iterationã€‚ Nowï¼Œ we add theã€‚Loss to the running lossã€‚
    So we say running loss plus equals loss dot itemã€‚ And we also add the number of
    correct predictions to the running correctã€‚ So for thisï¼Œ we want to get the predictionsã€‚
    And we can do this the same way as we are doing it down here by calling torch
    dot maxã€‚Soã€‚Let's do this up hereï¼Œ as wellã€‚So we get the predicted valuesã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ±æ­‰ï¼Œä¹‹å‰åœ¨æ¯æ¬¡è¿­ä»£ä¸­ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æŸå¤±æ·»åŠ åˆ°è¿è¡ŒæŸå¤±ä¸­ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´`running_loss += loss.item()`ã€‚æˆ‘ä»¬è¿˜å°†æ­£ç¡®é¢„æµ‹çš„æ•°é‡æ·»åŠ åˆ°è¿è¡Œçš„æ­£ç¡®å€¼ä¸­ã€‚å› æ­¤ï¼Œå¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬æƒ³è¦å¾—åˆ°é¢„æµ‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨`torch.max`ä»¥ä¸æˆ‘ä»¬åœ¨ä¸‹é¢æ‰€åšçš„æ–¹å¼ç›¸åŒæ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œä¹Ÿè¿™æ ·åšã€‚æˆ‘ä»¬å¾—åˆ°é¢„æµ‹å€¼ã€‚
- en: and then we say running correct plus equalsã€‚ And here we say predicted equals
    equals the actual labelsã€‚ and then the sumã€‚ And this is a tensor with only one
    itemã€‚ So we can call dot itemã€‚And nowï¼Œ yeahã€‚ here we add this to the running lossã€‚
    And now every hundredth stepã€‚ we want to calculate the mean value and add this
    to the tenor boardã€‚ So we call rider dot at Scalaã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¯´`running_correct +=`ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¯´`predicted == actual_labels`ï¼Œç„¶åæ˜¯æ±‚å’Œã€‚è¿™æ˜¯ä¸€ä¸ªä»…åŒ…å«ä¸€ä¸ªé¡¹ç›®çš„å¼ é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨`.item()`ã€‚ç°åœ¨ï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå°†å…¶æ·»åŠ åˆ°è¿è¡ŒæŸå¤±ä¸­ã€‚ç°åœ¨æ¯100æ­¥ï¼Œæˆ‘ä»¬æƒ³è¦è®¡ç®—å¹³å‡å€¼å¹¶å°†å…¶æ·»åŠ åˆ°TensorBoardä¸­ã€‚æ‰€ä»¥æˆ‘ä»¬è°ƒç”¨`rider.at_scala()`ã€‚
- en: And now we have to add have to give it a labelã€‚ So hereï¼Œ let's give it the label
    draining lossã€‚And now the actual loss is the running loss divided by 100ï¼Œ because
    we sum this up for 100 stepsã€‚ And then we also have to give it the current global
    stepã€‚And this is the by saying epoch and times the number of total steps that
    we extracted up hereã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¿…é¡»æ·»åŠ æ ‡ç­¾ã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œè®©æˆ‘ä»¬ç»™å®ƒæ ‡ç­¾ä¸ºè®­ç»ƒæŸå¤±ã€‚ç°åœ¨å®é™…æŸå¤±æ˜¯è¿è¡ŒæŸå¤±é™¤ä»¥100ï¼Œå› ä¸ºæˆ‘ä»¬ä¸º100æ­¥è¿›è¡Œäº†æ±‚å’Œã€‚ç„¶åæˆ‘ä»¬è¿˜å¿…é¡»ç»™å®ƒå½“å‰çš„å…¨å±€æ­¥éª¤ã€‚é€šè¿‡è¯´epochå’Œæå–çš„æ€»æ­¥éª¤æ•°æ¥è¡¨ç¤ºè¿™ä¸€ç‚¹ã€‚
- en: So this is the length of the training loaderã€‚ and then plus Iï¼Œ and I is the
    current batch iterationã€‚So this is the current global stepã€‚ So here we add the
    training lossã€‚ And now let's do the same thing again and add the accuracyã€‚ So
    let's say accuracyã€‚And then here we have to sayï¼Œ runningã€‚Correctã€‚Divided by 100ã€‚And
    after thatã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯è®­ç»ƒåŠ è½½å™¨çš„é•¿åº¦ã€‚å†åŠ ä¸ŠIï¼Œè€ŒIæ˜¯å½“å‰æ‰¹æ¬¡è¿­ä»£ã€‚æ‰€ä»¥è¿™æ˜¯å½“å‰çš„å…¨å±€æ­¥éª¤ã€‚è¿™é‡Œæˆ‘ä»¬æ·»åŠ è®­ç»ƒæŸå¤±ã€‚ç°åœ¨è®©æˆ‘ä»¬å†åšä¸€æ¬¡ï¼Œæ·»åŠ å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è¯´å‡†ç¡®æ€§ã€‚ç„¶åè¿™é‡Œæˆ‘ä»¬è¦è¯´ï¼Œè¿è¡Œã€‚æ­£ç¡®ã€‚é™¤ä»¥100ã€‚ç„¶ååœ¨é‚£ä¹‹åã€‚
- en: we have to set the running loss and the running predicted to the running correct
    to 0 againã€‚ So let's say running loss equals0ã€‚0 and running lossã€‚And noï¼Œ sorryã€‚
    Run correct equals 0 againã€‚And thenã€‚Yeahï¼Œ now we have to save thisã€‚ and now we
    have to run the whole training pipelineã€‚ So let's comment this system exit out
    againã€‚And nowï¼Œ let's run our scriptã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»å°†è¿è¡ŒæŸå¤±å’Œè¿è¡Œé¢„æµ‹æ­£ç¡®çš„å€¼é‡æ–°è®¾ä¸º0ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´è¿è¡ŒæŸå¤±ç­‰äº0.0å’Œè¿è¡ŒæŸå¤±ã€‚ä¸ï¼ŒæŠ±æ­‰ã€‚è¿è¡Œæ­£ç¡®å†æ¬¡ç­‰äº0ã€‚ç„¶åï¼Œæ˜¯çš„ï¼Œç°åœ¨æˆ‘ä»¬å¿…é¡»ä¿å­˜è¿™ä¸ªã€‚ç°åœ¨æˆ‘ä»¬å¿…é¡»è¿è¡Œæ•´ä¸ªè®­ç»ƒç®¡é“ã€‚è®©æˆ‘ä»¬å†æ¬¡æ³¨é‡Šæ‰ç³»ç»Ÿé€€å‡ºã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿è¡Œæˆ‘ä»¬çš„è„šæœ¬ã€‚
- en: And we should still see theï¼Œ the printing outputs hereã€‚ So for every 100th stepã€‚
    we see that how the loss is decreasingã€‚And now we should be doneã€‚ And now we also
    see the whole accuracy of our networkã€‚ And now let's go to our Tensor board again
    and againï¼Œ hit reloadã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç„¶åº”è¯¥çœ‹åˆ°è¿™é‡Œçš„æ‰“å°è¾“å‡ºã€‚å› æ­¤ï¼Œå¯¹äºæ¯100æ­¥ï¼Œæˆ‘ä»¬çœ‹åˆ°æŸå¤±æ˜¯å¦‚ä½•å‡å°‘çš„ã€‚ç°åœ¨æˆ‘ä»¬åº”è¯¥å®Œæˆäº†ã€‚ç°åœ¨æˆ‘ä»¬ä¹Ÿçœ‹åˆ°æˆ‘ä»¬ç½‘ç»œçš„æ•´ä½“å‡†ç¡®æ€§ã€‚ç°åœ¨è®©æˆ‘ä»¬å†æ¬¡å›åˆ°æˆ‘ä»¬çš„TensorBoardï¼Œç‚¹å‡»é‡æ–°åŠ è½½ã€‚
- en: And then we have one more entry up hereã€‚ And this is the scholars entryã€‚ And
    here we have our two plotsã€‚ So yeahï¼Œ we see that it workedã€‚ So we see the accuracyã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_18.png)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªæ¡ç›®ã€‚è¿™æ˜¯å­¦è€…æ¡ç›®ã€‚è¿™é‡Œæˆ‘ä»¬æœ‰æˆ‘ä»¬çš„ä¸¤ä¸ªå›¾è¡¨ã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬çœ‹åˆ°å®ƒæˆåŠŸäº†ã€‚æˆ‘ä»¬çœ‹åˆ°äº†å‡†ç¡®æ€§ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_18.png)
- en: For each of the stepsã€‚ And we also see how the training loss is decreasingã€‚And
    yeahã€‚ so here by defaultï¼Œ Tenzo flowï¼Œ Tenzo board is smoothing this line so we
    can modify the smoothing parameter hereã€‚But yeahï¼Œ and now we can analyze how the
    loss is decreasingã€‚ And soï¼Œ for exampleã€‚ if we see that at some pointï¼Œ it is not
    decreasing furtherï¼Œ and we can see that at this pointã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ­¥éª¤ã€‚æˆ‘ä»¬ä¹Ÿçœ‹åˆ°è®­ç»ƒæŸå¤±åœ¨å‡å°‘ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒTensorFlowå’ŒTensorBoardä¼šå¹³æ»‘è¿™æ¡çº¿ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹å¹³æ»‘å‚æ•°ã€‚ä½†ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ†ææŸå¤±æ˜¯å¦‚ä½•å‡å°‘çš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çœ‹åˆ°åœ¨æŸä¸€ç‚¹ä¸Šï¼ŒæŸå¤±æ²¡æœ‰è¿›ä¸€æ­¥å‡å°‘ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚
- en: we have to improve somethingã€‚Soï¼Œ for exampleï¼Œ what we can do then is we can
    try out a different learning rateã€‚ of courseï¼Œ So this is usually one of the first
    things that we want to optimizeã€‚ So let's modify the learning rateã€‚ And now let's
    call the folder mistã€‚ Let's say simply2ã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»æ”¹è¿›ä¸€äº›ä¸œè¥¿ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ä¸åŒçš„å­¦ä¹ ç‡ã€‚å½“ç„¶ï¼Œè¿™é€šå¸¸æ˜¯æˆ‘ä»¬æƒ³è¦ä¼˜åŒ–çš„ç¬¬ä¸€ä»¶äº‹ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬ä¿®æ”¹å­¦ä¹ ç‡ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç§°è¿™ä¸ªæ–‡ä»¶å¤¹ä¸ºmistï¼Œç®€å•åœ°è¯´æ˜¯simply2ã€‚
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_20.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_20.png)'
- en: And then againï¼Œ let's clear this and run our script againã€‚Andã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_22.png)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå†æ¬¡ï¼Œè®©æˆ‘ä»¬æ¸…ç†è¿™ä¸ªå¹¶å†æ¬¡è¿è¡Œæˆ‘ä»¬çš„è„šæœ¬ã€‚å¹¶ä¸”ï¼[](img/ee3dacee23dcf8b95d479be89b099b38_22.png)
- en: Then this should already update our tenor board during theã€‚During the file runningsã€‚
    So now we see a second graphã€‚And also here we see a second graph in the loss graphã€‚
    Nowã€‚ let's reload this againã€‚ And now yeahï¼Œ it should be doneã€‚ And nowï¼Œ for exampleã€‚
    here we see then another graph with a different learning rateã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿™åº”è¯¥å·²ç»åœ¨æ–‡ä»¶è¿è¡ŒæœŸé—´æ›´æ–°äº†æˆ‘ä»¬çš„éŸ³è°ƒæ¿ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çœ‹åˆ°ç¬¬äºŒä¸ªå›¾è¡¨ã€‚è€Œä¸”åœ¨æŸå¤±å›¾è¡¨ä¸­æˆ‘ä»¬ä¹Ÿçœ‹åˆ°ç¬¬äºŒä¸ªå›¾è¡¨ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å†æ¬¡é‡æ–°åŠ è½½è¿™ä¸ªã€‚ç°åœ¨ï¼Œæ˜¯çš„ï¼Œåº”è¯¥å®Œæˆäº†ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œè¿™é‡Œæˆ‘ä»¬åˆçœ‹åˆ°ä¸€ä¸ªä¸åŒå­¦ä¹ ç‡çš„å›¾è¡¨ã€‚
- en: And this is how we can interactively optimize and analyze our modelã€‚And nowï¼Œ
    as a last thingã€‚ what I want to show you is how we can add a precision recall
    curveã€‚ So precision recall curve lets you understand your model performance under
    different threshold settingsã€‚ And this makes more sense in a binary classification
    problemã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•äº’åŠ¨åœ°ä¼˜åŒ–å’Œåˆ†ææˆ‘ä»¬çš„æ¨¡å‹ã€‚ç°åœ¨ï¼Œæœ€åä¸€ä»¶äº‹ï¼Œæˆ‘æƒ³å‘ä½ å±•ç¤ºçš„æ˜¯æˆ‘ä»¬å¦‚ä½•æ·»åŠ ç²¾ç¡®åº¦å¬å›æ›²çº¿ã€‚ç²¾ç¡®åº¦å¬å›æ›²çº¿è®©ä½ ç†è§£æ¨¡å‹åœ¨ä¸åŒé˜ˆå€¼è®¾ç½®ä¸‹çš„è¡¨ç°ã€‚åœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­ï¼Œè¿™æ›´æœ‰æ„ä¹‰ã€‚
- en: But if we analyze each class separately hereã€‚ Then we do have a binary classification
    problemã€‚ So let's add a precision recall curve for each class hereã€‚AndFor those
    of you who do not know what a precision and recall meanã€‚ then I have a link for
    you in the descriptionã€‚ So please check that outã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¦‚æœæˆ‘ä»¬åˆ†åˆ«åˆ†ææ¯ä¸ªç±»åˆ«ã€‚é‚£æˆ‘ä»¬ç¡®å®æœ‰ä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ã€‚å› æ­¤è®©æˆ‘ä»¬åœ¨è¿™é‡Œä¸ºæ¯ä¸ªç±»åˆ«æ·»åŠ ç²¾ç¡®ç‡-å¬å›æ›²çº¿ã€‚å¦‚æœä½ ä¸çŸ¥é“ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„å«ä¹‰ï¼Œæˆ‘åœ¨æè¿°ä¸­æœ‰ä¸€ä¸ªé“¾æ¥ã€‚è¯·æŸ¥çœ‹ä¸€ä¸‹ã€‚
- en: And now what we want to do here isã€‚ let's have a look at the official documentation
    hereã€‚ So I also I recommend that you check out this linkã€‚ So let's search for
    at PRã€‚ And then we see here we have the method at precision at PRr curveã€‚ So this
    adds a precision recall curveã€‚ And this needs the attack firstã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æƒ³è¦åšçš„æ˜¯ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®˜æ–¹æ–‡æ¡£ã€‚æˆ‘ä¹Ÿå»ºè®®ä½ æŸ¥çœ‹è¿™ä¸ªé“¾æ¥ã€‚è®©æˆ‘ä»¬æœç´¢ä¸€ä¸‹PRã€‚ç„¶åæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œæœ‰æ–¹æ³•at precision at PRæ›²çº¿ã€‚è¿™å°†æ·»åŠ ç²¾ç¡®ç‡-å¬å›æ›²çº¿ã€‚è¿™éœ€è¦é¦–å…ˆæ”»å‡»ã€‚
- en: and then it needs the labelsã€‚ and here we see the labels is the ground truth
    dataã€‚ So a binary label for each elementã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_24.png)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åéœ€è¦æ ‡ç­¾ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°æ ‡ç­¾æ˜¯å®é™…æ•°æ®ã€‚æ¯ä¸ªå…ƒç´ çš„äºŒå…ƒæ ‡ç­¾ã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_24.png)
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_25.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_25.png)'
- en: And then it needs the predictions and the predictions are the probability that
    an element be classified is trueã€‚ and the value should be between 0 and1ã€‚ So this
    is important hereã€‚ So we need to have the actual labels and also the predictions
    hereã€‚ All rightã€‚ So now let's go to the code and at a precision recall curve for
    each classã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åéœ€è¦è¿›è¡Œé¢„æµ‹ï¼Œé¢„æµ‹æ˜¯å…ƒç´ è¢«åˆ†ç±»ä¸ºçœŸçš„æ¦‚ç‡ï¼Œå€¼åº”åœ¨0åˆ°1ä¹‹é—´ã€‚å› æ­¤ï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ã€‚æˆ‘ä»¬éœ€è¦å®é™…æ ‡ç­¾ä»¥åŠè¿™é‡Œçš„é¢„æµ‹ã€‚å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç ï¼Œå¹¶ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›æ›²çº¿ã€‚
- en: So here in our evaluationã€‚ we want to create a list where we store our labelsã€‚
    So let's say labels equals an empty listã€‚ And also a list for the predictionsã€‚
    So pres equals an empty listã€‚ And then during the batch evaluationã€‚ So what we
    do hereã€‚ So for the labelsï¼Œ we can say labels stopped app penï¼Œ the actual labels
    is the predicted labelsã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›åˆ›å»ºä¸€ä¸ªå­˜å‚¨æ ‡ç­¾çš„åˆ—è¡¨ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾ç½®labelsç­‰äºä¸€ä¸ªç©ºåˆ—è¡¨ã€‚åŒæ ·ä¹Ÿéœ€è¦ä¸€ä¸ªé¢„æµ‹çš„åˆ—è¡¨ã€‚æ‰€ä»¥presç­‰äºä¸€ä¸ªç©ºåˆ—è¡¨ã€‚åœ¨æ‰¹è¯„ä¼°æœŸé—´ï¼Œæˆ‘ä»¬æ‰€åšçš„æ˜¯ã€‚å¯¹äºæ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥è¯´æ ‡ç­¾åœæ­¢è¿½åŠ ï¼Œå®é™…æ ‡ç­¾æ˜¯é¢„æµ‹æ ‡ç­¾ã€‚
- en: And now for theã€‚ğŸ˜Šã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_27.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¯¹äºã€‚ğŸ˜Šã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_27.png)
- en: Predictionsï¼Œ we have to be carefulã€‚ So for hereï¼Œ we need probabilities between
    0 and 1ã€‚And now here we get the outputs from our modelã€‚ And if we have a look
    at the neural net againã€‚ and we see that we have a linear layer at the endã€‚ So
    these are raw valuesã€‚ And here we even have a commentã€‚ So no activationctuaation
    and no softms at the endã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºé¢„æµ‹ï¼Œæˆ‘ä»¬å¿…é¡»å°å¿ƒã€‚å› æ­¤åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦çš„æ¦‚ç‡åœ¨0åˆ°1ä¹‹é—´ã€‚ç°åœ¨æˆ‘ä»¬ä»æ¨¡å‹ä¸­è·å¾—è¾“å‡ºã€‚å¦‚æœæˆ‘ä»¬å†æ¬¡æŸ¥çœ‹ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬ä¼šå‘ç°æœ€åæœ‰ä¸€å±‚çº¿æ€§å±‚ã€‚è¿™äº›æ˜¯åŸå§‹å€¼ã€‚è¿™é‡Œç”šè‡³æœ‰ä¸€ä¸ªè¯„è®ºã€‚æ‰€ä»¥æ²¡æœ‰æ¿€æ´»å’Œæ²¡æœ‰softmaxåœ¨æœ€åã€‚
- en: because in this caseï¼Œ this is applied in our loss function in the cross entropy
    lossã€‚ But nowã€‚ againï¼Œ in the evaluationï¼Œ we want to have actual probabilitiesã€‚Andã€‚If
    you've watched my tutorial about activationation functionsã€‚ then you know which
    activationation function we must use here to get the probabilitiesã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿™åº”ç”¨äºæˆ‘ä»¬çš„æŸå¤±å‡½æ•°ä¸­çš„äº¤å‰ç†µæŸå¤±ã€‚ä½†ç°åœ¨ï¼Œå†æ¬¡ï¼Œåœ¨è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬æƒ³è¦è·å–å®é™…æ¦‚ç‡ã€‚å¦‚æœä½ çœ‹è¿‡æˆ‘å…³äºæ¿€æ´»å‡½æ•°çš„æ•™ç¨‹ï¼Œä½ å°±çŸ¥é“åœ¨è¿™é‡Œå¿…é¡»ä½¿ç”¨å“ªç§æ¿€æ´»å‡½æ•°æ¥è·å¾—æ¦‚ç‡ã€‚
- en: And this is the soft max functionã€‚ So this  squeezes our values to be probabilities
    between 0 and 1ã€‚ So let's call the softms here explicitly for our outputsã€‚ And
    for thisï¼Œ let's import Fã€‚ So functionalã€‚ So let's say hereã€‚ğŸ˜Šï¼ŒLet's import torch
    dot Nï¼Œ N dot functionalï¼Œ S Fã€‚Capital Fã€‚And thenï¼Œ down hereã€‚We want to calculate
    the soft max for each output in our outputã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯softmaxå‡½æ•°ã€‚æ‰€ä»¥å®ƒå°†æˆ‘ä»¬çš„å€¼å‹ç¼©ä¸º0åˆ°1ä¹‹é—´çš„æ¦‚ç‡ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œæ˜ç¡®è°ƒç”¨softmaxç”¨äºæˆ‘ä»¬çš„è¾“å‡ºã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬å¯¼å…¥Fã€‚ä¹Ÿå°±æ˜¯åŠŸèƒ½æ€§ã€‚æˆ‘ä»¬è¿™é‡Œè®¾ç½®ã€‚ğŸ˜Šï¼Œè®©æˆ‘ä»¬å¯¼å…¥torch.dot
    Nï¼ŒN.dot.functionalï¼ŒSFã€‚å¤§å†™Fã€‚ç„¶åï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¸Œæœ›è®¡ç®—æ¯ä¸ªè¾“å‡ºçš„softmaxã€‚
- en: So let's use list comprehension for thisã€‚And let's call this classã€‚ğŸ¤¢ï¼Œå—¯ã€‚Predictions
    equalsã€‚ And now here we use list comprehension and call F dot soft maxã€‚ And then
    here we say of the outputã€‚ And then we do thisã€‚ We have also have to give it the
    dimensionã€‚ So let's say dimension equals along dimension 0ã€‚ And then we want to
    do this for output in outputsã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨åˆ—è¡¨æ¨å¯¼æ¥å®ç°è¿™ä¸ªã€‚æˆ‘ä»¬å°†å…¶å‘½åä¸ºç±»åˆ«ã€‚ğŸ¤¢ï¼Œå—¯ã€‚é¢„æµ‹ç­‰äºã€‚ç°åœ¨æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¹¶è°ƒç”¨Fç‚¹softmaxã€‚ç„¶åæˆ‘ä»¬è¯´è¾“å‡ºã€‚æ¥ç€æˆ‘ä»¬éœ€è¦ç»™å‡ºç»´åº¦ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾ç½®ç»´åº¦ç­‰äºæ²¿ç»´åº¦0ã€‚ç„¶åæˆ‘ä»¬å¸Œæœ›å¯¹æ¯ä¸ªè¾“å‡ºæ‰§è¡Œæ­¤æ“ä½œã€‚
- en: And then let's add this to ourï¼Œ what did we call it prettzã€‚ So prets dotï¼Œ a
    penã€‚ And then here class predictionsã€‚ And then when we are done with the for loopã€‚
    we want to convert this to a1zoã€‚ So here we say labels equalsã€‚ and then torch
    dot cut the labelsã€‚ So right nowï¼Œ this is a listã€‚ And when we want to concatenate
    all the elements in our list along one dimensionã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†è¿™ä¸ªæ·»åŠ åˆ°æˆ‘ä»¬çš„ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º prettz çš„å¯¹è±¡ä¸­ã€‚prets dotï¼Œä¸€æ”¯ç¬”ã€‚ç„¶ååœ¨è¿™é‡Œæ˜¯ç±»åˆ«é¢„æµ‹ã€‚å½“æˆ‘ä»¬å®Œæˆå¾ªç¯æ—¶ï¼Œæˆ‘ä»¬æƒ³è¦å°†å…¶è½¬æ¢ä¸º
    a1zoã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¯´ labels ç­‰äºã€‚ç„¶å torch dot cut è¿™äº›æ ‡ç­¾ã€‚ç°åœ¨è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚å½“æˆ‘ä»¬æƒ³è¦åœ¨ä¸€ä¸ªç»´åº¦ä¸Šè¿æ¥åˆ—è¡¨ä¸­çš„æ‰€æœ‰å…ƒç´ æ—¶ã€‚
- en: Into a one dimensional tenorã€‚ And for the predictionsï¼Œ we want to have a two
    dimensional tensorã€‚ So for eachã€‚For each classï¼Œ we want to stack the predictionsã€‚
    and then we want to concatenate thisã€‚ So we sayã€‚Prats equalsã€‚ And then here we
    say torch dot catã€‚ And then here we use list comprehension again and say torch
    dot stackã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢ä¸ºä¸€ç»´å¼ é‡ã€‚å¯¹äºé¢„æµ‹ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰ä¸€ä¸ªäºŒç»´å¼ é‡ã€‚å¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œæˆ‘ä»¬æƒ³è¦å †å é¢„æµ‹ã€‚ç„¶åæˆ‘ä»¬æƒ³è¦è¿æ¥å®ƒã€‚æ‰€ä»¥æˆ‘ä»¬è¯´ã€‚Prats ç­‰äºã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬è¯´ torch
    dot catã€‚æ¥ç€æˆ‘ä»¬å†æ¬¡ä½¿ç”¨åˆ—è¡¨æ¨å¯¼ï¼Œè¯´ torch dot stackã€‚
- en: And here we stack each batch and say four batch in our predictionsã€‚So you should
    check the the shape of these tensors for yourselfã€‚ So this has shapeã€‚ I think
    how manyã€‚ we haveï¼Œ I think 10000 samplesã€‚ So this is 10000 by one and this should
    be 10000 by 10ã€‚ So for each classï¼Œ we stacked it hereã€‚ and now when we are doneã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å †å æ¯ä¸ªæ‰¹æ¬¡ï¼Œå¹¶åœ¨é¢„æµ‹ä¸­è¯´å››ä¸ªæ‰¹æ¬¡ã€‚æ‰€ä»¥ä½ åº”è¯¥è‡ªå·±æ£€æŸ¥è¿™äº›å¼ é‡çš„å½¢çŠ¶ã€‚æˆ‘è®¤ä¸ºæœ‰å¤šå°‘ã€‚æˆ‘ä»¬æœ‰ï¼Œæˆ‘æƒ³æ˜¯10000ä¸ªæ ·æœ¬ã€‚æ‰€ä»¥è¿™æ˜¯10000ä¹˜ä»¥1ï¼Œè¿™åº”è¯¥æ˜¯10000ä¹˜ä»¥10ã€‚å¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå †å å®ƒã€‚ç°åœ¨å½“æˆ‘ä»¬å®Œæˆæ—¶ã€‚
- en: So now the last thing we have to do is to have the actual PR curveã€‚ So for thisï¼Œ
    we say classesã€‚ So our class labels in this caseï¼Œ it's just the range 10 because
    we have theã€‚Ditchitts from 0 to 9ã€‚ And now let's iterate over thisã€‚ So4 I in classesã€‚
    And then we say we get the labels I equalsã€‚ So this is where labels equals equals
    Iã€‚ And then the same thing with the predictions I equals the predictionsã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¿…é¡»åšçš„æœ€åä¸€ä»¶äº‹æ˜¯å¾—åˆ°å®é™…çš„ PR æ›²çº¿ã€‚å¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬è¯´ classesã€‚æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„ç±»åˆ«æ ‡ç­¾åªæ˜¯èŒƒå›´10ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ä»0åˆ°9çš„æ•°å€¼ã€‚ç°åœ¨æˆ‘ä»¬è¿­ä»£è¿™ä¸ªã€‚æ‰€ä»¥4
    I åœ¨ classes ä¸­ã€‚ç„¶åæˆ‘ä»¬è¯´æˆ‘ä»¬å¾—åˆ°çš„ labels I ç­‰äºã€‚è¿™é‡Œçš„ labels ç­‰äº Iã€‚ç„¶åé¢„æµ‹çš„åŒæ ·æ“ä½œï¼Œé¢„æµ‹ I ç­‰äºé¢„æµ‹ã€‚
- en: And here we want to have all the samplesã€‚ But only for the class Iã€‚ And then
    we call writer dot atã€‚ And this is called at PR curveã€‚And this needs a tagã€‚ So
    for the tagã€‚ we just use the class label as stringã€‚ And then here we have theã€‚Labels
    firstã€‚ and then the predictionsã€‚ So predictions Iï¼Œ and then as global global stepï¼Œ
    we just use0ã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬æƒ³è¦è·å–æ‰€æœ‰æ ·æœ¬ã€‚ä½†ä»…é’ˆå¯¹ç±»åˆ« Iã€‚ç„¶åæˆ‘ä»¬è°ƒç”¨ writer dot atã€‚è¿™ç§°ä¸º PR æ›²çº¿ã€‚è¿™ä¸ªéœ€è¦ä¸€ä¸ªæ ‡ç­¾ã€‚å¯¹äºæ ‡ç­¾ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨ç±»åˆ«æ ‡ç­¾ä½œä¸ºå­—ç¬¦ä¸²ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬æœ‰ã€‚é¦–å…ˆæ˜¯æ ‡ç­¾ï¼Œç„¶åæ˜¯é¢„æµ‹ã€‚æ‰€ä»¥é¢„æµ‹
    Iï¼Œç„¶åä½œä¸ºå…¨å±€æ­¥éª¤ï¼Œæˆ‘ä»¬å°±ç”¨0ã€‚
- en: And then let's call writer dot closeã€‚ And then we are doneã€‚ So now let's save
    this and run our script one more timeã€‚And now when this is doneã€‚ and we should
    see precision recall curve for each of the class labelsã€‚Soã€‚Almost doneã€‚ And a
    penã€‚ So I have a typo hereã€‚So I have two different labels variablesã€‚ So let's
    call thisã€‚å—¯ã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è°ƒç”¨ writer dot closeã€‚è¿™æ ·æˆ‘ä»¬å°±å®Œæˆäº†ã€‚ç°åœ¨ä¿å­˜è¿™ä¸ªå¹¶å†æ¬¡è¿è¡Œæˆ‘ä»¬çš„è„šæœ¬ã€‚å®Œæˆåï¼Œæˆ‘ä»¬åº”è¯¥èƒ½çœ‹åˆ°æ¯ä¸ªç±»åˆ«æ ‡ç­¾çš„ç²¾ç¡®å¬å›æ›²çº¿ã€‚æ‰€ä»¥ï¼Œå·®ä¸å¤šå®Œæˆäº†ã€‚è¿˜æœ‰ä¸€æ”¯ç¬”ã€‚æˆ‘è¿™é‡Œæœ‰ä¸ªæ‹¼å†™é”™è¯¯ã€‚æˆ‘æœ‰ä¸¤ä¸ªä¸åŒçš„æ ‡ç­¾å˜é‡ã€‚æˆ‘ä»¬å°±å«è¿™ä¸ªã€‚å—¯ã€‚
- en: Let's just call this labels 1 hereã€‚ So labels1 and labels 1 and labels1ã€‚And
    nowã€‚Let's run this one more timeã€‚Sorry about thatã€‚So let's clear this and run
    this one more timeã€‚And now againï¼Œ we have to go through the training pipelineã€‚Ohï¼Œ
    I didn't save itã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™é‡Œå°±å«è¿™ä¸ª labels 1ã€‚è¿™æ · labels1 å’Œ labels 1 ä»¥åŠ labels1ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å†è¿è¡Œä¸€æ¬¡ã€‚æŠ±æ­‰ã€‚æˆ‘ä»¬å…ˆæ¸…ç†ä¸€ä¸‹ï¼Œå†è¿è¡Œä¸€æ¬¡ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬åˆå¾—ç»è¿‡è®­ç»ƒç®¡é“ã€‚å“¦ï¼Œæˆ‘æ²¡ä¿å­˜ã€‚
- en: '![](img/ee3dacee23dcf8b95d479be89b099b38_29.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee3dacee23dcf8b95d479be89b099b38_29.png)'
- en: Alrightï¼Œ so now we are doneï¼Œ So let's reload our tensor board one more timeã€‚And
    now we have one more entry up hereã€‚ and this is the PR curveã€‚ And now we should
    see the precision recall curves for each of our class labelã€‚ So here we have label
    0ï¼Œ label 1 and so onã€‚And then we can inspect the precision and the recall for
    the different thresholdsã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œç°åœ¨æˆ‘ä»¬å®Œæˆäº†ã€‚è®©æˆ‘ä»¬å†é‡æ–°åŠ è½½ä¸€æ¬¡ tensor boardã€‚ç°åœ¨æˆ‘ä»¬è¿™é‡Œæœ‰ä¸€ä¸ªæ–°çš„æ¡ç›®ã€‚è¿™æ˜¯ PR æ›²çº¿ã€‚ç°åœ¨æˆ‘ä»¬åº”è¯¥çœ‹åˆ°æ¯ä¸ªç±»åˆ«æ ‡ç­¾çš„ç²¾ç¡®å¬å›æ›²çº¿ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æœ‰æ ‡ç­¾0ã€æ ‡ç­¾1ç­‰ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ä¸åŒé˜ˆå€¼ä¸‹çš„ç²¾ç¡®åº¦å’Œå¬å›ç‡ã€‚
- en: So here on the y axissï¼Œ we have the precision and on the x axisï¼Œ we have the
    recallã€‚ And thenã€‚ for exampleï¼Œ for each for different thresholds we can analyze
    it and see how many true positivesã€‚ how many false positivesï¼Œ how many true negatives
    and false negatives we haveã€‚So this is also really helpful to analyze the modelã€‚And
    yeahã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨yè½´ä¸Šï¼Œæˆ‘ä»¬æœ‰ç²¾ç¡®åº¦ï¼Œåœ¨xè½´ä¸Šï¼Œæˆ‘ä»¬æœ‰å¬å›ç‡ã€‚ç„¶åï¼Œä¾‹å¦‚ï¼Œå¯¹äºä¸åŒçš„é˜ˆå€¼ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†æä¸€ä¸‹ï¼Œçœ‹çœ‹æœ‰å¤šå°‘ä¸ªçœŸæ­£é˜³æ€§ï¼Œæœ‰å¤šå°‘ä¸ªå‡é˜³æ€§ï¼Œæœ‰å¤šå°‘ä¸ªçœŸæ­£é˜´æ€§å’Œå‡é˜´æ€§ã€‚å› æ­¤ï¼Œè¿™å¯¹åˆ†ææ¨¡å‹ä¹Ÿéå¸¸æœ‰å¸®åŠ©ã€‚æ²¡é”™ã€‚
- en: so that's all I wanted to show you for the Tenser boardã€‚ I hope you enjoyed
    this tutorialã€‚ and please consider subscribing to the channel and see you next
    timeï¼Œ byeã€‚ğŸ˜Šã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_31.png)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘æƒ³å±•ç¤ºç»™ä½ çš„å…³äºTensoræ¿çš„æ‰€æœ‰å†…å®¹ã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ã€‚è¯·è€ƒè™‘è®¢é˜…é¢‘é“ï¼Œä¸‹ä¸€æ¬¡å†è§ï¼Œæ‹œæ‹œã€‚ğŸ˜Šã€‚![](img/ee3dacee23dcf8b95d479be89b099b38_31.png)
