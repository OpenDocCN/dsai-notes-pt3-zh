- en: 【双语字幕+资料下载】PyTorch 极简实战教程！全程代码讲解，在实践中掌握深度学习&搭建全pipeline！＜实战教程系列＞ - P17：L17-
    保存和加载模型 - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】PyTorch 极简实战教程！全程代码讲解，在实践中掌握深度学习&搭建全pipeline！＜实战教程系列＞ - P17：L17-
    保存和加载模型 - ShowMeAI - BV12m4y1S7ix
- en: Hey， guys， welcome to a new Pytorch tutorial Today。 I want to show you how we
    can save and load our model。 I will show you the different methods and safe options
    you have to know。 And also what you have to consider when you are using a GP U。
    So let's start。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嘿，大家，欢迎来到新的Pytorch教程。今天我想展示如何保存和加载我们的模型。我会展示你必须知道的不同方法和保存选项，以及在使用GPU时需要考虑的事项。那么，我们开始吧。
- en: These are the only three different methods you have to remember。 So we have
    torch dot safe。 then torch dot load and model dot load state dit。😊，And these are
    all the methods we must remember。 and I will show you all of them in detail。 So
    Torch dot Sa here can use tenor models or any dictionary as parameter for saving。
    So you should know here that we can save any dictionary with it。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种不同的方法你必须记住。所以我们有torch.dot.safe，接着是torch.dot.load和model.dot.load.state_dit。😊这些都是我们必须记住的方法，我会详细展示所有这些方法。torch.dot.Sa这里可以使用tensor模型或任何字典作为保存参数。所以你应该知道我们可以用它保存任何字典。
- en: And I will show you how we can use this later in our training pipeline。😊。So
    torch doa then makes use of Python's pickle module to serialize the objects and
    saves them。 So the result is serialized and not human readable。And now for saving
    our model。 we have two options。 The first one is the lazy method。 So we just call
    torch do save on our model。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我会展示如何在训练管道中后续使用这些。😊所以torch doa然后利用Python的pickle模块来序列化对象并保存它们。结果是序列化的，不可读。而现在保存我们的模型，我们有两种选择。第一种是懒惰的方法。我们只需在模型上调用torch.do.save。
- en: and we also have to specify the path or the file name。 And then later。 when
    we want to load our model， we just set up our model by saying model equals torch
    do load and then the file name again。 And then we also want to set our model to
    evaluation method。 So by saying model do evil。 So this is the lazy option。 and
    the disadvantage of this approach is that the serialized data is bound to the
    specific classes and the exact directory structure that is used when the model
    is saved。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须指定路径或文件名。然后，当我们想加载模型时，只需设置模型，方法是model等于torch.do.load，再加上文件名。接着，我们还想将模型设置为评估模式，所以可以说model.do.evil。这是懒惰的方法，这种方法的缺点是序列化数据与模型保存时使用的特定类和确切目录结构绑定在一起。
- en: So there is a second option， which is the recommended way of saving our model。😊。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_1.png)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 还有第二个选项，这是推荐的保存模型方式。😊![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_1.png)
- en: If we just want to save our model， our trained model and use it later for interference。
    then it is enough to only save the parameters。 And as you should remember。 we
    can save any dictionary with torcha。So we can save the parameters by calling torch
    dot save and then model dot state di。 So this holds the parameters and then the
    path。And then later。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想保存我们的模型、训练好的模型，并在之后进行推理，那么只需保存参数即可。你应该记得，我们可以用torcha保存任何字典。所以我们可以通过调用torch.dot.save，然后model.dot.state_di来保存参数。因此，这里持有参数和路径，然后在之后使用。
- en: when we want to load our model again first， we have to create the model object。
    and then we call model dot load state dit。 And then inside this。 we call torch
    dot load path。 So be careful here since load state di doesn't take a only a path。
    but instead it takes the loaded dictionary year。 And then again。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想再次加载模型时，首先必须创建模型对象，然后调用model.dot.load.state_dit。在这里，我们调用torch.dot.load路径。注意，load.state_di不仅接受路径，还接受加载的字典年。
- en: we set our model to evaluation mode。 So this is the preferred way that you should
    remember。 And now let's jump to the code to see the different saving ways in practice。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_3.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将模型设置为评估模式。这是你应该记住的首选方式。现在让我们跳到代码中，看看实践中的不同保存方式。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_3.png)
- en: So here I have a little script where I defined a small model class and here
    I created our model and now let me show you the lazy method first。 So first we
    define our file name so we say file equals and let's call this model do p So it's
    come and practice to use the ending dot p so short for pytorrch and then we save
    the whole model by saying torch do save and then model and the file So let's save
    this and let's run the script So let's say Python save load do pi and now if we
    open up our browser So we can ignore this warning here then we see here we have
    the model do p。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我有一个小脚本，其中我定义了一个小模型类，在这里我创建了我们的模型，现在让我先给你展示懒惰的方法。所以首先我们定义我们的文件名，所以我们说文件等于，让我们称之为模型do
    p，所以它是个好习惯使用结尾.dot p，缩写为pytorch。然后我们通过说`torch.save`来保存整个模型，然后是模型和文件。所以让我们保存这个并运行脚本。所以我们说Python
    save load do pi，现在如果我们打开浏览器，我们可以忽略这个警告，然后我们看到我们有模型do p。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_5.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_5.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_6.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_6.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_7.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_7.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_8.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_8.png)'
- en: In the Exper。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_10.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在Exper。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_10.png)
- en: And if we open this， then we see that this is some serialase data， so this is
    not human readable。And now if we go back to our code。 So let's load our model
    so we can comment this out。 and we also can comment this out。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_12.png)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打开这个，我们会看到这是一部分序列化数据，因此这是不可读的。现在如果我们回到我们的代码。我们加载我们的模型，所以我们可以注释掉这个。我们也可以注释掉这个。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_12.png)
- en: And then we can load our model by saying， model equals。Equals torch dot load。
    and then the file。 And then remember， we want to set it to evaluation method。So
    we say model dot evil。 and then we can use our model。 For example， we can inspect
    the parameters。 So let's say for Para in model dot parameters。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以通过说，模型等于来加载我们的模型。等于`torch.load`，然后是文件。然后记住，我们想要设置为评估模式。所以我们说模型.dot evil。然后我们可以使用我们的模型。例如，我们可以检查参数。所以我们假设对于Para在模型的参数中。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_14.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_14.png)'
- en: And then， let's print our Para。And save this。 And let's。Clear this and run our
    script again。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_16.png)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们打印我们的Para。并保存这个。然后让我们清除这个并再次运行我们的脚本。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_16.png)
- en: And let me make this larger for you。 So now if we run our script again。 then
    we can see that we loaded our model and we can use the parameters。So this is the
    lazy option。 And now， let me show you the preferred way of doing this。 So instead
    of just saying torch dot save model here and what we instead want to do is to
    say torch dot save。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我把这个放大给你看。所以现在如果我们再次运行我们的脚本，那么我们可以看到我们加载了模型并可以使用参数。所以这是懒惰选项。现在，让我给你展示做这件事的首选方式。所以不是仅仅说`torch.save
    model`，而是我们想要做的是说`torch.save`。
- en: and then we want to save the state dit。 So here we have our model again。 And
    then we say torch dot model dot。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_18.png)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们想要保存状态字典。所以这里我们再次有我们的模型。然后我们说`torch.model.`。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_18.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_19.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_19.png)'
- en: Tarch dotafe model dot state。State diiced。And then， let's run this。So， let me
    clear this。And let's open up the Explorer and delete this file here。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_21.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.save model.state dict`。然后，让我们运行这个。所以，让我清除这个。然后打开资源管理器，删除这个文件。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_21.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_22.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_22.png)'
- en: And now if we run our script again， then we again have the file。 But now here
    it only save the state dictates。 And now if we want to load our model again。 we
    first have to define it。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_24.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们再次运行脚本，那么我们又有文件。但现在它只保存状态字典。现在如果我们想要再次加载模型，我们首先必须定义它。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_24.png)
- en: So let's call this loaded model。Loaded model。Equals。 and then let's also say
    the model and the number of input features is the same。 So it's 6。 And then we
    call loaded model dot load state di。 And inside this。 Remember。 we have to call
    torch dot load。 and then the file name。 And then again。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们称这个为加载的模型。加载的模型。等于。然后我们还说模型和输入特征的数量是相同的。所以是6。然后我们调用加载的模型.dot load state
    dict。在里面。记住，我们必须调用`torch.load`，然后是文件名。然后再次。
- en: we set our loaded model to evaluation mode。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_26.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载的模型设置为评估模式。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_26.png)
- en: And then if we run this， So let's print the parameterss of the loaded model。
    And up here。 let's also print the parameterss of our normal model。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_28.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后如果我们运行这个，所以让我们打印加载模型的参数。再上面，*让我们也打印一下我们正常模型的参数*。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_28.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_29.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_29.png)'
- en: So this， if we don't do any training here， Then our model is still initialized
    with some random parameters。 So let's run the script and let's check if the parameters
    are the same。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_31.png)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们在这里不进行任何训练，那么我们的模型仍然会初始化为一些随机参数。所以让我们运行脚本，检查参数是否相同。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_31.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_32.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_32.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_33.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_33.png)'
- en: So here， yeah， we see that it worked。 and it first printed the parameters of
    the model of the normal model。 and then here of the loaded model。 So these are
    the same。 So we see we have a tenzo with the weights。 and we also have a tenzo
    with the bias。 and this is the same for both of our model。 So we see that this
    worked， too。 So yeah， again。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这里，我们看到它成功了。它首先打印了正常模型的参数，然后是加载模型的参数。所以这些是相同的。所以我们看到有一个包含权重的张量，还有一个包含偏置的张量，这对我们的两个模型都是一样的。所以我们看到这也成功了。所以是的，再次。
- en: so this is the recommended way of doing it by saying safe dot model state diict。
    And then when we load it， we call a load state dict method。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_35.png)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是推荐的做法，通过调用`safe dot model state dict`。然后当我们加载它时，我们调用一个`load state dict`方法。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_35.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_36.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_36.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_37.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_37.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_38.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_38.png)'
- en: And yeah， so here we just save the state di。 So this holds the parameters。 So
    let me show you how this state dit looks like。 So when we have our model。 let's
    print model dot state。😊。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_40.png)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，所以在这里我们只是保存状态字典。所以这保存了参数。让我展示一下这个状态字典的样子。所以当我们有我们的模型时，让我们打印`model.state`。😊！[](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_40.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_41.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_41.png)'
- en: Dickt， and let's save this。And let's clear this and run the script。 Then we
    see here we have our state dick。 So here we have the linear weight。 which has
    the tenzo with the weights。 And then we also have the。Bastenzor。 So this is our
    state dic。And now let me show you a common way of saving a whole checkpoint during
    training so as you know。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，*让我们保存这个*。接下来清除这个并运行脚本。然后我们看到这里有我们的状态字典。因此这里我们有线性权重，包含权重的张量。接下来我们还有一个张量。所以这就是我们的状态字典。现在让我给你展示一个在训练期间保存整个检查点的常见方法，正如你所知道的。
- en: we can save any dictionary here。So let's say we also have a optimizer here。
    So let's say we defined a learning rate。 So let's say this is 0001。 And we also
    have a optr。 This is， let's say， torch dot optim。Dot。Let's use stochastic gradient
    descent。 And here we want to optimize the model parameters。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里保存任何字典。假设我们在这里也有一个优化器。假设我们定义一个学习率。设为`0.0001`。我们还有一个优化器。假设这是`torch.optim`，让我们使用随机梯度下降。在这里我们想优化模型参数。
- en: and we will also have to give it the learning rate by saying learning rate equals
    the learning rate and our optimizer also has a state di。 So we can also print
    the optimizer state di。 Now， if we clear this and run this。 then we see the state
    dictionary of the optimizer where we can see， for example。 the learning rate and
    the momentum。So now during training。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要给它学习率，设置为`learning rate = learning rate`，我们的优化器也有一个状态字典。因此我们也可以打印优化器的状态字典。现在，如果我们清除这个并运行这个。那么我们看到优化器的状态字典，其中可以看到，例如，学习率和动量。因此现在在训练过程中。
- en: let's say we want to stop somewhere at some point during training and save a
    checkpoint。 Then we can do it like this， so。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_43.png)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想在训练过程中某个时刻暂停并保存一个检查点。那么我们可以这样做，所以下面是！[](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_43.png)
- en: We create our checkpoint， and this must be a dictionary。 So let's create a dictionary。
    And as a first thing， what we want to save is， for example， the epoch。 So let's
    define the epoch。 So the key is called epoch。 And let's say we are just， we are
    an epoch 90。 And then we want to save the model state。 So we have to give it a
    key。 let's say model state。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建我们的检查点，这必须是一个字典。所以我们来创建一个字典。首先，我们想保存的内容是，比如说，纪元。所以我们来定义这个纪元。键叫做epoch。假设我们正处于第90个纪元。然后我们想保存模型状态。所以我们必须给它一个键。假设是model
    state。
- en: And here we use model dot state diict。And then we also want to save the optimizer
    state dick。 So the key， let's say， optim state。 And then here as a value， we have
    to call optr state dick。 So this is our checkpoint。 And now we can call torch
    dot save。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们使用模型的状态字典。然后我们还想保存优化器状态字典。键，假设为optim state。然后这里的值，我们必须调用optr state字典。所以这是我们的检查点。现在我们可以调用torch
    dot save。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_45.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_45.png)'
- en: And then save the whole checkpoint。 So let's say torch checkpoint as， as a file
    name。 Let's call this check。Point dot P， T H。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_47.png)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后保存整个检查点。所以假设torch checkpoint作为文件名。我们称这个为check.Point dot P， T H。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_47.png)
- en: And now again， let me show you the explorer and let's run the script。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_49.png)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在再次，让我给你看看资源管理器，运行脚本。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_49.png)
- en: So now we clear this and run this。 Then we see we have our checkpoint here。
    And now。 when we load this， we want to load the whole checkpoint， so。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_51.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们清除这个并运行它。然后我们看到这里有我们的检查点。现在，当我们加载这个时，我们想加载整个检查点，所以。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_51.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_52.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_52.png)'
- en: We can comment this out。 And also， we don't need this， so。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_54.png)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以注释掉这个。同时，我们也不需要这个，所以。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_54.png)
- en: Let's say our loaded checkpoint。 So let's say， loaded checkpoint。Equals torch
    dot load。 And then the file name was the same as this one。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_56.png)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的加载检查点。假设，loaded checkpoint等于torch dot load。然后文件名与这个相同。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_56.png)
- en: And now you have to set up the different。Model and optimizes again。 so we can
    get the epoch right away by saying epoch equals load at checkpoint。 So this is
    a dictionary。 so we can just。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_58.png)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你必须重新设置不同的模型和优化器，以便我们可以立即获得纪元，方法是说epoch等于load at checkpoint。这是一个字典，所以我们可以直接。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_58.png)
- en: Call the。Or access the epoch key。 And then for the model。 remember。 we have
    to create our model here again。 So let's say model equals。 and then the model
    with the number of input features equals 6 and the optimizer equals the same as
    this one。 So we don't have to use the same learning rate actually。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 调用。或者访问纪元键。然后对于模型。记住。我们必须在这里再次创建我们的模型。所以假设模型等于。然后模型的输入特征数量等于6，优化器与这个相同。实际上我们不必使用相同的学习率。
- en: So let me just grab this one here and paste it down here。 And for example。 we
    can use the learning rate 0。 And then later， we can see that we load the correct
    learning rate into the optimizer。 So。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_60.png)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我把这个复制过来，粘贴在这里。例如。我们可以使用学习率0。然后稍后，我们可以看到我们将正确的学习率加载到优化器中。所以。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_60.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_61.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_61.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_62.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_62.png)'
- en: Now， let's say model dot load state。Dicks， and then here we give it the checkpoint。
    and then we access the key。 We call it model state。 So this will load all the
    parameters into our model。 and the same with our optimizer。 So we call optimizer
    dot load state dis。 and then we use the checkpoint。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设模型加载状态。然后这里我们给它检查点。然后我们访问键。我们称之为model state。所以这将加载所有参数到我们的模型中。优化器也是如此。我们称优化器为load
    state dis。然后使用检查点。
- en: And here we call it optim state。 So now we have the loaded model and the optr
    and also the current epoch。 So we can continue our training。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_64.png)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们称它为optim state。所以现在我们有了加载的模型和优化器，以及当前的纪元。所以我们可以继续训练。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_64.png)
- en: And let me show you that this is all correct by saying we want to print the
    optimizer dot state di。 So if you notice here， we set the learning rate to 0 and
    then we loaded the correct state di。 So now if we run this。 And as a last thing，
    we printed the optimizer state di。 then we see we have the same learning rate
    as in the initial optimizer。 So this work2。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我通过打印优化器的 `state_dict` 来验证这一切是否正确。所以如果你注意到，我们将学习率设置为 0，然后加载了正确的 `state_dict`。现在如果我们运行这个。最后，我们打印了优化器的
    `state_dict`，然后看到我们有与初始优化器相同的学习率。因此这有效。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_66.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_66.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_67.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_67.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_68.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_68.png)'
- en: So this is how we can save and load a whole checkpoint。 And yeah。 these are
    all the three ways of saving you have to know。 And now as a last thing。 I want
    to show you what you have to consider when you are using a GPU during training。
    So if you are doing training and loading both on the CPU then you don't have to
    make any difference。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何保存和加载整个检查点。是的，这三种保存方法你必须知道。最后，我想告诉你在使用 GPU 进行训练时需要考虑的事项。如果你在 CPU 上进行训练和加载，那么你不需要做任何区别。
- en: So you can just use it like I did here， But now if you save your model on the
    GP。 And then later you want to load it on the CPU， then you have to do it this
    way。 So let's say somewhere during your training， you set up your ka device and
    you send your model to the device and then you save it by using the state d。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以像我在这里做的那样使用它，但如果你在 GPU 上保存模型，然后稍后想在 CPU 上加载，那么你必须这样做。假设在你训练的某个时刻，你设置了 CUDA
    设备并将模型发送到设备，然后通过使用 `state_dict` 保存它。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_70.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_70.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_71.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_71.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_72.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_72.png)'
- en: And then you want to load it to the CPU。 So you have your CPU device。 then you
    create your model again， and then you call load state died and then load path。
    And here you have to specify the map location。 And here you give it the CPU device。
    So this is if you want to save on the GP and load on the CPU。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你想要加载到 CPU。所以你有你的 CPU 设备，然后重新创建模型，再调用 `load_state_dict` 和加载路径。在这里你必须指定映射位置，并给它
    CPU 设备。如果你想在 GPU 上保存并在 CPU 上加载，就这样做。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_74.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_74.png)'
- en: Now， if you want to do both on the GPU。 So you send your model to the Kuda device
    and saved it。 and then you also want to load it on the GPU， then you just do it
    like this。 So you。Set up your model， you load the state di， and then you send
    your model to the Kuda device。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你想在 GPU 上同时进行这两项操作。你将模型发送到 CUDA 设备并保存，然后你也想在 GPU 上加载它，你只需这样做。设置你的模型，加载
    `state_dict`，然后将模型发送到 CUDA 设备。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_76.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_76.png)'
- en: And now as a third option。 So let's say you saved your model on the CPU。 So
    you didn't send。 you didn't call model to Kuda device somewhere。 But then later，
    during loading。 you want to load it to the GP， you have to do it like this。 So
    first you specify your Ka device。 Then you create your model。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在作为第三个选项。假设你在 CPU 上保存了模型，所以你没有将模型发送到 CUDA 设备上。但后来在加载时，你想将其加载到 GPU 上，你必须这样做。首先，你指定你的
    CUDA 设备，然后创建你的模型。
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_78.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_78.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_79.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_79.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_80.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_80.png)'
- en: And then you call model dot load date diiced and then torch load with the path
    and then as map location。 you specify Kuda and then colon and then any GPU device
    number you want。 So for example。 Kuda colon0。 and then also you have to call model
    to device So to the ka device。 So this will send the model to device to the device
    and also all the loaded parameter tenzoos to the device So then you can continue
    with your training or interference on the GPU。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你调用模型的 `load_state_dict`，接着用路径调用 `torch.load`，并指定映射位置。你需要指定 CUDA，然后是冒号，再加上你想要的任何
    GPU 设备编号。例如，CUDA:0。然后你还需要调用模型到设备，所以指定到 CUDA 设备。这会将模型和所有加载的参数张量发送到设备上。这样你就可以继续在
    GPU 上进行训练或推理。
- en: and of course， you also have to send all the training samples to the device
    that you then use for the forward path。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_82.png)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你还必须将所有训练样本发送到用于前向传播的设备上。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_82.png)
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_83.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_83.png)'
- en: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_84.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_84.png)'
- en: So yeah， this is what you have to consider when you're using a GPU。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_86.png)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，是的，当你使用GPU时，这些是你需要考虑的事项。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_86.png)
- en: And now， you know all the different ways of saving and loading your model。 And
    yeah。 that's all for now。 I hope you enjoyed this tutorial。 And if you like this
    then please consider subscribing to the channel and see you next time， bye。😊。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_88.png)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你了解了保存和加载模型的各种方法。 是的，这就是目前为止的所有内容。 希望你喜欢这个教程。如果你喜欢，请考虑订阅频道，下次见，再见。😊。![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_88.png)
