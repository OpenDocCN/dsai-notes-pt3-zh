# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P3ï¼šL3- æ¨¡å‹å’Œåˆ†è¯å™¨ - ShowMeAI - BV1cF411v7kC

Let's see how we can use this model and tokenizer directly and do some of the steps manuallyã€‚ this will give you a little bit more flexibilityã€‚ So down hereã€‚ let's first use the tokenizer and see what this doesã€‚ So firstã€‚ let's call the tokenizer dot tokenize functionã€‚ So we sayã€‚

 let's call the tokens and then equals tokenizer dot tokenize and then the string or the sentence we want to tokenizeã€‚ So let's copy and paste this in hereã€‚ And then once we get the tokensã€‚ we can use them and get the token Is out of itã€‚ So we can say token Is equalsã€‚ And then we again use the tokenizer and the function convert tokenizer toã€‚ğŸ˜Šã€‚



![](img/4e0ddcb38791825272bb7f961349fc05_1.png)

![](img/4e0ddcb38791825272bb7f961349fc05_2.png)

![](img/4e0ddcb38791825272bb7f961349fc05_3.png)

![](img/4e0ddcb38791825272bb7f961349fc05_4.png)

![](img/4e0ddcb38791825272bb7f961349fc05_5.png)

![](img/4e0ddcb38791825272bb7f961349fc05_6.png)

![](img/4e0ddcb38791825272bb7f961349fc05_7.png)

![](img/4e0ddcb38791825272bb7f961349fc05_8.png)

Called Isã€‚ And then it meet the tokensã€‚ So this is one way how to do thisã€‚ Or we can do this directly by saying token I equalsã€‚ And then we call this tokenizer like a functionã€‚ And then againï¼Œ we give it the same string hereã€‚ So now let's print all these three variables to see where is the differenceã€‚

 So first we print the tokensï¼Œ then we print the token Isã€‚ And then here let's actually give this a different nameã€‚ So let's call this input Iã€‚ So now let's run this and see how this looks likeã€‚ Alrightï¼Œ so here is the resultã€‚ So as you can see when we call tokenizer dot tokenizeï¼Œ then we get a list of stringsã€‚



![](img/4e0ddcb38791825272bb7f961349fc05_10.png)

![](img/4e0ddcb38791825272bb7f961349fc05_11.png)

![](img/4e0ddcb38791825272bb7f961349fc05_12.png)

![](img/4e0ddcb38791825272bb7f961349fc05_13.png)

![](img/4e0ddcb38791825272bb7f961349fc05_14.png)

![](img/4e0ddcb38791825272bb7f961349fc05_15.png)

![](img/4e0ddcb38791825272bb7f961349fc05_16.png)

![](img/4e0ddcb38791825272bb7f961349fc05_17.png)

The list of the words backs so now each word is a sorry each word is a separate token and for exampleã€‚ this one is our smiley face or our emoji So yeah this is what the tokenized function does and then once we call this convert tokens to IDs we get this one back so now it converted each token to an ID so each word has a very unique ID and this is basically the mathematical representation or the numerical representation that our model then can understand So this is what we get after this function and if we call this tokenr directly then we get a dictionary back and here we have the key input Is and we also have the attention mask soã€‚



![](img/4e0ddcb38791825272bb7f961349fc05_19.png)

For now you don't really have to worry about this but let's have a look at the input IDs so if we compare the token IDs with the input IDs then we see we have the exact same sequence of token IDs but we also have this 101 and 102 token and this is just the beginning of string and the end of string token but basically it's the same so yeah this is the difference between these three functions and then these input IDs this is what we can pass to our model later to do the predictions manually so now like before we can also use multiple sentences of course for our tokenr so for example usually in your code you have your training data so let's say xtrain and in this example let's justã€‚



![](img/4e0ddcb38791825272bb7f961349fc05_21.png)

![](img/4e0ddcb38791825272bb7f961349fc05_22.png)

![](img/4e0ddcb38791825272bb7f961349fc05_23.png)

![](img/4e0ddcb38791825272bb7f961349fc05_24.png)

Use these two sentencesã€‚ So this is our X train and then we and then we can pass this to our tokenizer and let's call this batchã€‚ So this is our batch that we put into our model laterã€‚ So we say batch equals tokenizer and then we call this tokenizer directly with our training dataã€‚ and then I also want to show you some useful argumentã€‚ So we say padding equals trueã€‚

 and we also say truncation equals trueã€‚ and then we say max length equals 412ã€‚ and we say return tenss equals and then as a string P for pi torchã€‚ So this will ensure that all of our samples in our batch have the same lengthã€‚ So it will apply padding and truncationã€‚

![](img/4e0ddcb38791825272bb7f961349fc05_26.png)

![](img/4e0ddcb38791825272bb7f961349fc05_27.png)

![](img/4e0ddcb38791825272bb7f961349fc05_28.png)

![](img/4e0ddcb38791825272bb7f961349fc05_29.png)

![](img/4e0ddcb38791825272bb7f961349fc05_30.png)

![](img/4e0ddcb38791825272bb7f961349fc05_31.png)

Necessary and this is also importantã€‚ So in this caseã€‚ we want to have a pytorch tenor returned directlyã€‚ So I will show you later what's the difference if you don't use thisã€‚ But for now let's just use this and then first of allã€‚ let's print this batch and see how this looks likeã€‚ And then we see we get a dictionary and again it has the key input Is and the key attention mask and then here it has two tenzosã€‚ So the first one for the first sentence and the second one for the second sentence and the same for the attention mask So two tensã€‚ So yeah as I saidï¼Œ these input id are these unique Is that our model can understandã€‚

 So yeah now we have this batch and now we can pass this to our modelã€‚![](img/4e0ddcb38791825272bb7f961349fc05_33.png)

![](img/4e0ddcb38791825272bb7f961349fc05_34.png)

![](img/4e0ddcb38791825272bb7f961349fc05_35.png)

![](img/4e0ddcb38791825272bb7f961349fc05_36.png)

Andã€‚