- en: 【双语字幕+资料下载】官方教程来啦！5位 Hugging Face 工程师带你了解 Transformers 原理细节及NLP任务应用！＜官方教程系列＞
    - P19：L3.2- 预处理句对数据(PyTorch) - ShowMeAI - BV1Jm4y1X7UL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】官方教程来啦！5位 Hugging Face 工程师带你了解 Transformers 原理细节及NLP任务应用！＜官方教程系列＞
    - P19：L3.2- 预处理句对数据(PyTorch) - ShowMeAI - BV1Jm4y1X7UL
- en: How to proposepo pairs of sentences。We have seen enough to tokenize single sentences
    and patch them to coverver in the patch inputs to Cavers video。If this code look
    infamiliar to you， be sure to check the video again。Here we all focus on tasks
    but classified personal sentences。For instance。 we may want to class where our
    two texts are parases on it。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如何提出句子对。我们已经见识了如何对单句进行分词并将其拼接到覆盖输入中。如果这段代码对你来说有些陌生，请务必再次查看视频。在这里，我们专注于任务，但分类个人句子。例如，我们可能想要判断我们的两个文本是否是相同的。
- en: Here is an example taken from the Qa question P dataset set。 which focuses on
    identifying duplicate questions。In the first pair。 the two questions are duplicates
    in the second format。![](img/6c5fec0939d8ec492c6e56dd82094de9_1.png)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从Qa问题P数据集中提取的示例，专注于识别重复问题。在第一对中，这两个问题在第二种格式下是重复的。![](img/6c5fec0939d8ec492c6e56dd82094de9_1.png)
- en: Another of a per classification problem is when we want to know if two sentences
    are logically related or not。A problem called natural language inference or the。In
    this example taken from the multiana dataset set。 we have a pair of sentences
    for each possible label， contradiction， network or enment。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个分类问题是我们想知道两个句子是否在逻辑上相关。这是一个称为自然语言推理的问题。在这个从multiana数据集中提取的例子中，我们为每个可能的标签准备了一对句子，矛盾、网络或确证。
- en: which is a fancy way of saying the first sentence implies a second。![](img/6c5fec0939d8ec492c6e56dd82094de9_3.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种华丽的说法，意味着第一句暗示第二句。![](img/6c5fec0939d8ec492c6e56dd82094de9_3.png)
- en: So classifying pair certain is a problem worth telling。In fact， in the group
    benchmark。 which is an academic benchmark for text ratification。Eight of the 10
    dataset sets are focused on tasks using pairs of sentences。That's why models like
    Bt are often betweened with a dual objective。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，某些配对分类确实是一个值得讨论的问题。实际上，在群体基准中，这是一个文本验证的学术基准。10个数据集中的8个专注于使用句子对的任务。这就是为什么像Bt这样的模型通常采用双重目标。
- en: On top of the language modeling objective， we often have an objective related
    to sentence pairs。For instance， during co traininging， B is shown pair of sentences
    and must predict both the value of randomly mask tokens and whether a second sentence
    flow from the first hall。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 除了语言建模目标外，我们通常还有与句子对相关的目标。例如，在共同训练过程中，B展示了一对句子，并必须预测随机掩盖的标记的值以及第二句是否从第一句引出。
- en: Fortunately， the Tukenezer from the transformformer library has a nice API to
    deal with pair sentences。You just have to pass them as two arguments to the tokenizer。On
    top of the input ID and the attach mask we studied already。 it returns a new field
    called token type 8s， which tells us the model which to can spin to the first
    sentence。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，transformer库中的Tukenezer有一个不错的API来处理句子对。你只需将它们作为两个参数传递给分词器。在我们已经学习的输入ID和附加掩码之上，它返回一个新字段，称为token
    type 8s，这告诉模型哪个可以映射到第一句。
- en: And which ones belonged to the second sentence？Zooming in a little bit。 here
    has the input ID aligned with the tokens we correspond to our respective token
    type ID and attention mask。We can see the tokenizer also added special tokens。So
    we have a C S token。 the tukens from the first sentence， a septukin， the tokens
    from the secondken sentence。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 哪些属于第二句？稍微放大一下，这里有与我们各自的标记类型ID和注意力掩码对应的输入ID。我们可以看到分词器也添加了特殊标记。所以我们有一个C S标记，来自第一句的标记，还有一个来自第二句的septukin标记。
- en: and a final septuken。If we have several pairs of sentences。 we can take an nice
    together bypassing the list of first sentences。 then the list of certain sentences，
    and all the keyword arguments we studied already。 like padding ault。![](img/6c5fec0939d8ec492c6e56dd82094de9_5.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以及一个最终的septuken。如果我们有多个句子对，可以通过传递第一句的列表，然后是某些句子的列表，以及我们已经学习的所有关键字参数，如填充选项，来整合它们。![](img/6c5fec0939d8ec492c6e56dd82094de9_5.png)
- en: Zooming in as a result， we can see how the tokeniser added padding to the second
    pair of sentences to make the two outputs the same length and properly dealt with
    token type IDs and attention masks for the two sentences。This is an already2 pass
    straw model。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 放大后，我们可以看到分词器如何为第二对句子添加填充，以使两个输出具有相同的长度，并正确处理两个句子的标记类型ID和注意力掩码。这已经是一个2次传递的模型。
- en: '![](img/6c5fec0939d8ec492c6e56dd82094de9_7.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c5fec0939d8ec492c6e56dd82094de9_7.png)'
- en: '![](img/6c5fec0939d8ec492c6e56dd82094de9_8.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c5fec0939d8ec492c6e56dd82094de9_8.png)'
- en: 。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 。
