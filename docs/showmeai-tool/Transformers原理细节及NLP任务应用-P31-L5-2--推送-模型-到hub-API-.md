# Transformers原理细节及NLP任务应用！P31：L5.2- 推送(模型)到hub API 

让我们来看看推送到每个API。就在录制这个视频之前，我提到了坏模型和C M PCC数据集。我们在这里不会详细讨论代码，因为你可以在任何Transformers教程中找到它，或者查看下面的视频链接。我们关心的是当训练结束且我们得到了满意的指标时会发生什么。

这个视频要求你首先在Hugging Face网站上注册一个账户，其次，你需要将你的身份验证令牌存储到该网站，这可以通过在终端中输入`huggingface-cli login`或在Colab笔记本中使用感叹号的方式轻松完成。

如果你使用的是常规的Jupyter笔记本，该命令将不起作用。因此，如果你在使用它且没有访问终端的权限，你需要将你的访问令牌从Hugging Face网站复制到训练参数中。我稍后会告诉你确切的位置。完成后。

推送API将允许我们将模型及其配置和相关的tokenizer推送到hub。要在训练器中使用它，必须确保将push2设置为训练参数中的equal2。如果不指定Mo ID，默认将使用输出的名称。

只要我们是该组织的成员，就可以推送到组织。如果需要，这里应该是你的Hugging Face账户所在的位置。推送完成后，我们可以在训练结束时调用Twinner来执行推送。未来的发展中，我们将添加在每个epoch结束或每给定步数后自动推送到应用的功能。

所以请继续关注。该命令返回特定提交的URL，我们可以在浏览器中检查，如果我们在检查之前复制它。请注意，如果你不使用训练器API，你可以通过使用push方法直接推送模型和tokenizer。

通过在浏览器中访问该提交，我可以访问名为Fine-tuned MPC的仓库，并看到已添加的文件。包括模型计数、模型配置、模型权重、运行的日志以及tokenizer所需的所有文件。训练器草拟的模型卡包含了评估集上的最终结果。

训练输出参数、中间训练结果以及我使用的框架。如果我点击编辑模型卡以查看原始内容，可以看到训练器还生成了一张元数据表，Hugging Face网站将使用这些数据来正确应用领域到我的模型中。我还可以通过点击这里的训练指标直接访问模型库中的运行情况。

现在模型已经开发完成，我们可以通过`from betweentrain`方法从任何地方使用它。我们只需使用E中的标识符，就可以看到模型配置和权重会自动下载。我们可以像使用任何变换器模型一样使用这个模型，例如，通过在管道中读取它。由于MRPC数据集是一组平行句子。

任务是确定两个句子是否相互为段落。我们在两个句子之间用S进行操作。看到它预测标签为零有点令人失望。这是因为我在创建模型配置时没有指定任何标签。修复这个问题通过推送到APIP是非常简单的。首先。

我们可以通过将标签设置为AD并用适当的值添加到标签，来在本地修复配置。然后我们可以通过推送到某个方法，将修复后的内容推送到我们的报告中。再一次，请返回一个提交的URL，以便我们可以检查并查看配置的具体内容。请注意，由于我使用的是之前的相同本地文件夹，命令执行得非常快。

我报告的克隆已经完成。一旦完成并创建新的管道，我们可以看到新的配置会自动下载，这要感谢构建追踪系统，并且我们得到了新的标签。我们也可以直接在模型卡上与模型进行互动。通过使用文本并点击Comp。我只需等一段时间，直到模型在推理API上加载并显示结果。

当模型加载完成后，我们可以进行双重检查，确认我们得到的结果与之前相同，直接在Wiidget上！[](img/6cf4bd9efdb86360f2e26a7c6c7e3239_1.png)

尝试今天将模型推送到VPA上！[](img/6cf4bd9efdb86360f2e26a7c6c7e3239_3.png)

是的。
