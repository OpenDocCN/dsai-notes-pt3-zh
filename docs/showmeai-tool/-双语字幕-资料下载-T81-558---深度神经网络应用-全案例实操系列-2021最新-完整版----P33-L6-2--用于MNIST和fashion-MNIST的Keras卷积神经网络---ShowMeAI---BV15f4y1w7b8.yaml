- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P33：L6.2- 用于MNIST和fashion-MNIST的Keras卷积神经网络
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P33：L6.2- 用于MNIST和fashion-MNIST的Keras卷积神经网络
    - ShowMeAI - BV15f4y1w7b8
- en: Hi， this is Jeff Heaton。 welcome to applications of Deep neural Network with
    Washington University In this video。 we're going to look at how to use convolution
    neural networks。 and we're going to start with one of the classic neural network
    data sets that has been used on many different。😊，Models other than neural networks
    as well， this is the Mins digits data set。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是Jeff Heaton。欢迎来到华盛顿大学的深度神经网络应用。在这个视频中，我们将看看如何使用卷积神经网络。我们将从一个经典的神经网络数据集开始，这个数据集在许多不同的模型中使用，除了神经网络之外，这就是MNS数字数据集。
- en: then we're going to look at a newer data set that is very similar。 it's meant
    to be a drop in replacement for Minst。 it is the mens fashion data set。After we
    get through these we'll be able to see more advanced topics for convolution neural
    networks for the latest on my AI course and projects。 click subscribe and the
    bell next to it to be notified of every new video。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看一个非常相似的新数据集。它被设计为MNS的替代品，这就是男性时尚数据集。在我们完成这些之后，我们将能够看到卷积神经网络的更高级主题。想了解我最新的AI课程和项目，请点击订阅，并点击旁边的铃铛以获得每个新视频的通知。
- en: so you'll notice that I am using Google CoLb rather than just simply my laptop
    like I've done in a number of these videos。![](img/194e506320f5e9abc6ca37065bbd9036_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你会注意到，我使用Google Coab而不仅仅是简单地使用我的笔记本电脑，就像我在许多这些视频中所做的那样。![](img/194e506320f5e9abc6ca37065bbd9036_1.png)
- en: We're using Google coab because we're going to need to make use of a GPU。 If
    we don't make use of the GPU， this is gonna to run very slowly。 We'll literally
    have things that would take probably five minutes with the GPU that could take
    two hours without the GPU。 So it's very important that you have that GPU available
    to you。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Google Coab是因为我们需要使用GPU。如果不使用GPU，这将运行得非常慢。实际上，有些事情在GPU上可能需要五分钟，而没有GPU可能需要两个小时。因此，拥有可用的GPU非常重要。
- en: I have a complete video that I'll link to this。 It's linked with the class that
    shows how to use Google coabab in conjunction with this with this course。 Basically，
    if you want to run any of my course material It's best just to open up the Github
    repository with Google coab and pull the file in。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个完整的视频，我会链接到这个。它与这个课程相关，展示了如何将Google Coab与此课程结合使用。基本上，如果你想运行我的任何课程材料，最好打开带有Google
    Coab的GitHub仓库，并将文件导入。
- en: that's exactly what I've done here。 You can see up here。 I've connected to to
    Github and I've pulled in this class 6。 Now。 let's look at how to use this with
    Kira's and convolution neural networks。 First of all。 let's go ahead and change
    the runtime type。 We do want to use。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我在这里所做的。你可以在这里看到。我已连接到GitHub，并导入了这个类6。现在，让我们看看如何将其与Kira和卷积神经网络一起使用。首先，让我们更改运行时类型。我们确实想要使用。
- en: '![](img/194e506320f5e9abc6ca37065bbd9036_3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/194e506320f5e9abc6ca37065bbd9036_3.png)'
- en: So it's saying in Python 3，6， Washington University。 that's something local。
    So it would complain about that as soon as I tried to run it because Google Coabb
    doesn't know what that is。 That's a local Python environment that I have。 I'm
    going switch it to Python 3 hardware accelerator。 We want a GPU。 We'll get into
    TUus later。 and let's go ahead and save。 Now。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它在Python 3.6中说，华盛顿大学。这是一些本地内容。因此，当我尝试运行时，它会对此抱怨，因为Google Coab不知道那是什么。这是我拥有的本地Python环境。我将其切换到Python
    3硬件加速器。我们想要GPU。我们稍后会进入TUus，让我们继续保存。现在。
- en: whenever I run things in this。 It'll run it with the GPU。 So we're going to
    look at computer vision data sets。 There's a couple of them that we see in this。😊。![](img/194e506320f5e9abc6ca37065bbd9036_5.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我在这里运行东西时。它会用GPU运行。所以我们将查看计算机视觉数据集。在这个中，我们看到几个。😊。![](img/194e506320f5e9abc6ca37065bbd9036_5.png)
- en: Course module， and then we get into some even more advanced ones later in this
    semester。The classic Ho world computer vision data set is the minsed digits。These
    are basically handwritten digits that are 28 by 28 pixels。 they have been studied
    and used to death in research。Papers。As a result。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 课程模块，接下来我们将在本学期后面进入一些更高级的内容。经典的计算机视觉数据集是MNS数字。这些基本上是28x28像素的手写数字，它们在研究论文中被反复研究和使用。因此。
- en: there's been a very closely related data set added to this called Minced fashion。
    which looks very much like this， except its handbags and shoes and shirts。 So
    you try to detect an article of clothing rather than rather than digits。But we
    need to go through the the mins digits。 We want to see how this works because
    it's。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个与此非常相关的数据集被添加到这个名为**Minced fashion**的项目中。它看起来非常相似，只不过是手袋、鞋子和衬衫。所以你试图检测的是衣物，而不是数字。但我们需要通过这些**mins**数字。我们想看看这是如何运作的，因为它是。
- en: it's your typical hello world for。For machine learning and for computer vision。
    now where these digits came from。Standardized tests， more and more， this is becoming
    online but。You guys have probably done fill in the bubble sort of standardized
    tests。When I was in grade school。 high school and getting ready for ACT exams
    and sat， getting ready for college。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你典型的**hello world**程序。对于机器学习和计算机视觉来说。这些数字来自哪里。标准化考试，越来越多地，这正在变得在线。但你们可能做过填泡的那种标准化测试。当我上小学、高中，并为ACT和SAT考试准备时，准备上大学。
- en: this is the only way you took this kind of thing literally they know that these
    students were creating perfect computer vision training data because the students
    would draw like a three end here and then fill in the blank。 so you've got your
    X which is going to be the what they drew and the Y。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是唯一的方式，你可以字面理解这些学生正在创建完美的计算机视觉训练数据，因为学生们会在这里画个三，然后填空。所以你得到了X，即他们画的内容和Y。
- en: the expected labels of what they filled in the little blank with。Now there's
    noise in this dataset set。 Some students， me in particular。 when I was taking
    these things had really bad handwriting。 Some students would lie。 they would draw
    a three here and fill in a four here。 R's a legitimate mistake。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 他们填入小空白的期望标签。现在这个数据集中有噪声。一些学生，特别是我。在参加这些考试时字迹非常糟糕。有些学生会撒谎。他们会在这里画个三，然后在这里填个四。R是一个合法的错误。
- en: So that is that is basically how this works。 I also remember some of these exams
    that I took back in the innocent days before identity theft。 You'd literally put
    your social security number right on the exam paper。 What could possibly go wrong。
    So that is the mined digits。 Minsed fashion is basically articles of clothing
    in exactly the same format as the mins digits。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这基本上就是它的工作原理。我还记得一些我在身份盗窃前的天真时代参加的考试。你会在考试纸上写上你的社会安全号码。可能会出什么问题呢。所以这就是被挖掘的数字。**Minced
    fashion**基本上是与**mins digits**完全相同格式的衣物。
- en: So it's a drop in replacement。 and we will take a look at this data， because
    it it's great。 and it's more difficult than minst for the machine learning。 Mach
    learning has gotten smarter。 So we need smarter， not smarter but harder data sets
    for the machine learning to tackle。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是一种可替代的解决方案。我们将查看这些数据，因为它非常出色，并且对于机器学习来说比**minst**更具挑战性。机器学习变得更聪明了。所以我们需要更聪明，而不是更聪明，而是更困难的数据集来挑战机器学习。
- en: '![](img/194e506320f5e9abc6ca37065bbd9036_7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/194e506320f5e9abc6ca37065bbd9036_7.png)'
- en: You can see there's shoes， there's pants， there's shirts， dresses。![](img/194e506320f5e9abc6ca37065bbd9036_9.png)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到有鞋子、裤子、衬衫、裙子。![](img/194e506320f5e9abc6ca37065bbd9036_9.png)
- en: Fashion items basically for the neural network to figure out。 So instead of
    10 different digits。 you have 10 different types of fashion。 It's also the CR
    data set。 C 10， we will use because。![](img/194e506320f5e9abc6ca37065bbd9036_11.png)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 时尚物品基本上是让神经网络去识别的。所以你有10种不同类型的时尚，而不是10个不同的数字。它也是CR数据集。C 10，我们会使用它，因为。![](img/194e506320f5e9abc6ca37065bbd9036_11.png)
- en: We're going to look at resnets later in this course and Resnets。This is the
    data set that they really distinguish themselves on for the first time。 so we'll
    see how you can apply a resnet to these full color。Data set here where you've
    got different types of airplanes and different types of cars， cats， birds。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本课程稍后查看**resnets**，这是他们首次真正展示自己能力的数据集。所以我们将看到如何将**resnet**应用于这些全彩色的数据集，这里你有不同类型的飞机、汽车、猫、鸟。
- en: All these kind of things， by the way， a common complaint of some of these machine
    learning databases that later ones have tried to fix is what percentage of these
    are animals。Airplane is not bird， cat， deer dog， frog， horse。 Okay， so a good
    60% of that。Is an animal。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，这些事情的共同抱怨是一些机器学习数据库后来的版本试图修复的问题，即这些数据中有多少百分比是动物。飞机不是鸟，猫，鹿，狗，青蛙，马。好的，所以大约60%是动物。
- en: So not not completely balanced as far as the the features that it's learning。
    other resources that I do want to show you。At Stanford。 there's an entire course
    just on convolution neural networks。 And just like this course。 they make all
    of the material available on the Internet。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在学习的特征方面并不是完全平衡。我想向你展示其他资源。在斯坦福，有一整门课程专门讲卷积神经网络。就像这门课程一样，他们将所有材料都放在网上。
- en: So you'll want to check that out if you're particularly interested in convolution
    neural networks。 Andre Kpathy is。I've followed his research since he was a grad
    student and very interesting guy who does a lot with computer vision。 his his
    dissertation was on captioning。Now you could have a picture of a cat riding a
    skateboard and the neural network would literally write out in text。 Cat riding
    skateboard。 That was the image that I think he had as one of the figures in his。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果你特别对卷积神经网络感兴趣，想要查看一下。Andre Kpathy是一个我从他读研究生时就关注的研究者，他是一个非常有趣的人，做了很多计算机视觉的工作。他的论文是关于图像字幕的。你可能有一张猫骑滑板的图片，神经网络会真的以文本形式写出来：猫骑滑板。这是我认为他论文中的一个图像。
- en: in his dissertation。He taught the course at Stanford initially。I think he works
    for Tesla now。 so he probably doesn't teach that course anymore for Stanford University
    and all the information is is online He also wrote Convenet JS。There's an early
    convolution neural network library completely in JavaScript。 probably these days
    you would use the Google Tensorflow for JavaScript。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 他最初在斯坦福教授这门课程。我想他现在在特斯拉工作，所以他可能不再教这门课程，斯坦福大学的所有信息都在线上。他还写了Convenet JS。这是一个完全用JavaScript编写的早期卷积神经网络库。现在你可能会使用Google的Tensorflow
    for JavaScript。
- en: but it's worth taking a look at so we'll look at convolution neural networks。
    convolution neural networks， a lot of the application to deep learning and to
    neural networks in general。 came from Janang Laon， who is one of the corecipients
    of the Tring Award for deep learning that was awarded to him。Yshua Benjiio and
    Jeffrey Hinton。What this？Does that is really powerful compared to neural networks
    before。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但值得一看，因此我们将研究卷积神经网络。卷积神经网络，很多深度学习和神经网络的一般应用，来源于Janang Laon，他是深度学习领域的Tring奖的共同获得者之一，获得者还包括Yshua
    Benjiio和Jeffrey Hinton。这个有什么？与之前的神经网络相比，真的很强大。
- en: And other traditional machine learning models like support vector machines is
    it can scan。So we've got the digit A here and notice this little box connected
    to the convolution layer。The convolution layer is one of a couple of new types
    of layers that we have now。 we had dense layers。Now we get convolution layers
    and max pooling layers。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他传统的机器学习模型，比如支持向量机，可以进行扫描。所以我们这里有数字A，注意这个小框与卷积层相连。卷积层是我们现在拥有的几种新类型层之一。我们有密集层，现在我们得到了卷积层和最大池化层。
- en: We also got dropout layers previously in this course， but these are the two
    new ones。 The convolution layer takes this square。That is used to scan。 so you
    specify the size of that square， the size of the scanning region。And it scans
    across。The entire image area， and it learns。As it goes。So if the square was right
    here。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这门课程中之前也介绍了dropout层，但这两个是新的。卷积层使用这个正方形。用于扫描，所以你指定那个正方形的大小，扫描区域的大小。它会在整个图像区域内扫描，并在过程中学习。如果正方形就在这里。
- en: it would learn about the bump on the top of the a sort of an angle。 Now。 other
    letters might have a feature such as that and these。Filters they' typically called
    or neurons。 they're roughly equivalent to the neurons in a normal hidden layer。Would
    learn each of these attributes。 Maybe one of them would learn a line that stops
    here。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 它会学习顶部隆起的特征，呈现出一个角度。现在，其他字母可能也有这样的特征，这些通常被称为过滤器或神经元。它们大致相当于普通隐藏层中的神经元。会学习这些属性。也许其中一个会学习一条在这里停止的线。
- en: Maybe one of them learns a line going at an angle。 One learns a somewhat perpendicular
    connection to the line。 The bump at the top。 All those would be learned by the
    feature maps， and that's in the convolution neural network。 The convolution layers。
    feature map is another term for a convolution layer。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 也许其中一个学习了一个倾斜的线，另一个学习了与线垂直的连接。顶部的隆起。这些都会被特征图学习，而这些在卷积神经网络中。卷积层。特征图是卷积层的另一种说法。
- en: Then after you've learned this， you might want to sub sampleample it and decrease
    it to a lower resolution。 That is the max pooling layer。 We'll see all of these
    layers work in a moment， exactly。😊。Then you have some additional convolution layers
    now learn to find features on this much reduced map。 So since it's smaller resolution，
    what you're really looking for now is the building blocks that this first layer
    learned。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在你学习完这个后，你可能想要进行下采样并降低到更低的分辨率。这就是最大池化层。我们稍后将看到所有这些层如何工作，确切地说。😊然后你有一些额外的卷积层，现在学习在这个大大缩小的图上找到特征。所以由于它的分辨率较小，你现在真正要寻找的是第一层学习到的构建块。
- en: So this first layer maybe learn bump Perpendicular connection line and end of
    a line。 now using just those building blocks， this layer then builds higher level
    abstractions。 So maybe it learns， okay， bump connected to two lines。 and then
    we pass through some fully connected layers， these are dense layers。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这个第一层可能学习的是垂直连接线和线的末端。现在仅仅使用这些构建块，这一层然后构建更高层次的抽象。所以也许它学习到，好的，凸起连接到两条线。然后我们通过一些全连接层，这些是稠密层。
- en: there's a variety of terminologies floating about on these。😊。Dense layer is
    pretty much what I've seen them called at least in the last five years worth worth
    of literature and then Gaussian connections。 that is pretty much being used then
    for classification。 So the output has 10。 So there are 10 different types of digits。
    It's interesting that he specifies 10 outputs。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些上面有各种术语在流传。😊稠密层基本上就是我在过去五年文献中看到的称谓，然后高斯连接。基本上用于分类。所以输出有10。因此有10种不同类型的数字。有趣的是，他指定了10个输出。
- en: but has a letter here you'd expect maybe 26 if he was teaching it on。 but the
    paper that this was used a lot in was using mined digits。 but you could draw an
    a and it would probably might think it's a9 with a weird line on it。 nonetheless
    this is the original diagram from La's original paper in 1998 that set the framework
    for a lot of what was to come。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在这里有个字母，如果他在教的时候，可能会期待26个字母。但这篇论文使用了挖掘的数字。你可以画一个“A”，它可能会认为这是一个“A9”，上面有奇怪的线条。尽管如此，这是来自La在1998年原始论文中的原始图表，为后来的很多内容奠定了框架。
- en: Convolution layers。 What you need to specify on them is the number of filters。
    The filter size。 That's the size of that square that's scanning across。Side is
    how many pixels that square jumps as it is scanning across padding is essentially
    a border that you put around the image because when that square hits the edge。
    you don't necessarily one it just falling off the edge of the image and not having
    a full set of pixels so you can put a padding around it zeros basically a black
    background and you also need to specify some activation function。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层。你需要在它们上面指定的是过滤器的数量。过滤器的大小。那是扫描的正方形的大小。侧边是那个正方形在扫描时跳跃的像素数，填充基本上是你放置在图像周围的边框，因为当那个正方形到达边缘时。你并不希望它就这样掉出图像的边缘，而没有完整的像素集，所以你可以在它周围放置填充，基本上是黑色背景的零，同时你还需要指定一些激活函数。
- en: usually re or one of the variance like like prelu or leaky re one of that family
    typically convolution layers are basically add weights and add parameters just
    like the other layers。 the amount of parameters that it would add would be the
    filter size times the filter size because the scanning square is always square
    so the filter size is assumed to be the same horizontal and vertically times the
    number of filters and that's just basically weights that are inside of that convolution
    layer。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通常是ReLU或类似的变体，如PReLU或Leaky ReLU，那一类。通常卷积层基本上添加权重和参数，就像其他层一样。它添加的参数量将是过滤器大小乘以过滤器大小，因为扫描正方形总是正方形，因此过滤器大小被假定为水平和垂直相同，乘以过滤器的数量，这基本上就是卷积层内部的权重。
- en: Once it scans across the entire region of the image。 they're often called shared
    weights because that means that something detected up here in the image can also
    be detected down here in the image。Positional invariance。 Basically， you can something
    could move。 and it's still， it's still detected。 This is essentially how you would
    think of a convolution layer as working。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦它扫描整个图像区域。它们通常被称为共享权重，因为这意味着在图像上方检测到的东西也可以在图像下方被检测到。位置不变性。基本上，你可以让某个东西移动，而它仍然可以被检测到。这就是你可以考虑卷积层如何工作的本质。
- en: You would have this square。 Now， this is dealing with gray scale。 So there's
    not three individual elements of red， green and blue on each of these pixels。
    If this were color， thered basically just be a depth component and you would have
    three numbers for each of these。 But this blue region is basically the scan and
    it goes across as it， as it scans and。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你将有这个方形。现在，这是处理灰度图像。因此，每个像素上并没有红、绿、蓝三个独立元素。如果这是彩色图像，基本上只会有一个深度组件，每个像素将有三个数字。但这个蓝色区域基本上是扫描，它在扫描时横跨而过。
- en: It has to go completely through the entire image for each prediction or each
    step in the training。 Now max pooling layers。 This is where you reduce the resolution。
    So say you wanted to cut the resolution in half。 You would take essentially a
    6 by 6。 and you would take it down to a 3 by 3。 So it would divide it into these
    regions。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 它必须在每次预测或训练的每一步中完全遍历整个图像。现在是最大池化层。这里是你减少分辨率的地方。所以说你想将分辨率减半。你将基本上取一个6乘6的区域，降到3乘3。所以它将分成这些区域。
- en: and you would take the maximum hence max pooling layer。 maximum in this cell
    is 8。 So you get an8。 Max in this cell is 2。 you get a 2。 so on， and I do have
    a link here to give。 if you want more information on the lower levels of convolution
    neural networks。 So let's have a look at how we would handle the digits data set
    I'm going to go ahead and run this region here。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你将取最大值，因此是最大池化层。这个单元中的最大值是8。所以你得到8。这个单元中的最大值是2。你得到2。依此类推，我这里有一个链接可以提供。如果你想了解更多关于卷积神经网络低层的信息。我们来看看如何处理数字数据集，我将继续运行这里的区域。
- en: and it displays the information。 So we've got 60000 in the training set and
    10000 in the test set。 Now， notice we are not。Having to split train and test on
    our own。 they don't want you to for the immense data set。 This is because this
    was used almost in a competitive way for papers。 So they wanted everybody using
    the same training and the same test set so that you could have a reasonable comparison
    So if you said that you got a certain result on it。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示了信息。所以我们的训练集有60000个，测试集有10000个。现在，注意我们并不需要自己拆分训练和测试。他们不希望你这样做，以应对庞大的数据集。这是因为这个数据集几乎以竞争的方式用于论文。所以他们希望每个人都使用相同的训练和测试集，以便能够进行合理的比较。因此，如果你说你在这个数据集上得到了某个结果。
- en: It's not just because you picked a lucky break between train and test。 Now。
    if we want to display the digits， we can simply run this。 This shows you what's
    actually in this this data set。 Now， notice， too。 we did pull the data set directly
    from Kis。 Kis provides this for common dataset sets as a convenience。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅仅是因为你在训练和测试之间选择了一个幸运的结果。如果我们想显示数字，我们可以简单地运行这个。这显示了这个数据集中实际包含的内容。现在，注意，我们确实是直接从Kis提取数据集的。Kis为常见的数据集提供了这个便利。
- en: but this can be a real pain。 if you're trying to use your own images。 And we'll
    talk about that in a future video how to pull in literally your own images raw
    Jpegs and P and Gs。But for now， we'll use the convenience methods Here。 you can
    see one of the images。 It's very big。 You can see probably some sort of a spiral
    there。 If you want to actually display it。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你尝试使用自己的图像，这可能会非常麻烦。我们将在未来的视频中讨论如何提取你自己的原始JPEG和PNG图像。不过现在，我们将使用这里的便利方法。你可以看到其中一张图像。它非常大。你可能会看到某种螺旋形。如果你想实际显示它。
- en: You can run this。And it displays it some sort of a one。That's the 105th digit
    if you want to pick。The next digit it would display it， which is a six。 So this
    is essentially heat map that Matplot Live provides us。 It provides a convenient
    way to visualize these。 If you want to see a whole bunch。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以运行这个。它以某种方式显示出来。这是第105个数字，如果你想选择下一个数字，它将显示出6。所以这本质上是Matplot Live提供的热图。它提供了一种方便的可视化方式。如果你想查看很多数据。
- en: you just do subplots。In Mapllib， you run that。 and it will show you a whole
    bunch of digits。 So this is a good way to visualize some of these data sets and
    show that they really are just images that are being pulled in for you。 You basically
    have to take the raw P and G and Jpeg files and turn them into tensors into cubes
    heightthe width by the color depth。 Now， let's go ahead and build a neural network
    to train this on。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需做子图。在Mapllib中运行它。它会显示一堆数字。所以这是可视化这些数据集的一种好方法，显示它们确实只是为你提取的图像。你基本上需要将原始PNG和JPEG文件转换为张量，变成高宽度乘以颜色深度的立方体。现在，让我们构建一个神经网络来训练这个。
- en: This is where we'll be glad we have a GPU。😊，Doesn't take too much time to actually
    build this。 It shows some of our hyperparameter We're choosing a batch size of
    128。 We are doing some basic transformation on on the data set so that everything
    is in the right order that Tensorflow wants it。 Typically， we， we need a height
    by width by。The color depth。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们会很高兴有GPU。😊 实际上构建这个并不需要太多时间。它显示了我们的一些超参数，我们选择的批处理大小是128。我们对数据集进行一些基本转换，以确保一切符合Tensorflow的要求。通常，我们需要一个高度乘以宽度乘以颜色深度。
- en: And we will see how to actually do that when。How to do this on raw images When
    we get into dealing with loading our own images for this。 this is important。This
    is doing some basic normalization on it。 So I said that neural networks deal best
    with。Data that's always in the same range。 Well。 you're always in the same range
    of 0 to 255 on the individual color components of RGB。But here it。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如何实际做到这一点。如何处理原始图像。当我们加载自己的图像时，这是重要的。这是在进行一些基本规范化。所以我说神经网络最好处理的数据总是在相同范围内。好吧，你的RGB每个颜色分量始终在0到255的相同范围内。但这里。
- en: this is getting everything between 0 and 1。 since the normal range was 0 to
    2。55 for a little better result， you could even potentially center this about
    0。 So you'd probably subtract 128 and divide by 128。 We'll see an example of that。Later
    on。We print out how many train sizes we've got。Here is where we build up the neural
    network。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这将获取所有在0到1之间的值。因为正常范围是0到2.55，为了获得更好的结果，你甚至可以将其围绕0居中。所以你可能需要减去128并除以128。稍后我们将看到一个例子。我们打印出有多少训练样本。这里是我们构建神经网络的地方。
- en: We add in some convolution to the layers。You don't really have a convolution
    3D， there might be one。 but typically you're dealing with 2D because you're recognizing
    2D images。 it wouldn't surprise me if somebody has figured out a way to send in
    3D images for recognition。 be interesting how you would capture those you'd probably
    need two cameras。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在层中添加了一些卷积。你实际上没有3D卷积，可能会有一个，但通常你处理的是2D，因为你在识别2D图像。如果有人找到了发送3D图像进行识别的方法，我不会感到惊讶。你可能需要两个相机来捕捉这些。
- en: But we'll deal just with 2D images， not 3D。 Then we put in the max pooling layer。
    add some dropout。 The flattening layer is always needed when you move from these
    2D to the dense layers like we've had before。 So always put that flatten in there
    because that basically now you can't go back once you flattened。 you can't use
    the convolution layers again， or at least not without some extraordinary reshaping
    in there。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们只处理2D图像，而不是3D。然后我们加入最大池化层，添加一些dropout。在从这些2D层转换到我们之前提到的密集层时，总是需要扁平层。所以一定要加上这个扁平层，因为一旦扁平化，你就不能再回去，或者至少没有一些非常特殊的重塑。
- en: never say never。 And then you use a dense layer。 and this is classification。
    So we're using the classes categorical crossenttropy and softm。 just just like
    we've had many times before。 Now， when you want to train and fit it。 and notice
    these times that I have here， this takes nearly two hours on the CPU and 13 minutes
    on the GP。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要说永远不。然后你使用一个密集层。这是分类。因此我们使用类的类别交叉熵和softmax，就像我们以前看到的那样。现在，当你想训练并适应它时，注意我这里的时间，这在CPU上需要近两个小时，而在GPU上只需13分钟。
- en: It's not gonna to take you that much time on the GP。 this Google GP that they
    give you for free is better than my GP that I that I ran this on about a year
    ago when I took those times。 So it's awesome what you get。For free。Let's go ahead
    and run this。 we're going to go ahead and train it， this is training code just
    like we've seen before。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU上并不会花你太多时间。这个谷歌免费提供的GPU比我大约一年前运行时用的GPU要好。所以你免费获得的东西真是太棒了。让我们继续运行这个。我们将继续训练，这段代码与我们之前看到的训练代码一样。
- en: I do time it， so we'll see exactly how much time this takes。 Now you want to
    run that。 It tends to take it a little bit of time to get going， but we're already
    on the first epoch。And it's， it's really pretty quick。 We're on our second epoch。
    and it， it took really。 it's taking only about 4 seconds a epoch。 So I will go
    ahead and fast forward this， but it's。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我会计时，所以我们将确切看到这需要多少时间。现在你想运行它。启动时通常需要一点时间，但我们已经进入第一个纪元。它，真的很快。我们在第二个纪元，它，实际上只需要大约4秒每个纪元。所以我会继续快进，但它是。
- en: it's not gonna take much time。 Just think this could be two hours on some CPUus。
    And there we are 53 seconds。 I love GPus。 Now， there's two types of GPU that you're
    dealing with right now。 there's the K 80 that I think that's what it's called
    that Google gives you for for free。 That's the cheaper one。 It's probably around
    a $500 to $700 GPU。 This is in 2019。😊，Well。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这不会花费太多时间。想想看，这可能在一些 CPU 上需要两个小时。而我们只用了 53 秒。我喜欢 GPU。现在，你正在处理两种类型的 GPU。有 K80，我认为这是它的名称，Google
    免费提供给你。那是更便宜的，可能在 $500 到 $700 的 GPU 范围内。这是 2019 年的情况。😊，好吧。
- en: I willm sure I will have updated the video by the time this that changes radically。
    There's also a V 100 more advanced enterprise 1。 I use that on Amazon cloud。 And
    that's probably a $6 or $7000 GPU。 You would think that it would run even faster
    on that one。 but it does not。 This is not a complicated enough neural network。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我会确保在这个视频发生重大变化时已经更新了它。还有一个更先进的 V100 企业级 GPU。我在亚马逊云上使用这个。它大概是 $6000 或 $7000
    的 GPU。你可能会认为在那个上运行会更快，但并不会。这个神经网络并不复杂。
- en: It runs about the same speed on this GPU versus the other。So when you are running
    on something like Amazon Cloud。 you need to balance really and not overuse to
    advanced of a GPU or or you're simply wasting your money。 You're dealing with
    something the more advanced GPU on Amazon Cloud， at least in today's dollars。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 GPU 上的运行速度与另一个差不多。因此，当你在像亚马逊云这样的环境中运行时，你需要真正地进行平衡，避免过度使用高级 GPU，否则你只是在浪费金钱。你正在处理亚马逊云上更先进的
    GPU，至少在今天的价格上。
- en: it's about $4 an hour。Versus under1 dollar an hour for this GPU that Google's
    given you for free。 so definitely use the Google one。For some of the assignments
    that I give you。 you will need GPU level processing performance otherwise you're
    going to spend hours and hours and hours training and it'll take you a long time。
    so I'll discuss that when we get into some of those assignments because there's
    separate videos and explanations for each of the assignments Now let's evaluate
    the accuracy。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每小时大约 $4，而 Google 提供给你的这个 GPU 每小时不到 $1。因此，肯定要使用 Google 的那个。在我给你的一些作业中，你将需要 GPU
    级别的处理性能，否则你将花费数小时进行训练，并且将花费很长时间。因此，在讨论这些作业时，我会说明，因为每个作业都有单独的视频和解释。现在，让我们评估准确性。
- en: Let's just run this and look at the accuracy，99%。 This is why fashion minst
    was introduced。 because this this is a decent hello world that what are you going
    to do if you're trying to do any sort of research on this。 I mean， you're going
    to be at 99999。 it's pointless to say that you increase the accuracy from 99%
    and 99。99999%。Now this is another thing that's useful to know too， when you're
    scoring。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行这个并看看准确率，99%。这就是为什么引入 Fashion MNIST 的原因，因为这是一个不错的 Hello World，如果你想对这个进行任何研究，你将会得到
    99.9999 的结果。说你将准确率从 99% 提高到 99.9999% 是毫无意义的。现在，还有一件事在评分时也很有用。
- en: that is sending data to get values back predictions back， if you're using a
    GPU。 you might get a resource exhaust error that is simply because you have thrown
    too much data at the GPU for it to score at once。So you have a couple of options
    there， this usually won't come up during training because you're using mini batches。
    but if you're trying to score a big block of like a million rows， it might not
    fit in the GPU。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在发送数据以获取预测值时，如果你在使用 GPU，你可能会遇到资源耗尽错误，这仅仅是因为你一次性向 GPU 投入了太多数据进行评分。因此，你有几个选择，这通常在训练期间不会出现，因为你使用的是小批量。但是如果你试图对像一百万行这样的大数据块进行评分，它可能无法适应
    GPU。
- en: coupleuple of options there， scoring is usually pretty quick。 you can just send
    that to the CPU and it doesn't matter how big it is within reason。Or you can break
    it up into pieces and send each of those pieces one by one to the GPU。 And you
    would use this kind of code to do it here。 if I wanted to just score the first
    100。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个选择，评分通常非常快。你可以将其发送到 CPU，无论大小，只要在合理范围内都没关系。或者你可以将其分成几部分，一次将每部分发送到 GPU。你可以使用这样的代码来实现这一点，如果我只想评分前
    100 个。
- en: So I give you an example of of doing that。 Now， let's look at mensed fashion。
    Again。 we're using convenience methods to load this in so that we don't have to
    have the data sets of all those fashion items。 we're going go ahead and run that。
    it is downloading it。 So when you run some of these for the first time， it will
    download it。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我给你举个例子。现在，让我们看看时尚数据集。我们正在使用便捷的方法加载数据，这样我们就不必拥有所有时尚项目的数据集。我们将继续运行，这正在下载。因此，当你第一次运行这些时，它会下载数据。
- en: if we want to display these just like before， this is exactly， by the way。 the
    same code as the digits。 So I'm not going to explain， reexplain it all。 just going
    kind of show you what it looks like。Let's go ahead and run this。 I shouldn't really
    say digit9。 this is a fashion apparel number nine， which is a shoe。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想像之前一样显示这些，这正是，顺便说一下。与数字的代码完全相同。因此我不打算重新解释这一切。只是稍微给你展示一下它的样子。让我们来运行一下。我不应该真的说是数字9。这是时尚服装的第九号，也就是一双鞋。
- en: And if we want to display a whole range of them just like the digits we can。
    So there's a block of fashion items that it's trying to。Again， pretty similar。Training
    times。 I'm going to go ahead and define。The neural network just like before。It's
    defined。We're going to now train it。And we'll see that the training time is really
    pretty comparable。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想像数字一样显示一整系列的物品，我们是可以的。因此，有一组时尚物品正试图展示出来。再次强调，这非常相似。训练时间。我将继续定义。神经网络就像之前那样。它已经定义好了。我们现在将进行训练。我们会发现训练时间确实非常相似。
- en: To what we are dealing with before。 Notice the accuracy is not just pegging
    right up to 99%。 It's around 89%。90%。 So this is definitely more difficult。 You
    would have to。 you'd have to work a lot more to get this up to the higher levels
    of accuracy。 And I have not looked。 This is not too much of a real data set。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前处理的情况相比。注意，准确率并没有直接上升到99%。大约在89%。90%。所以这显然更困难。你需要。你必须付出更多努力才能将其提升到更高的准确率水平。而且我没有查看。这并不是一个太真实的数据集。
- en: I suppose it's used some in research， but I have not looked at where。Some of
    the the more advanced researchers have gotten this up to。 but it looks like we're
    going to be right at around 92% of validation accuracy。 and it looks like it's。![](img/194e506320f5e9abc6ca37065bbd9036_13.png)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我想它在研究中有一些使用，但我没有查看过具体在哪里。一些更先进的研究人员将其提升到哪里。但看起来我们大约在92%的验证准确率。并且看起来它是。![](img/194e506320f5e9abc6ca37065bbd9036_13.png)
- en: Kind of stopping there。 Thank you for watching this video。 In the next video。
    we're going to continue with computer vision and look at resnets。 This content
    changes often。 so subscribe to the channel to stay up to date on this course and
    other topics in artificial intelligence。😊。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 大致停在这里。感谢你观看这个视频。在下一个视频中。我们将继续讨论计算机视觉，并研究残差网络（resnets）。这部分内容经常更新。因此请订阅频道，以便随时了解本课程及其他人工智能主题。😊
