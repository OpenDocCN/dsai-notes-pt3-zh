# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPyTorch ÊûÅÁÆÄÂÆûÊàòÊïôÁ®ãÔºÅÂÖ®Á®ã‰ª£Á†ÅËÆ≤Ëß£ÔºåÂú®ÂÆûË∑µ‰∏≠ÊéåÊè°Ê∑±Â∫¶Â≠¶‰π†&Êê≠Âª∫ÂÖ®pipelineÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P17ÔºöL17- ‰øùÂ≠òÂíåÂä†ËΩΩÊ®°Âûã - ShowMeAI - BV12m4y1S7ix

HeyÔºå guysÔºå welcome to a new Pytorch tutorial Today„ÄÇ

 I want to show you how we can save and load our model„ÄÇ

 I will show you the different methods and safe options you have to know„ÄÇ

 And also what you have to consider when you are using a GP U„ÄÇ So let's start„ÄÇ

 These are the only three different methods you have to remember„ÄÇ So we have torch dot safe„ÄÇ

 then torch dot load and model dot load state dit„ÄÇüòäÔºåAnd these are all the methods we must remember„ÄÇ

 and I will show you all of them in detail„ÄÇ So Torch dot Sa here can use tenor models or any dictionary as parameter for saving„ÄÇ

 So you should know here that we can save any dictionary with it„ÄÇ

 And I will show you how we can use this later in our training pipeline„ÄÇüòä„ÄÇ

So torch doa then makes use of Python's pickle module to serialize the objects and saves them„ÄÇ

 So the result is serialized and not human readable„ÄÇAnd now for saving our model„ÄÇ

 we have two options„ÄÇ The first one is the lazy method„ÄÇ So we just call torch do save on our model„ÄÇ

 and we also have to specify the path or the file name„ÄÇ And then later„ÄÇ

 when we want to load our modelÔºå we just set up our model by saying model equals torch do load and then the file name again„ÄÇ

 And then we also want to set our model to evaluation method„ÄÇ So by saying model do evil„ÄÇ

 So this is the lazy option„ÄÇ and the disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure that is used when the model is saved„ÄÇ

 So there is a second optionÔºå which is the recommended way of saving our model„ÄÇüòä„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_1.png)

If we just want to save our modelÔºå our trained model and use it later for interference„ÄÇ

 then it is enough to only save the parameters„ÄÇ And as you should remember„ÄÇ

 we can save any dictionary with torcha„ÄÇSo we can save the parameters by calling torch dot save and then model dot state di„ÄÇ

 So this holds the parameters and then the path„ÄÇAnd then later„ÄÇ

 when we want to load our model again firstÔºå we have to create the model object„ÄÇ

 and then we call model dot load state dit„ÄÇ And then inside this„ÄÇ we call torch dot load path„ÄÇ

 So be careful here since load state di doesn't take a only a path„ÄÇ

 but instead it takes the loaded dictionary year„ÄÇ And then again„ÄÇ

 we set our model to evaluation mode„ÄÇ So this is the preferred way that you should remember„ÄÇ

 And now let's jump to the code to see the different saving ways in practice„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_3.png)

So here I have a little script where I defined a small model class and here I created our model and now let me show you the lazy method first„ÄÇ

 So first we define our file name so we say file equals and let's call this model do p So it's come and practice to use the ending dot p so short for pytorrch and then we save the whole model by saying torch do save and then model and the file So let's save this and let's run the script So let's say Python save load do pi and now if we open up our browser So we can ignore this warning here then we see here we have the model do p„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_5.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_6.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_7.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_8.png)

In the Exper„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_10.png)

And if we open thisÔºå then we see that this is some serialase dataÔºå so this is not human readable„ÄÇ

And now if we go back to our code„ÄÇ So let's load our model so we can comment this out„ÄÇ

 and we also can comment this out„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_12.png)

And then we can load our model by sayingÔºå model equals„ÄÇEquals torch dot load„ÄÇ and then the file„ÄÇ

 And then rememberÔºå we want to set it to evaluation method„ÄÇSo we say model dot evil„ÄÇ

 and then we can use our model„ÄÇ For exampleÔºå we can inspect the parameters„ÄÇ

 So let's say for Para in model dot parameters„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_14.png)

And thenÔºå let's print our Para„ÄÇAnd save this„ÄÇ And let's„ÄÇClear this and run our script again„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_16.png)

And let me make this larger for you„ÄÇ So now if we run our script again„ÄÇ

 then we can see that we loaded our model and we can use the parameters„ÄÇSo this is the lazy option„ÄÇ

 And nowÔºå let me show you the preferred way of doing this„ÄÇ

 So instead of just saying torch dot save model here and what we instead want to do is to say torch dot save„ÄÇ

 and then we want to save the state dit„ÄÇ So here we have our model again„ÄÇ

 And then we say torch dot model dot„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_18.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_19.png)

Tarch dotafe model dot state„ÄÇState diiced„ÄÇAnd thenÔºå let's run this„ÄÇSoÔºå let me clear this„ÄÇ

And let's open up the Explorer and delete this file here„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_21.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_22.png)

And now if we run our script againÔºå then we again have the file„ÄÇ

 But now here it only save the state dictates„ÄÇ And now if we want to load our model again„ÄÇ

 we first have to define it„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_24.png)

So let's call this loaded model„ÄÇLoaded model„ÄÇEquals„ÄÇ

 and then let's also say the model and the number of input features is the same„ÄÇ So it's 6„ÄÇ

 And then we call loaded model dot load state di„ÄÇ And inside this„ÄÇ Remember„ÄÇ

 we have to call torch dot load„ÄÇ and then the file name„ÄÇ And then again„ÄÇ

 we set our loaded model to evaluation mode„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_26.png)

And then if we run thisÔºå So let's print the parameterss of the loaded model„ÄÇ And up here„ÄÇ

 let's also print the parameterss of our normal model„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_28.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_29.png)

So thisÔºå if we don't do any training hereÔºå Then our model is still initialized with some random parameters„ÄÇ

 So let's run the script and let's check if the parameters are the same„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_31.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_32.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_33.png)

So hereÔºå yeahÔºå we see that it worked„ÄÇ and it first printed the parameters of the model of the normal model„ÄÇ

 and then here of the loaded model„ÄÇ So these are the same„ÄÇ

 So we see we have a tenzo with the weights„ÄÇ and we also have a tenzo with the bias„ÄÇ

 and this is the same for both of our model„ÄÇ So we see that this workedÔºå too„ÄÇ So yeahÔºå again„ÄÇ

 so this is the recommended way of doing it by saying safe dot model state diict„ÄÇ

 And then when we load itÔºå we call a load state dict method„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_35.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_36.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_37.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_38.png)

And yeahÔºå so here we just save the state di„ÄÇ So this holds the parameters„ÄÇ

 So let me show you how this state dit looks like„ÄÇ So when we have our model„ÄÇ

 let's print model dot state„ÄÇüòä„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_40.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_41.png)

DicktÔºå and let's save this„ÄÇAnd let's clear this and run the script„ÄÇ

 Then we see here we have our state dick„ÄÇ So here we have the linear weight„ÄÇ

 which has the tenzo with the weights„ÄÇ And then we also have the„ÄÇBastenzor„ÄÇ So this is our state dic„ÄÇ

And now let me show you a common way of saving a whole checkpoint during training so as you know„ÄÇ

 we can save any dictionary here„ÄÇSo let's say we also have a optimizer here„ÄÇ

 So let's say we defined a learning rate„ÄÇ So let's say this is 0001„ÄÇ And we also have a optr„ÄÇ

 This isÔºå let's sayÔºå torch dot optim„ÄÇDot„ÄÇLet's use stochastic gradient descent„ÄÇ

 And here we want to optimize the model parameters„ÄÇ

 and we will also have to give it the learning rate by saying learning rate equals the learning rate and our optimizer also has a state di„ÄÇ

 So we can also print the optimizer state di„ÄÇ NowÔºå if we clear this and run this„ÄÇ

 then we see the state dictionary of the optimizer where we can seeÔºå for example„ÄÇ

 the learning rate and the momentum„ÄÇSo now during training„ÄÇ

 let's say we want to stop somewhere at some point during training and save a checkpoint„ÄÇ

 Then we can do it like thisÔºå so„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_43.png)

We create our checkpointÔºå and this must be a dictionary„ÄÇ So let's create a dictionary„ÄÇ

 And as a first thingÔºå what we want to save isÔºå for exampleÔºå the epoch„ÄÇ So let's define the epoch„ÄÇ

 So the key is called epoch„ÄÇ And let's say we are justÔºå we are an epoch 90„ÄÇ

 And then we want to save the model state„ÄÇ So we have to give it a key„ÄÇ let's say model state„ÄÇ

 And here we use model dot state diict„ÄÇAnd then we also want to save the optimizer state dick„ÄÇ

 So the keyÔºå let's sayÔºå optim state„ÄÇ And then here as a valueÔºå we have to call optr state dick„ÄÇ

 So this is our checkpoint„ÄÇ And now we can call torch dot save„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_45.png)

And then save the whole checkpoint„ÄÇ So let's say torch checkpoint asÔºå as a file name„ÄÇ

 Let's call this check„ÄÇPoint dot PÔºå T H„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_47.png)

And now againÔºå let me show you the explorer and let's run the script„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_49.png)

So now we clear this and run this„ÄÇ Then we see we have our checkpoint here„ÄÇ And now„ÄÇ

 when we load thisÔºå we want to load the whole checkpointÔºå so„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_51.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_52.png)

We can comment this out„ÄÇ And alsoÔºå we don't need thisÔºå so„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_54.png)

Let's say our loaded checkpoint„ÄÇ So let's sayÔºå loaded checkpoint„ÄÇEquals torch dot load„ÄÇ

 And then the file name was the same as this one„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_56.png)

And now you have to set up the different„ÄÇModel and optimizes again„ÄÇ

 so we can get the epoch right away by saying epoch equals load at checkpoint„ÄÇ

 So this is a dictionary„ÄÇ so we can just„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_58.png)

Call the„ÄÇOr access the epoch key„ÄÇ And then for the model„ÄÇ remember„ÄÇ

 we have to create our model here again„ÄÇ So let's say model equals„ÄÇ

 and then the model with the number of input features equals 6 and the optimizer equals the same as this one„ÄÇ

 So we don't have to use the same learning rate actually„ÄÇ

 So let me just grab this one here and paste it down here„ÄÇ And for example„ÄÇ

 we can use the learning rate 0„ÄÇ And then laterÔºå we can see that we load the correct learning rate into the optimizer„ÄÇ

 So„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_60.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_61.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_62.png)

NowÔºå let's say model dot load state„ÄÇDicksÔºå and then here we give it the checkpoint„ÄÇ

 and then we access the key„ÄÇ We call it model state„ÄÇ

 So this will load all the parameters into our model„ÄÇ and the same with our optimizer„ÄÇ

 So we call optimizer dot load state dis„ÄÇ and then we use the checkpoint„ÄÇ

 And here we call it optim state„ÄÇ So now we have the loaded model and the optr and also the current epoch„ÄÇ

 So we can continue our training„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_64.png)

And let me show you that this is all correct by saying we want to print the optimizer dot state di„ÄÇ

 So if you notice hereÔºå we set the learning rate to 0 and then we loaded the correct state di„ÄÇ

 So now if we run this„ÄÇ And as a last thingÔºå we printed the optimizer state di„ÄÇ

 then we see we have the same learning rate as in the initial optimizer„ÄÇ So this work2„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_66.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_67.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_68.png)

So this is how we can save and load a whole checkpoint„ÄÇ And yeah„ÄÇ

 these are all the three ways of saving you have to know„ÄÇ And now as a last thing„ÄÇ

 I want to show you what you have to consider when you are using a GPU during training„ÄÇ

 So if you are doing training and loading both on the CPU then you don't have to make any difference„ÄÇ

 So you can just use it like I did hereÔºå But now if you save your model on the GP„ÄÇ

 And then later you want to load it on the CPUÔºå then you have to do it this way„ÄÇ

 So let's say somewhere during your trainingÔºå you set up your ka device and you send your model to the device and then you save it by using the state d„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_70.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_71.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_72.png)

And then you want to load it to the CPU„ÄÇ So you have your CPU device„ÄÇ

 then you create your model againÔºå and then you call load state died and then load path„ÄÇ

 And here you have to specify the map location„ÄÇ And here you give it the CPU device„ÄÇ

 So this is if you want to save on the GP and load on the CPU„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_74.png)

NowÔºå if you want to do both on the GPU„ÄÇ So you send your model to the Kuda device and saved it„ÄÇ

 and then you also want to load it on the GPUÔºå then you just do it like this„ÄÇ So you„ÄÇ

Set up your modelÔºå you load the state diÔºå and then you send your model to the Kuda device„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_76.png)

And now as a third option„ÄÇ So let's say you saved your model on the CPU„ÄÇ So you didn't send„ÄÇ

 you didn't call model to Kuda device somewhere„ÄÇ But then laterÔºå during loading„ÄÇ

 you want to load it to the GPÔºå you have to do it like this„ÄÇ So first you specify your Ka device„ÄÇ

 Then you create your model„ÄÇ

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_78.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_79.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_80.png)

And then you call model dot load date diiced and then torch load with the path and then as map location„ÄÇ

 you specify Kuda and then colon and then any GPU device number you want„ÄÇ So for example„ÄÇ

 Kuda colon0„ÄÇ and then also you have to call model to device So to the ka device„ÄÇ

 So this will send the model to device to the device and also all the loaded parameter tenzoos to the device So then you can continue with your training or interference on the GPU„ÄÇ

 and of courseÔºå you also have to send all the training samples to the device that you then use for the forward path„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_82.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_83.png)

![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_84.png)

So yeahÔºå this is what you have to consider when you're using a GPU„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_86.png)

And nowÔºå you know all the different ways of saving and loading your model„ÄÇ And yeah„ÄÇ

 that's all for now„ÄÇ I hope you enjoyed this tutorial„ÄÇ

 And if you like this then please consider subscribing to the channel and see you next timeÔºå bye„ÄÇüòä„ÄÇ



![](img/d077e5bf8acaccfa2f2d408a7bb4ae8d_88.png)