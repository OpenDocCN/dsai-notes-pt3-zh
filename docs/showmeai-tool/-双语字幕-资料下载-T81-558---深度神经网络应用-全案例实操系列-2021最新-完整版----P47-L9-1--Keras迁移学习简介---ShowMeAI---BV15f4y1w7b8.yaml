- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P47ï¼šL9.1- Kerasè¿ç§»å­¦ä¹ ç®€ä»‹ -
    ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P47ï¼šL9.1- Kerasè¿ç§»å­¦ä¹ ç®€ä»‹ -
    ShowMeAI - BV15f4y1w7b8
- en: '![](img/57e575643f505aee4c9c36ac4901f183_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57e575643f505aee4c9c36ac4901f183_0.png)'
- en: Hiï¼Œ this is Jeff Heatonã€‚ Welcom to applications of deep neural networks with
    Washington Universityã€‚ You know whatï¼Œ It's a lot of work to train a neural networkï¼Œ
    and it can take a lot of compute timeã€‚ It's mostly your computer doing the workï¼Œ
    but still it can take a longï¼Œ long timeã€‚ especially if you don't have a multi
    thousand dollar GPUã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚ä½ çŸ¥é“å—ï¼Œè®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œéœ€è¦å¾ˆå¤šå·¥ä½œï¼Œè€Œä¸”å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—æ—¶é—´ã€‚å¤§éƒ¨åˆ†æ—¶é—´æ˜¯ä½ çš„è®¡ç®—æœºåœ¨å·¥ä½œï¼Œä½†ä»ç„¶å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œå°¤å…¶æ˜¯å¦‚æœä½ æ²¡æœ‰ä¸€å—å‡ åƒç¾å…ƒçš„GPUã€‚
- en: This is where transferfer learning comes in handyã€‚ Transfer learningï¼Œ lets you
    takeã€‚ğŸ˜Šã€‚Neurural networks that were developed by larger companies or startups or
    other people who have a lot of money to blow on GPUsã€‚ and you can use this training
    in your own projects for the latest on my AI course and projectsã€‚ click subscribe
    in the bell next to it to be notified of every new videoã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯è¿ç§»å­¦ä¹ æ´¾ä¸Šç”¨åœºçš„åœ°æ–¹ã€‚è¿ç§»å­¦ä¹ è®©ä½ å¯ä»¥ä½¿ç”¨é‚£äº›ç”±å¤§å…¬å¸æˆ–åˆ›ä¸šå…¬å¸å¼€å‘çš„ç¥ç»ç½‘ç»œï¼Œæˆ–å…¶ä»–åœ¨GPUä¸ŠèŠ±äº†å¤§é‡èµ„é‡‘çš„äººï¼Œåˆ©ç”¨è¿™äº›è®­ç»ƒæ¥è¿›è¡Œä½ è‡ªå·±çš„é¡¹ç›®ã€‚æƒ³äº†è§£æˆ‘çš„AIè¯¾ç¨‹å’Œé¡¹ç›®çš„æœ€æ–°åŠ¨æ€ï¼Œè¯·ç‚¹å‡»è®¢é˜…æ—è¾¹çš„é“ƒé“›ï¼Œä»¥ä¾¿è·å¾—æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚
- en: '![](img/57e575643f505aee4c9c36ac4901f183_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57e575643f505aee4c9c36ac4901f183_2.png)'
- en: '![](img/57e575643f505aee4c9c36ac4901f183_3.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57e575643f505aee4c9c36ac4901f183_3.png)'
- en: Transfer learning is a very important concept in deep learningã€‚ This is because
    it can take a tremendous amount of timeã€‚ Compute resources and money to train
    advanced neural networksã€‚ particularly in the area of computer vision and natural
    language processingã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç§»å­¦ä¹ æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä¸€ä¸ªéå¸¸é‡è¦çš„æ¦‚å¿µã€‚è¿™æ˜¯å› ä¸ºå®ƒéœ€è¦å¤§é‡çš„æ—¶é—´ã€è®¡ç®—èµ„æºå’Œé‡‘é’±æ¥è®­ç»ƒå…ˆè¿›çš„ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«æ˜¯åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚
- en: You don't see transfer learning as much with tabular dataã€‚ because there's just
    not a lot of actual neural networks out there that are already trained for that
    sort of thingã€‚ It depends on your data set for tabular and the tabular dataset
    sets tend to be very differentã€‚ Comp imaging and computer vision there tends to
    be a lot of commonalitiesã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¡¨æ ¼æ•°æ®ä¸­ï¼Œä½ ä¸ä¼šçœ‹åˆ°è¿ç§»å­¦ä¹ ï¼Œå› ä¸ºå®é™…ä¸Šæ²¡æœ‰å¾ˆå¤šå·²ç»ä¸ºæ­¤ç±»æ•°æ®è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œã€‚è¿™å–å†³äºä½ çš„è¡¨æ ¼æ•°æ®é›†ï¼Œè¡¨æ ¼æ•°æ®é›†å¾€å¾€éå¸¸ä¸åŒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè®¡ç®—æˆåƒå’Œè®¡ç®—æœºè§†è§‰ä¹‹é—´å¾€å¾€æœ‰å¾ˆå¤šå…±åŒç‚¹ã€‚
- en: Some of the elements that you will see like edges and wheels and eyesï¼Œ nosesã€‚
    mouths are common across manyï¼Œ many computer vision tasksã€‚ So you can take some
    of the learning that large companies such as Google and Microsoft and others have
    put into trainingã€‚ these advanced neural networks and transferã€‚ğŸ˜Šï¼ŒData into your
    neural network to begin as a basisã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†çœ‹åˆ°çš„ä¸€äº›å…ƒç´ ï¼Œå¦‚è¾¹ç¼˜ã€è½®å­ã€çœ¼ç›ã€é¼»å­å’Œå˜´å·´ï¼Œåœ¨è®¸å¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­éƒ½æ˜¯å¸¸è§çš„ã€‚å› æ­¤ï¼Œä½ å¯ä»¥å°†è°·æ­Œã€å¾®è½¯ç­‰å¤§å…¬å¸åœ¨è®­ç»ƒè¿™äº›å…ˆè¿›ç¥ç»ç½‘ç»œæ—¶æ‰€ç§¯ç´¯çš„çŸ¥è¯†è¿ç§»åˆ°ä½ çš„ç¥ç»ç½‘ç»œï¼Œä»¥ä½œä¸ºåŸºç¡€ã€‚
- en: So if you're going to teach a neural network to recognize a couple of very specific
    image typesã€‚ you probably don't want to train the neural network entirely from
    scratchã€‚ if you can transfer in a neural network weight system that has already
    been trained on imagenet or some of the other common computer vision data setsã€‚
    The way that this works is you will typically find a pretrained neural network
    that will have a variety of layersã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå¦‚æœä½ æ‰“ç®—æ•™ä¸€ä¸ªç¥ç»ç½‘ç»œè¯†åˆ«å‡ ç§éå¸¸ç‰¹å®šçš„å›¾åƒç±»å‹ï¼Œä½ å¯èƒ½ä¸æƒ³å®Œå…¨ä»å¤´å¼€å§‹è®­ç»ƒè¿™ä¸ªç¥ç»ç½‘ç»œã€‚å¦‚æœä½ å¯ä»¥è¿ç§»ä¸€ä¸ªå·²ç»åœ¨ImageNetæˆ–å…¶ä»–å¸¸è§è®¡ç®—æœºè§†è§‰æ•°æ®é›†ä¸Šè®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæƒé‡ç³»ç»Ÿã€‚å…¶å·¥ä½œæ–¹å¼é€šå¸¸æ˜¯æ‰¾åˆ°ä¸€ä¸ªé¢„è®­ç»ƒçš„ç¥ç»ç½‘ç»œï¼Œå®ƒä¼šæœ‰å¤šå±‚ã€‚
- en: it doesn't even really matter exactly what these layers areã€‚ you can definitely
    display them and we'll see that when we run the programs here for this exampleã€‚
    and you will typically shear off the top partã€‚ So imagenet is very common one
    and some of the others you'll typically see them trained for 10 different image
    categoriesã€‚ So we might want to train it for something much smaller than thatã€‚
    We willã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å±‚åˆ°åº•æ˜¯ä»€ä¹ˆå…¶å®å¹¶ä¸é‡è¦ã€‚ä½ å¯ä»¥ç¡®å®å±•ç¤ºå®ƒä»¬ï¼Œå½“æˆ‘ä»¬åœ¨è¿™é‡Œè¿è¡Œç¤ºä¾‹ç¨‹åºæ—¶ä½ ä¼šçœ‹åˆ°ï¼Œé€šå¸¸ä½ ä¼šå‰Šå‡æ‰é¡¶éƒ¨éƒ¨åˆ†ã€‚æ‰€ä»¥ï¼ŒImageNetæ˜¯ä¸€ä¸ªéå¸¸å¸¸è§çš„æ•°æ®é›†ï¼Œå…¶ä»–ä¸€äº›æ•°æ®é›†é€šå¸¸ä¼šé’ˆå¯¹10ä¸ªä¸åŒçš„å›¾åƒç±»åˆ«è¿›è¡Œè®­ç»ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ä¸ºæ¯”è¿™å°å¾—å¤šçš„ä¸œè¥¿è¿›è¡Œè®­ç»ƒã€‚
- en: Move that top layer and transfer just these layersã€‚ These layersã€‚ All of the
    weights are going to move across into our neural networkã€‚ and we will train just
    the new layers that we add for our new neural networkã€‚ So here we add a dense
    layer that is going to learn from these lower layers and only these top two layers
    are going to actually be trainedã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç§»åŠ¨é‚£ä¸ªé¡¶å±‚ï¼Œä»…è½¬ç§»è¿™äº›å±‚ã€‚è¿™äº›å±‚çš„æ‰€æœ‰æƒé‡å°†è½¬ç§»åˆ°æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä¸­ã€‚æˆ‘ä»¬å°†ä»…è®­ç»ƒä¸ºæˆ‘ä»¬çš„æ–°ç¥ç»ç½‘ç»œæ·»åŠ çš„æ–°å±‚ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬æ·»åŠ ä¸€ä¸ªç¨ å¯†å±‚ï¼Œå®ƒå°†ä»è¿™äº›è¾ƒä½å±‚å­¦ä¹ ï¼Œè€Œåªæœ‰è¿™ä¸¤ä¸ªé¡¶å±‚å°†å®é™…è¢«è®­ç»ƒã€‚
- en: These bottom layers essentially become feature engineeringï¼Œ especially for computer
    vision tasksã€‚ These are learning all of the building blocks that went into imagenet
    and the other dataset sets that the neural network was trained onã€‚ Firstï¼Œ we're
    going to look at a very simple transfer learning exampleã€‚ and this will be tabular
    dataã€‚ This lets you look at a very simple will use the iris data setã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åº•å±‚åŸºæœ¬ä¸Šæˆä¸ºç‰¹å¾å·¥ç¨‹ï¼Œç‰¹åˆ«æ˜¯ç”¨äºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚è¿™äº›æ­£åœ¨å­¦ä¹ è¿›å…¥imagenetå’Œå…¶ä»–æ•°æ®é›†çš„æ‰€æœ‰æ„å»ºå—ï¼Œè¿™äº›æ•°æ®é›†æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒçš„åŸºç¡€ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†çœ‹ä¸€ä¸ªéå¸¸ç®€å•çš„è¿ç§»å­¦ä¹ ç¤ºä¾‹ï¼Œè¿™å°†æ˜¯è¡¨æ ¼æ•°æ®ã€‚è¿™ä½¿ä½ èƒ½å¤ŸæŸ¥çœ‹ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ã€‚
- en: just so that we can see the mechanics of how this all comes togetherã€‚ Typicallyã€‚
    you probably won't be creating transfer learning neural networks that others will
    transfer into theirs unless you're going to reallyã€‚ğŸ˜Šï¼ŒCommit to getting a lot of
    data and building an advanced training set up with GPUs and other things like
    that and spending some serious money For this oneã€‚ thoughï¼Œ we will create that
    initial neural network that we are going to transfer into something elseã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åªæ˜¯ä¸ºäº†è®©æˆ‘ä»¬çœ‹åˆ°è¿™ä¸€åˆ‡å¦‚ä½•ç»“åˆåœ¨ä¸€èµ·ã€‚é€šå¸¸ï¼Œä½ å¯èƒ½ä¸ä¼šåˆ›å»ºå…¶ä»–äººä¼šè½¬ç§»çš„è¿ç§»å­¦ä¹ ç¥ç»ç½‘ç»œï¼Œé™¤éä½ çœŸçš„ğŸ˜Šï¼Œæ‰¿è¯ºè·å–å¤§é‡æ•°æ®å¹¶å»ºç«‹ä¸€ä¸ªé«˜çº§è®­ç»ƒè®¾ç½®ï¼Œä½¿ç”¨GPUå’Œå…¶ä»–ä¸œè¥¿ï¼Œå¹¶èŠ±è´¹ä¸€äº›ä¸¥è‚ƒçš„é’±ã€‚ä¸è¿‡ï¼Œå¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬å°†åˆ›å»ºé‚£ä¸ªåˆå§‹çš„ç¥ç»ç½‘ç»œï¼Œç„¶åæˆ‘ä»¬å°†å…¶è½¬ç§»åˆ°å…¶ä»–åœ°æ–¹ã€‚
- en: and we're going to we're going to basically try to learn to classify some additional
    flowers beyond those three irriss that the data was originally set up forã€‚ We'll
    hope that some of the learning for the original iris data set will transfer to
    this new oneã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åŸºæœ¬ä¸Šè¦å°è¯•å¯¹æ¯”è¿™ä¸‰ä¸ªåŸå§‹é¸¢å°¾èŠ±æ•°æ®é›†ä¹‹å¤–çš„å…¶ä»–èŠ±è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬å¸Œæœ›åŸå§‹é¸¢å°¾èŠ±æ•°æ®é›†çš„ä¸€äº›å­¦ä¹ èƒ½å¤Ÿè½¬ç§»åˆ°è¿™ä¸ªæ–°çš„æ•°æ®é›†ä¸Šã€‚
- en: So here the first thing we're going to do is actually get our training data
    loaded in and build our neural networkã€‚ So this neural network that we're building
    here this simulates what the tech companies or researchers are doing using advanced
    computer rays to really seriously train theseã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹å°±æ˜¯åŠ è½½è®­ç»ƒæ•°æ®å¹¶æ„å»ºæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæ„å»ºçš„è¿™ä¸ªç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäº†ç§‘æŠ€å…¬å¸æˆ–ç ”ç©¶äººå‘˜ä½¿ç”¨é«˜çº§è®¡ç®—æŠ€æœ¯æ¥è¿›è¡Œä¸¥è‚ƒè®­ç»ƒçš„è¿‡ç¨‹ã€‚
- en: So now we have a iris data setã€‚ We would probably save it at this point so that
    we could transfer itã€‚ We'll check the accuracy real quickã€‚ which runs about 98%ã€‚
    So that's pretty accurate andã€‚Print out the summaryã€‚ We use summary a lot to analyze
    the neural networks that we're transferring in Here we can see that we essentially
    have some dense layersã€‚ the 50ï¼Œ25 and3ï¼Œ just like we set up up here for the neural
    networkã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªé¸¢å°¾èŠ±æ•°æ®é›†ã€‚æˆ‘ä»¬å¯èƒ½ä¼šåœ¨æ­¤æ—¶ä¿å­˜å®ƒï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿè½¬ç§»å®ƒã€‚æˆ‘ä»¬å¿«é€Ÿæ£€æŸ¥ä¸€ä¸‹å‡†ç¡®æ€§ï¼Œå¤§çº¦ä¸º98%ã€‚æ‰€ä»¥è¿™ç›¸å½“å‡†ç¡®ï¼Œå¹¶ä¸”ã€‚æ‰“å°å‡ºæ‘˜è¦ã€‚æˆ‘ä»¬ç»å¸¸ä½¿ç”¨æ‘˜è¦æ¥åˆ†ææˆ‘ä»¬è½¬ç§»çš„ç¥ç»ç½‘ç»œã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬åŸºæœ¬ä¸Šæœ‰ä¸€äº›ç¨ å¯†å±‚ï¼Œ50ï¼Œ25å’Œ3ï¼Œå°±åƒæˆ‘ä»¬åœ¨ç¥ç»ç½‘ç»œä¸­è®¾ç½®çš„é‚£æ ·ã€‚
- en: So 5025 and 3 summary can be very good for looking at these things and seeing
    what's going onã€‚ total parameters So that's how many weights we have in the neural
    network trainable parameters is the same in this case because everything is trainable
    Now when we transfer this simple neural network into something elseã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥5025å’Œ3çš„æ‘˜è¦åœ¨è§‚å¯Ÿè¿™äº›æƒ…å†µå’Œäº†è§£å‘ç”Ÿäº†ä»€ä¹ˆæ—¶éå¸¸æœ‰ç”¨ã€‚æ€»å‚æ•°å°±æ˜¯æˆ‘ä»¬åœ¨ç¥ç»ç½‘ç»œä¸­çš„æƒé‡æ•°é‡ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹å¯è®­ç»ƒå‚æ•°æ˜¯ç›¸åŒçš„ï¼Œå› ä¸ºæ‰€æœ‰å†…å®¹éƒ½æ˜¯å¯è®­ç»ƒçš„ã€‚ç°åœ¨ï¼Œå½“æˆ‘ä»¬å°†è¿™ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œè½¬ç§»åˆ°å…¶ä»–ä¸œè¥¿æ—¶ã€‚
- en: we're going to mark some of these untrainable and we'll see thatã€‚ So now I am
    going to show you that basically we can rebuild this neural networkã€‚ we're creating
    model2 sequentialã€‚ and I'm taking all the layers in the original model and adding
    them when we run thisã€‚ we see an exact duplicate up here 1603 just like we had
    up hereã€‚ And just as a sanity checkã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¼šæ ‡è®°ä¸€äº›ä¸å¯è®­ç»ƒçš„å±‚ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥ç°åœ¨æˆ‘å°†å‘ä½ å±•ç¤ºï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå¯ä»¥é‡å»ºè¿™ä¸ªç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬åˆ›å»ºäº†model2 sequentialã€‚æˆ‘å°†åŸå§‹æ¨¡å‹ä¸­çš„æ‰€æœ‰å±‚æ·»åŠ åˆ°è¿™é‡Œã€‚å½“æˆ‘ä»¬è¿è¡Œè¿™ä¸ªæ—¶ï¼Œæˆ‘ä»¬åœ¨ä¸Šé¢çœ‹åˆ°ä¸€ä¸ªå®Œå…¨çš„å‰¯æœ¬1603ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ä¸€æ ·ã€‚ä½œä¸º
    sanity checkã€‚
- en: we're going to evaluate model 2ã€‚SeeHere and see what the accuracy isã€‚ the accuracy
    should exactly match the original one that we transferredã€‚ So we have basically
    done transfer learning hereã€‚ We've transferred everythingã€‚ which is typically
    not what you'll want to doã€‚ We would have a duplicate of this neural network that
    can classify the same three flowers that the original neural network could not
    too usefulã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¯„ä¼°æ¨¡å‹2ã€‚è¯·æŸ¥çœ‹è¿™é‡Œï¼Œçœ‹çœ‹å‡†ç¡®ç‡æ˜¯å¤šå°‘ã€‚å‡†ç¡®ç‡åº”è¯¥ä¸æˆ‘ä»¬è½¬ç§»è¿‡æ¥çš„åŸå§‹å‡†ç¡®ç‡å®Œå…¨ä¸€è‡´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šå®Œæˆäº†è¿ç§»å­¦ä¹ ã€‚æˆ‘ä»¬å·²ç»è½¬ç§»äº†ä¸€åˆ‡ã€‚é€šå¸¸è¿™ä¸æ˜¯ä½ æƒ³è¦åšçš„äº‹æƒ…ã€‚æˆ‘ä»¬ä¼šæœ‰ä¸€ä¸ªé‡å¤çš„ç¥ç»ç½‘ç»œï¼Œå¯ä»¥åˆ†ç±»ä¸åŸå§‹ç¥ç»ç½‘ç»œç›¸åŒçš„ä¸‰ç§èŠ±ï¼Œä½†å¹¶ä¸å¤ªæœ‰ç”¨ã€‚
- en: where it becomes useful is if we have these fake flowers that we want to add
    to itã€‚ Now I'm just calling them fake flowersï¼Œ because are hypotheticalã€‚ This
    shows againã€‚ the mechanics you would go through if you wanted to truly create
    your own neural network that others could transferã€‚ What we're going to do is
    create now model 3ã€‚ and I'm just going to move those first two layers in and drop
    off the output layerã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå˜å¾—æœ‰ç”¨çš„åœ°æ–¹åœ¨äºï¼Œå¦‚æœæˆ‘ä»¬æƒ³æ·»åŠ è¿™äº›å‡èŠ±ã€‚æˆ‘ç§°å®ƒä»¬ä¸ºå‡èŠ±ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å‡è®¾çš„ã€‚è¿™å†æ¬¡æ˜¾ç¤ºäº†ï¼Œå¦‚æœä½ æƒ³çœŸæ­£åˆ›å»ºè‡ªå·±çš„ç¥ç»ç½‘ç»œä¾›ä»–äººè½¬ç§»æ—¶ï¼Œä½ ä¼šç»å†çš„æœºåˆ¶ã€‚æˆ‘ä»¬ç°åœ¨è¦åšçš„æ˜¯åˆ›å»ºæ¨¡å‹3ã€‚æˆ‘å°†æŠŠå‰ä¸¤å±‚ç§»å…¥å¹¶å»æ‰è¾“å‡ºå±‚ã€‚
- en: So these will be feature engineering for the new modelã€‚ You'll see we have fewer
    parameters because we've dropped off the top layer that was going to do the top
    are the final layerã€‚ depending on your perspectiveï¼Œ but the output layerï¼Œ what
    we dropped offã€‚ Now we're goingã€‚ğŸ˜Šã€‚To add on a new softm layer with four output
    neurons to classify those fourth leg fake flowersã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å°†æ˜¯æ–°æ¨¡å‹çš„ç‰¹å¾å·¥ç¨‹ã€‚ä½ ä¼šçœ‹åˆ°æˆ‘ä»¬çš„å‚æ•°æ›´å°‘ï¼Œå› ä¸ºæˆ‘ä»¬å»æ‰äº†åŸæœ¬è¦åšæœ€ç»ˆå±‚çš„é¡¶å±‚ï¼Œè¿™å–å†³äºä½ çš„è§‚ç‚¹ï¼Œä½†æˆ‘ä»¬å»æ‰çš„æ˜¯è¾“å‡ºå±‚ã€‚ç°åœ¨æˆ‘ä»¬è¦æ·»åŠ ä¸€ä¸ªæ–°çš„softmaxå±‚ï¼Œå¸¦æœ‰å››ä¸ªè¾“å‡ºç¥ç»å…ƒï¼Œä»¥åˆ†ç±»è¿™å››ç§å‡èŠ±ã€‚
- en: We run that And we see that basically now we have the 5025ï¼Œ but we have a four
    attached to itã€‚ Nowã€‚ we could have also added some additional dense layers to
    maybe give some additional processingã€‚ But for this simple of a networkï¼Œ not reallyï¼Œ
    not really necessaryã€‚ Nowï¼Œ we alsoã€‚ when we added these mark the new ones trainable
    falseã€‚ Nowã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿è¡Œå®ƒï¼ŒåŸºæœ¬ä¸Šç°åœ¨æˆ‘ä»¬æœ‰5025ï¼Œä½†æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ª4é™„åŠ åœ¨ä¸Šé¢ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ·»åŠ ä¸€äº›é¢å¤–çš„å¯†é›†å±‚ï¼Œä¹Ÿè®¸å¯ä»¥æä¾›ä¸€äº›é¢å¤–çš„å¤„ç†ã€‚ä½†å¯¹äºè¿™æ ·ç®€å•çš„ç½‘ç»œï¼Œå…¶å®å¹¶ä¸æ˜¯ç‰¹åˆ«å¿…è¦ã€‚ç°åœ¨ï¼Œå½“æˆ‘ä»¬æ·»åŠ è¿™äº›æ ‡è®°çš„æ–°å±‚æ—¶ï¼Œå°†å…¶å¯è®­ç»ƒæ€§è®¾ç½®ä¸ºfalseã€‚
- en: for the original layers that we transferred inï¼Œ we march trainable is false
    up hereã€‚ That's very important for transfer learningï¼Œ because we don't want to
    train the weights that we already hadã€‚ that's what we're transferring inã€‚ That's
    the benefitã€‚ So here you'll see that the total parameters is 1629ã€‚ But only 1525
    of themï¼Œ the first two layersã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬è½¬ç§»è¿›æ¥çš„åŸå§‹å±‚ï¼Œè¿™é‡Œå¯è®­ç»ƒæ€§è®¾ç½®ä¸ºfalseã€‚è¿™å¯¹äºè¿ç§»å­¦ä¹ éå¸¸é‡è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æƒ³è®­ç»ƒæˆ‘ä»¬å·²ç»æ‹¥æœ‰çš„æƒé‡ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¿›è¡Œè½¬ç§»çš„åŸå› ã€‚è¿™æ˜¯å¥½å¤„ã€‚å› æ­¤ï¼Œä½ ä¼šçœ‹åˆ°æ€»å‚æ•°ä¸º1629ï¼Œä½†å…¶ä¸­åªæœ‰1525æ˜¯å‰ä¸¤å±‚ã€‚
- en: the input and the 5025ï¼Œ those are the only trainable layersã€‚ So those numbers
    are different hereã€‚ I create just some contrived valuesã€‚ğŸ˜Šï¼ŒThat we will use for
    these four flowersã€‚ I'm only giving two training samples on eachã€‚ But againã€‚ this
    is just showing the mechanics that you would go throughã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥å’Œ5025æ˜¯å”¯ä¸€å¯è®­ç»ƒçš„å±‚ã€‚æ‰€ä»¥è¿™äº›æ•°å­—åœ¨è¿™é‡Œæ˜¯ä¸åŒçš„ã€‚æˆ‘åˆ›é€ äº†ä¸€äº›äººä¸ºçš„å€¼ï¼Œè¿™äº›å€¼å°†ç”¨äºè¿™å››ç§èŠ±ã€‚æˆ‘åªç»™æ¯ç§èŠ±ä¸¤ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ä½†è¿™åªæ˜¯å±•ç¤ºäº†ä½ å°†è¦ç»å†çš„æœºåˆ¶ã€‚
- en: Here's the one hot encoding for each of those four flowers that correspond to
    the X inputs hereã€‚ We're going to fit the neural network with just training that
    final output layerã€‚ and we're going to try to see how well it can classify those
    four new flower typesã€‚ We run itã€‚ we see the accuracy the last time I run it was
    about 88ã€‚ We'll see what this is1ã€‚0ã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸Xè¾“å…¥ç›¸å¯¹åº”çš„è¿™å››ç§èŠ±çš„ç‹¬çƒ­ç¼–ç ã€‚æˆ‘ä»¬å°†ä»…é€šè¿‡è®­ç»ƒæœ€åçš„è¾“å‡ºå±‚æ¥æ‹Ÿåˆç¥ç»ç½‘ç»œï¼Œå¹¶è¯•å›¾çœ‹çœ‹å®ƒèƒ½å¤šå¥½åœ°åˆ†ç±»è¿™å››ç§æ–°èŠ±å‹ã€‚æˆ‘ä»¬è¿è¡Œå®ƒï¼Œçœ‹åˆ°ä¸Šæ¬¡è¿è¡Œæ—¶çš„å‡†ç¡®ç‡å¤§çº¦ä¸º88ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹è¿™æ˜¯ä»€ä¹ˆã€‚
- en: So actually perfect accuracy in this caseã€‚ So it's the stochastic nature of
    neural networksã€‚ you'll get different resultsã€‚ So here we've gone through the
    entire process of thisã€‚ So this is how you would truly create a neural network
    that you would want to transferã€‚ The rest of this courseã€‚ we will be transferring
    in other people's neural networks to us rather than being the producer of thoseã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹å®é™…ä¸Šæ˜¯å®Œç¾çš„å‡†ç¡®ç‡ã€‚è¿™æ˜¯ç¥ç»ç½‘ç»œçš„éšæœºæ€§è´¨ï¼Œä½ ä¼šå¾—åˆ°ä¸åŒçš„ç»“æœã€‚å› æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†æ•´ä¸ªè¿‡ç¨‹ã€‚è¿™å°±æ˜¯ä½ å¦‚ä½•çœŸæ­£åˆ›å»ºä¸€ä¸ªä½ æƒ³è¦è½¬ç§»çš„ç¥ç»ç½‘ç»œã€‚æ¥ä¸‹æ¥çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†è½¬ç§»å…¶ä»–äººçš„ç¥ç»ç½‘ç»œï¼Œè€Œä¸æ˜¯è‡ªå·±å»åˆ¶ä½œé‚£äº›ç½‘ç»œã€‚
- en: So we'll simply be the consumerï¼Œ which is usually how it goesã€‚ Thank you for
    watching this video in the next videoã€‚ we're going to take a look at howã€‚ğŸ˜Šã€‚![](img/57e575643f505aee4c9c36ac4901f183_5.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†ç®€å•åœ°æˆä¸ºæ¶ˆè´¹è€…ï¼Œè¿™é€šå¸¸æ˜¯æƒ…å†µçš„å¸¸æ€ã€‚æ„Ÿè°¢ä½ è§‚çœ‹è¿™æ®µè§†é¢‘ï¼Œåœ¨ä¸‹ä¸€ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ã€‚ğŸ˜Šï¼[](img/57e575643f505aee4c9c36ac4901f183_5.png)
- en: To actuallyã€‚Find some of theseã€‚Open neural networks that you can put into your
    own learning for transfer learningã€‚ This content changes oftenã€‚ so subscribe to
    the channel to stay up to date on this course and other topics in artificial intelligenceã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šè¦æ‰¾åˆ°ä¸€äº›è¿™æ ·çš„å¼€æ”¾ç¥ç»ç½‘ç»œï¼Œä½ å¯ä»¥å°†å…¶åº”ç”¨äºè‡ªå·±çš„å­¦ä¹ ä»¥è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚è¿™ä¸ªå†…å®¹ç»å¸¸æ›´æ–°ï¼Œæ‰€ä»¥è¯·è®¢é˜…é¢‘é“ä»¥ä¿æŒå¯¹æœ¬è¯¾ç¨‹åŠå…¶ä»–äººå·¥æ™ºèƒ½ä¸»é¢˜çš„æœ€æ–°äº†è§£ã€‚
