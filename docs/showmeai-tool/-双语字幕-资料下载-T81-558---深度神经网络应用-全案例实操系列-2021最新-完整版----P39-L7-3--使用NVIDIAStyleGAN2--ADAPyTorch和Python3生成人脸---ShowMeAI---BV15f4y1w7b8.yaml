- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P39：L7.3- 使用NVIDIAStyleGAN2-
    ADAPyTorch和Python3生成人脸 - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to applications of deep neural networks with Washington University In
    this video。 we're going to take a look at using NviDdia stylegan 2 AD for Ptorrch
    to get some really quality G face images。 Now， previously we saw that we could
    use our own technology our own custom built neural network to generate GNs。 but
    the faces didn't look particularly good。 It takes a lot of compute power and a
    lot of clever algorithms to really get high quality faces like you see with stylegan。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: So we're going to look at Stgan2 AD Ptorrch， which is really the latest technology
    in this area。![](img/c3dd1d946bd070469333fc209ecae79b_1.png)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 🎼。Okay， let's have a look at the code。 So this is the module that there's a
    link to in the description。 And I do put the note here。 This module requires pytorch。
    So most of this course that I teach you is in Tensorflowkis。 There's two parts。
    at least as of the recording of this video that I do make use of pytorrch。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: That is for reinforcement learning and also for stylegan。 This is mainly just
    because。These two very important libraries in this case， stylegan in the case
    of reinforcement learning。 stable baselines have made the switch to Pytorch and
    really the neural network is kind of below everything that you're doing so you
    really almost don't notice it。I am adding in more pytorch components as optional
    directions in this course so that you can see some of the same technology with
    Pytorch Pytorch is gaining a lot of momentum and it's a very especially in research。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: it's a very used technology are a framework for implementing deep learning all
    the underlying underpinnings are the same thing even the pickle files that I created
    with the old version of stylegan before NviIDdia made the switch to Pytorch the
    pickle files。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: the saved neural networks can just be loaded right into Pytorch So the underlying
    technologies are all the same essentially between these Now you'll see with stylegan2
    AD there are all these very。 very high quality faces that you can generate these
    are not real people they were generated by stylegan to ADA and by the way。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: the AD on the end that's augmented essentially you see it here with。CaSo maybe
    there is just one picture of the cat in the original one， but as they train。 they
    put a higher probability of augmentation happening and augmentation is one of
    the big breakthroughs in computer vision in terms of augmenting the images rotating
    them doing other distortions on them so that you have additional training data
    when training these Gs and I'll show you some of theganNs that I've trained from
    scratch in this class we're talking primarily just about generatingganNs from
    networks that are already trained to generate your owngans。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: you need high end GPU and I mean you can do with coab but coLab Pro really buts
    it takes a lot of compute most of the GNs that I generated were done on highend
    GPUs that I let run four days generating these but here you can see the images
    they look they all look quite realistic there are some some things that will tip
    you off that you're not looking at a real。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要高端GPU，我的意思是你可以用Colab，但Colab Pro真的需要很多计算资源。我生成的大部分图像都是在我让其运行四天的高端GPU上生成的。但在这里你可以看到这些图像，它们看起来都非常逼真，不过有些东西会让你意识到你看到的不是现实的图像。
- en: Image consider these at first glance， these look very， very realistic。 But if
    you look at the background， that's usually a telltale sign that you're looking
    at a generated image。 The background is kind of whimsical kind of mysterious。
    You're not quite sure what you're what you're looking at。 Also。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，这些看起来非常非常逼真。但如果你看背景，通常是一个明显的迹象，表明你看到的是生成的图像。背景有点异想天开，有点神秘。你不太确定自己在看什么。还有。
- en: things that are not the face will not look as as good like earrings。 It has
    a hard time with earrings。 noticeice her earrings very rarely does a again create
    symmetric earrings。Also the clothing， I mean， there's a button， maybe there and
    I'm granted。 I'm not the best at at always having my my clothes neat prem and
    proper if you've watched my videos。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 非脸部的东西看起来不会那么好，比如耳环。耳环的表现很差。注意她的耳环，很少会出现对称的耳环。此外，衣服，我的意思是，那里可能有一个按钮，我承认。我不是总能让我的衣服整洁得体，如果你看过我的视频的话。
- en: But the collar will usually be a little disheveel for me。 That would look entirely
    normal。 I guess it does not know the difference between one face and two faces。
    So some of the training data as good as Ninvidia did in curating it and and paying
    people to remove certain things。 Some of them have multiple faces。 And you can
    see this， this guy has a twin that is appearing here。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但领子对我来说通常会有点凌乱。那看起来完全正常。我想它无法分辨一个脸和两个脸之间的区别。因此，尽管NVIDIA在策划训练数据和支付人们去去除某些东西方面做得很好，但其中一些却有多个面孔。你可以看到，这个家伙在这里有一个双胞胎。
- en: and it's extremely distorted。 Similarlyly， hands。 She has moved her hand up
    into the frame and it's not looking so good hats it's。 it's hard to tell on hats。
    I mean， hats can be very bizarre， especially in high fashion。 But usually hats
    will sort of blend into the hair， like you're seeing here， not real。 And her her
    neck is。Really， really slender。 So looking at those， you can see another thing
    if。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 而且它极度扭曲。类似地，手。她把手移到了画面中，看起来并不好。很难判断她的帽子。我是说，帽子可能会非常奇怪，尤其是在高端时尚中。但通常帽子会和头发融为一体，就像你在这里看到的那样，不真实。而她的脖子真的，真的很细。看看这些，你可以看到另一件事。
- en: I were to produce a video of just going through all kinds of random faces。 you
    would notice that their eyes are always in exactly the same spot and by that。
    I mean the two eyes Now their face and head can move around a bit but the eyes
    are pegged to right here and the reason that is is more of a quirk in the way
    that NviDIdia train these is they used a feature detector to detect where the
    eyes were to crop so they centered each of the pictures around the eyes because
    you know people are in all kinds of weird positions and flickr and these pictures
    all came from flickr the training data so those are some of the things that you
    will notice as you work through these kinds of images Now I want to actually show
    you how to generate some of these so I'm going to go ahead and open this in collab
    because you've got to have a GPU to run this。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我要制作一个视频，展示各种随机面孔。你会注意到他们的眼睛总是在完全相同的位置。我的意思是，两个眼睛。现在，他们的脸和头可以稍微移动，但眼睛却固定在这里。这是因为NVIDIA训练这些模型的方式的一个特性，他们使用特征检测器来检测眼睛的位置进行裁剪，因此他们围绕眼睛居中每张图片，因为你知道人们会处于各种奇怪的位置，这些图片都来自Flickr的训练数据。所以这是你在处理这些类型的图像时会注意到的一些事情。现在，我想向你展示如何生成一些这样的图像，所以我将去Colab打开这个，因为你需要有GPU才能运行这个。
- en: Now you could probably run this just fine without a GPU for training no way。
    but for generating them potentially is it it generates very， very quickly。 but
    this is software from NVIDdia so they assume you have a GPU it's just the way
    it works and especially Pytorrch Pytorch。 you kind of have to program it differently
    for a GPU versus a non GPU so a lot of Pytorrch that you will see code。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能可以在没有GPU的情况下很好地运行这个训练，但生成时可能会很快。但这是NVIDdia的软件，所以他们假设你有一个GPU，这就是它的工作方式，尤其是Pytorrch，你需要为GPU和非GPU以不同方式编程，因此你看到的很多Pytorrch代码。
- en: Does require a GPU just because the original researcher programmed it that way。
    actually need to update that I will remove that。 We're actually not using Tensorflowlow
    1。 x。 That was one of the problems with the old version before NviIDdia upgraded
    it they had used a very old version of Tensorflowlow。 but now they are using the
    latest hightorrch， at least as of the recording of this video。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为原始研究人员以那种方式编程，所以需要一个GPU。实际上我需要更新一下，我会去掉这一点。我们实际上并没有使用Tensorflowlow 1。x。这是NviIDdia升级之前旧版本的一个问题，他们使用了非常旧的Tensorflowlow版本。但现在他们使用的是最新的hightorrch，至少在录制这段视频时是这样。
- en: So I'm going to go ahead and run that and I do trust myself， I created this，
    this notebook anyway。 and I'm going to do this so that I do have access to my
    G drive。You may want to do this as well。 because if you generate some of these
    images， you you'll probably want to save them。 So I'm putting that into there
    and it's no security breach。 that I'm letting you see that code。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我会继续运行这个，我相信我自己，我创建了这个笔记本。我将这样做，以便我可以访问我的G驱动器。你可能也想这样做，因为如果你生成了一些图像，你可能想保存它们。所以我把它放到那里，这并不是安全漏洞，我让你看到那段代码。
- en: This is all you have to do to really install it。 You have to clone it。 Piytorrch
    is installed by default in collab。 You do also need ninja。 Ninja that add in for
    Pytorrch that。This that NviDIdia made use of for this。 Now。 if you look at that，
    if you look at stug into8A Ptorch， you'll see the latest version here。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要这样做就可以真正安装它。你需要克隆它。Piytorrch在collab中默认安装。你还需要ninja。Ninja是NviDIdia为此使用的Pytorrch添加功能。如果你查看stug
    into8A Ptorch，你会看到这里的最新版本。
- en: we just cloned it right into our content on coabab is where you store all of
    your content that's temporary。 This gets blown away as soon as you exit coab。
    So be aware of that that's why we have to get it back each time。 Now I'm going
    to generate some images。 And what we're going to do here is we're going to use
    pretrained faces code from NviDdia and we're going to generate seeds 6600 to 25。
    I'll explain that in a moment。 So let's go ahead and run this。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚将其克隆到我们的内容中，coabab是你存储所有临时内容的地方。一旦你退出coab，这些内容就会被清除。所以要注意这一点，这就是为什么我们每次都需要重新获取它。现在我将生成一些图像。我们将使用NviDdia的预训练人脸代码生成6600到25的种子。我稍后会解释这一点。现在让我们继续运行这个。
- en: So these seeds these are just random number seeds that will cause the random
    number to generate consistently random numbers across。 So the way again really
    works is you're generating the image from a 512 number vector and that 512 number
    vector。Is giving you is each each of those numbers generates part of of the image。
    So if you change one of them just slightly， it's going to change the image ever
    so slightly。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些种子只是随机数种子，会使随机数生成一致的随机数字。再次说明，实际工作方式是你是从一个512数字向量生成图像，而那个512数字向量中的每一个数字都生成图像的一部分。所以如果你稍微改变其中一个数字，它会稍微改变图像。
- en: That is how you do these kind of transitional images and videos videos actually
    that you are watching here as as I go through this this part I'm going to show
    you how to create that a video just like that of your of your own Now this takes
    a moment for this to install everything that's needed。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是如何制作这种过渡图像和视频的方法，实际上你在这里观看的这些视频，在我进行这个部分时，我将向你展示如何创建你自己的那种视频。现在，这需要一些时间来安装所需的一切。
- en: there's two now it's there's two kernels that Nvi uses to make this go faster。
    Actually。 since they have custom kernels， this would not work on a CPU So I take
    I take that back what I said previously you would have to recode those kernels
    and that would not be fun So here we have the images they were generated they
    are now sitting in my content results and I could basically copy them to my G
    drive if I wanted to。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有两个Nvi使用的内核来加速这个过程。实际上，由于他们有自定义内核，这在CPU上是无法工作的。所以我收回之前说的话，你必须重新编码这些内核，那样可不有趣。所以这里有生成的图像，它们现在保存在我的内容结果中，如果我想的话，我可以基本上将它们复制到我的G驱动器。
- en: I'll show you another way to， to get to those。 So if you look at that， you can
    see them there。 And now if we run this section。 if you get this error here， you'll
    see basically that stylegan 2。 not a directory， that just means that you didn't
    create the the folder on your G drive。 I just corrected that。 So if I run this。
    Now they copy there。 So if I go to my G drive。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我会向你展示另一种获取这些图像的方法。所以如果你查看，可以看到它们在那里。现在如果我们运行这个部分，如果你在这里得到这个错误，你会看到基本上是stylegan
    2。不是一个目录，这仅仅意味着你没有在你的G驱动器上创建文件夹。我刚刚纠正了这个。所以如果我运行这个。现在它们被复制过来了。所以如果我去我的G驱动器。
- en: you'll see that I have a project stylegan 2， let me refresh it。 and you should
    see the。The images that it generated there they all are。 So you can click on these
    download them individually。 These are the images that styleylegan generates。 Now。
    I'm going to run this code which basically just sets up some code so that we can
    change those seeds into the actual vectors because we want to modify those 512
    number vectors to。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到我有一个项目stylegan 2，稍微刷新一下。你应该能看到生成的图像，它们都在这里。所以你可以点击这些，单独下载它们。这些是stylegan生成的图像。现在，我将运行这段代码，它基本上只是设置一些代码，以便我们可以将这些种子转换为实际的向量，因为我们想修改那512个数字向量。
- en: to do some of the things that we're going to do here。 This is just quick function
    to display an image， and this is a function that I wrote that uses the NviDdia
    code to actually generate an image。 Now， some of the things that you'll that you'll。😊。![](img/c3dd1d946bd070469333fc209ecae79b_3.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 做我们将在这里做的一些事情。这只是一个快速的函数来显示图像，这是我写的一个函数，它使用NviDdia的代码来实际生成图像。现在，你会看到的一些事情。😊。![](img/c3dd1d946bd070469333fc209ecae79b_3.png)
- en: '![](img/c3dd1d946bd070469333fc209ecae79b_4.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3dd1d946bd070469333fc209ecae79b_4.png)'
- en: That you'll see in here too is we're dealing also with labels。 I'm not going
    to really get into into labels in this video。 I could certainly do a video on
    that usually you have the GN that you're using and we're using all pre-trainedganNs
    here has to have been trained for labels。So for example， say you trained yourgan
    on pictures of puppies and pictures of kitties， cats。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里你还会看到我们也在处理标签。我在这个视频中不会真正深入标签。我当然可以做一个关于这个的视频，通常你会有你使用的GN，而我们在这里使用的是所有预训练的ganNs，必须已经为标签进行过训练。所以例如，假设你在小狗和小猫的图片上训练了你的gan。
- en: if you don't put labels in there， it'll do quite good， it'll give you cats。
    I'll give you dogs and it'll give you cats that look kind of like dogs and vice
    versa you can label them so that you're telling it what class it is and then you
    can request when it's being generated to generate something more like a cat or
    like a dog。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不在那里放标签，它会表现得相当不错，它会给你猫，会给你狗，也会给你看起来有点像狗的猫，反之亦然。你可以给它打标签，这样你就告诉它是什么类别，然后你可以在生成时请求生成更像猫或狗的东西。
- en: they have one actually in in the NviDdia stylegan page that is trained for this
    and it's generating very low resolution images from the from the C images set
    if I remember right。 Yeah， the CR 10 one if you've worked with this， these are
    10 these are。Fairly low resolution in 32 by 32 images that was used earlier in
    machine learning of 10 different types of image for。The data set so if you look
    at CR， I forget what the 10 classes are for CR。Airplanes， automobiles。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，他们在NviDdia的stylegan页面上有一个为此训练的模型，它从C图像集中生成非常低分辨率的图像，如果我没记错的话。是的，CR 10的那个，如果你用过这些，它们是10个。这些是32乘32的图像，早期在机器学习中使用的10种不同类型的图像数据集。所以如果你查看CR，我忘了CR的10个类别是什么。飞机，汽车。
- en: birds， cats， deer dogs， so this data set has these 10 classes all mixed in and
    to get the best results。 you created a labeled G and you can pick which of these
    that you want to generate otherwise。Gans are not too good without without that
    labeling of distinguishing between between different things。 I'll show you an
    example of a very broadly trained GN when we get to that in。This lecture。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟、猫、鹿、狗，这个数据集混合了这10个类别，为了获得最佳结果。你创建了一个标记的G，然后可以选择想要生成的类别。否则，Gans在没有区分不同事物的标记时效果不佳。我会给你展示一个广泛训练的GN示例，等我们讲到那时。
- en: you can pass in a truncation Pi vary that will change the quality that you're
    getting。 you can also introduce noise。 I keep it constant。 If you introduce noise。
    you'll see the hair and other small things change small thing so it won't change
    into an entirely different person but it will look almost like the hair is blowing
    in the wind if you generate a bunch of if you set this to random instead constant
    and then the class index。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以传入一个截断的Pi变体，这将改变你所得到的质量。你也可以引入噪声。我保持它恒定。如果你引入噪声，你会看到头发和其他小东西会改变一些小细节，所以它不会变成完全不同的人，但看起来几乎就像头发在风中飘动。如果你将这个设置为随机而不是恒定，然后再调整类索引。
- en: I'm not really using that for this class so I won't have that there and you
    run that and then here you're going to pick which pre-trained one。 I'm going to
    use the fishgan。 this is one of my own。 I trained this I trained the scan I use
    flickicker and got a whole bunch of fish images and this is basically just showing
    you how you will load a pretrainedgan。It's just a pickle file。I actually trained
    this one on the old Tensorflow version。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上并不在这个课程中使用它，所以我不会有这个。你运行这个，然后在这里选择哪个预训练的模型。我将使用fishgan。这是我自己的一个。我训练了这个模型，使用Flicker获取了一堆鱼的图像，这基本上就是向你展示如何加载一个预训练的gan。这只是一个pickle文件。我实际上是在旧的Tensorflow版本上训练的。
- en: so it shows you how compatible these are， and I'm going to generate random fish
    from these seeds from 1000 to 1003。 And there's three random fish。 And you can
    see they look really， pretty， pretty good。 If you go through a bunch of different
    ones。 Some of them are definitely not as good as others。 I mean， this one has
    an eye here and a very long mouth。 This does not have an eye。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它展示了这些模型的兼容性，我将从1000到1003生成随机鱼。这里有三条随机鱼。你可以看到它们看起来真的很不错。如果你查看不同的样本，有些确实不如其他的好。这条鱼这里有一个眼睛，还有一个很长的嘴巴，而这条没有眼睛。
- en: and this one has an eye here， but an unusual sort of nose， but they look， they
    look really， very。😊。Very fishlike you can generate quite a bit more if you put
    additional seeds in there。 And you can see some of these look really， they really
    very nice fish。 You can see these fish really look pretty good。 This one looks
    quite good， quite good here。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个鱼有一个眼睛，但有一种不寻常的鼻子，不过它们看起来，真的很像鱼。😊 如果你再放入更多的种子，你可以生成更多的鱼。你会发现这些鱼看起来真的很不错。这条鱼看起来相当不错。
- en: And that's a bit abstract as is that one。 Now you can vary the latent vector。
    The latent vectors that 512 number vector that we're generating that actually
    creates these。 So I。😊。And basically going to， I'm going to use the F F HQ。 So
    I'm going to use actual faces。 and I'm going to run this code here that I wrote。
    What this is doing is loading the。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 那有点抽象，现在你可以改变潜在向量。那个512数字的潜在向量实际上创建了这些图像。所以我。😊 我将使用F F HQ，所以我将使用真实的面孔。我将运行我写的这段代码。这段代码的作用是加载。
- en: Faces so that I I can use now I'm going to transition between seeds 1000， 1003
    and 1001。 Let me go ahead and run this just so that it's going。And what this does
    is I'm using 100 steps to get between 1000， 1003， 1001， so these individual seeds。
    if you go from seed 1000 to 1001， it's going to be a completely different looking
    person。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 面孔，所以我现在可以使用它。我将进行1000、1003和1001之间的过渡。让我运行这个，以便它可以进行。这样做是我使用100步在1000、1003和1001之间进行过渡，所以这些单独的种子。如果你从种子1000过渡到1001，那将会是一个完全不同样子的人。
- en: but if you take that big vector of 512 numbers that that seed generated。Then
    you're going to get the more gradual results and right now I'm generating for
    each of these people。 I'm transitionisting from 1000 to person 1003 back to person
    1001。And you can see it takes it a little while to generate this。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你拿到那个由512个数字组成的种子生成的大向量，那么你将会得到更渐进的结果。现在我正在为这些人生成图像。我正在从1000过渡到1003，再回到1001。你可以看到生成这些图像需要一些时间。
- en: This is generating just a whole bunch of frames as I go through and gradually
    just sort of skew from one vector to another。 you can see I basically get my vector1
    and2。 I take the difference of the two vectors linear algebra style I divide that
    difference by the number of steps。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这段话生成了一整堆帧，当我逐渐从一个向量偏移到另一个向量时。你可以看到我基本上得到了我的 vector1 和 vector2。我采用这两个向量的差异，按线性代数的方式，将差值除以步数。
- en: and that's the value that I keep using each time to be my steps。 So I'm adding
    that step vector。 which is added to the original vector slowly takes it to to
    the second vector and this is almost done。 let's go ahead and fast forward。 Allright，
    it's done with that。 and then I use something called FF Mpeg to convert all those
    frames back into a video and now we can download the video。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我每次使用的值，作为我的步数。所以我添加了那个步向量。它慢慢地加到原始向量上，最终到达第二个向量，差不多完成了。让我们快进一下。好了，这部分完成了。然后我使用一个叫做
    FF Mpeg 的工具将所有这些帧转换回视频，现在我们可以下载这个视频。
- en: It prepares it and I'm going to go ahead and open the video and there you can
    see the transition。 I'm basically transitioning。en those those key images that
    I picked and you're able to see those those people trans in in real time。 Now
    you can train your owngans。 These are somegans that I trained。 There's the fishgan。
    I trained one on Minecraft as well science fiction pictures。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它正在准备视频，我会打开视频，你可以看到过渡。我基本上是在过渡这些我选择的关键图像，你能实时看到那些人的转换。现在你可以训练你自己的 GAN。这些是我训练的一些
    GAN，其中有一个是鱼 GAN。我也训练了一个关于 Minecraft 的，科学幻想图片。
- en: and then I wanted to try something really crazy。 I took just a bunch of random
    Christmas holiday videos。 I mean， there were lights， there were Christmas trees。
    There were。Santa Claus is all kinds of stuff GNs don't do as well on that because
    there's nothing really to specialize on so it creates some really wild sort of
    Christmas E kind of nightmare before Christmas E images and I give you links to
    all my pretraingans there if you want to generate any of your own Minecraft images
    or other things。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我想尝试一些非常疯狂的事情。我拿了一些随机的圣诞假期视频。我的意思是，那里有灯光，有圣诞树，还有各种各样的圣诞老人。因为没有什么特别的，所以 GNs
    在这方面做得不是很好，这导致了一些非常狂野的、类似于《圣诞前夜》的图像。如果你想生成自己的 Minecraft 图像或其他东西，我给你所有的预训练模型的链接。
- en: '![](img/c3dd1d946bd070469333fc209ecae79b_6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3dd1d946bd070469333fc209ecae79b_6.png)'
