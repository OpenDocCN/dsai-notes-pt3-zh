# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPyTorch ÊûÅÁÆÄÂÆûÊàòÊïôÁ®ãÔºÅÂÖ®Á®ã‰ª£Á†ÅËÆ≤Ëß£ÔºåÂú®ÂÆûË∑µ‰∏≠ÊéåÊè°Ê∑±Â∫¶Â≠¶‰π†&Êê≠Âª∫ÂÖ®pipelineÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P3ÔºöL3- ‰ΩøÁî® Autograd ËÆ°ÁÆóÊ¢ØÂ∫¶ - ShowMeAI - BV12m4y1S7ix

HiÔºå everybody„ÄÇ Welcome to a new pytorrch tutorial„ÄÇ Today„ÄÇ we learn about the autograd package in pytorrch and how we can calculate gradients with it„ÄÇ Grds are essential for our model optimization„ÄÇ So this is a very important concept that we should understand„ÄÇLuckilyÔºå Pytorch provides the autograd packageÔºå which can do all the computations for us„ÄÇ

 We just have to know how to use it„ÄÇ So let's start to see how we can calculate gradients in pieytorrch„ÄÇ So first of allÔºå we import torch„ÄÇ Of course„ÄÇüòäÔºåAnd now let's create a tenor x equals torch dot R n of size 3„ÄÇ And now let's print our x„ÄÇ So this is a tenzor with three values„ÄÇ So three random values„ÄÇAnd now„ÄÇ let's say laterÔºå we want to calculate the gradients of some function with respect to x„ÄÇ

 Then what we have to do is we must specify the argument requires Gr equals true„ÄÇ So by default„ÄÇ this is false„ÄÇAnd now if we run this againÔºå then we see that also Pyto tracks that it requires the gradient„ÄÇAnd now„ÄÇWhenever we do operations with this tenorÔºå Py toch will create a so called computational graph for us„ÄÇ So now let's say we do the operation x plus 2Ôºå and we start this in an output„ÄÇ

 So we say y equals x plus 2„ÄÇ Then this will create the computational graph„ÄÇ![](img/cecd5af4135b2f12f1bfa0bb78e5d673_1.png)

And this looks like this„ÄÇSo for each nodeÔºå we have a for each operation„ÄÇ we have a node with inputs and an output„ÄÇ So here the operation is the plus„ÄÇ So in addition„ÄÇAnd our inputs are x and 2Ôºå and the output is y„ÄÇAnd now with this graph and the technique that is called back propagation„ÄÇ we can then calculate the gradients„ÄÇI will explain the concept of Beck propagation in detail in the next video„ÄÇ

 But for nowÔºå it's fine to just know that we or how we can use it„ÄÇSo firstÔºå we do a forward pass„ÄÇ So here we apply this operation„ÄÇ And in the forward passÔºå we calculate the output y„ÄÇAnd since we specified that it requires the gradient„ÄÇ Pytoch will then automatically create and store a function for us„ÄÇ

 And this function is then used in the back proagation and to get the gradients„ÄÇ So here y has an attribute Gr underscore F N„ÄÇ So this will point to a gradient function„ÄÇ And in this caseÔºå it's called at add backward„ÄÇAnd with this function„ÄÇ we can then calculate the gradients in the so called backward pass„ÄÇ

 So this will calculate the gradient of y with respect to x in this case„ÄÇ So now if we print y„ÄÇ![](img/cecd5af4135b2f12f1bfa0bb78e5d673_3.png)

Then we will see exactly this grat Fn attribute„ÄÇ And hereÔºå this is an at backward function„ÄÇ So because hereÔºå our operation was a plus„ÄÇAnd thenÔºå our„ÄÇThen we do the back propagation later„ÄÇ So that's why it's called at backward„ÄÇAnd let's do some more operation with our tensrs„ÄÇSo let's say we have C equals y times y times 2Ôºå for example„ÄÇ

 So this tensor then also has this gra function attribute So here Grt Fn equals mile backward because here our operation is a multiplication„ÄÇ And for exampleÔºå we can say C equals C dot mean„ÄÇ So we can apply a mean operation„ÄÇ And then our gradient function is the mean backward„ÄÇAnd now„ÄÇ when we want to calculate the gradientsÔºå the only thing that we must do is to call C dot backward„ÄÇ

So this will then calculate the gradient of C with respect to x„ÄÇ So x then has a gradient„ÄÇ a dot Gr attribute where the gradients are stored„ÄÇ so we can print this„ÄÇAnd now if you run this„ÄÇ then we see that we have the gradients here in this tenor„ÄÇ So this is all we have to do„ÄÇAnd now let's have a look what happens when we don't specify this argument„ÄÇ So first of all„ÄÇ

 if we print our tenzos„ÄÇThen we see that they don't have this gra function attribute„ÄÇ And if we try to call the backward functionÔºå then this will produce an  error„ÄÇ So it says tens does not require gr and does not have the gr function„ÄÇSo remember that we must specify this argument and then it will work„ÄÇ

And one thing that we should also know is so in the background what this basically does„ÄÇ this will create a socal vector Jacobcobian product to get the gradients„ÄÇ So this will look like this„ÄÇ I will not go into the mathematical details„ÄÇ but we should know that we have the Jacobcobian matrix„ÄÇ with the partial derivatives„ÄÇ

 And then we multiply this with a gradient vector„ÄÇ and then we will get the final the final gradients that we are interested in„ÄÇ So this is also called the chain rule„ÄÇ And I will also explain this more in detail in the next video But yeah„ÄÇ we should know that actually we must multiply it with a vector„ÄÇ So in this case„ÄÇ since our C is a scala valueÔºå We don't have to put the don't have to use an argument„ÄÇ



![](img/cecd5af4135b2f12f1bfa0bb78e5d673_5.png)

And here for our backward function„ÄÇ![](img/cecd5af4135b2f12f1bfa0bb78e5d673_7.png)

So our C here has only v value„ÄÇ So this is fine„ÄÇ But let's say we didn't apply the mean operation„ÄÇ So now our C has more than one value in it„ÄÇ So it's also size 1 by 3„ÄÇ And now when we try to call the backward function like this„ÄÇ And this will produce an error„ÄÇ So Gr can be implicitly created only for scala outputs„ÄÇ So in this caseÔºå we have to„ÄÇ

Give it the gradient argument„ÄÇ So we have to create a vector of the same sizeÔºå so„ÄÇLet's say V equals torch dot1or„ÄÇ And here we putÔºå for exampleÔºå011„ÄÇ0 and0„ÄÇ0Ôºå0Ôºå1„ÄÇ and we give it a data type of torch dot float 32„ÄÇ and then we must pass this vector to our backward function„ÄÇ and now it will work again„ÄÇSo nowÔºå if we run this„ÄÇThen this is okay„ÄÇ

 So we should know that in the backgroundÔºå this is a a vector Jacobbian product„ÄÇ And a lot of times„ÄÇ the last operation is some operation that will create a scala value„ÄÇ So this is„ÄÇ it's okay to call it like this without an argument„ÄÇ But if this is not an a scala„ÄÇ Then we must give it the the vector„ÄÇAnd yeah„ÄÇThen some other thing that we should know is how we can prevent Pyth from tracking the history and calculating this gra f n attribute„ÄÇ

 So for exampleÔºå sometimes during our training loop when we want to update our weights„ÄÇ Then this operation should not be part of the gradient computation„ÄÇ So in one of the next tutorials„ÄÇ I will give a concrete example of how we apply this autocrad package„ÄÇ And then it will become clearerÔºå maybe„ÄÇ But yeahÔºå for now„ÄÇ

 we should know how we can prevent this from from tracking the gradients„ÄÇ and we have three option for this„ÄÇ So the first one is to call the requires„ÄÇGrat„ÄÇ underscore functionÔºå and set this to false„ÄÇThe second option is to call X dot det„ÄÇ So this will create a new Tenzoor that doesn't require the gradient„ÄÇ

 And the second option would be to wrap this in a width statement„ÄÇ So with torchÔºå dotÔºå no gr„ÄÇ And then we can do our operations„ÄÇSoÔºå yeahÔºå let's try each of these„ÄÇ So first„ÄÇWe can say„ÄÇ x dot requires„ÄÇGratÔºå underscore and set this to false„ÄÇ So whenever a function has a trailing underscore in Pytorch„ÄÇ

 then this means that it will modify our variable in place„ÄÇ So nowÔºå if we print X„ÄÇThen we will see that it doesn't have this require Gr attribute anymore„ÄÇ So now this is false„ÄÇSo this is the first optionÔºå and the second option would be to call x detaach„ÄÇ So we say y equals x do detaach„ÄÇ So this will create a new vector with the same or a newtenzo with the same values„ÄÇ

 but it doesn't require the gradient„ÄÇ So here we see that our y has the same values„ÄÇ but doesn't require the gradients„ÄÇAnd the last option is to wrap it in a torch in a width with statement with torch dot no Gr„ÄÇ And then we can do some operationsÔºå for exampleÔºå y equals„ÄÇX plus 2„ÄÇAnd nowÔºå if we print our y„ÄÇ then we see that it doesn't have the gradient function attribute here„ÄÇ SoÔºå yeah„ÄÇ

 if we don't use this and would run it like this„ÄÇThen our y has the gradient function„ÄÇ So these are the three ways how we can stop Pythot from creating this gradient functions and tracking the history in our computational graph„ÄÇAnd now one more very important thing that we should also know is that whenever we call the backward function„ÄÇ then the gradient for this tenzoor will be accumulated into the dot gra attribute„ÄÇ

 So the values will be summed up„ÄÇ So here we we must be very careful„ÄÇ So let's create some dummy training example„ÄÇ where we have some have some weights„ÄÇ So this is a a tenzoor with ones in it of sizeÔºå let's say4Ôºå and they require the gradient„ÄÇ So requires gra equals true„ÄÇ And now let's say we have a training loop where we say four epo in range and first„ÄÇ

 let's only do one iteration„ÄÇ And here we doÔºå let's say model output„ÄÇEqualsÔºå let's say„ÄÇWeights times 3 dot sum„ÄÇ So this is just a dummy operationÔºå which will simulate some model output„ÄÇ And then we want to calculate the gradients„ÄÇ So we say model output dot backward„ÄÇAnd now we have the gradientÔºå so we can call weight dot Gr„ÄÇAnd print this„ÄÇÂóØ„ÄÇ

So I what gradients here are 3„ÄÇSo the tensor is filled with threes„ÄÇ And now if we do another iteration„ÄÇ So if we say we have two iterations„ÄÇ then the second backward call will again accumulate the values and write them into the Gr attribute„ÄÇ So now our grs has sixes in it„ÄÇ And now if we do a third iteration„ÄÇ Then it has nines in it„ÄÇ

 So all the values are summed up„ÄÇ And now our weights or our gradients are clearly incorrect„ÄÇ So before we do the next iteration and optimization step„ÄÇ we must empty the gradients„ÄÇ So we must call weights dot Gr dot0 underscore„ÄÇ And now if we run this then our gradients are correct again„ÄÇSo this is one very important„ÄÇTh that we must know during our training steps„ÄÇ

 and later we will work with the Pytorch built in Opr„ÄÇ So let's say we have a optr from the torch optimization package„ÄÇ So torch do optim do SGD for stochastic gradient descent„ÄÇ which has our weights as parameters and some learning rate and now with this optimizer„ÄÇ

 we can call or do a optimization step and then before we do the next iteration„ÄÇ we must call the optimizer do0 gra functionÔºå which will do exactly the same„ÄÇSoÔºå yeah„ÄÇ we will talk about the optimizes in some later tutorials„ÄÇ But yeahÔºå for now„ÄÇ the things you should remember is that whenever we want to calculate the gradients„ÄÇ

 We must specify the require gr parameter and set this to true„ÄÇ Then we can simply calculate the gradients with calling the backward function and before we want to do the next operation or the next iteration in our optimization steps„ÄÇ we must empty our gradients„ÄÇ So we must call the0 function again„ÄÇAnd we also should know how we can prevent some operations from being tracked in the computational graph„ÄÇ

And that's all I wanted to show you for now with the autograd package„ÄÇ And I hope you liked it„ÄÇ Please subscribe to the channel and see you next timeÔºå bye„ÄÇ![](img/cecd5af4135b2f12f1bfa0bb78e5d673_9.png)