# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠNLPä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P30ï¼šL5.1- æ¨¡å‹Hubä¸­å¿ƒé€Ÿè§ˆ - ShowMeAI - BV1Jm4y1X7UL

In this videoï¼Œ we're going to go over the Huging F model H navigationã€‚This is the Huging phaseã€‚t co landing pageã€‚To access the Model hubï¼Œ click on the Models tab in the upper right cornerã€‚You should be facing this web interfaceï¼Œ which can be split into several partsã€‚

![](img/bdba16451070db4a97f5f64c01c66332_1.png)

On the leftï¼Œ you will find categories which you can use to tailor your model searchã€‚The first category is the tasksã€‚Mugles on the hub may be used for a wide variety of tasksã€‚ These include natural language processing tasks such as question answering or text classificationã€‚ but it isn't only limited to an LPã€‚Other tasks from other fields are also availableã€‚

 such as image classification for computer vision or automatic speech recognition for speechã€‚The second category is the librariesã€‚Moels on the hub usually share one of three backbonesï¼Œ pytorrchã€‚ Tensorflowlowï¼Œ or jacksã€‚Howeverï¼Œ other backbones such as rust or onyxï¼Œ also existã€‚Finallyã€‚ this tab can also be used to specify from which high level framework the models comesã€‚

This includes transformersï¼Œ but it isn't limited to itã€‚ The model hub is used to host a lot of different frameworks modelsã€‚ and we are actively looking to host other frameworks modelsã€‚The third category is the datasets tabã€‚Selecting a dataset set from this tab means filtering the models so that they were trained on that specific datasetã€‚

The fourth category is the languages tabã€‚Selecting a language from this tab means filtering the models so that the handle of the language selectedã€‚Finallyï¼Œ the last category allows to choose the license with which the model is sharedã€‚![](img/bdba16451070db4a97f5f64c01c66332_3.png)

![](img/bdba16451070db4a97f5f64c01c66332_4.png)

On the rightï¼Œ you'll find the models available on the Model Hã€‚![](img/bdba16451070db4a97f5f64c01c66332_6.png)

The models are ordered by download by defaultã€‚When clicking on a modelã€‚ you should be facing its model cardã€‚The model card contains information about the modelã€‚ its description intended useï¼Œ limitations and biasesã€‚It can also show code snippets on how to use the model as well as any relevant informationï¼Œ trainingã€‚

 procedureï¼Œ data processingï¼Œ evaluation results or copyrightsã€‚This information is crucial for the model to be usedã€‚ the better craft to a model card is the easier it will be for other users to leverage your model and their applicationsã€‚![](img/bdba16451070db4a97f5f64c01c66332_8.png)

On the right of the model card is the inference APIã€‚This inference API can be used to play with the model directlyã€‚Feel free to modify the text and click on Comp to see how would the model behave to your inputsã€‚![](img/bdba16451070db4a97f5f64c01c66332_10.png)

![](img/bdba16451070db4a97f5f64c01c66332_11.png)

At the top of your screen lies the model tagsã€‚ğŸ˜Šï¼ŒThese includes the model task as well as any other tag that is relevant to the categories we have just seenã€‚ğŸ˜Šã€‚![](img/bdba16451070db4a97f5f64c01c66332_13.png)

The files and version tab displays the architecture of the repository of that modelã€‚Here we can see all the files that define this modelã€‚You will see all usual features of a getT repositoryï¼Œ the branches availableã€‚Do you commit historyã€‚As well as the committed diã€‚

![](img/bdba16451070db4a97f5f64c01c66332_15.png)

Three different buttons are available at the top of the model cardã€‚The first one shows how to use the inference API programmaticallyã€‚![](img/bdba16451070db4a97f5f64c01c66332_17.png)

![](img/bdba16451070db4a97f5f64c01c66332_18.png)

The second one shows how to train this model in sage makerã€‚And the last one shows how to load that model within the appropriate library for Btã€‚ this is transformersã€‚![](img/bdba16451070db4a97f5f64c01c66332_20.png)

å—¯ã€‚