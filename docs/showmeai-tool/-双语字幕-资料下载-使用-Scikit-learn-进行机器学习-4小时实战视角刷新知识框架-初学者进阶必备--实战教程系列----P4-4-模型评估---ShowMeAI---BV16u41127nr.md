# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘ä½¿ç”¨ Scikit-learn è¿›è¡Œæœºå™¨å­¦ä¹ ï¼Œ4å°æ—¶å®æˆ˜è§†è§’åˆ·æ–°çŸ¥è¯†æ¡†æ¶ï¼Œåˆå­¦è€…è¿›é˜¶å¿…å¤‡ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼š4ï¼‰æ¨¡å‹è¯„ä¼° - ShowMeAI - BV16u41127nr

We talked about our squared scoreï¼Œ we talked about being an absolute squared or errorã€‚And that's different ways we can measure our errorsã€‚ The next thing I' to talk about is if our score is trying to mediocre like 0ã€‚2 out of oneã€‚ how do I know that that's actually grow and it's not just chanceã€‚



![](img/685f8a9a43bae69c2b04fb232b54014c_1.png)

And the answer is that what we'll do is we'll take our original data hereã€‚And we'll score it with our modelã€‚ We're able to train a model that the x's and the y's and just scoreã€‚ And so let's say my score is 0ã€‚8ï¼Œ which is not that dreadã€‚What I'll do is I'll shuffle around the dataã€‚ so I know that there's no relationship between the y's and x'sã€‚

 rightï¼Œ so what I'll do is I'll take this y column and just randomly shuffle itã€‚ And the word for that is up permateatedã€‚ As I get this permutated version of this columnï¼Œ rightã€‚ you can see thatã€‚For exampleï¼Œ5 used to be the first number and now now5 this down here So I just kind to randomly shuffle that thing and then I train the model on itã€‚ trying to look for the relationship between the y's and x'sã€‚

 and there should be no relationship obviously right because I just shuffle everything around but I can try to train a model and get a score on it And so if I see that when I'm basically training a model on garbage dataã€‚ if I get a better score then then I did originallyã€‚

 well that probably means that I didn't have any sort of significant result originally so I probably didn't have any sort of meaningful model And that's the rough idea an actual implementation of what this function here is going to do for us is it's going to shuffle around the data like thisã€‚

And it's going to get a score and it's try to shuffle it again and it's going to get a score it's trying to get something like know 100 or 100 different scores based on these shuffled dataã€‚ and then based on that we can estimate and really see this score over hereã€‚

 is it kind of unusually good or does it feel like this could fit in with the garbage data and based on that we we can basically sayã€‚ well heyï¼Œ do I trust this model or that So let me head over here back the notebookï¼Ÿ



![](img/685f8a9a43bae69c2b04fb232b54014c_3.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_4.png)

Andã€‚ And so maybe I'm just trying to make some notes in here just so it's clear to what we're doingã€‚ So this part was about metricsã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_6.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_7.png)

And then this part is going to be about permutation testingã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_9.png)

And so let me I actually already imported itï¼Œ which is great so all these things that are kind of related to model evaluation and they're under this thing called model selection because what we'll often do is have a few different models and we're trying to have different tools to say well what is the model that we think is best and we're going recommend to people So I see that I have this permutation test scoreã€‚



![](img/685f8a9a43bae69c2b04fb232b54014c_11.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_12.png)

And I might paste this right hereï¼Œ and I can see that I need three thingsã€‚At a minimumã€‚ I have to have my modelï¼Œ which is just L Rã€‚ğŸ¤§I have to have my ownã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_14.png)

My x values and then finally my y valuesã€‚ And so the way I'm going be doing this here is sinceã€‚å—¯ã€‚Since here I have this testF and andã€‚For both my x and my Y I'm just going to grab these rightã€‚ so this was my x right here based on the seven day averageï¼Œ I want to predict this right hereã€‚And I'm going grab thisã€‚And it turns out that this is going to return a tuple of length  threeã€‚

 so I'm just going run thatï¼Œ that'll take a momentã€‚ and the three things in that tuple are going to be the score of my module model originallyã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_16.png)

It will be you know some other scores when I have maybe I'll just tell the garbage scores since I'm peruting the dataã€‚ I'm not expecting to have any patternï¼Œ there's going to be a bunch of thoseã€‚And then there's going to be something called a P valueã€‚And what the P value is telling me isã€‚Wellã€‚ what is the probability that a score this goodã€‚Would be generated by a system that's generating all these garbage scoresã€‚

Rightï¼Œ and so if this is really smallï¼Œ then I can seeï¼Œ wellã€‚ this is actually much better than my garbage coresã€‚ And so I actually have a significant resultã€‚ So since these are the three things I was returningã€‚ğŸ˜Šï¼ŒRight I know that T is a tupleã€‚ I just put that here and it'll automatically unpack those things for meã€‚

 so I'll take a look at thisã€‚And then I get a score for my modelã€‚ and then I can have my garbage cores hereã€‚ I see there's a whole bunch of themã€‚ If I want toã€‚ I can put those in a seriesã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_18.png)

And then I could do a histogram of thoseã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_20.png)

And I can see thatï¼Œ you knowï¼Œ they're actually around0 or lessï¼Œ rightï¼Œ all of theseã€‚ And this was around 0 pointã€‚0ï¼Œ9ï¼Œ which isã€‚Actuallyã€‚Ptty far over hereã€‚ So it seems like we're pretty far away from these garbage scoresã€‚ And thereforeã€‚ this P value is going to be pretty smallã€‚ It seems like whatever processã€‚



![](img/685f8a9a43bae69c2b04fb232b54014c_22.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_23.png)

I'm using to get all these garbage cores is not likely to have a score this goodã€‚ so I will take this as a meaningful resultã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_25.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_26.png)

Let me head back here for another ideaï¼Œ so how do we deal with the noiseã€‚ we saw that when I kept doing it a bunch of times I was getting different scores and for that we're going to use as something called a cross Valã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_28.png)

Cross validation scoreã€‚ And And the way it' will work is I'm going splitlin my data instead of just having these train and tasksã€‚ Im going split into four piecesã€‚And then each of those four pieces are going to take turns being the test dataã€‚ so maybe first I'll train my data on these rowsï¼Œ and then I'll test it on thisã€‚

![](img/685f8a9a43bae69c2b04fb232b54014c_30.png)

And then my model will getï¼Œ let's sayï¼Œ a score of 0ã€‚2ã€‚And then I'll take a different chunk of the dataï¼Œ and each of these are called a fold of the dataã€‚ by the wayï¼Œ and so I'll train on those firstï¼Œ second and fourth piecesã€‚So I get a model and then I evaluate on that test data set and let's say this time I get a little bit luckier and it's 0ã€‚

3ï¼Œ do it againï¼Œ 01 again 0ã€‚2ï¼Œ and then I could take the average of these and that would be a more stable measurement of kind of how well my model does us not asã€‚Its not kind of as vulnerable to what happens to go on the test or training data set is all the data at some point is in the test dataã€‚

Or the training dataã€‚ So I going head over here and and do thisï¼Œ rightï¼Œ So this is calledã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_32.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_33.png)

Cross validationã€‚And let me call this thing so cross validation scoreã€‚And what I have to pass in hereï¼Œ I pass in my estimatorã€‚And then I have to pass in my x values and then my y valuesã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_35.png)

Rightï¼Œ so let me grab those thingsã€‚So it's actuallyï¼Œ I guess identical to this right hereã€‚ so I me grab my modelï¼Œ my x values and my y valuesã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_37.png)

And at this timeï¼Œ I just want to do it on all my dataã€‚ So can I say data frameã€‚And then data frame and actually really what is kind of the best practices is just to that of the training dataã€‚And so I'm going to do that and then I get all these scores back right and the reason is that there were five folds by default so I can say you know in this picture right there's four here I see well by default there were five that's why I got five scores I can say I want 10 of them and I'd be fine I these 10 scores back and these times look like those numbers we were seeing earlier like 0ã€‚

27 0ã€‚17 another 0ã€‚27 is 0ã€‚304 right if I head back here and I just kind of run this thing a few times those are the kinds of numbers I'm getting out of it as I randomly split my train of my testã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_39.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_40.png)

So why is this useful while I can have my scores hereã€‚And I can say a couple things I can say scores I meanã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_42.png)

And so I can see while on averageï¼Œ R2 square R squared score is going to be 0ã€‚21ã€‚ but I could also get some sense of the varianceï¼Œ and that'll tell me how sensitive I am to what data happens to end off in the test or training data setã€‚ and that probably depends how much on how much I have some outliers and how much outliers toã€‚What happens with the scoringï¼ŸOkayï¼Œ so this will be the way we'll generally do itã€‚

 And so one last thingï¼Œ rightï¼Œ when I wasã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_44.png)

Showing this picture here rightï¼Œ I kind of saidï¼Œ wellï¼Œ heyï¼Œ I have all my dataã€‚ then I just split it up into train and testã€‚![](img/685f8a9a43bae69c2b04fb232b54014c_46.png)

Why didn I use all my data here and the reason is thatã€‚Is that even though that would have been fine to do in this example what you're often going to be doing is you're going be trying to do a few different models and what you'll want to do is you'll want to do cross validation on each of the models and then you'll see well what one has the best score on average and you say well that one's the winner that's one where you use in the futureã€‚

And so there's this risk when you're doing thatï¼Œ let's say I evaluate 20 modelsã€‚And pick the best oneã€‚ the best one probably did a little bit better than it shouldã€‚ rightã€‚ if I do 20 modelsï¼Œ some will just by luckï¼Œ do better and some will do worseã€‚ And so even though that's the right process to pick the best model I shouldn't throw brag about this cross validation score because it wasn't like I was just doing one model as in hereã€‚

 I doing many modelsã€‚ So what I would do is I look at this cross validation score across each of my modelsã€‚ pick the best oneï¼Œ And then finally what I go back and actually do my real test data which is still hanging out hereã€‚ and then that's what I would report is the kind of accuracy of my favorite chosen modelã€‚

![](img/685f8a9a43bae69c2b04fb232b54014c_48.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_49.png)

![](img/685f8a9a43bae69c2b04fb232b54014c_50.png)