- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘140åˆ†é’Ÿå…¥é—¨ PyTorchï¼Œå®˜æ–¹æ•™ç¨‹æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒç¬¬ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P1ï¼šL1- PyTorch ç®€ä»‹
    - ShowMeAI - BV19L4y1t7tu
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘140åˆ†é’Ÿå…¥é—¨ PyTorchï¼Œå®˜æ–¹æ•™ç¨‹æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒç¬¬ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P1ï¼šL1- PyTorch ç®€ä»‹
    - ShowMeAI - BV19L4y1t7tu
- en: Helloï¼Œ my name is Brad Heinzã€‚ I'm a partner engineer working with the Piytorrch
    team at Facebookã€‚In this videoï¼Œ I'll be giving you an introduction to Pytorrchï¼Œ
    its featuresã€‚ key concepts and associated tools and librariesã€‚ This overview assumes
    that you are new to doing machine learning with Pytorrchã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯Brad Heinzã€‚æˆ‘æ˜¯Facebook Pytorrchå›¢é˜Ÿçš„åˆä½œå·¥ç¨‹å¸ˆã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘å°†å‘ä½ ä»‹ç»Pytorrchï¼Œå®ƒçš„ç‰¹æ€§ã€å…³é”®æ¦‚å¿µå’Œç›¸å…³å·¥å…·åŠåº“ã€‚è¿™ä¸ªæ¦‚è¿°å‡è®¾ä½ æ˜¯ç¬¬ä¸€æ¬¡æ¥è§¦Pytorrchè¿›è¡Œæœºå™¨å­¦ä¹ ã€‚
- en: '![](img/1181a3784e7b926ea0c178203ada7ae1_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1181a3784e7b926ea0c178203ada7ae1_1.png)'
- en: In this videoï¼Œ we're going to cover an overview of Pytorr and related projectsã€‚Tenssorsã€‚
    which are the core data abstraction of Ptorrchã€‚Autogradã€‚ which tries the eager
    mode computation that makes rapid iteration in your model possibleã€‚We'll talk
    about building a model with Ptorrch modulesã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†æ¶µç›–Pytorrchå’Œç›¸å…³é¡¹ç›®çš„æ¦‚è¿°ã€‚å¼ é‡ï¼Œå®ƒä»¬æ˜¯Pytorchçš„æ ¸å¿ƒæ•°æ®æŠ½è±¡ã€‚è‡ªåŠ¨å¾®åˆ†ï¼Œå®ƒå°è¯•å¿«é€Ÿè®¡ç®—æ¨¡å¼ï¼Œä½¿æ¨¡å‹å¿«é€Ÿè¿­ä»£æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•ä½¿ç”¨Pytorchæ¨¡å—æ„å»ºæ¨¡å‹ã€‚
- en: We'll talk about how to load your data efficiently to train your modelã€‚We'll
    demonstrate a basic training loopã€‚And finallyï¼Œ we'll talk about deployment with
    Torchscriptã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_3.png)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•é«˜æ•ˆåŠ è½½æ•°æ®ä»¥è®­ç»ƒæ¨¡å‹ã€‚æˆ‘ä»¬å°†æ¼”ç¤ºä¸€ä¸ªåŸºæœ¬çš„è®­ç»ƒå¾ªç¯ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®¨è®ºä½¿ç”¨Torchscriptè¿›è¡Œéƒ¨ç½²ã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_3.png)
- en: Before we get startedï¼Œ you'll want to install Pytorrch and torch visions so
    you can follow along with the demos and exercisesã€‚ If you haven't installed the
    latest version of Pytorrch yetï¼Œ visit Pytorrch dot orgã€‚The front page has an installed
    wizard shown hereã€‚There are two important things to note hereã€‚ Firstã€‚ coupa drivers
    are not available for the Macã€‚ Thereforeã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦å®‰è£…Pytorrchå’Œtorchvisionsï¼Œä»¥ä¾¿èƒ½å¤Ÿè·Ÿéšæ¼”ç¤ºå’Œç»ƒä¹ ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„Pytorrchï¼Œè¯·è®¿é—®Pytorrch.orgã€‚é¦–é¡µæœ‰ä¸€ä¸ªå®‰è£…å‘å¯¼ã€‚è¿™é‡Œæœ‰ä¸¤ä¸ªé‡è¦äº‹é¡¹éœ€è¦æ³¨æ„ã€‚é¦–å…ˆï¼ŒMacä¸Šä¸æä¾›CUDAé©±åŠ¨ç¨‹åºã€‚å› æ­¤ã€‚
- en: GP PU acceleration is not going to be available by a pietorch on the Macã€‚Secondã€‚
    if you're working on a Linux or Windows machine with one or more NviIdia couda
    compatible GPUs attachedã€‚ make sure the version of couta tool kit you installed
    matches the couda drivers on your machineã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Macä¸Šä¸ä¼šæä¾›GPUåŠ é€Ÿã€‚å…¶æ¬¡ï¼Œå¦‚æœä½ åœ¨é…å¤‡ä¸€ä¸ªæˆ–å¤šä¸ªNvidia CUDAå…¼å®¹GPUçš„Linuxæˆ–Windowsæœºå™¨ä¸Šå·¥ä½œï¼Œè¯·ç¡®ä¿ä½ å®‰è£…çš„CUDAå·¥å…·åŒ…ç‰ˆæœ¬ä¸æœºå™¨ä¸Šçš„CUDAé©±åŠ¨ç¨‹åºåŒ¹é…ã€‚
- en: '![](img/1181a3784e7b926ea0c178203ada7ae1_5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1181a3784e7b926ea0c178203ada7ae1_5.png)'
- en: So what is Pytorchï¼Ÿ
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆPytorchæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
- en: '![](img/1181a3784e7b926ea0c178203ada7ae1_7.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1181a3784e7b926ea0c178203ada7ae1_7.png)'
- en: Pytorchã€‚orgã€‚Tells us that Pytorch is an open source machine learning framework
    that accelerates the path from research prototyping to production deploymentã€‚Let's
    unpack thatã€‚Firstã€‚Pytorchches software for machine learningã€‚ It contains a full
    toolkit for building and deploying M L applicationsã€‚ including deep learning primitivesï¼Œ
    such as neural network layer typesã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorch.orgå‘Šè¯‰æˆ‘ä»¬ï¼ŒPytorchæ˜¯ä¸€ä¸ªå¼€æºæœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤ŸåŠ é€Ÿä»ç ”ç©¶åŸå‹åˆ°ç”Ÿäº§éƒ¨ç½²çš„è·¯å¾„ã€‚è®©æˆ‘ä»¬è¯¦ç»†äº†è§£ä¸€ä¸‹ã€‚é¦–å…ˆï¼ŒPytorchæ˜¯æœºå™¨å­¦ä¹ çš„è½¯ä»¶ã€‚å®ƒåŒ…å«æ„å»ºå’Œéƒ¨ç½²æœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºçš„å®Œæ•´å·¥å…·åŒ…ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ çš„åŸºæœ¬å…ƒç´ ï¼Œå¦‚ç¥ç»ç½‘ç»œå±‚ç±»å‹ã€‚
- en: activation functions and gradient based optimizersã€‚ It has hardware acceleration
    on Nvidia GPusã€‚ and it has associated libraries for computer visionã€‚ text and
    natural language and audio applicationsã€‚Torchssionã€‚ the Pytorrch Library for Computer
    vision applicationsã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ¿€æ´»å‡½æ•°å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–å™¨ã€‚å®ƒåœ¨Nvidia GPUä¸Šå…·æœ‰ç¡¬ä»¶åŠ é€Ÿï¼Œå¹¶ä¸”æœ‰ä¸è®¡ç®—æœºè§†è§‰ã€æ–‡æœ¬ã€è‡ªç„¶è¯­è¨€å’ŒéŸ³é¢‘åº”ç”¨ç›¸å…³çš„åº“ã€‚Torchssionï¼ŒPytorchè®¡ç®—æœºè§†è§‰åº”ç”¨çš„åº“ã€‚
- en: also includes pre trained models and packaged data sets that you can use to
    train your own modelsã€‚Pytorch is built to enable fast iteration on your M L models
    and applicationsã€‚ You can work in regular idiomatic Pythonã€‚ There is no new domain
    specific language to learn to build your computation graph with autogradã€‚ Pytorch's
    automatic differentiation engineï¼Œ the backward passover your model is done with
    a single function call and done correctlyã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜åŒ…æ‹¬é¢„è®­ç»ƒæ¨¡å‹å’Œæ‰“åŒ…æ•°æ®é›†ï¼Œä½ å¯ä»¥ç”¨æ¥è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ã€‚Pytorchæ—¨åœ¨å¿«é€Ÿè¿­ä»£ä½ çš„æœºå™¨å­¦ä¹ æ¨¡å‹å’Œåº”ç”¨ç¨‹åºã€‚ä½ å¯ä»¥åœ¨å¸¸è§„çš„Pythonä¸­å·¥ä½œã€‚æ„å»ºè®¡ç®—å›¾æ—¶æ— éœ€å­¦ä¹ æ–°çš„ç‰¹å®šé¢†åŸŸè¯­è¨€ï¼ŒPytorchçš„è‡ªåŠ¨å¾®åˆ†å¼•æ“ï¼Œæ¨¡å‹çš„åå‘ä¼ æ’­é€šè¿‡å•ä¸ªå‡½æ•°è°ƒç”¨æ­£ç¡®å®Œæˆã€‚
- en: no matter which path through the code a computation tookã€‚ offering you unparalleled
    flexibility in model designã€‚Pytorch has the tooling to work at enterprise scale
    with tools like Torchcrã€‚ which is a way to create serializable and optimizable
    models from your Pytorrch codeï¼Œ Torchservã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºè®¡ç®—åœ¨ä»£ç ä¸­èµ°å“ªæ¡è·¯å¾„ï¼Œéƒ½æä¾›äº†æ— ä¸ä¼¦æ¯”çš„æ¨¡å‹è®¾è®¡çµæ´»æ€§ã€‚Pytorch æ‹¥æœ‰é€‚ç”¨äºä¼ä¸šè§„æ¨¡çš„å·¥å…·ï¼Œå¦‚ Torchcrï¼Œå®ƒå¯ä»¥ä» Pytorrch
    ä»£ç åˆ›å»ºå¯åºåˆ—åŒ–å’Œå¯ä¼˜åŒ–çš„æ¨¡å‹ï¼Œè¿˜æœ‰ Torchservã€‚
- en: Pytorrch's model serving solution and multiple options for quantizing your model
    for performanceã€‚And finallyï¼Œ Pytorrch is free in open source softwareã€‚ free to
    use and open to contributions from the communityã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_9.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorrch çš„æ¨¡å‹æœåŠ¡è§£å†³æ–¹æ¡ˆä»¥åŠå¤šç§é‡åŒ–æ¨¡å‹ä»¥æé«˜æ€§èƒ½çš„é€‰é¡¹ã€‚æœ€åï¼ŒPytorrch æ˜¯ä¸€ä¸ªå…è´¹å¼€æºè½¯ä»¶ï¼Œå…è´¹ä½¿ç”¨ï¼Œæ¬¢è¿ç¤¾åŒºçš„è´¡çŒ®ã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_9.png)
- en: Its open source nature fosters a rich ecosystem of community projects as wellã€‚
    supporting use cases from satochastic processes to graph based neural networksã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_11.png)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒçš„å¼€æºç‰¹æ€§ä¹Ÿä¿ƒè¿›äº†ä¸°å¯Œçš„ç¤¾åŒºé¡¹ç›®ç”Ÿæ€ç³»ç»Ÿï¼Œæ”¯æŒä»éšæœºè¿‡ç¨‹åˆ°åŸºäºå›¾çš„ç¥ç»ç½‘ç»œçš„ç”¨ä¾‹ã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_11.png)
- en: The Pyetorrch community is large and growingï¼Œ with over 1200 contributors to
    the project from around the world and over 50% cent year on year growth in research
    paper citationsã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_13.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorrch ç¤¾åŒºåºå¤§ä¸”ä¸æ–­å£®å¤§ï¼Œæ¥è‡ªå…¨çƒçš„è´¡çŒ®è€…è¶…è¿‡ 1200 åï¼Œç ”ç©¶è®ºæ–‡å¼•ç”¨å¹´å¢é•¿ç‡è¶…è¿‡ 50%ã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_13.png)
- en: Petorrch is in use at top tier companies like these and provides the foundations
    for projects like Alan N LPã€‚ the Open source Research Library for deep learninging
    with Natural Languageï¼Œ Fast AIã€‚ which simplifies training fast and accurate neural
    nets using best modern practicesã€‚Classy vision and end to end framework for image
    and video classification and capã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Petorrch åœ¨é¡¶çº§å…¬å¸ä¸­å¾—åˆ°äº†åº”ç”¨ï¼Œå¹¶ä¸ºåƒ Alan N LP è¿™æ ·çš„é¡¹ç›®æä¾›äº†åŸºç¡€ã€‚å®ƒæ˜¯ä¸€ä¸ªå¼€æºæ·±åº¦å­¦ä¹ ç ”ç©¶åº“ï¼Œä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ŒFast AI
    ç®€åŒ–äº†ä½¿ç”¨ç°ä»£æœ€ä½³å®è·µè¿›è¡Œå¿«é€Ÿå’Œå‡†ç¡®çš„ç¥ç»ç½‘ç»œè®­ç»ƒã€‚Classy Vision æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒå’Œè§†é¢‘åˆ†ç±»çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚
- en: an open source extensible library that helps you understand and interpret your
    model's behaviorã€‚Now that you've been introduced to Pytorrchï¼Œ let's look under
    the hoodã€‚ Tensors will be at the center of everything you do in P torchã€‚ Your
    modelsï¼Œ inputsã€‚ outputs and learning weights are all in the form of tensorsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¼€æºå¯æ‰©å±•åº“ï¼Œå¸®åŠ©ä½ ç†è§£å’Œè§£é‡Šæ¨¡å‹çš„è¡Œä¸ºã€‚ç°åœ¨ä½ å·²ç»äº†è§£äº† Pytorrchï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸€ä¸‹ã€‚å¼ é‡å°†æ˜¯ä½ åœ¨ Pytorrch ä¸­æ‰€åšçš„ä¸€åˆ‡çš„æ ¸å¿ƒã€‚ä½ çš„æ¨¡å‹ã€è¾“å…¥ã€è¾“å‡ºå’Œå­¦ä¹ æƒé‡éƒ½ä»¥å¼ é‡çš„å½¢å¼å­˜åœ¨ã€‚
- en: '![](img/1181a3784e7b926ea0c178203ada7ae1_15.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1181a3784e7b926ea0c178203ada7ae1_15.png)'
- en: Nowï¼Œ if Tensor is not a part of your normal mathematical vocabularyã€‚ just know
    that in this contextã€‚ we're talking about a multidisional arrayï¼Œ but with a lot
    of extra bells and whistlesã€‚Pietorrch tensors come bundled with over 300 mathematical
    and logical operations that can be performed on themã€‚Though you access tensors
    through a Python APIï¼Œ the computation actually happens in compiled C++ code optimized
    for CPUU and GPUã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¦‚æœå¼ é‡ä¸æ˜¯ä½ å¸¸ç”¨çš„æ•°å­¦è¯æ±‡ï¼Œåªéœ€çŸ¥é“åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬è°ˆè®ºçš„æ˜¯å¤šç»´æ•°ç»„ï¼Œä½†å¸¦æœ‰è®¸å¤šé¢å¤–çš„ç‰¹æ€§ã€‚Pietorrch å¼ é‡é™„å¸¦è¶…è¿‡ 300 ç§å¯å¯¹å…¶æ‰§è¡Œçš„æ•°å­¦å’Œé€»è¾‘æ“ä½œã€‚å°½ç®¡ä½ æ˜¯é€šè¿‡
    Python API è®¿é—®å¼ é‡ï¼Œä½†è®¡ç®—å®é™…ä¸Šæ˜¯åœ¨ä¸º CPU å’Œ GPU ä¼˜åŒ–çš„ç¼–è¯‘ C++ ä»£ç ä¸­è¿›è¡Œçš„ã€‚
- en: Let's look at some typical tensor manipulations in Pytorrchã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_17.png)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ Pytorrch ä¸­ä¸€äº›å…¸å‹çš„å¼ é‡æ“ä½œã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_17.png)
- en: The first thing we'll need to do is import pi torch with the import torch callã€‚Then
    we'll go ahead and create our first tensor hereã€‚ I'm going to take create a two
    dimensional tensor with five rows and three columns and fill it with zerosã€‚ I'm
    going to query it for the data type of those zerosã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯é€šè¿‡ `import torch` è°ƒç”¨æ¥å¯¼å…¥ Pytorrchã€‚ç„¶åæˆ‘ä»¬å°†ç»§ç»­åœ¨è¿™é‡Œåˆ›å»ºæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå¼ é‡ã€‚æˆ‘å°†åˆ›å»ºä¸€ä¸ªå…·æœ‰äº”è¡Œä¸‰åˆ—çš„äºŒç»´å¼ é‡ï¼Œå¹¶ç”¨é›¶å¡«å……å®ƒã€‚æˆ‘å°†æŸ¥è¯¢è¿™äº›é›¶çš„æ•°æ®ç±»å‹ã€‚
- en: And here you can see I got my requested matrix of 15 zerosï¼Œ and the data is
    32 B floating pointã€‚ By defaultï¼Œ pi torch creates all tensors as 32 bit floating
    pointã€‚What if you wanted integers insteadï¼Œ you can always override the defaultã€‚Here
    in the next cellã€‚ I create a tensor full of onesã€‚ I request that they be 16 B
    integers and note that when I print it without being askedã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘å¾—åˆ°äº†è¯·æ±‚çš„ 15 ä¸ªé›¶çš„çŸ©é˜µï¼Œæ•°æ®ç±»å‹ä¸º 32 ä½æµ®ç‚¹æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒPytorrch åˆ›å»ºçš„æ‰€æœ‰å¼ é‡éƒ½æ˜¯ 32 ä½æµ®ç‚¹æ•°ã€‚å¦‚æœä½ æƒ³è¦æ•´æ•°ï¼Œä½ å¯ä»¥éšæ—¶è¦†ç›–é»˜è®¤è®¾ç½®ã€‚åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªå……æ»¡
    1 çš„å¼ é‡ã€‚æˆ‘è¯·æ±‚å®ƒä»¬ä¸º 16 ä½æ•´æ•°ï¼Œå¹¶æ³¨æ„åˆ°åœ¨æˆ‘æ²¡æœ‰è¢«é—®åŠæ—¶æ‰“å°å‡ºæ¥ã€‚
- en: Pytorrch tells me that these are 16 B integers because it's not the default
    that might not be what I expectã€‚It's common to initialize learning weights randomlyã€‚
    often with a specific seed for the random number generators that you can reproduce
    your results on subsequent runs hereã€‚ we demonstrateã€‚Seeding the pytorch random
    mirror generator with a specific numberã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Pytorrchå‘Šè¯‰æˆ‘è¿™äº›æ˜¯16 Bæ•´æ•°ï¼Œå› ä¸ºå®ƒä¸æ˜¯é»˜è®¤çš„ï¼Œå¯èƒ½ä¸æˆ‘é¢„æœŸçš„ä¸ç¬¦ã€‚é€šå¸¸ä¼šéšæœºåˆå§‹åŒ–å­¦ä¹ æƒé‡ï¼Œå¸¸å¸¸ä½¿ç”¨ç‰¹å®šçš„éšæœºæ•°ç”Ÿæˆå™¨ç§å­ï¼Œä»¥ä¾¿åœ¨åç»­è¿è¡Œä¸­é‡ç°ç»“æœã€‚æˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•ç”¨ç‰¹å®šæ•°å­—å¯¹Pytorchéšæœºé•œåƒç”Ÿæˆå™¨è¿›è¡ŒåŠ ç§ã€‚
- en: Generating a random tensorã€‚Generating a second random tensorã€‚ which we expect
    to be different from the first reseing the random number generator with the same
    inputã€‚And then finallyï¼Œ creating another random tensorï¼Œ which we expect to match
    the first since it was the first thing created after seeding the R Gã€‚And sure
    enoughï¼Œ those are the results we getã€‚First tensor and the third tensor do matchã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ªéšæœºå¼ é‡ã€‚ç”Ÿæˆç¬¬äºŒä¸ªéšæœºå¼ é‡ï¼Œé¢„æœŸå®ƒä¸ç¬¬ä¸€ä¸ªä¸åŒï¼Œé€šè¿‡ä½¿ç”¨ç›¸åŒè¾“å…¥é‡æ–°è®¾ç½®éšæœºæ•°ç”Ÿæˆå™¨ã€‚æœ€åï¼Œåˆ›å»ºå¦ä¸€ä¸ªéšæœºå¼ é‡ï¼Œé¢„æœŸå®ƒä¸ç¬¬ä¸€ä¸ªåŒ¹é…ï¼Œå› ä¸ºå®ƒæ˜¯åœ¨å¯¹éšæœºç”Ÿæˆå™¨åŠ ç§ååˆ›å»ºçš„ç¬¬ä¸€ä¸ªå¼ é‡ã€‚æœç„¶ï¼Œè¿™äº›ç»“æœæ˜¯æˆ‘ä»¬å¾—åˆ°çš„ã€‚ç¬¬ä¸€ä¸ªå¼ é‡å’Œç¬¬ä¸‰ä¸ªå¼ é‡ç¡®å®åŒ¹é…ã€‚
- en: and the second one does notã€‚Arithmetic with Pytorch tensors is intuitiveã€‚ Tensors
    of similar shapes may be addedï¼Œ multipliedï¼Œ et ceteraã€‚ and operations between
    a scalar and a tensor will distribute over all the cells of the tensorã€‚ So let's
    look at a couple of examplesã€‚Firstï¼Œ I'm just going to create a tensor full of
    onesã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œç¬¬äºŒä¸ªåˆ™ä¸è¡Œã€‚Pytorchå¼ é‡çš„ç®—æœ¯æ“ä½œæ˜¯ç›´è§‚çš„ã€‚ç›¸ä¼¼å½¢çŠ¶çš„å¼ é‡å¯ä»¥ç›¸åŠ ã€ç›¸ä¹˜ç­‰ç­‰ï¼Œè€Œæ ‡é‡ä¸å¼ é‡ä¹‹é—´çš„æ“ä½œå°†åˆ†å¸ƒåˆ°å¼ é‡çš„æ‰€æœ‰å•å…ƒä¸Šã€‚æ‰€ä»¥è®©æˆ‘ä»¬çœ‹å‡ ä¸ªä¾‹å­ã€‚é¦–å…ˆï¼Œæˆ‘å°†åˆ›å»ºä¸€ä¸ªæ»¡æ˜¯1çš„å¼ é‡ã€‚
- en: Then I'm going to create another tensor full of onesã€‚ but I'm going to multiply
    it by a scalar 2ã€‚ And what's going to happen is all of those ones are going to
    become twosã€‚ The multiplication is distributed over every element of the tensorã€‚Then
    I'll add the two tensorsã€‚ I can do this because they're of the same shapeã€‚The
    operation happens element wise between the two of themã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘è¦åˆ›å»ºä¸€ä¸ªæ»¡æ˜¯1çš„å¼ é‡ï¼Œä½†æˆ‘å°†å…¶ä¹˜ä»¥æ ‡é‡2ã€‚ç»“æœæ˜¯æ‰€æœ‰çš„1éƒ½ä¼šå˜æˆ2ã€‚è¿™ä¸ªä¹˜æ³•åœ¨å¼ é‡çš„æ¯ä¸ªå…ƒç´ ä¸Šåˆ†å¸ƒã€‚ç„¶åæˆ‘ä¼šå°†è¿™ä¸¤ä¸ªå¼ é‡ç›¸åŠ ã€‚æˆ‘èƒ½è¿™æ ·åšæ˜¯å› ä¸ºå®ƒä»¬å½¢çŠ¶ç›¸åŒã€‚æ“ä½œåœ¨å®ƒä»¬ä¹‹é—´æŒ‰å…ƒç´ è¿›è¡Œã€‚
- en: And we get out now a tensor full of threesã€‚ When I query that tensor for its
    shapeã€‚ it's the same shape as the two input tensors from the addition operationã€‚Finallyã€‚
    I create two random tensors of different shapes and attempt to add themã€‚ I get
    a runtime error because there is no clean way to do element wise arithmetic operations
    between two tensors of different shapesã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¾—åˆ°äº†ä¸€ä¸ªæ»¡æ˜¯3çš„å¼ é‡ã€‚å½“æˆ‘æŸ¥è¯¢è¯¥å¼ é‡çš„å½¢çŠ¶æ—¶ï¼Œå®ƒä¸åŠ æ³•æ“ä½œä¸­çš„ä¸¤ä¸ªè¾“å…¥å¼ é‡å½¢çŠ¶ç›¸åŒã€‚æœ€åï¼Œæˆ‘åˆ›å»ºä¸¤ä¸ªä¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡å¹¶å°è¯•å°†å®ƒä»¬ç›¸åŠ ã€‚å› ä¸ºæ²¡æœ‰å¹²å‡€çš„æ–¹å¼åœ¨ä¸¤ä¸ªä¸åŒå½¢çŠ¶çš„å¼ é‡ä¹‹é—´è¿›è¡ŒæŒ‰å…ƒç´ çš„ç®—æœ¯æ“ä½œï¼Œæ‰€ä»¥æˆ‘å¾—åˆ°äº†ä¸€ä¸ªè¿è¡Œæ—¶é”™è¯¯ã€‚
- en: Here is a small sample of the mathematical operations available on Pytorch tensorsã€‚
    I'm going to create a random tensor and adjust it so its values are between -1
    and 1ã€‚I can take the absolute value of it and see all the values turn positiveã€‚I
    can take the inverse sign of it because values be are between minus1 and 1 and
    get an angle backã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯Pytorchå¼ é‡ä¸Šå¯ç”¨çš„æ•°å­¦æ“ä½œçš„å°æ ·æœ¬ã€‚æˆ‘å°†åˆ›å»ºä¸€ä¸ªéšæœºå¼ é‡å¹¶è°ƒæ•´å®ƒï¼Œä½¿å…¶å€¼åœ¨-1å’Œ1ä¹‹é—´ã€‚æˆ‘å¯ä»¥å–å®ƒçš„ç»å¯¹å€¼ï¼Œçœ‹åˆ°æ‰€æœ‰å€¼å˜æˆæ­£æ•°ã€‚æˆ‘å¯ä»¥å–å®ƒçš„åå‡½æ•°ï¼Œå› ä¸ºå€¼åœ¨-1å’Œ1ä¹‹é—´ï¼Œå¾—åˆ°ä¸€ä¸ªè§’åº¦ã€‚
- en: I can do linear algebra operations like taking the determinant or doing singular
    value decompositionã€‚And there are statistical and aggregate operations as wellã€‚Means
    and standard deviations and minimums and maximumimsï¼Œ et ceteraã€‚There's a good
    deal more to know about the power of Pytorch tensorsã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥æ‰§è¡Œçº¿æ€§ä»£æ•°æ“ä½œï¼Œæ¯”å¦‚æ±‚è¡Œåˆ—å¼æˆ–è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ç»Ÿè®¡å’Œæ±‡æ€»æ“ä½œï¼Œæ¯”å¦‚å‡å€¼ã€æ ‡å‡†å·®ã€æœ€å°å€¼å’Œæœ€å¤§å€¼ç­‰ç­‰ã€‚å…³äºPytorchå¼ é‡çš„å¼ºå¤§åŠŸèƒ½è¿˜æœ‰å¾ˆå¤šè¦äº†è§£çš„ã€‚
- en: including how to set them up for parallel computation on GPUã€‚ We'll be going
    into more depth in another videoã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_19.png)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…æ‹¬å¦‚ä½•ä¸ºGPUçš„å¹¶è¡Œè®¡ç®—è®¾ç½®å®ƒä»¬ã€‚æˆ‘ä»¬å°†åœ¨å¦ä¸€ä¸ªè§†é¢‘ä¸­æ·±å…¥è®¨è®ºã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_19.png)
- en: '![](img/1181a3784e7b926ea0c178203ada7ae1_20.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1181a3784e7b926ea0c178203ada7ae1_20.png)'
- en: As an introduction to autoradï¼Œ Pytorrchs automated differentiation engineã€‚ Let's
    consider the basic mechanics of a single training passã€‚For this exampleã€‚ we'll
    use a simple recurrent neural network or RNã€‚We start with four tensorsï¼Œ Xï¼Œ the
    input Hã€‚ the hidden state of the R N N that gives it its memory and two sets of
    learning weightsã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºå¯¹è‡ªåŠ¨æ±‚å¯¼çš„ä»‹ç»ï¼ŒPytorchtçš„è‡ªåŠ¨å¾®åˆ†å¼•æ“ã€‚æˆ‘ä»¬æ¥è€ƒè™‘ä¸€æ¬¡å•ä¸€è®­ç»ƒä¼ é€’çš„åŸºæœ¬æœºåˆ¶ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ã€‚æˆ‘ä»¬å¼€å§‹æ—¶æœ‰å››ä¸ªå¼ é‡ï¼ŒXï¼Œè¾“å…¥Hï¼ŒRNNçš„éšè—çŠ¶æ€ï¼Œè¿™èµ‹äºˆäº†å®ƒè®°å¿†ï¼Œä»¥åŠä¸¤ç»„å­¦ä¹ æƒé‡ã€‚
- en: 1 each for the input and the hidden stateã€‚Nextï¼Œ we multiply the weights by their
    respective tensorsã€‚In M here stands for Nature's multiplicationã€‚After thatã€‚ we
    add the outputs of the two matrix multiplicationsã€‚And pass the result through
    an activation function hereï¼Œ Hybolic tangentã€‚And finallyã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè¾“å…¥å’Œéšè—çŠ¶æ€éƒ½æœ‰ä¸€ä¸ªã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æƒé‡ä¹˜ä»¥å„è‡ªçš„å¼ é‡ã€‚åœ¨Mä¸­ï¼Œä»£è¡¨è‡ªç„¶ä¹˜æ³•ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•çš„è¾“å‡ºç›¸åŠ ã€‚å¹¶å°†ç»“æœé€šè¿‡æ¿€æ´»å‡½æ•°ï¼Œè¿™é‡Œæ˜¯åŒæ›²æ­£åˆ‡ã€‚æœ€åã€‚
- en: we compute the loss for this outputã€‚ The loss is the difference between the
    correct output and the actual prediction of our modelã€‚So we've taken a training
    inputï¼Œ run it through a modelï¼Œ gotten an output and determined the lossã€‚This is
    the point in the training loopï¼Œ where we have to compute the derivatives of that
    loss with respect to every parameter of the model and use the gradients over learning
    weights to decide how to adjust those weights in a way that reduces the lossã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¡ç®—è¿™ä¸ªè¾“å‡ºçš„æŸå¤±ã€‚æŸå¤±æ˜¯æ­£ç¡®è¾“å‡ºä¸æˆ‘ä»¬æ¨¡å‹çš„å®é™…é¢„æµ‹ä¹‹é—´çš„å·®å¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å·²ç»å–äº†ä¸€ä¸ªè®­ç»ƒè¾“å…¥ï¼Œé€šè¿‡æ¨¡å‹è¿è¡Œï¼Œå¾—åˆ°äº†è¾“å‡ºå¹¶ç¡®å®šäº†æŸå¤±ã€‚è¿™æ˜¯è®­ç»ƒå¾ªç¯ä¸­çš„ä¸€ä¸ªç¯èŠ‚ï¼Œæˆ‘ä»¬å¿…é¡»è®¡ç®—è¯¥æŸå¤±å¯¹æ¨¡å‹æ¯ä¸ªå‚æ•°çš„å¯¼æ•°ï¼Œå¹¶åˆ©ç”¨æ¢¯åº¦è°ƒæ•´å­¦ä¹ æƒé‡ï¼Œä»¥å‡å°‘æŸå¤±çš„æ–¹å¼æ¥è°ƒæ•´è¿™äº›æƒé‡ã€‚
- en: Even for a small model like thisï¼Œ that's a bunch of parameters and a lot of
    derivatives to computeã€‚But here's the good newsã€‚ You can do it in one line of
    codeã€‚Each tensor generated by this computation knows how it came to beã€‚ For exampleã€‚
    I to H carries metadata indicating that it came from the matrix multiplication
    of W X and Xã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æ˜¯è¿™æ ·ä¸€ä¸ªå°æ¨¡å‹ï¼Œä¹Ÿæœ‰ä¸€å †å‚æ•°å’Œå¤§é‡çš„å¯¼æ•°éœ€è¦è®¡ç®—ã€‚ä½†å¥½æ¶ˆæ¯æ˜¯ï¼Œä½ å¯ä»¥ç”¨ä¸€è¡Œä»£ç å®Œæˆã€‚æ¯ä¸ªç”±æ­¤è®¡ç®—ç”Ÿæˆçš„å¼ é‡éƒ½çŸ¥é“å®ƒæ˜¯å¦‚ä½•äº§ç”Ÿçš„ã€‚ä¾‹å¦‚ï¼ŒIåˆ°Hæºå¸¦å…ƒæ•°æ®ï¼Œè¡¨æ˜å®ƒæ¥è‡ªW
    Xå’ŒXçš„çŸ©é˜µä¹˜æ³•ã€‚
- en: And so it continues down the rest of the graphã€‚This history tracking enables
    the backward method to rapidly calculate the gradients your model needs for learningã€‚This
    history tracking is one of the things that enables flexibility and rapid iteration
    in your modelsã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”å®ƒä¼šç»§ç»­å‘ä¸‹å»¶ç»­åˆ°å›¾çš„å…¶ä½™éƒ¨åˆ†ã€‚è¿™ç§å†å²è·Ÿè¸ªä½¿å¾—åå‘æ–¹æ³•èƒ½å¤Ÿå¿«é€Ÿè®¡ç®—æ¨¡å‹åœ¨å­¦ä¹ ä¸­æ‰€éœ€çš„æ¢¯åº¦ã€‚è¿™ç§å†å²è·Ÿè¸ªæ˜¯ä½¿æ¨¡å‹çµæ´»å’Œå¿«é€Ÿè¿­ä»£çš„å› ç´ ä¹‹ä¸€ã€‚
- en: Even in a complex model with decision branches and loopsã€‚ the computation history
    will track the particular path through the model that a particular input took
    and compute the backward derivatives correctlyã€‚In a later videoï¼Œ we'll show you
    how to do more tricks with autogradã€‚ like using the autograd profiler and taking
    second derivatives and how to turn off autograd when you don't need itã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿åœ¨å…·æœ‰å†³ç­–åˆ†æ”¯å’Œå¾ªç¯çš„å¤æ‚æ¨¡å‹ä¸­ï¼Œè®¡ç®—å†å²ä¹Ÿä¼šè·Ÿè¸ªç‰¹å®šè¾“å…¥åœ¨æ¨¡å‹ä¸­æ‰€èµ°çš„è·¯å¾„ï¼Œå¹¶æ­£ç¡®è®¡ç®—åå‘å¯¼æ•°ã€‚åœ¨åç»­è§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨autogradè¿›è¡Œæ›´å¤šæŠ€å·§ï¼Œæ¯”å¦‚ä½¿ç”¨autogradåˆ†æå™¨ã€è®¡ç®—äºŒé˜¶å¯¼æ•°ï¼Œä»¥åŠå¦‚ä½•åœ¨ä¸éœ€è¦æ—¶å…³é—­autogradã€‚
- en: We've talked so far about tensors and automatic differentiation and some of
    the ways they interact with your Pytorrch modelã€‚ But what does that model look
    like in codeã€‚Let's build and run a simple one to get a feel for itã€‚Firstï¼Œ we're
    going to import pie torchã€‚We're also going to import torchsha Nnã€‚ which contains
    the neural network layers that we're going to compose into our modelã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è°ˆåˆ°äº†å¼ é‡ã€è‡ªåŠ¨å¾®åˆ†ä»¥åŠå®ƒä»¬å¦‚ä½•ä¸Pytorchtæ¨¡å‹ç›¸äº’ä½œç”¨ã€‚ä½†è¿™ä¸ªæ¨¡å‹åœ¨ä»£ç ä¸­æ˜¯ä»€ä¹ˆæ ·å­çš„å‘¢ï¼Ÿè®©æˆ‘ä»¬æ„å»ºå¹¶è¿è¡Œä¸€ä¸ªç®€å•çš„æ¨¡å‹ä»¥è·å–æ„Ÿè§‰ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†å¯¼å…¥PyTorchã€‚æˆ‘ä»¬è¿˜å°†å¯¼å…¥torch.nnï¼Œå®ƒåŒ…å«æˆ‘ä»¬å°†ç»„åˆæˆæ¨¡å‹çš„ç¥ç»ç½‘ç»œå±‚ã€‚
- en: as well as the parent class of the model itselfã€‚ And we're going to import torchta
    Nn do functional to give us activation functions and max pullinging functions
    that we'll use to connect the layersã€‚So here we have a diagram of Linenette 5ã€‚
    It's one of the earliest convolutional neural networks and one of the drivers
    of the explosion and deep learningã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ¨¡å‹æœ¬èº«çš„çˆ¶ç±»ã€‚æˆ‘ä»¬å°†å¯¼å…¥torch.nn.functionalï¼Œä»¥ä¾¿æä¾›æ¿€æ´»å‡½æ•°å’Œæœ€å¤§æ± åŒ–å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å°†ç”¨äºè¿æ¥å±‚ã€‚å› æ­¤ï¼Œè¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªLinenette
    5çš„ç¤ºæ„å›¾ã€‚å®ƒæ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œä¹Ÿæ˜¯æ·±åº¦å­¦ä¹ çˆ†ç‚¸çš„æ¨åŠ¨è€…ä¹‹ä¸€ã€‚
- en: It was built to read small images of handwritten numbersã€‚ The eddenist data
    set and correctly classify which digit was represented in the imageã€‚Here's the
    abridged version of how it worksã€‚ Layer C 1 is a convolutional layerã€‚ meaning
    that it scans the input image for features it learn during trainingã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ä¸ºäº†è¯»å–æ‰‹å†™æ•°å­—çš„å°å›¾åƒè€Œæ„å»ºçš„ã€‚è¯¥æ•°æ®é›†æ—¨åœ¨æ­£ç¡®åˆ†ç±»å›¾åƒä¸­æ‰€è¡¨ç¤ºçš„æ•°å­—ã€‚ä¸‹é¢æ˜¯å…¶å·¥ä½œåŸç†çš„ç®€è¦ç‰ˆæœ¬ã€‚å±‚C1æ˜¯å·ç§¯å±‚ï¼Œè¿™æ„å‘³ç€å®ƒæ‰«æè¾“å…¥å›¾åƒä»¥è¯†åˆ«åœ¨è®­ç»ƒæœŸé—´å­¦ä¹ åˆ°çš„ç‰¹å¾ã€‚
- en: It outputs a map of where it saw each each of its learned features in this imageã€‚
    This activation map is down sampled in layer S 2ã€‚Layer C 3 is another convolutional
    layerã€‚ This time scanning C1's activation map for combinations of featuresã€‚ It
    also puts out an activation map describing the spatial locations of these feature
    combinationsã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¾“å‡ºäº†åœ¨è¯¥å›¾åƒä¸­çœ‹åˆ°çš„æ¯ä¸ªå­¦ä¹ åˆ°çš„ç‰¹å¾çš„ä½ç½®å›¾ã€‚è¿™ä¸ªæ¿€æ´»å›¾åœ¨å±‚S2ä¸­è¿›è¡Œäº†ä¸‹é‡‡æ ·ã€‚å±‚C3æ˜¯å¦ä¸€ä¸ªå·ç§¯å±‚ï¼Œè¿™æ¬¡æ‰«æC1çš„æ¿€æ´»å›¾ä»¥å¯»æ‰¾ç‰¹å¾ç»„åˆã€‚å®ƒè¿˜è¾“å‡ºä¸€ä¸ªæ¿€æ´»å›¾ï¼Œæè¿°è¿™äº›ç‰¹å¾ç»„åˆçš„ç©ºé—´ä½ç½®ã€‚
- en: which is down sampled in layer S 4ã€‚Finallyï¼Œ the fully connected layers of the
    end at 5 F 6 and output are a classifier that takes the final activation map and
    classifies it into one of 10 bins representing the 10 digitsã€‚So how do we express
    this simple neural network in codeï¼ŸLooking over this codeã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¾“å‡ºåœ¨å±‚S4ä¸­è¿›è¡Œäº†ä¸‹é‡‡æ ·ã€‚æœ€åï¼Œä½äº5F6çš„å…¨è¿æ¥å±‚å’Œè¾“å‡ºæ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå®ƒæ¥å—æœ€ç»ˆçš„æ¿€æ´»å›¾å¹¶å°†å…¶åˆ†ç±»ä¸ºè¡¨ç¤º10ä¸ªæ•°å­—çš„10ä¸ªç®±å­ä¹‹ä¸€ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•åœ¨ä»£ç ä¸­è¡¨è¾¾è¿™ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œå‘¢ï¼Ÿçœ‹çœ‹è¿™æ®µä»£ç ã€‚
- en: you should be able to spot some structural similarities with a diagram aboveã€‚This
    demonstrates the structure of a typical pi torch modelã€‚ It inherits from torrssha
    and N dot moduleã€‚And modules may be nestedã€‚ In factã€‚ even the co2 D and linear
    layers here are subclasss of Torta and end dot moduleã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åº”è¯¥èƒ½çœ‹åˆ°ä¸ä¸Šé¢çš„å›¾è¡¨æœ‰ä¸€äº›ç»“æ„ä¸Šçš„ç›¸ä¼¼ä¹‹å¤„ã€‚è¿™å±•ç¤ºäº†ä¸€ä¸ªå…¸å‹çš„PyTorchæ¨¡å‹çš„ç»“æ„ã€‚å®ƒç»§æ‰¿è‡ªTorchå’ŒN.dotæ¨¡å—ï¼Œæ¨¡å—å¯ä»¥åµŒå¥—ã€‚å®é™…ä¸Šï¼Œè¿™é‡Œçš„2Då·ç§¯å±‚å’Œçº¿æ€§å±‚ä¹Ÿæ˜¯Tortaå’ŒN.dotæ¨¡å—çš„å­ç±»ã€‚
- en: Every model will have an in it where it constructs the layers that it will compose
    into its computation graphã€‚And loads any data artifacts it might needã€‚ For exampleï¼Œ
    an NLP model might load a vocabularyã€‚A model will have a forward functionã€‚ This
    is where the actual computation happensã€‚ and input is passed through the network
    layers in various functions to generate an outputã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡å‹éƒ½ä¼šæœ‰ä¸€ä¸ªåˆå§‹åŒ–æ–¹æ³•ï¼Œåœ¨å…¶ä¸­æ„å»ºå°†ç»„æˆå…¶è®¡ç®—å›¾çš„å±‚ï¼Œå¹¶åŠ è½½å¯èƒ½éœ€è¦çš„ä»»ä½•æ•°æ®å·¥ä»¶ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªNLPæ¨¡å‹å¯èƒ½ä¼šåŠ è½½ä¸€ä¸ªè¯æ±‡è¡¨ã€‚æ¨¡å‹å°†å…·æœ‰ä¸€ä¸ªå‰å‘å‡½æ•°ã€‚è¿™æ˜¯å®é™…è®¡ç®—å‘ç”Ÿçš„åœ°æ–¹ï¼Œè¾“å…¥é€šè¿‡ç½‘ç»œå±‚åœ¨å„ç§å‡½æ•°ä¸­ä¼ é€’ä»¥ç”Ÿæˆè¾“å‡ºã€‚
- en: a predictionã€‚Other than thatï¼Œ you can build out your model class like any other
    Python classã€‚ adding whatever properties and methods you need to support your
    model's computationã€‚So let's instanttantiate thisã€‚And run an input through itã€‚So
    there are a few important things happening hereã€‚ We're creating an instance of
    limitã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé¢„æµ‹ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä½ å¯ä»¥åƒæ„å»ºå…¶ä»–Pythonç±»ä¸€æ ·æ„å»ºä½ çš„æ¨¡å‹ç±»ï¼Œæ·»åŠ ä»»ä½•ä½ éœ€è¦æ”¯æŒæ¨¡å‹è®¡ç®—çš„å±æ€§å’Œæ–¹æ³•ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å®ä¾‹åŒ–è¿™ä¸ªï¼Œå¹¶é€šè¿‡å®ƒè¿è¡Œä¸€ä¸ªè¾“å…¥ã€‚è¿™é‡Œå‘ç”Ÿäº†å‡ ä¸ªé‡è¦çš„äº‹æƒ…ã€‚æˆ‘ä»¬æ­£åœ¨åˆ›å»ºä¸€ä¸ªé™åˆ¶çš„å®ä¾‹ã€‚
- en: We are printing the objectã€‚ now a sub of Tortra and in a moduleã€‚Will report
    the layers it has created and their shapes and parametersã€‚ This can provide a
    handy overview of a model if you want to get the gist of its processingã€‚Below
    thatï¼Œ we created dummy input representing a 32 by 32 image with one color channelã€‚Normallyã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨æ‰“å°å¯¹è±¡ï¼Œç°åœ¨æ˜¯Tortraçš„ä¸€ä¸ªå­ç±»å¹¶åœ¨ä¸€ä¸ªæ¨¡å—ä¸­ã€‚å°†æŠ¥å‘Šå®ƒåˆ›å»ºçš„å±‚åŠå…¶å½¢çŠ¶å’Œå‚æ•°ã€‚è¿™å¯ä»¥ä¸ºä½ æä¾›ä¸€ä¸ªæ¨¡å‹çš„æ–¹ä¾¿æ¦‚è¿°ï¼Œä»¥ä¾¿ä½ äº†è§£å…¶å¤„ç†çš„è¦ç‚¹ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè¡¨ç¤º32Ã—32å›¾åƒå’Œä¸€ä¸ªé¢œè‰²é€šé“çš„è™šæ‹Ÿè¾“å…¥ã€‚é€šå¸¸ã€‚
- en: you would load an image tile and convert it to a tensor of this shapeã€‚You may
    have noticed an extra dimension to our tensorã€‚ This is the batch dimensionã€‚Pytorrch
    models assume they are working on batches of dataã€‚ For exampleã€‚ a batch of 16
    of our image tiles would have the shape 16 by 1 by 32 by 32ã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦åŠ è½½ä¸€ä¸ªå›¾åƒåˆ‡ç‰‡å¹¶å°†å…¶è½¬æ¢ä¸ºè¿™ç§å½¢çŠ¶çš„å¼ é‡ã€‚ä½ å¯èƒ½æ³¨æ„åˆ°æˆ‘ä»¬çš„å¼ é‡æœ‰ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ã€‚è¿™æ˜¯æ‰¹é‡ç»´åº¦ã€‚PyTorchæ¨¡å‹å‡è®¾å®ƒä»¬åœ¨å¤„ç†æ•°æ®æ‰¹é‡ã€‚ä¾‹å¦‚ï¼Œä¸€æ‰¹16ä¸ªå›¾åƒåˆ‡ç‰‡å°†å…·æœ‰å½¢çŠ¶16Ã—1Ã—32Ã—32ã€‚
- en: Since we're only using one imageï¼Œ we create a batch of one with shape 1 by one
    by 32 by 32ã€‚We ask the model for an inference by calling it like a functionï¼Œ net
    inputã€‚The output of this call represents the model's confidence that the input
    represents a particular digitã€‚Since this instance of the model hasn't been trainedã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬åªä½¿ç”¨ä¸€å¼ å›¾åƒï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå½¢çŠ¶ä¸º1Ã—1Ã—32Ã—32çš„æ‰¹é‡ã€‚æˆ‘ä»¬é€šè¿‡è°ƒç”¨å®ƒä½œä¸ºä¸€ä¸ªå‡½æ•°æ¥è¯·æ±‚æ¨¡å‹è¿›è¡Œæ¨æ–­ï¼Œnet inputã€‚è¿™ä¸ªè°ƒç”¨çš„è¾“å‡ºè¡¨ç¤ºæ¨¡å‹å¯¹è¾“å…¥è¡¨ç¤ºç‰¹å®šæ•°å­—çš„ä¿¡å¿ƒã€‚å› ä¸ºè¯¥æ¨¡å‹å®ä¾‹å°šæœªç»è¿‡è®­ç»ƒã€‚
- en: we shouldn't expect to see any signal in the outputã€‚Looking at the shape of
    the outputã€‚ we can see that it also has a batch dimensionï¼Œ the size of which should
    always match the input batch dimensionã€‚ Had we passed in an input batch of 16
    instancesï¼Œ output would have a shape of 16 by 10ã€‚You've seen how a model is built
    and how to give it a batch of input and examine the outputã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸åº”è¯¥æœŸæœ›åœ¨è¾“å‡ºä¸­çœ‹åˆ°ä»»ä½•ä¿¡å·ã€‚æŸ¥çœ‹è¾“å‡ºçš„å½¢çŠ¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒè¿˜æœ‰ä¸€ä¸ªæ‰¹æ¬¡ç»´åº¦ï¼Œå¤§å°åº”è¯¥å§‹ç»ˆä¸è¾“å…¥æ‰¹æ¬¡ç»´åº¦ç›¸åŒ¹é…ã€‚å¦‚æœæˆ‘ä»¬ä¼ å…¥ä¸€ä¸ª16ä¸ªå®ä¾‹çš„è¾“å…¥æ‰¹æ¬¡ï¼Œè¾“å‡ºçš„å½¢çŠ¶å°†æ˜¯16Ã—10ã€‚ä½ å·²ç»äº†è§£äº†å¦‚ä½•æ„å»ºæ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•æä¾›ä¸€æ‰¹è¾“å…¥å¹¶æ£€æŸ¥è¾“å‡ºã€‚
- en: The model didn't do muchï¼Œ thoughï¼Œ because it hasn't been trained yet for thatã€‚
    We'll need to feed it a bunch of dataã€‚In order to train our modelã€‚ we're going
    to need a way to feed it data in bulkã€‚ This is where the Ptorrch data set and
    data load classes come into playã€‚Let's see them in actionã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œæ¨¡å‹å¹¶æ²¡æœ‰åšå¤ªå¤šï¼Œå› ä¸ºå®ƒå°šæœªç»è¿‡è®­ç»ƒã€‚æˆ‘ä»¬éœ€è¦æä¾›å¤§é‡æ•°æ®ï¼Œä»¥ä¾¿è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥æ‰¹é‡æä¾›æ•°æ®ã€‚è¿™å°±æ˜¯Pytorchæ•°æ®é›†å’Œæ•°æ®åŠ è½½ç±»å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚
- en: So here I'm declaring Matpllib in line because we'll be rendering some images
    in the notebook bookã€‚ I'm importing pitorrchã€‚ I'm also importing torch vision
    and torch vision transformsã€‚ These are going to give us our data sets and some
    transforms that we need to apply to the imagesã€‚To make them digestible by our
    pieytorrch modelã€‚So the first thing we need to do is transform our incoming images
    into a pi torch tensorã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™é‡Œæˆ‘åœ¨çº¿å£°æ˜Matplotlibï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨ç¬”è®°æœ¬ä¸­æ¸²æŸ“ä¸€äº›å›¾åƒã€‚æˆ‘æ­£åœ¨å¯¼å…¥Pytorchï¼ŒåŒæ—¶ä¹Ÿå¯¼å…¥torchvisionå’Œtorchvisionå˜æ¢ã€‚è¿™äº›å°†ä¸ºæˆ‘ä»¬æä¾›æ‰€éœ€çš„æ•°æ®é›†å’Œä¸€äº›éœ€è¦åº”ç”¨äºå›¾åƒçš„å˜æ¢ï¼Œä»¥ä¾¿è®©å®ƒä»¬é€‚åˆæˆ‘ä»¬çš„Pytorchæ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯å°†ä¼ å…¥çš„å›¾åƒè½¬æ¢ä¸ºPytorchå¼ é‡ã€‚
- en: Here we specify two transformations for our input Transs to Tensor takes images
    loaded by the pillow libraryã€‚And converts them into Py toch tensorsã€‚ transformers
    dot normalizeã€‚ adjust the values of the tensor so that their average is 0ï¼Œ and
    their standard deviation is 0ã€‚5ã€‚ Most activation functions had their strongest
    radiance around the0 pointã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºè¾“å…¥æŒ‡å®šäº†ä¸¤ä¸ªå˜æ¢ã€‚Transs to Tensorå°†ç”±Pillowåº“åŠ è½½çš„å›¾åƒè½¬æ¢ä¸ºPytorchå¼ é‡ã€‚transformers.dot
    normalizeä¼šè°ƒæ•´å¼ é‡çš„å€¼ï¼Œä½¿å…¶å¹³å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º0.5ã€‚å¤§å¤šæ•°æ¿€æ´»å‡½æ•°åœ¨0ç‚¹é™„è¿‘çš„è¾å°„æœ€å¼ºã€‚
- en: So centering our data there can speed learningã€‚There are many more transforms
    availableã€‚ including croppingï¼Œ centeringï¼Œ rotationï¼Œ reflectionã€‚ and most of the
    other things you might do to an imageã€‚Nextã€‚ we're going to create an instance
    of the Car 10 data setã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸­å¿ƒåŒ–æˆ‘ä»¬çš„æ•°æ®å¯ä»¥åŠ é€Ÿå­¦ä¹ ã€‚è¿˜æœ‰è®¸å¤šå…¶ä»–å¯ç”¨çš„å˜æ¢ï¼ŒåŒ…æ‹¬è£å‰ªã€ä¸­å¿ƒåŒ–ã€æ—‹è½¬ã€åå°„ï¼Œä»¥åŠä½ å¯èƒ½å¯¹å›¾åƒè¿›è¡Œçš„å…¶ä»–å¤§å¤šæ•°æ“ä½œã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªCar
    10æ•°æ®é›†çš„å®ä¾‹ã€‚
- en: This is a set of 32 by 32 color image tiles representing 10 classes of objectsã€‚6
    of animals and four vehiclesã€‚When you're on this all aboveã€‚ it may take a minute
    or two for this the data set to finish downloading for youã€‚ so be aware of thatã€‚So
    this is an example of creating a data set in Pytorrchã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç»„32Ã—32çš„å½©è‰²å›¾åƒç“·ç –ï¼Œä»£è¡¨10ç±»ç‰©ä½“ï¼ŒåŒ…æ‹¬6ç§åŠ¨ç‰©å’Œ4ç§è½¦è¾†ã€‚å½“ä½ å‡†å¤‡å¥½ä»¥ä¸Šæ‰€æœ‰å†…å®¹æ—¶ï¼Œå¯èƒ½éœ€è¦ä¸€ä¸¤åˆ†é’Ÿçš„æ—¶é—´æ¥ä¸‹è½½è¿™ä¸ªæ•°æ®é›†ï¼Œæ‰€ä»¥è¯·æ³¨æ„è¿™ä¸€ç‚¹ã€‚è¿™æ˜¯ä½¿ç”¨Pytorchåˆ›å»ºæ•°æ®é›†çš„ä¸€ä¸ªç¤ºä¾‹ã€‚
- en: downloadable data sets like Siffer 10 above are subclasses of Torchï¼Œ Us data
    data setã€‚Data set classes in pitorrch include the downloadable dataset sets in
    torchvisionã€‚ Torch text and torch audioï¼Œ as well as utility data set classes such
    as Torchvision datasets do image folderã€‚ which will read a folder of labeled imagesã€‚
    You can also create your own subclasses of data setã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä¸‹è½½çš„æ•°æ®é›†ï¼Œå¦‚ä¸Šé¢çš„Siffer 10ï¼Œæ˜¯Torchå’ŒUsæ•°æ®é›†çš„å­ç±»ã€‚Pytorchä¸­çš„æ•°æ®é›†ç±»åŒ…æ‹¬å¯åœ¨torchvisionä¸­ä¸‹è½½çš„æ•°æ®é›†ï¼Œä»¥åŠTorchæ–‡æœ¬å’ŒtorchéŸ³é¢‘ï¼Œè¿˜æœ‰ä¸€äº›å®ç”¨çš„æ•°æ®é›†ç±»ï¼Œä¾‹å¦‚Torchvision
    datasetsä¸­çš„å›¾åƒæ–‡ä»¶å¤¹ï¼Œå®ƒå°†è¯»å–ä¸€ä¸ªæ ‡è®°å›¾åƒçš„æ–‡ä»¶å¤¹ã€‚ä½ ä¹Ÿå¯ä»¥åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†å­ç±»ã€‚
- en: When we instantiate our data setï¼Œ we need to tell it a few thingsã€‚The file system
    path where we want the data to goï¼Œ whether or not we're using this set for trainingã€‚
    because most data sets will be split between training and test subsetsã€‚Whether
    we would like to download the data set if we haven't already and the transformations
    that we want to apply to the imagesã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å®ä¾‹åŒ–æˆ‘ä»¬çš„æ•°æ®é›†æ—¶ï¼Œéœ€è¦å‘Šè¯‰å®ƒä¸€äº›ä¿¡æ¯ï¼ŒåŒ…æ‹¬æˆ‘ä»¬å¸Œæœ›æ•°æ®å­˜æ”¾çš„æ–‡ä»¶ç³»ç»Ÿè·¯å¾„ï¼Œæ˜¯å¦å°†æ­¤æ•°æ®é›†ç”¨äºè®­ç»ƒï¼Œå› ä¸ºå¤§å¤šæ•°æ•°æ®é›†ä¼šåœ¨è®­ç»ƒå’Œæµ‹è¯•å­é›†ä¹‹é—´è¿›è¡Œæ‹†åˆ†ã€‚æ˜¯å¦å¸Œæœ›ä¸‹è½½æ•°æ®é›†ï¼ˆå¦‚æœæˆ‘ä»¬è¿˜æ²¡æœ‰ä¸‹è½½çš„è¯ï¼‰ä»¥åŠæˆ‘ä»¬å¸Œæœ›å¯¹å›¾åƒåº”ç”¨çš„å˜æ¢ã€‚
- en: Once you have your data set readyï¼Œ you can give it to the data loaderã€‚Now a
    data set subclass wraps access to the data and is specialized the type of the
    data is servingã€‚The data loader knows nothing about the dataï¼Œ but organizes the
    input tensors served by the data set into batches with the parameters you specify
    In the example aboveã€‚ we've asked a data loader to give us batches of four images
    from train setã€‚Randomizing their orderã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ å‡†å¤‡å¥½æ•°æ®é›†ï¼Œå°±å¯ä»¥å°†å…¶äº¤ç»™æ•°æ®åŠ è½½å™¨ã€‚ç°åœ¨ï¼Œæ•°æ®é›†å­ç±»å°è£…äº†å¯¹æ•°æ®çš„è®¿é—®ï¼Œå¹¶ä¸“é—¨é’ˆå¯¹å…¶æ‰€æœåŠ¡çš„æ•°æ®ç±»å‹ã€‚æ•°æ®åŠ è½½å™¨å¯¹æ•°æ®ä¸€æ— æ‰€çŸ¥ï¼Œä½†æ ¹æ®ä½ åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­æŒ‡å®šçš„å‚æ•°ï¼Œå°†æ•°æ®é›†æä¾›çš„è¾“å…¥å¼ é‡ç»„ç»‡æˆæ‰¹æ¬¡ã€‚æˆ‘ä»¬è¯·æ±‚æ•°æ®åŠ è½½å™¨ä»è®­ç»ƒé›†ä¸­ç»™æˆ‘ä»¬æä¾›å››å¼ å›¾åƒçš„æ‰¹æ¬¡ï¼ŒéšæœºåŒ–å®ƒä»¬çš„é¡ºåºã€‚
- en: With shuffle equals trueã€‚ And we told to spin up two workers to load data from
    diskã€‚ It's good practice to visualize the batches your data loader servesã€‚Rning
    the cells should show you a strip of four images and you should see a correct
    label for each oneã€‚And so here are our four images which do in fact look like
    a catï¼Œ a deer in two trucksã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è®¾ç½®ä¸ºshuffleä¸ºçœŸæ—¶ï¼Œæˆ‘ä»¬å‘Šè¯‰å®ƒå¯åŠ¨ä¸¤ä¸ªå·¥ä½œçº¿ç¨‹ä»ç£ç›˜åŠ è½½æ•°æ®ã€‚å¯è§†åŒ–æ•°æ®åŠ è½½å™¨æä¾›çš„æ‰¹æ¬¡æ˜¯ä¸€ç§è‰¯å¥½çš„å®è·µã€‚è¿è¡Œè¿™äº›å•å…ƒåº”è¯¥ä¼šæ˜¾ç¤ºå‡ºå››å¼ å›¾åƒçš„æ¡å¸¦ï¼Œå¹¶ä¸”ä½ åº”è¯¥èƒ½çœ‹åˆ°æ¯å¼ å›¾åƒçš„æ­£ç¡®æ ‡ç­¾ã€‚é‚£ä¹ˆï¼Œè¿™é‡Œæ˜¯æˆ‘ä»¬çš„å››å¼ å›¾åƒï¼Œå®é™…ä¸Šçœ‹èµ·æ¥åƒæ˜¯ä¸€åªçŒ«å’Œä¸€åªåœ¨ä¸¤è¾†å¡è½¦é‡Œçš„é¹¿ã€‚
- en: We've looked under the hood at tensors and autogradã€‚ and we've seen how pi torch
    models are constructed and how to efficiently feed them datatumã€‚It's time to put
    all the pieces together and see how a model gets trainedã€‚So here we are back in
    our notebookï¼Œ you'll see the imports hereã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»æ·±å…¥äº†è§£äº†å¼ é‡å’Œè‡ªåŠ¨æ±‚å¯¼ï¼Œå¹¶çœ‹åˆ°äº†PyTorchæ¨¡å‹æ˜¯å¦‚ä½•æ„å»ºçš„ï¼Œä»¥åŠå¦‚ä½•é«˜æ•ˆåœ°ä¸ºå®ƒä»¬æä¾›æ•°æ®ã€‚æ˜¯æ—¶å€™æŠŠæ‰€æœ‰çš„éƒ¨åˆ†ç»“åˆèµ·æ¥ï¼Œçœ‹çœ‹ä¸€ä¸ªæ¨¡å‹æ˜¯å¦‚ä½•è®­ç»ƒçš„ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å›åˆ°äº†ç¬”è®°æœ¬ï¼Œä½ ä¼šçœ‹åˆ°è¿™é‡Œçš„å¯¼å…¥ã€‚
- en: all of these should look familiar from earlier in the video except for Torchdot
    Opumã€‚ which I'll be talking about soonã€‚The first thing we'll need is training
    and test data setsã€‚ So if you haven't already run the cell below and make sure
    the data set is downloadedã€‚ you may take a minute if you haven't done so alreadyã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†Torchdot Opumï¼Œæ‰€æœ‰è¿™äº›åœ¨è§†é¢‘æ—©äº›æ—¶å€™åº”è¯¥çœ‹èµ·æ¥éƒ½å¾ˆç†Ÿæ‚‰ã€‚æˆ‘ä»¬é¦–å…ˆéœ€è¦çš„æ˜¯è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰è¿è¡Œä¸‹é¢çš„å•å…ƒï¼Œè¯·ç¡®ä¿æ•°æ®é›†å·²ä¸‹è½½ã€‚å¦‚æœä½ è¿˜æ²¡è¿™æ ·åšï¼Œå¯èƒ½éœ€è¦èŠ±ä¸€åˆ†é’Ÿçš„æ—¶é—´ã€‚
- en: We'll run our check on the output from the data loaderã€‚And againã€‚ we should
    see a strip of four imagesï¼Œ a plainï¼Œ plainï¼Œ plain shipã€‚ That looks correctã€‚ Sorryã€‚
    data letter is goodã€‚This is the model we'll trainã€‚ Nowã€‚ this model looks familiar
    It's because it's a variant of Lyetteã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ£€æŸ¥æ•°æ®åŠ è½½å™¨çš„è¾“å‡ºã€‚å†æ¬¡ï¼Œæˆ‘ä»¬åº”è¯¥çœ‹åˆ°å››å¼ å›¾åƒçš„æ¡å¸¦ï¼Œè¿™çœ‹èµ·æ¥æ˜¯æ­£ç¡®çš„ã€‚æŠ±æ­‰ï¼Œæ•°æ®åŠ è½½å™¨å¾ˆå¥½ã€‚è¿™æ˜¯æˆ‘ä»¬å°†è®­ç»ƒçš„æ¨¡å‹ã€‚ç°åœ¨ï¼Œè¿™ä¸ªæ¨¡å‹çœ‹èµ·æ¥å¾ˆç†Ÿæ‚‰ï¼Œå› ä¸ºå®ƒæ˜¯Lyetteçš„ä¸€ä¸ªå˜ä½“ã€‚
- en: which we discussed earlier in this videoï¼Œ but it's adapted to take three color
    imagesã€‚The final ingredients we need are a loss functionï¼Œ and an optimizerã€‚The
    loss functionã€‚ as discussed earlier in this videoï¼Œ is a measure of how far from
    our ideal output the model's prediction wasã€‚ Cross entropy loss is a typical loss
    function for classification models like oursã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æœ¬è§†é¢‘æ—©äº›æ—¶å€™è®¨è®ºè¿‡è¿™ä¸€ç‚¹ï¼Œä½†å®ƒè¢«è°ƒæ•´ä¸ºå¤„ç†ä¸‰ç§é¢œè‰²çš„å›¾åƒã€‚æˆ‘ä»¬éœ€è¦çš„æœ€ç»ˆç»„æˆéƒ¨åˆ†æ˜¯æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ã€‚æŸå¤±å‡½æ•°ï¼Œå¦‚æœ¬è§†é¢‘æ—©äº›æ—¶å€™è®¨è®ºçš„ï¼Œæ˜¯è¡¡é‡æ¨¡å‹é¢„æµ‹ä¸ç†æƒ³è¾“å‡ºä¹‹é—´å·®è·çš„æŒ‡æ ‡ã€‚äº¤å‰ç†µæŸå¤±æ˜¯åƒæˆ‘ä»¬è¿™æ ·çš„åˆ†ç±»æ¨¡å‹çš„å…¸å‹æŸå¤±å‡½æ•°ã€‚
- en: The optimizer is what drives the learningã€‚Hereï¼Œ we've created an optimizer that
    implements stochastic gradient descentã€‚ one of the more straightforward optimization
    algorithmsã€‚ Besides parameters of the algorithmã€‚ like the learning rate and momentumã€‚
    we also pass in net dot parametersã€‚ which is a collection of all the learning
    weights in the modelï¼Œ which is what the optimizer adjustsã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–å™¨æ˜¯æ¨åŠ¨å­¦ä¹ çš„å…³é”®ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå®ç°éšæœºæ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–å™¨ï¼Œè¿™æ˜¯æœ€ç®€å•çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ã€‚é™¤äº†ç®—æ³•çš„å‚æ•°ï¼Œå¦‚å­¦ä¹ ç‡å’ŒåŠ¨é‡å¤–ï¼Œæˆ‘ä»¬è¿˜ä¼ å…¥äº†netçš„å‚æ•°ï¼Œè¿™æ˜¯æ¨¡å‹ä¸­æ‰€æœ‰å­¦ä¹ æƒé‡çš„é›†åˆï¼Œä¼˜åŒ–å™¨ä¼šè°ƒæ•´è¿™äº›æƒé‡ã€‚
- en: Finallyï¼Œ all this is assembled into the training loopã€‚Go ahead and run this
    cellã€‚ as it'll take a couple of minutes to executeã€‚So here we're only doing two
    training epicsã€‚ as you can see from line 1ï¼Œ that is two complete passes over the
    training data setã€‚Each pass has an inner loop that iterates over the training
    dataã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ‰€æœ‰è¿™äº›éƒ½æ±‡é›†åˆ°è®­ç»ƒå¾ªç¯ä¸­ã€‚ç»§ç»­è¿è¡Œè¿™ä¸ªå•å…ƒï¼Œå› ä¸ºå®ƒä¼šèŠ±å‡ åˆ†é’Ÿæ¥æ‰§è¡Œã€‚ä»ç¬¬ä¸€è¡Œä½ å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬åªè¿›è¡Œäº†ä¸¤æ¬¡è®­ç»ƒå†ç¨‹ï¼Œå³å¯¹è®­ç»ƒæ•°æ®é›†çš„ä¸¤æ¬¡å®Œæ•´éå†ã€‚æ¯æ¬¡éå†éƒ½æœ‰ä¸€ä¸ªå†…å¾ªç¯ï¼Œç”¨äºè¿­ä»£è®­ç»ƒæ•°æ®ã€‚
- en: serving batches of transformed images in their correct labelsã€‚Zing the gradients
    in line 9 is a very important stepã€‚ When you run a batchã€‚ gradients are accumulated
    over that batchã€‚ And if we don't reset the gradients for every batchã€‚ they will
    keep accumulating and provide incorrect valuesï¼Œ and learning will stopã€‚In line
    12ã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†æ‰¹æ¬¡çš„å˜æ¢å›¾åƒåŠå…¶æ­£ç¡®æ ‡ç­¾ã€‚åœ¨ç¬¬9è¡Œä¸­å¤„ç†æ¢¯åº¦æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„æ­¥éª¤ã€‚å½“ä½ è¿è¡Œä¸€ä¸ªæ‰¹æ¬¡æ—¶ï¼Œæ¢¯åº¦ä¼šåœ¨è¯¥æ‰¹æ¬¡ä¸­ç´¯ç§¯ã€‚å¦‚æœæˆ‘ä»¬ä¸ä¸ºæ¯ä¸ªæ‰¹æ¬¡é‡ç½®æ¢¯åº¦ï¼Œå®ƒä»¬å°†ç»§ç»­ç´¯ç§¯å¹¶æä¾›ä¸æ­£ç¡®çš„å€¼ï¼Œä»è€Œå¯¼è‡´å­¦ä¹ åœæ­¢ã€‚åœ¨ç¬¬12è¡Œä¸­ã€‚
- en: we ask the model for its actual prediction on the batchã€‚In the following lineï¼Œ
    line 13ã€‚ we compute the lossã€‚ The difference between the outputs and the labelsã€‚In
    line 14ã€‚ we do our backward pass and calculate the gradients that will direct
    the learningã€‚In line 15ã€‚ the optimizer performs one learning stepã€‚It uses the
    gradients from the backward call to nudge the learning weights in the direction
    it thinks will reduce the lossã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘æ¨¡å‹è¯·æ±‚å…¶å¯¹è¯¥æ‰¹æ¬¡çš„å®é™…é¢„æµ‹ã€‚åœ¨æ¥ä¸‹æ¥çš„è¡Œä¸­ï¼Œè¡Œ13ï¼Œæˆ‘ä»¬è®¡ç®—æŸå¤±ã€‚è¾“å‡ºä¸æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ã€‚åœ¨è¡Œ14ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œåå‘ä¼ æ’­ï¼Œè®¡ç®—å°†å¼•å¯¼å­¦ä¹ çš„æ¢¯åº¦ã€‚åœ¨è¡Œ15ä¸­ï¼Œä¼˜åŒ–å™¨æ‰§è¡Œä¸€æ¬¡å­¦ä¹ æ­¥éª¤ã€‚å®ƒåˆ©ç”¨åå‘è°ƒç”¨ä¸­çš„æ¢¯åº¦æ¥æ¨åŠ¨å­¦ä¹ æƒé‡æœç€å‡å°‘æŸå¤±çš„æ–¹å‘è°ƒæ•´ã€‚
- en: So the remainder of the loop just does some light reporting on the epic number
    and how many training instances have been completedã€‚What the collective losses
    is over the training epicã€‚So note that the loss is monotonomically descendedã€‚
    indicating that our model is continuing to improve its performance in the training
    data setã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¾ªç¯çš„å…¶ä½™éƒ¨åˆ†åªæ˜¯å¯¹å²è¯—ç¼–å·å’Œå·²å®Œæˆçš„è®­ç»ƒå®ä¾‹æ•°é‡è¿›è¡Œä¸€äº›ç®€å•æŠ¥å‘Šã€‚æ€»ä½“æŸå¤±åœ¨è®­ç»ƒå²è¯—ä¸Šæ˜¯å¤šå°‘ã€‚å› æ­¤è¯·æ³¨æ„ï¼ŒæŸå¤±æ˜¯å•è°ƒä¸‹é™çš„ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¸æ–­æé«˜ã€‚
- en: As a final stepï¼Œ we should check that the model is actually doing general learning
    and not simply memorizing a data setã€‚ This is called overfitting and will often
    indicate that either your data set is too small and doesn't have enough examples
    or that your model is too large that it's overspecifiedã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬åº”è¯¥æ£€æŸ¥æ¨¡å‹æ˜¯å¦çœŸçš„åœ¨è¿›è¡Œä¸€èˆ¬å­¦ä¹ ï¼Œè€Œä¸æ˜¯ç®€å•åœ°è®°å¿†æ•°æ®é›†ã€‚è¿™ç§°ä¸ºè¿‡æ‹Ÿåˆï¼Œé€šå¸¸è¡¨æ˜ä½ çš„æ•°æ®é›†å¤ªå°ï¼Œç¤ºä¾‹ä¸è¶³ï¼Œæˆ–æ¨¡å‹è¿‡å¤§ï¼Œè¶…å‡ºäº†è§„èŒƒã€‚
- en: For modeling the dataã€‚You're treatinging itã€‚So our training was doneã€‚å—¯ã€‚So anywaysï¼Œ
    the way weã€‚Check for overfitting and guard against it is to test the model on
    data it hasn't trained onã€‚ that's where we have a test data setã€‚So here I'm just
    going to run the test data throughã€‚ we'll get in accuracy measure outã€‚55% Okayï¼Œ
    so that's not exactly the state of the artã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚ä½ æ­£åœ¨å¤„ç†å®ƒã€‚æ‰€ä»¥æˆ‘ä»¬çš„è®­ç»ƒå®Œæˆäº†ã€‚å—¯ã€‚æ— è®ºå¦‚ä½•ï¼Œæˆ‘ä»¬æ£€æµ‹è¿‡æ‹Ÿåˆå¹¶é˜²æ­¢å®ƒçš„æ–¹æ³•æ˜¯æµ‹è¯•æ¨¡å‹åœ¨æœªè®­ç»ƒè¿‡çš„æ•°æ®ä¸Šã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ‹¥æœ‰æµ‹è¯•æ•°æ®é›†çš„åŸå› ã€‚æ‰€ä»¥æˆ‘å°†è¿è¡Œæµ‹è¯•æ•°æ®ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªå‡†ç¡®åº¦åº¦é‡ã€‚55%
    å¥½å§ï¼Œè¿™å¹¶ä¸ç®—å…ˆè¿›ã€‚
- en: but it's much better than the 10% we'd expect to see from a random outputã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_22.png)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™æ¯”æˆ‘ä»¬æœŸæœ›çš„éšæœºè¾“å‡ºçš„10%è¦å¥½å¾—å¤šã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_22.png)
- en: This demonstrates that some general learning did happen in the modelã€‚Nowã€‚ when
    you go to the trouble of building and training a non trivial model is usually
    because you want to use it for somethingã€‚ You need to connect it to a system that
    feeds its inputs and processes the model's predictionsã€‚If you're keen on optimizing
    performanceï¼Œ you may want to do this without a dependency on the Python interpreterã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨æ˜æ¨¡å‹ç¡®å®å‘ç”Ÿäº†ä¸€äº›ä¸€èˆ¬å­¦ä¹ ã€‚ç°åœ¨ï¼Œå½“ä½ èŠ±è´¹æ—¶é—´æ„å»ºå’Œè®­ç»ƒä¸€ä¸ªéå¹³å‡¡æ¨¡å‹æ—¶ï¼Œé€šå¸¸æ˜¯å› ä¸ºä½ å¸Œæœ›å°†å…¶ç”¨äºæŸä¸ªç›®çš„ã€‚ä½ éœ€è¦å°†å…¶è¿æ¥åˆ°ä¸€ä¸ªç³»ç»Ÿï¼Œä»¥ä¾¿è¾“å…¥æ•°æ®å¹¶å¤„ç†æ¨¡å‹çš„é¢„æµ‹ã€‚å¦‚æœä½ çƒ­è¡·äºä¼˜åŒ–æ€§èƒ½ï¼Œå¯èƒ½å¸Œæœ›åœ¨ä¸ä¾èµ–Pythonè§£é‡Šå™¨çš„æƒ…å†µä¸‹åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: The good news is that Pytorrch accommodates you with torch scriptã€‚ğŸ˜Šï¼ŒTorchscript
    is a staticã€‚ high performance subset of Pythonã€‚ When you convert a model to torchscriptã€‚
    the dynamic and pythonic nature of your model is fully preservedã€‚ Control flow
    is preserved when convert to torchscriptã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½æ¶ˆæ¯æ˜¯PyTorchä¸ºä½ æä¾›äº†torch scriptã€‚ğŸ˜Šï¼ŒTorchscriptæ˜¯Pythonçš„ä¸€ä¸ªé™æ€é«˜æ€§èƒ½å­é›†ã€‚å½“ä½ å°†æ¨¡å‹è½¬æ¢ä¸ºtorchscriptæ—¶ï¼Œæ¨¡å‹çš„åŠ¨æ€å’ŒPythonicç‰¹æ€§ä¼šè¢«å®Œå…¨ä¿ç•™ã€‚æ§åˆ¶æµåœ¨è½¬æ¢ä¸ºtorchscriptæ—¶å¾—åˆ°ä¿ç•™ã€‚
- en: and you can still use convenient Python data structuresï¼Œ like lists and dictionariesã€‚Looking
    at the code on the rightï¼Œ you'll see a py torch model defined in Pythonã€‚Below
    thatã€‚ in instance of the model is createdï¼Œ and then we'll call torch dot dot script
    my moduleã€‚That one line of code is all it takes to convert your Python model to
    torchscriptã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ä½ ä»ç„¶å¯ä»¥ä½¿ç”¨æ–¹ä¾¿çš„Pythonæ•°æ®ç»“æ„ï¼Œå¦‚åˆ—è¡¨å’Œå­—å…¸ã€‚æŸ¥çœ‹å³ä¾§çš„ä»£ç ï¼Œä½ ä¼šçœ‹åˆ°ç”¨Pythonå®šä¹‰çš„py torchæ¨¡å‹ã€‚åœ¨æ­¤ä¹‹ä¸‹ï¼Œåˆ›å»ºæ¨¡å‹çš„å®ä¾‹ï¼Œç„¶åæˆ‘ä»¬å°†è°ƒç”¨torch
    dot dot script my moduleã€‚åªéœ€ä¸€è¡Œä»£ç ï¼Œå°±å¯ä»¥å°†ä½ çš„Pythonæ¨¡å‹è½¬æ¢ä¸ºtorchscriptã€‚
- en: The serialized version of this gets saved in the final lineã€‚ and it contains
    all the information about your model's computation graph and its learning weightsã€‚The
    torch grip rendering of the model is shown at the rightã€‚Torch script is meant
    to be consumed by the piytorrch just in time compiler or Jitã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åºåˆ—åŒ–ç‰ˆæœ¬ä¿å­˜åœ¨æœ€åä¸€è¡Œï¼Œå…¶ä¸­åŒ…å«æœ‰å…³æ‚¨æ¨¡å‹è®¡ç®—å›¾åŠå…¶å­¦ä¹ æƒé‡çš„æ‰€æœ‰ä¿¡æ¯ã€‚æ¨¡å‹çš„torch gripæ¸²æŸ“æ˜¾ç¤ºåœ¨å³ä¾§ã€‚Torchè„šæœ¬æ—¨åœ¨è¢«PyTorchå³æ—¶ç¼–è¯‘å™¨æˆ–Jitä½¿ç”¨ã€‚
- en: The Jit seeks runtime optimizations such as operation reordering and layer fusion
    to maximize your model's performance on CPU or GP hardwareã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_24.png)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Jitå¯»æ±‚è¿è¡Œæ—¶ä¼˜åŒ–ï¼Œå¦‚æ“ä½œé‡æ’åºå’Œå±‚èåˆï¼Œä»¥æœ€å¤§åŒ–æ‚¨æ¨¡å‹åœ¨CPUæˆ–GPUç¡¬ä»¶ä¸Šçš„æ€§èƒ½ã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_24.png)
- en: So how do you load and execute a torch script modelã€‚ You start by loading the
    serialized package with a torch shott Jet dot loadã€‚ and then you can call it just
    like any other modelã€‚What's moreï¼Œ you can do this in Python orã€‚You can load it
    into the Pytorrch C plus plus runtime to remove the interpreted language dependencyã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæ‚¨å¦‚ä½•åŠ è½½å’Œæ‰§è¡Œtorchè„šæœ¬æ¨¡å‹å‘¢ï¼Ÿæ‚¨å¯ä»¥é€šè¿‡torch shott Jet dot loadåŠ è½½åºåˆ—åŒ–åŒ…ï¼Œç„¶ååƒå…¶ä»–æ¨¡å‹ä¸€æ ·è°ƒç”¨å®ƒã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæ‚¨å¯ä»¥åœ¨Pythonä¸­è¿™æ ·åšï¼Œä¹Ÿå¯ä»¥å°†å…¶åŠ è½½åˆ°Pytorrch
    C++è¿è¡Œæ—¶ä¸­ï¼Œä»¥æ¶ˆé™¤å¯¹è§£é‡Šè¯­è¨€çš„ä¾èµ–ã€‚
- en: In subsequent videos we'll go into more detail about Torch scriptï¼Œ best practices
    for deploymentã€‚ and will cover Torch Ser P Torch's model serving solutionã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_26.png)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åç»­è§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°è®¨è®ºTorchè„šæœ¬ã€éƒ¨ç½²çš„æœ€ä½³å®è·µï¼Œå¹¶æ¶µç›–Torch Ser P Torchçš„æ¨¡å‹æœåŠ¡è§£å†³æ–¹æ¡ˆã€‚![](img/1181a3784e7b926ea0c178203ada7ae1_26.png)
- en: So that's our lightningï¼Œ fast overview of Pyetorrchã€‚ The models and data sets
    we used here were quite simpleã€‚ But Pytorrchches used in production at large enterprises
    for powerful real world use casesã€‚ like translating between human languagesï¼Œ describing
    the content of video scenes or generating realistic human voices in the videos
    to follow will' give you access to that power will go deeper on all the topics
    covered here with more complex use cases like the ones you'll see in the real
    worldã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯æˆ‘ä»¬å¯¹Pyetorrchçš„å¿«é€Ÿæ¦‚è¿°ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨çš„æ¨¡å‹å’Œæ•°æ®é›†ç›¸å¯¹ç®€å•ã€‚ä½†Pytorrchåœ¨å¤§å‹ä¼ä¸šä¸­ç”¨äºå¼ºå¤§çš„å®é™…åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚åœ¨äººç±»è¯­è¨€ä¹‹é—´è¿›è¡Œç¿»è¯‘ã€æè¿°è§†é¢‘åœºæ™¯çš„å†…å®¹æˆ–åœ¨è§†é¢‘ä¸­ç”Ÿæˆé€¼çœŸçš„äººå£°ã€‚æ¥ä¸‹æ¥å°†æ·±å…¥æ¢è®¨è¿™é‡Œè®¨è®ºçš„æ‰€æœ‰ä¸»é¢˜ï¼Œæ¶µç›–æ›´å¤æ‚çš„ç”¨ä¾‹ï¼Œå°±åƒæ‚¨åœ¨ç°å®ä¸–ç•Œä¸­çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: ğŸ˜Šï¼ŒThank you for your time and attentionã€‚ And I hope to see you around the Pytorrch
    Forsã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæ„Ÿè°¢æ‚¨çš„æ—¶é—´å’Œå…³æ³¨ã€‚å¸Œæœ›åœ¨Pytorrch Forsè§åˆ°æ‚¨ã€‚
