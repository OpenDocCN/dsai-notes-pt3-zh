- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠNLPä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P29ï¼šL4.6- TensorFlow é¢„æµ‹å’Œè¯„ä¼°æŒ‡æ ‡ - ShowMeAI - BV1Jm4y1X7UL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥äº†ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠ NLP ä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P29ï¼šL4.6- TensorFlow é¢„æµ‹å’Œè¯„ä¼°æŒ‡æ ‡ - ShowMeAI - BV1Jm4y1X7UL
- en: In our other videosã€‚ and as alwaysï¼Œ there'll be links below if you want to check
    those outã€‚ We showed you how to initialize and finet a transformer model in Tensorflowã€‚
    So the question now isã€‚ what can we do with a model after we train itã€‚ The obvious
    thing to try is to use it to get predictions for new dataã€‚ So let's see how to
    do thatï¼Œ Againï¼Œ if you're familiar with Kaisã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å…¶ä»–çš„è§†é¢‘ä¸­ï¼Œå’Œå¾€å¸¸ä¸€æ ·ï¼Œå¦‚æœä½ æƒ³æŸ¥çœ‹è¿™äº›ï¼Œä¸‹é¢ä¼šæœ‰é“¾æ¥ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨ Tensorflow ä¸­åˆå§‹åŒ–å’Œå¾®è°ƒä¸€ä¸ª transformer æ¨¡å‹ã€‚é‚£ä¹ˆç°åœ¨çš„é—®é¢˜æ˜¯ï¼Œè®­ç»ƒåæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¨¡å‹åšä»€ä¹ˆï¼Ÿæ˜¾ç„¶è¦å°è¯•çš„æ˜¯ç”¨å®ƒå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬çœ‹çœ‹æ€ä¹ˆåšï¼Œå†æ¬¡ï¼Œå¦‚æœä½ ç†Ÿæ‚‰
    Kaisã€‚
- en: The good news is that because these are just standard caris modelsã€‚ we can use
    the standard Keis predict method as shown hereã€‚ğŸ˜Šã€‚You simply pass in tokenized
    text to this method like you'd get from a tokenizer and you get your resultsã€‚Our
    models can output several different thingsï¼Œ depending on the options you saidã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½æ¶ˆæ¯æ˜¯ï¼Œå› ä¸ºè¿™äº›åªæ˜¯æ ‡å‡† caris æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ ‡å‡†çš„ Keis é¢„æµ‹æ–¹æ³•ï¼Œå¦‚æ­¤å¤„æ‰€ç¤ºã€‚ğŸ˜Šã€‚ä½ åªéœ€å°†æ ‡è®°åŒ–çš„æ–‡æœ¬ä¼ é€’ç»™è¿™ä¸ªæ–¹æ³•ï¼Œå°±åƒä½ ä»æ ‡è®°å™¨ä¸­å¾—åˆ°çš„ç»“æœä¸€æ ·ï¼Œä½ å°±èƒ½è·å¾—ä½ çš„ç»“æœã€‚æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æ ¹æ®ä½ è®¾ç½®çš„é€‰é¡¹è¾“å‡ºå‡ ç§ä¸åŒçš„å†…å®¹ã€‚
- en: but most of the timeï¼Œ the thing you want is the output logtsã€‚ If you haven't
    come across them beforeï¼Œ Los sometimes pronounced logitsã€‚ because no one's sure
    are the outputs of the last layer of the network because before a softm has been
    appliedã€‚ So if you want to turn the logics into the model's probability outputsã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¤§å¤šæ•°æ—¶å€™ï¼Œä½ æƒ³è¦çš„ä¸œè¥¿æ˜¯è¾“å‡º logtsã€‚å¦‚æœä½ ä¹‹å‰æ²¡æœ‰é‡åˆ°è¿‡ï¼Œå®ƒä»¬æœ‰æ—¶è¢«ç§°ä¸º logitsï¼Œå› ä¸ºæ²¡æœ‰äººç¡®å®šï¼Œå®ƒä»¬æ˜¯ç½‘ç»œæœ€åä¸€å±‚çš„è¾“å‡ºï¼Œå› ä¸ºåœ¨åº”ç”¨
    softm ä¹‹å‰ã€‚æ‰€ä»¥å¦‚æœä½ æƒ³å°† logics è½¬æ¢ä¸ºæ¨¡å‹çš„æ¦‚ç‡è¾“å‡ºã€‚
- en: you just apply a softm like soã€‚What if we wantï¼Œ But what if we want to turn
    those probabilities into class predictionsã€‚ Againï¼Œ it's very straightforwardã€‚
    We just pick the biggest probability for each outputã€‚ and you can get that immediately
    with the Argm functionã€‚ Argmax will return the index of the largest probability
    in each rowã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åªéœ€åƒè¿™æ ·åº”ç”¨ä¸€ä¸ª softmã€‚é‚£ä¹ˆå¦‚æœæˆ‘ä»¬æƒ³æŠŠè¿™äº›æ¦‚ç‡è½¬åŒ–ä¸ºç±»é¢„æµ‹å‘¢ï¼Ÿå†æ¬¡ï¼Œè¿™éå¸¸ç®€å•ã€‚æˆ‘ä»¬åªéœ€ä¸ºæ¯ä¸ªè¾“å‡ºé€‰æ‹©æœ€å¤§çš„æ¦‚ç‡ï¼Œå¹¶ä¸”ä½ å¯ä»¥ç«‹å³é€šè¿‡ Argm
    å‡½æ•°è·å¾—è¿™ä¸€ç»“æœã€‚Argmax å°†è¿”å›æ¯ä¸€è¡Œä¸­æœ€å¤§æ¦‚ç‡çš„ç´¢å¼•ã€‚
- en: which means that it will get a vector of integersï¼Œ So 0ã€‚ if the largest probability
    was in the zeroth positionï¼Œ1 in the first position and so onã€‚ So these are our
    class predictions indicating class 0ï¼Œ class 1 and so onã€‚ In factã€‚ if class predictions
    are all you wantã€‚ you can skip the softm step entirely because the largest logic
    will always be the largest probability as wellã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€å®ƒå°†å¾—åˆ°ä¸€ä¸ªæ•´æ•°å‘é‡ï¼Œå¦‚æœæœ€å¤§æ¦‚ç‡åœ¨ç¬¬é›¶ä½ç½®ï¼Œåˆ™ä¸º 0ï¼Œåœ¨ç¬¬ä¸€ä½ç½®åˆ™ä¸º 1ï¼Œä¾æ­¤ç±»æ¨ã€‚å› æ­¤è¿™äº›æ˜¯æˆ‘ä»¬çš„ç±»é¢„æµ‹ï¼Œè¡¨ç¤ºç±» 0ï¼Œç±» 1 ç­‰ã€‚å®é™…ä¸Šï¼Œå¦‚æœä½ åªæƒ³è¦ç±»é¢„æµ‹ï¼Œä½ å¯ä»¥å®Œå…¨è·³è¿‡
    softm æ­¥éª¤ï¼Œå› ä¸ºæœ€å¤§ logits æ€»æ˜¯æœ€å¤§æ¦‚ç‡ã€‚
- en: ğŸ˜Šï¼ŒSo if probabilities and class predictions are all you wantã€‚ then you've seen
    everything you need at this pointã€‚ but if you're interested in benchmarking your
    model or using it for researchã€‚ you might want to delve deeper into the results
    you get and one way to do that is to compute some metrics for the model's predictionsã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæ‰€ä»¥å¦‚æœä½ åªæƒ³è¦æ¦‚ç‡å’Œç±»é¢„æµ‹ï¼Œé‚£ä¹ˆæ­¤æ—¶ä½ å·²ç»çœ‹åˆ°äº†æ‰€æœ‰éœ€è¦çš„å†…å®¹ã€‚ä½†å¦‚æœä½ å¯¹åŸºå‡†æµ‹è¯•ä½ çš„æ¨¡å‹æˆ–ç”¨äºç ”ç©¶æ„Ÿå…´è¶£ï¼Œä½ å¯èƒ½æƒ³æ·±å…¥æ¢è®¨ä¸€ä¸‹ä½ å¾—åˆ°çš„ç»“æœï¼Œè®¡ç®—æ¨¡å‹é¢„æµ‹çš„ä¸€äº›æŒ‡æ ‡æ˜¯ä¸€ç§æ–¹æ³•ã€‚
- en: If you're following along with our dataset sets and fine tuning videosã€‚ we got
    our data from the MRRPC dataï¼Œ which is part of the blue benchmarkã€‚Each of the
    blue dataset setsï¼Œ as well as many other datasets in our datasets light hub has
    some predefined metricsã€‚ and we read we can load them easily with the dataset's
    load metric functionã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨è·Ÿéšæˆ‘ä»¬æ•°æ®é›†å’Œå¾®è°ƒè§†é¢‘ï¼Œæˆ‘ä»¬çš„æ•°æ®æ¥è‡ª MRRPC æ•°æ®é›†ï¼Œå®ƒæ˜¯ blue åŸºå‡†çš„ä¸€éƒ¨åˆ†ã€‚æ¯ä¸ª blue æ•°æ®é›†ï¼Œä»¥åŠæˆ‘ä»¬æ•°æ®é›†ç¯å¡”ä¸­çš„è®¸å¤šå…¶ä»–æ•°æ®é›†éƒ½æœ‰ä¸€äº›é¢„å®šä¹‰çš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ•°æ®é›†çš„åŠ è½½æŒ‡æ ‡å‡½æ•°è½»æ¾åŠ è½½å®ƒä»¬ã€‚
- en: For the M or PC dataset setï¼Œ the built in metrics are accuracyã€‚ which just measures
    the percentage of time the model's prediction was correctï¼Œ and the F1 scoreã€‚ which
    is a slightly more complex measure that measures how well the model trades off
    precision and recallã€‚To compute those metrics to benchmark our modelï¼Œ we just
    pass them the model's predictions under the ground truth labels and we get our
    results in a straightforward dip Python ditã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº M æˆ– PC æ•°æ®é›†ï¼Œå†…ç½®æŒ‡æ ‡æ˜¯å‡†ç¡®ç‡ï¼Œè¡¡é‡æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ—¶é—´ç™¾åˆ†æ¯”ï¼Œä»¥åŠ F1 åˆ†æ•°ï¼Œè¿™æ˜¯ä¸€ç§ç¨å¾®å¤æ‚çš„åº¦é‡ï¼Œè¡¡é‡æ¨¡å‹åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´çš„æƒè¡¡ã€‚ä¸ºäº†è®¡ç®—è¿™äº›æŒ‡æ ‡æ¥åŸºå‡†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€å°†æ¨¡å‹çš„é¢„æµ‹ä¸çœŸå®æ ‡ç­¾è¿›è¡Œå¯¹æ¯”ï¼Œä¾¿èƒ½ç®€å•åœ°å¾—åˆ°ç»“æœã€‚
- en: ğŸ˜Šï¼ŒIf you're familiar with Keisï¼Œ thoughï¼Œ you might notice that this is a slightly
    weird way to compute metrics because we're only computing metrics at the very
    end of trainingã€‚ but in Keisï¼Œ you have this built in ability to compute a wide
    range of metrics on the fly while you're trainingã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œä¸è¿‡å¦‚æœä½ ç†Ÿæ‚‰ Kerasï¼Œä½ å¯èƒ½ä¼šæ³¨æ„åˆ°ï¼Œè¿™æ˜¯ä¸€ç§è®¡ç®—æŒ‡æ ‡çš„ç¨å¾®å¥‡æ€ªçš„æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬åªåœ¨è®­ç»ƒç»“æŸæ—¶è®¡ç®—æŒ‡æ ‡ã€‚ä½†åœ¨ Keras ä¸­ï¼Œä½ å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®æ—¶è®¡ç®—å¤šç§æŒ‡æ ‡ã€‚
- en: which gives you a very useful insight into how training is goingã€‚So if you want
    to use built in metricsï¼Œ it's very straightforward and you use the standard careis
    approach againã€‚ you just pass a metric argument to the compile methodã€‚ As with
    things like loss and optimizerã€‚ you can specify the metrics you want by string
    or you can import the actual metric objects and pass specific arguments to themã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è®©ä½ å¯¹è®­ç»ƒè¿›å±•æœ‰éå¸¸æœ‰ç”¨çš„æ´å¯Ÿã€‚æ‰€ä»¥å¦‚æœä½ æƒ³ä½¿ç”¨å†…ç½®æŒ‡æ ‡ï¼Œè¿™éå¸¸ç®€å•ï¼Œä½ å†æ¬¡ä½¿ç”¨æ ‡å‡†çš„ Keras æ–¹æ³•ã€‚ä½ åªéœ€å°†æŒ‡æ ‡å‚æ•°ä¼ é€’ç»™ç¼–è¯‘æ–¹æ³•ã€‚ä¸æŸå¤±å’Œä¼˜åŒ–å™¨ç±»ä¼¼ï¼Œä½ å¯ä»¥é€šè¿‡å­—ç¬¦ä¸²æŒ‡å®šæ‰€éœ€çš„æŒ‡æ ‡ï¼Œæˆ–è€…å¯¼å…¥å®é™…çš„æŒ‡æ ‡å¯¹è±¡å¹¶ä¼ é€’å…·ä½“å‚æ•°ç»™å®ƒä»¬ã€‚
- en: but note that unlike loss and accuracyï¼Œ you have to supply metrics as a listã€‚
    even if there's only one metric you wantã€‚Once a model has been compiled with a
    metricã€‚ it will report that metric for trainingï¼Œ validation and predictionsã€‚Assuming
    there are labels passed to the predictionsï¼Œ you can even write your own metric
    classesã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¯·æ³¨æ„ï¼Œä¸æŸå¤±å’Œå‡†ç¡®ç‡ä¸åŒï¼Œä½ å¿…é¡»å°†æŒ‡æ ‡ä½œä¸ºåˆ—è¡¨æä¾›ã€‚å³ä½¿ä½ åªæƒ³è¦ä¸€ä¸ªæŒ‡æ ‡ã€‚ä¸€æ—¦æ¨¡å‹ç¼–è¯‘äº†ä¸€ä¸ªæŒ‡æ ‡ï¼Œå®ƒå°†æŠ¥å‘Šè¯¥æŒ‡æ ‡ç”¨äºè®­ç»ƒã€éªŒè¯å’Œé¢„æµ‹ã€‚å‡è®¾æœ‰æ ‡ç­¾ä¼ é€’ç»™é¢„æµ‹ï¼Œä½ ç”šè‡³å¯ä»¥ç¼–å†™è‡ªå·±çš„æŒ‡æ ‡ç±»ã€‚
- en: although this is a bit beyond the scope of this courseã€‚ I'll link to the relevant
    T F docs below because it can be very handy if you want a metric that isn't supported
    by default in Carisã€‚ such as the F1 scoreã€‚![](img/beadff4afadc3bf0228241989afe4e3f_1.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™æœ‰ç‚¹è¶…å‡ºæœ¬è¯¾ç¨‹çš„èŒƒå›´ï¼Œä½†æˆ‘ä¼šåœ¨ä¸‹é¢é“¾æ¥ç›¸å…³çš„ TensorFlow æ–‡æ¡£ï¼Œå› ä¸ºå¦‚æœä½ æƒ³è¦ä¸€ä¸ªåœ¨ Caris ä¸­ä¸å—æ”¯æŒçš„æŒ‡æ ‡ï¼ˆå¦‚ F1 åˆ†æ•°ï¼‰ï¼Œè¿™å°†éå¸¸æ–¹ä¾¿ã€‚![](img/beadff4afadc3bf0228241989afe4e3f_1.png)
- en: ã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ã€‚
- en: '![](img/beadff4afadc3bf0228241989afe4e3f_3.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/beadff4afadc3bf0228241989afe4e3f_3.png)'
