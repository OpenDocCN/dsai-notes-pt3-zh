# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Hugging Faceé€ŸæˆæŒ‡å—ï¼ä¸€éæå®šNLPä»»åŠ¡ä¸­æœ€å¸¸ç”¨çš„åŠŸèƒ½æ¿å—ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P4ï¼šL4- åŸºäºPyTorchçš„åˆ†ç±»å®ç° - ShowMeAI - BV1cF411v7kC

Let's do this manually and see how we can call our modelsã€‚ So in Pytorrchã€‚ when we do inferenceã€‚

 we also want to say with torch dot no graã€‚ So this will disable the gradient trackingã€‚

 I explain this in a lot of my tutorialsã€‚ So you can just have a look at them if you want to learn more about thisã€‚

 And then we can call our model by saying outputs equalsã€‚ And then we call the modelã€‚

 And then here we use two asteriskã€‚ and then we unpack this batchã€‚ So if you remember hereã€‚

 this is a dictionaryã€‚ And here basically with thisï¼Œ we just unpack these values in our dictionaryã€‚

 So for tens offlowï¼Œ you don't do thisã€‚ So you just pass in the batch like thisã€‚ But for pytorrchã€‚

 you have to unpack thisã€‚ And now we get the outputs of our modelã€‚ So let'sã€‚



![](img/6f843910cc38c033063518b8167635a3_1.png)

![](img/6f843910cc38c033063518b8167635a3_2.png)

![](img/6f843910cc38c033063518b8167635a3_3.png)

![](img/6f843910cc38c033063518b8167635a3_4.png)

![](img/6f843910cc38c033063518b8167635a3_5.png)

Print the outputsã€‚ And as you might know thisï¼Œ these are just the raw valuesã€‚

 So to get the actual probabilities and the predictionsï¼Œ we can apply the soft maxã€‚

 So let's say predictions equals torch or we also have this in F dot soft max and then here we say outputs dot logics and we want to do this along dimension equals1ã€‚

 and let's also print the predictions and then let's do one more thingã€‚

 So let's also get the labels labels equals and we just get this by taking the prediction with the the index with the highest probabilitiesã€‚

 So we get this by saying torch dot arc max and we can either put in the predictions orã€‚



![](img/6f843910cc38c033063518b8167635a3_7.png)

![](img/6f843910cc38c033063518b8167635a3_8.png)

![](img/6f843910cc38c033063518b8167635a3_9.png)

![](img/6f843910cc38c033063518b8167635a3_10.png)

![](img/6f843910cc38c033063518b8167635a3_11.png)

![](img/6f843910cc38c033063518b8167635a3_12.png)

We can put in the outputs and actually don't need thisã€‚

 but just for demonstration let's use the predictions and then again dimension equals one and then let's print the labels as well and now let's actually do one more thing So let's convert the labels by saying labels equals and then we use list comprehension and call model dot config dot I to label and then it needs the actual label ID and then we iterate so we say four label ID in labels to list and now what this does you will see this when we print this So we print the labels and now let's actuallyã€‚



![](img/6f843910cc38c033063518b8167635a3_14.png)

![](img/6f843910cc38c033063518b8167635a3_15.png)

![](img/6f843910cc38c033063518b8167635a3_16.png)

![](img/6f843910cc38c033063518b8167635a3_17.png)

![](img/6f843910cc38c033063518b8167635a3_18.png)

R this and see if this worksã€‚ Alrightï¼Œ so this worksã€‚ So as you can see hereï¼Œ we print the outputã€‚

 So these are our outputã€‚ This is a sequence classifier outputã€‚ And as you seeã€‚

 it has the launchets argumentã€‚ So that's why we used outputs dot launchetã€‚ğŸ˜Šã€‚



![](img/6f843910cc38c033063518b8167635a3_20.png)

![](img/6f843910cc38c033063518b8167635a3_21.png)

And then we get the actual probabilitiesã€‚ and then to get the labelsã€‚ we used Arcmã€‚

 So this is a tensza with the label1 and the label 0ã€‚

 And then we converted each label to the actual class name and then we get positive and negativeã€‚

 So by the wayï¼Œ this functionï¼Œ I think is only dedicated to a auto model for sequence classificationã€‚

 For exampleï¼Œ if we just use a auto modelï¼Œ Then I think it won't be availableã€‚

 So that's what these more concrete classes will do for youã€‚

 it gives you a little bit more functionality for the dedicated taskã€‚

 So we see that the loss is none in this caseã€‚ So if you also want to have a loss that we want to inspectã€‚

 Then we can give the loss or theã€‚ğŸ˜Šã€‚

![](img/6f843910cc38c033063518b8167635a3_23.png)

![](img/6f843910cc38c033063518b8167635a3_24.png)

![](img/6f843910cc38c033063518b8167635a3_25.png)

![](img/6f843910cc38c033063518b8167635a3_26.png)

Not the lossï¼Œ but the labels argument to our model that it knows how to compute the lossã€‚

 So we say labelsã€‚ and then we create a torch dot tenor by saying torch dot tenorã€‚

 And then as a listï¼Œ we give it the labels1 and 0ã€‚ And now let's run this againã€‚

 And then you should see that we should see a loss hereã€‚ And yetï¼Œ now here we see the lossã€‚

 And againï¼Œ this labels argument isï¼Œ I think special to this automod for sequence classificationã€‚



![](img/6f843910cc38c033063518b8167635a3_28.png)

![](img/6f843910cc38c033063518b8167635a3_29.png)

Soï¼Œ yeahï¼Œ this workedã€‚ And now if we have a careful look at the probabilitiesã€‚ So first of allã€‚

 we see we get label positive and negativeã€‚ and here for the first oneã€‚ This is the highest probabilã€‚

 So 9ã€‚997ã€‚ And here for the second oneï¼Œ this is the largest numberã€‚ So it took this oneã€‚

 And this is 5ã€‚30ã€‚ So if we compare them with the results that we got from our pipelineã€‚

 Then we see these are exactly the same numbersã€‚ So now you might see what's the difference between a pipeline and using tokenizer and model directlyã€‚

 So with the pipelineï¼Œ we only need two lines of codeã€‚ And then we actually get what we wantã€‚

 So we get the label and we get the score we are interested inã€‚ So this might be just fineï¼Œ butã€‚ğŸ˜Šã€‚

Yeah if you want to do it manually you can do it like I showed you and you will get the same results that you can then useã€‚

 So yeahï¼Œ that's how you can use a model and a tokenizer and yeah so using the model and the tokenizer will be important when you for example want to find tune in your model so I will show you roughly how to do this later but yeah so this is how you use model and tokenizer and let's just assume we did find tune in our modelã€‚



![](img/6f843910cc38c033063518b8167635a3_31.png)

![](img/6f843910cc38c033063518b8167635a3_32.png)

![](img/6f843910cc38c033063518b8167635a3_33.png)