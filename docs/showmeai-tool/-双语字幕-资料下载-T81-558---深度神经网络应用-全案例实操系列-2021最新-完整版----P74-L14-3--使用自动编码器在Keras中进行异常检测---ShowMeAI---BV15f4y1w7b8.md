# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P74ÔºöL14.3- ‰ΩøÁî®Ëá™Âä®ÁºñÁ†ÅÂô®Âú®Keras‰∏≠ËøõË°åÂºÇÂ∏∏Ê£ÄÊµã - ShowMeAI - BV15f4y1w7b8

HiÔºå this is Jeff Heaton„ÄÇ Wecom to applications of deep neural networks with Washington University„ÄÇ In this videoÔºå we're going to look at anomaly detection„ÄÇ How can you detect something that is not the way it should be„ÄÇThis has great application in computer securityÔºå but in other fields as well„ÄÇ

 We'll have a look at that in this video for the latest on my AI course and projects„ÄÇ click subscribe and the bell next to it to be notified of every new video„ÄÇ So now let's look at a use of autoencors„ÄÇ We're going to see how an autoencor can be applied to anomaly detection„ÄÇ I have a link to a couple of other tutorials on the internet that talk about various ways to do anomaly detection in Kes„ÄÇ

 Some of these might be useful to you„ÄÇ The approach that I'm using here is using an autoencor and looking at the error of the autoencor to determine if the data are unusual compared to the previous data that we've seen„ÄÇ We're going to make use of something called the KDd99 data set„ÄÇ

 We'll use this in two parts of this course„ÄÇ We'll use it to create an intrusion detection system in the next part„ÄÇ This is an older dataset at 2019„ÄÇüòä„ÄÇ![](img/231301739b63fc07324b14a0fb6dafd4_1.png)

is now going on 20 years old„ÄÇ So this is this is an older security data„ÄÇ It's got enough columns and whatnot that it is useful„ÄÇ I don't know that I would base anything on current research„ÄÇ meaning trying to create systems that detect current intrusion detections or current anomaly detection based on 20 year old data„ÄÇ

 but it is a good sort of hello world for securityÔºå and it's not trivial„ÄÇ It's a decent amount„ÄÇ It's not big data by any stretch of the imaginationÔºå but it's useful„ÄÇ So we'll see it here„ÄÇ It's good for examples„ÄÇ I wouldn't use it for current research„ÄÇ That means said I see papers published with it frequentlyÔºå but of of varying quality„ÄÇ

 I don't include it with the Github repository because it's decently large„ÄÇ but this command here will allow you to download it I'll go ahead and run this„ÄÇ it lets you know where you download it to fearing coab„ÄÇ You may need to put it on your„ÄÇriive somewhere I'll try to put specific instructions for coabab in here„ÄÇ So now we've got the data„ÄÇ

 And I displayed the first five rows„ÄÇ You can see what this looks like„ÄÇ This is network type data„ÄÇ This was created in a simulated environment for a competition K kind of an early tagle and doesn't show all the data„ÄÇ There's quite quite a bit of it„ÄÇ But what I am going to do is let's take this data and grouped by the outcome„ÄÇ So these are the outcomes buffer overflow FTP right guess password„ÄÇ

 Those are all different types of attacks that were simulated in this„ÄÇ Some of these are still attack types today„ÄÇ Some of these are probably pretty uncommon 20 years later„ÄÇ definitely be be aware of that normal is one we're particularly interested in because that means nothing is happening„ÄÇ So we're going to train it that the normal or well normal and the others are the anomalies„ÄÇ

 So we're going to train a neural network to detect„ÄÇThings that are not like normal„ÄÇ We're going to do this completely with a autoencoder„ÄÇ I create two functions to help us preproces thisÔºå one that encodes the z scores and one that encodes dummy variables„ÄÇ and this is my preprocessing form„ÄÇ You can see there's a lot of columns here„ÄÇ

 and I'm encoding basically in Z scores and dummies„ÄÇ Those are the only two transformation types that I'm doing So I'm keeping things relatively simple„ÄÇ and we drop any Ns„ÄÇ rows that have Ns„ÄÇ There's not really that many„ÄÇ and you can see the rows here„ÄÇ You can clearly see the effects of the Z scores„ÄÇ Now„ÄÇ

 what we're going to do is create a mask that has the normal and the attacks„ÄÇ that way we're able to segregate this data„ÄÇ We're going to drop the outcome because we're not really training on the outcome„ÄÇ that's essentially the target„ÄÇ reallyÔºå this is unsupervised learning once you get it separated into into these two groups„ÄÇ such as the nature of autoenderrs„ÄÇ We'll go ahead and run that„ÄÇ and you can see„ÄÇ

Normal counts about 97 k attacks are much more common in this dataset set„ÄÇ We separate it out so that we have the x for the attack and the x4 normal and then we're going to break this into a train test split we're breaking normal up is we're going to use normal to evaluate it„ÄÇ

 we're going to see if the normal looks like normal data to it9 anomaly Now we're going to use an autoencoder for this and we've talked about autoencors before„ÄÇ but just so these videos somewhat stand alone just to give you a quick overview of this„ÄÇ an autoencoder is essentially a neural network that has sort of a skinny hidden layer structure„ÄÇ the idea is you have a number of inputs now you're going to have all the Kdv99 inputs for this particular one you do have the bias neurons like you do in most networks and you have an output count equal to the input count„ÄÇ

 and what we're going to do is basically train the auto encoder so that„ÄÇIt is able to produce the same input as output Now that seems useless„ÄÇ but that is teaching it essentially to do feature reduction and simplification so it teaches it to take all of these inputs„ÄÇ these five inputs are 100 as we will have probably with KDD99 and represents them as just the two numbers being output to the hidden one and hidden2 Now all the weights leading into here are the encoding weights and these are the decoding weights so those are what it learns„ÄÇ

For how to decompress it HereÔºå we're going to build our autoencoder„ÄÇ We are going to have a little more complicated autoencoder than here„ÄÇ So we're going to have essentially 25Ôºå25Ôºå3„ÄÇ We still have this very thinning area but we have a little bit of sort of an hourglass„ÄÇ So it's almost like we have three hidden layers here to actually give us our compression capabilities„ÄÇ

 So I'm going to go ahead and run this„ÄÇ It will actually fit it„ÄÇ So it's going to take it a little bit to fit this neural network„ÄÇ I will fast forward this part„ÄÇ OkayÔºå it's trained just to explain sort of the theory of what's going on here„ÄÇ We trained this just on the normal data„ÄÇ and it is being trained un superupervised„ÄÇ

 So we're not even giving it the outcomes„ÄÇ There'd be no point to give it the outcomes because they're all normal„ÄÇ So the outcome would be the same„ÄÇ Since it's learning to compress to reduce the dimensions„ÄÇ the way the dimension reduction or compression in general works„ÄÇBy using patterns to represent common portions of the data„ÄÇ

 So it's simplifying it that will only work on cases where the data coming in is pretty similar to that„ÄÇ NowÔºå I'll give you a perfect example of a unintended anomaly detector„ÄÇ Now„ÄÇ cell phones are a lot better about this„ÄÇ but earlier cell phones„ÄÇ the way that they would compress is they knew a lot about the human voice that would normally go through there so they used the ranges that the human voice was normally in„ÄÇ

 they only compressed it and degraded quality in such a way so that it would not be annoying for human voices you'd still recognize the voice you would still be able to understand it„ÄÇ HoweverÔºå if you tried to play music through a cell phone or other other tones that the compression algorithms simply were not designed for„ÄÇ

 they would not be reproduced as well„ÄÇ there would be static and other distortions in that„ÄÇBecauseuse those different tones other than what the compression algorithms were built for are different„ÄÇ They're anomalies„ÄÇ and the cell phone detected the anomaly„ÄÇ Not rather designed for„ÄÇ It's just an exampleÔºå but it detected the anomaly by distorting it„ÄÇ

 That's what we're going to see here„ÄÇ We'll put data into the input and look at how similar the data is in the output to the input„ÄÇ because the autoencor is meant to be a straight pass throughÔºå but it compresses in the process„ÄÇ So it compresses and then expands„ÄÇ and we want to make sure that we're not seen too much distortion in that process„ÄÇ because if we areÔºå then the data coming in are probably different„ÄÇ

 then the data that this was originally trained for„ÄÇ Now we saw earlier in this course that you could use chaos statistics and other things to determine if your data have changed to the point that your neural network might need to be retrained„ÄÇ This is another great way to do this„ÄÇ Anomaly detection and detecting„ÄÇIf your data is sufficiently like the training data to know when to update your neural network are all very similar„ÄÇ

 let's go ahead and run it and do just that test„ÄÇ So let's run this cell now and we'll see the results„ÄÇ first I'm going to ask it to predict on the normal test and then I'm going to score it basically seeing how well these predictions lined up to the normal test that it was trained on„ÄÇ

 so we're literally seen„ÄÇ So if you look at it here„ÄÇ the two in sample now the ens samplele normal attack„ÄÇ this is essentially the data that it was trained on„ÄÇ So you have to take that with a green assault„ÄÇ these are normal data that were not part of the training set„ÄÇ

 but you can see that the RMSse for both of these two is right around 0„ÄÇ3 notice the RMSE is higher for attacks because they are anomalies and these are all pretty simple„ÄÇ We're doing predictions on the X normal test and then we evaluate the error based on the same thing„ÄÇ So we're seeing how well can this„ÄÇTo flow through the auto encoder with minimal distortion„ÄÇ

 the more distortion you seeÔºå the more likely it's an anomaly this content changes often so subscribe to the channel to stay up to date on this course and other topics and artificial intelligence„ÄÇ![](img/231301739b63fc07324b14a0fb6dafd4_3.png)