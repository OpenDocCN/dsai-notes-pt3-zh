# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P39ÔºöL7.3- ‰ΩøÁî®NVIDIAStyleGAN2- ADAPyTorchÂíåPython3ÁîüÊàê‰∫∫ËÑ∏ - ShowMeAI - BV15f4y1w7b8

Welcome to applications of deep neural networks with Washington University In this video„ÄÇ

 we're going to take a look at using NviDdia stylegan 2 AD for Ptorrch to get some really quality G face images„ÄÇ

 NowÔºå previously we saw that we could use our own technology our own custom built neural network to generate GNs„ÄÇ

 but the faces didn't look particularly good„ÄÇ It takes a lot of compute power and a lot of clever algorithms to really get high quality faces like you see with stylegan„ÄÇ

 So we're going to look at Stgan2 AD PtorrchÔºå which is really the latest technology in this area„ÄÇ



![](img/c3dd1d946bd070469333fc209ecae79b_1.png)

üéº„ÄÇOkayÔºå let's have a look at the code„ÄÇ So this is the module that there's a link to in the description„ÄÇ

 And I do put the note here„ÄÇ This module requires pytorch„ÄÇ

 So most of this course that I teach you is in Tensorflowkis„ÄÇ There's two parts„ÄÇ

 at least as of the recording of this video that I do make use of pytorrch„ÄÇ

 That is for reinforcement learning and also for stylegan„ÄÇ This is mainly just because„ÄÇ

These two very important libraries in this caseÔºå stylegan in the case of reinforcement learning„ÄÇ

 stable baselines have made the switch to Pytorch and really the neural network is kind of below everything that you're doing so you really almost don't notice it„ÄÇ

I am adding in more pytorch components as optional directions in this course so that you can see some of the same technology with Pytorch Pytorch is gaining a lot of momentum and it's a very especially in research„ÄÇ

 it's a very used technology are a framework for implementing deep learning all the underlying underpinnings are the same thing even the pickle files that I created with the old version of stylegan before NviIDdia made the switch to Pytorch the pickle files„ÄÇ

 the saved neural networks can just be loaded right into Pytorch So the underlying technologies are all the same essentially between these Now you'll see with stylegan2 AD there are all these very„ÄÇ

 very high quality faces that you can generate these are not real people they were generated by stylegan to ADA and by the way„ÄÇ

 the AD on the end that's augmented essentially you see it here with„ÄÇ

CaSo maybe there is just one picture of the cat in the original oneÔºå but as they train„ÄÇ

 they put a higher probability of augmentation happening and augmentation is one of the big breakthroughs in computer vision in terms of augmenting the images rotating them doing other distortions on them so that you have additional training data when training these Gs and I'll show you some of theganNs that I've trained from scratch in this class we're talking primarily just about generatingganNs from networks that are already trained to generate your owngans„ÄÇ

 you need high end GPU and I mean you can do with coab but coLab Pro really buts it takes a lot of compute most of the GNs that I generated were done on highend GPUs that I let run four days generating these but here you can see the images they look they all look quite realistic there are some some things that will tip you off that you're not looking at a real„ÄÇ

Image consider these at first glanceÔºå these look veryÔºå very realistic„ÄÇ

 But if you look at the backgroundÔºå that's usually a telltale sign that you're looking at a generated image„ÄÇ

 The background is kind of whimsical kind of mysterious„ÄÇ

 You're not quite sure what you're what you're looking at„ÄÇ Also„ÄÇ

 things that are not the face will not look as as good like earrings„ÄÇ

 It has a hard time with earrings„ÄÇ noticeice her earrings very rarely does a again create symmetric earrings„ÄÇ

Also the clothingÔºå I meanÔºå there's a buttonÔºå maybe there and I'm granted„ÄÇ

 I'm not the best at at always having my my clothes neat prem and proper if you've watched my videos„ÄÇ

But the collar will usually be a little disheveel for me„ÄÇ That would look entirely normal„ÄÇ

 I guess it does not know the difference between one face and two faces„ÄÇ

 So some of the training data as good as Ninvidia did in curating it and and paying people to remove certain things„ÄÇ

 Some of them have multiple faces„ÄÇ And you can see thisÔºå this guy has a twin that is appearing here„ÄÇ

 and it's extremely distorted„ÄÇ SimilarlylyÔºå hands„ÄÇ She has moved her hand up into the frame and it's not looking so good hats it's„ÄÇ

 it's hard to tell on hats„ÄÇ I meanÔºå hats can be very bizarreÔºå especially in high fashion„ÄÇ

 But usually hats will sort of blend into the hairÔºå like you're seeing hereÔºå not real„ÄÇ

 And her her neck is„ÄÇReallyÔºå really slender„ÄÇ So looking at thoseÔºå you can see another thing if„ÄÇ

I were to produce a video of just going through all kinds of random faces„ÄÇ

 you would notice that their eyes are always in exactly the same spot and by that„ÄÇ

 I mean the two eyes Now their face and head can move around a bit but the eyes are pegged to right here and the reason that is is more of a quirk in the way that NviDIdia train these is they used a feature detector to detect where the eyes were to crop so they centered each of the pictures around the eyes because you know people are in all kinds of weird positions and flickr and these pictures all came from flickr the training data so those are some of the things that you will notice as you work through these kinds of images Now I want to actually show you how to generate some of these so I'm going to go ahead and open this in collab because you've got to have a GPU to run this„ÄÇ

Now you could probably run this just fine without a GPU for training no way„ÄÇ

 but for generating them potentially is it it generates veryÔºå very quickly„ÄÇ

 but this is software from NVIDdia so they assume you have a GPU it's just the way it works and especially Pytorrch Pytorch„ÄÇ

 you kind of have to program it differently for a GPU versus a non GPU so a lot of Pytorrch that you will see code„ÄÇ

Does require a GPU just because the original researcher programmed it that way„ÄÇ

 actually need to update that I will remove that„ÄÇ We're actually not using Tensorflowlow 1„ÄÇ x„ÄÇ

 That was one of the problems with the old version before NviIDdia upgraded it they had used a very old version of Tensorflowlow„ÄÇ

 but now they are using the latest hightorrchÔºå at least as of the recording of this video„ÄÇ

So I'm going to go ahead and run that and I do trust myselfÔºå I created thisÔºå this notebook anyway„ÄÇ

 and I'm going to do this so that I do have access to my G drive„ÄÇYou may want to do this as well„ÄÇ

 because if you generate some of these imagesÔºå you you'll probably want to save them„ÄÇ

 So I'm putting that into there and it's no security breach„ÄÇ that I'm letting you see that code„ÄÇ

 This is all you have to do to really install it„ÄÇ You have to clone it„ÄÇ

 Piytorrch is installed by default in collab„ÄÇ You do also need ninja„ÄÇ

 Ninja that add in for Pytorrch that„ÄÇThis that NviDIdia made use of for this„ÄÇ Now„ÄÇ

 if you look at thatÔºå if you look at stug into8A PtorchÔºå you'll see the latest version here„ÄÇ

 we just cloned it right into our content on coabab is where you store all of your content that's temporary„ÄÇ

 This gets blown away as soon as you exit coab„ÄÇ So be aware of that that's why we have to get it back each time„ÄÇ

 Now I'm going to generate some images„ÄÇ And what we're going to do here is we're going to use pretrained faces code from NviDdia and we're going to generate seeds 6600 to 25„ÄÇ

 I'll explain that in a moment„ÄÇ So let's go ahead and run this„ÄÇ

 So these seeds these are just random number seeds that will cause the random number to generate consistently random numbers across„ÄÇ

 So the way again really works is you're generating the image from a 512 number vector and that 512 number vector„ÄÇ

Is giving you is each each of those numbers generates part of of the image„ÄÇ

 So if you change one of them just slightlyÔºå it's going to change the image ever so slightly„ÄÇ

 That is how you do these kind of transitional images and videos videos actually that you are watching here as as I go through this this part I'm going to show you how to create that a video just like that of your of your own Now this takes a moment for this to install everything that's needed„ÄÇ

 there's two now it's there's two kernels that Nvi uses to make this go faster„ÄÇ Actually„ÄÇ

 since they have custom kernelsÔºå this would not work on a CPU So I take I take that back what I said previously you would have to recode those kernels and that would not be fun So here we have the images they were generated they are now sitting in my content results and I could basically copy them to my G drive if I wanted to„ÄÇ

I'll show you another way toÔºå to get to those„ÄÇ So if you look at thatÔºå you can see them there„ÄÇ

 And now if we run this section„ÄÇ if you get this error hereÔºå you'll see basically that stylegan 2„ÄÇ

 not a directoryÔºå that just means that you didn't create the the folder on your G drive„ÄÇ

 I just corrected that„ÄÇ So if I run this„ÄÇ Now they copy there„ÄÇ So if I go to my G drive„ÄÇ

 you'll see that I have a project stylegan 2Ôºå let me refresh it„ÄÇ and you should see the„ÄÇ

The images that it generated there they all are„ÄÇ So you can click on these download them individually„ÄÇ

 These are the images that styleylegan generates„ÄÇ Now„ÄÇ

 I'm going to run this code which basically just sets up some code so that we can change those seeds into the actual vectors because we want to modify those 512 number vectors to„ÄÇ

 to do some of the things that we're going to do here„ÄÇ

 This is just quick function to display an imageÔºå and this is a function that I wrote that uses the NviDdia code to actually generate an image„ÄÇ

 NowÔºå some of the things that you'll that you'll„ÄÇüòä„ÄÇ



![](img/c3dd1d946bd070469333fc209ecae79b_3.png)

![](img/c3dd1d946bd070469333fc209ecae79b_4.png)

That you'll see in here too is we're dealing also with labels„ÄÇ

 I'm not going to really get into into labels in this video„ÄÇ

 I could certainly do a video on that usually you have the GN that you're using and we're using all pre-trainedganNs here has to have been trained for labels„ÄÇ

So for exampleÔºå say you trained yourgan on pictures of puppies and pictures of kittiesÔºå cats„ÄÇ

 if you don't put labels in thereÔºå it'll do quite goodÔºå it'll give you cats„ÄÇ

 I'll give you dogs and it'll give you cats that look kind of like dogs and vice versa you can label them so that you're telling it what class it is and then you can request when it's being generated to generate something more like a cat or like a dog„ÄÇ

 they have one actually in in the NviDdia stylegan page that is trained for this and it's generating very low resolution images from the from the C images set if I remember right„ÄÇ

 YeahÔºå the CR 10 one if you've worked with thisÔºå these are 10 these are„ÄÇ

Fairly low resolution in 32 by 32 images that was used earlier in machine learning of 10 different types of image for„ÄÇ

The data set so if you look at CRÔºå I forget what the 10 classes are for CR„ÄÇAirplanesÔºå automobiles„ÄÇ

 birdsÔºå catsÔºå deer dogsÔºå so this data set has these 10 classes all mixed in and to get the best results„ÄÇ

 you created a labeled G and you can pick which of these that you want to generate otherwise„ÄÇ

Gans are not too good without without that labeling of distinguishing between between different things„ÄÇ

 I'll show you an example of a very broadly trained GN when we get to that in„ÄÇThis lecture„ÄÇ

 you can pass in a truncation Pi vary that will change the quality that you're getting„ÄÇ

 you can also introduce noise„ÄÇ I keep it constant„ÄÇ If you introduce noise„ÄÇ

 you'll see the hair and other small things change small thing so it won't change into an entirely different person but it will look almost like the hair is blowing in the wind if you generate a bunch of if you set this to random instead constant and then the class index„ÄÇ

 I'm not really using that for this class so I won't have that there and you run that and then here you're going to pick which pre-trained one„ÄÇ

 I'm going to use the fishgan„ÄÇ this is one of my own„ÄÇ

 I trained this I trained the scan I use flickicker and got a whole bunch of fish images and this is basically just showing you how you will load a pretrainedgan„ÄÇ

It's just a pickle file„ÄÇI actually trained this one on the old Tensorflow version„ÄÇ

 so it shows you how compatible these areÔºå and I'm going to generate random fish from these seeds from 1000 to 1003„ÄÇ

 And there's three random fish„ÄÇ And you can see they look reallyÔºå prettyÔºå pretty good„ÄÇ

 If you go through a bunch of different ones„ÄÇ Some of them are definitely not as good as others„ÄÇ

 I meanÔºå this one has an eye here and a very long mouth„ÄÇ This does not have an eye„ÄÇ

 and this one has an eye hereÔºå but an unusual sort of noseÔºå but they lookÔºå they look reallyÔºå very„ÄÇüòä„ÄÇ

Very fishlike you can generate quite a bit more if you put additional seeds in there„ÄÇ

 And you can see some of these look reallyÔºå they really very nice fish„ÄÇ

 You can see these fish really look pretty good„ÄÇ This one looks quite goodÔºå quite good here„ÄÇ

 And that's a bit abstract as is that one„ÄÇ Now you can vary the latent vector„ÄÇ

 The latent vectors that 512 number vector that we're generating that actually creates these„ÄÇ So I„ÄÇüòä„ÄÇ

And basically going toÔºå I'm going to use the F F HQ„ÄÇ So I'm going to use actual faces„ÄÇ

 and I'm going to run this code here that I wrote„ÄÇ What this is doing is loading the„ÄÇ

Faces so that I I can use now I'm going to transition between seeds 1000Ôºå 1003 and 1001„ÄÇ

 Let me go ahead and run this just so that it's going„ÄÇ

And what this does is I'm using 100 steps to get between 1000Ôºå 1003Ôºå 1001Ôºå so these individual seeds„ÄÇ

 if you go from seed 1000 to 1001Ôºå it's going to be a completely different looking person„ÄÇ

 but if you take that big vector of 512 numbers that that seed generated„ÄÇ

Then you're going to get the more gradual results and right now I'm generating for each of these people„ÄÇ

 I'm transitionisting from 1000 to person 1003 back to person 1001„ÄÇ

And you can see it takes it a little while to generate this„ÄÇ

 This is generating just a whole bunch of frames as I go through and gradually just sort of skew from one vector to another„ÄÇ

 you can see I basically get my vector1 and2„ÄÇ I take the difference of the two vectors linear algebra style I divide that difference by the number of steps„ÄÇ

 and that's the value that I keep using each time to be my steps„ÄÇ So I'm adding that step vector„ÄÇ

 which is added to the original vector slowly takes it to to the second vector and this is almost done„ÄÇ

 let's go ahead and fast forward„ÄÇ AllrightÔºå it's done with that„ÄÇ

 and then I use something called FF Mpeg to convert all those frames back into a video and now we can download the video„ÄÇ

 It prepares it and I'm going to go ahead and open the video and there you can see the transition„ÄÇ

 I'm basically transitioning„ÄÇen those those key images that I picked and you're able to see those those people trans in in real time„ÄÇ

 Now you can train your owngans„ÄÇ These are somegans that I trained„ÄÇ There's the fishgan„ÄÇ

 I trained one on Minecraft as well science fiction pictures„ÄÇ

 and then I wanted to try something really crazy„ÄÇ I took just a bunch of random Christmas holiday videos„ÄÇ

 I meanÔºå there were lightsÔºå there were Christmas trees„ÄÇ There were„ÄÇ

Santa Claus is all kinds of stuff GNs don't do as well on that because there's nothing really to specialize on so it creates some really wild sort of Christmas E kind of nightmare before Christmas E images and I give you links to all my pretraingans there if you want to generate any of your own Minecraft images or other things„ÄÇ



![](img/c3dd1d946bd070469333fc209ecae79b_6.png)