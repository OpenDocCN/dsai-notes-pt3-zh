# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘Pytorch è¿›é˜¶å­¦ä¹ è®²åº§ï¼14ä½Facebookå·¥ç¨‹å¸ˆå¸¦ä½ è§£é” PyTorch çš„ç”Ÿäº§åº”ç”¨ä¸æŠ€æœ¯ç»†èŠ‚ ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼ - P9ï¼šL9- æœ€æ–°çš„ Profiler API å’Œæœ€ä½³å®è·µ - ShowMeAI - BV1ZZ4y1U7dg

ğŸ¼ã€‚![](img/8ecf516795c50978f573dce9c644f972_1.png)

Helloï¼Œ my name is Elliaï¼Œ I'm a software engineer at Facebook working on PyOch and in this presentation I'll talk about PyTch Pror and two new features that we recently addedã€‚![](img/8ecf516795c50978f573dce9c644f972_3.png)

So what is Pytoch Pror Pytoch includes an easy to use tool that allows you to measure runtime and other performance metrics of models operatorsã€‚In a simple exampleï¼Œ we first start with necessary module inputsã€‚ then we create Gsite 18 model and then as you can see we're on model inference insideã€‚By profile Cons managerã€‚Everything inside this Conx Manager is profiledï¼Œ and once you have finishedã€‚

 you can print out the resultsã€‚In this caseï¼Œ you will see a table with entries grouped by operator nameã€‚And with some rail metrics such as self and total CPU timeã€‚Profiller also has more features such as group by operator input shapesã€‚ support for both CPU and GPU operatorsï¼Œ custom labeled code rangersã€‚

 and saving the trace in Chrome JON formatã€‚For exampleã€‚ if you want to see the input shapes of the operatorsã€‚Just past record shapes true and grew by input shapesã€‚In this caseã€‚ we see multiple operators such as convolution with different input shapes as expectedã€‚

So let's check the check in memory usage feature that we recently addedã€‚In addition to measuring runtimeï¼Œ Pror can also be used to measure the amount of tensor memory used by the model's operatorsã€‚Just pass Pro memory trueï¼Œ and then you can sort by CPU or Quda memory usageã€‚In our exampleã€‚ we see that most of the memory was consumed by empty operatorã€‚

 which is not surprising because we use this operator to create new tensorsã€‚And also memory was consumed by Resize operatorï¼Œ which is used to change tensor sizeã€‚Based on the total CPU memory columnï¼Œ you can see that there are other operators that directly or indirectly call empty and resizeã€‚

![](img/8ecf516795c50978f573dce9c644f972_5.png)

But what if you want to know not only the operatorï¼Œ but where in the model the operator isï¼Ÿ



![](img/8ecf516795c50978f573dce9c644f972_7.png)

Stack traces are helpful in cases like thisã€‚So you can justã€‚Pass with stack2ã€‚ and then you can group by top and stack entriesã€‚And in our exampleã€‚ we see that there are two top Mkelian N convolution operatorsã€‚And in the source locationã€‚ we can see not only the location inside torch andM convolution modelã€‚

 but also two different coal sites in the original Resnet model scriptã€‚![](img/8ecf516795c50978f573dce9c644f972_9.png)

If you want to learn more about Profilr and see more examplesã€‚ please check out our Pror recipe on website Thank you very muchã€‚![](img/8ecf516795c50978f573dce9c644f972_11.png)

![](img/8ecf516795c50978f573dce9c644f972_12.png)