- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P13ï¼šL13-
    å‰é¦ˆç¥ç»ç½‘ç»œ - ShowMeAI - BV12m4y1S7ix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PyTorch æç®€å®æˆ˜æ•™ç¨‹ï¼å…¨ç¨‹ä»£ç è®²è§£ï¼Œåœ¨å®è·µä¸­æŒæ¡æ·±åº¦å­¦ä¹ &æ­å»ºå…¨pipelineï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P13ï¼šL13-
    å‰é¦ˆç¥ç»ç½‘ç»œ - ShowMeAI - BV12m4y1S7ix
- en: Hiï¼Œ everybodyã€‚ Welcome to a new Pytorch tutorialã€‚ Todayã€‚ we will implement our
    first multilayer neural network that can do diit classification based on the famous
    endlessnes data setã€‚ In this tutorialï¼Œ we put all the things from the last tutorials
    togetherã€‚ So we use the data loader to load our dataã€‚ We apply a transform to
    the dataã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œå¤§å®¶å¥½ã€‚æ¬¢è¿æ¥åˆ°æ–°çš„ Pytorch æ•™ç¨‹ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†å®ç°ç¬¬ä¸€ä¸ªå¤šå±‚ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œå¯ä»¥åŸºäºè‘—åçš„æ— å°½æ•°æ®é›†è¿›è¡Œæ•°å­—åˆ†ç±»ã€‚åœ¨è¿™ä¸ªæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸Šä¸€æœŸæ•™ç¨‹çš„æ‰€æœ‰å†…å®¹ç»“åˆåœ¨ä¸€èµ·ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®åŠ è½½å™¨æ¥åŠ è½½æˆ‘ä»¬çš„æ•°æ®ã€‚æˆ‘ä»¬å¯¹æ•°æ®åº”ç”¨å˜æ¢ã€‚
- en: Then we will implement our neural net with input layerï¼Œ hidden layer and output
    layerã€‚ and we will also apply activation functionsã€‚ Then we set up the loss and
    the optimizer and implement the training loop that can use batch trainingã€‚ and
    finallyï¼Œ we evaluate our model and calculate the accuracyã€‚ And additionallyã€‚ we
    will make sure that our whole code can also run on the GPu if we have GPU supportã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªè¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚çš„ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜å°†åº”ç”¨æ¿€æ´»å‡½æ•°ã€‚æ¥ç€æˆ‘ä»¬è®¾ç½®æŸå¤±å’Œä¼˜åŒ–å™¨ï¼Œå¹¶å®ç°å¯ä»¥ä½¿ç”¨æ‰¹é‡è®­ç»ƒçš„è®­ç»ƒå¾ªç¯ã€‚æœ€åï¼Œæˆ‘ä»¬è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹å¹¶è®¡ç®—å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†ç¡®ä¿æˆ‘ä»¬çš„æ•´ä¸ªä»£ç ä¹Ÿå¯ä»¥åœ¨æ”¯æŒ
    GPU çš„æƒ…å†µä¸‹è¿è¡Œã€‚
- en: So let's startã€‚ and first of allï¼Œ we import the things we needã€‚ So we import
    torchã€‚ Then we import torch dot and N as an Nã€‚ Then we import torchã€‚ğŸ˜Šï¼ŒVision for
    the data setsã€‚ and we import torch vision dot transforms as transformsã€‚And we
    also import Matpllip dot pipl S P L T to show you some data laterã€‚ And then first
    of allã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆè®©æˆ‘ä»¬å¼€å§‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥æˆ‘ä»¬éœ€è¦çš„ä¸œè¥¿ã€‚æ‰€ä»¥æˆ‘ä»¬å¯¼å…¥ torchã€‚ç„¶åæˆ‘ä»¬å¯¼å…¥ torch å’Œ N ä½œä¸º Nã€‚æ¥ç€æˆ‘ä»¬å¯¼å…¥ torchã€‚ğŸ˜Šï¼ŒVision
    ç”¨äºæ•°æ®é›†ã€‚æˆ‘ä»¬å¯¼å…¥ torch vision.transforms ä½œä¸º transformsã€‚æˆ‘ä»¬è¿˜å¯¼å…¥ Matpllip.pipl SPLT æ¥ç¨åæ˜¾ç¤ºä¸€äº›æ•°æ®ã€‚ç„¶åé¦–å…ˆã€‚
- en: we do the device configurationï¼Œ So device configã€‚ And for thisã€‚ we create a
    device by saying device equals torch dot deviceï¼Œ and this has the name Kudaã€‚ if
    we have GP supportã€‚ So ifã€‚Torch dot kuda dot is availableã€‚ And if it is not availableã€‚
    So elseã€‚ we call our device simply CPUã€‚ And then laterï¼Œ we have to push our tenzos
    to the deviceã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿›è¡Œè®¾å¤‡é…ç½®ï¼Œå› æ­¤è®¾å¤‡é…ç½®ã€‚è€Œå¯¹äºè¿™ä¸ªï¼Œæˆ‘ä»¬é€šè¿‡è¯´è®¾å¤‡ç­‰äº torch.dot.device æ¥åˆ›å»ºä¸€ä¸ªè®¾å¤‡ï¼Œå¹¶ä¸”å®ƒçš„åç§°æ˜¯ Kudaã€‚å¦‚æœæˆ‘ä»¬æœ‰
    GPU æ”¯æŒã€‚æ‰€ä»¥å¦‚æœ torch.kuda æ˜¯å¯ç”¨çš„ã€‚å¦‚æœä¸å¯ç”¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬åªç§°æˆ‘ä»¬çš„è®¾å¤‡ä¸º CPUã€‚ç„¶åç¨åï¼Œæˆ‘ä»¬éœ€è¦å°†æˆ‘ä»¬çš„å¼ é‡æ¨é€åˆ°è®¾å¤‡ä¸Šã€‚
- en: And this will guarantee that it will run on the GP if this is supportedã€‚Soï¼Œ
    yeahã€‚ so let's define some hyper parametersã€‚And here let's define the input sizeã€‚
    And this is 784ã€‚ And this is because later we see that our images have the size
    28 by 28ã€‚ And then we will flatten this array to be a 1 d Tenzoa and 28 times
    28 is 784ã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ä¿è¯å¦‚æœæ”¯æŒçš„è¯ï¼Œå®ƒå°†è¿è¡Œåœ¨ GPU ä¸Šã€‚é‚£ä¹ˆï¼Œæ˜¯çš„ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›è¶…å‚æ•°ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å®šä¹‰è¾“å…¥å¤§å°ï¼Œè¿™å°±æ˜¯ 784ã€‚è¿™æ˜¯å› ä¸ºç¨åæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„å›¾åƒå¤§å°ä¸º
    28x28ã€‚ç„¶åæˆ‘ä»¬å°†æŠŠè¿™ä¸ªæ•°ç»„å±•å¹³ä¸ºä¸€ç»´å¼ é‡ï¼Œ28 ä¹˜ 28 æ˜¯ 784ã€‚
- en: So that's why our input size has to be 784ã€‚ Then let's define a hidden sizeã€‚
    And here I will say this is 100ã€‚ You can also try our different sizes hereã€‚And
    the number of classesã€‚ And this has to be 10 because we have 10 different classesã€‚
    We have the digtits from 0 to 9ã€‚Then let's define the number of epochsã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬çš„è¾“å…¥å¤§å°å¿…é¡»æ˜¯ 784ã€‚ç„¶åæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªéšè—å±‚å¤§å°ã€‚åœ¨è¿™é‡Œæˆ‘ä¼šè¯´è¿™æ˜¯ 100ã€‚ä½ ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–ä¸åŒçš„å¤§å°ã€‚è¿˜æœ‰ç±»åˆ«çš„æ•°é‡ï¼Œè¿™å¿…é¡»æ˜¯
    10ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ 10 ä¸ªä¸åŒçš„ç±»åˆ«ã€‚æˆ‘ä»¬æœ‰æ•°å­— 0 åˆ° 9ã€‚ç„¶åæˆ‘ä»¬å®šä¹‰è®­ç»ƒçš„è½®æ•°ã€‚
- en: And here I will simply say two so that a training doesn't take too longã€‚ but
    you can set this to a higher valueã€‚Then we define the batch size hereï¼Œ and this
    isï¼Œ let's sayã€‚ 100ã€‚ And let's also define the learning rate here by saying learning
    rate equals 0ã€‚001ã€‚And now let's import the famous Amnes dataã€‚ So you can have
    that from the Pytorrch library by saying training data set equalsã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä¼šç®€å•è®¾ç½®ä¸º 2ï¼Œè¿™æ ·è®­ç»ƒä¸ä¼šèŠ±å¤ªé•¿æ—¶é—´ã€‚ä½†ä½ å¯ä»¥å°†å…¶è®¾ç½®ä¸ºæ›´é«˜çš„å€¼ã€‚ç„¶åæˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰æ‰¹é‡å¤§å°ï¼Œå‡è®¾ä¸º 100ã€‚æˆ‘ä»¬ä¹Ÿåœ¨è¿™é‡Œå®šä¹‰å­¦ä¹ ç‡ï¼Œè®¾ä¸ºå­¦ä¹ ç‡ç­‰äº
    0.001ã€‚ç°åœ¨è®©æˆ‘ä»¬å¯¼å…¥è‘—åçš„ Amnes æ•°æ®ã€‚ä½ å¯ä»¥é€šè¿‡è¯´è®­ç»ƒæ•°æ®é›†ç­‰äºä» Pytorch åº“ä¸­è·å–å®ƒã€‚
- en: And here we use torchvision dot data sets dot Amistã€‚![](img/ee06be2433f88c7e880533bc41c954a0_1.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ torchvision.data.datasets.Amistã€‚![](img/ee06be2433f88c7e880533bc41c954a0_1.png)
- en: And this will have to have the root where it has to be storedï¼Œ So rootã€‚![](img/ee06be2433f88c7e880533bc41c954a0_3.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†éœ€è¦æŒ‡å®šæ ¹ç›®å½•ï¼Œæ ¹ç›®å½•ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_3.png)
- en: Equalsï¼Œ and hereï¼Œ this should be in the same folderã€‚ So dotã€‚ And then it should
    create a folder called dataã€‚![](img/ee06be2433f88c7e880533bc41c954a0_5.png)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰äºï¼Œè¿™é‡Œåº”è¯¥åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚æ‰€ä»¥ .ï¼Œç„¶åå®ƒåº”è¯¥åˆ›å»ºä¸€ä¸ªåä¸º data çš„æ–‡ä»¶å¤¹ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_5.png)
- en: And then we say train equals trueã€‚ So this is our training data setã€‚![](img/ee06be2433f88c7e880533bc41c954a0_7.png)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¯´ train ç­‰äº trueã€‚è¿™æ˜¯æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_7.png)
- en: And then we say we apply a transform right awayã€‚ So we say transform equals
    transforms dot to tenzoã€‚ So we convert this to a tenzzo hereã€‚![](img/ee06be2433f88c7e880533bc41c954a0_9.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¯´ç«‹å³åº”ç”¨ä¸€ä¸ªå˜æ¢ã€‚æ‰€ä»¥æˆ‘ä»¬è¯´å˜æ¢ç­‰äº transforms.dot to tenzoã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªtenzzoã€‚![](img/ee06be2433f88c7e880533bc41c954a0_9.png)
- en: And then we also say download equals trueã€‚ So it should be downloaded if it
    is not available alreadyã€‚![](img/ee06be2433f88c7e880533bc41c954a0_11.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜è¯´ download ç­‰äº trueã€‚æ‰€ä»¥å¦‚æœå®ƒå°šä¸å¯ç”¨ï¼Œåˆ™åº”è¯¥ä¸‹è½½ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_11.png)
- en: Then let's copy this and do the same thing with our test data setã€‚ And here
    we have to say train equals falseã€‚ And we also don't have to download this any
    moreã€‚So now let's continue and create the data loaders by saying train loader
    equalsã€‚ And here we get this from torch dot u dot data dot data loaderã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¤åˆ¶è¿™ä¸ªï¼Œå¯¹æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®é›†åšåŒæ ·çš„äº‹æƒ…ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¿…é¡»è¯´ train ç­‰äº falseã€‚è€Œä¸”æˆ‘ä»¬ä¹Ÿä¸éœ€è¦å†ä¸‹è½½å®ƒã€‚ç°åœ¨è®©æˆ‘ä»¬ç»§ç»­ï¼Œé€šè¿‡è¯´ train
    loader ç­‰äºæ¥åˆ›å»ºæ•°æ®åŠ è½½å™¨ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä» torch.dot u.dot data.dot data loader è·å–è¿™ä¸ªã€‚
- en: and then it will have to have the data set by saying data set equalsã€‚ And here
    it gets the trainingã€‚![](img/ee06be2433f88c7e880533bc41c954a0_13.png)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¿…é¡»è®¾ç½®æ•°æ®é›†ï¼Œæ–¹æ³•æ˜¯è¯´æ•°æ®é›†ç­‰äºã€‚è¿™é‡Œè¿›è¡Œè®­ç»ƒã€‚![](img/ee06be2433f88c7e880533bc41c954a0_13.png)
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_14.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_14.png)'
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_15.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_15.png)'
- en: Data setï¼Œ a train data setã€‚ Then we have to specify the batch sizeã€‚ So this
    is equal to the batch sizeã€‚![](img/ee06be2433f88c7e880533bc41c954a0_17.png)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†ï¼Œä¸€ä¸ªè®­ç»ƒæ•°æ®é›†ã€‚ç„¶åæˆ‘ä»¬å¿…é¡»æŒ‡å®šæ‰¹é‡å¤§å°ã€‚æ‰€ä»¥è¿™ç­‰äºæ‰¹é‡å¤§å°ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_17.png)
- en: And then we also have to sayï¼Œ or we can say shuffle equals trueã€‚ So this is
    pretty good for trainingã€‚And then we copy this again and do the same thing for
    our test loaderã€‚ So test loader equals gets the test data setã€‚ And we can say
    shuffle equals false because it doesn't matter for the evaluationã€‚And now let's
    have a look at one batch of this data by saying examples equalsã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è¿˜è¦è¯´ï¼Œæˆ–è€…å¯ä»¥è¯´ shuffle ç­‰äº trueã€‚è¿™å¯¹è®­ç»ƒéå¸¸å¥½ã€‚ç„¶åæˆ‘ä»¬å†å¤åˆ¶è¿™ä¸ªï¼Œå¹¶å¯¹æˆ‘ä»¬çš„æµ‹è¯•åŠ è½½å™¨åšåŒæ ·çš„äº‹æƒ…ã€‚æ‰€ä»¥æµ‹è¯•åŠ è½½å™¨ç­‰äºè·å–æµ‹è¯•æ•°æ®é›†ã€‚æˆ‘ä»¬å¯ä»¥è¯´
    shuffle ç­‰äº falseï¼Œå› ä¸ºå¯¹äºè¯„ä¼°æ¥è¯´è¿™æ— å…³ç´§è¦ã€‚ç°åœ¨æˆ‘ä»¬é€šè¿‡è¯´ examples ç­‰äºæ¥çœ‹ä¸€ä¸‹è¿™ä¸€æ‰¹æ•°æ®ã€‚
- en: And then we convert it to a inner objectï¼Œ Iter of the train loaderã€‚ And then
    we can call the next method and unpack this into samples and into labels by saying
    this equals examples dot nextã€‚ And now let's print the size of theseã€‚ So let's
    print samples dot shapeã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºå†…éƒ¨å¯¹è±¡ï¼Œå³è®­ç»ƒåŠ è½½å™¨çš„è¿­ä»£å™¨ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥è°ƒç”¨ä¸‹ä¸€ä¸ªæ–¹æ³•ï¼Œå¹¶é€šè¿‡è¯´è¿™ç­‰äº examples.dot next å°†å…¶è§£åŒ…ä¸ºæ ·æœ¬å’Œæ ‡ç­¾ã€‚ç°åœ¨æˆ‘ä»¬æ‰“å°è¿™äº›çš„å¤§å°ã€‚æ‰€ä»¥è®©æˆ‘ä»¬æ‰“å°
    samples.dot shapeã€‚
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_19.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_19.png)'
- en: And alsoï¼Œ printï¼Œ print the label dot shapeã€‚![](img/ee06be2433f88c7e880533bc41c954a0_21.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ï¼Œæ‰“å°ï¼Œæ‰“å°æ ‡ç­¾çš„å½¢çŠ¶ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_21.png)
- en: And now let's save this and run thisã€‚ So let's call Python feet forward dot
    p to see if this is working so farã€‚ And yesï¼Œ here we have the size of the samplesã€‚
    So this is 100 by 1 by 28 by 28ã€‚ And this is because our batch size is 100ã€‚ So
    we have 100 samples in our batchã€‚ Then the one is because we only have one channelã€‚
    So we don't have any colored channels hereã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬ä¿å­˜å¹¶è¿è¡Œè¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬è°ƒç”¨ Python feet forward.dot pï¼Œçœ‹çœ‹åˆ°ç›®å‰ä¸ºæ­¢æ˜¯å¦æœ‰æ•ˆã€‚æ˜¯çš„ï¼Œè¿™é‡Œæˆ‘ä»¬æœ‰æ ·æœ¬çš„å¤§å°ã€‚æ‰€ä»¥è¿™æ˜¯
    100 ä¹˜ 1 ä¹˜ 28 ä¹˜ 28ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬çš„æ‰¹é‡å¤§å°ä¸º 100ã€‚å› æ­¤æˆ‘ä»¬åœ¨æ‰¹æ¬¡ä¸­æœ‰ 100 ä¸ªæ ·æœ¬ã€‚ç„¶åçš„ 1 æ˜¯å› ä¸ºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªé€šé“ã€‚å› æ­¤æˆ‘ä»¬è¿™é‡Œæ²¡æœ‰ä»»ä½•å½©è‰²é€šé“ã€‚
- en: So only one channelã€‚ And this is our actual image arrayã€‚ So 28 by 28ï¼Œ as I said
    in the beginningã€‚And our labels is only a tenor of size 100ã€‚ So for each class
    labelï¼Œ we have one value hereã€‚So yeahã€‚ this is our some example dataã€‚ And now
    let's also plot this here to see how this is lookingã€‚ So for I in range 6 and
    here we use matplotlipï¼Œ So I call PLT dot subplot of the with two rows and three
    columns and the index I plus1 and then I can say PLt do I showã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åªæœ‰ä¸€ä¸ªé€šé“ã€‚è¿™æ˜¯æˆ‘ä»¬çš„å®é™…å›¾åƒæ•°ç»„ã€‚æ‰€ä»¥æ˜¯28ä¹˜28ï¼Œæ­£å¦‚æˆ‘ä¸€å¼€å§‹æ‰€è¯´çš„ã€‚æˆ‘ä»¬çš„æ ‡ç­¾åªæœ‰ä¸€ä¸ªå¤§å°ä¸º100çš„å¼ é‡ã€‚æ‰€ä»¥å¯¹äºæ¯ä¸ªç±»åˆ«æ ‡ç­¾ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæœ‰ä¸€ä¸ªå€¼ã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„ä¸€äº›ç¤ºä¾‹æ•°æ®ã€‚ç°åœ¨æˆ‘ä»¬ä¹Ÿåœ¨è¿™é‡Œç»˜åˆ¶ä¸€ä¸‹ï¼Œçœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚æ‰€ä»¥å¯¹äº
    I åœ¨èŒƒå›´ 6 ä¸­ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ matplotlipï¼Œå› æ­¤æˆ‘è°ƒç”¨ PLT.dot subplotï¼Œè®¾ç½®ä¸¤è¡Œä¸‰åˆ—ï¼Œç´¢å¼•ä¸º I åŠ  1ï¼Œç„¶åæˆ‘å¯ä»¥è¯´ PLT.showã€‚
- en: and here I want to show the actual dataï¼Œ So samples of I and then of0 because
    we want to access the first channel and then I will also give this a column map
    So C map equals grayã€‚![](img/ee06be2433f88c7e880533bc41c954a0_23.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å±•ç¤ºå®é™…æ•°æ®ï¼Œæ‰€ä»¥æ ·æœ¬ä¸º Iï¼Œç„¶åä¸º 0ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è®¿é—®ç¬¬ä¸€ä¸ªé€šé“ï¼Œç„¶åæˆ‘è¿˜ä¼šç»™å®ƒä¸€ä¸ªé¢œè‰²æ˜ å°„ã€‚å› æ­¤ cmap ç­‰äº grayã€‚![](img/ee06be2433f88c7e880533bc41c954a0_23.png)
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_24.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_24.png)'
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_25.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_25.png)'
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_26.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_26.png)'
- en: And then I say Pï¼Œ LT dot showã€‚And let's save thisï¼Œ and run this againã€‚![](img/ee06be2433f88c7e880533bc41c954a0_28.png)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘è¯´Pï¼ŒLT.showã€‚è®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªï¼Œå¹¶å†æ¬¡è¿è¡Œå®ƒã€‚![](img/ee06be2433f88c7e880533bc41c954a0_28.png)
- en: And here we have a look at the dataã€‚ So these are some example handwritten digtitsã€‚
    and now we want to classify these digtitsã€‚ So for thisã€‚ we want to set up a fully
    connected neural network with one hidden layerã€‚ So let's do thisã€‚![](img/ee06be2433f88c7e880533bc41c954a0_30.png)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹æ•°æ®ã€‚è¿™äº›æ˜¯ä¸€äº›æ‰‹å†™æ•°å­—çš„ç¤ºä¾‹ã€‚ç°åœ¨æˆ‘ä»¬æƒ³å¯¹è¿™äº›æ•°å­—è¿›è¡Œåˆ†ç±»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æƒ³å»ºç«‹ä¸€ä¸ªå…·æœ‰ä¸€ä¸ªéšè—å±‚çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼![](img/ee06be2433f88c7e880533bc41c954a0_30.png)
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_31.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_31.png)'
- en: So let's comment this out againã€‚And now let's create a class neural netã€‚ And
    this has to be derived from an and dot moduleã€‚ And now we have to define the in
    it and the forward methodã€‚ So the in it methodã€‚ So this will selfã€‚ And then it
    will has to have the input sizeï¼Œ then the hidden sizeï¼Œ and then the output sizeã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬å†æ¬¡æ³¨é‡Šæ‰è¿™ä¸€ç‚¹ã€‚ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç¥ç»ç½‘ç»œç±»ã€‚è¿™å¿…é¡»ä»ä¸€ä¸ªæ¨¡å—ä¸­æ´¾ç”Ÿã€‚ç°åœ¨æˆ‘ä»¬å¿…é¡»å®šä¹‰åˆå§‹åŒ–å’Œå‰å‘æ–¹æ³•ã€‚å› æ­¤ï¼Œåˆå§‹åŒ–æ–¹æ³•å°†åŒ…å«selfã€‚ç„¶åå®ƒå¿…é¡»æœ‰è¾“å…¥å¤§å°ã€éšè—å¤§å°å’Œè¾“å‡ºå¤§å°ã€‚
- en: So the output size is the number of classesã€‚ And here firstï¼Œ we want to call
    the super in itã€‚ So super of neural net and self and dot in itã€‚Selfã€‚Dotã€‚In itã€‚And
    then we create our layersã€‚ So firstï¼Œ we want to have a linear layer by saying
    self dot L 1 equals Nn dot linearã€‚ And this will have has the input size as input
    and the output size is the hidden sizeã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¾“å‡ºå¤§å°æ˜¯ç±»åˆ«çš„æ•°é‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æƒ³è°ƒç”¨superçš„åˆå§‹åŒ–ã€‚å› æ­¤super of neural netå’Œselfçš„åˆå§‹åŒ–ã€‚self.dot.initã€‚ç„¶åæˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„å±‚ã€‚å› æ­¤ï¼Œé¦–å…ˆæˆ‘ä»¬æƒ³é€šè¿‡è¯´self.dot.L1ç­‰äºNn.dot.linearæ¥æ‹¥æœ‰ä¸€ä¸ªçº¿æ€§å±‚ã€‚è¿™å°†æŠŠè¾“å…¥å¤§å°ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºå¤§å°æ˜¯éšè—å¤§å°ã€‚
- en: Then after the first layerï¼Œ we want to apply a activation functionã€‚ And here
    I simply use the famous relu activationã€‚ So self dot relu equals N N dot realluã€‚![](img/ee06be2433f88c7e880533bc41c954a0_33.png)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨ç¬¬ä¸€å±‚ä¹‹åï¼Œæˆ‘ä»¬æƒ³åº”ç”¨æ¿€æ´»å‡½æ•°ã€‚è¿™é‡Œæˆ‘ç®€å•åœ°ä½¿ç”¨è‘—åçš„reluæ¿€æ´»å‡½æ•°ã€‚å› æ­¤self.dot.reluç­‰äºN N.dot.reluã€‚![](img/ee06be2433f88c7e880533bc41c954a0_33.png)
- en: And then at the endï¼Œ we have another linear layerã€‚ So self dot L 2 equalsã€‚![](img/ee06be2433f88c7e880533bc41c954a0_35.png)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æœ€åï¼Œæˆ‘ä»¬æœ‰å¦ä¸€ä¸ªçº¿æ€§å±‚ã€‚å› æ­¤self.dot.L2ç­‰äºã€‚![](img/ee06be2433f88c7e880533bc41c954a0_35.png)
- en: Nï¼Œ N dot linearã€‚ Now we have to be carefulã€‚ So the input size here is the hidden
    sizeã€‚ and the output size is the number of classesã€‚![](img/ee06be2433f88c7e880533bc41c954a0_37.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Nï¼ŒN ç‚¹çº¿æ€§ã€‚ç°åœ¨æˆ‘ä»¬å¿…é¡»å°å¿ƒã€‚å› æ­¤ï¼Œè¾“å…¥å¤§å°æ˜¯éšè—å¤§å°ï¼Œè¾“å‡ºå¤§å°æ˜¯ç±»åˆ«çš„æ•°é‡ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_37.png)
- en: And now let's define the forward methodã€‚ So this will have self and one sample
    Xã€‚ and now we apply all these layersã€‚ So we say out equalsã€‚ and now we use the
    first layer L1ã€‚ which gets the sample X and then the next out is self dot relu
    now use the activationation functionã€‚ which will get the previous output hereï¼Œ
    and the last out equals self dot L2 outã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å®šä¹‰å‰å‘æ–¹æ³•ã€‚è¿™å°†åŒ…å«selfå’Œä¸€ä¸ªæ ·æœ¬Xã€‚ç°åœ¨æˆ‘ä»¬åº”ç”¨æ‰€æœ‰è¿™äº›å±‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´è¾“å‡ºç­‰äºã€‚ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ç¬¬ä¸€å±‚L1ï¼Œå®ƒè·å–æ ·æœ¬Xï¼Œç„¶åä¸‹ä¸€ä¸ªè¾“å‡ºæ˜¯self.dot.reluï¼Œä½¿ç”¨æ¿€æ´»å‡½æ•°ã€‚æœ€åçš„è¾“å‡ºç­‰äºself.dot.L2è¾“å‡ºã€‚
- en: So this will apply the second linear function and now we have to be careful
    again because here at the endã€‚ we don't want an activation functionã€‚ So we don't
    apply the softm here as usual in multiclass classification problems because in
    a secondã€‚ we will see that we will use the cross entropy lossï¼Œ and this will applyã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åº”ç”¨ç¬¬äºŒä¸ªçº¿æ€§å‡½æ•°ï¼Œç°åœ¨æˆ‘ä»¬å¿…é¡»å†æ¬¡å°å¿ƒï¼Œå› ä¸ºåœ¨æœ€åï¼Œæˆ‘ä»¬ä¸æƒ³è¦æ¿€æ´»å‡½æ•°ã€‚å› æ­¤æˆ‘ä»¬ä¸ä¼šåƒé€šå¸¸åœ¨å¤šç±»åˆ†ç±»é—®é¢˜ä¸­é‚£æ ·åº”ç”¨softmaxï¼Œå› ä¸ºç¨åæˆ‘ä»¬å°†çœ‹åˆ°æˆ‘ä»¬å°†ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œè€Œè¿™å°†ä¼šåº”ç”¨ã€‚
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_39.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_39.png)'
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_40.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_40.png)'
- en: Ply the soft max for usã€‚ So no soft max hereã€‚ So we simply say return outã€‚ So
    this is our whole modelã€‚ And then we can create it here by saying model equals
    neural netã€‚And this will get the input sizeï¼Œ then the hidden size and the number
    of classesã€‚Soï¼Œ yeahã€‚ now we have the modelsã€‚ So now let's come create the loss
    and the optrã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæˆ‘ä»¬åº”ç”¨è½¯æœ€å¤§å€¼ã€‚å› æ­¤è¿™é‡Œæ²¡æœ‰è½¯æœ€å¤§å€¼ã€‚æˆ‘ä»¬ç®€å•åœ°è¿”å›è¾“å‡ºã€‚è¿™æ˜¯æˆ‘ä»¬çš„æ•´ä¸ªæ¨¡å‹ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´æ¨¡å‹ç­‰äºç¥ç»ç½‘ç»œæ¥åˆ›å»ºå®ƒã€‚è¿™å°†è·å–è¾“å…¥å¤§å°ï¼Œç„¶åæ˜¯éšè—å¤§å°å’Œç±»åˆ«æ•°é‡ã€‚æ‰€ä»¥ï¼Œæ²¡é”™ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†æ¨¡å‹ã€‚ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºæŸå¤±å’Œä¼˜åŒ–å™¨ã€‚
- en: So here we say criterion equals N N dot cross entropy lossã€‚ And this will apply
    the soft marks for usã€‚ So that's why we don't want this hereã€‚ So be very careful
    about thisã€‚And now let's create our optimizer as well by saying tor optimizer
    equals torch dot optim dotã€‚å—¯ã€‚Nowï¼Œ let's use the atom optimizer hereã€‚ And this
    has to get the parametersã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘ä»¬è¯´criterionç­‰äºN N.dot.cross_entropy_lossã€‚è¿™å°†ä¸ºæˆ‘ä»¬åº”ç”¨softmaxã€‚å› æ­¤æˆ‘ä»¬ä¸æƒ³åœ¨è¿™é‡Œä½¿ç”¨è¿™ä¸ªã€‚æ‰€ä»¥å¯¹æ­¤è¦éå¸¸å°å¿ƒã€‚ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡è¯´tor.optimizerç­‰äºtorch.optimæ¥åˆ›å»ºæˆ‘ä»¬çš„ä¼˜åŒ–å™¨ã€‚å—¯ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨Adamä¼˜åŒ–å™¨ã€‚å¹¶ä¸”è¿™å¿…é¡»è·å–å‚æ•°ã€‚
- en: And here we can use model dot parametersã€‚ And it also has to get the learning
    rateã€‚ L R equals learning rateã€‚![](img/ee06be2433f88c7e880533bc41c954a0_42.png)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¨¡å‹çš„ç‚¹å‚æ•°ã€‚å¹¶ä¸”å®ƒè¿˜éœ€è¦è·å–å­¦ä¹ ç‡ã€‚å­¦ä¹ ç‡ç­‰äºå­¦ä¹ ç‡ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_42.png)
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_43.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_43.png)'
- en: Now we have the loss and the optimizerã€‚ and now we can do our training loopã€‚
    So training loop nowã€‚And for thisï¼Œ let's first define the number of total stepsã€‚
    So n total steps equalsã€‚ And this is the length of the training loaderã€‚So now
    we can do the typical loopã€‚ So we say four epoch in rangeã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æŸå¤±å’Œä¼˜åŒ–å™¨ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›è¡Œè®­ç»ƒå¾ªç¯ã€‚å› æ­¤ï¼Œç°åœ¨æ˜¯è®­ç»ƒå¾ªç¯ã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬é¦–å…ˆå®šä¹‰æ€»æ­¥éª¤æ•°ã€‚å› æ­¤ï¼Œæ€»æ­¥éª¤æ•°ç­‰äºã€‚è¿™æ˜¯è®­ç»ƒåŠ è½½å™¨çš„é•¿åº¦ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›è¡Œå…¸å‹çš„å¾ªç¯ã€‚æˆ‘ä»¬è¯´å››ä¸ªå‘¨æœŸåœ¨èŒƒå›´å†…ã€‚
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_45.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_45.png)'
- en: Noum epochsã€‚![](img/ee06be2433f88c7e880533bc41c954a0_47.png)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Noum epochsã€‚![](img/ee06be2433f88c7e880533bc41c954a0_47.png)
- en: And so this will loop over the epochsã€‚ And now we loop over all the batchesã€‚
    So here we say for Iã€‚ And then againï¼Œ we unpack thisã€‚ So we say imagesï¼Œ images
    and labelsã€‚And then we iterate overã€‚ enumerate over our train loaderã€‚ So the enumerate
    function will give us the actual index and then the data and the data here is
    the tuple of the images and the labels and now we have to reshape our images firstã€‚
    because if we have a look at the shapeï¼Œ then we see that this is 100 by1 by 28
    by 28ã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¿™å°†å¾ªç¯éå†å‘¨æœŸã€‚ç°åœ¨æˆ‘ä»¬å¾ªç¯éå†æ‰€æœ‰æ‰¹æ¬¡ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬è¯´for Iã€‚ç„¶åå†æ¬¡ï¼Œæˆ‘ä»¬è§£åŒ…è¿™ä¸ªã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¯´imagesï¼Œimageså’Œlabelsã€‚ç„¶åæˆ‘ä»¬éå†enumerateæˆ‘ä»¬çš„è®­ç»ƒåŠ è½½å™¨ã€‚å› æ­¤ï¼Œenumerateå‡½æ•°å°†ç»™æˆ‘ä»¬å®é™…çš„ç´¢å¼•ï¼Œç„¶åæ˜¯æ•°æ®ï¼Œè€Œè¿™é‡Œçš„æ•°æ®æ˜¯å›¾åƒå’Œæ ‡ç­¾çš„å…ƒç»„ï¼Œç°åœ¨æˆ‘ä»¬å¿…é¡»é¦–å…ˆé‡å¡‘æˆ‘ä»¬çš„å›¾åƒã€‚å› ä¸ºå¦‚æœæˆ‘ä»¬çœ‹çœ‹å½¢çŠ¶ï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™æ˜¯100ä¹˜1ä¹˜28ä¹˜28ã€‚
- en: as I showed you in the beginningã€‚ And now we set our input size is 784ã€‚ So our
    image tensor needs the size100 by and 784 is second dimensionã€‚![](img/ee06be2433f88c7e880533bc41c954a0_49.png)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘åœ¨å¼€å§‹æ—¶æ‰€ç¤ºã€‚ç°åœ¨æˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„è¾“å…¥å¤§å°ä¸º784ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„å›¾åƒå¼ é‡éœ€è¦çš„å¤§å°æ˜¯100ä¹˜784ï¼Œè¿™æ˜¯ç¬¬äºŒä¸ªç»´åº¦ã€‚![](img/ee06be2433f88c7e880533bc41c954a0_49.png)
- en: So the number of batches firstã€‚Soï¼Œ let's reshape ourã€‚Our tenor firstã€‚ So we
    can do this by saying images equals images dot reshapeã€‚ And here we put in -1
    as the first dimensionã€‚ So then Tsor can find out this automatically for usã€‚And
    here as second dimensionï¼Œ we want to have 28 by 28ã€‚ And then we also call2 deviceã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥é¦–å…ˆæ˜¯æ‰¹æ¬¡æ•°ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬é‡å¡‘æˆ‘ä»¬çš„å¼ é‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´imagesç­‰äºimages.dot.reshapeæ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†-1æ”¾åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ã€‚å› æ­¤ï¼ŒTsorå¯ä»¥ä¸ºæˆ‘ä»¬è‡ªåŠ¨æ‰¾åˆ°è¿™ä¸ªã€‚åœ¨è¿™é‡Œä½œä¸ºç¬¬äºŒä¸ªç»´åº¦ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰28ä¹˜28ã€‚ç„¶åæˆ‘ä»¬ä¹Ÿè°ƒç”¨è®¾å¤‡ã€‚
- en: We will push this to the GP Uï¼Œ if it is availableã€‚And we have also have to push
    it to theã€‚ push the labels to the deviceã€‚ So labels equals labels toã€‚Deevviceã€‚And
    now let's do the forward passã€‚ So firstï¼Œ we do the forward passã€‚ and afterwardsã€‚
    the backward passã€‚So the forward passï¼Œ we simply say outputs equals modelã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯ç”¨ï¼Œæˆ‘ä»¬å°†æŠŠè¿™ä¸ªæ¨é€åˆ°GPUã€‚æˆ‘ä»¬è¿˜å¿…é¡»å°†æ ‡ç­¾æ¨é€åˆ°è®¾å¤‡ã€‚å› æ­¤ï¼Œlabelsç­‰äºlabels.to.deviceã€‚ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œå‰å‘ä¼ æ’­ã€‚å› æ­¤ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬è¿›è¡Œå‰å‘ä¼ æ’­ã€‚ç„¶åæ˜¯åå‘ä¼ æ’­ã€‚æ‰€ä»¥å‰å‘ä¼ æ’­ï¼Œæˆ‘ä»¬ç®€å•åœ°è¯´outputsç­‰äºmodelã€‚
- en: And this will get the imagesã€‚ and then we calculate the loss by saying lossã€‚Equalsã€‚
    and then here we call our criterionã€‚ And this will get the predicted outputs and
    the actual labelsã€‚ So this is the forward passã€‚ And then in the backward passã€‚
    the first thing we want to do is call optr dot0 gra to empty the values in the
    gradient attributeã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†è·å–å›¾åƒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡è¯´lossç­‰äºæ¥è®¡ç®—æŸå¤±ã€‚ç„¶ååœ¨è¿™é‡Œæˆ‘ä»¬è°ƒç”¨æˆ‘ä»¬çš„æ ‡å‡†ã€‚è¿™æ ·å°†è·å–é¢„æµ‹è¾“å‡ºå’Œå®é™…æ ‡ç­¾ã€‚è¿™æ˜¯å‰å‘ä¼ æ’­ã€‚ç„¶ååœ¨åå‘ä¼ æ’­ä¸­ï¼Œé¦–å…ˆæˆ‘ä»¬è¦åšçš„æ˜¯è°ƒç”¨optr.dot0
    graä»¥æ¸…ç©ºæ¢¯åº¦å±æ€§ä¸­çš„å€¼ã€‚
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_51.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_51.png)'
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_52.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_52.png)'
- en: And then we can do the next step by saying lost dot backwardã€‚ So this will do
    the back propagationã€‚ And now we can call optr dot stepã€‚ So this will do an update
    step and update the parameters for usã€‚And nowï¼Œ let's also print someã€‚Print the
    lossã€‚ So let's sayï¼Œ if I plus1ã€‚Moulular 100 equals equals 0ã€‚ So every 100th stepï¼Œ
    we want to print some informationã€‚ So let's print the current epochã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯´â€œä¸¢å¤±çš„ç‚¹å‘åâ€æ¥è¿›è¡Œä¸‹ä¸€æ­¥ã€‚è¿™å°†è¿›è¡Œåå‘ä¼ æ’­ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è°ƒç”¨`optr dot step`ã€‚è¿™æ ·å°†æ‰§è¡Œæ›´æ–°æ­¥éª¤å¹¶ä¸ºæˆ‘ä»¬æ›´æ–°å‚æ•°ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚æ‰“å°æŸå¤±ã€‚å‡è®¾ï¼Œå¦‚æœæˆ‘åŠ 1ã€‚`Moulular
    100`ç­‰äº0ã€‚é‚£ä¹ˆæ¯100æ­¥ï¼Œæˆ‘ä»¬æƒ³æ‰“å°ä¸€äº›ä¿¡æ¯ã€‚è®©æˆ‘ä»¬æ‰“å°å½“å‰çš„çºªå…ƒã€‚
- en: So by saying this is epoch epoch plus  oneã€‚ And then we want to print all theã€‚Epochã€‚
    So number of epochsã€‚ Then let's also print the current step by saying stepã€‚ And
    this is I plus1ã€‚ And then the total number of steps by saying n total stepsã€‚And
    we also want to print the loss by saying loss equals loss dot itemã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¯´è¿™æ˜¯`epoch epoch plus one`ã€‚ç„¶åæˆ‘ä»¬æƒ³æ‰“å°æ‰€æœ‰çš„çºªå…ƒã€‚å³çºªå…ƒæ•°é‡ã€‚ç„¶åè®©æˆ‘ä»¬ä¹Ÿé€šè¿‡è¯´`step`æ‰“å°å½“å‰æ­¥éª¤ã€‚è¿™æ˜¯`I plus1`ã€‚ç„¶åé€šè¿‡è¯´`n
    total steps`æ‰“å°æ€»æ­¥éª¤æ•°é‡ã€‚æˆ‘ä»¬è¿˜æƒ³é€šè¿‡è¯´`loss equals loss dot item`æ‰“å°æŸå¤±ã€‚
- en: And let's also say we only want to print four decimal valuesã€‚Soï¼Œ yeahã€‚ now we
    are done with the trainingã€‚ So this is the whole training loopã€‚ And now let's
    do the testing and the evaluationã€‚And for thisã€‚ we don't want to compute the gradients
    for all the steps we doã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ï¼Œè®©æˆ‘ä»¬è¯´æˆ‘ä»¬åªæƒ³æ‰“å°å››ä½å°æ•°ã€‚å› æ­¤ï¼Œæ˜¯çš„ã€‚ç°åœ¨æˆ‘ä»¬å®Œæˆäº†è®­ç»ƒã€‚è¿™æ˜¯æ•´ä¸ªè®­ç»ƒå¾ªç¯ã€‚ç°åœ¨è®©æˆ‘ä»¬è¿›è¡Œæµ‹è¯•å’Œè¯„ä¼°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¸æƒ³è®¡ç®—æ‰€æœ‰æ­¥éª¤çš„æ¢¯åº¦ã€‚
- en: So we want to wrap this in a with torch dot no gra statementã€‚And then firstã€‚
    we say the number of correct predictions equals 0 and the number of samples equals
    0 in the beginningã€‚ And then we loop over all the batches in the test samplesã€‚
    So we say four images and labels inã€‚And here we can simply say in test loaderã€‚
    and then againï¼Œ we have to reshape thisã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›å°†å…¶åŒ…è£…åœ¨`with torch dot no gra`è¯­å¥ä¸­ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¯´æ­£ç¡®é¢„æµ‹çš„æ•°é‡ç­‰äº0ï¼Œæ ·æœ¬æ•°é‡ç­‰äº0ã€‚åœ¨å¼€å§‹æ—¶ã€‚ç„¶åæˆ‘ä»¬éå†æ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸­çš„æ‰¹æ¬¡ã€‚æˆ‘ä»¬è¯´â€œå¯¹äºå›¾åƒå’Œæ ‡ç­¾â€ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¯´åœ¨`test
    loader`ä¸­ã€‚ç„¶åæˆ‘ä»¬éœ€è¦é‡æ–°è°ƒæ•´å½¢çŠ¶ã€‚
- en: So like we did hereã€‚ So images and labelsï¼Œ we want to reshape this and put it
    and push it to the deviceã€‚Andã€‚Then let's callã€‚ let's calculate the predictions
    by saying outputs equals modelsã€‚ So this is our trained model nowï¼Œ and this will
    get the test images hereã€‚And then let's get the actual predictions by saying underscore
    and then predictions equals torch dot maxã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„é‚£æ ·ã€‚å›¾åƒå’Œæ ‡ç­¾ï¼Œæˆ‘ä»¬æƒ³è°ƒæ•´å½¢çŠ¶å¹¶å°†å…¶æ¨é€åˆ°è®¾å¤‡ä¸Šã€‚ç„¶åè®©æˆ‘ä»¬è°ƒç”¨ã€‚é€šè¿‡è¯´`outputs equals models`æ¥è®¡ç®—é¢„æµ‹ã€‚è¿™æ˜¯æˆ‘ä»¬ç°åœ¨è®­ç»ƒçš„æ¨¡å‹ï¼Œè¿™å°†è·å–æµ‹è¯•å›¾åƒã€‚ç„¶åè®©æˆ‘ä»¬é€šè¿‡è¯´ä¸‹åˆ’çº¿å’Œ`predictions
    equals torch dot max`æ¥è·å–å®é™…é¢„æµ‹ã€‚
- en: Of the outputs and along the dimensionï¼Œ along the number oneã€‚So the torch up
    max function will return the value and the indexã€‚ So we are interested in the
    actual indexã€‚ So this is the class labelã€‚ So that's why we don't need the first
    actual valueã€‚So these are our predictionsã€‚ And nowã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå’Œæ²¿ç€ç»´åº¦ï¼Œæ²¿ç€ç»´åº¦1ã€‚å› æ­¤ï¼Œ`torch up max`å‡½æ•°å°†è¿”å›å€¼å’Œç´¢å¼•ã€‚æˆ‘ä»¬å¯¹å®é™…ç´¢å¼•æ„Ÿå…´è¶£ã€‚æ‰€ä»¥è¿™å°±æ˜¯ç±»åˆ«æ ‡ç­¾ã€‚å› æ­¤æˆ‘ä»¬ä¸éœ€è¦ç¬¬ä¸€ä¸ªå®é™…å€¼ã€‚è¿™äº›å°±æ˜¯æˆ‘ä»¬çš„é¢„æµ‹ã€‚ç°åœ¨ã€‚
- en: let's say the number of samples plus equalsã€‚ And here we say labels dot shape
    0ã€‚ So this will give us the number of samples and the currentã€‚Batchã€‚So should
    be 100ã€‚ And then we say the number of correctã€‚ So the correct predictions equalsã€‚
    And here we can say predictions equals equals the actual labels and then dot sum
    and then dot itemã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æ ·æœ¬æ•°é‡åŠ 1ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬è¯´`labels dot shape 0`ã€‚è¿™å°†ç»™æˆ‘ä»¬æ ·æœ¬çš„æ•°é‡å’Œå½“å‰æ‰¹æ¬¡ã€‚æ‰€ä»¥åº”è¯¥æ˜¯100ã€‚ç„¶åæˆ‘ä»¬è¯´æ­£ç¡®çš„æ•°é‡ã€‚é‚£ä¹ˆæ­£ç¡®é¢„æµ‹çš„æ•°é‡ç­‰äºã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥è¯´`predictions
    equals equals the actual labels`ï¼Œç„¶å`dot sum`å’Œ`dot item`ã€‚
- en: So for each correct predictionï¼Œ we will add plus oneã€‚And thenï¼Œ of courseã€‚ we
    have to say plus equals the number of correctã€‚Valuesã€‚ And then when we are done
    with the loopã€‚ we calculate the total accuracy by saying a equals 100 times the
    number of correctã€‚And predictions divided by the number of samplesã€‚ So this is
    the accuracy in percentã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªæ­£ç¡®çš„é¢„æµ‹ï¼Œæˆ‘ä»¬å°†åŠ 1ã€‚ç„¶åï¼Œå½“ç„¶ï¼Œæˆ‘ä»¬å¿…é¡»è¯´`plus equals the number of correct`ã€‚ç„¶åå½“æˆ‘ä»¬å®Œæˆå¾ªç¯æ—¶ã€‚é€šè¿‡è¯´`a
    equals 100 times the number of correct`æ¥è®¡ç®—æ€»å‡†ç¡®ç‡ã€‚é¢„æµ‹é™¤ä»¥æ ·æœ¬æ•°é‡ã€‚è¿™æ˜¯ä»¥ç™¾åˆ†æ¯”è¡¨ç¤ºçš„å‡†ç¡®ç‡ã€‚
- en: And now let's print thisã€‚ So printã€‚å—¯ã€‚And we want to print accuracy equalsã€‚ And
    here we simply say aã€‚ And then we are doneã€‚ So now let's save this and clear this
    and let's run this and hope that everything is workingã€‚So now our training startsï¼Œ
    and we should see that the loss should be increased with every stepã€‚ Sometimes
    it will also increase againã€‚ But finallyï¼Œ it should get lower and lowerã€‚Andã€‚Nowã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ‰“å°è¿™ä¸ªã€‚æ‰€ä»¥æ‰“å°ã€‚å—¯ã€‚æˆ‘ä»¬æƒ³æ‰“å°å‡†ç¡®ç‡ç­‰äºã€‚ç„¶åæˆ‘ä»¬ç®€å•åœ°è¯´aã€‚è¿™æ ·æˆ‘ä»¬å°±å®Œæˆäº†ã€‚ç°åœ¨è®©æˆ‘ä»¬ä¿å­˜è¿™ä¸ªï¼Œæ¸…ç©ºå®ƒï¼Œç„¶åè¿è¡Œï¼Œå¸Œæœ›ä¸€åˆ‡æ­£å¸¸ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çš„è®­ç»ƒå¼€å§‹äº†ï¼Œæˆ‘ä»¬åº”è¯¥çœ‹åˆ°æŸå¤±åœ¨æ¯ä¸€æ­¥éƒ½åº”è¯¥å¢åŠ ã€‚æœ‰æ—¶å®ƒä¹Ÿä¼šå†æ¬¡å¢åŠ ã€‚ä½†æœ€åï¼Œå®ƒåº”è¯¥è¶Šæ¥è¶Šä½ã€‚ç°åœ¨ã€‚
- en: it should be done and testing is very fastã€‚ So now we see that the accuracy
    is 94ã€‚9ã€‚ So it workedã€‚ Our first feet forward model is doneã€‚ And yeahï¼Œ I hope
    you understood everythingã€‚ And you enjoyed thisã€‚ If you like itï¼Œ please subscribe
    to the channel and see you next timeï¼Œ byeã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åº”è¯¥å®Œæˆï¼Œå¹¶ä¸”æµ‹è¯•éå¸¸å¿«ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çœ‹åˆ°å‡†ç¡®ç‡æ˜¯94.9ã€‚æ‰€ä»¥å®ƒæˆåŠŸäº†ã€‚æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå‰é¦ˆæ¨¡å‹å®Œæˆäº†ã€‚å¸Œæœ›ä½ èƒ½ç†è§£è¿™ä¸€åˆ‡ï¼Œå¹¶ä¸”äº«å—è¿™ä¸ªè¿‡ç¨‹ã€‚å¦‚æœä½ å–œæ¬¢ï¼Œè¯·è®¢é˜…é¢‘é“ï¼Œæˆ‘ä»¬ä¸‹æ¬¡è§ï¼Œæ‹œã€‚
- en: '![](img/ee06be2433f88c7e880533bc41c954a0_54.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee06be2433f88c7e880533bc41c954a0_54.png)'
