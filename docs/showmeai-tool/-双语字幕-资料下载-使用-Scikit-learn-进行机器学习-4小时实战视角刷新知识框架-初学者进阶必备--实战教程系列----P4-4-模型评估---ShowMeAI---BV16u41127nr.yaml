- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„Äë‰ΩøÁî® Scikit-learn ËøõË°åÊú∫Âô®Â≠¶‰π†Ôºå4Â∞èÊó∂ÂÆûÊàòËßÜËßíÂà∑Êñ∞Áü•ËØÜÊ°ÜÊû∂ÔºåÂàùÂ≠¶ËÄÖËøõÈò∂ÂøÖÂ§áÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P4Ôºö4ÔºâÊ®°ÂûãËØÑ‰º∞
    - ShowMeAI - BV16u41127nr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We talked about our squared scoreÔºå we talked about being an absolute squared
    or error„ÄÇAnd that's different ways we can measure our errors„ÄÇ The next thing I'
    to talk about is if our score is trying to mediocre like 0„ÄÇ2 out of one„ÄÇ how do
    I know that that's actually grow and it's not just chance„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_1.png)'
  prefs: []
  type: TYPE_IMG
- en: And the answer is that what we'll do is we'll take our original data here„ÄÇAnd
    we'll score it with our model„ÄÇ We're able to train a model that the x's and the
    y's and just score„ÄÇ And so let's say my score is 0„ÄÇ8Ôºå which is not that dread„ÄÇWhat
    I'll do is I'll shuffle around the data„ÄÇ so I know that there's no relationship
    between the y's and x's„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: rightÔºå so what I'll do is I'll take this y column and just randomly shuffle
    it„ÄÇ And the word for that is up permateated„ÄÇ As I get this permutated version
    of this columnÔºå right„ÄÇ you can see that„ÄÇFor exampleÔºå5 used to be the first number
    and now now5 this down here So I just kind to randomly shuffle that thing and
    then I train the model on it„ÄÇ trying to look for the relationship between the
    y's and x's„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and there should be no relationship obviously right because I just shuffle everything
    around but I can try to train a model and get a score on it And so if I see that
    when I'm basically training a model on garbage data„ÄÇ if I get a better score then
    then I did originally„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: well that probably means that I didn't have any sort of significant result originally
    so I probably didn't have any sort of meaningful model And that's the rough idea
    an actual implementation of what this function here is going to do for us is it's
    going to shuffle around the data like this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And it's going to get a score and it's try to shuffle it again and it's going
    to get a score it's trying to get something like know 100 or 100 different scores
    based on these shuffled data„ÄÇ and then based on that we can estimate and really
    see this score over here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: is it kind of unusually good or does it feel like this could fit in with the
    garbage data and based on that we we can basically say„ÄÇ well heyÔºå do I trust this
    model or that So let me head over here back the notebookÔºü
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_3.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_4.png)'
  prefs: []
  type: TYPE_IMG
- en: And„ÄÇ And so maybe I'm just trying to make some notes in here just so it's clear
    to what we're doing„ÄÇ So this part was about metrics„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_6.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_7.png)'
  prefs: []
  type: TYPE_IMG
- en: And then this part is going to be about permutation testing„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_9.png)
  prefs: []
  type: TYPE_NORMAL
- en: And so let me I actually already imported itÔºå which is great so all these things
    that are kind of related to model evaluation and they're under this thing called
    model selection because what we'll often do is have a few different models and
    we're trying to have different tools to say well what is the model that we think
    is best and we're going recommend to people So I see that I have this permutation
    test score„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_11.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_12.png)'
  prefs: []
  type: TYPE_IMG
- en: And I might paste this right hereÔºå and I can see that I need three things„ÄÇAt
    a minimum„ÄÇ I have to have my modelÔºå which is just L R„ÄÇü§ßI have to have my own„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_14.png)
  prefs: []
  type: TYPE_NORMAL
- en: My x values and then finally my y values„ÄÇ And so the way I'm going be doing
    this here is since„ÄÇÂóØ„ÄÇSince here I have this testF and and„ÄÇFor both my x and my
    Y I'm just going to grab these right„ÄÇ so this was my x right here based on the
    seven day averageÔºå I want to predict this right here„ÄÇAnd I'm going grab this„ÄÇAnd
    it turns out that this is going to return a tuple of length  three„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so I'm just going run thatÔºå that'll take a moment„ÄÇ and the three things in that
    tuple are going to be the score of my module model originally„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_16.png)
  prefs: []
  type: TYPE_NORMAL
- en: It will be you know some other scores when I have maybe I'll just tell the garbage
    scores since I'm peruting the data„ÄÇ I'm not expecting to have any patternÔºå there's
    going to be a bunch of those„ÄÇAnd then there's going to be something called a P
    value„ÄÇAnd what the P value is telling me is„ÄÇWell„ÄÇ what is the probability that
    a score this good„ÄÇWould be generated by a system that's generating all these garbage
    scores„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: RightÔºå and so if this is really smallÔºå then I can seeÔºå well„ÄÇ this is actually
    much better than my garbage cores„ÄÇ And so I actually have a significant result„ÄÇ
    So since these are the three things I was returning„ÄÇüòäÔºåRight I know that T is a
    tuple„ÄÇ I just put that here and it'll automatically unpack those things for me„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: so I'll take a look at this„ÄÇAnd then I get a score for my model„ÄÇ and then I
    can have my garbage cores here„ÄÇ I see there's a whole bunch of them„ÄÇ If I want
    to„ÄÇ I can put those in a series„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_18.png)
  prefs: []
  type: TYPE_NORMAL
- en: And then I could do a histogram of those„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_20.png)
  prefs: []
  type: TYPE_NORMAL
- en: And I can see thatÔºå you knowÔºå they're actually around0 or lessÔºå rightÔºå all of
    these„ÄÇ And this was around 0 point„ÄÇ0Ôºå9Ôºå which is„ÄÇActually„ÄÇPtty far over here„ÄÇ
    So it seems like we're pretty far away from these garbage scores„ÄÇ And therefore„ÄÇ
    this P value is going to be pretty small„ÄÇ It seems like whatever process„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_22.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_23.png)'
  prefs: []
  type: TYPE_IMG
- en: I'm using to get all these garbage cores is not likely to have a score this
    good„ÄÇ so I will take this as a meaningful result„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_25.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_26.png)'
  prefs: []
  type: TYPE_IMG
- en: Let me head back here for another ideaÔºå so how do we deal with the noise„ÄÇ we
    saw that when I kept doing it a bunch of times I was getting different scores
    and for that we're going to use as something called a cross Val„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_28.png)
  prefs: []
  type: TYPE_NORMAL
- en: Cross validation score„ÄÇ And And the way it' will work is I'm going splitlin
    my data instead of just having these train and tasks„ÄÇ Im going split into four
    pieces„ÄÇAnd then each of those four pieces are going to take turns being the test
    data„ÄÇ so maybe first I'll train my data on these rowsÔºå and then I'll test it on
    this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_30.png)'
  prefs: []
  type: TYPE_IMG
- en: And then my model will getÔºå let's sayÔºå a score of 0„ÄÇ2„ÄÇAnd then I'll take a different
    chunk of the dataÔºå and each of these are called a fold of the data„ÄÇ by the wayÔºå
    and so I'll train on those firstÔºå second and fourth pieces„ÄÇSo I get a model and
    then I evaluate on that test data set and let's say this time I get a little bit
    luckier and it's 0„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 3Ôºå do it againÔºå 01 again 0„ÄÇ2Ôºå and then I could take the average of these and
    that would be a more stable measurement of kind of how well my model does us not
    as„ÄÇIts not kind of as vulnerable to what happens to go on the test or training
    data set is all the data at some point is in the test data„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Or the training data„ÄÇ So I going head over here and and do thisÔºå rightÔºå So this
    is called„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_32.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_33.png)'
  prefs: []
  type: TYPE_IMG
- en: Cross validation„ÄÇAnd let me call this thing so cross validation score„ÄÇAnd what
    I have to pass in hereÔºå I pass in my estimator„ÄÇAnd then I have to pass in my x
    values and then my y values„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_35.png)
  prefs: []
  type: TYPE_NORMAL
- en: RightÔºå so let me grab those things„ÄÇSo it's actuallyÔºå I guess identical to this
    right here„ÄÇ so I me grab my modelÔºå my x values and my y values„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_37.png)
  prefs: []
  type: TYPE_NORMAL
- en: And at this timeÔºå I just want to do it on all my data„ÄÇ So can I say data frame„ÄÇAnd
    then data frame and actually really what is kind of the best practices is just
    to that of the training data„ÄÇAnd so I'm going to do that and then I get all these
    scores back right and the reason is that there were five folds by default so I
    can say you know in this picture right there's four here I see well by default
    there were five that's why I got five scores I can say I want 10 of them and I'd
    be fine I these 10 scores back and these times look like those numbers we were
    seeing earlier like 0„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 27 0„ÄÇ17 another 0„ÄÇ27 is 0„ÄÇ304 right if I head back here and I just kind of run
    this thing a few times those are the kinds of numbers I'm getting out of it as
    I randomly split my train of my test„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_39.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_40.png)'
  prefs: []
  type: TYPE_IMG
- en: So why is this useful while I can have my scores here„ÄÇAnd I can say a couple
    things I can say scores I mean„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_42.png)
  prefs: []
  type: TYPE_NORMAL
- en: And so I can see while on averageÔºå R2 square R squared score is going to be
    0„ÄÇ21„ÄÇ but I could also get some sense of the varianceÔºå and that'll tell me how
    sensitive I am to what data happens to end off in the test or training data set„ÄÇ
    and that probably depends how much on how much I have some outliers and how much
    outliers to„ÄÇWhat happens with the scoringÔºüOkayÔºå so this will be the way we'll
    generally do it„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And so one last thingÔºå rightÔºå when I was„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_44.png)
  prefs: []
  type: TYPE_NORMAL
- en: Showing this picture here rightÔºå I kind of saidÔºå wellÔºå heyÔºå I have all my data„ÄÇ
    then I just split it up into train and test„ÄÇ![](img/685f8a9a43bae69c2b04fb232b54014c_46.png)
  prefs: []
  type: TYPE_NORMAL
- en: Why didn I use all my data here and the reason is that„ÄÇIs that even though that
    would have been fine to do in this example what you're often going to be doing
    is you're going be trying to do a few different models and what you'll want to
    do is you'll want to do cross validation on each of the models and then you'll
    see well what one has the best score on average and you say well that one's the
    winner that's one where you use in the future„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And so there's this risk when you're doing thatÔºå let's say I evaluate 20 models„ÄÇAnd
    pick the best one„ÄÇ the best one probably did a little bit better than it should„ÄÇ
    right„ÄÇ if I do 20 modelsÔºå some will just by luckÔºå do better and some will do worse„ÄÇ
    And so even though that's the right process to pick the best model I shouldn't
    throw brag about this cross validation score because it wasn't like I was just
    doing one model as in here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I doing many models„ÄÇ So what I would do is I look at this cross validation score
    across each of my models„ÄÇ pick the best oneÔºå And then finally what I go back and
    actually do my real test data which is still hanging out here„ÄÇ and then that's
    what I would report is the kind of accuracy of my favorite chosen model„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_48.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_49.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/685f8a9a43bae69c2b04fb232b54014c_50.png)'
  prefs: []
  type: TYPE_IMG
