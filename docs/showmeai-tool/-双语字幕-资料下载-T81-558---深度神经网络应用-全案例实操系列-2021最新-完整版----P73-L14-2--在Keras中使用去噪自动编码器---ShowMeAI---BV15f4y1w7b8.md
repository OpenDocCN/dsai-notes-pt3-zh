# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P73ï¼šL14.2- åœ¨Kerasä¸­ä½¿ç”¨å»å™ªè‡ªåŠ¨ç¼–ç å™¨ - ShowMeAI - BV15f4y1w7b8

Hiï¼Œ this is Jeff Heatonï¼Œ welcome to Application of Deep neural Network with Washington Universityã€‚

In this videoï¼Œ we're going to look at auto encoders or specifically auto dennoine encodersã€‚

 These are auto encoders that can be used to rebuildã€‚

Data that's been obscured by noise for the latest on my AI course and projectsã€‚

 click subscribe and the bell next to it to be notified of every new videoã€‚ So for auto encodersã€‚

 we're going to first look at function approximationã€‚

 We've been doing function approximation before its' pretty much regressionã€‚

 but I am going to define a function to do the approximation to chart itã€‚ğŸ˜Šã€‚



![](img/be628560dda59c2203db5dbe7b4cf58a_1.png)

And now I am going to create a simple neural network that has essentially the sine functionã€‚

 We're going to try to predict the sine waveã€‚ If I run thatï¼Œ it is going to trainã€‚

 and we're essentially just training it on on the sine function being passed in how fast forward this while it trainsã€‚

 Allrightï¼Œ it's completeã€‚ You can see it it's tracking it really pretty wellã€‚

 Now I put some noise into the expected just so that it's not exactly perfectã€‚

 You can also see the actual in the predicted that prettyï¼Œ pretty closeï¼Œ reallyï¼Œ Nextã€‚

 we'll do multi output regressionã€‚ Multi outputput regression is critical for a autoencoderã€‚

 Essentiallyï¼Œ what's happening is you have your inputs just like before input 1 input 2 input 3 input 4ã€‚

 but you can have multiple output neuronsã€‚ Now for an autoencoderã€‚

 usually the number of inputs matches the number of outputsã€‚ Let's just go ahead and run this oneã€‚ğŸ˜Šã€‚

Which is attempting to train it on both the sine and the cosine simultaneouslyã€‚

 I'll go in fast forward this until it gets doneã€‚ Okayï¼Œ it completes the RMS E looks pretty goodã€‚

 You can see some of the predictions and expectedã€‚ So it is learning sine and cosineã€‚

 at the same timeã€‚ which isï¼Œ which is amazingã€‚ Wellï¼Œ not reallyã€‚ I meanï¼Œ neural networksã€‚

 multiple output regressioning is really a pretty common thingã€‚ You don't see it a lotï¼Œ thoughã€‚

 in other types of machine learning modelã€‚ Nowï¼Œ let's do a simple autoencoderã€‚

 And notice the autoencoderï¼Œ we have five inputs we have five outputsã€‚

 Whatever number of inputs you have should be the same number of outputsã€‚

 And what we're essentially doingã€‚ This is kind of fascinatingã€‚ This is what autoencors doã€‚

 We're putting inã€‚ğŸ˜Šï¼ŒEssentiallyï¼Œ random numbers hereã€‚And we are training itã€‚

 expecting that we get the same numbers out as we put in originallyã€‚

This teaches the neural network to use just these two hidden layersã€‚

 these two hidden neurons here to essentially compressã€‚

All the inputs down into just two number of valuesã€‚

 So here we'll just train that same shape1 that we had beforeã€‚ It trains very quicklyã€‚

 And you can see I'm basically passing in 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ8ï¼Œ9ã€‚

 And it's essentially returning close to the same thingï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6ï¼Œ7ï¼Œ8ã€‚

 and in a quite get that oneï¼Œ correctã€‚ Oftenï¼Œ these autoenrs are used on imagesã€‚

 So let's go ahead and load some images in that we can make use ofã€‚

 I'm showing you basically here how we created an autoencor to encode this image of Washington Universityã€‚

 Nowï¼Œ if you look at the definition for thisã€‚ğŸ˜Šï¼ŒIt's essentially reducing through a hidden layer of oneã€‚

 So it's teaching it to very highly compress this so that just one numeric value can represent itã€‚

 Nowï¼Œ of courseï¼Œ the hidden layers above and below it will' have some knowledge of the imageã€‚

 So that's where you can basically put it into something so small and still get meaningful output out of itã€‚

 Let's load a number of images and standardize themã€‚ We're going to make sure that all the same sizeã€‚

 There's other standardizations we could doã€‚ We could also make sure that the amount of light matchesã€‚

 which currently it does notã€‚ And now we are going to try to predict thoseã€‚

 So we essentially loop through these are 1 28 by 128ã€‚ğŸ˜Šã€‚

We are compressing them down to that size and passing that value as the input and the outputã€‚

 trying to get the output from the neural network to look just like the training dataã€‚

 I'll fast forward here at this pointã€‚ And here you can see it's able to reconstruct the images just based on these vectors coming inã€‚

 Nowï¼Œ let's look at a denoisisingã€‚Auto encoderã€‚ These are very interestingï¼Œ soã€‚

Let's run one and we'll see that we can add noise to an imageã€‚ I've just put random boxes in thereã€‚

We can essentially train it Nowã€‚ normallyï¼Œ an autoencorã€‚

 you put in the input and you expect the same output out of itã€‚

 But here we're going to be putting input with these squares obstructed and expecting to get as close we can as the original imageã€‚

 This teaches the autoencors to remove noiseã€‚We can run it and watch the outputã€‚

 These images that are slowly flashing byã€‚ They had all those pixels removed with boxesã€‚

 but yet they're still coming out pretty wellã€‚ And then we'll train the neural network based on those noisy images that we created and we'll run it through 10 sort of random trialsã€‚

 Here you can see with noise and without noiseã€‚ It's doing pretty good taking that awayã€‚

 You'll notice some distortionsã€‚ If you zoom in on where the the boxes areã€‚

 But this is kind of how that worksã€‚ You can see itã€‚

 it's really able to do well at removing the noiseã€‚ This is an auto noisingã€‚

 This is an auto denoising autoencoderã€‚ Nowï¼Œ autoencors can do all kinds of thingsã€‚ We will seeã€‚ğŸ˜Šã€‚

In the next partï¼Œ how we can make use of themã€‚To detect anomaliesã€‚

 So input is that is different than what we've seen beforeã€‚ this content changes oftenã€‚

 so subscribe to the channel to stay up to date on this course and other topics in artificial intelligenceã€‚



![](img/be628560dda59c2203db5dbe7b4cf58a_3.png)