# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P2ï¼šL2- Pyspark æ•°æ®å¸§ - ShowMeAI - BV1sL4y147dP

ã€‚

![](img/064c89eed1f0032152a18a66a64a8949_1.png)

Hello allã€‚ My name is Krisushnaak and welcome to my Udish channelã€‚ So guys we will be continuing the Pipar seriesã€‚ and in this tutorial we are actually going to see what Pispar data frames we try to read the data setã€‚ check the data types of the columns we basically say in Pipar call a schema then well see that how we can select the columns and do indexing describe functionality that we have similar to pandas and then we'll try to see that how we can add new columns and probably drop columns this is just the part1 So let me just write it down as part one because after this they will also be one more partã€‚

 why this video will be important because in Piparã€‚ Also if you are planning to apply M the machine learning libraries really need to do data precrosing initially probably in the part two will try to see how to handle missing values and will try to see how to alter the rows how we can probably put a filterer condition and all right So let's proceed before going ahead what I'm going to do is that we will first of all I have aã€‚

ğŸ˜Šã€‚![](img/064c89eed1f0032152a18a66a64a8949_3.png)

![](img/064c89eed1f0032152a18a66a64a8949_4.png)

set called as test1ã€‚ So I've taken three columnsã€‚ One is nameï¼Œ age and experienceã€‚ And then I have a data set like Kris 31ï¼Œ10 like thisã€‚ So the Sunny rightã€‚ So this is some data setã€‚ which I have saved in the same locationã€‚ Now what I'm going to doï¼Œ first of allï¼Œ as usualã€‚ the first step with respect to Pipar is to build the Pipar sessionã€‚ Nowã€‚

 in order to build the Pipar sessionã€‚ I will write the code line by lineã€‚ So please make sure that you also do along with meã€‚ it will definitely be helpfulã€‚ So I'm going to write from Piparã€‚ğŸ˜Šï¼ŒDot sqelã€‚Importã€‚Spark sessionã€‚ and then I will create a variable Osï¼Œ sorryã€‚

![](img/064c89eed1f0032152a18a66a64a8949_6.png)

![](img/064c89eed1f0032152a18a66a64a8949_7.png)

Then I'll start to create a variable regarding my sessionã€‚ So I'll write Sp is equal to Sp session dotã€‚ We basically write builder dot app nameã€‚And here I'm just going to give my app name as practiceã€‚ I can just say or let me write data frame practice or data frameï¼Œ rightï¼Œ something like thisã€‚

 since we are practicing data frame dot get or create functionã€‚ And this is how you actually start a sessionã€‚ So once and againã€‚ if you're executing for the first timeï¼Œ it will take some timeã€‚ Otherwise itll it is perfect to goã€‚ So here is my entire spaï¼Œ it is running in memoryï¼Œ the version that it is running over hereã€‚

 And obviouslyï¼Œ when you're running in the localï¼Œ you basically have one master nodeã€‚ Okayã€‚ and the app name is data frameã€‚ So to begin with we' try to read the data set againã€‚ğŸ˜Šã€‚So let's read the data set now reading the data set I have already shown you multiple ways one is through read option one is to and since this is a CV file we will try to read it first first option we try to see how we can actually read it and then I'll show you multiple ways of reading it okay so I'll write spark dotã€‚

Re dot optionsã€‚And here in this optionï¼Œ we basically say key valueã€‚ rightã€‚ So here I'll just make it as header physical to true so thatï¼Œ you knowã€‚ it should be considering my first row as the headerã€‚And here I'll write it has head true dot CSsv inside the CSvã€‚

I' give my dataset name that is called test1 dot Cism right Now when I execute this probably I think you'll be able to see the data setã€‚ So here you are able to see thatã€‚ Okayï¼Œ it is a data frame and you have features like name age experience right So if I want to see the complete data I'll just write dot show So here is my entire data set over here very clearly I can see it Now let me just save this in a variable call Df underscoreco piparã€‚

 Okay so here is my entire data setsã€‚ Now first thingï¼Œ how do we check the schemaã€‚ let's check the schemaã€‚ Okayï¼Œ schema basically means the data types like how we write in pandas Df dot info Similarlylyã€‚ we can write over hereã€‚ So here you'll be able to see that I have written Df undercope Ipar dotã€‚ğŸ˜Šã€‚Printã€‚Think it should work print schemechemaã€‚No type has spring schema Oh sorryã€‚

 So I had written dot showed and saved in a variableã€‚ I'll remove this dot showã€‚ let me execute it once againã€‚ And now if I write print schema here you'll be able to see name age and experienceã€‚ but by defaultï¼Œ it is taking a stringã€‚ even though in my Excel sheetã€‚ what we have done is that we have written valuesï¼Œ probably this should be stringã€‚

 this should be integersï¼Œ then this should be integersã€‚ But white it is taking it as string the reason it is probably taking a string guys because by default unless until we don't give one more option in Csv this Csv have one option call us infer schemaã€‚

 Okay if I don't make this as true right it will by defaultã€‚ consider all the features as you know in the string valuesï¼Œ string valuesã€‚ So I'll execute this nowã€‚ And now if I go and see Df underscore P dot print schemaã€‚ you'll be able to see that I'm getting name as string age as integer experience as integer and the level is to doã€‚

 that basically is it can have null valuesã€‚ so thisã€‚ğŸ˜Šã€‚One way of reading it one more way Ill try to show youã€‚ which is pretty much simple so I can include both header and infofer schema in one thing itself so Ill write B F underscorecope I spark is equal to spark dot readã€‚Dot CS SV And inside this CS S Vã€‚ Andï¼Œ first of allï¼Œ I will provide my test fileï¼Œ C SVã€‚Okayã€‚

 and then here I will go ahead and write headerã€‚Probably equal to trueã€‚And I can write in for schema Iã€‚ So when I write like thisã€‚ And if I write D F underscoreã€‚Picepar dot showã€‚ hereã€‚ you'll be able to see all my data setã€‚Okayï¼Œ so here is my entire data setã€‚ Nowï¼Œ if I go and see and execute this schema againï¼Œ it will probably give me the same wayã€‚

Like how we haveï¼Œ we had over hereã€‚ Okayï¼Œ so here you can see name is to string is is to integerã€‚ experience inte to integerã€‚ perfectã€‚ So what all things we have doneã€‚ we have understood about this oneã€‚ And rightï¼Œ if I go and see the type of thisã€‚ğŸ˜Šã€‚If I go and see the type of thisï¼Œ this is basically a data frameã€‚ Panda also have a data frameã€‚

 So if somebody ask you an interviewï¼Œ what is a data frameã€‚ you can basically say that data frame is a data structuresï¼Œ you knowã€‚ because inside this you can perform various kind of operationsã€‚ So this is also one kind of data structuresã€‚ Okayã€‚ so what are things we have actually done I've given an introduction of data frame reading the data setã€‚ Now checking the data types of the columnã€‚ in order to check the data types of the columnã€‚ we have already just written print schemaã€‚ Okayï¼Œ now one more thing that I can do after thisã€‚ let's see selecting columns and indexingã€‚ first of allï¼Œ let's understandã€‚

Whatatttle columns are basically present how you can get all the column namesã€‚ So in order to get the column namesï¼Œ you can just write dotã€‚Columnsï¼Œ okayã€‚ and when you execute over hereï¼Œ you'll be able to get the column name like name age experienceã€‚ perfectã€‚ This is perfectly fineã€‚ Nowï¼Œ this is my Dã€‚ Nowã€‚

 suppose if I want to pick up some head elements Alsoã€‚ I will be able to pick up because in pandas Also you havet headã€‚ supposeupp I see I want to get the top three recordsã€‚ I will be getting in this particular format in the list formatï¼Œ usually in pandas when we are usingã€‚

 we usually get in a data frame formatã€‚ So here you'll be seeing the combination of name age and experienceã€‚ Okayï¼Œ like thisï¼Œ This is my first rowã€‚ This is my second rowã€‚ This is my third rowã€‚ Okayã€‚ now coming to the next thing that we are going to discuss nowï¼Œ how do I select a columnï¼Œ You knowã€‚ I probably want to pick up a column and see all the elements rightï¼Œ like how we do it in pandasã€‚

 So first of allï¼Œ let me just write it like thisã€‚ğŸ˜Šã€‚Pspar dot show here willll be able to see all the columnsã€‚ Nowã€‚ if I really want to pick up only name columnã€‚ Okayï¼Œ so how do I do itï¼Œ Okayï¼Œ let'sã€‚ let's actually see now in order to pick up the name columnã€‚

 there is very simple functionality that we writeï¼Œ which is called as Pipar dot selectã€‚ğŸ˜Šã€‚And here I will just give my name column now once I execute this you will be able to see the return type is data frame okay the return type is data frame and name is basically a string now if I write dot show I will be able to see the entire column okay so when I do this I will be able to see this and if I try to find the type of thisã€‚

So sorryï¼Œ if I remove this dot show and see the type of thisï¼Œ this is basically a data frameã€‚ Pipar dot sql dot data frameï¼Œ dot data frameï¼Œ not pandas dot data frameã€‚ Okayï¼Œ pretty much simpleã€‚ nowï¼Œ suppose I want to pick up multiple rowsã€‚ like I sorryï¼Œ multiple columnsã€‚ Like I want to pick up name and experienceï¼Œ probably two columns I want to pick upã€‚ So what I'll doã€‚

 I'll just make one changes here initiallyï¼Œ I was providing my one column name like this after thisã€‚ what I'll doã€‚ I will provide another columnï¼Œ which is like experienceã€‚ğŸ˜Šï¼ŒAnd I'll execute thisã€‚ Nowã€‚ once I execute this over hereï¼Œ you can see that caseï¼Œ I'm getting a data frame with two featuresã€‚ One is name and experienceã€‚ Nowï¼Œ if I go and write dot showã€‚ğŸ˜Šã€‚

Here you will be able to see my all my elements are basically present inside this particular data frame pretty much simple days how do you select multiple rows and yes here slicing definitely will not work because I tried doing slicing it was not working okay and okay whenever you have any kind of concerns always try to see the documentationã€‚

ğŸ˜Šï¼ŒThe Pi park documentationï¼Œ Pre much simpleã€‚ Okayã€‚ this is one way that how we can actually select the columns and probably see the rowsã€‚ Okayã€‚ now let's show youï¼Œ if I just want to pick upï¼Œ there is also one way like the Cã€‚ if I write D of Pipar of nameã€‚If I execute this hereï¼Œ you'll be able to see column nameã€‚

 The return type will be column over hereã€‚ if I'm directly picking because in pandasã€‚ we directly pick like this right and then we have this kind of columnsã€‚ definitely just not we are just able to understand what this particular featureã€‚ It is basically a column it is saying okay nothing more we won't be able to get the data Cã€‚

 there will be no show function it will be saying that it is basically an error So usually what we do whenever we want to get or pick up any kind of columns and try to see itã€‚ we basically need to select using this particular select operationï¼Œ which is my functionã€‚

 Okay so these all things have been done guys what we try to understandã€‚ Now let's see how we can check the data typesã€‚ So there is a functionalityï¼Œ which is called D typesã€‚ So here you'll be able to see name is called to string age is called to end experience it is to And again D types is pretty much similar because we also use this in pandas most of the functionality are similar to pandas guys So what are things we have actually doneã€‚

 Let's seepar data name reading the dataã€‚ğŸ˜Šï¼ŒSa checking the data typeã€‚ selecting columns and indexing check the describe options similar to pandaã€‚ so we can also check out the describe optionsã€‚ So lets seeã€‚Picepar dot describeã€‚ and if I execute this you will be able to see it will give you a data frame summary is to string this this this information is there Now when I write dot showã€‚

ğŸ˜Šï¼ŒOkayã€‚You will be able to see all this this is basically in the form of data frameã€‚ğŸ˜Šã€‚You may be thinking why this nug values is coming mean and standard deviationã€‚ because understand even in thisï¼Œ it will take the string column alsoã€‚ basically the values that are having the data type of string away hereï¼Œ obviouslyã€‚

 you don't have anythingã€‚ So min and max is basically taken on the index because in the0 in the second indexã€‚ you will be able to see crashes then after that sun is thereã€‚ Okayã€‚ in the fourth index and remaining all this information are actually presentã€‚ Okayã€‚ so this is basically the same like the describe options that we are actually seenã€‚ğŸ˜Šï¼ŒYou knowã€‚

 probably in our pandasï¼Œ rightï¼Œ So similarlyï¼Œ we have actually done thatã€‚ Okayã€‚ so describe option is also doneã€‚ So now nowï¼Œ let's go and see adding columnsï¼Œ dropping columnsã€‚ Okayï¼Œ adding columns and dropping columns is veryï¼Œ very simpleã€‚ guysã€‚ If we need to add the columnsã€‚ So I'm just going to write the comment over hereï¼Œ adding columnsã€‚

In data frame and this data frame is pipar data frameã€‚ Okayï¼Œ now in order to add the columnã€‚ So we have an amazing functional functionï¼Œ which is called as Df Pi spark dotã€‚ there is something called as width column Okay now this width column if I see the functionality it returns a new data frame by adding a class or replacing the existing column that has the same name Okayã€‚ so here the first parameter that I am going to give is my column nameã€‚ supposeupp I want to pick upã€‚

 let's see I'll pick up experienceã€‚ğŸ˜Šï¼ŒSo I'll say experience okayã€‚ and probably this will be my new column after two yearsã€‚ what will happen if experience after two yearsï¼Œ you knowã€‚ initially the candidate is 10 years experience after two yearsã€‚ it will become 12 right so we'll try to put now the value This is my new column name and what value it should have so for that I'll write Df P spark and here I'll say probably I'll take that spa experienceã€‚ğŸ˜Šï¼ŒI will multiply by I will add by two because after two yearsï¼Œ the experience will get added by twoã€‚

 just I'm taking oneï¼Œ one way of actually solving thisã€‚ I can put any values I want guys it is up to youã€‚ Okayï¼Œ and you can actually check it outã€‚ Okayã€‚ now after thisï¼Œ this is only the two things that is requiredã€‚ And now if I execute itã€‚ you'll be able to see that some operation will happenã€‚ And now you in this data frameï¼Œ you have1ï¼Œ2ã€‚

3 and 4 featureã€‚ If I want to see the complete data setï¼Œ I can write dot showã€‚ğŸ˜Šã€‚Once I execute it now here we willll be seeing that experience after two years is nothing but 12ï¼Œ10ã€‚66 because 10 plus 2 12 you have veryï¼Œ very simple guysã€‚ And this is what width column is basically told as and you can also do different different things with respect to thisã€‚

 So this is how you can add a column in a data frameã€‚ And againï¼Œ guysã€‚ this is not an in place operationï¼Œ you basically need to assign it to a variable in order to get reflectedã€‚ supposeupp if I want to get it reflectedï¼Œ I really need to assign like this And here now if I go and see my sorry first of allã€‚ let me remove this show the show will not give us proper resultã€‚ğŸ˜Šï¼ŒOkayå“¦ã€‚

Has no attribute width columnã€‚Okayï¼Œ sorryï¼Œ so thisï¼Œ there was a problem with respect to thisã€‚ I'llã€‚ I'll read this data set because I replaced it it completelyï¼Œ rightã€‚ Now I will execute it once againã€‚Now is fineã€‚ Nowï¼Œ if I go and write dot show hereã€‚ you will be able to see the elements all properly givenã€‚ Nowã€‚

 this was with respect to adding the columns withã€‚Data frameã€‚ Nowã€‚ I probably need to drop the columns alsoã€‚So drop the columnsã€‚ Let's see how we can actually drop the columnsã€‚ Dping the columns is pretty much simpleã€‚ like how we usually drop this drop functionality by defaultï¼Œ take column namesã€‚

 You can give a list of columnsã€‚ you can give a single column nameã€‚ So suppose Ill say experience after two yearsã€‚ I want to drop thisã€‚Because who knows after two years what will happenã€‚ So let's drop this in order to drop thisã€‚ just execute like this and just go and see dot showã€‚

Here you will be able to find out without that specific column againã€‚ this is not an in place operation you need to assign it to a variable very most simpleã€‚ so let me just assign it to a variableã€‚Is it called to and please make sure that you remove this dot showã€‚ dot show is a functionality right nowï¼Œ if I write this dot showã€‚

Here you'll be able to see all the elementsã€‚Goodï¼Œ now let's go ahead andã€‚See how to rename the columnã€‚So we are just doing this guys because you really need to be very good at data pre processingã€‚ Okayï¼Œ so I'll write thought and there is another functionï¼Œ which is called as widthã€‚ğŸ˜Šï¼ŒColumn renameã€‚ Okayï¼Œ now in thisï¼Œ you just give your existing and the new column nameã€‚

 Suppose I my existing column name over hereã€‚ I'll say nameï¼Œ and I'll say new nameã€‚Okay and just execute itã€‚ and now if I go and just write dot show and try to see the elements here you will be able to see instead of name there will be something called as new name right now this is what I had to actually discussã€‚

 I am just writing one more point over hereã€‚ we have also discussed about our renaming columnsã€‚Rightã€‚Yesï¼Œ this is just the part one of data framesã€‚ The part two will try to do something called as filter operationã€‚ And in filter operation will try to see various operation guysï¼Œ it'll be pretty much amazingã€‚ You'll be able to learn a lotã€‚ So I hope you like this particular videoã€‚

 Please just subscribe the channel if youre all this sky I see in the next videoã€‚ Have a great dayã€‚ Thank you on it allã€‚ And guysï¼Œ keep sharingã€‚ Keep supporting I see in the next videoã€‚ Bye byeã€‚ğŸ˜Šã€‚![](img/064c89eed1f0032152a18a66a64a8949_9.png)