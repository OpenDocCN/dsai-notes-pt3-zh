# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëPyTorch ÊûÅÁÆÄÂÆûÊàòÊïôÁ®ãÔºÅÂÖ®Á®ã‰ª£Á†ÅËÆ≤Ëß£ÔºåÂú®ÂÆûË∑µ‰∏≠ÊéåÊè°Ê∑±Â∫¶Â≠¶‰π†&Êê≠Âª∫ÂÖ®pipelineÔºÅÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P14ÔºöL14- Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (CNN) - ShowMeAI - BV12m4y1S7ix

HiÔºå everybody„ÄÇ Welcome to a new Pytorch tutorial„ÄÇ Today„ÄÇ

 we are implementing a convolutional neural network and do image classification based on the Cypher 10 dataset set„ÄÇ

 The Cypher 10 is a very popular image data set with 10 different classes„ÄÇ Like we have airplanes„ÄÇ

 carsÔºå birdsÔºå cats and other classes„ÄÇ and this data set is available directly in Pytors„ÄÇ

 So we will create a convolutional neural net that can classify these images„ÄÇ

 So now let's talk about convolutional neural networks very briefly„ÄÇ

 I will not go into too much detail nowÔºå because this tutorial should be focused on the Pytorch implementation„ÄÇ

 but I will provide further links in the description if you want to learn more in detail„ÄÇüòä„ÄÇ

So convolutional neural nets or confnets are similar to ordinary neural networks„ÄÇ

 They are made up of neurons that have learnable weights and biases„ÄÇ

 And the main difference now is that convolutional nets mainly work on image data and apply the so called convolutional filters„ÄÇ

 So a typical conf architecture looks like this„ÄÇSo we have our image„ÄÇ

 and then we have different convolutional layers and optional activationation functions followed by socalled pooling layers„ÄÇ

 And these layers are used to automatically learn some features from the images„ÄÇ and then at the end„ÄÇ

 we have a one or more fully connected layers for the actual classification task„ÄÇ So yeah„ÄÇ

 this is a typical architecture of a CNN„ÄÇAnd these convolutional filters„ÄÇNow„ÄÇ

 they work by applying a filter kernel to our image„ÄÇ

 So we put the filter at the first position position in our image„ÄÇ So this is the filter here„ÄÇ

 And this is the input image„ÄÇ So we put it at the first positionÔºå the position„ÄÇ

 and then we compute the output value by multiplying and summing up all the values„ÄÇ

 and then we write the value into the output image„ÄÇ So here at the red position„ÄÇ

 And then we slide our filter to the next position„ÄÇ So the green position„ÄÇ

 then if you can see this here„ÄÇAnd then we do the same thing and the same filter operation„ÄÇ

 And then we slide our filter over the whole image until we are done„ÄÇ

 So this is how convolutional filters work„ÄÇAnd now with this transform„ÄÇ

 our resulting image may have a smaller size because our filter does not fit in the corners here„ÄÇ

 except if we use a technique that is called padding„ÄÇ

 but we will not cover this here in this lecture„ÄÇSo getting the correct size is an important step that we will see later in practice„ÄÇ

And now let's also talk about pooling layers briefly„ÄÇ So pooling layers or more specific„ÄÇ

 In this caseÔºå the max pooling max pooling is used to downs sampleampble an image by applying a maximum filter to subre„ÄÇ

 So here we have a filter of size 2 by2„ÄÇ And then we look at the two by two subre in our original image„ÄÇ

 And we write the maximum value of this region into the output image„ÄÇ

 So max pooling is used to reduce the computational cost by reducing the size of the image„ÄÇ

 So this reduces the number of parameters that our model has to learn„ÄÇ

And it also helps to avoid overfitting by providing an abstracted form of the input„ÄÇSo yeah„ÄÇ

 these are all the concepts we must know and again„ÄÇ

 please check out the provided links if you want to learn more and now enough of the theory and let's get to the code„ÄÇ

 So here I already wrote the most things that we need so we import the things that we need then we make sure that we also have the GPU support then we define the hyperpar and if you don't know how I structure my Pythtorch files and please also watch the previous tutorials because there I already explained all of these steps„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_1.png)

So then first of allÔºå we load the dataset set and here as I said„ÄÇ

 the Spher 10 dataset is already available in Pytorarch so we can use it for from the Pytorch dot datas module„ÄÇ

 Then we define our Pytorch data sets and the Pytorch data loaders so then we can do automatically batch optimization and batch training„ÄÇ

Then I defined the classes and hard coded them here„ÄÇ

 And then here now we have to implement the convolutional net„ÄÇAnd then as always„ÄÇ

 we typically we create our model and we create our loss and the optimizer„ÄÇ So in this case„ÄÇ

 as this is a multiclass classification problemÔºå we use the cross entropy loss„ÄÇ

 and then as optimizer we use the stochastic gradient descent„ÄÇ

 which has to optimize the model parameters and it gets the defined learning rate and then we have the typical training loop„ÄÇ

 which does the batch optimization so we loop over the number of epochs and then we loop over the training loader so we get all the different batches„ÄÇ

And then here againÔºå we have to push the images and the labels to the device to get the GPU support„ÄÇ

 Then we to do our typical forward pass and create the loss„ÄÇ

 And then we do the backward pass where we must not forget to call to empty the gradients first you with the zero Gr„ÄÇ

Then we call the backward function and optimize a step„ÄÇAnd then print some information„ÄÇ

 Then when we are doneÔºå we evaluate the model„ÄÇ And as always„ÄÇ

 we wrap this in a width torch do no gr argument or statement„ÄÇ So because we don't need the„ÄÇ

 the backward propagation here„ÄÇAnd the gradient calculations„ÄÇ And then we calculate the accuracy„ÄÇ

 So we calculate the accuracy of the total networkÔºå and we calculate the a for each single class„ÄÇ So„ÄÇ

 yeahÔºå so this is the script„ÄÇ You can also find this on my Github„ÄÇ So please check that out there„ÄÇ

And now the only thing that is missing now is to implement the convolutional net„ÄÇSo for this„ÄÇ

 we define a class confnetÔºå which must inherit an end dot module„ÄÇ And as always„ÄÇ

 we have to define or implement the init function and the forward function for the forward pass„ÄÇ

 So now let's write some code here„ÄÇ

![](img/bdf3154fd8a3cad04eb6fed3d8610645_3.png)

So for thisÔºå we have a look at the architecture again„ÄÇ So hereÔºå first„ÄÇ

 we have a convolutional layer and then followed by a reo activation function„ÄÇ

 Then we apply a max pooling„ÄÇ Then we have a second convolutional layer with a relu function and a max pooling„ÄÇ

 And then we have three different fully connected layers„ÄÇ And then at the very end„ÄÇ

 we have the softms and the cross entropy„ÄÇ So the softm is already included in the cross entropy loss here„ÄÇ

 So we don't need to care about this„ÄÇ So yeahÔºå so let's set up or create all these layers„ÄÇ

 So let's say self dot con1 equals And here we get the first convolutional layer by we get this by saying n and dot conf to the„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_5.png)

![](img/bdf3154fd8a3cad04eb6fed3d8610645_6.png)

And now we have to specify the sizes„ÄÇ So the input channel size now is 3 because our images have three color channels„ÄÇ

So that's why the input channel size is 3„ÄÇ And then let's say the output channel size is 6 and the kernel size is 5„ÄÇ

 so  five times 5„ÄÇAnd now let's define a pooling layer„ÄÇ

 self pool equals N N dot max pool 2 D with a kernel size of 2 and a stride of2„ÄÇ

 So this is exactly in the as in the image that we have seen„ÄÇ So our kernel size is size 2 by 2„ÄÇ

 And after each operationÔºå we shifted to pixels to the right„ÄÇ So that's why the stride is 2„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_8.png)

![](img/bdf3154fd8a3cad04eb6fed3d8610645_9.png)

And then let's define the second convolutional layer„ÄÇ So self con2 equals„ÄÇ

 And now the input channel size must be equal to the last output channel size„ÄÇ So here we say 6„ÄÇ

 And as outputÔºå let's say 16 and kernel size is still 5„ÄÇ And so now we have our convolutional layers„ÄÇ

 And now let's set up the fully connected layer by saying self dot F1 equals and and dot linear„ÄÇ

 And now here as an input size„ÄÇ So firstÔºå I will write this for you„ÄÇ So this is 16 times 5 times 5„ÄÇ

 and as output sizeÔºå I will simply say I will say 100„ÄÇ So you can try out a different one here„ÄÇ

 And I will explain in a secondÔºå why this is 16 times 5 times 5„ÄÇ

Then let's set up the next fully collected layer„ÄÇ So this has 120 input features„ÄÇ

 and let's say84 output features„ÄÇ And then let's use a next of final fully connected layer„ÄÇ

 So we have F 1Ôºå F2 and F3„ÄÇ And this is an input size of 84„ÄÇ

 and the output size must be 10 because we have 10 different classes„ÄÇ

So you can change the 120 here and also the 84Ôºå but this must be fixed and also the 10 must be fixed„ÄÇ

 So now let's have a look at why this isÔºå this must be this number„ÄÇ

 So here I have a little script that does exactly the same thing„ÄÇ So oh„ÄÇ

 let me change the number of epoch„ÄÇ Oh yeahÔºå this is4„ÄÇ So here„ÄÇ

I have the same thing in the beginning„ÄÇ I load the data setÔºå and let's also„ÄÇÂóØ„ÄÇ

Print or plot some images„ÄÇAnd then here I have the same layers„ÄÇ

 So here I have the first convolutional layer and the pooling layer and the second convolutional layer„ÄÇ

 And first of allÔºå let's run this and plot the imagesÔºå so„ÄÇLet's say PythonÔºå CNN test dot pi„ÄÇAnd„ÄÇ

I've already downloaded it„ÄÇ So it prints„ÄÇ also yeahÔºå it's very blurt„ÄÇ but I think you can see this„ÄÇ

 This is a horse and maybe a bird and another horse„ÄÇ And yeahÔºå IÔºå I don't recognize this actually„ÄÇ

 So let's runÔºå run this again„ÄÇSee some better picturesÔºå maybe„ÄÇSoÔºå yeahÔºå it's still very blurred„ÄÇ

 Then I think this is a deerÔºå a carÔºå a f and a ship„ÄÇSo„ÄÇYeahÔºå so„ÄÇLet's see„ÄÇHow the sizes look„ÄÇ

 So firstÔºå we just print images that shape„ÄÇ So this is 4 by 3 by 32 by 32„ÄÇ

 And this is because our batch size is 4„ÄÇ And then we have three different colour channels„ÄÇ

 And then our„ÄÇImages have subized 32 by 32„ÄÇSo now let's apply the first convolutional layer„ÄÇ

 So we say x equals cont1„ÄÇ and this will get the images„ÄÇ

 And now let's print the next size after this operation„ÄÇSo let's don't„ÄÇ sorryÔºå I don't want to„ÄÇ

Pot this anymore„ÄÇSo now we have the next sizeÔºå so this is 4 by 6 by 28 by 28 and so there's6„ÄÇ

 now we have six output channels as we specified here and then the image size is 28 by 28 because as I said„ÄÇ

 the resulting image may be smaller because our filter doesn't fit in the corners here and the formula to calculate the output size is this„ÄÇ

 So this is the input width minus the filter size plus2 times padding„ÄÇ

 So in this case we don't have padding and then divided by the strip and then plus1 So in this example we have an input size 5 by5 a filter size 3 by3 padding is 0 and stride is 1„ÄÇ

 So then we have the output size is 5 minus-3 plus 1„ÄÇ So this is2 then divided by„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_11.png)

1 is still 2Ôºå and then plus one„ÄÇSo that's why here our output image is 3 by 3„ÄÇ

 And now we have to apply the same formula in our case„ÄÇ So we have 32 minus the filter size„ÄÇ So-5„ÄÇ

 So this is 27„ÄÇPlus 0Ôºå still 27 divided by  oneÔºå still 27Ôºå and then plus 1„ÄÇ So that's why it's 28„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_13.png)

So here we have 28 by 28„ÄÇ Then let's apply the next layer„ÄÇ

 So the next operation is the pooling layer„ÄÇ So let's save this and run this„ÄÇ

So now our size is 4 by 6 by 14 by 14„ÄÇ So this is because as in the example„ÄÇ

 our pooling layer with a kernel size 2 by2 and a strip of2 will reduce the images by a factor of2„ÄÇ

 So yeahÔºå and now let's apply the second convolutional layer„ÄÇ

 So let's print the size after this operation„ÄÇ So clear this first„ÄÇAnd run this„ÄÇ And then again„ÄÇ

 we would have to apply the formulaÔºå as I just showed you to reduce the size„ÄÇ

 So here Pythtorarch can figure this out for us„ÄÇ So the size is 4 by 16 and this is because the next channel output size„ÄÇ

 and that we specified is 16Ôºå and then the resulting image is 10 by 10„ÄÇ

 and then we apply another pooling operation that will again reduce the size by a factor of 2„ÄÇ

 So this is why now we see that the final size after both convolutional layers and the pooling layers is 4 by 16 by 5 by 5„ÄÇ

 So„ÄÇAnd nowÔºå if we have a look again„ÄÇ So now after„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_15.png)

These convolutional layers„ÄÇ NowÔºå when we put them into our classification layers„ÄÇ

 we want to flatten the sizeÔºå So we want to flatten our 3D tenor to a 1 D tenor„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_17.png)

And now this is why nowÔºå if we have a look at the size now„ÄÇ

 the input size of the first linear layer is exactly this that we have here„ÄÇ So 16 times 5 times 5„ÄÇ

 So this is very important to get the correct size here„ÄÇ

 But now we know why this is this must be 16 times 5 times 5„ÄÇ And now we have the correct sizes„ÄÇ

 So now we have all the layers defined„ÄÇ and now we have to apply them in the forward pass„ÄÇ

 So we say x equals„ÄÇ And now let's apply the first convolutional layerÔºå which gets x„ÄÇ

 And then after thatÔºå we apply an activationation function„ÄÇ So we can do this by calling F„ÄÇ

 So I imported„ÄÇTorch and and functional S F„ÄÇ And then I can call F dot relu and then put in this as the argument„ÄÇ

 And then after the activationation function„ÄÇ So by the way„ÄÇ

 the activationation function does not change the size„ÄÇ

So now we apply the first pooling layer So self dot pool and wrap this here„ÄÇ

 And so this is the first convolutional and pooling layer„ÄÇ

 And then we do the same thing with the second convolutional layer„ÄÇ

 And now we have to pass it to the first fully connected layer„ÄÇ And for thisÔºå we have to flatten it„ÄÇ

 So we can do this by saying x equals x dot view„ÄÇ And the first sizeÔºå we can simply say1„ÄÇ

 So Pytorch then can automatically define the correct size for us„ÄÇ So this is the number of batches„ÄÇ

 the number of samples we have in our batch here„ÄÇ So four in this case„ÄÇ

 And then here we must say 16 times 5 times 5„ÄÇAnd now we have our tens of Latins„ÄÇ

 And now let's call the first fully connected layer by saying x equals self dot F1„ÄÇ

 And this will get X„ÄÇ And then we apply an activationation function AgainÔºå we simply use the relo„ÄÇ

 I also have a whole tutorial about activationation functions„ÄÇ

 So please check that out if you haven't already„ÄÇSo now after thisÔºå we apply the second one„ÄÇ

 So x equals thisÔºå the second fully connected layer with a re activationation function„ÄÇ

 And at the very endÔºå we simply have x equals self dot the last fully connected layer F C 3 with X„ÄÇ

And no activation function at the end„ÄÇ and also no softmax activation function here„ÄÇ

 because this is already included in our loss that we set up here„ÄÇ So then we can simply return X„ÄÇ

 And this is the whole convolutional net model„ÄÇ Now you should know how we can set up this„ÄÇAnd yeah„ÄÇ

 so then we create our model hereÔºå and then we continue with the„ÄÇ

A training loop that I already showed you„ÄÇ So now let's save this„ÄÇ and let's run this„ÄÇ

 So clear this and say PythonÔºå C andN dot P and hope that this will start the training„ÄÇSo„ÄÇOh yeah„ÄÇ

 One thing I forgotÔºå of courseÔºå is to call the super in it„ÄÇ So never forget to call super„ÄÇ

 And this has to get the con and selfÔºå and then„ÄÇDot underscore in it„ÄÇ

So let's clear this again and try this one more time„ÄÇAnd„ÄÇNowÔºå this should start the training„ÄÇ

 So I don't have GP U support on my MacBook„ÄÇ so this can take a few minutes„ÄÇ

 So I think I will skip this and continue when the training is done„ÄÇ So we'll see you in a second„ÄÇ

AlrightÔºå so now we are back„ÄÇ Our training has finished„ÄÇ and if we have a look„ÄÇ

 we can see that the loss slowly decreasedÔºå and then we have the final evaluation„ÄÇ

 So the accuracy of the total network is 46„ÄÇ6% and the accuracy of each class is listed here„ÄÇ

 So it's not very good„ÄÇ and this is because we only specified for epochs here„ÄÇ

 So you might want to try out and more epochs but yeah„ÄÇ

 now you should know how a convolutional neural net can be implemented„ÄÇ

 And I hope you enjoyed this tutorial„ÄÇ If you enjoyed this„ÄÇ

 please leave a like and subscribe to the channel and see a next time by„ÄÇüòä„ÄÇ



![](img/bdf3154fd8a3cad04eb6fed3d8610645_19.png)