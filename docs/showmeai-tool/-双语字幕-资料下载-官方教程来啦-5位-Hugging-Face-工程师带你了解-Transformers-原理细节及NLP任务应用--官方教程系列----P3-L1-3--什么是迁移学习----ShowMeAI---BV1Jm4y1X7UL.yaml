- en: 【双语字幕+资料下载】官方教程来啦！5位 Hugging Face 工程师带你了解 Transformers 原理细节及NLP任务应用！＜官方教程系列＞
    - P3：L1.3- 什么是迁移学习？ - ShowMeAI - BV1Jm4y1X7UL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is transfer learning？The idea of transfer learning is to leverage the knowledge
    acquired by a model train with lotss of data on another task。The Model A will
    be trained specifically for task A。Now let's say you want to train it all B for
    a different task。One option would be to train the model from scratch。This could
    take lots of computation。
  prefs: []
  type: TYPE_NORMAL
- en: time and data。Instead， we could initialize Model B with the same weights as
    Model A。 transferring the knowledge of Model A on T P。When training from scratch。
    all the middle' weights are initialized randomly。In this example。 we are training
    a belt model on the task of recognizing if two sentences are similar on it。
  prefs: []
  type: TYPE_NORMAL
- en: On the left， it's trained from scratch。And on the right， it's venting a protrained
    model。As we can see， using transfer learning on the preed model yields better
    results。And it doesn't matter if we train longer， so training from scratch is
    keptped around 70% accuracy。 or the wetrain would all beat the 86% easily。This
    is because portraytrained models are usually trained on large amounts of data。
  prefs: []
  type: TYPE_NORMAL
- en: but provides a model with a statistical understanding of the language used during
    per traininging。In computer visions， transfer learning has been applied successfully
    for almost 10 years。Models are frequently retained on ImageNet by a asset set
    containing 1。2 million of photo images。Each image is classified by one of 1000
    levels。Training like this。
  prefs: []
  type: TYPE_NORMAL
- en: unlabeled data is called supervised learning。In natural language processing。
    transfer learning is a bit more recent。A key difference with ImageNet is that
    the training is usually self supervised。Which means it doesn't require humanation
    for the labels。A very common portraying objective is to guess the next world in
    a sentence。
  prefs: []
  type: TYPE_NORMAL
- en: Which only requires lots and lots of text。GPT2， for instance。 was portrayed
    this way using the content of 45 million links posted by users on read。Another
    example of selfupvised per training objective is to predict the value of randomly
    massed squls。Which is similar to fit in blood B tests you may have done in school。
  prefs: []
  type: TYPE_NORMAL
- en: Et was between this way using the English Wikipedia and had1，000 and published
    books。In practice。 transfer learning is applied on a given model by throwing away
    its head。 that is its last layers focused on the per training objective。And we
    sitting it with have a new randomly initialized a suitable for the desk attempt。For
    instance。
  prefs: []
  type: TYPE_NORMAL
- en: when you invented in the build model earlier， we remove the a that classified
    Mque and replaced it with a classifier with two outputposts since our task at
    two levels。To be as efficient as possible， the protrained model used should be
    as similar as possible to the task it's fine tune on。
  prefs: []
  type: TYPE_NORMAL
- en: For instance， if the problem is to classify German sentences。It's best to use
    a German portraying model。But with the good comes to bad。 the betweened model
    does not only transfer its knowledge， but also any bias it may contain。ImageNe
    mostly contains images coming from the United States and Western Europe。
  prefs: []
  type: TYPE_NORMAL
- en: so models fine tuned with it usually will perform better on images from these
    countries。But Beni also studied the bias in the prediction of its Gpyy3。 which
    was between using the guess and X world objectives。Changing the gender of the
    prone from E Westbury to she Westbury changed the predictions from mostly neutral
    objectives。
  prefs: []
  type: TYPE_NORMAL
- en: To almost only physical ones。In the model code of the GT2 Mor。 Open AI also
    acknowledges its bias and discourages its use in systems that interact with humans。![](img/d4c722df1d794b9f140ba25884ae87c9_1.png)
  prefs: []
  type: TYPE_NORMAL
- en: Yeah。![](img/d4c722df1d794b9f140ba25884ae87c9_3.png)
  prefs: []
  type: TYPE_NORMAL
