- en: 【双语字幕+资料下载】“当前最好的 TensorFlow 教程！”，看完就能自己动手做项目啦！＜实战教程系列＞ - P18：L18- 图像的自定义数据集
    - ShowMeAI - BV1em4y1U7ib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this video， we will learn various ways that we can efficiently load a custom
    image dataset set。 Perhaps you've scraped this data online， or maybe you've created
    it yourself。 So I'm going to show you three different methods which are all efficient
    and good methods。 but one might be more convenient depending on how your dataset
    is already structured。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_1.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_2.png)'
  prefs: []
  type: TYPE_IMG
- en: So the first method is that we have images in different subfolders so as usual
    we have a good old MNT and in this case we have you know the folder 01 to eta
    up to9 so if you just take a look at one subfoldder in this case we just have
    five images but of course you can imagine having you as many as you want so here
    we have all of the images corresponding to that class and then for the ninth one
    we have all the digit of9 and of course in this case the label is exactly the
    same as the class name but you can also imagine having something else if you would
    have let's say a cat and dog data set then you would just replace the zero with
    let's say cats and then you would have another one for dogs in this case it just
    so happens that the labels are exactly what the class names are so stepping into
    the code these are all the imports that we're going to use and then I'm actually。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_4.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_5.png)'
  prefs: []
  type: TYPE_IMG
- en: going to show you two methods to load this data so let's start with specifying
    what we want as the image height so image height is going to be 28。 the image
    width is going to be 28 as well and then let's say we want the batch size of two
    just because we have so few examples and then let's also create just a very simple
    k sequential model just to make sure or let me actually copy paste that in so
    this is just to demonstrate that this works and that we can overfit this small
    data set and then let's go to the first method。
  prefs: []
  type: TYPE_NORMAL
- en: which is using data set from directory So what we're going to do to use this
    is the Ds train is Tf ks that preprocessing that image。Data set from directory。Allright，
    and then first of all。 we're gonna specify the folder for where all of the images
    are or rather where the subfolds are。 So that's in this case that's in data。 and
    then it's in Mist subfolds。
  prefs: []
  type: TYPE_NORMAL
- en: then we're gonna do labels is inferred。 and and that just means that the labels
    are inferred from the structure of the subfolds in alphabetical order。 And then
    label mode， we're gonna specify to integer。 and you have a different options here。
    but integer is the most common one but you can also use categorical or binary
    and that would mean that this would be a categorical vector。 So basically it would
    be for you know one hot encodings anyways。
  prefs: []
  type: TYPE_NORMAL
- en: then you can also send in something called class names。 So in this case our
    class names would just be0，1 to3 etc， right this makes sense。 But let's say that
    we would replace 1 and 0 here。 That means that index。0 would actually represent
    the digit1。 but of course， that would be kind of confusing。
  prefs: []
  type: TYPE_NORMAL
- en: So let's just change those back。 Then we can specify color mode。 And in this
    case。 we're gonna specify grayscale。 You can also specify RGB here。 and then you
    specify the batch size。 let's say two。 rather we had argument。 Yeah， we had batch
    size equals here。 So we let's do batch size。Which is going to be two。
  prefs: []
  type: TYPE_NORMAL
- en: and then we can do image size is going to be image height and then image width。And
    it's。 it's going to， so it's going to reshape if。Not in this size。Then we're going
    to do shuffle equals true so that we get a randomized order。 then we can specify
    a seed， and this is important if you want to have。
  prefs: []
  type: TYPE_NORMAL
- en: let's say you're splitting it into a validation set and a training set and you
    want the exact same training and validation set every time you run it then it's
    important to set the seed。 and then we can also do something like validation split。Let's
    set it to 0。1。
  prefs: []
  type: TYPE_NORMAL
- en: so 10% of the images are going to be in a validation data。Then to make sure
    that this is the training， we can specify subset equals training。![](img/5a48387aad10b0cf4a2d2bc3dacad647_7.png)
  prefs: []
  type: TYPE_NORMAL
- en: Training。😔，And then what we would do for the validation is simply just copy
    paste all of that。![](img/5a48387aad10b0cf4a2d2bc3dacad647_9.png)
  prefs: []
  type: TYPE_NORMAL
- en: And then we would， first of all， change the name to， let's say， D validation。And
    then right here we would split it to validation and this way it's going to randomly
    split it into a validation data that is 10% of the original data that's in the
    subfolds。
  prefs: []
  type: TYPE_NORMAL
- en: So now when we have used this image data set from directory It's going to be
    in a tensorflow data set format and now we know exactly what to do from previous
    videos So let's say we wanted to do some data augmentation then that would be
    pretty straightforward。
  prefs: []
  type: TYPE_NORMAL
- en: we would do， as we did in the data augmentation tutorial and let me just give
    a simple example。 we would do image is Tf image random。Brightness， and then let's
    send in X。Specify some max delta。 and then we would return image and Y。So that's
    just a very， very simple data augmentation。 We would do DS S train equals。D Strain
    dot map and then augment。😔。
  prefs: []
  type: TYPE_NORMAL
- en: And then let's say you wanted to train on this。 You would do four epochs in
    range of， I don't know。10 or the number of epochs of your choice。 So let's just
    be clear here。 This is for custom loops。And then you would do for x and Y in the
    S train。 and then you would do， you know， train here。 But let's just do。A pass
    on that right now， but that's we've covered this in previous tutorials。
  prefs: []
  type: TYPE_NORMAL
- en: And then， of course， if want， if you wanted to do with model dot compile， that
    works as well。 So you would just， let me， I'm just gonna copy it in so that we
    don't have to。Spend unnecessary necessary time on this so then and again this
    is all covered from previous tutorials but here we do model the compile with Adamom
    optimizer sparse categorical cross entropy and then we do model that fit on that
    for 10 epos let's say so yeah if we just run this we can see right here that it
    found 50 files and then it's using 45 of those for training and then again for
    the validation it's using five of those for the validation and just to be clear
    these 45 rather none of these images inside of these 45 are going to be equal
    to the5 for the validation so they are unique and we not we're not training on
    the images for the validation data。
  prefs: []
  type: TYPE_NORMAL
- en: Alright， and then we can see just every110 box。 we have 100% training accuracy。
    which means that we overfit to those 45 training examples。 Alright， so that's
    the method one。 and that works fine。 then for the method 2。We're going to use
    image data generator and then flow from directory and what we're going to do first
    is define this image data generator。So we're going to do data generator。Is image
    data generator， and we imported this at the top。
  prefs: []
  type: TYPE_NORMAL
- en: so we imported this right here on this line。So we're going to do image data
    generator and then we're going to do。 first of all， we're going to specify rescale
    and we're going to do one divided by 255。And we're just doing this to make sure
    that it's in float。But we're going to divide by 255 to normalize the images and
    then we can specify a lot of data augmentation inside of this image data generator。
  prefs: []
  type: TYPE_NORMAL
- en: so let's just give an example we can do rotation range and there are a ton of
    different arguments that you can send into this I'm going to put the documentation
    part on the screen so you can see but there's really a lot so there are more than
    what I'm showing you right here。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_11.png)'
  prefs: []
  type: TYPE_IMG
- en: But then you can do something like zoom range and you can do in a twople， let's
    say 0。990。99。 And what this is going to do is zoom out 1% and then zoom out 1%
    in a within that range。 but it's going to do it randomly。 So I mean， that's very，
    very few right let's do 5% at least。And then we can do horizontal flip and we
    can set it to false。
  prefs: []
  type: TYPE_NORMAL
- en: we don't want to flip the digits that would ruin some of them。So then we can
    do vertical flip as well。 And again， they are false by default。 I'm just kind
    of showing you how you would do it。you can specify more things like data format
    and we can do channels last。 and this is kind of the standard way Tensorflow wanted
    in。
  prefs: []
  type: TYPE_NORMAL
- en: but you can you can also have channels first， if you'd like。And then you can
    also specify validation split similarly to what we did above。 but let's just set
    0 for this for now。 and then D type is going to be TF float 32。![](img/5a48387aad10b0cf4a2d2bc3dacad647_13.png)
  prefs: []
  type: TYPE_NORMAL
- en: And then when we have the data the image data generator。 we're going to construct
    this train generator because you know so far we haven't specified the directory
    for any of the images。 so now we've just sort of specified how we want the data
    to be processed。So what we do is we do datagen。 flow from directory， all right。
  prefs: []
  type: TYPE_NORMAL
- en: so we do flow from directory on this data generator， on this image data generator
    object。And then here we specify data and then mist subfolders again， and then
    target size。We're gonna specify image。Image height， image width。Then we specify
    the batch size。 let's say batch size， which is two color mode， gray scale in this
    case。
  prefs: []
  type: TYPE_NORMAL
- en: but you can set it to RGB as well， class mode is going to be a sparse and it's
    going to be sparse because we want it to be in a you know the integer representing
    that one。 we don't want one hot encodings。And then we can do shuffle again we
    want the data to be randomized then we can do subset training and in this case
    since we're setting the validation split to zero。
  prefs: []
  type: TYPE_NORMAL
- en: this is going to be the entire one but you could specify you could just as we
    did previously you could copy this and then specify validation generator and then
    specify validation right here so if you're using a validation data here you're
    going specify you're just gonna copy paste all of this and then specify subset
    is validation let's say you would have them in different folders you would have
    a training folder and then a validation folder you would just change the folder
    right here and perhaps you don't want to do data augmentation so you would have
    to then also specify a new data generator。
  prefs: []
  type: TYPE_NORMAL
- en: But yeah， so then we're going to do specify see as well。 which is important
    if we want the same result for different runs。And then， yeah。 so that's it for
    the actual generator。Let me just show you an example example。 so let's do a training
    loop。And let's just do pass。
  prefs: []
  type: TYPE_NORMAL
- en: but here you could specify one sort of one training step。And then I'm gonna
    show you， first of all。 with custom loops。 And then this is a little bit different
    than what we saw previously。 So let's say in range of I don't know，10 again or
    number of epos of your choice。 What we got to do here is we got to count the number
    of batches。 So let's say we start at0。
  prefs: []
  type: TYPE_NORMAL
- en: We're gonna do4 x and y in D S train。 we're gonna iterate up the number of batches
    by one right。 So we've now gone through one more batch。 So we're gonna step one。
    Then we're gonna。Do training。 so we're going to call training。Right here and again。
    this is in the custom loops tutorial if you're unfamiliar with this。
  prefs: []
  type: TYPE_NORMAL
- en: And then we're going to do if no batches is greater equal to 25。 So basically
    if it's equal to 25。And why I'm choosing 25 here is because that's the length
    of our data set or to be specific。 the length of our train data set divided by
    the batch size。So if that's the case。 then we've now gone through the entire data
    set and we need to break。
  prefs: []
  type: TYPE_NORMAL
- en: And the reason we need to break is because we have a generator object that's
    going to go on forever if we don't break。 So this is how you would specify the
    custom training loop set up and。Let me just copy in the code。Right heres to save
    some time。 So let me go through it。 if you would do model compile。 Yes。 were redoing
    model compile just to reset the optimizer state。
  prefs: []
  type: TYPE_NORMAL
- en: so then we would have atom sparse categorical columnmetric accuracy nothing
    odd here and then when we do model fit。 we send in the train generator that we
    you know constructed over here and then we do steps per epoch which is exactly
    the same as we did here if the number of batches equals 25 So the steps per epoch
    is 25 verbose equals2 just that is normal and then。
  prefs: []
  type: TYPE_NORMAL
- en: If we had a validation generator， we would do validation data is equal to that
    validation generator。 and then again the validation steps would be similarly as
    the steps per epoch。 which is the length of validation set divided by the batch
    size。 Allright。 so that hopefully gives you a clear view of two different methods
    that you can use assuming that the data is structured in a subfold way。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_15.png)'
  prefs: []
  type: TYPE_IMG
- en: So the second way that your dataset might be structured is that you have all
    of the images in a folder and then you have a corresponding CSV file and a CSV
    file tells you the fine name and then the label so for example。 in this case it
    says that 0 underscore 1 JPEG is a target labels so the digit is0。
  prefs: []
  type: TYPE_NORMAL
- en: the label of that is0， and then it does that for all of the images in the folder
    and it gives all of the corresponding labels。So if that's the way which is also
    a common way to structure your data。 then I'm going show you exactly what you
    want to do  moving on to the code these are the imports that we're going to use
    and I guess it's nothing weird there the first thing we're going to do is we're
    going to specify the directory so the red oh my God the directory is data and
    then Mmunist images CSv that's just what I decided to call it and the first thing
    we're going to do is we're going to do data frame is pandas do read CSV。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_17.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_18.png)'
  prefs: []
  type: TYPE_IMG
- en: And then so we're going to read the CSE file with pandas。 We're going to specify
    the directory and we're going to do。Then we're going to add train dot CSV。 Now
    that we have the CSV file， what we can do is we can do file paths。We can do data
    frame and then we can obtain from that column， remember we call that column file
    name。
  prefs: []
  type: TYPE_NORMAL
- en: And then we can do that values。 That's gonna to give us all of right， let me。
    let me print it actually。 It's going to become a little bit clearer， I think。So。Like
    that。What。Oh file pads。 All right， so as you can see here， we basically get a
    list of all of the the file names and in this way。 and in this case， they're actually
    pretty nice formatted。 you have you know。
  prefs: []
  type: TYPE_NORMAL
- en: you have the label right here and then you have the index for that one。 So this
    is a a digit0。 digit0， digit1 and so on。 But anyways， then we have the file pads
    and we can get the labels。 we can do that by doing pretty much same thing， but
    we do label and then we do dot values。Now that we have the file pads and the labels
    and the labels in this case are going to be integer。
  prefs: []
  type: TYPE_NORMAL
- en: what we do then is we do Dtrain is Tf dot data do data set dot from tensor slices
    All right so what we do then is we send in the file pads。And then the labels。
    all right， and we do this because。The first one in this。 so the first value in
    this file paths list is going to be equal to the label of the first element in
    this labels list。 so that we use from from tensor slices to sort of map them together
    similar to as you would do zip in Python What we do then is we do a function for
    read image。
  prefs: []
  type: TYPE_NORMAL
- en: So we send in the image file and we also send in the label。 So the first thing
    we do is we do Tf do o do read file。 So we're going to read that file from that
    image file。And also， rather。 we need to specify the directory first and then we
    need to add the image file。Right。
  prefs: []
  type: TYPE_NORMAL
- en: so we're reading that file， then we're going do TF dot image dot decocode image。And
    then we're going to send in that image， we're going to do channels equals1 because
    we have grayscale。 then we're going to do D type is Tf floatat 32， and then we
    just return image and then the label。And just for illustration， let me also show
    you， or rather not show you would。
  prefs: []
  type: TYPE_NORMAL
- en: you would do something like define augment。 if you want data augmentation， you
    do image and label。 and then。I guess data augmentation here， but in this case
    let's just return image and label and then you would do map similarly as we did
    before。 so DSre dot map， we would send that to read image and then you know dot
    map augment and then we can do dot batch of two。Yeah。So now that we have the Ds
    train。 so that that's all for loading the data。
  prefs: []
  type: TYPE_NORMAL
- en: And I just want to show you how you would set it up for training and it's pretty
    basic。 We would do forpoC in range of 10。Then we would do4 x and Y in DS S train。
    So we would train here。 in this case， we're just going do pass or。Let's do print。
    Now， let's just do pass。 Alright。 so then let me copy in just to show you that
    it works， so。
  prefs: []
  type: TYPE_NORMAL
- en: Here we have the same model as we saw previously， simple model。And then we have
    model compile。 and then model fit。And all of this should be very familiar from
    previous videos。 then if we just run it。We can see that we're overfitting pretty
    quickly because we have so few images。 but that's kind of what we expect。So that's
    the method to。
  prefs: []
  type: TYPE_NORMAL
- en: and hopefully this gives you a nice way to a nice general way how you would
    do this。![](img/5a48387aad10b0cf4a2d2bc3dacad647_20.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_21.png)'
  prefs: []
  type: TYPE_IMG
- en: Alright， so the third way is if you would just have all of the images in a single
    single folder。 so in this case we have no CSV file， we just have all of them thrown
    into a single folder but we're assuming here that there is some nice format so
    that we can interpret the label for that image just by having the file name so
    in this case we as we said before the first digit here is representing the class
    of that image and in the second value is just the index so we can actually just
    from the file name。
  prefs: []
  type: TYPE_NORMAL
- en: we can interpret what the label should be for that image。![](img/5a48387aad10b0cf4a2d2bc3dacad647_23.png)
  prefs: []
  type: TYPE_NORMAL
- en: So going to the code， these aret inputs that we're going to use， we're also
    going to use Pathlib。 it's in the standard library， and I'm going to show you
    in just in a minute what we are going to use it for。So let's start with specifying，
    I guess， the batch size， let's do two and then image height is 28。 image width
    is 28。And then we're going to specify the directory。
  prefs: []
  type: TYPE_NORMAL
- en: which is data and then emist images only。 So first of all。 to create the Tensorflow
    data set we're going to do Ds train is Tf dot data dot data dot list files。Then
    we're going to do a string， and here were going to specify we're going to use
    the pathlib。So not to go too much in depth， this is we're using pathlib here because
    that is the format that list files wants the defaulted directory in。
  prefs: []
  type: TYPE_NORMAL
- en: So we're just going to do pathlib。t path then we're going to do the directory。Then
    we're going do plus， and then。t Jpeg， al right。 so it's basically going to find
    all of the files in that directory which is right here that ends with a JpeEg
    file。 Alright， so what you would do then is we would define a process to actually
    you know。
  prefs: []
  type: TYPE_NORMAL
- en: given the file pad， we need to process the image just as we saw for for from
    the previous file So we're going to do define process path。We're gonna send in
    the file pack。And then we're going to do image is TFI O read file of the file
    path。Then we're going to do image is Tf image dodecode JpeEG of that image， and
    then channels equals1。Then for the labels and this is going to depend on the file
    format of of your images。
  prefs: []
  type: TYPE_NORMAL
- en: so this is going to be different for every scenario I'm just showing you one
    way。 So label here is TF strings dots we're going do Tf strings dot split we're
    going to do the file path and then we're going to specify the split So in this
    case we're splitting by the path separator I believe it's called and then in our
    case。
  prefs: []
  type: TYPE_NORMAL
- en: Maybe I can actually do this。 So for x and y in the S train， I can do as to
    Y print。 Y TF strings do split。And then or rather， we just have a file path， so
    file path。So we're gonna split the file path。By this and you're just going to
    see what it looks like。And in this way， I think you can easier follow the the
    logic I had。 So here we have data。
  prefs: []
  type: TYPE_NORMAL
- en: emmin images only。 and then we have this。 And， of course。 here is the important
    information about the file。 So what we're going to do is we're going to take the
    the second index of this list。 So we're going to take this part。Now in our case，
    and this is dependent on your dataset again。 but in our case we can just take
    this one right here and convert it to a number。
  prefs: []
  type: TYPE_NORMAL
- en: so how we can do that is let's see we can do label is Tfstrs。 substr of label
    position zero and then the length is one and if you would have you know varying
    length of of your class names and you could perhaps you split again if you would
    have something like you know cats。
  prefs: []
  type: TYPE_NORMAL
- en: dogs， horses something like that， and you would have that these two are different
    in length you would need to split it some in some way。But this is just how you
    would handle strings。And then label， we can do TF strings do2 number。 and we send
    in the label and we can also specify the out type to be TF in 64。So in in this
    case。 then we have processed image and also the label。 So then what we would do。Is
    DSstrain is DSstrainin。
  prefs: []
  type: TYPE_NORMAL
- en: map。And then we would just do a process path。And then we would do batch and
    then send in the batch size。Alright， and then I'm gonna copy the model again and
    just make sure that this works。 So we have。 you know， again， the model that we
    have previously simple model。 we have model compile similar as before model that
    fit and we send in that D S train。
  prefs: []
  type: TYPE_NORMAL
- en: So let's run it to make sure it works。 Oh yeah。 So here we need to also take
    index2。 So let's rerun it。All right， so then we see after tinyny buck， we'll get
    100% training accuracy。All right， so thank you so much for watching the video
    that was three ways that you can load a custom data set for images in TensorFlow
    hopefully you found the video useful and I hope to see you in the next video。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_25.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5a48387aad10b0cf4a2d2bc3dacad647_26.png)'
  prefs: []
  type: TYPE_IMG
