- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëHugging FaceÈÄüÊàêÊåáÂçóÔºÅ‰∏ÄÈÅçÊêûÂÆöNLP‰ªªÂä°‰∏≠ÊúÄÂ∏∏Áî®ÁöÑÂäüËÉΩÊùøÂùóÔºúÂÆûÊàòÊïôÁ®ãÁ≥ªÂàóÔºû - P3ÔºöL3- Ê®°ÂûãÂíåÂàÜËØçÂô® - ShowMeAI
    - BV1cF411v7kC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's see how we can use this model and tokenizer directly and do some of the
    steps manually„ÄÇ this will give you a little bit more flexibility„ÄÇ So down here„ÄÇ
    let's first use the tokenizer and see what this does„ÄÇ So first„ÄÇ let's call the
    tokenizer dot tokenize function„ÄÇ So we say„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's call the tokens and then equals tokenizer dot tokenize and then the string
    or the sentence we want to tokenize„ÄÇ So let's copy and paste this in here„ÄÇ And
    then once we get the tokens„ÄÇ we can use them and get the token Is out of it„ÄÇ So
    we can say token Is equals„ÄÇ And then we again use the tokenizer and the function
    convert tokenizer to„ÄÇüòä„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_1.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_2.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_3.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_4.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_5.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_6.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_7.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_8.png)'
  prefs: []
  type: TYPE_IMG
- en: Called Is„ÄÇ And then it meet the tokens„ÄÇ So this is one way how to do this„ÄÇ Or
    we can do this directly by saying token I equals„ÄÇ And then we call this tokenizer
    like a function„ÄÇ And then againÔºå we give it the same string here„ÄÇ So now let's
    print all these three variables to see where is the difference„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So first we print the tokensÔºå then we print the token Is„ÄÇ And then here let's
    actually give this a different name„ÄÇ So let's call this input I„ÄÇ So now let's
    run this and see how this looks like„ÄÇ AlrightÔºå so here is the result„ÄÇ So as you
    can see when we call tokenizer dot tokenizeÔºå then we get a list of strings„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_10.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_11.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_12.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_13.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_14.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_15.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_16.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_17.png)'
  prefs: []
  type: TYPE_IMG
- en: The list of the words backs so now each word is a sorry each word is a separate
    token and for example„ÄÇ this one is our smiley face or our emoji So yeah this is
    what the tokenized function does and then once we call this convert tokens to
    IDs we get this one back so now it converted each token to an ID so each word
    has a very unique ID and this is basically the mathematical representation or
    the numerical representation that our model then can understand So this is what
    we get after this function and if we call this tokenr directly then we get a dictionary
    back and here we have the key input Is and we also have the attention mask so„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_19.png)'
  prefs: []
  type: TYPE_IMG
- en: For now you don't really have to worry about this but let's have a look at the
    input IDs so if we compare the token IDs with the input IDs then we see we have
    the exact same sequence of token IDs but we also have this 101 and 102 token and
    this is just the beginning of string and the end of string token but basically
    it's the same so yeah this is the difference between these three functions and
    then these input IDs this is what we can pass to our model later to do the predictions
    manually so now like before we can also use multiple sentences of course for our
    tokenr so for example usually in your code you have your training data so let's
    say xtrain and in this example let's just„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_21.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_22.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_23.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_24.png)'
  prefs: []
  type: TYPE_IMG
- en: Use these two sentences„ÄÇ So this is our X train and then we and then we can
    pass this to our tokenizer and let's call this batch„ÄÇ So this is our batch that
    we put into our model later„ÄÇ So we say batch equals tokenizer and then we call
    this tokenizer directly with our training data„ÄÇ and then I also want to show you
    some useful argument„ÄÇ So we say padding equals true„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and we also say truncation equals true„ÄÇ and then we say max length equals 412„ÄÇ
    and we say return tenss equals and then as a string P for pi torch„ÄÇ So this will
    ensure that all of our samples in our batch have the same length„ÄÇ So it will apply
    padding and truncation„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_26.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_27.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_28.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_29.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_30.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_31.png)'
  prefs: []
  type: TYPE_IMG
- en: Necessary and this is also important„ÄÇ So in this case„ÄÇ we want to have a pytorch
    tenor returned directly„ÄÇ So I will show you later what's the difference if you
    don't use this„ÄÇ But for now let's just use this and then first of all„ÄÇ let's print
    this batch and see how this looks like„ÄÇ And then we see we get a dictionary and
    again it has the key input Is and the key attention mask and then here it has
    two tenzos„ÄÇ So the first one for the first sentence and the second one for the
    second sentence and the same for the attention mask So two tens„ÄÇ So yeah as I
    saidÔºå these input id are these unique Is that our model can understand„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So yeah now we have this batch and now we can pass this to our model„ÄÇ![](img/4e0ddcb38791825272bb7f961349fc05_33.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_34.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_35.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/4e0ddcb38791825272bb7f961349fc05_36.png)'
  prefs: []
  type: TYPE_IMG
- en: And„ÄÇ
  prefs: []
  type: TYPE_NORMAL
