- en: 【双语字幕+资料下载】使用 Scikit-learn 进行机器学习，4小时实战视角刷新知识框架，初学者进阶必备！＜实战教程系列＞ - P10：10）正则化和标准化
    - ShowMeAI - BV16u41127nr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】使用 Scikit-learn 进行机器学习，4小时实战视角刷新知识框架，初学者进阶必备！＜实战教程系列＞ - P10：10）正则化和标准化
    - ShowMeAI - BV16u41127nr
- en: '![](img/ba488996234f1aee5936aea9ea40f4bf_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba488996234f1aee5936aea9ea40f4bf_0.png)'
- en: Well in this video I'm may be talking about two topics。 one is regularization
    and other is standardization。 standardization is something that we have to use
    a lot in this course and understand。 and it's really relatively simple， but regularization
    is a very complicated topic and might require a lot of time and a more advanced
    machine learning course。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个视频中，我可能会谈论两个主题，一个是正则化，另一个是标准化。标准化是我们在本课程中经常使用并理解的内容，相对简单，但正则化是一个非常复杂的话题，可能需要更多时间和更高级的机器学习课程。
- en: I'm not trying to get into any math regarding regularization。 and I'm just trying
    to try to give the kind of simplest intuition and we aren't going to get deep
    into it。 but just wanting to know that that's an important and deeper topic。So
    in terms of things that we've already done。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想深入探讨正则化的数学，我只是想给出最简单的直觉，我们不会深入研究，但希望大家知道这是一个重要且深刻的话题。至于我们已经做过的事情。
- en: '![](img/ba488996234f1aee5936aea9ea40f4bf_2.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba488996234f1aee5936aea9ea40f4bf_2.png)'
- en: We've been using logistic regression a lot and a problem that it has that I
    haven't talked about is that it's very sensitive to scaling。And so for example，
    you might have a data set and there might be some numbers in it with specific
    units。And you might get one result of due do the classification if you change
    those units， so for example。 maybe you change miles to feet， you might get a different
    result。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经频繁使用逻辑回归，但它有一个我还没谈到的问题，那就是它对缩放非常敏感。例如，你可能有一个数据集，其中包含一些特定单位的数字。如果你改变这些单位，比如把英里换成英尺，可能会得到不同的分类结果。
- en: which is of course not what we want we just care about the actual kind of information。
    not what units somebody arbitrarily chose to use。Why is that well it's because
    logistic regression is applying this technique to regularization？
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这显然不是我们想要的，我们关心的是真实的信息，而不是某人随意选择的单位。为什么呢？因为逻辑回归将这种技术应用于正则化。
- en: Which tries to use smaller coefficientes and in general。 not have a very large
    coefficient on just one of our features。You can imagine that I have lots and lots
    of feature columns。That just by chance。 maybe one of them does better on the training
    data than others。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 它试图使用较小的系数，通常不希望在某一个特征上有一个非常大的系数。你可以想象我有很多特征列，或许其中之一在训练数据上表现得比其他的好。
- en: Even if the other feature columns are kind of still somewhat useful。 and so
    what I wouldn't want to do is just by chance choose that best one because then
    it won't work well later on a test data set。 regularization basically is providing
    a motivation to use multiple features and not consider one too heavily。 even if
    that would do better in the short term。So logistic regression does this linear
    regression which was the first model we learned in this course does not。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 即使其他特征列仍然有些有用，我不希望仅仅因为运气选择了那个最好的特征，因为这样在测试数据集上效果不好。正则化基本上是提供了一种动机，使用多个特征，而不太重视其中一个，即便它在短期内表现更好。因此，逻辑回归实现了这种线性回归，而这是我们在本课程中学习的第一个模型。
- en: but there are also things very similar to linear regression that do such as
    ridge regression and lasal regression。 we're not trying to talk about those at
    320 but they're important and use all the time and so know that this regularization
    thing is a big deal。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有类似于线性回归的东西，比如岭回归和套索回归。我们在320中不打算讨论这些，但它们很重要，且经常使用，因此要知道这个正则化的概念非常重要。
- en: So what would we really like， we don't want our model to be sensitive to units。
    We would like to standardize it in some way so that we have the same numbers going
    in。 regardless of what their original units were。So for this example I just made
    up kind of a fake scenario。 we're measuring some sort of quantity in the real
    world three times and based on we're trying to predict what sort of category it's
    in the category will either be true or false。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们真正希望的是什么呢？我们不希望我们的模型对单位敏感。我们希望以某种方式标准化，使输入的数字相同，而不管它们原来的单位是什么。以此例子，我编造了一个虚构的场景，我们在现实世界中测量某种数量三次，并根据这些数据预测它属于哪个类别，类别将是“真”或“假”。
- en: The underlying rule is that when the true length， which we don't know。 is bigger
    than 5 than the category is true。 It's less than 5。 The category is false。 And
    so these three kind of noisy measurements， even though they know tell us exactly
    what the true length is。 they give us some information about that they can help
    us guess whether it's true or false。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基本规则是，当真实长度（我们不知道）大于5时，类别为真；如果小于5，类别为假。因此这三个有些嘈杂的测量值，尽管它们没有确切告诉我们真实长度是什么，但它们给我们提供了一些信息，可以帮助我们猜测它是真还是假。
- en: So here I have that data， that fake data I'm talking about， the y column here
    is the category。 and then I have my three measurements， x1 x to an x3。Let me just
    talk a little bit about how I'm generating this。So under anumpot random。 there
    are a bunch of functions that will generate random data， I'm doing a normal distribution
    here。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我有我所说的那些虚假数据，y列是类别。然后我有我的三个测量值，x1、x2和x3。让我谈谈我是如何生成这些的。在numpy的随机函数下，有许多函数可以生成随机数据，我在这里做的是正态分布。
- en: you can sample from different distributions， you don't know what that means
    that's fine for this course。 but basically I'm generating1000 random numbers with
    an average of four and putting them in here。And so this will be an array of numbers。
    and then I'm saying， well， whatever that's five。 greater than five， I want to
    have a true， otherwise I'll have a false。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从不同的分布中抽样，如果你不知道这意味着什么，那对这门课来说没关系。但基本上，我在这里生成了1000个随机数，平均值为4，然后将它们放入这里。这将是一个数字数组。然后我在说，任何大于5的，我希望它为真，否则我就会得到假。
- en: When I'm looking at this data frame down here， truefe does not directly go then
    into any of these columns it's unknown。 but category does and categories what
    we're trying to predict。So how are we trying to predict if we don't know true
    feet， why have these three other columns。 which are basically just true feet plus
    some random noise。 So if I look at it down here。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当我查看下面的数据框时，truefe并没有直接进入这些列，它是未知的，但类别是已知的，而类别是我们试图预测的。那么，我们如何进行预测呢？既然我们不知道真实的长度，为什么还会有另外三个列呢？它们基本上是实际长度加上一些随机噪声。所以如果我在下面查看一下。
- en: let me look at this first one。 All three measurements were less than5。 So it
    makes a lot of sense that I'll predict that the y is less than than5。 Maybe I
    can even look at some more cases here。 I wonder if。I can see where it's true。Let
    me do that So I can see some other cases here where it's true right， all in this
    case。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我看看第一个测量值。所有三个测量值都小于5。所以我预测y会小于5是非常合理的。也许我还可以查看一些其他情况。我想知道是否能看到它为真的地方。让我来做一下，这样我可以看到其他一些情况，这些情况在这个例子中都是正确的。
- en: all the measurements were greater than5。 So I say it's true。 This is kind of
    a more interesting example。 This number is very large。 right。 One measurement
    was like almost of7。And even though the other two measurements were less than
    5。 this was enough of a signal that the model decide it's true。 Well， it's true
    overall。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的测量值都大于5。所以我认为这是真的。这是一个更有趣的例子。这个数字非常大，对吧。一个测量值几乎是7。即使其他两个测量值小于5，这也足以让模型判断为真。好吧，总体上它是真的。
- en: and hopefully the model will decide the same。 Okay， so that's the data we're
    working with。 And let's see if we can。Train a model to try to predict this。 so
    I'm going to create a model and I'm going to use a linear or logistic regression
    model。And I'm going to fit it。To my data， and so I may have some x and and Y's
    for my Y's。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 希望模型会得出相同的结论。好的，这就是我们正在处理的数据。让我们看看能否训练一个模型来尝试预测这个。因此，我将创建一个模型，我将使用线性或逻辑回归模型。我会将其拟合到我的数据中，所以我可能会有一些X和Y的值。
- en: I'm just going to pull out y column for my training data and for my X。I want
    to pass in a list of all my columns that contain features so x1 and x2 and x3。
    and I'm going be using these again， so I'm actually try to put this in a variable
    called x columns。And then I don't have to keep typing that whole long thing every
    time。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从我的训练数据中提取y列，对于我的X，我想传入一个包含所有特征列的列表，所以是x1、x2和x3。我会再次使用这些，所以我实际上会把它放入一个名为x
    columns的变量中。这样我就不需要每次都输入那么长的内容。
- en: And so I fit it and that's straight and so pretty soon I may look at the coefficients
    for this model。 but before that I just want to as an aside， see what accuracy
    it has if I want to see the accuracy of the model。 I can just say instead of fit
    I want to score and then to be realistic I shouldn't score it on data that I haven't
    seen before instead of the thing I trained it on right so this is kind of a better
    test and I see that it has 89% accuracy is that good 89% seems high that we would
    be right that often but let me show you why it's not necessarily。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我进行了拟合，这很简单，很快我可能会查看这个模型的系数。但在此之前，我想顺便看看如果我想查看模型的准确率，它有多高。我可以说，不是拟合，而是评分，然后为了现实起见，我不应该在我之前没见过的数据上进行评分，而是我训练的东西，所以这是一种更好的测试，我看到它有
    89% 的准确率，这样好？89% 似乎很高，我们会那么频繁地正确，但让我给你看看为什么这不一定。
- en: If I look at this Y column， I see it's almost always false and indeed if I say
    value counts。 I could see it's only true less than 20% of the time。 and I can
    actually just divide this by the length of tests to see that。 And so what this
    means is that even if I had a very naive model， it just always says false。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我查看这个 Y 列，我发现它几乎总是为假，实际上如果我说值计数，我可以看到它只有少于 20% 的时间为真。我实际上可以将其除以测试的长度来看这一点。因此，这意味着即使我有一个非常简单的模型，它总是说假。
- en: I would be getting 81% accuracy， 89% is better， but in that context it's not
    so amazing just given that there's so much skew in that column。Okay， so after
    I look at the accuracy of a model， the next thing I'll often want to look at are
    my coefficients。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我会得到 81% 的准确率，89% 更好，但在那种情况下并不是那么惊人，因为这一列的偏差太大。好吧，所以在我查看模型的准确率后，接下来我通常想查看的是我的系数。
- en: and I like to plot those in some way， oh， my model coefficients。And I see those
    are right here and and I'd like have some sort of bar plots。 I know that these
    things are paired up with these x columns right so this is the coefficient for
    x1 so on and so forth。 And so the way I'll often make such a bar plot is I'll
    say PDd do series。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢以某种方式绘制这些，我的模型系数。而且我看到这些就在这里，我想要某种条形图。我知道这些与这些 x 列是成对的，所以这是 x1 的系数，以此类推。因此我通常制作这样的条形图的方法是说
    PDd do series。
- en: And then I will have my Y values。And then I'll have index equals x values。Dot
    plot， dot bar。So on the x values， I'm going to use those column names， and I'm
    going to put the coefficients。To basically have the quantities that are going
    to go to the Y axis。And it's complaining that the length of one of these things
    is one when it was supposed to be three。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我会有我的 Y 值。然后我会有索引等于 x 值。点图，点条形图。在 x 值上，我将使用这些列名，并将系数放入其中。基本上会有量值用于 Y 轴。而且它在抱怨其中一个的长度是
    1，而它应该是 3。
- en: and so x columns， that's pretty simple there， but if I look at this。This array
    right here what do I see I see there's it's really a twodiional thing I can flatten
    it into a one dimensional array with three numbers or if I say negative one。 it'll
    make it one dimensional it'll make it you know it doesn't matter how many numbers
    I have and I'll figure it out so I may put that here now and now I get this plot
    and this is interesting right I was talking about how maybe sometimes just by
    chance we focus more in one problem than another and that happens here right x1
    x2 and x3 we're all equally noisy but it just so happens that based on the training
    data the model thinks that x1 is more kind of more useful right that was just
    by chance。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 x 列，这里非常简单，但如果我看看这个。这一数组，我看到它其实是一个二维的东西，我可以将其展平为一个包含三个数字的一维数组，或者如果我说负一，它会变成一维的，不管我有多少个数字，它都会搞定，所以我可以把它放在这里，现在我得到了这个图，这很有趣，对吧？我在谈论有时候仅仅是偶然，我们在一个问题上比另一个问题更关注，这种情况在这里发生了，对吧？x1、x2
    和 x3 都是同样嘈杂的，但恰好基于训练数据，模型认为 x1 更有用，对吧？这纯粹是偶然。
- en: And so you could imagine a worse scenario where it picks one column that I really
    likes and ignores all these other ones that have good information in it。 and so
    the model will try to avoid doing that。 regularization means that we'll try not
    to put too much weight on just one factor we'll try to spread it out a little
    bit and then if you took it to an extreme。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以想象一个更糟糕的情况，它选择了我非常喜欢的一列，忽略了所有其他具有良好信息的列。因此模型会尽量避免这种情况。正则化意味着我们会尽量不对单一因素赋予过多权重，我们会尝试稍微分散一下，如果你将其推向极端。
- en: you might imagine that I could have a model where I just look at my intercept。My
    intercept is you can imagine that being like the average and the model could just
    predict animal all my coefficients could be zero in that case。 well we all just
    predict the same thing， and we want to have this problem I guess we have another
    problem that just want to be very accurate。Okay， so I have that。And so let me
    head back here and I'm going randomly generate this data。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想象我可以有一个只看我的截距的模型。我的截距可以想象成平均值，在这种情况下，模型可以预测动物，所有我的系数都可以为零。好吧，我们都只预测同样的东西，我想我们有另一个问题，只想非常准确。好的，我有这个。所以让我回去，我将随机生成这些数据。
- en: but this time I'm just going to change the units on this column and I'm going
    to change the units to be miles and so there's 5。280 feet in a mile so I'm just
    to make a comment here this is feet to miles like that and so I have the same
    kind of data just different units。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但这次我只是改变这一列的单位，我将单位改为英里，因此一英里有5280英尺。我在这里想做一个评论，这是英尺到英里的转换，所以我有相同类型的数据，只是单位不同。
- en: so I might hope that my model won't do anything that differently。And so I'm
    going to run this again。 and I see that not too much has changed here。 And then
    I want to think about what's going to happen when I rerun this。So in this x2 column。The
    numbers are all much smaller now because it's in miles。 and so I might expect
    that to use this， I might have a bigger coefficient on x2。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我希望我的模型不会有什么不同的变化。所以我将再次运行这个。我看到这里没有太多变化。然后我想想重新运行时会发生什么。因此，在这个 x2 列中，数字现在都小得多，因为它是以英里为单位。因此，我可能期望使用这个时，x2
    的系数会更大。
- en: If I wanted to be just like before。It turns out when I run it， I actually see
    the opposite。 It's adverse to having such large coefficients on one column because
    of that regularization thing I talked about。 So it actually decides， hey， I'm
    just going to ignore x2 entirely。 I have to put a bigger or a bigger weight on
    that that I'm comfortable doing to have it be a factor。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我想和以前一样。结果发现当我运行它时，我实际上看到了相反的情况。由于我之前提到的正则化因素，拥有一个列上如此大的系数是有害的。因此，它实际上决定，嘿，我将完全忽略
    x2。我必须在我能够接受的情况下，给它一个更大的权重。
- en: So I just lost some information there。 I' using these two columns anymore。 Now，
    of course。 that's silly right， putting a bigger coefficient on it isn't really
    waiting it more。 It's just canceling out the fact that I have different units
    on it。 And so there's different ways to solve this。 One is that I could just insist
    that I have the same units for everything。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我在这里丢失了一些信息。我不再使用这两列。现在，当然，这很傻，对吧，把更大的系数放上去并没有真正增加权重。它只是抵消了我有不同单位的事实。因此，有不同的方法来解决这个问题。一种是我可以坚持所有东西都有相同的单位。
- en: Another way I could do it is I could try to kind of make this a little more
    uniform in some way。 And so that's what I'm going to do here。😊，I'm going head
    back here， and let me。Let me take my training data and my actually， where do I
    want to do this？
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是我可以尝试以某种方式让这个更统一。所以这就是我在这里要做的。😊，我将回到这里，让我。让我拿到我的训练数据，实际上，我想在哪里做这个？
- en: I take these x columns even sooner， Actually， no， that's fine。 I'm going to
    leave that there。 so I'm going take my training data and I want to take a slice
    of it and I want to get all the rows and I want to get columns x1。Through R x2。And
    so this is just my features now well through x3， sorry， these are just my features。And
    I want to somehow standardize it so that they all have roughly the same scale。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我很快就会处理这些 x 列，实际上，不，这没问题。我打算把它留在那里。因此，我将提取我的训练数据，并想取一个切片，我想获取所有行，并提取列 x1。通过
    R x2。所以这就是我的特征，现在通过 x3，抱歉，这些只是我的特征。我想以某种方式标准化它们，以便它们大致具有相同的尺度。
- en: And so I'm to do is I'm just going pull this out into this x variable right
    here。 and there's going be two things I'm going to do。 one is that I'm going take
    the mean of each of each column just like that。 and I'm going subtract these numbers
    off of each column I'm going say that。 And so now all of these columns are centered
    at  zero right after I subtracted away the mean the average of every column is0。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我要做的是将其提取到这个 x 变量中。我要做两件事。一是计算每列的平均值，就这样。我将从每列中减去这些数字。我会说这样。因此现在所有这些列都以零为中心，减去均值后，每列的平均值都是0。
- en: it turns out that that is also helpful for logistic regression to run faster。
    I'm not trying to get any details about why that's useful And then more importantly
    I want them to be on the same scale。 and so oops， what happen there。I jump onto
    a new column or to a new cell and so if I look at this。 that's a standard deviation
    of each column and if I have larger numbers while the standard deviation shall
    be higher and so standardization the real key part is that I'm dividing all of
    this by that standard deviation and if I do that I may get a bunch of small numbers
    that have roughly the same scale so after I've done this all of them will have
    the same average0 and then the same standard deviation of one and so this would
    be a better x data and I can actually put this back in to my training data like
    this so I may say this equals my new X data so I make it out here Im going say
    manually standardize the data。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，这对逻辑回归的运行速度也很有帮助。我并不想了解为什么这是有用的，更重要的是，我希望它们在同一尺度上。那么，哎，发生了什么事？我跳到了新的一列或新的一单元格，所以如果我查看这个，那是每列的标准差，如果我有更大的数字，那么标准差就会更高，因此标准化的关键部分是我将所有这些除以那个标准差，如果我这样做，我可能会得到一堆小数字，它们大致在同一尺度上，所以在我完成这一切后，它们都会有相同的均值和标准差为1，因此这将是更好的x数据，我实际上可以像这样把它放回我的训练数据中，所以我可以说这等于我的新x数据，所以我手动将数据标准化。
- en: And so after I do that I run all of this stuff again and now I see that great
    x2 is back in play。 even though I have different units， it's not getting obsessed
    with these other columns just based on the units。 so this was a good thing to
    do okay that's what standardization is。Now it turns out that to do this right，
    I have to calculate this mean and standard deviation on the training data。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在我完成后，我再次运行所有这些，现在我看到x2重新发挥作用。尽管我有不同的单位，它并没有过于关注其他列的单位。因此，这是一个不错的做法，好的，这就是标准化的意义。现在结果是，要正确做到这一点，我必须在训练数据上计算这个均值和标准差。
- en: but then I have to use that same mean and standard deviation on the test data
    I can't retake the mean on the test data and so the methodology of this gets a
    little bit complicated and so generally we won't do this generally we'll have
    ask K learn do that for us and so it turns out that there's a preprocessing step
    called standardization and we're going to use that as so manually doing this so
    I'm going to head back here。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但我必须在测试数据上使用相同的均值和标准差，我不能重新计算测试数据上的均值，因此这一方法论会变得有些复杂，所以一般我们不会这样做，我们会请K学习为我们完成，所以结果是有一个预处理步骤叫做标准化，我们将使用这个，而不是手动进行，所以我将回到这里。
- en: And you can see I've already import my standard scalar。And I'm to run this here。And
    this is skipping now for my model， right， I'll just actually leave this for now。
    and that'll be my bad model。 What I'll do is I'll' create a new model。 which will
    be a pipeline model。And in that pipeline model。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我已经导入了我的标准化器。我将在这里运行这个。这现在跳过了我的模型，对吧，我现在就先不处理这个。这将是我的糟糕模型。我将创建一个新的模型，它将是一个管道模型。在这个管道模型中。
- en: I want to have a standard scalar followed by a logistic regression。Just like
    that and。This one。 I may have to actually create them like that。I have to give
    them names， right。 So I'm going pass tus here。 So I'm going to call that standard
    scalar。Okay。 I have to put Thomas to separate these things。And then， then we go
    have this logistic regression。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要一个标准化器，后面跟着逻辑回归。就这样。这一个，我可能确实要这样创建它们。我必须给它们命名，对吧。所以我将把它称为标准化器。好的。我必须用逗号分隔这些东西。然后，我们将有这个逻辑回归。
- en: Like that And this is my new model and then it turns out all this stuff I was
    doing before of like fitting。 for example it can work the same way I can fit just
    like I did before because I this new one also fit and so I can do that I could
    also score it like I did before let me score it now and I get something very similar
    and then what's might be interesting is that when I actually do this when I actually
    try to get this bar plot it should show that it's back in play right even though
    the nonstandardized version is ignoring x2 now。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 就像这样，这是我的新模型，然后发现之前我做的所有拟合工作，比如说，它可以以相同的方式工作，我可以像以前一样进行拟合，因为这个新的模型也可以拟合，所以我可以这样做，我也可以像以前一样对它进行评分，现在让我来评分，我得到的结果非常相似，然后可能有趣的是，当我实际这样做时，当我实际尝试获取这个条形图时，它应该显示它重新发挥作用，尽管非标准化的版本现在忽略了x2。
- en: this version should show it so remember this there's gonna be a small error
    here and the problem is that pipeline doesn't have coefficients this pipeline
    as a whole doesn't have coefficients but the logistic regression inside of it
    does have coefficients。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本应该会显示出来，所以记住这里会有一个小错误，问题在于管道没有系数，整个管道没有系数，但里面的逻辑回归是有系数的。
- en: 😊，And so how can I get to that it turns out that any pipeline works like a dictionary
    and I can for example I can copy these names and use that like a key and so that
    would get me my standard scalar from the beginning or I could pass in this key
    and that would get me a logistic my logistic regression stage of it and so from
    that then I could actually see well what are the coefficients involved there and
    I would I would paste this here instead of what I originally had and so now I
    can see that when I have the standardization in play as a transformer before my
    estimator it'll automatically do that and then it'll do the right things as well
    if I do my fitting here it'll calculate that mean and a standard deviation and
    I do scoring it's just going to use the same mean in standard deviation from before
    it would not look at that for the task because that would be kind of a methodological
    mistake so we're going to be generally doing whenever we have a logistic regression
    unless we have some very special scenario。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 😊，那么我怎么能发现任何管道都像字典一样呢？我可以复制这些名称并用作键，这样就能从一开始获得我的标准化器，或者我可以传入这个键，这样就能得到我的逻辑回归阶段，因此我可以看到涉及的系数。我会把这个粘贴到这里，而不是我原本的内容，这样我就能看到在标准化作为变换器的情况下，它会自动执行，然后如果我在这里进行拟合，它将计算均值和标准差，而在评分时，它只会使用之前的均值和标准差，而不会考虑任务，因为那会是一个方法论错误。因此，只要没有非常特殊的情况，我们通常会这样做，尤其是在逻辑回归中。
- en: For example， the data has already been standardized。![](img/ba488996234f1aee5936aea9ea40f4bf_4.png)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，数据已经被标准化。![](img/ba488996234f1aee5936aea9ea40f4bf_4.png)
