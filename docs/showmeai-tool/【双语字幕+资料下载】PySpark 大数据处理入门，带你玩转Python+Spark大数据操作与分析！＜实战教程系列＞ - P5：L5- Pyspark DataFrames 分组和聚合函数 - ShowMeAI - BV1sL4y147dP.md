# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘PySpark å¤§æ•°æ®å¤„ç†å…¥é—¨ï¼Œå¸¦ä½ ç©è½¬Python+Sparkå¤§æ•°æ®æ“ä½œä¸åˆ†æï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P5ï¼šL5- Pyspark DataFrames åˆ†ç»„å’Œèšåˆå‡½æ•° - ShowMeAI - BV1sL4y147dP

ã€‚

![](img/1babe07f0737b77a8ca240e4a3c70599_1.png)

Hello allï¼Œ my name is Krisnaak and welcome to my YouTube channelã€‚

 So guys we will be continuing the Pipar series and in this particular video we are going to see group by an aggregate functionã€‚

ğŸ˜Šï¼ŒAlready I have actually created somewhere around four tutorials on Piparã€‚

 this is basically the fit tutorialã€‚ And againï¼Œ this is a part of a data frameã€‚

 why we should actually use group by aggregate functions again for doing some kind of data preprosingã€‚

 So let's begin for this particular data for this particular problem I created a data which has three features like name departments and salary and you have some of the data like Kris data science salaryã€‚

 rightï¼Œ something like thisã€‚ So over here in shortã€‚

 if I want to basically understand about this particular data they are some departments probably where Krisish and other people teach and based on different different departmentsã€‚

 they get a different different salaryï¼Œ So let's see how we can perform different different group by an aggregate functions and see how we can preproces or how we can get some or retrieve some kind of results from this particular dataã€‚

 So to begin with what we are going to do we are a first of all going to import Piparã€‚



![](img/1babe07f0737b77a8ca240e4a3c70599_3.png)

![](img/1babe07f0737b77a8ca240e4a3c70599_4.png)

SQL importã€‚Spark sessionï¼Œ as usualï¼Œ we have to create a spark sessionã€‚ So after thisã€‚

 what we have to doï¼Œ I'll create a spark variableã€‚ So I'll use spark sessionï¼Œ dot builder dotã€‚

Ap nameï¼Œ I think everybody must be familiar with thisã€‚ but againï¼Œ I'm trying to show you this oneã€‚

 So let me write it as aggregateã€‚Dotã€‚Get or createã€‚ So now I've actually created a spark sessionã€‚

Okayï¼Œ probably this will take some time now if I go and check out my spark variableã€‚

 so here is your entire information okayã€‚With respect to this particular spark very wellã€‚ Nowã€‚

 let's go ahead and try to read the data setã€‚ Nowï¼Œ I will just write D F underscore pi sparkã€‚

And then here I'll write Sp dot readã€‚Dot CSvï¼Œ the CV file name is basically testã€‚3 dot Csvã€‚

 And rememberï¼Œ I'll be giving this particular CV file in the Github alsoã€‚

 and then I'll be using header is equal to trueã€‚Coma infer schema is equal to2ã€‚Nowã€‚

 this is my dear underscoreosscope by sparkã€‚Nowï¼Œ what I'll do in the next statementã€‚

 I will write Df underscorecope pipar dot showã€‚Right now here you'll be able to see that I am actually being able to see all the data sets here I have nameã€‚

 departments and salary on all this particular informationã€‚

If I really want to see the schema or the columns like which all columns where it belongs toã€‚

 just like a data typesï¼Œ I can definitely use DF underscorecope Iparã€‚

Dot print schema right and now here you can see name is a string department is string and salary is basically an in teacher okayã€‚

Nowï¼Œ let's perform some group by operationã€‚ Firstï¼Œ we'll start by group by operationã€‚

Probably I want to group by name and probably try to see what will be the mean average salaryã€‚

You know what suppose let's let's take a specific example over hereã€‚

 So I'll write Pf dot underscorecope bypar dot group byã€‚

 supposeupp I want to go and check who is having the maximum salary out of all these people that are present in this particular data setã€‚

 So I'll first of all group by name if I execute this you can see that we will be getting a return type of group data at some specific memory locationã€‚

And you should always know that guys group by aggregate functions works togetherã€‚

 That basically limits is first of allï¼Œ we we need to apply a group by functionalityã€‚

 and then we need to apply an aggregate functionã€‚ So aggregate function here really want to check just press dot and press tab So here you'll be able to see a lot of different different function examples like aggregate average count max mean pi and many mode right now what I'm going to do I'm just going to use this dot sum because I really need to find which is the maximum salaryã€‚

ğŸ˜Šï¼ŒHoweverFrom out of all these particular employeesï¼Œ who is having the maximum salaryã€‚

 So here I'll say dot sumã€‚ And if I execute itï¼Œ you'll be able to see that we are getting a sQL dot data frameã€‚

 which has name and sum of salaryã€‚ This is very much important as sum of salary because I really want to have the sum of the salaryã€‚

 rememberï¼Œ we cannot apply sum on the stringã€‚ So that is the reason it has not done over hereã€‚

 it is just giving you the name because we have group by nameã€‚

 And this dot sum will just get applied on this particular salaryã€‚ Nowã€‚

 if I go and write dot show here you will be able to seeã€‚ğŸ˜Šã€‚

Sudanhu over here is having the highest salary of 35000ã€‚ Sunny has 12000ã€‚ Krissh has 19000ã€‚

 Mahesh has 7000ã€‚ So if you go and see over hereï¼Œ Sudanhu is basically present hereã€‚

 here and in big dataã€‚ So overallï¼Œ his salary should be 35000 if you compute it Similarlylyã€‚

 you can go and compute my salary over hereã€‚ğŸ¤§Over here by just calculating thisã€‚

 and then you can also compute sunny salaryã€‚ and you can also see my Hã€‚

 So this is one just an exampleã€‚ So here I'll just writeã€‚ we have groupedã€‚Do fineã€‚The maximum salaryã€‚

AndDefinite over here from this entire observationã€‚

 we can retrieve that Sudanhi is having the highest salaryã€‚ Okayï¼Œ now let's go to one step aheadã€‚

 one more step aheadã€‚ now we will try to group by departments to find out which department gives maximum salary Okayã€‚

 we are going to do a group byã€‚Departmentsã€‚Which gives maximum salaryã€‚ Suppose this is myã€‚

This is my requirementã€‚ Okayï¼Œ and different different types of requirement makeup upã€‚

 I'm just trying to show you some examplesã€‚ So I'm just going to copy thisã€‚å— going doã€‚

Use this departmentã€‚Okayï¼Œ and then I'm basically going to say dot sum dot showã€‚

 If I execute it let me see department is a wrong column name so I'll write department it is department So let me write S now if I go and see Iot over here gives some salary around115000 to this employees to all the employees right combined because we are doing the sum big data gives somewhere around 15000 data science gifts Im around 4300 Now suppose if I go and see big data over here 404080008000 and 13000ã€‚

130015000 so I hope I'm getting yesï¼Œ big data is actually giving us 15000 so you can go and calculate it suppose if you want to find out the mean you can also find out the mean okayã€‚

 so let me just write it over hereï¼Œ just copy this entire thing paste it over here and write me write instead of instead of sum I'll write to write mean so by default the mean salaryã€‚

Here you can see that for a particular employee somewhere for I O T to 7500ã€‚

 because this mean will be based on how many number of people are working in the departmentï¼Œ rightã€‚

 So like thisï¼Œ you can actually find out Nowï¼Œ I can also check one more thingã€‚ guysï¼Œ I can copy thisã€‚

 I can try to find out how many number ofã€‚Employees are actually working based on the departmentã€‚

 so I can use dot countã€‚ And then if I go and execute thisï¼Œ probably this is a methodã€‚Okayã€‚

Now here you will be seeing that in Io there are two people in big data there are four people in data science they are four peopleã€‚

 so4 plus 4 plus8 total employees that are present over here is basically 10ã€‚Nowã€‚

 one more way that I can basically apply a directly aggregate function also to seeã€‚

 these are all some of the examples and againï¼Œ you can do different different group by let me use Df Pparã€‚

 suppose I say dot aggregate okayï¼Œ and inside this I will just give my key value pairs like thisã€‚

 suppose I say let me say that salaryï¼Œ I want to find out the sum of the salariesã€‚

The overall salary that is basically given to the entire total expenditure insertã€‚

 So the total expenditure that you will be able to see somewhere around 73000 alrightã€‚

 so we can also apply direct aggregate functionï¼Œ otherwise this all are also aggregate function which we basically apply after after you know applying a group by function now suppose this are probably the salary I want to find out suppose I'll take this example I want to find out the maximum salary that the person is basically getting who is getting the maximum salary sorryã€‚

So here instead of writing dot sum now I'll write max dot show now here you can see Sudansha is basically getting 20000 over here10000 Krisish is getting 10000 my is getting for 4000 right so all this particular data is theyy Kris is basically getting with respect to data science over here 10000 so it has basically picked up it is not picking up both the records but at least when it is grouping by name and then it is showing this particular data that time you will be able to see it let's see whether Ill be also able to see this or notã€‚

So group byï¼Œ if I score and write minã€‚So here you will be able to see minimum value with respect to different different records when Im grouping by here you will be able to see that Suanhu sorryã€‚

 Sudanhu is getting a minimum salary of 50002000 Kris is getting a minimum salary of 4000 rightã€‚

 we can also get that particular informationã€‚ Now let's see what all different different types of operation are thereã€‚

Average is also thereã€‚ So if I write A V Gï¼Œ it's just like mean only guysã€‚

 So this is basically the mean salary that probably againã€‚Againã€‚

 you can check out different different functionalities why these all things are basically requiredã€‚

 Under one thing is that you really need to do a lot of data preprosing a lot of retrieving skills that you basically doã€‚

 You can check it out this one and you can do different different functionalities as you likeã€‚

 So I hope you like this particular video Probably in the next video I'm going to start with spark Mlib libraries where we'll be solving some machine learning algorithm problemsã€‚



![](img/1babe07f0737b77a8ca240e4a3c70599_6.png)

So I hope you like this particular video I'll see you all in the next weekã€‚

 Have a great day thank you babaã€‚