- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P70ï¼šL13.4- ä½•æ—¶é‡æ–°è®­ç»ƒæ‚¨çš„ç¥ç»ç½‘ç»œ
    - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P70ï¼šL13.4- ä½•æ—¶é‡æ–°è®­ç»ƒæ‚¨çš„ç¥ç»ç½‘ç»œ
    - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonã€‚ Welcome to applications of deep neural Network with
    Washington Universityã€‚ In this videoï¼Œ we're going to take a look at howï¼Œ you know
    when this neural network that you've moved into production is perhaps not being
    as efficient as it had been in the pastã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ã€‚æ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨è¯¾ç¨‹ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ä½ å·²æŠ•å…¥ç”Ÿäº§çš„ç¥ç»ç½‘ç»œæ˜¯å¦ä»ç„¶é«˜æ•ˆã€‚
- en: We're going to look at model drift and what to do about it For the latest on
    my AI course and projectsã€‚ Click subscribe in the bell next to it to be notified
    of every new video continuing along with our topic of deployment in this moduleã€‚
    We're going to look at when we should retrain a neural networkã€‚ Nowã€‚ if you just
    have a data set like the auto Miles per gallon or the Iis or any of these sample
    data sets that you download and work withã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è®¨è®ºæ¨¡å‹æ¼‚ç§»ä»¥åŠå¦‚ä½•åº”å¯¹å®ƒã€‚æœ‰å…³æˆ‘æœ€æ–°çš„äººå·¥æ™ºèƒ½è¯¾ç¨‹å’Œé¡¹ç›®ï¼Œè¯·ç‚¹å‡»é“ƒé“›æ—çš„è®¢é˜…ï¼Œä»¥ä¾¿åœ¨æ¯ä¸ªæ–°è§†é¢‘å‘å¸ƒæ—¶æ”¶åˆ°é€šçŸ¥ï¼Œç»§ç»­æˆ‘ä»¬åœ¨æœ¬æ¨¡å—ä¸­å…³äºéƒ¨ç½²çš„ä¸»é¢˜ã€‚æˆ‘ä»¬å°†æ¢è®¨ä½•æ—¶åº”è¯¥é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚ç°åœ¨ï¼Œå¦‚æœä½ ä»…æœ‰åƒæ±½è½¦æ¯åŠ ä»‘è‹±é‡Œæ•°ï¼ˆMiles
    per gallonï¼‰æˆ–Iisç­‰è¿™äº›æ ·æœ¬æ•°æ®é›†ï¼Œä¸‹è½½åè¿›è¡Œå¤„ç†ã€‚
- en: ğŸ˜Šã€‚![](img/de3c5a0770101a2c095d10c9f95e8614_1.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šã€‚![](img/de3c5a0770101a2c095d10c9f95e8614_1.png)
- en: You're not going to know really when you need to retrain your modelã€‚ For exampleã€‚
    the miles per gallon data set that we've worked with a number of times it has
    stats on cars that help you determine what the miles per gallon isã€‚ most of the
    data from this data set is from the late 1970s and early 1980sã€‚ Yesã€‚ you almost
    certainly need to retrain that model from modern dataã€‚ but for that closed data
    setã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸ä¼šçœŸçš„çŸ¥é“ä½•æ—¶éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ›¾å¤šæ¬¡ä½¿ç”¨çš„æ¯åŠ ä»‘è‹±é‡Œæ•°æ•°æ®é›†ï¼Œå…¶ä¸­æœ‰å…³äºæ±½è½¦çš„ç»Ÿè®¡æ•°æ®ï¼Œå¸®åŠ©ä½ ç¡®å®šæ¯åŠ ä»‘çš„è¡Œé©¶é‡Œç¨‹ã€‚è¯¥æ•°æ®é›†çš„å¤§éƒ¨åˆ†æ•°æ®æ¥è‡ª1970å¹´ä»£æœ«å’Œ1980å¹´ä»£åˆã€‚æ˜¯çš„ï¼Œä½ å‡ ä¹å¯ä»¥è‚¯å®šéœ€è¦ä½¿ç”¨ç°ä»£æ•°æ®æ¥é‡æ–°è®­ç»ƒè¯¥æ¨¡å‹ï¼Œä½†å¯¹äºè¯¥å°é—­æ•°æ®é›†æ¥è¯´ã€‚
- en: the model is as good as it's ever going to getã€‚ The problem is that as time
    marches on changes occur in the distributions of your dataã€‚ and your incoming
    new data that you're trying to get real scores for is differentã€‚ And this is a
    very common problem that you need to deal with as you develop models that are
    going to be used in real business ongoing applicationsã€‚ I work in the life insurance
    industryï¼Œ and I'll give you an example of it for thisã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„æ€§èƒ½å·²ç»è¾¾åˆ°äº†æé™ã€‚é—®é¢˜åœ¨äºï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œä½ çš„æ•°æ®åˆ†å¸ƒå‘ç”Ÿäº†å˜åŒ–ï¼Œè€Œä½ è¯•å›¾è·å¾—çœŸå®åˆ†æ•°çš„æ–°æ•°æ®æ˜¯ä¸åŒçš„ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æ™®éçš„é—®é¢˜ï¼Œä½ éœ€è¦åœ¨å¼€å‘å°†åœ¨å®é™…ä¸šåŠ¡ä¸­æŒç»­åº”ç”¨çš„æ¨¡å‹æ—¶å¤„ç†ã€‚æˆ‘åœ¨å¯¿é™©è¡Œä¸šå·¥ä½œï¼Œç»™ä½ ä¸¾ä¸ªä¾‹å­ã€‚
- en: So as your data for an individual So we're trying to determine what the risk
    of ensuringã€‚Individual for life insurance isï¼Œ so that's the risk essentially of
    them dying mortality risk we often call it if the person is really fairly average
    in terms of the input data that you're giving on they're not a smoke or their
    average height their average weight or average build your neural network is going
    to tend towards giving predictions that are really pretty average for this person
    Well average tends to change as you look at health trends over the yearsã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ­£åœ¨è¯•å›¾ç¡®å®šä¸ªäººçš„å¯¿é™©é£é™©ã€‚åŸºæœ¬ä¸Šï¼Œè¿™æ˜¯ä»–ä»¬çš„æ­»äº¡é£é™©ï¼Œæˆ‘ä»¬é€šå¸¸ç§°ä¹‹ä¸ºæ­»äº¡ç‡é£é™©ã€‚å¦‚æœè¿™ä¸ªäººå°±åƒä½ æä¾›çš„è¾“å…¥æ•°æ®é‚£æ ·ï¼Œç®—æ˜¯æ¯”è¾ƒæ™®é€šçš„ï¼Œä¸å¸çƒŸï¼Œèº«é«˜ã€ä½“é‡æˆ–ä½“å‹éƒ½åœ¨å¹³å‡èŒƒå›´å†…ï¼Œé‚£ä¹ˆä½ çš„ç¥ç»ç½‘ç»œä¼šå€¾å‘äºç»™å‡ºå¯¹è¿™ä¸ªäººç›¸å¯¹æ™®é€šçš„é¢„æµ‹ã€‚ç„¶è€Œï¼Œéšç€å¥åº·è¶‹åŠ¿çš„å˜åŒ–ï¼Œå¹³å‡æ°´å¹³ä¹Ÿåœ¨ä¸æ–­å˜åŒ–ã€‚
- en: mortality is improving more and more people tend to be living towards advanced
    yearsã€‚ the advanced year is still relatively in the same range that it has been
    for a whileã€‚ but more people are living to that high end of that range and also
    smoking is declining all these things togetherã€‚ change over time and this affect
    with the ground truth so to speak is that your neural network predicting towards
    so as this ground truth moves you need to potentially retrain your neural network
    with newer data everyã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ­»äº¡ç‡æ­£åœ¨æ”¹å–„ï¼Œè¶Šæ¥è¶Šå¤šçš„äººå€¾å‘äºæ´»åˆ°è€å¹´ã€‚è€å¹´äººçš„æ ‡å‡†ä»ç„¶ä¸ä¸€æ®µæ—¶é—´ä»¥æ¥çš„èŒƒå›´ç›¸å¯¹ä¸€è‡´ï¼Œä½†è¶Šæ¥è¶Šå¤šçš„äººæ´»åˆ°è¿™ä¸ªèŒƒå›´çš„é«˜ç«¯ï¼Œå¸çƒŸç‡ä¹Ÿåœ¨ä¸‹é™ã€‚æ‰€æœ‰è¿™äº›å› ç´ éšç€æ—¶é—´çš„æ¨ç§»è€Œå˜åŒ–ï¼Œè¿™å½±å“äº†æ‰€è°“çš„â€œçœŸå®æƒ…å†µâ€ï¼Œä½ çš„ç¥ç»ç½‘ç»œçš„é¢„æµ‹ä¹Ÿéšä¹‹è°ƒæ•´ã€‚å› æ­¤ï¼Œéšç€çœŸå®æƒ…å†µçš„å˜åŒ–ï¼Œä½ å¯èƒ½éœ€è¦ç”¨æ›´æ–°çš„æ•°æ®é‡æ–°è®­ç»ƒä½ çš„ç¥ç»ç½‘ç»œã€‚
- en: F years look at how you determine when this is happeningã€‚ Nowã€‚ when you will
    see this in a closed datasetã€‚ So a dataset where you are given the data and you're
    never going to see any new data for this ever againã€‚ That's not a realistic situation
    in business when you're doing this in the real worldã€‚ Usually you're building
    a model because you expect new data if you didn't expect new dataã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Få¹´çœ‹çœ‹ä½ å¦‚ä½•ç¡®å®šä½•æ—¶å‘ç”Ÿè¿™ç§æƒ…å†µã€‚ç°åœ¨ï¼Œå½“ä½ åœ¨ä¸€ä¸ªå°é—­çš„æ•°æ®é›†ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹æ—¶ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ä¸€ä¸ªä½ è·å–æ•°æ®åå†ä¹Ÿä¸ä¼šçœ‹åˆ°æ–°æ•°æ®çš„æ•°æ®é›†ã€‚è¿™åœ¨å•†ä¸šä¸­å¹¶ä¸æ˜¯ä¸€ä¸ªç°å®çš„æƒ…å†µï¼Œå°¤å…¶æ˜¯åœ¨ç°å®ä¸–ç•Œä¸­ã€‚é€šå¸¸ä½ å»ºç«‹æ¨¡å‹æ˜¯å› ä¸ºä½ é¢„æœŸä¼šæœ‰æ–°æ•°æ®ï¼Œå¦‚æœä½ ä¸é¢„æœŸæœ‰æ–°æ•°æ®ã€‚
- en: why would you build the model in the first placeï¼Œ predicting closed data sets
    is interestingã€‚ but it lacks a lot of practical application Nowï¼Œ the only time
    when you will use these techniques on a closed data is where you have a defined
    test and training setã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆä½ ä¸ºä»€ä¹ˆè¦å»ºç«‹è¿™ä¸ªæ¨¡å‹å‘¢ï¼Ÿé¢„æµ‹å°é—­æ•°æ®é›†æ˜¯æœ‰è¶£çš„ï¼Œä½†ç¼ºä¹å¾ˆå¤šå®é™…åº”ç”¨ã€‚ç°åœ¨ï¼Œåªæœ‰åœ¨ä½ æ‹¥æœ‰ä¸€ä¸ªæ˜ç¡®çš„æµ‹è¯•å’Œè®­ç»ƒé›†æ—¶ï¼Œä½ æ‰ä¼šåœ¨å°é—­æ•°æ®ä¸Šä½¿ç”¨è¿™äº›æŠ€æœ¯ã€‚
- en: Some of the data sets that we've seenï¼Œ particularly some of the academic onesã€‚
    they define what your training set looks like and what your test looks likeã€‚ So
    you want to look at has any shift occurred between your training in your testã€‚
    This is often done in kleã€‚ So let's look at this diagram hereã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°çš„ä¸€äº›æ•°æ®é›†ï¼Œå°¤å…¶æ˜¯ä¸€äº›å­¦æœ¯æ•°æ®é›†ã€‚å®ƒä»¬å®šä¹‰äº†ä½ çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ·å­ã€‚æ‰€ä»¥ä½ è¦è§‚å¯Ÿä½ çš„è®­ç»ƒå’Œæµ‹è¯•ä¹‹é—´æ˜¯å¦å‘ç”Ÿäº†ä»»ä½•å˜åŒ–ã€‚è¿™é€šå¸¸åœ¨KLEä¸­å®Œæˆã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå›¾è¡¨ã€‚
- en: This is a diagram that appears I gaveã€‚source to itã€‚ it's from a paper written
    specifically on looking at data and covariance shiftsã€‚ These are to names for
    this sort of phenomenonï¼Œ somewhat differentã€‚ but the greenã€‚ the learned functionã€‚
    So this is using a very linear modelã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ç»™å‡ºçš„ä¸€ä¸ªå›¾è¡¨ã€‚æˆ‘ç»™å‡ºäº†æ¥æºï¼Œå®ƒæ¥è‡ªäºä¸€ç¯‡ä¸“é—¨ç ”ç©¶æ•°æ®å’Œåæ–¹å·®å˜åŒ–çš„è®ºæ–‡ã€‚è¿™äº›æ˜¯è¿™ç§ç°è±¡çš„ä¸¤ä¸ªåç§°ï¼Œè™½ç„¶æœ‰äº›ä¸åŒï¼Œä½†ç»¿è‰²çš„éƒ¨åˆ†æ˜¯å­¦ä¹ åˆ°çš„å‡½æ•°ã€‚å› æ­¤è¿™ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªéå¸¸çº¿æ€§çš„æ¨¡å‹ã€‚
- en: So you'll have a lot of bias in this becauses very linear modelï¼Œ but that's
    okay the true functionã€‚ So what really it should be learning is this redã€‚ but
    look what happens essentially over timeã€‚ And unfortunatelyï¼Œ the test samples occur
    a little bit later in time than the blue training samplesã€‚ So you learn the function
    on the blue dotsã€‚ But the reality is and even the true function you don't have
    much representation of it over hereã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨è¿™ä¸ªéå¸¸çº¿æ€§çš„æ¨¡å‹ä¸­ä½ ä¼šæœ‰å¾ˆå¤šåå·®ï¼Œä½†æ²¡å…³ç³»ï¼ŒçœŸå®çš„å‡½æ•°ã€‚æ‰€ä»¥å®ƒçœŸæ­£åº”è¯¥å­¦ä¹ çš„æ˜¯è¿™ä¸ªçº¢è‰²çš„éƒ¨åˆ†ã€‚ä½†çœ‹çœ‹éšæ—¶é—´çš„æ¨ç§»å‘ç”Ÿäº†ä»€ä¹ˆã€‚ä¸å¹¸çš„æ˜¯ï¼Œæµ‹è¯•æ ·æœ¬å‡ºç°åœ¨æ—¶é—´ä¸Šæ¯”è“è‰²è®­ç»ƒæ ·æœ¬ç¨æ™šã€‚æ‰€ä»¥ä½ æ˜¯åœ¨è“ç‚¹ä¸Šå­¦ä¹ è¿™ä¸ªå‡½æ•°ã€‚ä½†ç°å®æ˜¯ï¼Œç”šè‡³çœŸå®å‡½æ•°åœ¨è¿™é‡Œçš„ä»£è¡¨æ€§ä¹Ÿå¾ˆå°‘ã€‚
- en: you have no representation at all hardly hereã€‚ So you're going learn this very
    linear functionã€‚ Now there's definitely some noiseã€‚ nothing's right on the linear
    function hardlyã€‚ But nonetheless this is trying to minimize your residual so that
    the distances between every dot and the line is about averagedã€‚the dots above
    and the dots belowã€‚ But then when you get out hereã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨è¿™é‡Œå‡ ä¹æ²¡æœ‰ä»»ä½•ä»£è¡¨æ€§ã€‚å› æ­¤ä½ å°†å­¦ä¹ è¿™ä¸ªéå¸¸çº¿æ€§çš„å‡½æ•°ã€‚ç°åœ¨è¿™é‡Œç¡®å®æœ‰ä¸€äº›å™ªå£°ã€‚å‡ ä¹æ²¡æœ‰ä¸€ä¸ªç‚¹å®Œå…¨ç¬¦åˆçº¿æ€§å‡½æ•°ã€‚ä½†å°½ç®¡å¦‚æ­¤ï¼Œè¿™ä»åœ¨å°½é‡æœ€å°åŒ–ä½ çš„æ®‹å·®ï¼Œä½¿å¾—æ¯ä¸ªç‚¹ä¸çº¿ä¹‹é—´çš„è·ç¦»å¤§è‡´å¹³å‡ï¼Œåœ¨çº¿ä¸Šæ–¹çš„ç‚¹å’Œä¸‹æ–¹çš„ç‚¹ä¹‹é—´ã€‚ä½†æ˜¯å½“ä½ åˆ°è¾¾è¿™é‡Œæ—¶ã€‚
- en: you get to a different part of this functionã€‚ for some reason in timeã€‚ usually
    it's some variable that you're simply not capturing or you can't captureã€‚ now
    the trend is more this direction so you probably need to collect more data and
    reffi it and use a nonlinear model so that you can get this curvature built into
    your model and get more predictive dataã€‚ because if if you look at where this
    red line is now goingï¼Œ who knows is it going continue downã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šå‘ç°è¿™ä¸ªå‡½æ•°çš„ä¸åŒéƒ¨åˆ†ã€‚å‡ºäºæŸç§åŸå› ï¼Œæ—¶é—´ä¸Šé€šå¸¸æ˜¯æŸä¸ªå˜é‡ä½ æ²¡æœ‰æ•è·æˆ–è€…æ— æ³•æ•è·ã€‚ç°åœ¨çš„è¶‹åŠ¿æ›´å¤šåœ°æœè¿™ä¸ªæ–¹å‘å‘å±•ï¼Œæ‰€ä»¥ä½ å¯èƒ½éœ€è¦æ”¶é›†æ›´å¤šæ•°æ®ï¼Œé‡æ–°è°ƒæ•´å¹¶ä½¿ç”¨éçº¿æ€§æ¨¡å‹ï¼Œä»¥ä¾¿å°†è¿™ç§æ›²ç‡èå…¥æ¨¡å‹ä¸­ï¼Œä»è€Œè·å¾—æ›´å¤šçš„é¢„æµ‹æ•°æ®ã€‚å› ä¸ºå¦‚æœä½ çœ‹çœ‹è¿™æ¡çº¢çº¿ç°åœ¨çš„èµ°åŠ¿ï¼Œè°çŸ¥é“å®ƒæ˜¯å¦ä¼šç»§ç»­ä¸‹é™ã€‚
- en: maybe it's going to retake this shape hereã€‚ And if it doesã€‚ then our first model
    would not be so badã€‚ but you need probably something to look at that new segment
    in time that the ground truth has now shifted forã€‚ So how do we measure this driftã€‚
    I give you a whole bunch of different techniques for thisã€‚ I'm not going to go
    through every one of these in the courseã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸å®ƒä¼šé‡æ–°å‘ˆç°è¿™ä¸ªå½¢çŠ¶ã€‚å¦‚æœæ˜¯è¿™æ ·ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ä¹Ÿè®¸å¹¶ä¸ç®—å¤ªå·®ã€‚ä½†ä½ å¯èƒ½éœ€è¦å…³æ³¨è¿™ä¸ªæ—¶é—´æ®µå†…æ–°çš„ç‰‡æ®µï¼Œå› ä¸ºçœŸå®æƒ…å†µå·²ç»å‘ç”Ÿäº†å˜åŒ–ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•è¡¡é‡è¿™ç§æ¼‚ç§»å‘¢ï¼Ÿæˆ‘ç»™ä½ æä¾›äº†ä¸€ç³»åˆ—ä¸åŒçš„æŠ€æœ¯ï¼Œä½†æˆ‘ä¸ä¼šåœ¨è¯¾ç¨‹ä¸­é€ä¸€ä»‹ç»è¿™äº›ã€‚
- en: but just to give you an initial sort of literature review of those those are
    some of the ones to potentially look at this is a particularly good paperã€‚ifying
    view and data shift This tries to look at really all of these and come up with
    the commonalities of thoseã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åªæ˜¯ç»™ä½ ä¸€ä¸ªåˆæ­¥çš„æ–‡çŒ®ç»¼è¿°ï¼Œè¿™äº›æ˜¯ä¸€äº›å¯èƒ½å€¼å¾—å…³æ³¨çš„æ–‡çŒ®ã€‚è¿™æ˜¯ä¸€ç¯‡ç‰¹åˆ«å¥½çš„è®ºæ–‡ï¼Œå°è¯•æŸ¥çœ‹æ‰€æœ‰è¿™äº›å†…å®¹å¹¶æ€»ç»“å‡ºå®ƒä»¬çš„å…±åŒç‚¹ã€‚
- en: Now to look at this since it's difficult really for me to do a inclass example
    where we're getting a training set and then collecting new data and continue thought
    about doing this with the autompG data and we might get into this So we're going
    to use a Cagel data and we're going to analyze and see how different the distributions
    of some of these predictors change between the training set and the test set this
    becomes an important consideration when you're competing and a Cagelã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¥çœ‹è¿™ä¸ªï¼Œå› ä¸ºæˆ‘åœ¨è¯¾å ‚ä¸Šåšä¸€ä¸ªç¤ºä¾‹æ—¶çœŸçš„å¾ˆå›°éš¾ï¼Œæˆ‘ä»¬è·å–è®­ç»ƒé›†ï¼Œç„¶åæ”¶é›†æ–°æ•°æ®ï¼Œè€ƒè™‘ç”¨ autompG æ•°æ®æ¥åšè¿™ä¸ªï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè¿›å…¥è¿™ä¸ªã€‚æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨
    Cagel æ•°æ®ï¼Œåˆ†æå¹¶çœ‹çœ‹ä¸€äº›é¢„æµ‹å˜é‡çš„åˆ†å¸ƒåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´å¦‚ä½•å˜åŒ–ï¼Œè¿™åœ¨ä½ å‚åŠ  Cagel ç«èµ›æ—¶æˆä¸ºä¸€ä¸ªé‡è¦è€ƒè™‘å› ç´ ã€‚
- en: So we're going to use the sharebank Russian housing market data set just to
    show you that kgle it is essentially looking at can you predict Real price fluctuation
    in Russia's volatile market if you look at the data They give you a whole bunch
    really of input values hereã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ sharebank ä¿„ç½—æ–¯ä½æˆ¿å¸‚åœºæ•°æ®é›†ï¼Œåªæ˜¯ä¸ºäº†å‘ä½ å±•ç¤º kgle å®é™…ä¸Šæ˜¯åœ¨çœ‹ä½ èƒ½å¦é¢„æµ‹ä¿„ç½—æ–¯æ³¢åŠ¨å¸‚åœºä¸­çš„å®é™…ä»·æ ¼æ³¢åŠ¨ã€‚å¦‚æœä½ æŸ¥çœ‹æ•°æ®ï¼Œä»–ä»¬ç»™ä½ æä¾›äº†å¾ˆå¤šè¾“å…¥å€¼ã€‚
- en: they scroll acrossã€‚ So those are all the columns in the distributionsã€‚ We're
    going to be looking at those there areã€‚Hred total columnsã€‚ So it's got a lot of
    columns that you're dealing withã€‚ I always like to go to the overview and see
    what the evaluation isã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬åœ¨æ»šåŠ¨ã€‚å› æ­¤ï¼Œè¿™äº›å°±æ˜¯åˆ†å¸ƒä¸­çš„æ‰€æœ‰åˆ—ã€‚æˆ‘ä»¬å°†å…³æ³¨è¿™äº›åˆ—ã€‚Hred æ€»åˆ—ã€‚æ‰€ä»¥ä½ è¦å¤„ç†çš„åˆ—å¾ˆå¤šã€‚æˆ‘æ€»æ˜¯å–œæ¬¢æŸ¥çœ‹æ¦‚è¿°ï¼Œçœ‹çœ‹è¯„ä¼°æ˜¯ä»€ä¹ˆã€‚
- en: They're using RMSLE RMS logithmic errorã€‚ This is it's a regression errorã€‚ It's
    not a real common oneã€‚ And I had to go to the Cagel forms actually to find this
    The link on the competition actually results in a 404 page not found According
    to Cagel on definition from this RMSL penalizes under predicted estimate greater
    than an over predicteddictedã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ä½¿ç”¨ RMSLE RMS å¯¹æ•°è¯¯å·®ã€‚è¿™æ˜¯å›å½’è¯¯å·®ã€‚å®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªå¸¸è§çš„è¯¯å·®ã€‚æˆ‘å®é™…ä¸Šå¿…é¡»å» Cagel è®ºå›æŸ¥æ‰¾è¿™ä¸ªã€‚æ¯”èµ›ä¸­çš„é“¾æ¥å®é™…ä¸Šå¯¼è‡´äº†ä¸€ä¸ª 404
    é¡µé¢æœªæ‰¾åˆ°ã€‚æ ¹æ® Cagel çš„å®šä¹‰ï¼Œè¿™ä¸ª RMSL å¯¹ä½ä¼°çš„ä¼°è®¡çš„æƒ©ç½šå¤§äºå¯¹é«˜ä¼°çš„æƒ©ç½šã€‚
- en: So its it's like RMS more log scale and then really not going to deal with it
    a great deal because we are just looking at the shift between the train in the
    testã€‚ So we won't even really look at the targetã€‚ So the evaluation for this cale
    is really not important for the example that I'm going to give you Now you will
    have to download this data because it comes from Caleã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒå°±åƒ RMS æ›´å¤šæ˜¯å¯¹æ•°å°ºåº¦ï¼Œç„¶åå®é™…ä¸Šä¸ä¼šå¤ªå¤šå¤„ç†å®ƒï¼Œå› ä¸ºæˆ‘ä»¬åªæ˜¯çœ‹è®­ç»ƒå’Œæµ‹è¯•ä¹‹é—´çš„å·®å¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç”šè‡³ä¸ä¼šçœŸæ­£å…³æ³¨ç›®æ ‡ã€‚å¯¹äºæˆ‘å°†ç»™ä½ çš„ç¤ºä¾‹æ¥è¯´ï¼Œè¿™ä¸ªè¯„ä¼°å®é™…ä¸Šå¹¶ä¸é‡è¦ã€‚ç°åœ¨ä½ å¿…é¡»ä¸‹è½½è¿™ä¸ªæ•°æ®ï¼Œå› ä¸ºå®ƒæ¥è‡ª
    Caleã€‚
- en: I can't just build it into the course getthubã€‚ So I'm going to run thisã€‚ I already
    had myã€‚![](img/de3c5a0770101a2c095d10c9f95e8614_3.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸èƒ½ç›´æ¥å°†å…¶æ„å»ºåˆ°è¯¾ç¨‹çš„ GitHub ä¸­ã€‚æ‰€ä»¥æˆ‘å°†è¿è¡Œè¿™ä¸ªã€‚æˆ‘å·²ç»æœ‰æˆ‘çš„ã€‚![](img/de3c5a0770101a2c095d10c9f95e8614_3.png)
- en: Train and test loadedã€‚ I'm literally pulling it right out of the downloads directory
    on my mathã€‚ That's a temporary location for meï¼Œ but it does what I what I wanted
    to doã€‚ There's a lot of examples on this particular kggle of how to preproces
    the data I do a fairly basic preprocessing So if it's an object type that means
    that it's some sort of a category So I am going to fill Ns with the mode or the
    most common valueã€‚ if it's an integer afloat then we're going to fill in the media
    media is good to use over mean because medium is less sensitive to outliersã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå’Œæµ‹è¯•å·²åŠ è½½ã€‚æˆ‘å®é™…ä¸Šæ˜¯ç›´æ¥ä»æˆ‘çš„æ•°å­¦ä¸‹è½½ç›®å½•ä¸­æå–çš„ã€‚è¿™å¯¹æˆ‘æ¥è¯´æ˜¯ä¸€ä¸ªä¸´æ—¶ä½ç½®ï¼Œä½†å®ƒå®Œæˆäº†æˆ‘æƒ³åšçš„äº‹æƒ…ã€‚åœ¨è¿™ä¸ªç‰¹å®šçš„ kggle ä¸Šæœ‰å¾ˆå¤šé¢„å¤„ç†æ•°æ®çš„ç¤ºä¾‹ï¼Œæˆ‘åšäº†ä¸€ä¸ªç›¸å¯¹åŸºæœ¬çš„é¢„å¤„ç†ã€‚å¦‚æœå®ƒæ˜¯å¯¹è±¡ç±»å‹ï¼Œé‚£å°±æ„å‘³ç€å®ƒæ˜¯æŸç§ç±»åˆ«ã€‚å› æ­¤ï¼Œæˆ‘å°†ç”¨ä¼—æ•°æˆ–æœ€å¸¸è§çš„å€¼å¡«å……ç¼ºå¤±å€¼ã€‚å¦‚æœæ˜¯æ•´æ•°æˆ–æµ®ç‚¹æ•°ï¼Œæˆ‘ä»¬å°†ç”¨ä¸­ä½æ•°å¡«å……ã€‚ä¸­ä½æ•°åœ¨å‡å€¼ä¸Šæ›´å¥½ï¼Œå› ä¸ºä¸­ä½æ•°å¯¹å¼‚å¸¸å€¼çš„æ•æ„Ÿæ€§è¾ƒä½ã€‚
- en: Then we're going to go through and label and code essentially all of the categorical
    So we're not creating dummies we're actually label encoding them so that we end
    up with a integer value specifying what location they areã€‚ I won't get into why
    that was actually chosenï¼Œ but these were the common encodings that were used in
    this particular competitionã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†å¯¹æ‰€æœ‰ç±»åˆ«è¿›è¡Œæ ‡è®°å’Œç¼–ç ã€‚å› æ­¤æˆ‘ä»¬å¹¶ä¸åˆ›å»ºè™šæ‹Ÿå˜é‡ï¼Œè€Œæ˜¯è¿›è¡Œæ ‡ç­¾ç¼–ç ï¼Œä»¥ä¾¿æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæ•´æ•°å€¼ï¼ŒæŒ‡æ˜å®ƒä»¬çš„ä½ç½®ã€‚æˆ‘ä¸ä¼šæ·±å…¥è®¨è®ºä¸ºä»€ä¹ˆå®é™…ä¸Šé€‰æ‹©äº†è¿™ä¸ªï¼Œä½†è¿™äº›æ˜¯è¿™ä¸ªç‰¹å®šç«èµ›ä¸­ä½¿ç”¨çš„å¸¸è§ç¼–ç ã€‚
- en: I believe they shied away from dummies because they were simply too many dimensionsã€‚
    So we'll run this so those two functions are defined or that one function is defined
    and then we'll preprocess the dataã€‚We're going to drop the target because we're
    not trying to predict at this point nextã€‚ we're going to calculate something called
    the chaoss statisticã€‚ Nowï¼Œ when I first heard thisã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç›¸ä¿¡ä»–ä»¬å›é¿äº†è™šæ‹Ÿå˜é‡ï¼Œå› ä¸ºç»´åº¦å®åœ¨å¤ªå¤šäº†ã€‚æ‰€ä»¥æˆ‘ä»¬å°†è¿è¡Œè¿™äº›å‡½æ•°ä»¥å®šä¹‰ï¼Œç„¶åè¿›è¡Œæ•°æ®é¢„å¤„ç†ã€‚æˆ‘ä»¬å°†ä¸¢å¼ƒç›®æ ‡ï¼Œå› ä¸ºæ­¤æ—¶æˆ‘ä»¬å¹¶ä¸æƒ³è¿›è¡Œé¢„æµ‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¡ç®—ç§°ä¸ºæ··æ²Œç»Ÿè®¡é‡çš„ä¸œè¥¿ã€‚ç°åœ¨ï¼Œå½“æˆ‘ç¬¬ä¸€æ¬¡å¬åˆ°è¿™ä¸ªæ—¶ã€‚
- en: I thought of chaos statistic like COSã€‚ but this is the chaos Ks statistic It
    is essentially looking at how similar are the distributions between two thingsã€‚
    So let's just do a sanity checkã€‚ If I just run this oneã€‚ I am saying what is the
    chaos statistic between the kitchen square feet and the kitchen square feetã€‚ So
    what is the chaos statistic between itselfã€‚ So P valueï¼Œ it has to be below a certain
    thresholdã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æŠŠæ··æ²Œç»Ÿè®¡é‡æƒ³è±¡æˆCOSï¼Œä½†è¿™æ˜¯æ··æ²ŒKsç»Ÿè®¡é‡ï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯åœ¨æŸ¥çœ‹ä¸¤ä¸ªäº‹ç‰©ä¹‹é—´çš„åˆ†å¸ƒæœ‰å¤šç›¸ä¼¼ã€‚æ‰€ä»¥è®©æˆ‘ä»¬åšä¸€ä¸ªåˆç†æ€§æ£€æŸ¥ã€‚å¦‚æœæˆ‘ä»…è¿è¡Œè¿™ä¸ªï¼Œæˆ‘åœ¨é—®å¨æˆ¿å¹³æ–¹è‹±å°ºä¸å¨æˆ¿å¹³æ–¹è‹±å°ºä¹‹é—´çš„æ··æ²Œç»Ÿè®¡é‡æ˜¯å¤šå°‘ã€‚é‚£ä¹ˆå®ƒè‡ªèº«ä¹‹é—´çš„æ··æ²Œç»Ÿè®¡é‡æ˜¯å¤šå°‘ã€‚På€¼å¿…é¡»ä½äºæŸä¸ªé˜ˆå€¼ã€‚
- en: So this is not below 0ã€‚05 This is very highã€‚ So this means that it's very unlikely
    that there are any differences between these two distributionsã€‚ Yeahï¼Œ because
    they're the same And then the statistic hereã€‚ negative0 math majors always love
    negative zerosï¼Œ but computer scientists have themã€‚ So this is 0 there is no difference
    between the two values and sense the P value is is very high thatã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å¹¶ä¸ä½äº0.05ï¼Œè¿™éå¸¸é«˜ã€‚è¿™æ„å‘³ç€è¿™ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´å‡ ä¹æ²¡æœ‰å·®å¼‚ã€‚æ˜¯çš„ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ç›¸åŒçš„ã€‚ç„¶åè¿™é‡Œçš„ç»Ÿè®¡é‡ã€‚è´Ÿé›¶æ•°å­¦ä¸“ä¸šçš„å­¦ç”Ÿæ€»æ˜¯å–œæ¬¢è´Ÿé›¶ï¼Œä½†è®¡ç®—æœºç§‘å­¦å®¶å´æœ‰å®ƒã€‚æ‰€ä»¥è¿™æ˜¯0ï¼Œä¸¤è€…ä¹‹é—´æ²¡æœ‰å·®å¼‚ï¼ŒPå€¼éå¸¸é«˜ã€‚
- en: Means the null hypothesis really cannot be rejected in this case Now let's look
    at the same columnã€‚ but we're looking at the column in the training set versus
    the test setã€‚ Now the chaos statistic is a little differentã€‚ our P value is very
    low0 and the statistic shows us that there's a 0ã€‚25 difference between them So
    this is interesting that the distribution of the kitchen square feet is quite
    different between the training set and the test setã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€åœ¨è¿™ç§æƒ…å†µä¸‹æ— æ³•æ‹’ç»é›¶å‡è®¾ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹åŒä¸€åˆ—ï¼Œä½†æˆ‘ä»¬æŸ¥çœ‹è®­ç»ƒé›†ä¸æµ‹è¯•é›†ä¸­çš„åˆ—ã€‚ç°åœ¨æ··æ²Œç»Ÿè®¡é‡ç•¥æœ‰ä¸åŒï¼Œæˆ‘ä»¬çš„På€¼éå¸¸ä½ï¼Œç»Ÿè®¡é‡æ˜¾ç¤ºå®ƒä»¬ä¹‹é—´æœ‰0.25çš„å·®å¼‚ã€‚å› æ­¤ï¼Œå¨æˆ¿å¹³æ–¹è‹±å°ºçš„åˆ†å¸ƒåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´æœ‰å¾ˆå¤§ä¸åŒï¼Œè¿™å¾ˆæœ‰è¶£ã€‚
- en: the next thing we're going to do is essentially run this on all the columns
    so we'll run a chaos statistic on everything willll only report the times where
    the p value is less than 0ã€‚05 and the case statistic is greater than 0ã€‚1 Now the
    statistic this is somewhat tied to the units of the measurement so you have to
    look at these really relative to everything else in the values that you're actually
    measuring and as it runs through you can see this works better if I shrink the
    font size but then it's harder to read but the showã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æˆ‘ä»¬è¦åšçš„åŸºæœ¬ä¸Šæ˜¯åœ¨æ‰€æœ‰åˆ—ä¸Šè¿è¡Œè¿™ä¸ªï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å¯¹æ‰€æœ‰å†…å®¹è¿è¡Œæ··æ²Œç»Ÿè®¡é‡ï¼ŒåªæŠ¥å‘ŠPå€¼ä½äº0.05ä¸”æ··æ²Œç»Ÿè®¡é‡å¤§äº0.1çš„æƒ…å†µã€‚ç°åœ¨è¿™ä¸ªç»Ÿè®¡é‡åœ¨æŸç§ç¨‹åº¦ä¸Šä¸æµ‹é‡å•ä½æœ‰å…³ï¼Œæ‰€ä»¥ä½ å¿…é¡»ç›¸å¯¹äºä½ å®é™…æµ‹é‡çš„æ‰€æœ‰å…¶ä»–å€¼æ¥çœ‹è¿™äº›ï¼Œéšç€å®ƒçš„è¿è¡Œï¼Œå¦‚æœæˆ‘ç¼©å°å­—ä½“å¤§å°å¯ä»¥çœ‹åˆ°è¿™æ•ˆæœæ›´å¥½ï¼Œä½†é˜…è¯»èµ·æ¥å°±å›°éš¾äº†ï¼Œä½†è¿™è¡¨æ˜ã€‚
- en: All of the columns and the ones that had substantial enough differencesã€‚ Nextã€‚
    we're going to look at how to detect the driftã€‚ Nowã€‚ this is a very interesting
    technique that I've seen in a number of kgglesã€‚ What we're going to do is simply
    sample the training test set into smaller setsã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰åˆ—ä»¥åŠé‚£äº›å·®å¼‚æ˜¾è‘—çš„åˆ—ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦çœ‹çœ‹å¦‚ä½•æ£€æµ‹æ¼‚ç§»ã€‚ç°åœ¨ï¼Œè¿™æ˜¯ä¸€ç§æˆ‘åœ¨è®¸å¤škaggleç«èµ›ä¸­çœ‹åˆ°çš„éå¸¸æœ‰è¶£çš„æŠ€æœ¯ã€‚æˆ‘ä»¬è¦åšçš„å°±æ˜¯ç®€å•åœ°å°†è®­ç»ƒæµ‹è¯•é›†é‡‡æ ·æˆæ›´å°çš„é›†åˆã€‚
- en: we're going to take these data sets and essentially add in another column that
    you have down here that tells us where they came fromã€‚ We're going to see if we
    can fit a modelï¼Œ a random forest in this case that can predict when all the data
    are jumbble back togetherã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿™äº›æ•°æ®é›†è¿›è¡Œå¤„ç†ï¼Œå®é™…ä¸Šæ·»åŠ ä¸€ä¸ªåœ¨è¿™é‡Œçš„å¦ä¸€åˆ—ï¼Œå‘Šè¯‰æˆ‘ä»¬å®ƒä»¬æ¥è‡ªå“ªé‡Œã€‚æˆ‘ä»¬å°†çœ‹çœ‹èƒ½å¦æ‹Ÿåˆä¸€ä¸ªæ¨¡å‹ï¼Œè¿™é‡Œæ˜¯éšæœºæ£®æ—ï¼Œå¯ä»¥åœ¨æ‰€æœ‰æ•°æ®é‡æ–°æ··åˆåè¿›è¡Œé¢„æµ‹ã€‚
- en: can it predict or an individual itemï¼Œ if it came from the test set or the training
    setã€‚ If these are truly uniform random sampled value So there is no difference
    between the training set and the test setã€‚ we simply divided it that wayï¼Œ you
    should not be able to predict where an individual row came from if you can predict
    itã€‚ then theres there's differences in the distributions there that really help
    it to lock onã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒèƒ½å¦é¢„æµ‹æŸä¸ªå•ç‹¬é¡¹æ˜¯æ¥è‡ªæµ‹è¯•é›†è¿˜æ˜¯è®­ç»ƒé›†ã€‚å¦‚æœè¿™äº›å€¼ç¡®å®æ˜¯å‡åŒ€éšæœºé‡‡æ ·çš„ï¼Œé‚£ä¹ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´å°±æ²¡æœ‰åŒºåˆ«ã€‚æˆ‘ä»¬åªæ˜¯é‚£æ ·åˆ’åˆ†çš„ï¼Œå¦‚æœä½ èƒ½é¢„æµ‹å‡ºæŸä¸€è¡Œæ¥è‡ªå“ªé‡Œï¼Œé‚£ä¹ˆåœ¨åˆ†å¸ƒä¸Šå°±å­˜åœ¨å·®å¼‚ï¼Œè¿™ç¡®å®æœ‰åŠ©äºé”å®šã€‚
- en: What set it actually came fromã€‚ Let's go ahead and just run this so we can see
    sort of what it looks likeã€‚ We're gonna label the two data setsã€‚ We're going combine
    them together and re randomdomize themã€‚ Now we need to break out the X and Y so
    that we're ready to trainã€‚ This is a classificationã€‚ So we're using area under
    the curveã€‚re considering anything above 0ã€‚75ã€‚ that's not a real good AUã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šè¿™ä¸ªè®¾ç½®æ¥è‡ªå“ªé‡Œã€‚è®©æˆ‘ä»¬ç»§ç»­æ‰§è¡Œè¿™ä¸ªæ“ä½œï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°å®ƒçš„æ ·å­ã€‚æˆ‘ä»¬å°†ç»™è¿™ä¸¤ä¸ªæ•°æ®é›†è´´ä¸Šæ ‡ç­¾ã€‚æˆ‘ä»¬å°†æŠŠå®ƒä»¬ç»„åˆåœ¨ä¸€èµ·å¹¶é‡æ–°éšæœºåŒ–ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦åˆ†å‡º
    X å’Œ Yï¼Œä»¥ä¾¿å‡†å¤‡è®­ç»ƒã€‚è¿™æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨æ›²çº¿ä¸‹é¢ç§¯ã€‚æˆ‘ä»¬è€ƒè™‘ä»»ä½•è¶…è¿‡ 0.75 çš„å€¼ã€‚é‚£å¹¶ä¸æ˜¯ä¸€ä¸ªçœŸæ­£å¥½çš„ AUã€‚
- en: but it's a good enough A you that it's breaking that it's getting onto something
    that it can really determine what that isã€‚ We're going to use each of the columns
    so that we can evaluate the errors differentlyã€‚ we can see how good each of those
    columns is it actually predicting itã€‚ So we're using the columns one by one to
    form that predictionã€‚ And as we start to run thisã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å·²ç»è¶³å¤Ÿå¥½ï¼Œèƒ½å¤Ÿçªç ´å¹¶ç¡®å®šå®ƒåˆ°åº•æ˜¯ä»€ä¹ˆã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ¯ä¸€åˆ—ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä»¥ä¸åŒçš„æ–¹å¼è¯„ä¼°é”™è¯¯ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸€åˆ—åœ¨å®é™…é¢„æµ‹ä¸­æœ‰å¤šå¥½ã€‚æ‰€ä»¥æˆ‘ä»¬é€åˆ—ä½¿ç”¨è¿™äº›åˆ—æ¥å½¢æˆé¢„æµ‹ã€‚å½“æˆ‘ä»¬å¼€å§‹è¿è¡Œè¿™ä¸ªæ—¶ã€‚
- en: we'll see different ones that really varyã€‚ Now some of this really make senseã€‚
    The I you're not going to be using the I anyway to predict the I is ever increasingã€‚
    So yeahã€‚ it's going to be very different between the train and test setã€‚ same
    thing for timetsã€‚ especially if they were takenã€‚At different regions in timeã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†çœ‹åˆ°ä¸€äº›çœŸçš„æœ‰å¾ˆå¤§å·®å¼‚çš„ä¸œè¥¿ã€‚ç°åœ¨æœ‰äº›ä¸œè¥¿ç¡®å®å¾ˆæœ‰é“ç†ã€‚ä½ ä¸ä¼šç”¨ I æ¥é¢„æµ‹ï¼Œå› ä¸º I æ˜¯ä¸æ–­å¢åŠ çš„ã€‚æ‰€ä»¥æ˜¯çš„ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´ä¼šæœ‰å¾ˆå¤§å·®å¼‚ã€‚æ—¶é—´ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œå°¤å…¶æ˜¯å¦‚æœå®ƒä»¬æ˜¯åœ¨ä¸åŒçš„æ—¶é—´æ®µå†…é‡‡é›†çš„ã€‚
- en: So the fact that the timestamp is that differentï¼Œ is that predictive means that
    it's probably not uniformly sampled across the full time frame and we see the
    other values here that are also quite able to be predicted if they're in the training
    versus the test set this can be very useful information in a kle that you know
    how to balance this to some degreeã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ—¶é—´æˆ³çš„ä¸åŒæ„å‘³ç€å®ƒå…·æœ‰å¯é¢„æµ‹æ€§ï¼Œè¿™æ„å‘³ç€å®ƒå¯èƒ½ä¸æ˜¯åœ¨æ•´ä¸ªæ—¶é—´èŒƒå›´å†…å‡åŒ€é‡‡æ ·çš„ï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œçš„å…¶ä»–å€¼ä¹Ÿå¾ˆå®¹æ˜“é¢„æµ‹ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´ï¼Œè¿™åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥æä¾›éå¸¸æœ‰ç”¨çš„ä¿¡æ¯ã€‚
- en: but it's also very useful if you were collecting new data coming inã€‚ you don't
    need the outcomeã€‚ you do not need the target for your new dataï¼Œ you can compare
    it to your original data set and see if a random forest is able to predict if
    it's old data of its new dataã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¦‚æœä½ åœ¨æ”¶é›†æ–°æ•°æ®æ—¶ï¼Œè¿™ä¹Ÿéå¸¸æœ‰ç”¨ã€‚ä½ ä¸éœ€è¦ç»“æœã€‚ä½ ä¸éœ€è¦æ–°æ•°æ®çš„ç›®æ ‡ï¼Œå¯ä»¥å°†å…¶ä¸åŸå§‹æ•°æ®é›†è¿›è¡Œæ¯”è¾ƒï¼Œçœ‹çœ‹éšæœºæ£®æ—æ˜¯å¦èƒ½å¤Ÿé¢„æµ‹å®ƒæ˜¯æ—§æ•°æ®è¿˜æ˜¯æ–°æ•°æ®ã€‚
- en: if the random forest can predict with decent accuracy like 87 Auc hereã€‚ then
    the underlying data has probably shifted and you need to retrain your modelã€‚ This
    content changes oftenã€‚ So subscribe to the channel to stay up to date on this
    course and other topics in artificial intelligenceã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœéšæœºæ£®æ—å¯ä»¥ä»¥ä¸é”™çš„å‡†ç¡®ç‡é¢„æµ‹ï¼Œæ¯”å¦‚è¿™é‡Œçš„ 87 AUCã€‚é‚£ä¹ˆåŸºç¡€æ•°æ®å¯èƒ½å·²ç»å‘ç”Ÿäº†å˜åŒ–ï¼Œä½ éœ€è¦é‡æ–°è®­ç»ƒä½ çš„æ¨¡å‹ã€‚è¿™ç§å†…å®¹å˜åŒ–é¢‘ç¹ã€‚æ‰€ä»¥è®¢é˜…è¿™ä¸ªé¢‘é“ä»¥ä¿æŒæ›´æ–°ï¼Œäº†è§£è¿™ä¸ªè¯¾ç¨‹å’Œäººå·¥æ™ºèƒ½çš„å…¶ä»–ä¸»é¢˜ã€‚
- en: '![](img/de3c5a0770101a2c095d10c9f95e8614_5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de3c5a0770101a2c095d10c9f95e8614_5.png)'
