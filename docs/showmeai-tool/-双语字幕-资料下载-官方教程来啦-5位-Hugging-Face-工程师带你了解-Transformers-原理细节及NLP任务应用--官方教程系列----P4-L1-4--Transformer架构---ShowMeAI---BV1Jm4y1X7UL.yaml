- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠNLPä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P4ï¼šL1.4- Transformeræ¶æ„ - ShowMeAI - BV1Jm4y1X7UL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å®˜æ–¹æ•™ç¨‹æ¥å•¦ï¼5ä½ Hugging Face å·¥ç¨‹å¸ˆå¸¦ä½ äº†è§£ Transformers åŸç†ç»†èŠ‚åŠ NLP ä»»åŠ¡åº”ç”¨ï¼ï¼œå®˜æ–¹æ•™ç¨‹ç³»åˆ—ï¼
    - P4ï¼šL1.4- Transformeræ¶æ„ - ShowMeAI - BV1Jm4y1X7UL
- en: Let's study the transformer architectureã€‚This video is the introductory video
    to the encodersã€‚ decoders and Ender decoder series of videosã€‚In the seriesã€‚ we'll
    try to understand what makes a transformer network and we'll try to explain it
    in simple high level termsã€‚No advanced understanding of neural networks is necessaryã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç ”ç©¶ Transformer æ¶æ„ã€‚è¿™ä¸ªè§†é¢‘æ˜¯å…³äºç¼–ç å™¨ã€è§£ç å™¨å’Œç¼–ç å™¨è§£ç å™¨ç³»åˆ—è§†é¢‘çš„ä»‹ç»è§†é¢‘ã€‚åœ¨è¿™ä¸ªç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬å°†å°è¯•ç†è§£ Transformer
    ç½‘ç»œçš„ç»„æˆï¼Œå¹¶åŠªåŠ›ä»¥ç®€å•çš„é«˜çº§æœ¯è¯­è¿›è¡Œè§£é‡Šã€‚æ— éœ€å¯¹ç¥ç»ç½‘ç»œæœ‰æ·±å…¥ç†è§£ã€‚
- en: but an understanding of basic vectors and tensors may helpã€‚To get startedã€‚ we'll
    take up this diagram from the original transformformer paper entitledAttention
    is all you need by Pawa it upã€‚As we'll see hereï¼Œ we can leverage only some parts
    of it according to what we're trying to doã€‚We want to dive into the specific layersï¼Œ
    building up that architectureã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç†è§£åŸºæœ¬çš„å‘é‡å’Œå¼ é‡å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚ä¸ºäº†å¼€å§‹ï¼Œæˆ‘ä»¬å°†ä»Pawaçš„åŸå§‹è®ºæ–‡ã€Šæ³¨æ„åŠ›æ˜¯ä½ æ‰€éœ€è¦çš„ä¸€åˆ‡ã€‹ä¸­æå–æ­¤å›¾ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æˆ‘ä»¬è¦åšçš„äº‹æƒ…ï¼Œåˆ©ç”¨å…¶ä¸­çš„ä¸€äº›éƒ¨åˆ†ã€‚æˆ‘ä»¬æƒ³æ·±å…¥æ¢è®¨å…·ä½“çš„å±‚ï¼Œæ„å»ºè¯¥æ¶æ„ã€‚
- en: but we'll try to understand the different ways this architecture can be usedã€‚Let's
    first start by splitting that architecture into two parts on the leftã€‚ you have
    the encoder and on the rightï¼Œ the decoderã€‚These two can be used togetherã€‚ but
    they can also be used independentlyã€‚Let's understand how these workã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ä¼šå°è¯•ç†è§£è¿™æ¶æ„å¯ä»¥è¢«ä½¿ç”¨çš„ä¸åŒæ–¹å¼ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†è¯¥æ¶æ„åˆ†ä¸ºå·¦ä¾§çš„ç¼–ç å™¨å’Œå³ä¾§çš„è§£ç å™¨ã€‚è¿™ä¸¤ä¸ªéƒ¨åˆ†å¯ä»¥ä¸€èµ·ä½¿ç”¨ï¼Œä½†ä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨ã€‚è®©æˆ‘ä»¬ç†è§£è¿™äº›æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
- en: The encoder accepts inputs that represent textï¼Œ it converts these textã€‚ these
    words into numerical representationsã€‚These numerical representations can also
    be called embedding or featuresã€‚We'll see that it uses the self attention mechanism
    as its main componentã€‚And we recommend you check out the video on encoders specifically
    to understand what is this numerical presentation as well as how it worksã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–ç å™¨æ¥å—ä»£è¡¨æ–‡æœ¬çš„è¾“å…¥ï¼Œå¹¶å°†è¿™äº›æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—è¡¨ç¤ºã€‚è¿™äº›æ•°å­—è¡¨ç¤ºä¹Ÿå¯ä»¥ç§°ä¸ºåµŒå…¥æˆ–ç‰¹å¾ã€‚æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œå®ƒä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä½œä¸ºå…¶ä¸»è¦ç»„ä»¶ã€‚æˆ‘ä»¬å»ºè®®ä½ ç‰¹åˆ«æŸ¥çœ‹å…³äºç¼–ç å™¨çš„è§†é¢‘ï¼Œä»¥äº†è§£è¿™äº›æ•°å­—è¡¨ç¤ºæ˜¯ä»€ä¹ˆï¼Œä»¥åŠå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
- en: ğŸ˜Šï¼ŒWe'll study the self attention mechanism in more detail as well as its bidirectional
    propertiesã€‚ğŸ˜Šã€‚The decoder is similar to the encodeï¼Œ it can also accept text inputsã€‚It
    uses a similar mechanism as the encoderï¼Œ which is the masked self attention as
    wellã€‚It differs from the encoder due to its unitite directional feature and is
    traditionally used in an autoregressive mannerã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°ç ”ç©¶è‡ªæ³¨æ„åŠ›æœºåˆ¶åŠå…¶åŒå‘ç‰¹æ€§ã€‚ğŸ˜Šè§£ç å™¨ç±»ä¼¼äºç¼–ç å™¨ï¼Œä¹Ÿå¯ä»¥æ¥å—æ–‡æœ¬è¾“å…¥ã€‚å®ƒä½¿ç”¨ä¸ç¼–ç å™¨ç›¸ä¼¼çš„æœºåˆ¶ï¼Œå³è¢«æ©è”½çš„è‡ªæ³¨æ„åŠ›ã€‚ç”±äºå…¶å•å‘ç‰¹æ€§ï¼Œå®ƒä¸ç¼–ç å™¨æœ‰æ‰€ä¸åŒï¼Œé€šå¸¸ä»¥è‡ªå›å½’æ–¹å¼ä½¿ç”¨ã€‚
- en: Here tooï¼Œ we recommend you check out the video on decodersã€‚ especially to understand
    how all of this worksã€‚Combining the two parts results in what is known as an anchor
    decoder or a sequence to sequence transformã€‚The encoder accepts inputs and computes
    a high level representation of those inputsã€‚These outputs are then passed to the
    decoderã€‚ The decoder uses the encoder's outputs alongside other inputs to generate
    a predictionã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¹Ÿå»ºè®®ä½ æŸ¥çœ‹å…³äºè§£ç å™¨çš„è§†é¢‘ï¼Œç‰¹åˆ«æ˜¯ä¸ºäº†ç†è§£è¿™ä¸€åˆ‡æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚å°†ä¸¤ä¸ªéƒ¨åˆ†ç»“åˆåœ¨ä¸€èµ·å½¢æˆäº†æ‰€è°“çš„é”šè§£ç å™¨æˆ–åºåˆ—åˆ°åºåˆ—å˜æ¢ã€‚ç¼–ç å™¨æ¥å—è¾“å…¥å¹¶è®¡ç®—è¿™äº›è¾“å…¥çš„é«˜çº§è¡¨ç¤ºã€‚è¿™äº›è¾“å‡ºéšåè¢«ä¼ é€’ç»™è§£ç å™¨ã€‚è§£ç å™¨ä½¿ç”¨ç¼–ç å™¨çš„è¾“å‡ºå’Œå…¶ä»–è¾“å…¥æ¥ç”Ÿæˆé¢„æµ‹ã€‚
- en: And then predict an outputï¼Œ which is will reuse in future iterationsï¼Œ hence
    the term autoregressiveã€‚Finallyï¼Œ to get an understanding of encoder decoders as
    a wholeã€‚ we recommend you check out the video on encoder decoderã€‚![](img/d08fc3568a2c2da170bab8fd128110ce_1.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åé¢„æµ‹ä¸€ä¸ªè¾“å‡ºï¼Œè¿™å°†åœ¨æœªæ¥çš„è¿­ä»£ä¸­é‡ç”¨ï¼Œå› æ­¤ç§°ä¸ºè‡ªå›å½’ã€‚æœ€åï¼Œä¸ºäº†å…¨é¢ç†è§£ç¼–ç å™¨-è§£ç å™¨ï¼Œæˆ‘ä»¬å»ºè®®ä½ æŸ¥çœ‹å…³äºç¼–ç å™¨-è§£ç å™¨çš„è§†é¢‘ã€‚![](img/d08fc3568a2c2da170bab8fd128110ce_1.png)
- en: '![](img/d08fc3568a2c2da170bab8fd128110ce_2.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d08fc3568a2c2da170bab8fd128110ce_2.png)'
- en: Yeahã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ã€‚
