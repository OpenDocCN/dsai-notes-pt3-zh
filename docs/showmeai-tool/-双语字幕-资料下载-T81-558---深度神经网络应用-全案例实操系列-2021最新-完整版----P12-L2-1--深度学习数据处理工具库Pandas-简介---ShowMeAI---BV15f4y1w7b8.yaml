- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëT81-558 ÔΩú Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÂ∫îÁî®-ÂÖ®Ê°à‰æãÂÆûÊìçÁ≥ªÂàó(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P12ÔºöL2.1- Ê∑±Â∫¶Â≠¶‰π†Êï∞ÊçÆÂ§ÑÁêÜÂ∑•ÂÖ∑Â∫ìPandas
    ÁÆÄ‰ªã - ShowMeAI - BV15f4y1w7b8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HiÔºå this is Jeff HeatonÔºå welcome to applications of Deep neural networks with
    Washington University In this video„ÄÇ we are going to start a series for this moduleÔºå
    the next five videos„ÄÇThat will talk about pandas„ÄÇNowÔºå neural networks can accept
    tabular dataÔºå which is data like you might view in Microsoft Excel„ÄÇMany traditional
    data science problems are set up this way„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: many competitions on Kagle are set up this way„ÄÇWe will get into image and audio
    processing and textual natural language processing later in this course where
    we won't use pandas„ÄÇBut for the beginningÔºå when we deal with some of the traditional
    data sets„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: pandas is very useful for dealing with data sets that can be divided into columns
    For the latest on my AI course and projects„ÄÇ click subscribe in the bell next
    to it to be notified of every new video„ÄÇ neural networks you receive a variety
    of data to predict on„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1db266afde3ffa4a6350ef9fc4060579_1.png)'
  prefs: []
  type: TYPE_IMG
- en: One type of data that you will read is CSV filesÔºå and this deals with tabular
    data„ÄÇ We'll spend a few class sessions on tabular dataÔºå a few modules„ÄÇ but we'll
    also get very much into images and other more advanced inputs that neural networks
    can deal with that neural networks are particularly good at„ÄÇ But for nowÔºå we're
    going to look at pandas and see how to deal with tabular data„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Here we do the pandas read CSv„ÄÇ You'll see this a lot as we read different data
    sets„ÄÇ I'm reading this from the web„ÄÇ So this should work in collab as well as
    if you're running this locally and it prints out just a dump of of the data frame„ÄÇ
    The first five rows of it anyway„ÄÇ We can also use the display function that prints
    it a little nicer„ÄÇ So this shows you the miles per gallon data set„ÄÇ This is a
    classic data set„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: That you see in a lot of machine learning literature we'll use it some but not
    a great deal„ÄÇ It shows the miles per gallon for each of these various carsÔºå particularly
    cars made in the 1970s„ÄÇ these values of miles per gallon you try to predict using
    these other values that you see here„ÄÇThis shows a way that we can print some basic
    statistics on this value„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: and it shows kind of how you work with some of the pandas„ÄÇ If you run this„ÄÇ
    it basically gives you each of the fields„ÄÇ So the field is named miles per gallon„ÄÇ
    The next field is named cylinders and so on and so forth„ÄÇ And this gives you some
    of the statistics„ÄÇ The meanÔºå the varianceÔºå the standard deviation and so on„ÄÇKind
    of hard to read„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but we'll make it easy to read in a moment„ÄÇ Let's see how we're actually doing
    this though„ÄÇ We are taking the data frameÔºå and we're only using the data types
    that are integer and float„ÄÇ That's effectively dropping the name„ÄÇ Then we get
    the headers of these values„ÄÇ and we create an empty list called fields„ÄÇ And we're
    going to loop over each of the field in the in the column„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So each column we're going to loop over„ÄÇ and we're going to append to fields„ÄÇ
    a dictionary that we're just building on the fly„ÄÇ And this dictionary has four
    elements in it„ÄÇ for entries nameÔºå which is just the field that we're on mean„ÄÇWhich
    is the data frame„ÄÇ This is how you take the mean of a column in a data frame dot
    mean dot variance and dot standard deviation„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: You can do median whole whole bunch of statistical values are available to„ÄÇ
    And then we print them out„ÄÇ So this is a good example of how you build up a list
    of dictionaries„ÄÇ which is a very common structure to use„ÄÇ This is this is kind
    of like a database table„ÄÇ And this is also exactly the format that you can put
    data in to load it directly into a data frame„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So here we'll see that we can take this data that we created here and turn it
    into a pandas data frame„ÄÇ Very handy because now we can display it nicely„ÄÇ So
    we've basically created a data frame from scratch„ÄÇ All these mean values we put
    in NaÔºå standard deviations and variances„ÄÇ So this dictionary that we were adding
    one by one„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Those are like the rows in this particular table that we're creating„ÄÇ NowÔºå missing
    values„ÄÇ The reality is the data that you deal with as a data scientist always„ÄÇüòä„ÄÇhas
    problems fact if the data is perfectÔºå I would almost be afraid that there's a
    problem that I haven't seen here we're going to load in auto miles per gallon
    again„ÄÇ that's that same data set„ÄÇ but we're saying here that the NA values are
    NA and question mark because there's a few question marks in this particular data
    set there's a horsepower value that's missing So if you run this it will show
    you that yes„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: horsepower does have an NA value then we fill the missing values„ÄÇ we take the
    median Now median is usually a better value to put in for missing values than
    mean because median is not that sensitive to outliers whereas mean is if you have
    a huge outlier value that's going to affect your mean„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but it's not really going to affect your median So we take the horsepower and
    we fill in the missing the NA values the missing values with that median you could
    also just drop the NA values too if you want to do that that drops the entire
    row that has a NA value and now we print out that horsepower does indeed not„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Have a„ÄÇAnd NA A because we've we've filled it in outliers are another thing
    that you potentially have to deal with„ÄÇ You can remove them or deal with them
    in other ways„ÄÇ I show you how to remove them here„ÄÇ We are defining an outlier
    as something that is a higher number„ÄÇ maybe two or more standard deviations away
    two might be a bit closeÔºå but maybe three or higher„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but this shows you how to remove we want to remove a fair amount so we'll remove
    anything that is more than two standard deviations above or below the mean The
    first thing we do is we calculate what our drop rows are So we are essentially
    asking for a list of the values where the absolute value„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Of each of these individual valuesÔºå and name is the column that we're calculating
    the outliers of„ÄÇ we subtract it from the meanÔºå and we make sure that it is not
    that amount of standard deviations above„ÄÇ And then we drop these rows that we've
    gotten all of the indexes to„ÄÇAnd we use axis equals 0 because we're dealing with
    rows and our columns„ÄÇ We're not deleting columns„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: In place means that it modifies the actual data frame and does not return a
    second data frame„ÄÇ Run the function„ÄÇ So it's in memory„ÄÇ This then loads that same
    data set and creates the feature vector„ÄÇ It does that by replacing the the horse
    power with the median„ÄÇ We're going to drop name because we„ÄÇWe don't need itÔºå doesn't
    really matter so much for this example„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but and then we look at the length of the miles per gallon before we drop those
    values and after and we see that we went from 398 to 388 and I show of the some
    of the data here you probably really can't see a different dropping fields it's
    pretty easy to drop fields in pandas if we wanted to drop the name field we simply
    do this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: It tells you the number of columns before and after or the actual columns you
    can see name was there now it's very handy to be able to delete entire columns
    from the data frame we can also concatenate things together this becomes very
    useful when we start to generate dummy variables and other variables and we need
    to add them into our data frame„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: What this is going to do is we're going to create basically a new data frame
    that is just two of the values together so this is creating just name and horsepower
    so what we're doing is we're extracting horsepower„ÄÇ we're extracting name and
    then we're concatenating those two together as columns axis one always means columns
    and you get this nice resulting we're just displaying the first five rows„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but this is how you can subselect one of them anyway ways you can subselect„ÄÇAnd
    build up„ÄÇData frames from scratchÔºå some of the assignments will want you to do
    something very much like this„ÄÇ so this is this is useful to be able to take these
    columns or series and put them together to build entirely new data frame you also
    concatenate rows together what this is doing is taking the first two and this
    last two rows so we're taking data frame from zero to two and then from minus
    two which means two back from the end to the end„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And working catatum together„ÄÇ Now this is access zero because we're dealing
    with rows„ÄÇ Another thing that you will often use pandas4 is training„ÄÇ breaking
    your training data into training and validation sets and even k folding will get
    into k folding more in a later module„ÄÇ but you can basically take your data and
    break it into a training and validation split so that you have your entire data
    set here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but you're taking 80% for training 20% for validation„ÄÇ You'll usually train
    and fit your model on the training set and you'll evaluate that model created
    from the training set on your validation set This is some simple code that shows
    how to do this We're basically using the mask here to create a„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: A mask of valuesÔºå so this is just a list of truths and falses„ÄÇThe truths are
    the ones that will be included and the falses are the ones that are not„ÄÇ so since
    we're taking 80% the training data frame„ÄÇBasically gets the data frame with the
    mask applied opposite mass and we're able to print out that we have our training
    set of 312 and our validation set of 86„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: This is very important you don't send data frames directly onto Kras you need
    to be able to use nuy for that Numpy do values is what does this so here you can
    see it's basically taken the values and created a matrix Now you may not want
    all of these values like that name here is not numeric so that could cause problems„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: You can pass in a list now you often see this in Python as source of some confusion
    when you have the double brace for a array„ÄÇ It's not a double brace„ÄÇ It just means
    that the index that you're passing in is a list„ÄÇ so you're saying that I want
    all the rows from the data frame but I want just these columns„ÄÇAnd if you run
    that one now without the name there now you don't have that ugly character string
    in there it's pure numeric„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: which is what you want to have„ÄÇ We'll see more about this when we learn how
    to prepare feature vectors for neural networks you can save a data frame that
    you've created or modified to a CSV file This allows you to view it outside of
    Jupyter notebook using Excel or preferably something more advanced for CSV file
    viewing you have to be careful with Excel it tends to modify CSV files and we'll
    even corrupt them by removing leading zeros and other things and it also has kind
    of limited support of text encodings like UTF 8 just using Excel to view things
    can be okay but just be aware it may reformat some of the data and corrupt it
    Now when you save it as a CSV file that can be useful because that's what I often
    have you submit those those files to me in that form for some of the assignments„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: When you compete in the CAgle competitionÔºå you'll often submit a CSV file for
    that„ÄÇI'll post exact requirements for the Caggle competition for this semester
    when we reach that point„ÄÇThe command to save a CSV follows simply this to CSV„ÄÇAnd
    we are„ÄÇEssentially just shuffling this data frame and then writing it back„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Index equals false usually you want index equals false because that is going
    to tell it not to put a row number on each on each row Now when you run this it
    just says done and it generates the CSv in the path that we said dot means the
    current directory if you're using Google coab which you probably are you should
    put the path to your mapped G driveve up there and then it will output it to a
    place that you can get a hold of that file and you can take a look at that in
    Google Docs or something else Google Docs is a very good program for viewing for
    viewing CSVs saving a data frame to pickle Pickle is a binary file format so when
    you save it a CSv you're basically writing it out to a text file which you often
    read it from but you can run into very very small precision problems when you
    bring things back and forth between CSv files usually this is not a problem it's
    only a problem if you're trying to diff two files so„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Pickle will ensure that you get an exact rendering of the„ÄÇOf the file and it
    also stores other metadata that is stored in the data frame that simply doesn't
    fit into a CSV like row numbers„ÄÇ if I run thisÔºå it simply tells me that that I'm
    done again it this it did this reindex scene again„ÄÇ we will load the pickle file
    back„ÄÇIt's done with this pickle load pickle dump is how you save it and this loads
    it back in Now here's something important to note this is the file„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: these are all the columns and everythingÔºå but here's how you can tell the difference
    between loading a pickle file and loading a CSV file notice the row numbers don't
    line up because we we reined it and we didn't rebuild that index so that„ÄÇThat
    was stored in the pickle file that would have been lost in the CSV file now typically
    you wouldn't mind necessarily losing those„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but your actual row numbers from when it was first loaded„ÄÇ these are only out
    of order because we shuffled it„ÄÇ but that is not something that would be stored
    into a CSV file„ÄÇ![](img/1db266afde3ffa4a6350ef9fc4060579_3.png)
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for watching this video on the introduction to pandas„ÄÇ We will see
    how to do more advanced processing with pandas in the other parts of this module„ÄÇ
    This content changes oftenÔºå so subscribe to the channel to stay up to date on
    this course and other topics in artificial intelligence„ÄÇüòä„ÄÇ
  prefs: []
  type: TYPE_NORMAL
