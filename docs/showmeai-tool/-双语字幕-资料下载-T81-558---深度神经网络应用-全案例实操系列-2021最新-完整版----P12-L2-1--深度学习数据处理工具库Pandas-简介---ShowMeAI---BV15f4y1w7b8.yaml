- en: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P12：L2.1- 深度学习数据处理工具库Pandas
    简介 - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 【双语字幕+资料下载】T81-558 ｜ 深度神经网络应用-全案例实操系列(2021最新·完整版) - P12：L2.1- 深度学习数据处理工具库Pandas
    简介 - ShowMeAI - BV15f4y1w7b8
- en: Hi， this is Jeff Heaton， welcome to applications of Deep neural networks with
    Washington University In this video。 we are going to start a series for this module，
    the next five videos。That will talk about pandas。Now， neural networks can accept
    tabular data， which is data like you might view in Microsoft Excel。Many traditional
    data science problems are set up this way。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨，我是杰夫·希顿，欢迎来到华盛顿大学的深度神经网络应用。在这个视频中，我们将开始这个模块的一系列内容，接下来的五个视频将讨论 pandas。现在，神经网络可以接受表格数据，这种数据就像你在
    Microsoft Excel 中看到的一样。许多传统数据科学问题都是这样设置的。
- en: many competitions on Kagle are set up this way。We will get into image and audio
    processing and textual natural language processing later in this course where
    we won't use pandas。But for the beginning， when we deal with some of the traditional
    data sets。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kagle 上的许多比赛都是这样设置的。我们将在本课程的后面深入探讨图像和音频处理以及文本自然语言处理，而不会使用 pandas。但在开始时，当我们处理一些传统数据集时，情况则不同。
- en: pandas is very useful for dealing with data sets that can be divided into columns
    For the latest on my AI course and projects。 click subscribe in the bell next
    to it to be notified of every new video。 neural networks you receive a variety
    of data to predict on。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 对处理可以分为列的数据集非常有用。关于我最新的 AI 课程和项目，请点击旁边的铃铛订阅，以便收到每个新视频的通知。神经网络接收多种数据进行预测。
- en: '![](img/1db266afde3ffa4a6350ef9fc4060579_1.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1db266afde3ffa4a6350ef9fc4060579_1.png)'
- en: One type of data that you will read is CSV files， and this deals with tabular
    data。 We'll spend a few class sessions on tabular data， a few modules。 but we'll
    also get very much into images and other more advanced inputs that neural networks
    can deal with that neural networks are particularly good at。 But for now， we're
    going to look at pandas and see how to deal with tabular data。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一种你将要读取的数据是 CSV 文件，这与表格数据有关。我们将在几节课上花时间讨论表格数据，几个模块。但我们还将深入研究神经网络擅长处理的图像和其他更高级的输入。不过现在，我们要看看
    pandas，看看如何处理表格数据。
- en: Here we do the pandas read CSv。 You'll see this a lot as we read different data
    sets。 I'm reading this from the web。 So this should work in collab as well as
    if you're running this locally and it prints out just a dump of of the data frame。
    The first five rows of it anyway。 We can also use the display function that prints
    it a little nicer。 So this shows you the miles per gallon data set。 This is a
    classic data set。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们使用 pandas 读取 CSV。你将在读取不同数据集时看到很多这一点。我是从网络读取的，所以在 collab 和本地运行时都应该有效，它会打印出数据框的输出。至少是前五行。我们也可以使用
    display 函数，使其打印得更好看。这显示了每加仑英里数数据集，这是一个经典的数据集。
- en: That you see in a lot of machine learning literature we'll use it some but not
    a great deal。 It shows the miles per gallon for each of these various cars， particularly
    cars made in the 1970s。 these values of miles per gallon you try to predict using
    these other values that you see here。This shows a way that we can print some basic
    statistics on this value。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多机器学习文献中你会看到，我们会使用它，但不太多。它显示了这些不同车型的每加仑英里数，特别是1970年代的车型。你试图用这里看到的其他值来预测每加仑英里数。这个展示了一种打印该值基本统计信息的方法。
- en: and it shows kind of how you work with some of the pandas。 If you run this。
    it basically gives you each of the fields。 So the field is named miles per gallon。
    The next field is named cylinders and so on and so forth。 And this gives you some
    of the statistics。 The mean， the variance， the standard deviation and so on。Kind
    of hard to read。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 并且它展示了你如何与 pandas 一起工作。如果你运行这个，它基本上会给你每个字段。因此，字段被命名为每加仑英里数。下一个字段被命名为气缸，依此类推。这会给你一些统计信息，均值、方差、标准差等等。稍微有点难读。
- en: but we'll make it easy to read in a moment。 Let's see how we're actually doing
    this though。 We are taking the data frame， and we're only using the data types
    that are integer and float。 That's effectively dropping the name。 Then we get
    the headers of these values。 and we create an empty list called fields。 And we're
    going to loop over each of the field in the in the column。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们稍后会让它更易读。让我们看看我们实际上是如何做到这一点的。我们正在使用数据框，只使用整数和浮点数类型的数据。这实际上是丢弃了名称。然后我们获取这些值的标题，并创建一个名为
    fields 的空列表。我们将循环遍历列中的每个字段。
- en: So each column we're going to loop over。 and we're going to append to fields。
    a dictionary that we're just building on the fly。 And this dictionary has four
    elements in it。 for entries name， which is just the field that we're on mean。Which
    is the data frame。 This is how you take the mean of a column in a data frame dot
    mean dot variance and dot standard deviation。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们将遍历每一列，并将一个我们动态构建的字典附加到字段中。这个字典有四个元素，分别是条目名称、我们当前处理的字段的均值。数据框就是这样计算某一列的均值：`.mean`、`.variance`
    和 `.standard deviation`。
- en: You can do median whole whole bunch of statistical values are available to。
    And then we print them out。 So this is a good example of how you build up a list
    of dictionaries。 which is a very common structure to use。 This is this is kind
    of like a database table。 And this is also exactly the format that you can put
    data in to load it directly into a data frame。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用中位数，许多统计值都可以使用。然后我们将它们打印出来。这是构建字典列表的一个好例子，这是一种非常常见的结构。这就像一个数据库表格。这也是你可以将数据放入的确切格式，以便直接加载到数据框中。
- en: So here we'll see that we can take this data that we created here and turn it
    into a pandas data frame。 Very handy because now we can display it nicely。 So
    we've basically created a data frame from scratch。 All these mean values we put
    in Na， standard deviations and variances。 So this dictionary that we were adding
    one by one。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们可以将这里创建的数据转换为 pandas 数据框。这非常方便，因为现在我们可以很好地展示它。因此，我们基本上是从头开始创建了一个数据框。所有这些均值、标准差和方差的值我们都放在了
    NA 中，这个字典是我们一个个添加的。
- en: Those are like the rows in this particular table that we're creating。 Now， missing
    values。 The reality is the data that you deal with as a data scientist always。😊。has
    problems fact if the data is perfect， I would almost be afraid that there's a
    problem that I haven't seen here we're going to load in auto miles per gallon
    again。 that's that same data set。 but we're saying here that the NA values are
    NA and question mark because there's a few question marks in this particular data
    set there's a horsepower value that's missing So if you run this it will show
    you that yes。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就像我们正在创建的这个特定表格中的行。现在，缺失值的现实是，作为数据科学家，你处理的数据总是有问题。😊。如果数据完美，我几乎会担心我没有发现的问题。我们将在这里加载每加仑的汽车英里数，这就是那个相同的数据集。但我们在这里说
    NA 值是 NA 和问号，因为在这个特定数据集中有几个问号，其中有一个马力值缺失。所以如果你运行这个，它会显示是的。
- en: horsepower does have an NA value then we fill the missing values。 we take the
    median Now median is usually a better value to put in for missing values than
    mean because median is not that sensitive to outliers whereas mean is if you have
    a huge outlier value that's going to affect your mean。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果马力确实有 NA 值，那么我们填充缺失的值。我们取中位数，现在中位数通常比均值更适合用于填充缺失值，因为中位数对离群值的敏感度较低，而均值则较高。如果你有一个巨大的离群值，这会影响你的均值。
- en: but it's not really going to affect your median So we take the horsepower and
    we fill in the missing the NA values the missing values with that median you could
    also just drop the NA values too if you want to do that that drops the entire
    row that has a NA value and now we print out that horsepower does indeed not。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不会真正影响你的中位数。因此我们采用马力，并用那个中位数填充缺失的 NA 值，如果你愿意，也可以直接删除 NA 值，这会删除整个包含 NA 值的行，现在我们打印出马力确实没有
    NA 值。
- en: Have a。And NA A because we've we've filled it in outliers are another thing
    that you potentially have to deal with。 You can remove them or deal with them
    in other ways。 I show you how to remove them here。 We are defining an outlier
    as something that is a higher number。 maybe two or more standard deviations away
    two might be a bit close， but maybe three or higher。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有 NA，因为我们填充了它。离群值是你可能需要处理的另一件事。你可以删除它们或以其他方式处理它们。我在这里向你展示如何删除它们。我们将离群值定义为高于或低于均值两个或更多标准差的值，两个可能有点近，但也许是三个或更高。
- en: but this shows you how to remove we want to remove a fair amount so we'll remove
    anything that is more than two standard deviations above or below the mean The
    first thing we do is we calculate what our drop rows are So we are essentially
    asking for a list of the values where the absolute value。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但这向你展示了如何删除，我们想删除大量数据，因此我们将删除任何高于或低于均值两个标准差的值。我们做的第一件事是计算要删除的行。因此我们基本上是在要求一个绝对值的列表。
- en: Of each of these individual values， and name is the column that we're calculating
    the outliers of。 we subtract it from the mean， and we make sure that it is not
    that amount of standard deviations above。 And then we drop these rows that we've
    gotten all of the indexes to。And we use axis equals 0 because we're dealing with
    rows and our columns。 We're not deleting columns。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个单独的值，name 是我们正在计算离群值的列。我们从均值中减去它，并确保它不超过该标准差的数量。然后我们删除这些行，这些行的索引已获取。我们使用
    axis 等于 0，因为我们处理的是行和列。我们并没有删除列。
- en: In place means that it modifies the actual data frame and does not return a
    second data frame。 Run the function。 So it's in memory。 This then loads that same
    data set and creates the feature vector。 It does that by replacing the the horse
    power with the median。 We're going to drop name because we。We don't need it， doesn't
    really matter so much for this example。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 就地意味着它修改实际的数据框，而不是返回第二个数据框。运行函数。因此它在内存中。这将加载相同的数据集并创建特征向量。它通过将马力替换为中位数来实现。我们将删除
    name，因为我们不需要它，这在这个例子中并不重要。
- en: but and then we look at the length of the miles per gallon before we drop those
    values and after and we see that we went from 398 to 388 and I show of the some
    of the data here you probably really can't see a different dropping fields it's
    pretty easy to drop fields in pandas if we wanted to drop the name field we simply
    do this。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们查看每加仑的英里数的长度，看看在删除这些值之前和之后，我们看到数量从 398 变为 388。我在这里展示了一些数据，你可能真的看不到明显的不同。在
    pandas 中删除字段非常简单，如果我们想删除 name 字段，只需这样做。
- en: It tells you the number of columns before and after or the actual columns you
    can see name was there now it's very handy to be able to delete entire columns
    from the data frame we can also concatenate things together this becomes very
    useful when we start to generate dummy variables and other variables and we need
    to add them into our data frame。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 它告诉你列的数量在前后或实际的列，你可以看到 name 之前在那里。能够从数据框中删除整个列是非常方便的，我们也可以将东西连接在一起，这在我们开始生成虚拟变量和其他变量时变得非常有用，我们需要将它们添加到数据框中。
- en: What this is going to do is we're going to create basically a new data frame
    that is just two of the values together so this is creating just name and horsepower
    so what we're doing is we're extracting horsepower。 we're extracting name and
    then we're concatenating those two together as columns axis one always means columns
    and you get this nice resulting we're just displaying the first five rows。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的数据框，仅包含两个值，因此这是仅创建 name 和马力。我们提取马力，提取 name，然后将这两者作为列连接在一起，axis 1 总是表示列，你会得到这个漂亮的结果，我们只显示前五行。
- en: but this is how you can subselect one of them anyway ways you can subselect。And
    build up。Data frames from scratch， some of the assignments will want you to do
    something very much like this。 so this is this is useful to be able to take these
    columns or series and put them together to build entirely new data frame you also
    concatenate rows together what this is doing is taking the first two and this
    last two rows so we're taking data frame from zero to two and then from minus
    two which means two back from the end to the end。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但这就是你可以选择其中一个的方法，无论你如何选择。并从头开始构建数据框，有些作业会要求你做非常类似的事情。因此，能够将这些列或系列放在一起以构建全新的数据框是非常有用的，你还可以将行连接在一起。这是将前两行和最后两行连接起来，因此我们从零到二取数据框，然后从负二开始，这意味着从末尾往回数两行到末尾。
- en: And working catatum together。 Now this is access zero because we're dealing
    with rows。 Another thing that you will often use pandas4 is training。 breaking
    your training data into training and validation sets and even k folding will get
    into k folding more in a later module。 but you can basically take your data and
    break it into a training and validation split so that you have your entire data
    set here。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一起处理 catatum。这是访问零，因为我们处理的是行。你经常会使用 pandas4 进行训练。将训练数据分割为训练集和验证集，甚至进行 k 折交叉验证，在后面的模块中会深入讨论
    k 折交叉验证。但你基本上可以将数据分割为训练集和验证集，这样你就可以在这里拥有整个数据集。
- en: but you're taking 80% for training 20% for validation。 You'll usually train
    and fit your model on the training set and you'll evaluate that model created
    from the training set on your validation set This is some simple code that shows
    how to do this We're basically using the mask here to create a。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但你取80%作为训练，20%作为验证。你通常会在训练集上训练和拟合你的模型，并在验证集上评估从训练集中创建的模型。这是一段简单的代码，展示了如何做到这一点。我们基本上是在这里使用掩码来创建一个。
- en: A mask of values， so this is just a list of truths and falses。The truths are
    the ones that will be included and the falses are the ones that are not。 so since
    we're taking 80% the training data frame。Basically gets the data frame with the
    mask applied opposite mass and we're able to print out that we have our training
    set of 312 and our validation set of 86。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一组值的掩码，这只是一组真和假的列表。真是会被包含的，而假则不会。因此，由于我们取了80%的训练数据框。基本上，得到应用掩码后的数据框，反向掩码，我们能够打印出我们的训练集为312，而验证集为86。
- en: This is very important you don't send data frames directly onto Kras you need
    to be able to use nuy for that Numpy do values is what does this so here you can
    see it's basically taken the values and created a matrix Now you may not want
    all of these values like that name here is not numeric so that could cause problems。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常重要，你不能直接将数据框发送到Kras，你需要能够使用nuy来实现。Numpy的do values正是这样做的，所以在这里你可以看到，它基本上是提取了值并创建了一个矩阵。现在你可能不想要所有这些值，比如这里的名字不是数字，这可能会导致问题。
- en: You can pass in a list now you often see this in Python as source of some confusion
    when you have the double brace for a array。 It's not a double brace。 It just means
    that the index that you're passing in is a list。 so you're saying that I want
    all the rows from the data frame but I want just these columns。And if you run
    that one now without the name there now you don't have that ugly character string
    in there it's pure numeric。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以传入一个列表，这在Python中经常会引起一些混淆，当你看到数组的双大括号时。这不是双大括号。这只是意味着你传入的索引是一个列表。因此你是在说，我想要数据框中的所有行，但我只想要这些列。如果你现在运行这一段，没有名字，那样你就没有了那个丑陋的字符字符串，它是纯数字的。
- en: which is what you want to have。 We'll see more about this when we learn how
    to prepare feature vectors for neural networks you can save a data frame that
    you've created or modified to a CSV file This allows you to view it outside of
    Jupyter notebook using Excel or preferably something more advanced for CSV file
    viewing you have to be careful with Excel it tends to modify CSV files and we'll
    even corrupt them by removing leading zeros and other things and it also has kind
    of limited support of text encodings like UTF 8 just using Excel to view things
    can be okay but just be aware it may reformat some of the data and corrupt it
    Now when you save it as a CSV file that can be useful because that's what I often
    have you submit those those files to me in that form for some of the assignments。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你想要的。当我们学习如何为神经网络准备特征向量时，我们会看到更多的内容。你可以将创建或修改的数据框保存为CSV文件，这允许你在Jupyter Notebook外部使用Excel或更高级的CSV文件查看工具查看它。你必须小心使用Excel，它往往会修改CSV文件，甚至会通过删除前导零和其他方式来破坏它，并且它对文本编码如UTF-8的支持也有限。仅使用Excel查看内容是可以的，但要注意它可能会重新格式化某些数据并破坏它。现在，当你将其保存为CSV文件时，这很有用，因为我通常会让你以这种形式提交这些文件作为一些作业。
- en: When you compete in the CAgle competition， you'll often submit a CSV file for
    that。I'll post exact requirements for the Caggle competition for this semester
    when we reach that point。The command to save a CSV follows simply this to CSV。And
    we are。Essentially just shuffling this data frame and then writing it back。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当你参加CAgle竞赛时，你通常会提交一个CSV文件。我会在我们到达那个点时发布本学期CAgle竞赛的确切要求。保存CSV的命令简单如下to CSV。我们基本上只是在洗牌这个数据框，然后写回去。
- en: Index equals false usually you want index equals false because that is going
    to tell it not to put a row number on each on each row Now when you run this it
    just says done and it generates the CSv in the path that we said dot means the
    current directory if you're using Google coab which you probably are you should
    put the path to your mapped G driveve up there and then it will output it to a
    place that you can get a hold of that file and you can take a look at that in
    Google Docs or something else Google Docs is a very good program for viewing for
    viewing CSVs saving a data frame to pickle Pickle is a binary file format so when
    you save it a CSv you're basically writing it out to a text file which you often
    read it from but you can run into very very small precision problems when you
    bring things back and forth between CSv files usually this is not a problem it's
    only a problem if you're trying to diff two files so。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 索引等于 false，通常你希望索引等于 false，因为这会告诉它不要在每一行上放置行号。现在，当你运行这个时，它只是显示完成，并生成我们所说的路径中的
    CSV，点表示当前目录。如果你正在使用 Google Colab，可能需要将你映射的 G 盘路径放在那里，然后它会将输出放到你可以获取该文件的地方，你可以在
    Google Docs 或其他地方查看它。Google Docs 是查看 CSV 的非常好用的程序。将数据框保存为 pickle，pickle 是一种二进制文件格式，因此当你保存为
    CSV 时，实际上是将其写入文本文件中，这通常可以读取，但在 CSV 文件之间来回传输时可能会遇到非常小的精度问题，通常这不是问题，只有在你试图比较两个文件时才会出现。
- en: Pickle will ensure that you get an exact rendering of the。Of the file and it
    also stores other metadata that is stored in the data frame that simply doesn't
    fit into a CSV like row numbers。 if I run this， it simply tells me that that I'm
    done again it this it did this reindex scene again。 we will load the pickle file
    back。It's done with this pickle load pickle dump is how you save it and this loads
    it back in Now here's something important to note this is the file。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle 将确保你获得文件的准确渲染，并且它还存储在数据框中不适合存入 CSV 的其他元数据，比如行号。如果我运行这个，它只是告诉我我已经完成了，再次进行了这个重新索引的操作。我们将重新加载
    pickle 文件，使用 pickle dump 来保存，而这会将其加载回去。现在，有一点很重要要注意，这是文件。
- en: these are all the columns and everything， but here's how you can tell the difference
    between loading a pickle file and loading a CSV file notice the row numbers don't
    line up because we we reined it and we didn't rebuild that index so that。That
    was stored in the pickle file that would have been lost in the CSV file now typically
    you wouldn't mind necessarily losing those。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是所有列和内容，但这里是你可以区分加载 pickle 文件和加载 CSV 文件的方法，注意行号不对齐，因为我们进行了重排，而且我们没有重建索引。因此，存储在
    pickle 文件中的内容在 CSV 文件中将会丢失，通常你并不在意丢失这些。
- en: but your actual row numbers from when it was first loaded。 these are only out
    of order because we shuffled it。 but that is not something that would be stored
    into a CSV file。![](img/1db266afde3ffa4a6350ef9fc4060579_3.png)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但是你实际的行号是从最初加载时来的。这些行号只是因为我们进行了洗牌而不按顺序排列，但这并不是会存储到 CSV 文件中的内容。![](img/1db266afde3ffa4a6350ef9fc4060579_3.png)
- en: Thank you for watching this video on the introduction to pandas。 We will see
    how to do more advanced processing with pandas in the other parts of this module。
    This content changes often， so subscribe to the channel to stay up to date on
    this course and other topics in artificial intelligence。😊。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢观看关于 pandas 介绍的视频。我们将在本模块的其他部分深入探讨如何进行更高级的处理。该内容经常更新，因此请订阅频道以获取有关本课程和人工智能其他主题的最新信息。😊
