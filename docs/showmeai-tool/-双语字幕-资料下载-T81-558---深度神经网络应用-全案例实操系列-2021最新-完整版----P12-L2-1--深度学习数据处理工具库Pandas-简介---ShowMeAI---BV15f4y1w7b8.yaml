- en: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P12ï¼šL2.1- æ·±åº¦å­¦ä¹ æ•°æ®å¤„ç†å·¥å…·åº“Pandas
    ç®€ä»‹ - ShowMeAI - BV15f4y1w7b8
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘T81-558 ï½œ æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨-å…¨æ¡ˆä¾‹å®æ“ç³»åˆ—(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P12ï¼šL2.1- æ·±åº¦å­¦ä¹ æ•°æ®å¤„ç†å·¥å…·åº“Pandas
    ç®€ä»‹ - ShowMeAI - BV15f4y1w7b8
- en: Hiï¼Œ this is Jeff Heatonï¼Œ welcome to applications of Deep neural networks with
    Washington University In this videoã€‚ we are going to start a series for this moduleï¼Œ
    the next five videosã€‚That will talk about pandasã€‚Nowï¼Œ neural networks can accept
    tabular dataï¼Œ which is data like you might view in Microsoft Excelã€‚Many traditional
    data science problems are set up this wayã€‚
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å—¨ï¼Œæˆ‘æ˜¯æ°å¤«Â·å¸Œé¡¿ï¼Œæ¬¢è¿æ¥åˆ°åç››é¡¿å¤§å­¦çš„æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨ã€‚åœ¨è¿™ä¸ªè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å°†å¼€å§‹è¿™ä¸ªæ¨¡å—çš„ä¸€ç³»åˆ—å†…å®¹ï¼Œæ¥ä¸‹æ¥çš„äº”ä¸ªè§†é¢‘å°†è®¨è®º pandasã€‚ç°åœ¨ï¼Œç¥ç»ç½‘ç»œå¯ä»¥æ¥å—è¡¨æ ¼æ•°æ®ï¼Œè¿™ç§æ•°æ®å°±åƒä½ åœ¨
    Microsoft Excel ä¸­çœ‹åˆ°çš„ä¸€æ ·ã€‚è®¸å¤šä¼ ç»Ÿæ•°æ®ç§‘å­¦é—®é¢˜éƒ½æ˜¯è¿™æ ·è®¾ç½®çš„ã€‚
- en: many competitions on Kagle are set up this wayã€‚We will get into image and audio
    processing and textual natural language processing later in this course where
    we won't use pandasã€‚But for the beginningï¼Œ when we deal with some of the traditional
    data setsã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kagle ä¸Šçš„è®¸å¤šæ¯”èµ›éƒ½æ˜¯è¿™æ ·è®¾ç½®çš„ã€‚æˆ‘ä»¬å°†åœ¨æœ¬è¯¾ç¨‹çš„åé¢æ·±å…¥æ¢è®¨å›¾åƒå’ŒéŸ³é¢‘å¤„ç†ä»¥åŠæ–‡æœ¬è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œè€Œä¸ä¼šä½¿ç”¨ pandasã€‚ä½†åœ¨å¼€å§‹æ—¶ï¼Œå½“æˆ‘ä»¬å¤„ç†ä¸€äº›ä¼ ç»Ÿæ•°æ®é›†æ—¶ï¼Œæƒ…å†µåˆ™ä¸åŒã€‚
- en: pandas is very useful for dealing with data sets that can be divided into columns
    For the latest on my AI course and projectsã€‚ click subscribe in the bell next
    to it to be notified of every new videoã€‚ neural networks you receive a variety
    of data to predict onã€‚
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: pandas å¯¹å¤„ç†å¯ä»¥åˆ†ä¸ºåˆ—çš„æ•°æ®é›†éå¸¸æœ‰ç”¨ã€‚å…³äºæˆ‘æœ€æ–°çš„ AI è¯¾ç¨‹å’Œé¡¹ç›®ï¼Œè¯·ç‚¹å‡»æ—è¾¹çš„é“ƒé“›è®¢é˜…ï¼Œä»¥ä¾¿æ”¶åˆ°æ¯ä¸ªæ–°è§†é¢‘çš„é€šçŸ¥ã€‚ç¥ç»ç½‘ç»œæ¥æ”¶å¤šç§æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚
- en: '![](img/1db266afde3ffa4a6350ef9fc4060579_1.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1db266afde3ffa4a6350ef9fc4060579_1.png)'
- en: One type of data that you will read is CSV filesï¼Œ and this deals with tabular
    dataã€‚ We'll spend a few class sessions on tabular dataï¼Œ a few modulesã€‚ but we'll
    also get very much into images and other more advanced inputs that neural networks
    can deal with that neural networks are particularly good atã€‚ But for nowï¼Œ we're
    going to look at pandas and see how to deal with tabular dataã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§ä½ å°†è¦è¯»å–çš„æ•°æ®æ˜¯ CSV æ–‡ä»¶ï¼Œè¿™ä¸è¡¨æ ¼æ•°æ®æœ‰å…³ã€‚æˆ‘ä»¬å°†åœ¨å‡ èŠ‚è¯¾ä¸ŠèŠ±æ—¶é—´è®¨è®ºè¡¨æ ¼æ•°æ®ï¼Œå‡ ä¸ªæ¨¡å—ã€‚ä½†æˆ‘ä»¬è¿˜å°†æ·±å…¥ç ”ç©¶ç¥ç»ç½‘ç»œæ“…é•¿å¤„ç†çš„å›¾åƒå’Œå…¶ä»–æ›´é«˜çº§çš„è¾“å…¥ã€‚ä¸è¿‡ç°åœ¨ï¼Œæˆ‘ä»¬è¦çœ‹çœ‹
    pandasï¼Œçœ‹çœ‹å¦‚ä½•å¤„ç†è¡¨æ ¼æ•°æ®ã€‚
- en: Here we do the pandas read CSvã€‚ You'll see this a lot as we read different data
    setsã€‚ I'm reading this from the webã€‚ So this should work in collab as well as
    if you're running this locally and it prints out just a dump of of the data frameã€‚
    The first five rows of it anywayã€‚ We can also use the display function that prints
    it a little nicerã€‚ So this shows you the miles per gallon data setã€‚ This is a
    classic data setã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ pandas è¯»å– CSVã€‚ä½ å°†åœ¨è¯»å–ä¸åŒæ•°æ®é›†æ—¶çœ‹åˆ°å¾ˆå¤šè¿™ä¸€ç‚¹ã€‚æˆ‘æ˜¯ä»ç½‘ç»œè¯»å–çš„ï¼Œæ‰€ä»¥åœ¨ collab å’Œæœ¬åœ°è¿è¡Œæ—¶éƒ½åº”è¯¥æœ‰æ•ˆï¼Œå®ƒä¼šæ‰“å°å‡ºæ•°æ®æ¡†çš„è¾“å‡ºã€‚è‡³å°‘æ˜¯å‰äº”è¡Œã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨
    display å‡½æ•°ï¼Œä½¿å…¶æ‰“å°å¾—æ›´å¥½çœ‹ã€‚è¿™æ˜¾ç¤ºäº†æ¯åŠ ä»‘è‹±é‡Œæ•°æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªç»å…¸çš„æ•°æ®é›†ã€‚
- en: That you see in a lot of machine learning literature we'll use it some but not
    a great dealã€‚ It shows the miles per gallon for each of these various carsï¼Œ particularly
    cars made in the 1970sã€‚ these values of miles per gallon you try to predict using
    these other values that you see hereã€‚This shows a way that we can print some basic
    statistics on this valueã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¸å¤šæœºå™¨å­¦ä¹ æ–‡çŒ®ä¸­ä½ ä¼šçœ‹åˆ°ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨å®ƒï¼Œä½†ä¸å¤ªå¤šã€‚å®ƒæ˜¾ç¤ºäº†è¿™äº›ä¸åŒè½¦å‹çš„æ¯åŠ ä»‘è‹±é‡Œæ•°ï¼Œç‰¹åˆ«æ˜¯1970å¹´ä»£çš„è½¦å‹ã€‚ä½ è¯•å›¾ç”¨è¿™é‡Œçœ‹åˆ°çš„å…¶ä»–å€¼æ¥é¢„æµ‹æ¯åŠ ä»‘è‹±é‡Œæ•°ã€‚è¿™ä¸ªå±•ç¤ºäº†ä¸€ç§æ‰“å°è¯¥å€¼åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯çš„æ–¹æ³•ã€‚
- en: and it shows kind of how you work with some of the pandasã€‚ If you run thisã€‚
    it basically gives you each of the fieldsã€‚ So the field is named miles per gallonã€‚
    The next field is named cylinders and so on and so forthã€‚ And this gives you some
    of the statisticsã€‚ The meanï¼Œ the varianceï¼Œ the standard deviation and so onã€‚Kind
    of hard to readã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸”å®ƒå±•ç¤ºäº†ä½ å¦‚ä½•ä¸ pandas ä¸€èµ·å·¥ä½œã€‚å¦‚æœä½ è¿è¡Œè¿™ä¸ªï¼Œå®ƒåŸºæœ¬ä¸Šä¼šç»™ä½ æ¯ä¸ªå­—æ®µã€‚å› æ­¤ï¼Œå­—æ®µè¢«å‘½åä¸ºæ¯åŠ ä»‘è‹±é‡Œæ•°ã€‚ä¸‹ä¸€ä¸ªå­—æ®µè¢«å‘½åä¸ºæ°”ç¼¸ï¼Œä¾æ­¤ç±»æ¨ã€‚è¿™ä¼šç»™ä½ ä¸€äº›ç»Ÿè®¡ä¿¡æ¯ï¼Œå‡å€¼ã€æ–¹å·®ã€æ ‡å‡†å·®ç­‰ç­‰ã€‚ç¨å¾®æœ‰ç‚¹éš¾è¯»ã€‚
- en: but we'll make it easy to read in a momentã€‚ Let's see how we're actually doing
    this thoughã€‚ We are taking the data frameï¼Œ and we're only using the data types
    that are integer and floatã€‚ That's effectively dropping the nameã€‚ Then we get
    the headers of these valuesã€‚ and we create an empty list called fieldsã€‚ And we're
    going to loop over each of the field in the in the columnã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ç¨åä¼šè®©å®ƒæ›´æ˜“è¯»ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å®é™…ä¸Šæ˜¯å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹çš„ã€‚æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨æ•°æ®æ¡†ï¼Œåªä½¿ç”¨æ•´æ•°å’Œæµ®ç‚¹æ•°ç±»å‹çš„æ•°æ®ã€‚è¿™å®é™…ä¸Šæ˜¯ä¸¢å¼ƒäº†åç§°ã€‚ç„¶åæˆ‘ä»¬è·å–è¿™äº›å€¼çš„æ ‡é¢˜ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªåä¸º
    fields çš„ç©ºåˆ—è¡¨ã€‚æˆ‘ä»¬å°†å¾ªç¯éå†åˆ—ä¸­çš„æ¯ä¸ªå­—æ®µã€‚
- en: So each column we're going to loop overã€‚ and we're going to append to fieldsã€‚
    a dictionary that we're just building on the flyã€‚ And this dictionary has four
    elements in itã€‚ for entries nameï¼Œ which is just the field that we're on meanã€‚Which
    is the data frameã€‚ This is how you take the mean of a column in a data frame dot
    mean dot variance and dot standard deviationã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬å°†éå†æ¯ä¸€åˆ—ï¼Œå¹¶å°†ä¸€ä¸ªæˆ‘ä»¬åŠ¨æ€æ„å»ºçš„å­—å…¸é™„åŠ åˆ°å­—æ®µä¸­ã€‚è¿™ä¸ªå­—å…¸æœ‰å››ä¸ªå…ƒç´ ï¼Œåˆ†åˆ«æ˜¯æ¡ç›®åç§°ã€æˆ‘ä»¬å½“å‰å¤„ç†çš„å­—æ®µçš„å‡å€¼ã€‚æ•°æ®æ¡†å°±æ˜¯è¿™æ ·è®¡ç®—æŸä¸€åˆ—çš„å‡å€¼ï¼š`.mean`ã€`.variance`
    å’Œ `.standard deviation`ã€‚
- en: You can do median whole whole bunch of statistical values are available toã€‚
    And then we print them outã€‚ So this is a good example of how you build up a list
    of dictionariesã€‚ which is a very common structure to useã€‚ This is this is kind
    of like a database tableã€‚ And this is also exactly the format that you can put
    data in to load it directly into a data frameã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä½¿ç”¨ä¸­ä½æ•°ï¼Œè®¸å¤šç»Ÿè®¡å€¼éƒ½å¯ä»¥ä½¿ç”¨ã€‚ç„¶åæˆ‘ä»¬å°†å®ƒä»¬æ‰“å°å‡ºæ¥ã€‚è¿™æ˜¯æ„å»ºå­—å…¸åˆ—è¡¨çš„ä¸€ä¸ªå¥½ä¾‹å­ï¼Œè¿™æ˜¯ä¸€ç§éå¸¸å¸¸è§çš„ç»“æ„ã€‚è¿™å°±åƒä¸€ä¸ªæ•°æ®åº“è¡¨æ ¼ã€‚è¿™ä¹Ÿæ˜¯ä½ å¯ä»¥å°†æ•°æ®æ”¾å…¥çš„ç¡®åˆ‡æ ¼å¼ï¼Œä»¥ä¾¿ç›´æ¥åŠ è½½åˆ°æ•°æ®æ¡†ä¸­ã€‚
- en: So here we'll see that we can take this data that we created here and turn it
    into a pandas data frameã€‚ Very handy because now we can display it nicelyã€‚ So
    we've basically created a data frame from scratchã€‚ All these mean values we put
    in Naï¼Œ standard deviations and variancesã€‚ So this dictionary that we were adding
    one by oneã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¯ä»¥å°†è¿™é‡Œåˆ›å»ºçš„æ•°æ®è½¬æ¢ä¸º pandas æ•°æ®æ¡†ã€‚è¿™éå¸¸æ–¹ä¾¿ï¼Œå› ä¸ºç°åœ¨æˆ‘ä»¬å¯ä»¥å¾ˆå¥½åœ°å±•ç¤ºå®ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯ä»å¤´å¼€å§‹åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®æ¡†ã€‚æ‰€æœ‰è¿™äº›å‡å€¼ã€æ ‡å‡†å·®å’Œæ–¹å·®çš„å€¼æˆ‘ä»¬éƒ½æ”¾åœ¨äº†
    NA ä¸­ï¼Œè¿™ä¸ªå­—å…¸æ˜¯æˆ‘ä»¬ä¸€ä¸ªä¸ªæ·»åŠ çš„ã€‚
- en: Those are like the rows in this particular table that we're creatingã€‚ Nowï¼Œ missing
    valuesã€‚ The reality is the data that you deal with as a data scientist alwaysã€‚ğŸ˜Šã€‚has
    problems fact if the data is perfectï¼Œ I would almost be afraid that there's a
    problem that I haven't seen here we're going to load in auto miles per gallon
    againã€‚ that's that same data setã€‚ but we're saying here that the NA values are
    NA and question mark because there's a few question marks in this particular data
    set there's a horsepower value that's missing So if you run this it will show
    you that yesã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å°±åƒæˆ‘ä»¬æ­£åœ¨åˆ›å»ºçš„è¿™ä¸ªç‰¹å®šè¡¨æ ¼ä¸­çš„è¡Œã€‚ç°åœ¨ï¼Œç¼ºå¤±å€¼çš„ç°å®æ˜¯ï¼Œä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œä½ å¤„ç†çš„æ•°æ®æ€»æ˜¯æœ‰é—®é¢˜ã€‚ğŸ˜Šã€‚å¦‚æœæ•°æ®å®Œç¾ï¼Œæˆ‘å‡ ä¹ä¼šæ‹…å¿ƒæˆ‘æ²¡æœ‰å‘ç°çš„é—®é¢˜ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡ŒåŠ è½½æ¯åŠ ä»‘çš„æ±½è½¦è‹±é‡Œæ•°ï¼Œè¿™å°±æ˜¯é‚£ä¸ªç›¸åŒçš„æ•°æ®é›†ã€‚ä½†æˆ‘ä»¬åœ¨è¿™é‡Œè¯´
    NA å€¼æ˜¯ NA å’Œé—®å·ï¼Œå› ä¸ºåœ¨è¿™ä¸ªç‰¹å®šæ•°æ®é›†ä¸­æœ‰å‡ ä¸ªé—®å·ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªé©¬åŠ›å€¼ç¼ºå¤±ã€‚æ‰€ä»¥å¦‚æœä½ è¿è¡Œè¿™ä¸ªï¼Œå®ƒä¼šæ˜¾ç¤ºæ˜¯çš„ã€‚
- en: horsepower does have an NA value then we fill the missing valuesã€‚ we take the
    median Now median is usually a better value to put in for missing values than
    mean because median is not that sensitive to outliers whereas mean is if you have
    a huge outlier value that's going to affect your meanã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœé©¬åŠ›ç¡®å®æœ‰ NA å€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¡«å……ç¼ºå¤±çš„å€¼ã€‚æˆ‘ä»¬å–ä¸­ä½æ•°ï¼Œç°åœ¨ä¸­ä½æ•°é€šå¸¸æ¯”å‡å€¼æ›´é€‚åˆç”¨äºå¡«å……ç¼ºå¤±å€¼ï¼Œå› ä¸ºä¸­ä½æ•°å¯¹ç¦»ç¾¤å€¼çš„æ•æ„Ÿåº¦è¾ƒä½ï¼Œè€Œå‡å€¼åˆ™è¾ƒé«˜ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªå·¨å¤§çš„ç¦»ç¾¤å€¼ï¼Œè¿™ä¼šå½±å“ä½ çš„å‡å€¼ã€‚
- en: but it's not really going to affect your median So we take the horsepower and
    we fill in the missing the NA values the missing values with that median you could
    also just drop the NA values too if you want to do that that drops the entire
    row that has a NA value and now we print out that horsepower does indeed notã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¹¶ä¸ä¼šçœŸæ­£å½±å“ä½ çš„ä¸­ä½æ•°ã€‚å› æ­¤æˆ‘ä»¬é‡‡ç”¨é©¬åŠ›ï¼Œå¹¶ç”¨é‚£ä¸ªä¸­ä½æ•°å¡«å……ç¼ºå¤±çš„ NA å€¼ï¼Œå¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åˆ é™¤ NA å€¼ï¼Œè¿™ä¼šåˆ é™¤æ•´ä¸ªåŒ…å« NA å€¼çš„è¡Œï¼Œç°åœ¨æˆ‘ä»¬æ‰“å°å‡ºé©¬åŠ›ç¡®å®æ²¡æœ‰
    NA å€¼ã€‚
- en: Have aã€‚And NA A because we've we've filled it in outliers are another thing
    that you potentially have to deal withã€‚ You can remove them or deal with them
    in other waysã€‚ I show you how to remove them hereã€‚ We are defining an outlier
    as something that is a higher numberã€‚ maybe two or more standard deviations away
    two might be a bit closeï¼Œ but maybe three or higherã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ NAï¼Œå› ä¸ºæˆ‘ä»¬å¡«å……äº†å®ƒã€‚ç¦»ç¾¤å€¼æ˜¯ä½ å¯èƒ½éœ€è¦å¤„ç†çš„å¦ä¸€ä»¶äº‹ã€‚ä½ å¯ä»¥åˆ é™¤å®ƒä»¬æˆ–ä»¥å…¶ä»–æ–¹å¼å¤„ç†å®ƒä»¬ã€‚æˆ‘åœ¨è¿™é‡Œå‘ä½ å±•ç¤ºå¦‚ä½•åˆ é™¤å®ƒä»¬ã€‚æˆ‘ä»¬å°†ç¦»ç¾¤å€¼å®šä¹‰ä¸ºé«˜äºæˆ–ä½äºå‡å€¼ä¸¤ä¸ªæˆ–æ›´å¤šæ ‡å‡†å·®çš„å€¼ï¼Œä¸¤ä¸ªå¯èƒ½æœ‰ç‚¹è¿‘ï¼Œä½†ä¹Ÿè®¸æ˜¯ä¸‰ä¸ªæˆ–æ›´é«˜ã€‚
- en: but this shows you how to remove we want to remove a fair amount so we'll remove
    anything that is more than two standard deviations above or below the mean The
    first thing we do is we calculate what our drop rows are So we are essentially
    asking for a list of the values where the absolute valueã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å‘ä½ å±•ç¤ºäº†å¦‚ä½•åˆ é™¤ï¼Œæˆ‘ä»¬æƒ³åˆ é™¤å¤§é‡æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å°†åˆ é™¤ä»»ä½•é«˜äºæˆ–ä½äºå‡å€¼ä¸¤ä¸ªæ ‡å‡†å·®çš„å€¼ã€‚æˆ‘ä»¬åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯è®¡ç®—è¦åˆ é™¤çš„è¡Œã€‚å› æ­¤æˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯åœ¨è¦æ±‚ä¸€ä¸ªç»å¯¹å€¼çš„åˆ—è¡¨ã€‚
- en: Of each of these individual valuesï¼Œ and name is the column that we're calculating
    the outliers ofã€‚ we subtract it from the meanï¼Œ and we make sure that it is not
    that amount of standard deviations aboveã€‚ And then we drop these rows that we've
    gotten all of the indexes toã€‚And we use axis equals 0 because we're dealing with
    rows and our columnsã€‚ We're not deleting columnsã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªå•ç‹¬çš„å€¼ï¼Œname æ˜¯æˆ‘ä»¬æ­£åœ¨è®¡ç®—ç¦»ç¾¤å€¼çš„åˆ—ã€‚æˆ‘ä»¬ä»å‡å€¼ä¸­å‡å»å®ƒï¼Œå¹¶ç¡®ä¿å®ƒä¸è¶…è¿‡è¯¥æ ‡å‡†å·®çš„æ•°é‡ã€‚ç„¶åæˆ‘ä»¬åˆ é™¤è¿™äº›è¡Œï¼Œè¿™äº›è¡Œçš„ç´¢å¼•å·²è·å–ã€‚æˆ‘ä»¬ä½¿ç”¨
    axis ç­‰äº 0ï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯è¡Œå’Œåˆ—ã€‚æˆ‘ä»¬å¹¶æ²¡æœ‰åˆ é™¤åˆ—ã€‚
- en: In place means that it modifies the actual data frame and does not return a
    second data frameã€‚ Run the functionã€‚ So it's in memoryã€‚ This then loads that same
    data set and creates the feature vectorã€‚ It does that by replacing the the horse
    power with the medianã€‚ We're going to drop name because weã€‚We don't need itï¼Œ doesn't
    really matter so much for this exampleã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åœ°æ„å‘³ç€å®ƒä¿®æ”¹å®é™…çš„æ•°æ®æ¡†ï¼Œè€Œä¸æ˜¯è¿”å›ç¬¬äºŒä¸ªæ•°æ®æ¡†ã€‚è¿è¡Œå‡½æ•°ã€‚å› æ­¤å®ƒåœ¨å†…å­˜ä¸­ã€‚è¿™å°†åŠ è½½ç›¸åŒçš„æ•°æ®é›†å¹¶åˆ›å»ºç‰¹å¾å‘é‡ã€‚å®ƒé€šè¿‡å°†é©¬åŠ›æ›¿æ¢ä¸ºä¸­ä½æ•°æ¥å®ç°ã€‚æˆ‘ä»¬å°†åˆ é™¤
    nameï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦å®ƒï¼Œè¿™åœ¨è¿™ä¸ªä¾‹å­ä¸­å¹¶ä¸é‡è¦ã€‚
- en: but and then we look at the length of the miles per gallon before we drop those
    values and after and we see that we went from 398 to 388 and I show of the some
    of the data here you probably really can't see a different dropping fields it's
    pretty easy to drop fields in pandas if we wanted to drop the name field we simply
    do thisã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬æŸ¥çœ‹æ¯åŠ ä»‘çš„è‹±é‡Œæ•°çš„é•¿åº¦ï¼Œçœ‹çœ‹åœ¨åˆ é™¤è¿™äº›å€¼ä¹‹å‰å’Œä¹‹åï¼Œæˆ‘ä»¬çœ‹åˆ°æ•°é‡ä» 398 å˜ä¸º 388ã€‚æˆ‘åœ¨è¿™é‡Œå±•ç¤ºäº†ä¸€äº›æ•°æ®ï¼Œä½ å¯èƒ½çœŸçš„çœ‹ä¸åˆ°æ˜æ˜¾çš„ä¸åŒã€‚åœ¨
    pandas ä¸­åˆ é™¤å­—æ®µéå¸¸ç®€å•ï¼Œå¦‚æœæˆ‘ä»¬æƒ³åˆ é™¤ name å­—æ®µï¼Œåªéœ€è¿™æ ·åšã€‚
- en: It tells you the number of columns before and after or the actual columns you
    can see name was there now it's very handy to be able to delete entire columns
    from the data frame we can also concatenate things together this becomes very
    useful when we start to generate dummy variables and other variables and we need
    to add them into our data frameã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå‘Šè¯‰ä½ åˆ—çš„æ•°é‡åœ¨å‰åæˆ–å®é™…çš„åˆ—ï¼Œä½ å¯ä»¥çœ‹åˆ° name ä¹‹å‰åœ¨é‚£é‡Œã€‚èƒ½å¤Ÿä»æ•°æ®æ¡†ä¸­åˆ é™¤æ•´ä¸ªåˆ—æ˜¯éå¸¸æ–¹ä¾¿çš„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ä¸œè¥¿è¿æ¥åœ¨ä¸€èµ·ï¼Œè¿™åœ¨æˆ‘ä»¬å¼€å§‹ç”Ÿæˆè™šæ‹Ÿå˜é‡å’Œå…¶ä»–å˜é‡æ—¶å˜å¾—éå¸¸æœ‰ç”¨ï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»¬æ·»åŠ åˆ°æ•°æ®æ¡†ä¸­ã€‚
- en: What this is going to do is we're going to create basically a new data frame
    that is just two of the values together so this is creating just name and horsepower
    so what we're doing is we're extracting horsepowerã€‚ we're extracting name and
    then we're concatenating those two together as columns axis one always means columns
    and you get this nice resulting we're just displaying the first five rowsã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®æ¡†ï¼Œä»…åŒ…å«ä¸¤ä¸ªå€¼ï¼Œå› æ­¤è¿™æ˜¯ä»…åˆ›å»º name å’Œé©¬åŠ›ã€‚æˆ‘ä»¬æå–é©¬åŠ›ï¼Œæå– nameï¼Œç„¶åå°†è¿™ä¸¤è€…ä½œä¸ºåˆ—è¿æ¥åœ¨ä¸€èµ·ï¼Œaxis 1 æ€»æ˜¯è¡¨ç¤ºåˆ—ï¼Œä½ ä¼šå¾—åˆ°è¿™ä¸ªæ¼‚äº®çš„ç»“æœï¼Œæˆ‘ä»¬åªæ˜¾ç¤ºå‰äº”è¡Œã€‚
- en: but this is how you can subselect one of them anyway ways you can subselectã€‚And
    build upã€‚Data frames from scratchï¼Œ some of the assignments will want you to do
    something very much like thisã€‚ so this is this is useful to be able to take these
    columns or series and put them together to build entirely new data frame you also
    concatenate rows together what this is doing is taking the first two and this
    last two rows so we're taking data frame from zero to two and then from minus
    two which means two back from the end to the endã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å°±æ˜¯ä½ å¯ä»¥é€‰æ‹©å…¶ä¸­ä¸€ä¸ªçš„æ–¹æ³•ï¼Œæ— è®ºä½ å¦‚ä½•é€‰æ‹©ã€‚å¹¶ä»å¤´å¼€å§‹æ„å»ºæ•°æ®æ¡†ï¼Œæœ‰äº›ä½œä¸šä¼šè¦æ±‚ä½ åšéå¸¸ç±»ä¼¼çš„äº‹æƒ…ã€‚å› æ­¤ï¼Œèƒ½å¤Ÿå°†è¿™äº›åˆ—æˆ–ç³»åˆ—æ”¾åœ¨ä¸€èµ·ä»¥æ„å»ºå…¨æ–°çš„æ•°æ®æ¡†æ˜¯éå¸¸æœ‰ç”¨çš„ï¼Œä½ è¿˜å¯ä»¥å°†è¡Œè¿æ¥åœ¨ä¸€èµ·ã€‚è¿™æ˜¯å°†å‰ä¸¤è¡Œå’Œæœ€åä¸¤è¡Œè¿æ¥èµ·æ¥ï¼Œå› æ­¤æˆ‘ä»¬ä»é›¶åˆ°äºŒå–æ•°æ®æ¡†ï¼Œç„¶åä»è´ŸäºŒå¼€å§‹ï¼Œè¿™æ„å‘³ç€ä»æœ«å°¾å¾€å›æ•°ä¸¤è¡Œåˆ°æœ«å°¾ã€‚
- en: And working catatum togetherã€‚ Now this is access zero because we're dealing
    with rowsã€‚ Another thing that you will often use pandas4 is trainingã€‚ breaking
    your training data into training and validation sets and even k folding will get
    into k folding more in a later moduleã€‚ but you can basically take your data and
    break it into a training and validation split so that you have your entire data
    set hereã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä¸€èµ·å¤„ç† catatumã€‚è¿™æ˜¯è®¿é—®é›¶ï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯è¡Œã€‚ä½ ç»å¸¸ä¼šä½¿ç”¨ pandas4 è¿›è¡Œè®­ç»ƒã€‚å°†è®­ç»ƒæ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œç”šè‡³è¿›è¡Œ k æŠ˜äº¤å‰éªŒè¯ï¼Œåœ¨åé¢çš„æ¨¡å—ä¸­ä¼šæ·±å…¥è®¨è®º
    k æŠ˜äº¤å‰éªŒè¯ã€‚ä½†ä½ åŸºæœ¬ä¸Šå¯ä»¥å°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œè¿™æ ·ä½ å°±å¯ä»¥åœ¨è¿™é‡Œæ‹¥æœ‰æ•´ä¸ªæ•°æ®é›†ã€‚
- en: but you're taking 80% for training 20% for validationã€‚ You'll usually train
    and fit your model on the training set and you'll evaluate that model created
    from the training set on your validation set This is some simple code that shows
    how to do this We're basically using the mask here to create aã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ å–80%ä½œä¸ºè®­ç»ƒï¼Œ20%ä½œä¸ºéªŒè¯ã€‚ä½ é€šå¸¸ä¼šåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå’Œæ‹Ÿåˆä½ çš„æ¨¡å‹ï¼Œå¹¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ä»è®­ç»ƒé›†ä¸­åˆ›å»ºçš„æ¨¡å‹ã€‚è¿™æ˜¯ä¸€æ®µç®€å•çš„ä»£ç ï¼Œå±•ç¤ºäº†å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šæ˜¯åœ¨è¿™é‡Œä½¿ç”¨æ©ç æ¥åˆ›å»ºä¸€ä¸ªã€‚
- en: A mask of valuesï¼Œ so this is just a list of truths and falsesã€‚The truths are
    the ones that will be included and the falses are the ones that are notã€‚ so since
    we're taking 80% the training data frameã€‚Basically gets the data frame with the
    mask applied opposite mass and we're able to print out that we have our training
    set of 312 and our validation set of 86ã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç»„å€¼çš„æ©ç ï¼Œè¿™åªæ˜¯ä¸€ç»„çœŸå’Œå‡çš„åˆ—è¡¨ã€‚çœŸæ˜¯ä¼šè¢«åŒ…å«çš„ï¼Œè€Œå‡åˆ™ä¸ä¼šã€‚å› æ­¤ï¼Œç”±äºæˆ‘ä»¬å–äº†80%çš„è®­ç»ƒæ•°æ®æ¡†ã€‚åŸºæœ¬ä¸Šï¼Œå¾—åˆ°åº”ç”¨æ©ç åçš„æ•°æ®æ¡†ï¼Œåå‘æ©ç ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ‰“å°å‡ºæˆ‘ä»¬çš„è®­ç»ƒé›†ä¸º312ï¼Œè€ŒéªŒè¯é›†ä¸º86ã€‚
- en: This is very important you don't send data frames directly onto Kras you need
    to be able to use nuy for that Numpy do values is what does this so here you can
    see it's basically taken the values and created a matrix Now you may not want
    all of these values like that name here is not numeric so that could cause problemsã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸é‡è¦ï¼Œä½ ä¸èƒ½ç›´æ¥å°†æ•°æ®æ¡†å‘é€åˆ°Krasï¼Œä½ éœ€è¦èƒ½å¤Ÿä½¿ç”¨nuyæ¥å®ç°ã€‚Numpyçš„do valuesæ­£æ˜¯è¿™æ ·åšçš„ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°ï¼Œå®ƒåŸºæœ¬ä¸Šæ˜¯æå–äº†å€¼å¹¶åˆ›å»ºäº†ä¸€ä¸ªçŸ©é˜µã€‚ç°åœ¨ä½ å¯èƒ½ä¸æƒ³è¦æ‰€æœ‰è¿™äº›å€¼ï¼Œæ¯”å¦‚è¿™é‡Œçš„åå­—ä¸æ˜¯æ•°å­—ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´é—®é¢˜ã€‚
- en: You can pass in a list now you often see this in Python as source of some confusion
    when you have the double brace for a arrayã€‚ It's not a double braceã€‚ It just means
    that the index that you're passing in is a listã€‚ so you're saying that I want
    all the rows from the data frame but I want just these columnsã€‚And if you run
    that one now without the name there now you don't have that ugly character string
    in there it's pure numericã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç°åœ¨å¯ä»¥ä¼ å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿™åœ¨Pythonä¸­ç»å¸¸ä¼šå¼•èµ·ä¸€äº›æ··æ·†ï¼Œå½“ä½ çœ‹åˆ°æ•°ç»„çš„åŒå¤§æ‹¬å·æ—¶ã€‚è¿™ä¸æ˜¯åŒå¤§æ‹¬å·ã€‚è¿™åªæ˜¯æ„å‘³ç€ä½ ä¼ å…¥çš„ç´¢å¼•æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚å› æ­¤ä½ æ˜¯åœ¨è¯´ï¼Œæˆ‘æƒ³è¦æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰è¡Œï¼Œä½†æˆ‘åªæƒ³è¦è¿™äº›åˆ—ã€‚å¦‚æœä½ ç°åœ¨è¿è¡Œè¿™ä¸€æ®µï¼Œæ²¡æœ‰åå­—ï¼Œé‚£æ ·ä½ å°±æ²¡æœ‰äº†é‚£ä¸ªä¸‘é™‹çš„å­—ç¬¦å­—ç¬¦ä¸²ï¼Œå®ƒæ˜¯çº¯æ•°å­—çš„ã€‚
- en: which is what you want to haveã€‚ We'll see more about this when we learn how
    to prepare feature vectors for neural networks you can save a data frame that
    you've created or modified to a CSV file This allows you to view it outside of
    Jupyter notebook using Excel or preferably something more advanced for CSV file
    viewing you have to be careful with Excel it tends to modify CSV files and we'll
    even corrupt them by removing leading zeros and other things and it also has kind
    of limited support of text encodings like UTF 8 just using Excel to view things
    can be okay but just be aware it may reformat some of the data and corrupt it
    Now when you save it as a CSV file that can be useful because that's what I often
    have you submit those those files to me in that form for some of the assignmentsã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä½ æƒ³è¦çš„ã€‚å½“æˆ‘ä»¬å­¦ä¹ å¦‚ä½•ä¸ºç¥ç»ç½‘ç»œå‡†å¤‡ç‰¹å¾å‘é‡æ—¶ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æ›´å¤šçš„å†…å®¹ã€‚ä½ å¯ä»¥å°†åˆ›å»ºæˆ–ä¿®æ”¹çš„æ•°æ®æ¡†ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Œè¿™å…è®¸ä½ åœ¨Jupyter Notebookå¤–éƒ¨ä½¿ç”¨Excelæˆ–æ›´é«˜çº§çš„CSVæ–‡ä»¶æŸ¥çœ‹å·¥å…·æŸ¥çœ‹å®ƒã€‚ä½ å¿…é¡»å°å¿ƒä½¿ç”¨Excelï¼Œå®ƒå¾€å¾€ä¼šä¿®æ”¹CSVæ–‡ä»¶ï¼Œç”šè‡³ä¼šé€šè¿‡åˆ é™¤å‰å¯¼é›¶å’Œå…¶ä»–æ–¹å¼æ¥ç ´åå®ƒï¼Œå¹¶ä¸”å®ƒå¯¹æ–‡æœ¬ç¼–ç å¦‚UTF-8çš„æ”¯æŒä¹Ÿæœ‰é™ã€‚ä»…ä½¿ç”¨ExcelæŸ¥çœ‹å†…å®¹æ˜¯å¯ä»¥çš„ï¼Œä½†è¦æ³¨æ„å®ƒå¯èƒ½ä¼šé‡æ–°æ ¼å¼åŒ–æŸäº›æ•°æ®å¹¶ç ´åå®ƒã€‚ç°åœ¨ï¼Œå½“ä½ å°†å…¶ä¿å­˜ä¸ºCSVæ–‡ä»¶æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºæˆ‘é€šå¸¸ä¼šè®©ä½ ä»¥è¿™ç§å½¢å¼æäº¤è¿™äº›æ–‡ä»¶ä½œä¸ºä¸€äº›ä½œä¸šã€‚
- en: When you compete in the CAgle competitionï¼Œ you'll often submit a CSV file for
    thatã€‚I'll post exact requirements for the Caggle competition for this semester
    when we reach that pointã€‚The command to save a CSV follows simply this to CSVã€‚And
    we areã€‚Essentially just shuffling this data frame and then writing it backã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ å‚åŠ CAgleç«èµ›æ—¶ï¼Œä½ é€šå¸¸ä¼šæäº¤ä¸€ä¸ªCSVæ–‡ä»¶ã€‚æˆ‘ä¼šåœ¨æˆ‘ä»¬åˆ°è¾¾é‚£ä¸ªç‚¹æ—¶å‘å¸ƒæœ¬å­¦æœŸCAgleç«èµ›çš„ç¡®åˆ‡è¦æ±‚ã€‚ä¿å­˜CSVçš„å‘½ä»¤ç®€å•å¦‚ä¸‹to CSVã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šåªæ˜¯åœ¨æ´—ç‰Œè¿™ä¸ªæ•°æ®æ¡†ï¼Œç„¶åå†™å›å»ã€‚
- en: Index equals false usually you want index equals false because that is going
    to tell it not to put a row number on each on each row Now when you run this it
    just says done and it generates the CSv in the path that we said dot means the
    current directory if you're using Google coab which you probably are you should
    put the path to your mapped G driveve up there and then it will output it to a
    place that you can get a hold of that file and you can take a look at that in
    Google Docs or something else Google Docs is a very good program for viewing for
    viewing CSVs saving a data frame to pickle Pickle is a binary file format so when
    you save it a CSv you're basically writing it out to a text file which you often
    read it from but you can run into very very small precision problems when you
    bring things back and forth between CSv files usually this is not a problem it's
    only a problem if you're trying to diff two files soã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç´¢å¼•ç­‰äº falseï¼Œé€šå¸¸ä½ å¸Œæœ›ç´¢å¼•ç­‰äº falseï¼Œå› ä¸ºè¿™ä¼šå‘Šè¯‰å®ƒä¸è¦åœ¨æ¯ä¸€è¡Œä¸Šæ”¾ç½®è¡Œå·ã€‚ç°åœ¨ï¼Œå½“ä½ è¿è¡Œè¿™ä¸ªæ—¶ï¼Œå®ƒåªæ˜¯æ˜¾ç¤ºå®Œæˆï¼Œå¹¶ç”Ÿæˆæˆ‘ä»¬æ‰€è¯´çš„è·¯å¾„ä¸­çš„
    CSVï¼Œç‚¹è¡¨ç¤ºå½“å‰ç›®å½•ã€‚å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ Google Colabï¼Œå¯èƒ½éœ€è¦å°†ä½ æ˜ å°„çš„ G ç›˜è·¯å¾„æ”¾åœ¨é‚£é‡Œï¼Œç„¶åå®ƒä¼šå°†è¾“å‡ºæ”¾åˆ°ä½ å¯ä»¥è·å–è¯¥æ–‡ä»¶çš„åœ°æ–¹ï¼Œä½ å¯ä»¥åœ¨
    Google Docs æˆ–å…¶ä»–åœ°æ–¹æŸ¥çœ‹å®ƒã€‚Google Docs æ˜¯æŸ¥çœ‹ CSV çš„éå¸¸å¥½ç”¨çš„ç¨‹åºã€‚å°†æ•°æ®æ¡†ä¿å­˜ä¸º pickleï¼Œpickle æ˜¯ä¸€ç§äºŒè¿›åˆ¶æ–‡ä»¶æ ¼å¼ï¼Œå› æ­¤å½“ä½ ä¿å­˜ä¸º
    CSV æ—¶ï¼Œå®é™…ä¸Šæ˜¯å°†å…¶å†™å…¥æ–‡æœ¬æ–‡ä»¶ä¸­ï¼Œè¿™é€šå¸¸å¯ä»¥è¯»å–ï¼Œä½†åœ¨ CSV æ–‡ä»¶ä¹‹é—´æ¥å›ä¼ è¾“æ—¶å¯èƒ½ä¼šé‡åˆ°éå¸¸å°çš„ç²¾åº¦é—®é¢˜ï¼Œé€šå¸¸è¿™ä¸æ˜¯é—®é¢˜ï¼Œåªæœ‰åœ¨ä½ è¯•å›¾æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶æ—¶æ‰ä¼šå‡ºç°ã€‚
- en: Pickle will ensure that you get an exact rendering of theã€‚Of the file and it
    also stores other metadata that is stored in the data frame that simply doesn't
    fit into a CSV like row numbersã€‚ if I run thisï¼Œ it simply tells me that that I'm
    done again it this it did this reindex scene againã€‚ we will load the pickle file
    backã€‚It's done with this pickle load pickle dump is how you save it and this loads
    it back in Now here's something important to note this is the fileã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle å°†ç¡®ä¿ä½ è·å¾—æ–‡ä»¶çš„å‡†ç¡®æ¸²æŸ“ï¼Œå¹¶ä¸”å®ƒè¿˜å­˜å‚¨åœ¨æ•°æ®æ¡†ä¸­ä¸é€‚åˆå­˜å…¥ CSV çš„å…¶ä»–å…ƒæ•°æ®ï¼Œæ¯”å¦‚è¡Œå·ã€‚å¦‚æœæˆ‘è¿è¡Œè¿™ä¸ªï¼Œå®ƒåªæ˜¯å‘Šè¯‰æˆ‘æˆ‘å·²ç»å®Œæˆäº†ï¼Œå†æ¬¡è¿›è¡Œäº†è¿™ä¸ªé‡æ–°ç´¢å¼•çš„æ“ä½œã€‚æˆ‘ä»¬å°†é‡æ–°åŠ è½½
    pickle æ–‡ä»¶ï¼Œä½¿ç”¨ pickle dump æ¥ä¿å­˜ï¼Œè€Œè¿™ä¼šå°†å…¶åŠ è½½å›å»ã€‚ç°åœ¨ï¼Œæœ‰ä¸€ç‚¹å¾ˆé‡è¦è¦æ³¨æ„ï¼Œè¿™æ˜¯æ–‡ä»¶ã€‚
- en: these are all the columns and everythingï¼Œ but here's how you can tell the difference
    between loading a pickle file and loading a CSV file notice the row numbers don't
    line up because we we reined it and we didn't rebuild that index so thatã€‚That
    was stored in the pickle file that would have been lost in the CSV file now typically
    you wouldn't mind necessarily losing thoseã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯æ‰€æœ‰åˆ—å’Œå†…å®¹ï¼Œä½†è¿™é‡Œæ˜¯ä½ å¯ä»¥åŒºåˆ†åŠ è½½ pickle æ–‡ä»¶å’ŒåŠ è½½ CSV æ–‡ä»¶çš„æ–¹æ³•ï¼Œæ³¨æ„è¡Œå·ä¸å¯¹é½ï¼Œå› ä¸ºæˆ‘ä»¬è¿›è¡Œäº†é‡æ’ï¼Œè€Œä¸”æˆ‘ä»¬æ²¡æœ‰é‡å»ºç´¢å¼•ã€‚å› æ­¤ï¼Œå­˜å‚¨åœ¨
    pickle æ–‡ä»¶ä¸­çš„å†…å®¹åœ¨ CSV æ–‡ä»¶ä¸­å°†ä¼šä¸¢å¤±ï¼Œé€šå¸¸ä½ å¹¶ä¸åœ¨æ„ä¸¢å¤±è¿™äº›ã€‚
- en: but your actual row numbers from when it was first loadedã€‚ these are only out
    of order because we shuffled itã€‚ but that is not something that would be stored
    into a CSV fileã€‚![](img/1db266afde3ffa4a6350ef9fc4060579_3.png)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ä½ å®é™…çš„è¡Œå·æ˜¯ä»æœ€åˆåŠ è½½æ—¶æ¥çš„ã€‚è¿™äº›è¡Œå·åªæ˜¯å› ä¸ºæˆ‘ä»¬è¿›è¡Œäº†æ´—ç‰Œè€Œä¸æŒ‰é¡ºåºæ’åˆ—ï¼Œä½†è¿™å¹¶ä¸æ˜¯ä¼šå­˜å‚¨åˆ° CSV æ–‡ä»¶ä¸­çš„å†…å®¹ã€‚![](img/1db266afde3ffa4a6350ef9fc4060579_3.png)
- en: Thank you for watching this video on the introduction to pandasã€‚ We will see
    how to do more advanced processing with pandas in the other parts of this moduleã€‚
    This content changes oftenï¼Œ so subscribe to the channel to stay up to date on
    this course and other topics in artificial intelligenceã€‚ğŸ˜Šã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢è§‚çœ‹å…³äº pandas ä»‹ç»çš„è§†é¢‘ã€‚æˆ‘ä»¬å°†åœ¨æœ¬æ¨¡å—çš„å…¶ä»–éƒ¨åˆ†æ·±å…¥æ¢è®¨å¦‚ä½•è¿›è¡Œæ›´é«˜çº§çš„å¤„ç†ã€‚è¯¥å†…å®¹ç»å¸¸æ›´æ–°ï¼Œå› æ­¤è¯·è®¢é˜…é¢‘é“ä»¥è·å–æœ‰å…³æœ¬è¯¾ç¨‹å’Œäººå·¥æ™ºèƒ½å…¶ä»–ä¸»é¢˜çš„æœ€æ–°ä¿¡æ¯ã€‚ğŸ˜Š
