- en: „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÈù¢ÂêëÂàùÂ≠¶ËÄÖÁöÑ TensorFlow ÊïôÁ®ãÔºåÁêÜËÆ∫Áü•ËØÜ„ÄÅ‰ª£Á†ÅÊÄùË∑ØÂíåÂ∫îÁî®Ê°à‰æãÔºåÁúüÊ≠£‰ªéÈõ∂ÂºÄÂßãËÆ≤ÊòéÁôΩÔºÅÔºúÂø´ÈÄüÂÖ•Èó®Á≥ªÂàóÔºû - P5ÔºöL5- Âç∑ÁßØÁ•ûÁªèÁΩëÁªú(CNN)
    - ShowMeAI - BV1TT4y1m7Xg
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_0.png)'
  prefs: []
  type: TYPE_IMG
- en: üéºÔºåHeyÔºå guysÔºå welcome to another Tensorflow tutorial„ÄÇ Today„ÄÇ we are going to
    implement our first convolutional neural net„ÄÇ So a convolutional neural net looks
    similar to our feet forward neural net from lesson number 3„ÄÇ The main difference
    now is that we use convolutional filters instead of just dense layers„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So here's a typical architecture of a confnet„ÄÇ We have our input image„ÄÇ and
    then we apply different convolutional layers with activationation functions like
    hereÔºå the relo„ÄÇ And we also apply pooling layers to reduce the size of our image„ÄÇ
    And then at the end„ÄÇ we do classification„ÄÇ And this means that we use a fully
    connected layer at the end„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Also known as the dense layer„ÄÇ with an output for each class that we have„ÄÇ So
    our convolutional layer uses convolutional filters and the filter slides over
    the image and then„ÄÇüòäÔºåCalculates a new value and writes it into the output image„ÄÇ
    so I will not go into detail here„ÄÇ but I will provide some links if you want to
    learn more about the theory here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So here's another image of a convolutional filter„ÄÇ So at first we put it at
    the rat position and then we calculate the convolution and write the output in
    here and then we slide it to the next position„ÄÇ So the green one and do the same
    and then we slide it to the blue position and do the same„ÄÇ And this is how we
    calculate the convolutions„ÄÇ And then we also apply max pooling„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: which is also just a filterÔºå for exampleÔºå hereÔºå a two by two filter and we put
    it at the first position and calculate just the maximum value like here„ÄÇ the 20
    and write it to the output„ÄÇ and then we slide it to the next position and do the
    same and so on„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So this reduces„ÄÇThe size of our image„ÄÇ And this is all the concepts that we're
    going to apply„ÄÇ So here again is an image of the architecture that we are going
    to implement„ÄÇ So we have the input image then we apply convolution plus the reo
    activationation function plus pooling„ÄÇ then we do the same thing again„ÄÇ And at
    the end we do we flatten the image to squeeze it into one dimension and use a
    fully connected dense layer with the softmax activationation function and then
    do the classification„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So this step at the end is the exact same that we used in tutorial number3„ÄÇ
    So I recommend that you watch this one first„ÄÇ if you haven't already And now we
    can jump to the code„ÄÇ So in this exampleÔºå we are going to use the scipher 10 dataset
    set„ÄÇ This is a image data set of 60032 by 32 color images and we have0„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: 1 different classes that we see hereÔºå for exampleÔºå airplaneÔºå a carÔºå bird cat
    and so on„ÄÇ And this is what were going to classify„ÄÇ So now let's jump to the code„ÄÇ
    Alright„ÄÇ so here I've already written some code„ÄÇ So this is similar to the code
    and tutorial number 3 So again„ÄÇ we import the things we need like Tensorflow and
    ks and layers„ÄÇ Then I import matpllip„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Then we use the ci for 10 data setÔºå which is integrated in Kara data sets and
    we can split this into training images and test images„ÄÇ And now if you print the
    shapeÔºå we seeÔºå for example„ÄÇ that this is the training images has 50000 samples
    and each image has the site 32 by 32 by 3 because it has three color channels„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_2.png)'
  prefs: []
  type: TYPE_IMG
- en: Then we normalize our data„ÄÇ So we want it to be in the range from 0 to 1„ÄÇ Then
    here I have the different class names„ÄÇ and I written I've written a helper function
    to show you some example images„ÄÇ So let's run it up until here„ÄÇ So now if I say
    Python„ÄÇ and then the name of this file„ÄÇ Then we see some example images here„ÄÇ
    and the images are very blur because our dimensions are very small„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: but that's okay„ÄÇ So now let's stop this„ÄÇ and now I can remove this code for
    plotting„ÄÇ So we don't need this anymore„ÄÇ![](img/f02af098f9ad70406fc18680eac4bd94_4.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_5.png)'
  prefs: []
  type: TYPE_IMG
- en: And now here we define our Kaa sequential model like the last time„ÄÇ And now
    this is what we have to implement„ÄÇ And then the code after that is exactly the
    same as in tutorial number 3„ÄÇ So againÔºå we define our loss and the optimizer„ÄÇ
    So here we want the sparse categorical cross entropy and say from logics equals
    true„ÄÇ So that it applies the softm„ÄÇ So this is important here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: Then we define some metrics that we want to track„ÄÇ And then we have to call
    model compile„ÄÇ and after thatÔºå we start our training by simply calling model dot
    fit with our training images and training labels„ÄÇ And then we can evaluate it
    by calling model dot evaluate with the test images and the test labels„ÄÇ So yeahÔºå
    that's the whole code„ÄÇ And now the only thing left to do here is to define our
    model„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So now let's have a look again„ÄÇ So againÔºå we want to apply„ÄÇ![](img/f02af098f9ad70406fc18680eac4bd94_7.png)
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layers with an activation function and a pooling layer„ÄÇ And then
    the same thing again„ÄÇ And at the endÔºå we want to flatten it and apply the fully
    connected layer„ÄÇ So let's do this„ÄÇ So firstÔºå let's add a convolution layer„ÄÇ So
    we can do this by saying model dot at„ÄÇ And then we use a layer from ks dot layers„ÄÇ
    And then this is the con2D layer„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So a 2D convolutional layer„ÄÇ And now firstÔºå we have to specify the filters„ÄÇ
    So this is the number of output filters after this convolution„ÄÇ So here we say
    32„ÄÇ Then we have to specify the kernel size„ÄÇ So here let's use a filter kernel
    of size 3 by3„ÄÇ Then I also write the strides and„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_9.png)'
  prefs: []
  type: TYPE_IMG
- en: Heading here for you„ÄÇ So strides equalsÔºå let's say 1 and one„ÄÇ This is just the
    default„ÄÇ How much we want to slideÔºå how far we want to slide it over the image„ÄÇAnd
    padding equals valet„ÄÇ So you have the option to say validale or same„ÄÇ These are
    basically two different rules„ÄÇ How the padding is applied„ÄÇ So let's say valid
    here„ÄÇ And thenÔºå as I said„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: we want to use an activationation„ÄÇ So we say activationation equals Relu„ÄÇ And
    for our first layer„ÄÇ we also specify the input shape„ÄÇ And this is 32 by 32 by
    3„ÄÇAnd now we have this„ÄÇ So nowÔºå after that„ÄÇ we want to apply a pooling layer„ÄÇ
    So we say model dot at„ÄÇ And then againÔºå layers dot maxs„ÄÇPoulling 2D„ÄÇ And then
    here also we can define the pool size„ÄÇ So here„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's just use two by two as default„ÄÇ or I can again write it for you so that
    it's clearer so we use a two by2 max pooling layer And then we do the same thing
    again„ÄÇ So let's copy and paste this„ÄÇ And here we remove the input shape so we
    don't need this anymore„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And let's also remove this because this is just the default„ÄÇ And then here I
    want to show you that you can specify a value for each dimension„ÄÇ or you can just
    specify a single integer value„ÄÇ And then it's using this for each dimension„ÄÇ So
    this is the same as this„ÄÇAnd then againÔºå a another max pooling layer„ÄÇAnd now we
    want to„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: let's have a look again„ÄÇ Now we want to flatten it and then apply the fully
    connected layer„ÄÇ So now we add a model dot add and then layers dot flatten„ÄÇ![](img/f02af098f9ad70406fc18680eac4bd94_11.png)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f02af098f9ad70406fc18680eac4bd94_12.png)'
  prefs: []
  type: TYPE_IMG
- en: So we squeeze it into one dimensionÔºå and then we say model dot add„ÄÇ And we want
    to add a dense layer„ÄÇ So layers dot„ÄÇDenseÔºå and then here let's use a hidden size
    of 64„ÄÇ and also an activation„ÄÇ And here againÔºå we use relu„ÄÇ And then let's do
    the same thing at the end„ÄÇ So model dot at a dense layer„ÄÇ And now we have to specify
    10 output classes„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And here we don't want an activation function because we say from Los equals
    true for our loss„ÄÇAnd now this is all that we need„ÄÇ So this is our first convolutional
    neural network„ÄÇ And now„ÄÇ for exampleÔºå we can call print and then print the model
    dot summary„ÄÇ And now„ÄÇSo for now„ÄÇ let's stop here„ÄÇ So I say import cis and cis
    dot exit„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: So it stops here and then don't start the training„ÄÇ So let's run it again and
    see if it works„ÄÇAlrightÔºå so now this works„ÄÇ So here it prints the summary„ÄÇ And
    then again„ÄÇ we can inspect our different layers and the output shapes of each
    layers and the number of parameters that we have for training„ÄÇ So yeahÔºå this is
    basically an overview of our convolutional neural net„ÄÇ And now we can remove this„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: And then the same as last time we compile the model and fit it and evaluate
    it„ÄÇ So let's run it„ÄÇ So let's clear this and run the training„ÄÇ AlrightÔºå so training
    is done„ÄÇ And we see that the loss decreased and the accuracy improve with with
    each epoch„ÄÇ and then we have a final evaluation accuracy„ÄÇ So it's not perfect
    yet„ÄÇ It's only an accuracy of 65%„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: But we also only train it for 5 epoch„ÄÇ So I'm sure that this will get better
    if we train it„ÄÇLonger„ÄÇ soÔºå yeahÔºå now you see that our con is working„ÄÇ and you
    know how you define and set up your model„ÄÇ And now you canÔºå for exampleÔºå play
    around with the learning rate or play around with different architectures here„ÄÇ
    And then you can further improve the accuracy„ÄÇ SoÔºå yeah„ÄÇ
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed this tutorial and please hit the like button and consider
    subscribing to the channel„ÄÇ And I hope to see you in the next video by„ÄÇ![](img/f02af098f9ad70406fc18680eac4bd94_14.png)
  prefs: []
  type: TYPE_NORMAL
