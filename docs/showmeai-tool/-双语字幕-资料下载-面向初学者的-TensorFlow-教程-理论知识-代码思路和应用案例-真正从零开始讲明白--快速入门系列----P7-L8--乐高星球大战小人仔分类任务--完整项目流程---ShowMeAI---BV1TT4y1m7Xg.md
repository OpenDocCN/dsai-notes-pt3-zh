# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é¢å‘åˆå­¦è€…çš„ TensorFlow æ•™ç¨‹ï¼Œç†è®ºçŸ¥è¯†ã€ä»£ç æ€è·¯å’Œåº”ç”¨æ¡ˆä¾‹ï¼ŒçœŸæ­£ä»é›¶å¼€å§‹è®²æ˜ç™½ï¼ï¼œå¿«é€Ÿå…¥é—¨ç³»åˆ—ï¼ - P7ï¼šL8- ä¹é«˜æ˜Ÿçƒå¤§æˆ˜å°äººä»”åˆ†ç±»ä»»åŠ¡  å®Œæ•´é¡¹ç›®æµç¨‹ - ShowMeAI - BV1TT4y1m7Xg

![](img/7956a7f6b5a10c99728c67c08635cf0e_0.png)

ğŸ¼ï¼ŒHeyï¼Œ guysï¼Œ welcome to another Tensorflow tutorial Todayï¼Œ I'll do another full project walkthroughã€‚

 And I think this project is going to be real fun because we're going use a real image data set from Kaaggle with Lego Star Wars minifisã€‚

 And we're trying to classify the charactersã€‚ So along the wayã€‚

 we will learn how we download and organize our data and how we load the images into Tensorflow and preprocessed themã€‚

 Then we set up a convolutional neural netï¼Œ train it and save our modelã€‚ And along the wayã€‚

 I'll also introduce some new concepts like image augmentation and Kara callbesã€‚

 So I hope you stay until the end and we'll find out if we can correctly identify Luke Skywalkerã€‚

 So here is the image data set that's available on Cagelã€‚ and I will put the link in a descriptionã€‚

 and then you can just click on download and download the dataã€‚

 So I already did this and copied it inã€‚ğŸ˜Šï¼Œto my project directoryã€‚ So here this Lego folderã€‚

 And we have some different categories like Harry Potter and Jurasic Worldã€‚

 But now I'm only going to use the Star Wars figures to make it simpler and easier to follow for youã€‚

 So let's make a copy of this folder so that we have a backup because we are going to reorganize the data a little bitã€‚

 So let's rename this to Star Wars imagesã€‚ And then inside hereï¼Œ we have 10 different classesã€‚

 but right now I'm only going to use the first fiveã€‚ So againï¼Œ to make it simpler for youã€‚

 And now let's have a look at these imagesã€‚ So now in this Star Wars images folderã€‚ We haveã€‚

 for exampleï¼Œ class1ã€‚ This is Yodaã€‚

![](img/7956a7f6b5a10c99728c67c08635cf0e_2.png)

Class two is Luke Skywalkerã€‚

![](img/7956a7f6b5a10c99728c67c08635cf0e_4.png)

Then we also have R2 D2ï¼Œ then we also have Macce windowã€‚ and as last characterã€‚

 we use general grievsã€‚ So these are the characters that we want to identify and right now the first thing I want to do is to reorganize this folder structure a little bitã€‚

 So you could load it like this and you also have some met data with the information for each directory so can you can load it with thisã€‚

 So I want to make it a little bit simpler so that we can easily load it with the tens of low image and loaderã€‚

 So I want to separate the data set into training images validation images and test imagesã€‚

 So we create three folders in here and then inã€‚

![](img/7956a7f6b5a10c99728c67c08635cf0e_6.png)

Each of the foldersï¼Œ we again create images for each characterã€‚ For exampleã€‚

 we have a training folderï¼Œ and then in the subfoldï¼Œ we have a folder for Yodaã€‚

 Luke Skywalker and so onã€‚ So this is the first thing we are going to doã€‚

 So here I'm in a twopyter notebookã€‚ And here we import the things that we needã€‚

Then here I named the base directory where we have the images and then I hardcoded the names of each characterã€‚

 So these five and I'm also setting a random seat to make it a little bit more reproducible and now the first thing we want to do is to create our different foldersã€‚

 So we can of course automate this with Pythonã€‚ So now if I run this code and we have a look then here in here it created these three new folders and then inside of each it created a folder for each character that we haveã€‚

 So right now these are empty and now we're going to take the images from in here and then copy them into here and so weã€‚

We have about 12 or 12 to 14 different images for each characterã€‚I know this is not a big amountã€‚

 especially not for deep learningï¼Œ but it's enough for this tutorial and I show you at the end that we get a pretty good accuracyã€‚

So yeahï¼Œ now we want to take about 60% for trainingã€‚

 then 25% for validation and the rest for testing and then copy them into these foldersã€‚

 So if I run thisã€‚Then it prints the total number of images in each directory and then the number of training samplesã€‚

 validation samples and test samplesã€‚ So now if we go back in hereã€‚

 then each of these folders here are empty so we can actually delete them so now move to trash and now in the training folderã€‚

 for exampleï¼Œ we should have the imagesï¼Œ so we have training images for each one testing images for each one and validation images for each characterã€‚

So againï¼Œ this is what your structure should look likeã€‚

 and this makes it very easy for the Tensorflow image data loaderã€‚

So now we can go ahead and set up our image data generator so we can get this from Kras preprocessing dot image do image data generator and in here you can pass in your own preprocessing function for exampleã€‚

 you can write a function that normalizes the dataã€‚

 but in the special case that we only want to normalize itã€‚

 we can also pass in the rescale argument and then here we use one divided by 255 so we want to have our image in the range between0 and1 like we did in the examples beforeã€‚

And then we have to call this with this generatorï¼Œ we call the flow from directory functionã€‚

 and then in here we pass in the directory for trainingã€‚

 So this is in Lego Star Wars images and then train and then we can specify the target sizeã€‚

 So right now I think the images have to dimension 512 by 512 and we can specify a target size and Tensorflow automatically does the resizing for usã€‚

Then I specify the class mode because I want to have the labels as a single integer valueã€‚

 So you can alsoï¼Œ for exampleï¼Œ use one hot encoding hereã€‚Then you can use the batch sizeã€‚

 Then for our training imagesï¼Œ we say shuffle equals trueã€‚ Then we specify that we have RGB imagesã€‚

 So againï¼Œ you canï¼Œ you can check out the arguments in the documentationã€‚

 and then we specify the class names that I hard coded up hereã€‚

And then we do the same thing for the validation and testã€‚

Images and the only difference here is that we use so for trainingï¼Œ we use shuffle equals trueã€‚

 and for validationï¼Œ we say this is falseã€‚ And so here it doesn't really matterã€‚

 but especially for testingï¼Œ you want shuffle equals falseã€‚ So now if we run thisã€‚

 then Tensorflow automatically loads this for usã€‚ So for exampleï¼Œ we have let's print theã€‚

Shapes of the test batchã€‚ So we said we only have batch size of fourã€‚

 So this is why we have four differentã€‚Labels hereã€‚And if we have a look at the very first batchã€‚

 then this is four because we have four samples and then each image has the size 256 by 256 by3 because here we specified this image size and we have three color channels so let's for exampleã€‚

 plot some images with Matpllip so here for example it prints the first four images of the test batch so here we have Yoda and Duke Skywalker and here we have we print four images of the training batch So yeah and now one more thing that I want to show you what we can very easily do with this image data generator is to use image augmentation so if we have a look at tens of flowã€‚

Then data augmentation is a technique to increase the diversity of your training set by applying random transformations such as image rotation or flippingã€‚

So this is very useful to have a better generalization of your modelã€‚

 and we can very easily get this with this data generatorã€‚

 So the only thing we have to pass in here are some more argumentsã€‚ And then if we want to have thisã€‚

 then we only do this for the training data setã€‚ So hereï¼Œ for exampleã€‚

 we can specify the rotation rangeã€‚ we can specify a random horizontal flip and we can also specify the a high shift and a width shift and also shearing and zoomingã€‚

So now if we use thisã€‚ So let me apply all these andã€‚Then againã€‚

 you only want to do this for your training data and not for theseã€‚

 And there are several different waysã€‚ Soï¼Œ of courseã€‚

 you can also write your own functions to do thisã€‚ But this image data generator makes it very simpleã€‚

 So now let's run this again with an image augmentationã€‚ So let's run this and thisã€‚

 and this one againã€‚ and yeahï¼Œ so here we seeï¼Œ for exampleã€‚

 we have a slight rotation and probably also a different zoom factor and maybe some shearing effects hereã€‚

 So yeahï¼Œ let's run it againã€‚ So let's take another random pick from the batchesã€‚And againã€‚

 let's have a lookã€‚And yeahï¼Œ I think you can definitely see that it's doing something with the imagesã€‚

 So againï¼Œ this one is rotated hereã€‚ So yeahï¼Œ this is a very nice technique that you can easily apply hereã€‚

 So I'm going to remove this again for nowï¼Œ So because we don't have so many imagesã€‚

 And in this caseï¼Œ its it actually might confuse our model and make the accuracy worseã€‚

 So in this exampleï¼Œ I'm going to leave this outã€‚ but keep in mind that you can easily do this hereã€‚

 So let's use run this and this and this againï¼Œ and then we should not see the augmentation anymoreã€‚

 So yeahï¼Œ I think these are the normal images without rotation or any other effectsã€‚

And now we set up our convolutional modelã€‚ So this is the same as in tutorial number 5ã€‚

 a simple convolutional neural net with different convolutional layers and max pooling and activation functions in betweenã€‚

And then at the endï¼Œ we use a dense layerã€‚ And this very last layer is importantã€‚

 So here we are only using five outputs because we have five different classesã€‚

 So let's run this and print the summary of our modelã€‚ So here we can inspect the architectureã€‚

And now we set up the loss and the optimizer and the metrics and compile our modelã€‚ So this isã€‚

 againï¼Œ the same as the last timeã€‚ So what's important here is to set from Lo it equals true because we don't use the activation function here as last layerã€‚

 So let's compile itã€‚And then we can easily call model fit to train our modelã€‚

 And now here I want to show you another new thingã€‚ So I want toã€‚Talk about Karas callbacksã€‚

 So with callbacksï¼Œ a callback is a function that is applied after each training epochã€‚

 So here you canï¼Œ for exampleï¼Œ safe checkpoints or use different thingsã€‚

 And what I want to do here is to use a early stopping callbackã€‚

 So we can very easily use this because this one is implemented in Kas dot callbacksã€‚

 And then we say early stoppingã€‚And we want to monitor the validation loss and have a patience of fiveã€‚

And this means that if the validation laws does not improve for the next five epochsã€‚

 then it will automatically do an early stopping of our trainingã€‚ Soï¼Œ and then when we have thisã€‚

 we can specify this argumentã€‚ So we can say callbacks equalsã€‚

 And then this is a list because we can pass in more callbacksï¼Œ if we wantã€‚

 And then we say early and then stoppingã€‚And then we used the rest of the argumentsã€‚

 And now let's train this and see what happensã€‚Alrightï¼Œ so training is doneã€‚

 So we actually said we want to have 30 epochsï¼Œ but then it stopped after epoch 10 because our validation loss didn't improveã€‚

 So here we have a our lowest value or hereï¼Œ And then it didn't get better in the next 5 epochã€‚

 So that's why it stopped hereã€‚ And what we can see here is if we have a look at the accuracy of our training data Then hereã€‚

 for exampleï¼Œ we have 100ã€‚ and 97 in the last epochã€‚ So this is very goodã€‚

 But now if we have a look at the validation accuracyã€‚

 then we see that this one was the best and then it's actually getting worseã€‚

 and our validation accuracy is not very good at allã€‚ So this is aã€‚

Clear indicator that we have an overfitting problem to our training dataã€‚ In this caseã€‚

 it's a little bit due to the problem that we don't have so many images available and especially not very much images for the validation setã€‚

 So this can be one problemã€‚But yeahï¼Œ I think in this caseï¼Œ it's very nice to have this call backã€‚

 And then we can stop and try to improve this modelã€‚ So I leave this for you as homeworkã€‚ You canã€‚

 for exampleï¼Œ try to use the image augmentation that I showed you or play around with the learning rate or per also try to change the architecture of our model a little bitã€‚

 So yeahï¼Œ this is one thing that we can doã€‚ğŸ˜Šï¼ŒAnd in the next tutorialã€‚

 I also show you another very powerful technique with which we can achieve a very high validation accuracyã€‚

 even on the small data setã€‚ So I hope you also watch the next tutorialã€‚ So for nowã€‚

 what I also want to doã€‚ So we can easily save our modelï¼Œ this is one thing I already showed youã€‚

 So we can save it like thisã€‚ And then if we have a look at this folderï¼Œ then it should be hereã€‚

 So yeahï¼Œ there it isã€‚ğŸ˜Šï¼ŒAnd then let's plot some dataã€‚So here we see the lossã€‚

 the training loss decrease trees very nicelyï¼Œ but the validation loss not so muchã€‚

And the same with the training accuracy for the trainingï¼Œ it's very goodã€‚ but full of validationã€‚

 it isn'tã€‚ Soï¼Œ againï¼Œ this can be an indicator that we have overfitting hereã€‚ And yeahã€‚

 And so now let's evaluate it on the test dataã€‚ And againã€‚

 here we see that our accuracy is not very good on this test dataã€‚

And then if we try to do predictionsï¼Œ we call model predictã€‚

 then we also have to apply the soft marks here because we didn't use it in our model layers as the last layerã€‚

 and then to get the actual labelsï¼Œ we have to call the artrc max along axis 1ã€‚

 So now if we print theã€‚Actual labels and the predicted labelsã€‚ Then we see we haveã€‚

 it's only 50% correct in this caseã€‚ So now againï¼Œ let's print someã€‚New images and predictionsã€‚

 So yeahï¼Œ so here our prediction is Luke Skywalker againï¼Œ So Luke Skywalkerã€‚ this was not very goodã€‚

So yeahï¼Œ but now I think you should know how we can apply a full project with a real world image data setã€‚

And we even achieved a high accuracy on the training data set with the techniques that we usedã€‚

But yeahï¼Œ we still have to improve it so that it's also good on the validation data set and for new data for the test data setã€‚

 So in the next tutorialï¼Œ were going to learn about transfer learningã€‚ And with thisï¼Œ weã€‚

 I think we will achieve a pretty good accuracyã€‚ So I hope to see you in the next videoã€‚

 and if you enjoyed the tutorialï¼Œ please hit the like button and consider subscribing to the channel and see you next timeã€‚

 byeã€‚ğŸ˜Šã€‚

![](img/7956a7f6b5a10c99728c67c08635cf0e_8.png)