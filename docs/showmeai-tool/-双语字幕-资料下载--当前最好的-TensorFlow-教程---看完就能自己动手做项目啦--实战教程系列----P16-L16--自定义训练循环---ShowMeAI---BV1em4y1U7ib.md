# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘â€œå½“å‰æœ€å¥½çš„ TensorFlow æ•™ç¨‹ï¼â€ï¼Œçœ‹å®Œå°±èƒ½è‡ªå·±åŠ¨æ‰‹åšé¡¹ç›®å•¦ï¼ï¼œå®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼ - P16ï¼šL16- è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ - ShowMeAI - BV1em4y1U7ib

What is going on guys hope you're doing freaking awesome in this video I'm going to show you how to do training loops from scratchã€‚



![](img/38a145700a6404a2026fbca3d7269917_1.png)

![](img/38a145700a6404a2026fbca3d7269917_2.png)

So this means that we're no longer using modelã€‚fiï¼Œ but rather we're doing everything by ourselves from scratch if you're familiar with coding and Pythtorch then this is going to be more how you're used to training networks but anyways let's get started and we aren't going to do anything complicated in this video in terms of what we're going to train on and the data and so onã€‚

 the point is just to show you the general structure of how it looks likeã€‚

So the starter code right here is just some basic imports that you've seen in previous videosã€‚

 we're going to use Tensorflowlow data setsï¼Œ so if you haven't watched that video then it's going to be in the top right cornerã€‚

So we're loading the Ms data set right here so we have a training and the test set and then we're just so we have a function for normalizedized images and all of this is from that video just copy pasted and then we have some very very simple model right hereã€‚

 just some one convolutional layer and then one dense layer and let's do layers that dense here just like that and then so then let's get started and what we're going to do is that first of all we're gonna have some metric so let's do accuracy metric is a ks do metrics dot ourã€‚



![](img/38a145700a6404a2026fbca3d7269917_4.png)

Categorical accuracyã€‚And then let's do firstï¼Œ let's do the training loopã€‚

So the first thing we're going to do is we're going to train it for a number of epochsã€‚

 so we're going to train it for epochs is5 in this caseã€‚

 So what we just do is we we write for epoch in range epochsã€‚Or maybe we should call itã€‚ğŸ˜”ï¼ŒNum epochã€‚

So nu epoch right thereã€‚ğŸ˜”ï¼ŒAnd then we could do printã€‚Justã€‚To printã€‚

Slash n and then start of training epochã€‚And thenï¼Œ we could doã€‚I we can do it like this epochã€‚

Now it's do F stringã€‚And so then we're going to iterate through all of the batches in our trainingã€‚

 And so we're going to do for batch index and thenã€‚X batch comm a Y batch in enumerateã€‚AD trainã€‚

Alrightï¼Œ so we're going to go through the strain for a number of epochsã€‚

 So right here we're going to first of allï¼Œ write the width Tf gradient tapeã€‚As tapeã€‚

 And this is for recording all of the operations that we're going to do in the forward propagation so that we can then do back propagation for the the model weightsã€‚

 So we're going to do Y prediction is modelã€‚X batchï¼Œ and then specify training is trueã€‚

 Then we're going to do loss is loss function right that we specified over hereã€‚

And we're going to send in the y batchï¼Œ the true labelsï¼Œ and then the y predictionsã€‚

 the one we just calculated for from forward propagationã€‚All rightã€‚

 so then we have those under that tapeï¼Œ then we can do gradients our equal tape dot gradientã€‚

And then we specify the loss and then model our trainable weightsã€‚

So we basically want the gradients of the loss with respect to trainable parametersã€‚

Then or the trainable weights ratherã€‚ And then we're going to do optimizerã€‚That apply gradientsã€‚

 We can do zip gradientsï¼Œ model the trainable weightã€‚

And then we're going to do accuracy metric dot update stateã€‚Why batch and then why predictionã€‚

Just so that we have a sense of what the accuracy was of that epochã€‚So at the end hereã€‚

 we're going to do training accuracy is equal to accuracy metric to resultã€‚

 and then we could print that so we could do accuracy overã€‚Epochï¼Œ and thenã€‚We can just doã€‚

Train accuracy like thatã€‚And then we could reset the accuracy metric so that it's going to be zeroed for the next epochã€‚

 So accuracysymmetric dot reset statesã€‚And that's it for the training loopã€‚

 so that's that's how it would look like it's very similar to the last video where we went through how to customize modelã€‚

 fitï¼Œ except now we're just removing the model that fit and we're just adding a loop here for the number of epochs that we want to trainã€‚

And then all we want to do is I guessã€‚So test loopã€‚

 so this is for the training and then we're going to want to have a test loop to evaluate our modelã€‚

And then we don't need to run it for a couple of epochsã€‚ we could just run through the data set onceã€‚

 so we're going to do batch index and then X batchã€‚

 Y batchge enumerate DSs test and I guess right now we're not using the batch indexã€‚

 but I mean you could So I guess you could just iterate through the DSs test as well there's no point of doing the enumerateã€‚

 but sometimes you want the batch indexã€‚Anywaysã€‚We don't need to do gradient tapeã€‚

 We're not going to collect the gradientsã€‚ So we're just going to do y prediction in this model of X batch training equals true and then accuracysymmetric dot updateã€‚

State Y badgeï¼Œ and then Y predictionã€‚Then in the end we could do train accuracy is accuracysymmetric dot resultã€‚

 right same as we did right hereã€‚And then we couldï¼Œ I guess we could print accuracy over testã€‚Setã€‚

Then we could just write training as hereã€‚And then in the endï¼Œ we could againï¼Œ reset itã€‚

We don't have to do this thoughï¼Œ since that's the last thing we're going to doã€‚But anywaysã€‚

 that's how it looks like if you want a training loop and a test loopï¼Œ of course you can alsoã€‚

 I meanï¼Œ you could put this right here in a function like define train or somethingã€‚

 and then you could you know for epoking range of you could just call that functionã€‚



![](img/38a145700a6404a2026fbca3d7269917_6.png)

![](img/38a145700a6404a2026fbca3d7269917_7.png)

Train 1 epochï¼Œ maybeã€‚And then run run itã€‚So you know you could think of the structure of you could think of how you want to structure thisã€‚

 but this is the fundamentals of how you do a training loopã€‚

 it's very simple we've done it in the most simple way that we can and of course if you're doing something more complicated like generative adversary networks or GANSã€‚

 then it's going to look more complicated than thisã€‚

 but it's still going to be a fundamentally the same method and I think if you sort of understand this basic layout then and then when do more complicated things it's going to help you and understand it general structureã€‚

All rightï¼Œ so first of allï¼Œ we should run this and make sure that it worksã€‚And it doesn'tã€‚

 So it has no attribute gradientsã€‚ that's because we want to have a tap dot gradientã€‚All rightã€‚

 and as we can see it makes sense it's training and this worksã€‚So yeahã€‚Anywaysã€‚

 that's it for this videoï¼Œ hopefully you found this useful if you have any questions then leave them in the comment section belowã€‚

 I think I said thank you for watching but thank you for watching and I hope to see you in the next videoã€‚



![](img/38a145700a6404a2026fbca3d7269917_9.png)