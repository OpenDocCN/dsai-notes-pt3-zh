# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘é©¬è¨è¯¸å¡CS685 ï½œ è‡ªç„¶è¯­è¨€å¤„ç†è¿›é˜¶(2020Â·å®Œæ•´ç‰ˆ) - P12ï¼šL9- ä¸‹æ¸¸ä»»åŠ¡è¿ç§»å­¦ä¹  - ShowMeAI - BV1BL411t7RV

Okayï¼Œ Henry I think we're liveï¼Œ pleaseï¼Œ if you're watching this type something in the chat boxã€‚

 so I know that it's on Also last time my chat box wasn't not updating for some reasonï¼Œ soã€‚å—¯ã€‚

I actually did not get a chance to look into why that was happeningã€‚

 Hopefully it doesn't happen againã€‚ All rightï¼Œ I see one personã€‚Two peopleã€‚

 I'm just going to assume it's workingã€‚Okayï¼Œ if I notice any periods whereã€‚

Like there have been suspiciously few questionsï¼Œ then I willã€‚Try to likeã€‚

 I actually don't know what I'm supposed to doã€‚ Maybe refresh theã€‚YouTe thing or somethingã€‚All rightã€‚

 so what are we talking about today hang on let me make sure this iPad is workingã€‚Okayã€‚Soã€‚

 today's topic is intermediateã€‚Taskã€‚Fineï¼Œ tuningã€‚And what I'm going to do is give a bit of intuition first on the iPadã€‚

 and then I'm going to switch over to some slides to talk about some very recent research that actually one of the Ts tou has done in this line of work as opposed to all of the previous stuff that we've learned this direction is incredibly newã€‚

 and it's seeking to build on top of selfsupervised pre-training using things like language modeling and mask language modelingã€‚

 but here it's trying to take advantage of other labeled data setsï¼Œ not just the downstream data setã€‚

So before we startï¼Œ I wanted to briefly go over maybe the most obvious way in which we can incorporate different downstream tasks into the same model to benefit a particular task that you care aboutã€‚

 so let's just set this upã€‚Imagineã€‚I am tryingã€‚To optimizeã€‚Performance on squadã€‚

So remember that S is the Q A data set that we talked at length about last timeã€‚ and in Sã€‚

 you have like a passageã€‚ you have a question about that passage and you're trying toã€‚

Train a model to figure out what that spanï¼Œ the answer span isã€‚å—¯ã€‚But so farã€‚

 we've just assumed that we have access to a large unlabeled data set for pre trainingã€‚

 and we also have access to our downstream training data setï¼Œ like the squad training data setã€‚

 rightï¼Œ So to draw this outï¼Œ it would look something likeã€‚

And this was basically a figure from one of our earlier slidesï¼Œ we have lots of unlabeled dataã€‚

We feed this into squadï¼Œ sorry tip Btã€‚Rightï¼Œ and we pre traineded Bert using the mask language model objectiveã€‚

We'll call this the pre training stepã€‚ And then we have access to our squadã€‚Training setã€‚

This is going to form our source of supervisionï¼Œ which we're then going to use to fine tuneã€‚

The B language model into aï¼Œ let's call it a squad specializedã€‚Modelã€‚Rightã€‚

 so this is the paradigm that we've talked about to this pointï¼Œ rightã€‚å—¯ã€‚We start with Bertã€‚

 and then we fine tune it to get the downstream modelã€‚

So what this ignores is that I also have access to numerous different labeled data sets that could potentially be helpful at increasing my performance on Sã€‚

One obvious example which kind of ties into what we talked about last time is there are numerous different QA data sets right so there's hotpot QA quack news QAã€‚

 lots of other dataset sets that we discussed last time and you might imagine that having access to some of these other QA data sets can help further boost my performance on Sã€‚

So one questionã€‚Can we leverageã€‚Otherã€‚Qï¼Œ A data setsã€‚To improveã€‚Our squadã€‚Test timeã€‚Herformã€‚

And so there are many ways you could think about doing thisã€‚

 The most standard way is to use multi task learningï¼Œ soã€‚Wenweiã€‚Multi taskã€‚3yã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_1.png)

Soï¼Œ hereã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_3.png)

We're just going to during this fine tuning processã€‚

 include examples from other data sets into the fine tuning processã€‚

 So if I take the same setup hereã€‚Can you just copy thisã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_5.png)

And paste it down hereã€‚Okayã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_7.png)

Where did thisï¼ŸHere I canï¼Œ instead of just having access to the squad dataset setã€‚

I'm going to have access to squadï¼Œ plusã€‚Hot pot Q A plus newsï¼Œ Q Aã€‚Plusï¼Œ so on rightã€‚

 I can just add as many of these dataset sets as I want into the fine tuning step and the nice thing about these QA data sets is that they all follow the basically the same format right you have a question about a passage and the answer is a span of text within that passage soã€‚

That is that makes it such that I can just concatenate all these data sets togetherã€‚

 and then hopefully I'm leveraging information from these other data sets that will be useful when I eventually evaluate this sunquaã€‚

So that's the idea but remember that in this setting we only care about our performance on Sã€‚

 we don't care about our performance on hotpot QA or news QA or so onã€‚

 and so the loss function that we might want to use in this multitask setting looks a little different than the standard cross entropy loss over all of the training examplesã€‚

So in particularï¼Œ let's just say we in the simple caseï¼Œ assume we trainã€‚OnSã€‚Plusï¼Œ hot potï¼Œ Qï¼Œ Aã€‚Okayã€‚

 I see that there is a questionï¼Œ I will get to these right after I finish explaining the current conceptã€‚

But good to know that thisï¼Œ this chat thing is actually workingã€‚ Okayã€‚

 so let's just assume we train on these two data setsã€‚ So in multitask learning or MTLã€‚

 I'm going to use the following loss functionï¼Œ which basically weights the loss coming from the squad examplesã€‚

ğŸ˜Šï¼ŒWith some particular lambmbda and then waits the hotpot QAã€‚Loss with1 minus lambdaã€‚

So in this settingï¼Œ rightï¼Œ if I only care about my squad performanceã€‚å—¯ã€‚If I careã€‚Aboutã€‚Squadã€‚Maybeã€‚

I use a high lambã€‚Here so hereï¼Œ of courseï¼Œ lambda is between 0 and 1ã€‚ it's basically sayingã€‚

 you knowï¼Œ if I set lambmbda to 0ã€‚8ï¼Œ that means 80% of my fine tu loss will come from S and 20% will come from hotpot QAã€‚

 So because I want to maximize my performance on Sï¼Œ I might want to up my lambmbda hereã€‚

 and I would hope that having some loss come from hotpot QA is going to get important information from hotpot QA into the model that maybe S didn't have and is going to eventually boost my performance Sã€‚

So the issues with this setup are mainly in how do we choose these lambmbdasï¼Œ rightï¼Ÿ

And this is because if I just naively set these things to 5050ï¼Œ in many casesï¼Œ I don't seeã€‚

 you know any corresponding gainã€‚ So in one of your assigned readings todayã€‚

 which was the stilts paperï¼Œ they tried the naive multitask setting where they basically just concatenated all of the data sets together and had this kind of equally weights for each task and it didn't really result in any improvements so choosing the lambmbda is an artã€‚

 you might want to adjust this lambda through training to maybe start with focusing equally on both data sets and then towards the end of trainingã€‚

 focus more on squ you might want to learn the lambmbdasã€‚

 So there's lots of methods proposed to deal with this stuffã€‚ but in generalã€‚

 multitask learning is really hard to get rightã€‚ And there haven't been many positive examples of it in NLPã€‚

So that kind of motivates this other direction that we're going to be talking about todayã€‚

 but before we get into thatï¼Œ let me take these questions so the first question since we are already using squad for fine tuningã€‚

 what do we mean by squad test time performance are we dividing squad into training and test Yesã€‚

 of course so we always are going to be dividing the data sets that we're that we eventually care about into trainingã€‚

 validation and test right so the reason is because if we train on all of the data then we don't have any way of evaluating how well we did rightï¼Ÿ

We need to have a held outset for test time so that we don't cheat and test our model on things that it's already seen during trainingã€‚

å—¯ã€‚Okay so next questionï¼Œ we need to have the same type of objective function as well as label data for all these data sets That is not actually trueã€‚

 That's just what I've shown in this exampleï¼Œ so you could potentially multitask with many different types of tasks and objectives but you can imagine this makes this weighting process even harder right not it's not very clear how I'm going to assign a weight to a completely different type of objective function and yeah you can imagine that as I add more and more tasks into this setupã€‚

 it becomes harder and harder to decide how to weight the different tasks properly another way that people do this is instead of explicitly weighting the tasksã€‚

 they subsample different data sets with certain probabilities but yeah all of this is it's just veryã€‚

 very difficult to figure out a setting that actually worksã€‚

And generalizes to multiple different downstream tasksã€‚Okay so why is it called multitask learningã€‚

 the task is still fixedï¼Œ which is to find the spin of task for all these data sets right so that's a good question but but the difference is that squad and hotpot QA are not the same task they might have the same formatã€‚

 but hotpot QA is data collection process was designed explicitly to avoid the types of simple string matchbased reasoning that squad you solved byã€‚

 So you might imagine that having some of that higher level reasoning that hotpot QA at least theoretically forces a model to learn can help a squad model on harder examples that are not necessarily solvable by string matching So there is a difference between the task format and the data set itself right so S and hotpotã€‚

ğŸ˜Šï¼ŒQA have the same formatï¼Œ but they actually are fairly different in terms of what kinds of reasoning the model needs to learn to solve themã€‚

And that's the intuitionã€‚Okayï¼Œ so let us continueã€‚ What we're going talk about here is a different processã€‚

 which isï¼Œ I guessï¼Œ a little less flexible in that it does not require any sort of learning weights or anything like thatã€‚

 but it's also it requires another phase of training essentiallyã€‚

 So if we take our maybe I'll just copyã€‚This oneã€‚So we're going to start as usualã€‚

 with this pre trainingã€‚I maybe yell and a separator thingã€‚Okayï¼Œ so we're going to start hereã€‚

 and eventually we're going to end up hereã€‚But instead of just going directly from pre training to fine tuningã€‚

 we're going to add an intermediate stageã€‚ And so here we're gonna have thisã€‚Intermediateã€‚A modelelã€‚

And we're going to get this intermediate model by using a different data setã€‚ so we could sayã€‚

 just use the hotpot QA trainingã€‚Data setã€‚And we do one round of fine tuningã€‚

 and we take the resulting model and then fine tune that completely on squadã€‚

 So this is kind of analogous to doing multi taskask learningï¼Œ butã€‚ğŸ˜Šï¼ŒOhï¼Œ was it bufferingã€‚

For' almost half a minuteï¼Œ all rightï¼Œ hopefully that was resolvedã€‚Okayï¼Œ that's not greatã€‚Sing onã€‚

 let me tryã€‚Reducing the bit rightï¼Œ or is it better nowï¼ŸIt seems to be betterã€‚

 so I'm just going to proceed and hope that this is workingã€‚Okayï¼Œ so yeahã€‚

 we have this intermediate model that we're adding into this pipeline and as I was sayingã€‚

 this is kind of analogous to having the multitask learning set except we are adjusting the lambmbdaAs dynamically to have like 100% of the weight on hotpot QA and then after convergenceã€‚

 we switch to 100% of the weight on squadã€‚ So if you look at it in that way you can kind of formalize it in the same manner as the multitask learning setupã€‚

Okayï¼Œ so this approach removes a lot of the variables for multitask learningã€‚

 because we have essentially fixed these lambdas to occur at certain points during trainingã€‚And itã€‚

 it forces the model to first completely specialize to hotpot Q A before re specializing to squadã€‚

So that's actually like the high levelve overview of the method that we're going to be discussing todayã€‚

 It's very straightforwardã€‚ It just takes another dataã€‚

 another label data and inserts it as an intermediate task into this processã€‚

 So a couple of questions aren't the outputs for these tasks differentã€‚

 are we replacing the final layer between tasksï¼Œ yeahï¼Œ good questionsã€‚ So in this caseã€‚

 the output format is the same so we could actually share the final softmax layers across both of these different QA tasksã€‚

 but in practiceï¼Œ I could put like sentiment analysis in as the intermediate task right And so if I did thatã€‚

 then of course my softmax layer is no longer useful first squad So I throw it away and just initialize a new softmax layer for the beginning of the spin and the end of spin predictionã€‚

ğŸ˜Šï¼Œbut the important thing is that the weights of Bt right those are also being fine- tuneuned in both of these processes and so after after this intermediate stageã€‚

 I have a new set of weights of Bt that have been they've taken the mask language model stuff that's been learned during pretrainingã€‚

 those weights and then they've adjusted them to make them better for hotpot QA and finally we're going to readjust them to be better for squadã€‚

So that's kind of the intuitionã€‚ Does the ordering of the intermediate models matterã€‚

 This is a great questionã€‚ So in all of the methods that we gave you for reading and that have been tried so farã€‚

 there's only been one intermediate task inserted If you go to multiple different intermediate tasksã€‚

 then we start running into the issue of how do we know what order optimizes our downstream performanceã€‚

 these are very expensive experiments to run right because we have to try all possible orderings to find something that might generalize to new downstream tasks its it's very difficult So so farã€‚

 yeahï¼Œ it's hard to say if I have multiple intermediate tasks how I should order themã€‚

 maybe there' are some simple heuristics like data set size or similarity to the downstream task that you actually care aboutã€‚

ğŸ˜Šï¼ŒThat can influence thisï¼Œ but currently those are all unknownsã€‚

Definitely interesting to explore in the futureã€‚I should also say that multitask settings that use more than one secondary objectiveã€‚

 it's basically analogous to the problem of finding optimal weights being harder and harder as I add more tasks hereã€‚

 it's just the order of the training of the intermediate fine tuningã€‚

For a very small dataset set can intermediate model healthã€‚ That's a great questionã€‚ Actuallyã€‚

 the second paper you had to read shows that the resultsã€‚

 the improvements that you get from intermediate fine tuning increase when the downstream task is smallã€‚

 like when the downstream data is smallã€‚ So we did this experiment on only and we only had access to 1000 squad training examplesã€‚

 this intermediate process provided we choose the right tasks helps a lot a lot more than if you have the full dataã€‚

 So yeahï¼Œ this is definitely something that is very useful in low resource settingsã€‚ğŸ˜Šã€‚

If we repeat this process multiple times how much would the squad performance varyã€‚

 I think you need to specify a couple things hereï¼Œ like what is being kept consistent across multiple iterationsã€‚

 if you repeat the entire process keeping the intermediate task the same and of course your downstream data the same it really depends a lot on the size of both the intermediate and the downstream data setsã€‚

 So if they're smallï¼Œ you of course will expect higher variantsã€‚

 but if they're both large then the experiments we've done to this point show that there's much lower varianceã€‚

 but yeah this method is only really useful on or I shouldn't say that it's significantly it results in significantly improvements when you have small downstream data sets and the experiments also show that intermediate fine reduces the varianceã€‚

Of the downstream task when you train it with a couple different trialsï¼Œ so yeahã€‚

 the benefits include better performance and lower varianceã€‚

 which is of course what you want in the endã€‚Okayï¼Œ so is this fine tuning based on backproï¼Œ if yesã€‚

 then how do we handle the differentials because they may be different for the different modelsï¼Ÿ

 Of courseï¼Œ all fine tuning and pretrainingï¼Œ etc cea is based on backproã€‚

 that's how we're you know calculating the gradients that we're using to update the modelsã€‚

 And remember that the core model hereï¼Œ the Bt model is is the same architecture in all three of these these phasesã€‚

 So the gradient updates are going to the same set of base parameters that come from the original Bt model right So the only differences could be the output layer based on what your intermediate task is but that's a really small part of the model right Bertã€‚

 you knowï¼Œ 24 layer transformer mostã€‚ğŸ˜Šï¼ŒSo the parameters are shared across all three of these phases hereã€‚

Okayï¼Œ so what else did I want to say before I move to the slidesï¼Œ Rightã€‚

 So I just wanted to highlight some interesting questions and note that a lot of these are not answered to this pointã€‚

 butã€‚This is kind ofï¼Œ I thinkï¼Œ a useful thing to think about when you're you know thinking about BerRT and whether just scaling up mask language modeling or language modelingã€‚

 the bigger and bigger data sets is the best way to see improvementsã€‚

 this provides an alternative to that where we actually leverage some of the label data sets that we have to get more improvements on top of BRTã€‚

So the most interesting questionï¼Œ possibly isï¼Œ how do we knowã€‚Whatã€‚Intermediate taskã€‚Will resultã€‚Inã€‚

The biggestã€‚Downstream improvementsã€‚So you might have a many different hypotheses for why a particular task is better than another one when it's used as an intermediate task here right like if I told you that hotpot QA results in like a5 F1 gain when it's used for intermediate fine tuning for squad and fine tuningã€‚

 doing intermediate fine tuning on sentiment analysis actually hurts the model and results in like a minus 10 F1 on squadã€‚

 you might intuitively thinkï¼Œ oh that's obvious rightï¼Œ because hotpot QA is a QA dataã€‚

 it tests a lot of the same kinds of reasoning as squadã€‚

 and so that's why hotpot QA is better than sentiment analysis for this intermediate task because sentiment and squad share very little in terms of what the model is expected to learnã€‚

So it would be niceï¼Œ of courseï¼Œ if that was always trueã€‚

 And there was like an interpretable reason why a particular data set work better than anotherã€‚

 But there are many different factorsï¼Œ rightï¼Œ So one is like task similarityã€‚ğŸ˜Šï¼ŒAnd so this is likeã€‚

QAã€‚QAï¼Œ so this is the intermediate taskã€‚Maybe I'll highlight these to make them more clearã€‚

 to the screen throughã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_9.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_10.png)

So this is QA for the intermediate task and then QA for the downstream taskã€‚

 like hotdpot QA and squatter both QA tasks sorryã€‚Versusã€‚Sentimentã€‚

So this this could be one possible way to chooseï¼Œ another is size of intermediate data setã€‚Rightã€‚

 maybe we expect a bigger data set to be more useful than a smaller data set for intermediate fine tuningã€‚

 So what happens if I haveã€‚100 Q A Aã€‚Examplesã€‚Versseã€‚100000ã€‚Sentimentã€‚Rightã€‚

 another thing we need to considerã€‚Here are both the intermediate taskã€‚

Another thing is domain similarityã€‚So remember that squad is constructed from Wikipedia articlesã€‚

 rightï¼Ÿ So what if I haveã€‚Qï¼Œ let's sayã€‚Make the data set size the sameï¼Œ10ï¼Œ000 QA examplesã€‚Fromã€‚

 I don't knowã€‚ What is a complicated domain specific data setï¼Œ maybe like someã€‚For medical journalsã€‚

 firstã€‚Something highly specific to a single field versus 10000ã€‚Sentimentã€‚Examplesã€‚From Wikipediaã€‚

Rightï¼Œ so there are so many different factors when you think aboutã€‚

Why a particular data set is more useful than another for intermediate fine tuningã€‚

 and it's hard to know in any particular case which of these factors is going to be the most significantã€‚

So that kind of motivates the questionã€‚Can we predictã€‚Whichã€‚Taskã€‚Out ofã€‚So finiteã€‚Set of tasksã€‚Willã€‚

The mostã€‚Usefulã€‚Asã€‚Inmediateã€‚Tkã€‚Givenã€‚å—¯ã€‚Given a specificã€‚Downstream data setã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_12.png)

Okayï¼Œ soã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_14.png)

Make that more clearã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_16.png)

Okayï¼Œ so at this pointï¼Œ I think I'll switch over to slidesã€‚

And we can talk a little bit more about like some methods that we can use and how they work in a kind of a high level of detailã€‚

But before thatï¼Œ can you explain in the given examples which one will work better or are these still questions Yeahã€‚

 so I kind of meant this as these are some of the factors that you need to consider when deciding what task to use as an intermediate task there have been methods that are proposed like the ones in your reading kind of get to some level of predicting which task will be betterã€‚

 but these are still mainly open questions they're unsolvedï¼Œ at least in a general settingã€‚

 it's yeahï¼Œ there's no method that'll tell you for sure what is the best task to use for any given downstream data setã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_18.png)

If we have a pair of data sets that we know work wellï¼Œ can we use them in any orderï¼Ÿ

So in in all of these settingsï¼Œ I'm assuming that you have one task that you care about right That's the one in red hereã€‚

 the downstream taskã€‚ So in this exampleï¼Œ it's squã€‚

 And you have a bunch of other tasks and you're going to use maybe one of them for intermediate fine tuningã€‚

 And so you're trying to pick which one task you're going to useã€‚ there isï¼Œ of courseã€‚

 the extension of thisï¼Œ which is maybe I can pick a sequence of many different tasks to use hereã€‚

 but no one really knows what happens in that settingï¼Œ you can imagineï¼Œ thoughï¼Œ if youã€‚ğŸ˜Šã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_20.png)

Maybe I can'tã€‚This is a bit of a diversion because I'm not actually sure what happens in this settingã€‚

But if I do this and instead of immediately going to the downstream taskã€‚

 I just like repeat this for N intermediate tasksã€‚Before getting to the downstream modelã€‚

 this could potentially helpï¼Œ rightï¼Œ Maybe I find like a nice sequence of tasks that specializes enough useful information into the model before eventually getting to the downstream data setã€‚

 but it could also really hurtï¼Œ rightï¼Œ because with each one of these new intermediate tasks that I add hereã€‚

 I kind of forget some of the information that I learned from my Bt pretrainingï¼Œ rightã€‚

 And that's really bad because note that the Bt pretraining phase was the one that had access to the largest training data setã€‚

 rightï¼Œ we could use unlabeled data so we have potentially infinite pretraining data versus for each intermediate task we have only a small amount of label like a relatively small amount of label dataã€‚

 rightï¼Œ soã€‚ğŸ˜Šï¼ŒThe the pre-training phase is definitely the most important and if we get too far away from the pretraining phaseã€‚

 then our model might forget a lot of the useful information that could potentially benefit our downstream squad modelã€‚

 but that saidï¼Œ I'm not actually sure what happens hereï¼Œ it's also unclear if using a sequenceã€‚

 the sequence ordering is best or maybe we can do some sort of joint training or train all of the fine tune and all the models directly from BRT separately and then do some sort of aggregation lots of open questions in this areaã€‚

 but I just wanted to kind of introduce the possibility of leveraging other downstream tasks to help on a particular down data setã€‚

Okayï¼Œ apartpart from the same task for a particular downstream taskã€‚

 how do we measure the similarity between different tasksã€‚

 we'll get to this when we go to the slides or at least one method for doing this Can't we use beam search to greedily choose the best task No soã€‚

Itã€‚Likeï¼Œ if you hadï¼Œ you knowï¼Œ like 50 different tasks and you wanted to find the best oneã€‚

Remember that the only way in which you can evaluate how good a particular task is is to do this entire fine tuning stage for every single of these 50 possibilities right so I could of course try out every single one of my 50 tasks in this process and pick the one that's best so that's not really scalable right if I come up with a new taskã€‚

 I don't want to wait you know several days for for this process to finish for each of the 50 different task so you really need a way to approximate the information that is preserved after fine tuning on a particular task and then do some sort of reasoning over this approximation of a task to figure out which one is best So it's not really possible at least now to toã€‚

ğŸ˜Šï¼ŒDo some sort of search without actually going through the full fine tuning process which is very expensive so all of the methods we'll be discussing here look for a way to encode a task into a low D representation that we can then do some sort of reasoning over so with that I will switch over to the slides wowã€‚

 so's not've been 36 minutesã€‚ğŸ˜Šã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_22.png)

Doing good hereã€‚Okayï¼Œ soã€‚I'm upseting youã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_24.png)

All rightã€‚å—¯ã€‚So yeahï¼Œ we're still talking about this intermediate taskã€‚

 fine tuning stuff here we'll get a little more concrete in methods that we can use to choose a particular intermediate task before we do that there is some stuff from last time that I will talk about here so we got to comment on the anonymous form about we were signing too many readings so I apologize for that I just figured that most of you aren't doing the readings anyway so if people are actually interested in learning more about the things that we talk about in the lecture you can check out the readingsã€‚

 but at this point I would say that you know the readings are just for people who are actually super interested in the material and we'll be covering all the important concepts in the lectures the readings now have become like very recent research papers so it's totally understandableã€‚

If you're unable to understand all of them completelyï¼Œ in factã€‚

 like neither myself nor the TAs are able to you know completely understand most of these papers by just reading them so don't feel bad about that a lot of it is just due to poor writing but yeahã€‚

 I think several papers assume a lot of background knowledge about related work that you have to then go and check out to understand what they're talking aboutã€‚

 so it's actually a long process to understand a research paperï¼Œ butã€‚

We'll try and cover most of the important concepts from each paper in the lectureã€‚

 so specifically I think for next class I've assigned a ton of different papers and yeahï¼Œ againã€‚

 don't feel obligated to read all of them completely at least make sure you check out you know the abstract introductionã€‚

 maybe some of the results and those are generally written at a high enough level for people who are familiar with basic NLP and machine learning concepts to understandã€‚

ğŸ˜Šï¼ŒThe other thing no one has complained about maybe unsurprisinglyã€‚

 which is homework one still hasn't been released is basically all on me at this pointã€‚

 the T has completed a draft of it and I'm still kind of tweaking things to make it more informative and useful for your final projects for those of you who are using Bt like models and neural language models in your project so yeahã€‚

 it will be out very soon and actually some of the I know I've been saying that hence the mythical homework it will be coming out at some point in the semester and homework will include a bit of stuff on intermediate fine tuning as well so we've now covered that also this past week we posted an extra credit assignment whichã€‚

ğŸ˜Šï¼ŒI think anyone can do regardless of time zone you don't have to attend these talks liveã€‚

 you can watch the recorded versionsï¼Œ but basically there's three or four or five talks this semester that are related to NLP or some of the concepts we've been discussing in this class and so these are you know like researchersã€‚

 facultyï¼Œ PhD students that are giving talks about their latest research so yeah the assignment is essentially to write up a summary answer some questions about their their talk and it's not a veryã€‚

Andã€‚Complex assignment or it shouldn't take that much timeã€‚Yeahã€‚

 I think that's all I wanted to say about this Oh yes also exam I'll be putting out the exams from previous semesters later this week and I'll put them up first without solutions so you can try them out and then the following week I'll put up the solutions but note that many of the things especially the most recent lectures that we're covering was't not present in previous iterations of this class so there will be questions that are on topics that you haven't seen before also there are sorry that aren't in the practice exams is what I'm meant to say there are also topics in the practice exams that we haven't covered in this class so you can ignore those I'll also mention you should ignore all the multiple choice questions we not going to have multiple choice on this exam and yeah I'll highlight particular questionsã€‚

ğŸ˜Šï¼ŒThat are going to be more like the things that you will see on the examã€‚ So more on that on Piazã€‚

Okayï¼Œ so I've been using this word task a lot in the when I was going over things on the iPadã€‚

 I just wanted to be a little more specific about what we mean when we talk about a taskã€‚

 right we're choosing a task to be this intermediate fine tuning and also for our downstream trainingã€‚

 And so we're gonna consider a task to have know a descriptionã€‚

 it's gonna tell you what the task is actually doingã€‚ And also a task is associated with a data setã€‚

 rightï¼Œ So for all of the cases we'll be considering these are labeled data setsã€‚

 So we have these x'sï¼Œ which are our inputs and our Y'sã€‚

 which are the labels sometimes these x's could be a little more complicatedï¼Œ rightã€‚

 So in the case of squadï¼Œ the input isã€‚ğŸ˜Šï¼ŒThe the question as well as this associated passage and the whys are the indices of this answer span in the passageã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_26.png)

So as we've seen or actually we haven't seen this yetï¼Œ but as I've impliedã€‚

 you can use different tasks to help each other to improve performance on a particular task and there's a lot of prior literature on this right so one of them that was assigned in your reading this Fo at all paper showed for classification tasks that you first start with your pre-training objective on language modeling then you do intermediate fine tuning on all these different task as well as reduced varianceã€‚

ğŸ˜Šï¼ŒSo there's this other paper that we did not assign in this for this lecture by Nelson Lu that shows thatã€‚

Using more related tasksï¼Œ so if my downstream task is QA pre training or doing intermediate fine tuning on another QA task is more helpful than doing just language model pretrain without thisã€‚

And yeahï¼Œ people have shown that in the QA settingã€‚

 you can get some boosts when you pretrain or sorryã€‚

 do intermediate fine tuning on other QA data sets before fine tuning on your target oneã€‚

 so these are three pieces of evidence that you can leverage other label data sets to help out with your current oneã€‚

All rightï¼Œ so whoopsã€‚å‘ƒã€‚I wanted to say that if we have a way to kind of encode the unique identifying properties of each individual taskã€‚

 then we might be able to come up with some way of measuring the similarity of different tasks to each other and also maybe measure how beneficial doing intermediate fine tuning on one task is to another task and all of these these kinds of works have practical applications because maybe I don't need to collect such a big label data for my specific downstream task I can leverage bigger existing data sets that are kind of related in some way to the one I want to solveã€‚

Okayï¼Œ so rightï¼Œ there are obviously real world use cases for this kind of thingã€‚

 right I think one that's particularly interesting forã€‚

 say a company is if you have a user that's able to submit a completely new task right so they provide maybe a description of what this task is and some sample data of you know X Y pairsã€‚

 input output pairs and the company responsible for training some sort of model on this data the company can kind of leverage their existing knowledge of all of these different tasks that have already been submitted to you know return either a single intermediate task or a sequence that can maximize the performance on the end user's taskã€‚

ğŸ˜Šã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_28.png)

Okayï¼Œ and within NLPï¼Œ I know we haven't talked about a lot of different downstream data setsã€‚

 but I just wanted to make it clear that there are a lot of different labelable data sets that have been created over the yearsã€‚

 rightï¼Œ So this table is only a small fraction of all of the data setsã€‚

 I'm sure many of you while browsing through the ALã€‚

 ELP proceedings noticed how many new data sets are proposed at every conferenceã€‚

 to test some new linguistic property or type of reasoning that hasn't been tested beforeï¼Œ rightã€‚

 And so this mass of tasks just taken together is a huge set of resources that we can use to further optimize our performance on the task that we care aboutã€‚

ğŸ˜Šï¼Œå—¯ã€‚Rightï¼Œ so if you look at the machine comprehension column hereï¼Œ you can see just a list of manyã€‚

 many different QA data setsï¼Œ many of which we haven't even discussed so farã€‚

 there's just way too many to go into any level of detail at allï¼Œ but yeahã€‚

 you can see how this paradigm of leveraging existing label data sets can be useful because of the sheer volume of these dataset setsã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_30.png)

Okayï¼Œ so computer vision research has in these kinds of ways been ahead of NLPã€‚

 you know it was of course ahead on the whole deep learning thingã€‚

 which you know the first advances were really in computer vision with convolutional nets and then shifted over to NLP with recurrent neural networks a couple years laterã€‚

 but in computer visionï¼Œ we also have a bunch of different tasks that are basically leveraging the same core architecture of a convolutional neural network that's been pretrained on the imageNe data setã€‚

And there's this paperï¼Œ which was assigned as optional reading called Taonomyã€‚

 It'd actually won a best paper award at CVPRï¼Œ which is one of the or I guess the top computer vision conferenceã€‚

 which showed that you can learn these relationships between tasks to maximize your performance of a target taskã€‚

 So in this exampleï¼Œ it's showing thatã€‚ğŸ˜Šï¼ŒHaving a model that's kind of fine tuned for this task ofã€‚

 I guess detecting surface normals and also detecting 3D edges benefits these other tasks like reshading or point matchingã€‚

So we wouldï¼Œ we would like to do that for NLP as wellã€‚Okayï¼Œ as an asideã€‚

 I haven't seen any questions in a whileã€‚I will assume that no one has had a questionã€‚

 but if that persistsï¼Œ then maybe I'll refreshã€‚Okayï¼Œ so in this paperã€‚

 they had 26 different computer vision tasksï¼Œ and these wereï¼Œ you knowã€‚

 roughly in different classes of like 2D modeling versus 3D modelingï¼Œ focusing on like segmentationã€‚

 etc ceteraã€‚ and they were able to discover these kinds of task relationshipsã€‚ğŸ˜Šã€‚

So we would like to do the same thing for NLP and one approach that we could use is to embed each task in our know vast collection of tasks in a low dimensional space similar to how we've thought of embedding words or sentences or documentsã€‚

 we can also think about just embedding an entire data setã€‚So what does this actually meanã€‚

 I'm going to get a single vector that represents a particular taskã€‚

And I would hope that the vector space is kind of interpretable in that if I look at the nearest neighbors of any given tasks representation in this vector spaceã€‚

 I get tasks that are related either in terms of the kinds of reasoning that's required to solve them or maybe the size of the data set or the domainã€‚

 you knowï¼Œ all those properties that we discussed beforeã€‚

So people have looked at this before they've looked atï¼Œ for exampleã€‚

 in the context of sequence labeling tasksï¼Œ so these are things like part of speech taggingã€‚

 I have a sentence and I want to predict the part of speech for each of the words in that sentence there are other sequence labeling tasks like named entity recognitionã€‚

 So I have a sentence and I want to for every word in the sentenceã€‚

 annotate is an entity or not at a high levelã€‚ So all these tasks follow the same format I'm making a single prediction at every token of the input and you can show that some tasks benefit others moreã€‚

 but some tasks have more benefits for a particular downstream task than others This workã€‚

 this binle and sogar work was looking at this in the context of multitask learning so with the different weights for each taskã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_32.png)

Okayï¼Œ so you can imagine a very simple approach here being if I am provided a description of a taskã€‚

 So we looked at this hereï¼Œ right for this taskï¼Œ M NLI I have a paragraph describing this taskã€‚

 rightï¼Ÿ So one kind of interesting wayï¼Œ I could go about getting a task embedding for this task is to pass this description of the task into Bt and then takeã€‚

 you knowï¼Œ it CLS vector or an averageã€‚ğŸ˜Šã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_34.png)

Okayï¼Œ sorry about thatã€‚ It looked like myã€‚Internet just disconnected thereã€‚å—¯ã€‚Okayã€‚

I think its it's workingï¼Œ but I will wait for a message before continuingã€‚Okayï¼Œ greatã€‚

 it's working nowã€‚Yesï¼Œ so I was saying that we might want to have a clearly formatted and consistent format for this description across different tasks and one way you could think about doing this as for every paper that's associated with a particular data like maybe extract its abstract or introduction or something and embed those and BMã€‚

 you have a task embedding spaceï¼Œ but no one has actually tried thisï¼Œ it's unclear if first of allã€‚

 there are embedding methods like BerRT that can learn useful representations of descriptions of highly specialized technical data and secondã€‚

 it's not clear that the description of a task is the best way of representation it because this ignores a lot of interesting information about the data set itself it could potentiallyã€‚

ğŸ˜Šï¼ŒIgnore the size of the data set or even more low level information likeã€‚

What parameters in BRT are kind of specialized when you do the fine tuning process toã€‚

 to solve this task versus what parameters are left unchangedã€‚

 So there's a lot of useful information going on in the fine tuning process that we might want to encode hereã€‚

okayï¼Œ so a question for comparing sorry for comparing the task embeddingsã€‚

 note these tasks need to be embedded in the same way like by using the same techniqueã€‚ Yesï¼Œ yesã€‚

 so here in this simple approach that we're not going to explore any furtherã€‚ we for every taskã€‚

 have a paragraph long description of the task and we pass it through Bt like the pretrain burnt model to get a single representation of itã€‚

 But yeahï¼Œ this way is undesirable for for all of those reasonsã€‚

 So we might want a method that distills this task embedding from the actual fine tuning process itselfã€‚

ğŸ˜Šï¼ŒOkayï¼Œ so in particularï¼Œ I can use some information about the gradients of the model during the fine tuning process to get some information about the task itself so here in our pretraining setup right we have our base networkã€‚

 which in the case of NLP is Bt in the case of computer vision is the imagenet CNNã€‚

 and then we have our task specific classifier layer which you know for S is the start and end predictors for sentiment its just the single softmax to predict positive and negative or so onã€‚

ğŸ˜Šï¼ŒSo we could do this without fine tuning by simply passing our entire data set like whichever one we want to get a task embedding for through this network and then kind of measuring the gradients during the backpro phase and what that means sorry in more specifically is what actually do we want to extract from this process so if you read the second paper that was assigned on task embeddings we were using the empirical fissure information matrix which at a high level is measuring how important or how much the loss changes when I change a particular parameterã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_36.png)

And so in Btï¼Œ I have so many parametersï¼Œ rightï¼Œ I have 24 layersã€‚

 Each layer has you know the query key value projectionsã€‚

 It has a feed forward layer we have our embeddings our token embeddingsï¼Œ we have our softm layerã€‚

 So we have a ton of parameters and we can calculate this fiser information matrix to tell us which of these parameters impact the downstream predictions the most intuitivelyã€‚

 So we're not going to get into too many more of the details hereã€‚

 but just imagine you can extract that kind of information for all of the different types of parameters in the Bt model right So for every single feed forward layer or every single query key value projection during the fine tuning process which ones of these result in are changed in the most during the fine tuning process from what they wereã€‚

ğŸ˜Šï¼ŒIn their in the pre trained BRT representationã€‚So againã€‚

 there's even within the each transformer blockï¼Œ there are many different feed forward layersã€‚

 the query key value projectionsã€‚ so we have lots of different parameters hereã€‚

 and using the fiser information matrix we can get and we can even do some sort of dimensionality reduction on this at the end of the day to make it smaller or you know some sort of averaging whateverã€‚

 but we will use this technique to basically get some information from each of Bts different layers and we're going to aggregate all those things into a single embeddingã€‚

 So this is the first stageã€‚ğŸ˜Šã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_38.png)

And then the second stage is we can now do this for a bunch of different other tasks in our task libraryã€‚

 So this could be like hundreds of different tasksã€‚

 So here let's say I have some input task it gets associated with this red dot hereã€‚

 and then I have all these other tasks in my embedding spaceã€‚

 Now I'm just going to look at the task that's closest to this one in the task embedding spaceã€‚

 So it turns out to be this wki hopop data setï¼Œ which I guess is some sort of multihop QA dataã€‚ğŸ˜Šã€‚

And so now I'm just going to proceed with intermediate fine tuningã€‚

 Now that I've identified the single task that's the closest in this task embedding space to the one that I care aboutã€‚

 I'm going fine tune Bert on Wiki Hopã€‚ğŸ˜Šï¼ŒAnd then I'm going to fine tune the resulting model on my target taskã€‚

 So we're essentially using these task embeddings as a way to figure out which of the all of the existing tasks should I select for intermediate fine tuningã€‚

And what I've described at a very high level is just one way in which you can embed a taskã€‚

 there are many others that haven't yet been exploredï¼Œ so you knowã€‚

 potential side projects for anyone who's interestedã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_40.png)

So in the paper there is this plot of here's 33 different tasks that are divided into three different classesã€‚

 so the red tasks here are classification tasksï¼Œ the blue ones are QA tasks and the green ones are sequence labeling tasksã€‚

And so the modelï¼Œ you knowï¼Œ the task embeddingsï¼Œ they have no idea of what type of task a particular task is right the only thing that is taken into account when computing the task embeddings are the information about the gradients So it's pretty cool to see that the model can learn in this nearest neighbor space that you know all the red tasksã€‚

 the classification ones are pretty close togetherã€‚

 also like between different instances of the same classï¼Œ like MNLI and SnLIã€‚

 these are both textual entailment dataï¼Œ so they have a strong connection between them also you see like these two part of speech tag datasets are fairly close to each other and there are also some interesting cases of classification task like this coA data being kind of closer to sequence labelingã€‚

ğŸ˜Šï¼ŒDaets they areã€‚ than it is to maybe some of the other classification data setsã€‚

 So both intuitive and unintuitive results when youï¼Œ when you look at thisã€‚

So I wanted to conclude with just looking at one of the figures in this paper to maybe make the point more clear that we're notã€‚

 we're still a little unsure why a particular task helps another oneã€‚And so in this plot hereã€‚

 we have on the X axis the target downstream taskã€‚And so this is the task that we actually care about and this is called a violin plot so each of these columns hereã€‚

 each dot inside one of these violins represents the performance on the test set of the associated target task when we fine tuned with a particular intermediate task so each dot represents different intermediate task so let's zoom in and see what kinds of results we or what kinds of intuitions we can take away from thisã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_42.png)

So these blue tasks here are all classification dataset setsã€‚

 And it turns out kind of weirdly that the best intermediate tasks for many of these classification data sets are actually QA tasksã€‚

 So here these orange dots are when we do intermediate fine tuning with a question answering dataset setã€‚

 So this could be squad or multi sorryï¼Œ hotpot QA or news QA or something like thatã€‚

 And you can see that the other the blue dotsï¼Œ the ones that correspond to other classification tasks are below these orange dotsã€‚

 This black line corresponds to what happens when you do no intermediate fine tuning at allã€‚

 So for this particular taskï¼Œ SSBï¼Œ which measures how similar are two sentences to each other semanticallyã€‚

ğŸ˜Šï¼ŒWe see that without any sort of intermediate fine tuningï¼Œ we get around 30% or soã€‚ But when weã€‚

Fine tune with these purple intermediate tasksï¼Œ which are associated with sequence labeling tasksã€‚

 Our performance actually drops below this baselineã€‚

 So this is just emphasizing that some of these intermediate tasks actually hurt the downstream performanceã€‚

 So you have to be carefulã€‚ this is not a method that always worksã€‚ but on the other handã€‚

 doing intermediate fine tuning with other tasks like this one result in huge gainsã€‚

 So here we have a gain of we get up to like 60 or 70 on thisã€‚ I forget what the actual metric isã€‚

 I don't think it's accuracyï¼Œ but maybe it isã€‚ğŸ˜Šï¼ŒSo there's a lot of room for improvement and this set of experiments has controlled for things like the data size of both the intermediate and the downstream tasksã€‚

 so they all have the same number of fine tuning examples and this is also in a low data setting so assuming that you don't have that many labeled data pointsã€‚

ğŸ˜Šï¼ŒYeahï¼Œ so the star here represents the task that is chosen by the task embeddingã€‚

 so you can see that here the task embedding methodã€‚

 the closest task in the space does give you some boost over the baseline but it's very far away from the best task right and that kind of makes sense right because for this particular task STSBã€‚

 the QA datas are not as closely tied to that as some of these other classification tasksã€‚

 so there's still a lot of work that needs to be done and a lot of room for improvement to you know take full advantage of the other labeled data setsã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_44.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_45.png)

So when we look at the QA dataset setsï¼Œ so these are the orange target tasks hereï¼Œ the top one hereã€‚

 the best tasks that improve the most with intermediate fine tuningï¼Œ are other QA dataset setsã€‚

 so here at least the results are more intuitive and we see that again using the sequence labeling tasksã€‚

 the purple ones hurt youï¼Œ they drop you below the baselineã€‚So these are someã€‚

 basically the takeaway here is that we don't really know anything about why a particular task is helpfulã€‚

And the models are predicting things that are kind of intuitive so farã€‚

 like QA data sets are close to other QA datasã€‚ But for some of these unintuitive casesã€‚

 it's very hard to figure out why a particular task is so useful one very interesting thing here is that I mentioned for all of these QA tasks that other QA tasks tend to be most helpfulã€‚

 except for this one task drop where the most helpful tasks by far were sequence labeling tasksã€‚ Ohã€‚

 I see there's a question about thisã€‚ Yesï¼Œ so this is a good question why why are these sequence labeling tasks helpful only for drop and they actually hurt for most other data setsã€‚

ğŸ˜Šã€‚

![](img/e996e93a8a3b5c4ef30008591fbba5d8_47.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_48.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_49.png)

We have tried to understand this but have failed so farã€‚The reason that is given in this questionã€‚

 perhaps because it was created to be adversarialã€‚Yeahã€‚

 we're not really sure how that ties into sequence labeling tasks being muchã€‚

 much better than having no intermediate fine tuning at allã€‚So yeahã€‚

 it's kind of an unknown at this pointã€‚ And you can see also that the star hereã€‚

 the task embedding model selects a task that does even worse than the baseline for dropã€‚ So yeahã€‚

 it's it's prettyï¼Œ pretty strangeã€‚Okay but overallã€‚

 just some high levelvel takeaways are these plots make it clear that for most tasks for basically every taskã€‚

 there is some intermediate task that will boost the performance compared to just the standard pretrain and then fine tune on your downstream dataã€‚

 we have some idea of methods that we can use to predict what the intermediate task should beã€‚

 but they're not perfect and in some cases they might actually be worse than not doing any intermediate fine tuning at all like in this particular caseã€‚

 but for those of you who are using models like BRT in your final project and you have relatively small downstream datasã€‚

 which I assume is many of you who are resource constrain and are only using collab or something like that you might want to check check out some of these or just doing some sort of intermediateã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_51.png)

Tuning isn a possibly easy way to improve your resultsã€‚å—¯ã€‚Okayã€‚Soã€‚Rightï¼Œ ohã€‚

 I see I missed a questionã€‚ Are we intuitively looking at how close the parameters are to the maximum likelihood estimates yeahã€‚

 so intuitively like we're looking at how basically for any two tasks when we get these aggregated task embeddingsã€‚

 their embeddings will be similar if the same parameters were changed most in the fine tuning process within the base BRT model from the pretrain modelã€‚

 So I guess that's kind of the intuitionï¼Œ although it's a little hard to extend to the case where you know we have all these different layers and we're doing some sort of aggregation over themã€‚

 But yeahï¼Œ that's the high level ideaï¼Œ at least but I think as these results should show this is not a perfect method or maybe even the best way to do this and we probably will see many better methodsã€‚



![](img/e996e93a8a3b5c4ef30008591fbba5d8_53.png)

s over the next yearã€‚ So it's a veryï¼Œ very new thingã€‚Ohã€‚

 another thing I should mention before concluding this lecture is that and maybe something to think about is whether this idea of doing intermediate fine tuning will even be required in the future when we get bigger and bigger pretrain models right so if I have a Bt that's been pretrained on say1 trillion words instead of 3 billion wordsã€‚

ğŸ˜Šï¼ŒMaybe a lot of this room for improvement that we see with these intermediate tasks goes away and the use of actual explicit labeled data sets becomes lower and lower So that is a plausible direction for research in NLP to proceed well see what happens I there any good open source code based on either the papersã€‚

 yeahï¼Œ so the homework will contain some cells that you can use to get started So yeahã€‚

 be on the lookout for thatã€‚ All rightï¼Œ I'll conclude here next time we'll be talking about different variants of Bt So things like ExcelNeã€‚

 Robertaï¼Œ Albert and so on that have been proposed that to address some of the limitations of Bt andã€‚

ğŸ˜Šã€‚