# P12ÔºöL9- ‰∏ãÊ∏∏‰ªªÂä°ËøÅÁßªÂ≠¶‰π† - ShowMeAI - BV1BL411t7RV

OkayÔºå Henry I think we're liveÔºå pleaseÔºå if you're watching this type something in the chat box„ÄÇ

 so I know that it's on Also last time my chat box wasn't not updating for some reasonÔºå so„ÄÇÂóØ„ÄÇ

I actually did not get a chance to look into why that was happening„ÄÇ

 Hopefully it doesn't happen again„ÄÇ All rightÔºå I see one person„ÄÇTwo people„ÄÇ

 I'm just going to assume it's working„ÄÇOkayÔºå if I notice any periods where„ÄÇ

Like there have been suspiciously few questionsÔºå then I will„ÄÇTry to like„ÄÇ

 I actually don't know what I'm supposed to do„ÄÇ Maybe refresh the„ÄÇYouTe thing or something„ÄÇAll right„ÄÇ

 so what are we talking about today hang on let me make sure this iPad is working„ÄÇOkay„ÄÇSo„ÄÇ

 today's topic is intermediate„ÄÇTask„ÄÇFineÔºå tuning„ÄÇAnd what I'm going to do is give a bit of intuition first on the iPad„ÄÇ

 and then I'm going to switch over to some slides to talk about some very recent research that actually one of the Ts tou has done in this line of work as opposed to all of the previous stuff that we've learned this direction is incredibly new„ÄÇ

 and it's seeking to build on top of selfsupervised pre-training using things like language modeling and mask language modeling„ÄÇ

 but here it's trying to take advantage of other labeled data setsÔºå not just the downstream data set„ÄÇ

So before we startÔºå I wanted to briefly go over maybe the most obvious way in which we can incorporate different downstream tasks into the same model to benefit a particular task that you care about„ÄÇ

 so let's just set this up„ÄÇImagine„ÄÇI am trying„ÄÇTo optimize„ÄÇPerformance on squad„ÄÇ

So remember that S is the Q A data set that we talked at length about last time„ÄÇ and in S„ÄÇ

 you have like a passage„ÄÇ you have a question about that passage and you're trying to„ÄÇ

Train a model to figure out what that spanÔºå the answer span is„ÄÇÂóØ„ÄÇBut so far„ÄÇ

 we've just assumed that we have access to a large unlabeled data set for pre training„ÄÇ

 and we also have access to our downstream training data setÔºå like the squad training data set„ÄÇ

 rightÔºå So to draw this outÔºå it would look something like„ÄÇ

And this was basically a figure from one of our earlier slidesÔºå we have lots of unlabeled data„ÄÇ

We feed this into squadÔºå sorry tip Bt„ÄÇRightÔºå and we pre traineded Bert using the mask language model objective„ÄÇ

We'll call this the pre training step„ÄÇ And then we have access to our squad„ÄÇTraining set„ÄÇ

This is going to form our source of supervisionÔºå which we're then going to use to fine tune„ÄÇ

The B language model into aÔºå let's call it a squad specialized„ÄÇModel„ÄÇRight„ÄÇ

 so this is the paradigm that we've talked about to this pointÔºå right„ÄÇÂóØ„ÄÇWe start with Bert„ÄÇ

 and then we fine tune it to get the downstream model„ÄÇ

So what this ignores is that I also have access to numerous different labeled data sets that could potentially be helpful at increasing my performance on S„ÄÇ

One obvious example which kind of ties into what we talked about last time is there are numerous different QA data sets right so there's hotpot QA quack news QA„ÄÇ

 lots of other dataset sets that we discussed last time and you might imagine that having access to some of these other QA data sets can help further boost my performance on S„ÄÇ

So one question„ÄÇCan we leverage„ÄÇOther„ÄÇQÔºå A data sets„ÄÇTo improve„ÄÇOur squad„ÄÇTest time„ÄÇHerform„ÄÇ

And so there are many ways you could think about doing this„ÄÇ

 The most standard way is to use multi task learningÔºå so„ÄÇWenwei„ÄÇMulti task„ÄÇ3y„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_1.png)

SoÔºå here„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_3.png)

We're just going to during this fine tuning process„ÄÇ

 include examples from other data sets into the fine tuning process„ÄÇ

 So if I take the same setup here„ÄÇCan you just copy this„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_5.png)

And paste it down here„ÄÇOkay„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_7.png)

Where did thisÔºüHere I canÔºå instead of just having access to the squad dataset set„ÄÇ

I'm going to have access to squadÔºå plus„ÄÇHot pot Q A plus newsÔºå Q A„ÄÇPlusÔºå so on right„ÄÇ

 I can just add as many of these dataset sets as I want into the fine tuning step and the nice thing about these QA data sets is that they all follow the basically the same format right you have a question about a passage and the answer is a span of text within that passage so„ÄÇ

That is that makes it such that I can just concatenate all these data sets together„ÄÇ

 and then hopefully I'm leveraging information from these other data sets that will be useful when I eventually evaluate this sunqua„ÄÇ

So that's the idea but remember that in this setting we only care about our performance on S„ÄÇ

 we don't care about our performance on hotpot QA or news QA or so on„ÄÇ

 and so the loss function that we might want to use in this multitask setting looks a little different than the standard cross entropy loss over all of the training examples„ÄÇ

So in particularÔºå let's just say we in the simple caseÔºå assume we train„ÄÇOnS„ÄÇPlusÔºå hot potÔºå QÔºå A„ÄÇOkay„ÄÇ

 I see that there is a questionÔºå I will get to these right after I finish explaining the current concept„ÄÇ

But good to know that thisÔºå this chat thing is actually working„ÄÇ Okay„ÄÇ

 so let's just assume we train on these two data sets„ÄÇ So in multitask learning or MTL„ÄÇ

 I'm going to use the following loss functionÔºå which basically weights the loss coming from the squad examples„ÄÇ

üòäÔºåWith some particular lambmbda and then waits the hotpot QA„ÄÇLoss with1 minus lambda„ÄÇ

So in this settingÔºå rightÔºå if I only care about my squad performance„ÄÇÂóØ„ÄÇIf I care„ÄÇAbout„ÄÇSquad„ÄÇMaybe„ÄÇ

I use a high lamb„ÄÇHere so hereÔºå of courseÔºå lambda is between 0 and 1„ÄÇ it's basically saying„ÄÇ

 you knowÔºå if I set lambmbda to 0„ÄÇ8Ôºå that means 80% of my fine tu loss will come from S and 20% will come from hotpot QA„ÄÇ

 So because I want to maximize my performance on SÔºå I might want to up my lambmbda here„ÄÇ

 and I would hope that having some loss come from hotpot QA is going to get important information from hotpot QA into the model that maybe S didn't have and is going to eventually boost my performance S„ÄÇ

So the issues with this setup are mainly in how do we choose these lambmbdasÔºå rightÔºü

And this is because if I just naively set these things to 5050Ôºå in many casesÔºå I don't see„ÄÇ

 you know any corresponding gain„ÄÇ So in one of your assigned readings today„ÄÇ

 which was the stilts paperÔºå they tried the naive multitask setting where they basically just concatenated all of the data sets together and had this kind of equally weights for each task and it didn't really result in any improvements so choosing the lambmbda is an art„ÄÇ

 you might want to adjust this lambda through training to maybe start with focusing equally on both data sets and then towards the end of training„ÄÇ

 focus more on squ you might want to learn the lambmbdas„ÄÇ

 So there's lots of methods proposed to deal with this stuff„ÄÇ but in general„ÄÇ

 multitask learning is really hard to get right„ÄÇ And there haven't been many positive examples of it in NLP„ÄÇ

So that kind of motivates this other direction that we're going to be talking about today„ÄÇ

 but before we get into thatÔºå let me take these questions so the first question since we are already using squad for fine tuning„ÄÇ

 what do we mean by squad test time performance are we dividing squad into training and test Yes„ÄÇ

 of course so we always are going to be dividing the data sets that we're that we eventually care about into training„ÄÇ

 validation and test right so the reason is because if we train on all of the data then we don't have any way of evaluating how well we did rightÔºü

We need to have a held outset for test time so that we don't cheat and test our model on things that it's already seen during training„ÄÇ

ÂóØ„ÄÇOkay so next questionÔºå we need to have the same type of objective function as well as label data for all these data sets That is not actually true„ÄÇ

 That's just what I've shown in this exampleÔºå so you could potentially multitask with many different types of tasks and objectives but you can imagine this makes this weighting process even harder right not it's not very clear how I'm going to assign a weight to a completely different type of objective function and yeah you can imagine that as I add more and more tasks into this setup„ÄÇ

 it becomes harder and harder to decide how to weight the different tasks properly another way that people do this is instead of explicitly weighting the tasks„ÄÇ

 they subsample different data sets with certain probabilities but yeah all of this is it's just very„ÄÇ

 very difficult to figure out a setting that actually works„ÄÇ

And generalizes to multiple different downstream tasks„ÄÇOkay so why is it called multitask learning„ÄÇ

 the task is still fixedÔºå which is to find the spin of task for all these data sets right so that's a good question but but the difference is that squad and hotpot QA are not the same task they might have the same format„ÄÇ

 but hotpot QA is data collection process was designed explicitly to avoid the types of simple string matchbased reasoning that squad you solved by„ÄÇ

 So you might imagine that having some of that higher level reasoning that hotpot QA at least theoretically forces a model to learn can help a squad model on harder examples that are not necessarily solvable by string matching So there is a difference between the task format and the data set itself right so S and hotpot„ÄÇ

üòäÔºåQA have the same formatÔºå but they actually are fairly different in terms of what kinds of reasoning the model needs to learn to solve them„ÄÇ

And that's the intuition„ÄÇOkayÔºå so let us continue„ÄÇ What we're going talk about here is a different process„ÄÇ

 which isÔºå I guessÔºå a little less flexible in that it does not require any sort of learning weights or anything like that„ÄÇ

 but it's also it requires another phase of training essentially„ÄÇ

 So if we take our maybe I'll just copy„ÄÇThis one„ÄÇSo we're going to start as usual„ÄÇ

 with this pre training„ÄÇI maybe yell and a separator thing„ÄÇOkayÔºå so we're going to start here„ÄÇ

 and eventually we're going to end up here„ÄÇBut instead of just going directly from pre training to fine tuning„ÄÇ

 we're going to add an intermediate stage„ÄÇ And so here we're gonna have this„ÄÇIntermediate„ÄÇA modelel„ÄÇ

And we're going to get this intermediate model by using a different data set„ÄÇ so we could say„ÄÇ

 just use the hotpot QA training„ÄÇData set„ÄÇAnd we do one round of fine tuning„ÄÇ

 and we take the resulting model and then fine tune that completely on squad„ÄÇ

 So this is kind of analogous to doing multi taskask learningÔºå but„ÄÇüòäÔºåOhÔºå was it buffering„ÄÇ

For' almost half a minuteÔºå all rightÔºå hopefully that was resolved„ÄÇOkayÔºå that's not great„ÄÇSing on„ÄÇ

 let me try„ÄÇReducing the bit rightÔºå or is it better nowÔºüIt seems to be better„ÄÇ

 so I'm just going to proceed and hope that this is working„ÄÇOkayÔºå so yeah„ÄÇ

 we have this intermediate model that we're adding into this pipeline and as I was saying„ÄÇ

 this is kind of analogous to having the multitask learning set except we are adjusting the lambmbdaAs dynamically to have like 100% of the weight on hotpot QA and then after convergence„ÄÇ

 we switch to 100% of the weight on squad„ÄÇ So if you look at it in that way you can kind of formalize it in the same manner as the multitask learning setup„ÄÇ

OkayÔºå so this approach removes a lot of the variables for multitask learning„ÄÇ

 because we have essentially fixed these lambdas to occur at certain points during training„ÄÇAnd it„ÄÇ

 it forces the model to first completely specialize to hotpot Q A before re specializing to squad„ÄÇ

So that's actually like the high levelve overview of the method that we're going to be discussing today„ÄÇ

 It's very straightforward„ÄÇ It just takes another data„ÄÇ

 another label data and inserts it as an intermediate task into this process„ÄÇ

 So a couple of questions aren't the outputs for these tasks different„ÄÇ

 are we replacing the final layer between tasksÔºå yeahÔºå good questions„ÄÇ So in this case„ÄÇ

 the output format is the same so we could actually share the final softmax layers across both of these different QA tasks„ÄÇ

 but in practiceÔºå I could put like sentiment analysis in as the intermediate task right And so if I did that„ÄÇ

 then of course my softmax layer is no longer useful first squad So I throw it away and just initialize a new softmax layer for the beginning of the spin and the end of spin prediction„ÄÇ

üòäÔºåbut the important thing is that the weights of Bt right those are also being fine- tuneuned in both of these processes and so after after this intermediate stage„ÄÇ

 I have a new set of weights of Bt that have been they've taken the mask language model stuff that's been learned during pretraining„ÄÇ

 those weights and then they've adjusted them to make them better for hotpot QA and finally we're going to readjust them to be better for squad„ÄÇ

So that's kind of the intuition„ÄÇ Does the ordering of the intermediate models matter„ÄÇ

 This is a great question„ÄÇ So in all of the methods that we gave you for reading and that have been tried so far„ÄÇ

 there's only been one intermediate task inserted If you go to multiple different intermediate tasks„ÄÇ

 then we start running into the issue of how do we know what order optimizes our downstream performance„ÄÇ

 these are very expensive experiments to run right because we have to try all possible orderings to find something that might generalize to new downstream tasks its it's very difficult So so far„ÄÇ

 yeahÔºå it's hard to say if I have multiple intermediate tasks how I should order them„ÄÇ

 maybe there' are some simple heuristics like data set size or similarity to the downstream task that you actually care about„ÄÇ

üòäÔºåThat can influence thisÔºå but currently those are all unknowns„ÄÇ

Definitely interesting to explore in the future„ÄÇI should also say that multitask settings that use more than one secondary objective„ÄÇ

 it's basically analogous to the problem of finding optimal weights being harder and harder as I add more tasks here„ÄÇ

 it's just the order of the training of the intermediate fine tuning„ÄÇ

For a very small dataset set can intermediate model health„ÄÇ That's a great question„ÄÇ Actually„ÄÇ

 the second paper you had to read shows that the results„ÄÇ

 the improvements that you get from intermediate fine tuning increase when the downstream task is small„ÄÇ

 like when the downstream data is small„ÄÇ So we did this experiment on only and we only had access to 1000 squad training examples„ÄÇ

 this intermediate process provided we choose the right tasks helps a lot a lot more than if you have the full data„ÄÇ

 So yeahÔºå this is definitely something that is very useful in low resource settings„ÄÇüòä„ÄÇ

If we repeat this process multiple times how much would the squad performance vary„ÄÇ

 I think you need to specify a couple things hereÔºå like what is being kept consistent across multiple iterations„ÄÇ

 if you repeat the entire process keeping the intermediate task the same and of course your downstream data the same it really depends a lot on the size of both the intermediate and the downstream data sets„ÄÇ

 So if they're smallÔºå you of course will expect higher variants„ÄÇ

 but if they're both large then the experiments we've done to this point show that there's much lower variance„ÄÇ

 but yeah this method is only really useful on or I shouldn't say that it's significantly it results in significantly improvements when you have small downstream data sets and the experiments also show that intermediate fine reduces the variance„ÄÇ

Of the downstream task when you train it with a couple different trialsÔºå so yeah„ÄÇ

 the benefits include better performance and lower variance„ÄÇ

 which is of course what you want in the end„ÄÇOkayÔºå so is this fine tuning based on backproÔºå if yes„ÄÇ

 then how do we handle the differentials because they may be different for the different modelsÔºü

 Of courseÔºå all fine tuning and pretrainingÔºå etc cea is based on backpro„ÄÇ

 that's how we're you know calculating the gradients that we're using to update the models„ÄÇ

 And remember that the core model hereÔºå the Bt model is is the same architecture in all three of these these phases„ÄÇ

 So the gradient updates are going to the same set of base parameters that come from the original Bt model right So the only differences could be the output layer based on what your intermediate task is but that's a really small part of the model right Bert„ÄÇ

 you knowÔºå 24 layer transformer most„ÄÇüòäÔºåSo the parameters are shared across all three of these phases here„ÄÇ

OkayÔºå so what else did I want to say before I move to the slidesÔºå Right„ÄÇ

 So I just wanted to highlight some interesting questions and note that a lot of these are not answered to this point„ÄÇ

 but„ÄÇThis is kind ofÔºå I thinkÔºå a useful thing to think about when you're you know thinking about BerRT and whether just scaling up mask language modeling or language modeling„ÄÇ

 the bigger and bigger data sets is the best way to see improvements„ÄÇ

 this provides an alternative to that where we actually leverage some of the label data sets that we have to get more improvements on top of BRT„ÄÇ

So the most interesting questionÔºå possibly isÔºå how do we know„ÄÇWhat„ÄÇIntermediate task„ÄÇWill result„ÄÇIn„ÄÇ

The biggest„ÄÇDownstream improvements„ÄÇSo you might have a many different hypotheses for why a particular task is better than another one when it's used as an intermediate task here right like if I told you that hotpot QA results in like a5 F1 gain when it's used for intermediate fine tuning for squad and fine tuning„ÄÇ

 doing intermediate fine tuning on sentiment analysis actually hurts the model and results in like a minus 10 F1 on squad„ÄÇ

 you might intuitively thinkÔºå oh that's obvious rightÔºå because hotpot QA is a QA data„ÄÇ

 it tests a lot of the same kinds of reasoning as squad„ÄÇ

 and so that's why hotpot QA is better than sentiment analysis for this intermediate task because sentiment and squad share very little in terms of what the model is expected to learn„ÄÇ

So it would be niceÔºå of courseÔºå if that was always true„ÄÇ

 And there was like an interpretable reason why a particular data set work better than another„ÄÇ

 But there are many different factorsÔºå rightÔºå So one is like task similarity„ÄÇüòäÔºåAnd so this is like„ÄÇ

QA„ÄÇQAÔºå so this is the intermediate task„ÄÇMaybe I'll highlight these to make them more clear„ÄÇ

 to the screen through„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_9.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_10.png)

So this is QA for the intermediate task and then QA for the downstream task„ÄÇ

 like hotdpot QA and squatter both QA tasks sorry„ÄÇVersus„ÄÇSentiment„ÄÇ

So this this could be one possible way to chooseÔºå another is size of intermediate data set„ÄÇRight„ÄÇ

 maybe we expect a bigger data set to be more useful than a smaller data set for intermediate fine tuning„ÄÇ

 So what happens if I have„ÄÇ100 Q A A„ÄÇExamples„ÄÇVersse„ÄÇ100000„ÄÇSentiment„ÄÇRight„ÄÇ

 another thing we need to consider„ÄÇHere are both the intermediate task„ÄÇ

Another thing is domain similarity„ÄÇSo remember that squad is constructed from Wikipedia articles„ÄÇ

 rightÔºü So what if I have„ÄÇQÔºå let's say„ÄÇMake the data set size the sameÔºå10Ôºå000 QA examples„ÄÇFrom„ÄÇ

 I don't know„ÄÇ What is a complicated domain specific data setÔºå maybe like some„ÄÇFor medical journals„ÄÇ

 first„ÄÇSomething highly specific to a single field versus 10000„ÄÇSentiment„ÄÇExamples„ÄÇFrom Wikipedia„ÄÇ

RightÔºå so there are so many different factors when you think about„ÄÇ

Why a particular data set is more useful than another for intermediate fine tuning„ÄÇ

 and it's hard to know in any particular case which of these factors is going to be the most significant„ÄÇ

So that kind of motivates the question„ÄÇCan we predict„ÄÇWhich„ÄÇTask„ÄÇOut of„ÄÇSo finite„ÄÇSet of tasks„ÄÇWill„ÄÇ

The most„ÄÇUseful„ÄÇAs„ÄÇInmediate„ÄÇTk„ÄÇGiven„ÄÇÂóØ„ÄÇGiven a specific„ÄÇDownstream data set„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_12.png)

OkayÔºå so„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_14.png)

Make that more clear„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_16.png)

OkayÔºå so at this pointÔºå I think I'll switch over to slides„ÄÇ

And we can talk a little bit more about like some methods that we can use and how they work in a kind of a high level of detail„ÄÇ

But before thatÔºå can you explain in the given examples which one will work better or are these still questions Yeah„ÄÇ

 so I kind of meant this as these are some of the factors that you need to consider when deciding what task to use as an intermediate task there have been methods that are proposed like the ones in your reading kind of get to some level of predicting which task will be better„ÄÇ

 but these are still mainly open questions they're unsolvedÔºå at least in a general setting„ÄÇ

 it's yeahÔºå there's no method that'll tell you for sure what is the best task to use for any given downstream data set„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_18.png)

If we have a pair of data sets that we know work wellÔºå can we use them in any orderÔºü

So in in all of these settingsÔºå I'm assuming that you have one task that you care about right That's the one in red here„ÄÇ

 the downstream task„ÄÇ So in this exampleÔºå it's squ„ÄÇ

 And you have a bunch of other tasks and you're going to use maybe one of them for intermediate fine tuning„ÄÇ

 And so you're trying to pick which one task you're going to use„ÄÇ there isÔºå of course„ÄÇ

 the extension of thisÔºå which is maybe I can pick a sequence of many different tasks to use here„ÄÇ

 but no one really knows what happens in that settingÔºå you can imagineÔºå thoughÔºå if you„ÄÇüòä„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_20.png)

Maybe I can't„ÄÇThis is a bit of a diversion because I'm not actually sure what happens in this setting„ÄÇ

But if I do this and instead of immediately going to the downstream task„ÄÇ

 I just like repeat this for N intermediate tasks„ÄÇBefore getting to the downstream model„ÄÇ

 this could potentially helpÔºå rightÔºå Maybe I find like a nice sequence of tasks that specializes enough useful information into the model before eventually getting to the downstream data set„ÄÇ

 but it could also really hurtÔºå rightÔºå because with each one of these new intermediate tasks that I add here„ÄÇ

 I kind of forget some of the information that I learned from my Bt pretrainingÔºå right„ÄÇ

 And that's really bad because note that the Bt pretraining phase was the one that had access to the largest training data set„ÄÇ

 rightÔºå we could use unlabeled data so we have potentially infinite pretraining data versus for each intermediate task we have only a small amount of label like a relatively small amount of label data„ÄÇ

 rightÔºå so„ÄÇüòäÔºåThe the pre-training phase is definitely the most important and if we get too far away from the pretraining phase„ÄÇ

 then our model might forget a lot of the useful information that could potentially benefit our downstream squad model„ÄÇ

 but that saidÔºå I'm not actually sure what happens hereÔºå it's also unclear if using a sequence„ÄÇ

 the sequence ordering is best or maybe we can do some sort of joint training or train all of the fine tune and all the models directly from BRT separately and then do some sort of aggregation lots of open questions in this area„ÄÇ

 but I just wanted to kind of introduce the possibility of leveraging other downstream tasks to help on a particular down data set„ÄÇ

OkayÔºå apartpart from the same task for a particular downstream task„ÄÇ

 how do we measure the similarity between different tasks„ÄÇ

 we'll get to this when we go to the slides or at least one method for doing this Can't we use beam search to greedily choose the best task No so„ÄÇ

It„ÄÇLikeÔºå if you hadÔºå you knowÔºå like 50 different tasks and you wanted to find the best one„ÄÇ

Remember that the only way in which you can evaluate how good a particular task is is to do this entire fine tuning stage for every single of these 50 possibilities right so I could of course try out every single one of my 50 tasks in this process and pick the one that's best so that's not really scalable right if I come up with a new task„ÄÇ

 I don't want to wait you know several days for for this process to finish for each of the 50 different task so you really need a way to approximate the information that is preserved after fine tuning on a particular task and then do some sort of reasoning over this approximation of a task to figure out which one is best So it's not really possible at least now to to„ÄÇ

üòäÔºåDo some sort of search without actually going through the full fine tuning process which is very expensive so all of the methods we'll be discussing here look for a way to encode a task into a low D representation that we can then do some sort of reasoning over so with that I will switch over to the slides wow„ÄÇ

 so's not've been 36 minutes„ÄÇüòä„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_22.png)

Doing good here„ÄÇOkayÔºå so„ÄÇI'm upseting you„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_24.png)

All right„ÄÇÂóØ„ÄÇSo yeahÔºå we're still talking about this intermediate task„ÄÇ

 fine tuning stuff here we'll get a little more concrete in methods that we can use to choose a particular intermediate task before we do that there is some stuff from last time that I will talk about here so we got to comment on the anonymous form about we were signing too many readings so I apologize for that I just figured that most of you aren't doing the readings anyway so if people are actually interested in learning more about the things that we talk about in the lecture you can check out the readings„ÄÇ

 but at this point I would say that you know the readings are just for people who are actually super interested in the material and we'll be covering all the important concepts in the lectures the readings now have become like very recent research papers so it's totally understandable„ÄÇ

If you're unable to understand all of them completelyÔºå in fact„ÄÇ

 like neither myself nor the TAs are able to you know completely understand most of these papers by just reading them so don't feel bad about that a lot of it is just due to poor writing but yeah„ÄÇ

 I think several papers assume a lot of background knowledge about related work that you have to then go and check out to understand what they're talking about„ÄÇ

 so it's actually a long process to understand a research paperÔºå but„ÄÇ

We'll try and cover most of the important concepts from each paper in the lecture„ÄÇ

 so specifically I think for next class I've assigned a ton of different papers and yeahÔºå again„ÄÇ

 don't feel obligated to read all of them completely at least make sure you check out you know the abstract introduction„ÄÇ

 maybe some of the results and those are generally written at a high enough level for people who are familiar with basic NLP and machine learning concepts to understand„ÄÇ

üòäÔºåThe other thing no one has complained about maybe unsurprisingly„ÄÇ

 which is homework one still hasn't been released is basically all on me at this point„ÄÇ

 the T has completed a draft of it and I'm still kind of tweaking things to make it more informative and useful for your final projects for those of you who are using Bt like models and neural language models in your project so yeah„ÄÇ

 it will be out very soon and actually some of the I know I've been saying that hence the mythical homework it will be coming out at some point in the semester and homework will include a bit of stuff on intermediate fine tuning as well so we've now covered that also this past week we posted an extra credit assignment which„ÄÇ

üòäÔºåI think anyone can do regardless of time zone you don't have to attend these talks live„ÄÇ

 you can watch the recorded versionsÔºå but basically there's three or four or five talks this semester that are related to NLP or some of the concepts we've been discussing in this class and so these are you know like researchers„ÄÇ

 facultyÔºå PhD students that are giving talks about their latest research so yeah the assignment is essentially to write up a summary answer some questions about their their talk and it's not a very„ÄÇ

And„ÄÇComplex assignment or it shouldn't take that much time„ÄÇYeah„ÄÇ

 I think that's all I wanted to say about this Oh yes also exam I'll be putting out the exams from previous semesters later this week and I'll put them up first without solutions so you can try them out and then the following week I'll put up the solutions but note that many of the things especially the most recent lectures that we're covering was't not present in previous iterations of this class so there will be questions that are on topics that you haven't seen before also there are sorry that aren't in the practice exams is what I'm meant to say there are also topics in the practice exams that we haven't covered in this class so you can ignore those I'll also mention you should ignore all the multiple choice questions we not going to have multiple choice on this exam and yeah I'll highlight particular questions„ÄÇ

üòäÔºåThat are going to be more like the things that you will see on the exam„ÄÇ So more on that on Piaz„ÄÇ

OkayÔºå so I've been using this word task a lot in the when I was going over things on the iPad„ÄÇ

 I just wanted to be a little more specific about what we mean when we talk about a task„ÄÇ

 right we're choosing a task to be this intermediate fine tuning and also for our downstream training„ÄÇ

 And so we're gonna consider a task to have know a description„ÄÇ

 it's gonna tell you what the task is actually doing„ÄÇ And also a task is associated with a data set„ÄÇ

 rightÔºå So for all of the cases we'll be considering these are labeled data sets„ÄÇ

 So we have these x'sÔºå which are our inputs and our Y's„ÄÇ

 which are the labels sometimes these x's could be a little more complicatedÔºå right„ÄÇ

 So in the case of squadÔºå the input is„ÄÇüòäÔºåThe the question as well as this associated passage and the whys are the indices of this answer span in the passage„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_26.png)

So as we've seen or actually we haven't seen this yetÔºå but as I've implied„ÄÇ

 you can use different tasks to help each other to improve performance on a particular task and there's a lot of prior literature on this right so one of them that was assigned in your reading this Fo at all paper showed for classification tasks that you first start with your pre-training objective on language modeling then you do intermediate fine tuning on all these different task as well as reduced variance„ÄÇ

üòäÔºåSo there's this other paper that we did not assign in this for this lecture by Nelson Lu that shows that„ÄÇ

Using more related tasksÔºå so if my downstream task is QA pre training or doing intermediate fine tuning on another QA task is more helpful than doing just language model pretrain without this„ÄÇ

And yeahÔºå people have shown that in the QA setting„ÄÇ

 you can get some boosts when you pretrain or sorry„ÄÇ

 do intermediate fine tuning on other QA data sets before fine tuning on your target one„ÄÇ

 so these are three pieces of evidence that you can leverage other label data sets to help out with your current one„ÄÇ

All rightÔºå so whoops„ÄÇÂëÉ„ÄÇI wanted to say that if we have a way to kind of encode the unique identifying properties of each individual task„ÄÇ

 then we might be able to come up with some way of measuring the similarity of different tasks to each other and also maybe measure how beneficial doing intermediate fine tuning on one task is to another task and all of these these kinds of works have practical applications because maybe I don't need to collect such a big label data for my specific downstream task I can leverage bigger existing data sets that are kind of related in some way to the one I want to solve„ÄÇ

OkayÔºå so rightÔºå there are obviously real world use cases for this kind of thing„ÄÇ

 right I think one that's particularly interesting for„ÄÇ

 say a company is if you have a user that's able to submit a completely new task right so they provide maybe a description of what this task is and some sample data of you know X Y pairs„ÄÇ

 input output pairs and the company responsible for training some sort of model on this data the company can kind of leverage their existing knowledge of all of these different tasks that have already been submitted to you know return either a single intermediate task or a sequence that can maximize the performance on the end user's task„ÄÇ

üòä„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_28.png)

OkayÔºå and within NLPÔºå I know we haven't talked about a lot of different downstream data sets„ÄÇ

 but I just wanted to make it clear that there are a lot of different labelable data sets that have been created over the years„ÄÇ

 rightÔºå So this table is only a small fraction of all of the data sets„ÄÇ

 I'm sure many of you while browsing through the AL„ÄÇ

 ELP proceedings noticed how many new data sets are proposed at every conference„ÄÇ

 to test some new linguistic property or type of reasoning that hasn't been tested beforeÔºå right„ÄÇ

 And so this mass of tasks just taken together is a huge set of resources that we can use to further optimize our performance on the task that we care about„ÄÇ

üòäÔºåÂóØ„ÄÇRightÔºå so if you look at the machine comprehension column hereÔºå you can see just a list of many„ÄÇ

 many different QA data setsÔºå many of which we haven't even discussed so far„ÄÇ

 there's just way too many to go into any level of detail at allÔºå but yeah„ÄÇ

 you can see how this paradigm of leveraging existing label data sets can be useful because of the sheer volume of these dataset sets„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_30.png)

OkayÔºå so computer vision research has in these kinds of ways been ahead of NLP„ÄÇ

 you know it was of course ahead on the whole deep learning thing„ÄÇ

 which you know the first advances were really in computer vision with convolutional nets and then shifted over to NLP with recurrent neural networks a couple years later„ÄÇ

 but in computer visionÔºå we also have a bunch of different tasks that are basically leveraging the same core architecture of a convolutional neural network that's been pretrained on the imageNe data set„ÄÇ

And there's this paperÔºå which was assigned as optional reading called Taonomy„ÄÇ

 It'd actually won a best paper award at CVPRÔºå which is one of the or I guess the top computer vision conference„ÄÇ

 which showed that you can learn these relationships between tasks to maximize your performance of a target task„ÄÇ

 So in this exampleÔºå it's showing that„ÄÇüòäÔºåHaving a model that's kind of fine tuned for this task of„ÄÇ

 I guess detecting surface normals and also detecting 3D edges benefits these other tasks like reshading or point matching„ÄÇ

So we wouldÔºå we would like to do that for NLP as well„ÄÇOkayÔºå as an aside„ÄÇ

 I haven't seen any questions in a while„ÄÇI will assume that no one has had a question„ÄÇ

 but if that persistsÔºå then maybe I'll refresh„ÄÇOkayÔºå so in this paper„ÄÇ

 they had 26 different computer vision tasksÔºå and these wereÔºå you know„ÄÇ

 roughly in different classes of like 2D modeling versus 3D modelingÔºå focusing on like segmentation„ÄÇ

 etc cetera„ÄÇ and they were able to discover these kinds of task relationships„ÄÇüòä„ÄÇ

So we would like to do the same thing for NLP and one approach that we could use is to embed each task in our know vast collection of tasks in a low dimensional space similar to how we've thought of embedding words or sentences or documents„ÄÇ

 we can also think about just embedding an entire data set„ÄÇSo what does this actually mean„ÄÇ

 I'm going to get a single vector that represents a particular task„ÄÇ

And I would hope that the vector space is kind of interpretable in that if I look at the nearest neighbors of any given tasks representation in this vector space„ÄÇ

 I get tasks that are related either in terms of the kinds of reasoning that's required to solve them or maybe the size of the data set or the domain„ÄÇ

 you knowÔºå all those properties that we discussed before„ÄÇ

So people have looked at this before they've looked atÔºå for example„ÄÇ

 in the context of sequence labeling tasksÔºå so these are things like part of speech tagging„ÄÇ

 I have a sentence and I want to predict the part of speech for each of the words in that sentence there are other sequence labeling tasks like named entity recognition„ÄÇ

 So I have a sentence and I want to for every word in the sentence„ÄÇ

 annotate is an entity or not at a high level„ÄÇ So all these tasks follow the same format I'm making a single prediction at every token of the input and you can show that some tasks benefit others more„ÄÇ

 but some tasks have more benefits for a particular downstream task than others This work„ÄÇ

 this binle and sogar work was looking at this in the context of multitask learning so with the different weights for each task„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_32.png)

OkayÔºå so you can imagine a very simple approach here being if I am provided a description of a task„ÄÇ

 So we looked at this hereÔºå right for this taskÔºå M NLI I have a paragraph describing this task„ÄÇ

 rightÔºü So one kind of interesting wayÔºå I could go about getting a task embedding for this task is to pass this description of the task into Bt and then take„ÄÇ

 you knowÔºå it CLS vector or an average„ÄÇüòä„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_34.png)

OkayÔºå sorry about that„ÄÇ It looked like my„ÄÇInternet just disconnected there„ÄÇÂóØ„ÄÇOkay„ÄÇ

I think its it's workingÔºå but I will wait for a message before continuing„ÄÇOkayÔºå great„ÄÇ

 it's working now„ÄÇYesÔºå so I was saying that we might want to have a clearly formatted and consistent format for this description across different tasks and one way you could think about doing this as for every paper that's associated with a particular data like maybe extract its abstract or introduction or something and embed those and BM„ÄÇ

 you have a task embedding spaceÔºå but no one has actually tried thisÔºå it's unclear if first of all„ÄÇ

 there are embedding methods like BerRT that can learn useful representations of descriptions of highly specialized technical data and second„ÄÇ

 it's not clear that the description of a task is the best way of representation it because this ignores a lot of interesting information about the data set itself it could potentially„ÄÇ

üòäÔºåIgnore the size of the data set or even more low level information like„ÄÇ

What parameters in BRT are kind of specialized when you do the fine tuning process to„ÄÇ

 to solve this task versus what parameters are left unchanged„ÄÇ

 So there's a lot of useful information going on in the fine tuning process that we might want to encode here„ÄÇ

okayÔºå so a question for comparing sorry for comparing the task embeddings„ÄÇ

 note these tasks need to be embedded in the same way like by using the same technique„ÄÇ YesÔºå yes„ÄÇ

 so here in this simple approach that we're not going to explore any further„ÄÇ we for every task„ÄÇ

 have a paragraph long description of the task and we pass it through Bt like the pretrain burnt model to get a single representation of it„ÄÇ

 But yeahÔºå this way is undesirable for for all of those reasons„ÄÇ

 So we might want a method that distills this task embedding from the actual fine tuning process itself„ÄÇ

üòäÔºåOkayÔºå so in particularÔºå I can use some information about the gradients of the model during the fine tuning process to get some information about the task itself so here in our pretraining setup right we have our base network„ÄÇ

 which in the case of NLP is Bt in the case of computer vision is the imagenet CNN„ÄÇ

 and then we have our task specific classifier layer which you know for S is the start and end predictors for sentiment its just the single softmax to predict positive and negative or so on„ÄÇ

üòäÔºåSo we could do this without fine tuning by simply passing our entire data set like whichever one we want to get a task embedding for through this network and then kind of measuring the gradients during the backpro phase and what that means sorry in more specifically is what actually do we want to extract from this process so if you read the second paper that was assigned on task embeddings we were using the empirical fissure information matrix which at a high level is measuring how important or how much the loss changes when I change a particular parameter„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_36.png)

And so in BtÔºå I have so many parametersÔºå rightÔºå I have 24 layers„ÄÇ

 Each layer has you know the query key value projections„ÄÇ

 It has a feed forward layer we have our embeddings our token embeddingsÔºå we have our softm layer„ÄÇ

 So we have a ton of parameters and we can calculate this fiser information matrix to tell us which of these parameters impact the downstream predictions the most intuitively„ÄÇ

 So we're not going to get into too many more of the details here„ÄÇ

 but just imagine you can extract that kind of information for all of the different types of parameters in the Bt model right So for every single feed forward layer or every single query key value projection during the fine tuning process which ones of these result in are changed in the most during the fine tuning process from what they were„ÄÇ

üòäÔºåIn their in the pre trained BRT representation„ÄÇSo again„ÄÇ

 there's even within the each transformer blockÔºå there are many different feed forward layers„ÄÇ

 the query key value projections„ÄÇ so we have lots of different parameters here„ÄÇ

 and using the fiser information matrix we can get and we can even do some sort of dimensionality reduction on this at the end of the day to make it smaller or you know some sort of averaging whatever„ÄÇ

 but we will use this technique to basically get some information from each of Bts different layers and we're going to aggregate all those things into a single embedding„ÄÇ

 So this is the first stage„ÄÇüòä„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_38.png)

And then the second stage is we can now do this for a bunch of different other tasks in our task library„ÄÇ

 So this could be like hundreds of different tasks„ÄÇ

 So here let's say I have some input task it gets associated with this red dot here„ÄÇ

 and then I have all these other tasks in my embedding space„ÄÇ

 Now I'm just going to look at the task that's closest to this one in the task embedding space„ÄÇ

 So it turns out to be this wki hopop data setÔºå which I guess is some sort of multihop QA data„ÄÇüòä„ÄÇ

And so now I'm just going to proceed with intermediate fine tuning„ÄÇ

 Now that I've identified the single task that's the closest in this task embedding space to the one that I care about„ÄÇ

 I'm going fine tune Bert on Wiki Hop„ÄÇüòäÔºåAnd then I'm going to fine tune the resulting model on my target task„ÄÇ

 So we're essentially using these task embeddings as a way to figure out which of the all of the existing tasks should I select for intermediate fine tuning„ÄÇ

And what I've described at a very high level is just one way in which you can embed a task„ÄÇ

 there are many others that haven't yet been exploredÔºå so you know„ÄÇ

 potential side projects for anyone who's interested„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_40.png)

So in the paper there is this plot of here's 33 different tasks that are divided into three different classes„ÄÇ

 so the red tasks here are classification tasksÔºå the blue ones are QA tasks and the green ones are sequence labeling tasks„ÄÇ

And so the modelÔºå you knowÔºå the task embeddingsÔºå they have no idea of what type of task a particular task is right the only thing that is taken into account when computing the task embeddings are the information about the gradients So it's pretty cool to see that the model can learn in this nearest neighbor space that you know all the red tasks„ÄÇ

 the classification ones are pretty close together„ÄÇ

 also like between different instances of the same classÔºå like MNLI and SnLI„ÄÇ

 these are both textual entailment dataÔºå so they have a strong connection between them also you see like these two part of speech tag datasets are fairly close to each other and there are also some interesting cases of classification task like this coA data being kind of closer to sequence labeling„ÄÇ

üòäÔºåDaets they are„ÄÇ than it is to maybe some of the other classification data sets„ÄÇ

 So both intuitive and unintuitive results when youÔºå when you look at this„ÄÇ

So I wanted to conclude with just looking at one of the figures in this paper to maybe make the point more clear that we're not„ÄÇ

 we're still a little unsure why a particular task helps another one„ÄÇAnd so in this plot here„ÄÇ

 we have on the X axis the target downstream task„ÄÇAnd so this is the task that we actually care about and this is called a violin plot so each of these columns here„ÄÇ

 each dot inside one of these violins represents the performance on the test set of the associated target task when we fine tuned with a particular intermediate task so each dot represents different intermediate task so let's zoom in and see what kinds of results we or what kinds of intuitions we can take away from this„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_42.png)

So these blue tasks here are all classification dataset sets„ÄÇ

 And it turns out kind of weirdly that the best intermediate tasks for many of these classification data sets are actually QA tasks„ÄÇ

 So here these orange dots are when we do intermediate fine tuning with a question answering dataset set„ÄÇ

 So this could be squad or multi sorryÔºå hotpot QA or news QA or something like that„ÄÇ

 And you can see that the other the blue dotsÔºå the ones that correspond to other classification tasks are below these orange dots„ÄÇ

 This black line corresponds to what happens when you do no intermediate fine tuning at all„ÄÇ

 So for this particular taskÔºå SSBÔºå which measures how similar are two sentences to each other semantically„ÄÇ

üòäÔºåWe see that without any sort of intermediate fine tuningÔºå we get around 30% or so„ÄÇ But when we„ÄÇ

Fine tune with these purple intermediate tasksÔºå which are associated with sequence labeling tasks„ÄÇ

 Our performance actually drops below this baseline„ÄÇ

 So this is just emphasizing that some of these intermediate tasks actually hurt the downstream performance„ÄÇ

 So you have to be careful„ÄÇ this is not a method that always works„ÄÇ but on the other hand„ÄÇ

 doing intermediate fine tuning with other tasks like this one result in huge gains„ÄÇ

 So here we have a gain of we get up to like 60 or 70 on this„ÄÇ I forget what the actual metric is„ÄÇ

 I don't think it's accuracyÔºå but maybe it is„ÄÇüòäÔºåSo there's a lot of room for improvement and this set of experiments has controlled for things like the data size of both the intermediate and the downstream tasks„ÄÇ

 so they all have the same number of fine tuning examples and this is also in a low data setting so assuming that you don't have that many labeled data points„ÄÇ

üòäÔºåYeahÔºå so the star here represents the task that is chosen by the task embedding„ÄÇ

 so you can see that here the task embedding method„ÄÇ

 the closest task in the space does give you some boost over the baseline but it's very far away from the best task right and that kind of makes sense right because for this particular task STSB„ÄÇ

 the QA datas are not as closely tied to that as some of these other classification tasks„ÄÇ

 so there's still a lot of work that needs to be done and a lot of room for improvement to you know take full advantage of the other labeled data sets„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_44.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_45.png)

So when we look at the QA dataset setsÔºå so these are the orange target tasks hereÔºå the top one here„ÄÇ

 the best tasks that improve the most with intermediate fine tuningÔºå are other QA dataset sets„ÄÇ

 so here at least the results are more intuitive and we see that again using the sequence labeling tasks„ÄÇ

 the purple ones hurt youÔºå they drop you below the baseline„ÄÇSo these are some„ÄÇ

 basically the takeaway here is that we don't really know anything about why a particular task is helpful„ÄÇ

And the models are predicting things that are kind of intuitive so far„ÄÇ

 like QA data sets are close to other QA datas„ÄÇ But for some of these unintuitive cases„ÄÇ

 it's very hard to figure out why a particular task is so useful one very interesting thing here is that I mentioned for all of these QA tasks that other QA tasks tend to be most helpful„ÄÇ

 except for this one task drop where the most helpful tasks by far were sequence labeling tasks„ÄÇ Oh„ÄÇ

 I see there's a question about this„ÄÇ YesÔºå so this is a good question why why are these sequence labeling tasks helpful only for drop and they actually hurt for most other data sets„ÄÇ

üòä„ÄÇ

![](img/e996e93a8a3b5c4ef30008591fbba5d8_47.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_48.png)

![](img/e996e93a8a3b5c4ef30008591fbba5d8_49.png)

We have tried to understand this but have failed so far„ÄÇThe reason that is given in this question„ÄÇ

 perhaps because it was created to be adversarial„ÄÇYeah„ÄÇ

 we're not really sure how that ties into sequence labeling tasks being much„ÄÇ

 much better than having no intermediate fine tuning at all„ÄÇSo yeah„ÄÇ

 it's kind of an unknown at this point„ÄÇ And you can see also that the star here„ÄÇ

 the task embedding model selects a task that does even worse than the baseline for drop„ÄÇ So yeah„ÄÇ

 it's it's prettyÔºå pretty strange„ÄÇOkay but overall„ÄÇ

 just some high levelvel takeaways are these plots make it clear that for most tasks for basically every task„ÄÇ

 there is some intermediate task that will boost the performance compared to just the standard pretrain and then fine tune on your downstream data„ÄÇ

 we have some idea of methods that we can use to predict what the intermediate task should be„ÄÇ

 but they're not perfect and in some cases they might actually be worse than not doing any intermediate fine tuning at all like in this particular case„ÄÇ

 but for those of you who are using models like BRT in your final project and you have relatively small downstream datas„ÄÇ

 which I assume is many of you who are resource constrain and are only using collab or something like that you might want to check check out some of these or just doing some sort of intermediate„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_51.png)

Tuning isn a possibly easy way to improve your results„ÄÇÂóØ„ÄÇOkay„ÄÇSo„ÄÇRightÔºå oh„ÄÇ

 I see I missed a question„ÄÇ Are we intuitively looking at how close the parameters are to the maximum likelihood estimates yeah„ÄÇ

 so intuitively like we're looking at how basically for any two tasks when we get these aggregated task embeddings„ÄÇ

 their embeddings will be similar if the same parameters were changed most in the fine tuning process within the base BRT model from the pretrain model„ÄÇ

 So I guess that's kind of the intuitionÔºå although it's a little hard to extend to the case where you know we have all these different layers and we're doing some sort of aggregation over them„ÄÇ

 But yeahÔºå that's the high level ideaÔºå at least but I think as these results should show this is not a perfect method or maybe even the best way to do this and we probably will see many better methods„ÄÇ



![](img/e996e93a8a3b5c4ef30008591fbba5d8_53.png)

s over the next year„ÄÇ So it's a veryÔºå very new thing„ÄÇOh„ÄÇ

 another thing I should mention before concluding this lecture is that and maybe something to think about is whether this idea of doing intermediate fine tuning will even be required in the future when we get bigger and bigger pretrain models right so if I have a Bt that's been pretrained on say1 trillion words instead of 3 billion words„ÄÇ

üòäÔºåMaybe a lot of this room for improvement that we see with these intermediate tasks goes away and the use of actual explicit labeled data sets becomes lower and lower So that is a plausible direction for research in NLP to proceed well see what happens I there any good open source code based on either the papers„ÄÇ

 yeahÔºå so the homework will contain some cells that you can use to get started So yeah„ÄÇ

 be on the lookout for that„ÄÇ All rightÔºå I'll conclude here next time we'll be talking about different variants of Bt So things like ExcelNe„ÄÇ

 RobertaÔºå Albert and so on that have been proposed that to address some of the limitations of Bt and„ÄÇ

üòä„ÄÇ