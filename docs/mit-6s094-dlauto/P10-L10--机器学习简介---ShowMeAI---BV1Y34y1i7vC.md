# P10ÔºöL10- Êú∫Âô®Â≠¶‰π†ÁÆÄ‰ªã - ShowMeAI - BV1Y34y1i7vC

The video you're watching now is in 360 resolution is not great„ÄÇ

 but we wanted to try something different„ÄÇSo if you're on a desktop or laptop„ÄÇ

 you can pen around with your mouseÔºå or if you're in a phone or tablet„ÄÇ

 you should be able to just move your device to look around Of course it's best viewed with a VR headset„ÄÇ

The video that follows is a guest lecture on machine learning that I gave an MIT Sloan course on the business of artificial intelligence„ÄÇ

The lecture is non technical and intended to build intuition about these ideas amongst the business students in the audience„ÄÇ

The room was a half circleÔºå so we thoughtÔºå why not film the lecture in 360Ôºü

We recorded a screencast of the slides and pasted it into the video so that the slides are more crisp„ÄÇ

Let me know what you think and remember it's an experiment„ÄÇSo this course is talking about„ÄÇ

The broad contextÔºå the impact of artificial intelligenceÔºå the globalÔºå there's global„ÄÇ

 which is the global impact of artificial intelligenceÔºå This is the business„ÄÇ

 which is when you have to take these fun research ideas that I'll talk about today„ÄÇ

 A lot of them are cool ontoy examples„ÄÇ when you bring them to realityÔºå you face real challenges„ÄÇ

 which is what I would like to really highlight today„ÄÇüòä„ÄÇ

That's the business part when you want to make real impact„ÄÇ

 when you're going to make these technologies a reality„ÄÇ

 So I'll talk about how amazing the technology is for a nerd like me„ÄÇ

 but also talk about how when you take that into the real worldÔºå what are the challenges you face„ÄÇ

 So machine learning„ÄÇWhich is the technology at the core of artificial intelligence„ÄÇ

We will talk about the promise„ÄÇThe excitement that I feel about it„ÄÇ

 the limitations will bring it down a little bit„ÄÇ What are the real capabilities of the technology„ÄÇ

We for the first time„ÄÇReallyÔºå as a civilizationÔºå exploring the meaning of intelligence„ÄÇIt is„ÄÇ

 if you pause for a second and just thinkÔºå you know„ÄÇ

 maybe if many of you want to make money out of this technologyÔºå many of you want to save lives„ÄÇ

 help peopleÔºå but also on the philosophical levelÔºå we get to explore what makes us human„ÄÇ

 So while I'll talk about the lowle technologiesÔºå also think about the incredible opportunity here„ÄÇ

 we get to almost psychoanalyze ourselves by trying to build versions of ourselves in the machine„ÄÇ

All rightÔºå so here's the open question„ÄÇHow powerful is artificial intelligence„ÄÇ

 How powerful is machine learning that lies at the core of artificial intelligence„ÄÇ

 Is it simply a helpful toolÔºå a special purpose tool to help you solve simple problems if you're which is what it currently is„ÄÇ

CurrentlyÔºå machine learningÔºå artificial intelligence is a way if you can formally define the problem„ÄÇ

 you can formally define the tools you're working with„ÄÇ

 you can formally define the utility function where you want to achieve those tools„ÄÇ

 as long as you can define those thingsÔºå we can come up with algorithms that can solve them„ÄÇ

 as long as you have the right kind of dataÔºå which is what I'll talk aboutÔºå data is key„ÄÇ

And the question is„ÄÇInto the future„ÄÇCan we break past this very narrow definition of what machine learning can give us„ÄÇ

 which is solve specific problems„ÄÇTo something bigger„ÄÇ

 to where we approach the general intelligence as we exhibit as human beings When we're born„ÄÇ

 we know nothing and we learn quickly from very little data„ÄÇThe right answer„ÄÇAs we don't know„ÄÇ

 we don't know what are the limitations of the technology„ÄÇWhat kind of machine learning are thereÔºü

They're several flavors„ÄÇ The first two is what's really the first is what's achieved success today„ÄÇ

 superupvised learning„ÄÇ what I'm showing here on the left of the slide is the teachers is the data that is fed to the system and on the right is the students„ÄÇ

 which is the system itself for machine learning„ÄÇSo theres supervised learning when everybody talks about machine learning today„ÄÇ

 for the most partÔºå they're referring to supervised learning„ÄÇ

 which means every single piece of data that is used to train the model is seen by human eyes and those human eyes„ÄÇ

With an accompanying brainÔºå label that data„ÄÇIn a way that makes it useful to the machine„ÄÇ This is„ÄÇ

 this is critical because that's oneÔºå the blue boxÔºå the human is really costly„ÄÇ

 So whenever every single piece of data that needs to be that's used to train the machine needs to be seen by a human„ÄÇ

 you need to pay for that human„ÄÇAnd secondÔºå you're limited to just the time„ÄÇ

s the amount of data necessary to label what it means to exist in this world is humongous„ÄÇAugmented„ÄÇ

 supervised learning is when you get machine to really to help you a little bit„ÄÇ

 There's a few tricks thereÔºå but still still only tricks„ÄÇ It's still the human is at the core of it„ÄÇ

 And the promise„ÄÇOf future research that we're pursuing that I'm pursuing and perhaps in the applications if we get to discuss or some of the speakers here get to discuss they're pursuing in semisupervised and reinforcement learning„ÄÇ

 where the human starts to play a smaller and smaller role in how much they get to annotate„ÄÇ

 they have to annotate the data„ÄÇAnd the dream of the sort of wizards of the dark arts of deep learning are all excited about unsupervised learning„ÄÇ

 that has very few actual successes in application in the real world today„ÄÇ But it is„ÄÇüòä„ÄÇ

The idea that you can build a machine that doesn't require a human teacher„ÄÇ

A human being to teach you anything„ÄÇIs fills us„ÄÇArtificial intelligence researchers with excitement„ÄÇ

There's a theme here„ÄÇMachine learning is really simple„ÄÇThe learning system in the middle„ÄÇ

There's a training stage where you teach it something„ÄÇ All you need is some data„ÄÇInput data„ÄÇ

And you need to teach it„ÄÇThe correct output for that input data„ÄÇSo you have to have a lot of„ÄÇ

Pearairs of input data and correct output„ÄÇThere'll be a theme of cats throughout this presentation„ÄÇ

 So if you want to teach us a system„ÄÇDifference between a cat and a dog„ÄÇ

 You need a lot of images of cats„ÄÇ And you need to tell it that this is a cat„ÄÇ

This bonding box here and the image is a cat„ÄÇYou have to give it a lot of images of dogs and tell it„ÄÇ

 okayÔºå wellÔºå this in thisÔºå in these picturesÔºå there are dogs„ÄÇAnd thenÔºå thenÔºå there's a„ÄÇ

Sppell only mistake on the second stage is the testing stage„ÄÇ

When you actually give it new input data as never seen before„ÄÇ

And you hope that it has given for cab versus dog enough data to guess„ÄÇ

 is this new image that I've never seen before„ÄÇA cat or a dog„ÄÇNow„ÄÇ

 one of the open questions you want to keep in mind„ÄÇIs what in this worldÔºü

Can we not model in this wayÔºå What activityÔºå what taskÔºå what goal„ÄÇMy„ÄÇ

 I offer to you that there's nothing you can't model in this way„ÄÇSoÔºå let's think about„ÄÇWhat„ÄÇ

In terms of machine learning„ÄÇCan be„ÄÇSo it starts small„ÄÇ What could be modeled in this way„ÄÇ

First on the bottom of the slide left is one to one mapping where the input is an image of a cat and the output is a label that says cat or dog„ÄÇ

You can also do one to many where the image„ÄÇThe input is an image of a cat„ÄÇ

 and the output is a story about that cat„ÄÇA captioning of the image„ÄÇYou canÔºå first of all„ÄÇ

 you can do it the other wayÔºå many to one mapping„ÄÇWhere you give it a story about a cat„ÄÇ

 and it generates an image„ÄÇThere's many to manyÔºå this is Google Translate„ÄÇ

 we translate a sentence from one language to another„ÄÇAnd there's various flavors of that„ÄÇ again„ÄÇ

 same theme hereÔºå input data„ÄÇProvided with correct output„ÄÇ and then„ÄÇ

Let it go into the wild where it runs on„ÄÇInput data hasn't seen before to provide guesses„ÄÇ

And it's as simple as this„ÄÇ whatever you can convert into one of the following four thingsÔºå numbers„ÄÇ

Vectctor of numbers„ÄÇ So a bunch of numbers„ÄÇA sequence of numbers where the temporal dynamics matters„ÄÇ

 So like audioÔºå video or the sequenceÔºå the ordering matters or a sequence of vector numbers„ÄÇ

 Just a bunch of numbers„ÄÇ If you can convert it into numbers„ÄÇ

And I propose to you that there's nothing you can't convert into numbers„ÄÇÂëÉ„ÄÇ

If you can converge numbersÔºå you can have a system learn to do it„ÄÇ

 And the same thing with the outputÔºå generate numbersÔºå vectors and numbers„ÄÇ

 sequence of numbers or sequence of vectors and numbers„ÄÇFirstÔºå is there any questions at this pointÔºü

WeÔºå we have a lot of fun slides to get through„ÄÇBut I'll pause every once in a while to make sure we're on the same page here„ÄÇ

 So what kind of input are we talking about just to fly through itÔºå images„ÄÇ

 So faces or medical applications for looking looking at scans of different parts of the body to determine if to diagnose any kind of medical conditions„ÄÇ

 textÔºå So conversationsÔºå your textsÔºå article blog posts for sentiment analysis„ÄÇ

 question and answeringÔºå So you ask it a question where the output you hope is answers„ÄÇ

 sounds of voice recognitionÔºå any kind of anything you could tell from audio„ÄÇTime series data„ÄÇ

 So financial dataÔºå stock marketÔºå can use it to predict„ÄÇAnything you want about the stock market„ÄÇ

 including whether to buy or sell„ÄÇIf you're curiousÔºå it doesn't work quite well„ÄÇ

As a machine learning application„ÄÇPhysical worldÔºå So cars or any kind of object„ÄÇ

 any kind of robot that exists in this world„ÄÇ So location of where I am„ÄÇ

A location of where other things areÔºå the actions of others that could be all input„ÄÇ

 all of it can be converted to numbers„ÄÇAnd the correct outputÔºå same thingÔºå classification„ÄÇ

 a bunch of numbers„ÄÇ classification is saying is this a cat or a dog„ÄÇ

 regressionion is saying to what degree I turn a steering wheel sequenceÔºå generating audio„ÄÇ

 generating videoÔºå generating storiesÔºå captioningÔºå textÔºå images„ÄÇ

 generating anything you could think of as numbers„ÄÇ

 And at the core of it is a bunch of data agnostic„ÄÇMachine learning algorithms„ÄÇ

There's traditional ones near neighbors na Bay support„ÄÇSupport vector machines„ÄÇA lot of them„ÄÇOur„ÄÇ

LimitedÔºå and I'll describe how„ÄÇ and then there's neural networks„ÄÇ

There's nothing special and new about neural networks„ÄÇ And I'll describe„ÄÇ

Exactly the very subtle thing that is„ÄÇPowerfulÔºå that's always been there all along„ÄÇ

 And certain things have now been able to unlock that power about neural networks„ÄÇ

 But it's still just the flavor of a machine learning algorithm„ÄÇ

And the inspiration from neural networksÔºå as Jonathan showed last time„ÄÇ

 is our human brain is perhaps why the mediaÔºå perhaps why the hype„ÄÇ

Is captivated by the idea of neural networks is because you immediately jump to this feeling like because there's this mysterious structure to them that scientists don't understand artificial neural networks I'm referring to„ÄÇ

And the biological onesÔºå we don't understand themÔºå And the similarity„ÄÇ

Capttivates our minds and we thinkÔºå well„ÄÇThis approach is perhaps as limited as our as limitless as our own human mind„ÄÇ

But the comparison ends there„ÄÇIn factÔºå artificial neuron„ÄÇ there are artificial neural networks„ÄÇ

Are much simpler computational units at the core of everything„ÄÇIs this neuron„ÄÇ

This is a computational unit„ÄÇThat does„ÄÇA veryÔºå twoÔºå very simple operations on the left side„ÄÇ

 it takes„ÄÇA set of numbers as inputs„ÄÇIt applies weights to those inputs„ÄÇSums them together„ÄÇ

Applies a little bias„ÄÇAnd provides an output„ÄÇSomewhere between0 and one„ÄÇ

So you can think of it as a computational entity„ÄÇThat gets excited when it sees certain inputs„ÄÇ

And gets totally turned off when it gets other kinds of inputs„ÄÇ So maybe this neuron„ÄÇWith a with  a „ÄÇ

7„ÄÇ6Ôºå1„ÄÇ4 weights„ÄÇIt gets really excited when it sees pictures of cats„ÄÇ

And totally doesn't care about dogs„ÄÇSome of us are like that„ÄÇSo that's the job of this neuron„ÄÇ

It to detect cats„ÄÇNowÔºå whatÔºå the way you build„ÄÇAn artificial neural network„ÄÇ

 the way you release the power that I'll talk about in the following slides about the applications of what could be achieved„ÄÇ

Is just stacking a bunch of these together„ÄÇThink about it„ÄÇËøô‰∫ãÂÆû„ÄÇBut this is a extremely simple„ÄÇ

 computational unit„ÄÇThere so you need to sort of pause whenever we talk about the following slides and think„ÄÇ

That„ÄÇThereÔºå there's a few slides that I'll show that say neural networks are amazing„ÄÇ

I want you to think back to this slide„ÄÇThat everything is built on top of these really simple addition operations with a simple nonlinear function applied at the end„ÄÇ

Just a tiny math operation„ÄÇWe stacked them together in a feed forward way„ÄÇ

 So there's a bunch of layers„ÄÇ And when people talk about deep neural networks„ÄÇ

 it means there's a bunch of those layers„ÄÇAnd then there's re neural networks that are also a special flavor that's able to have memory„ÄÇ

üòäÔºåSo as opposed to just pushing input into output directly„ÄÇ

 It's also able to do stuff on the inside in a loop where it remembers things„ÄÇ

 This is useful for natural language processingÔºå for audio processingÔºå whenever the sequence is„ÄÇ

Not the length of the sequence is not defined„ÄÇOkayÔºå slide number oneÔºå in terms of neural networks„ÄÇ

 they are amazing„ÄÇThis isÔºå this is perhaps for the math nerds„ÄÇBut also„ÄÇ

 I want you to use your imagination„ÄÇ there's a universality to neural networks„ÄÇ

 means that this simple computational unit on the left is an input on the right is the output of this network„ÄÇ

With just a single hidden layerÔºå it's called a hidden layer because it sits there in the middle of the input and the output layers„ÄÇ

A single hidden layer„ÄÇWith some number of nodes„ÄÇCan represent any function„ÄÇAny function„ÄÇThat means„ÄÇ

Anything you want to build in this worldÔºå Everyone in this room„ÄÇCan be represented„ÄÇ

With a neural network with a single hidden layer„ÄÇSo the powerÔºå and this is just one he layer„ÄÇ

 The power of these things is limitless„ÄÇ The problemÔºå of course„ÄÇIs how do you find the networkÔºü

So how do you build a network that as as clever as many of the people in this room„ÄÇ

 But the fact that that you can„ÄÇBuild such a network is incredible„ÄÇ It is amazing„ÄÇ

 I want you to think about that„ÄÇAnd the way you train a networkÔºå so„ÄÇIt's born as a blank slate„ÄÇ

 some random weights assigned to the edges„ÄÇ AgainÔºå a network is represented the numbers at the core„ÄÇ

 the parameters at the core of this network are the numbers on each of those arrows„ÄÇ

 each of those edges„ÄÇAnd you start knowing nothing„ÄÇ This is a baby network„ÄÇ

And the way you teach it something„ÄÇUnfortunatelyÔºå currentlyÔºå as I said„ÄÇ

 in a supervised learning mechanismÔºå you have to give it pairs of input and output„ÄÇ

 You have to give it pictures of cats„ÄÇAnd labels on those picturesÔºå saying that they're cats„ÄÇ

And the basic fundamental operation of learning„ÄÇIs when„ÄÇYou compute„ÄÇThe measure of an error„ÄÇ

And you back propagate it to the network„ÄÇ What I mean„ÄÇEverything's easier with cats„ÄÇ I apologize„ÄÇ

Apo to many cats„ÄÇAnd„ÄÇSo the input here is a cat„ÄÇ and the neural network we trained„ÄÇ

 It's just guessing„ÄÇ It doesn't know„ÄÇ It's likeÔºå I don't know„ÄÇI guessing cat„ÄÇWell„ÄÇ

 it happens to be right„ÄÇ So we have toÔºå this is the measure of error„ÄÇ YesÔºå you got it right„ÄÇ

 And you have to back propagate that error„ÄÇYou have to reward the network for doing a good job„ÄÇ

And all you doÔºå what I mean by reward„ÄÇ There's weights on each of those edges„ÄÇ

 And so the node that individual neurons that were responsible that back to that cat neuron„ÄÇ

 that cat neuron needs to be rewarded for seeing the cat„ÄÇ

So you just increase the weights on the neurons that were associated with producing the correct answer„ÄÇ

Now you give it a picture of a dog and the neural networkss his cat„ÄÇWellÔºå that's an incorrect answer„ÄÇ

 So noÔºå there's a high error needs to be back propagated to the network„ÄÇ

 So the weights they're responsible with classifying this this picture as a cat need to be punished„ÄÇ

 They need to be decreased„ÄÇËÇæ‰øù„ÄÇAnd you just repeat this process over and over„ÄÇ

 It's just what we do as kids when we're first learningÔºå and you knowÔºå for the most part„ÄÇ

 that we have twoÔºå we're also supervised learning machines in the sense that we have our parents„ÄÇ

And we have the environmentÔºå the world that teaches about what's correct and what's incorrect„ÄÇ

And we back propagate this error and reward through our brain to learn„ÄÇThe problem is„ÄÇ

As human beingsÔºå we don't need too many examples„ÄÇ And I'll talk about some of the drawbacks of these approaches„ÄÇ

 We don't need too many examples„ÄÇ You fall off your bike once or twice„ÄÇ

 and you learn how to ride the bike„ÄÇ Unfortunately„ÄÇ

 neural networks need tens of thousands of times when they fall off the bike in order to learn how to not do it„ÄÇ

 That's one of the limitations„ÄÇAnd one key thing I didn't mention here„ÄÇ

Is when we refer to the input data„ÄÇIt's„ÄÇWhen we refer to input data„ÄÇ

 we usually refer to sensory dataÔºå raw data„ÄÇ We have to represent that data in some clever way„ÄÇ

In some deeply clever way„ÄÇWhere we can reason about it„ÄÇ

Whether it's in our brains or in the neural network„ÄÇAnd a very simple example here„ÄÇ

To illustrate why representation of data matters„ÄÇSo the way you represent the data can make the discrimination of one class from another„ÄÇ

 a cat versus dogÔºå either incredibly difficult or incredibly simple„ÄÇ

 Here is a visualization of the same kind of data in Cartesian coordinates and p coordinates„ÄÇ

On the rightÔºå you can just draw a simple line to separate the two„ÄÇ

What you want is a system that's able to learn„ÄÇThe polar coordinate representation versus the Cartesian representation automatically„ÄÇ

And this is where deep learning has stepped in„ÄÇAnd revealed the incredible power of this approach„ÄÇ

Which„ÄÇDeep learning is the smallest circle there„ÄÇIs a type of representational learning„ÄÇ

Machine learning is the biggerÔºå second to the biggest„ÄÇ So this class is about the biggest circle„ÄÇ

 AI includes robotics includes all the fun things that are built on learning„ÄÇ And I'll discuss while„ÄÇ

 machine learningÔºå I think will close this entire circle into one„ÄÇ But for now„ÄÇ

 AI is the biggest circle than the subset of that is machine learning and a smaller subset of that is representation learning„ÄÇ

So deep learning is not only able to sayÔºå given a few examples of cats and dogs that discriminate between a cat and a dog„ÄÇ

It's able to represent what it means to be a cat„ÄÇIt's so it's able to automatically determine„ÄÇ

What are the fundamental units„ÄÇAt the low level and the high levelÔºå talking about this very Plato„ÄÇ

 what it means to represent a cat from the whiskers to the high level shape of the head to the fuzziness and the deformable aspects of the cat„ÄÇ

 not a cat expertÔºå but I hear these are the features of a cat versus that are essential to discriminate between a cat and a dog„ÄÇ

Learning those features as opposed to having to have experts„ÄÇ

 This is the drawback of systems that Jonathan talked about from the 80s and 90s where you had to bring in experts for any specific domain that you try to solve„ÄÇ

You had to have them encode that information„ÄÇ Deep learning„ÄÇ This is This is simply the only„ÄÇ

Big difference between deep learning and other methods is that it learns the representation for you„ÄÇ

 It learns what it means to be a cat„ÄÇ Nobody has to step in and help it figure out what that cats have whiskers and dogs don't„ÄÇ

What does this meanÔºå The fact that you can learn these featuresÔºå these whisker features is„ÄÇ

As opposed to having5 or 10 or 100 or 500 features„ÄÇ

 that are encoded by brilliant engineers with PhDs„ÄÇIt can find hundreds of thousands„ÄÇ

 millions of featuresÔºå automatically„ÄÇHundreds of millions of features„ÄÇ So stuff that„ÄÇ

That can't be put into words it described„ÄÇ In fact„ÄÇ

 it's one of the limitations in neural networks is they find so many fundamental things about what it means to be a cat that you can't visualize what it really knows„ÄÇ

 It just seems to know stuff„ÄÇAnd it finds that stuff automatically„ÄÇ WhatÔºå what does this mean„ÄÇ

 It's the critical thing here is because it's able to automatically learn those hundreds of millions of features„ÄÇ

 it's able to utilize data„ÄÇIt doesn't startÔºå the diminishing returns„ÄÇ

Don't hit on until what we don't know when they hit„ÄÇ The point is„ÄÇ

 with the classical machine learning algorithmsÔºå you start hitting a wall when you have tens of thousands of images of cats with deep learning„ÄÇ

 you get better and better with more data„ÄÇNeural networkss an amazing slide too„ÄÇHere's a game„ÄÇ

 a simple arcade gameÔºå where there's two paddlesÔºå balancing a ball back and forth„ÄÇOkayÔºå great„ÄÇ

 You can figure out an artificial intelligence agent that can play this game„ÄÇ It can„ÄÇ

 not even that well„ÄÇ just kind ofÔºå it kind of learns to do all right and eventually win„ÄÇ

Here's the fascinating thing„ÄÇWith deep learning„ÄÇAs opposed to encoding„ÄÇThe position of the paddles„ÄÇ

 the position of the ballÔºå having an expert in this game„ÄÇ

There many come in and encode the physics of this game„ÄÇ

The input to the neural network is the raw pixels of the game„ÄÇSo„ÄÇIt's learning in the following way„ÄÇ

You give it an evolution of the game„ÄÇ You give it a bunch of pixels„ÄÇ Pels are„ÄÇ

 images that built up of pixels„ÄÇ They are just numbers from 0 to 2Ôºå56„ÄÇ

So there's this array of numbers that represent each image„ÄÇ

 and then you give it several tens of thousands of images that represent a game„ÄÇ

 So you have this stack of pixels and stack of images that represent a game and the only thing you know„ÄÇ

 this giant stack of numbersÔºå the only thing you know is at the end you won or lost„ÄÇThat's it„ÄÇ

So based on that„ÄÇYou have to figure out how to play the game„ÄÇ You know nothing about games„ÄÇ

 You know nothing about colors or balls or paddles or winning or anything„ÄÇThat's it„ÄÇ So this is„ÄÇ

 why is this amazing that it even works and works It wins„ÄÇ

 It's amazing because that's exactly what we do as human beings„ÄÇ This is general intelligence„ÄÇüòä„ÄÇ

So I need you to pause and think about this„ÄÇWe'llÔºå we'll talk about special intelligence and the usefulness„ÄÇ

 And it's okayÔºå there's cool tricks here and there that we can do to get you an edge on your high frequency trading system„ÄÇ

 But this is general intelligence„ÄÇGeneral intelligence is the same intelligence we use as babies when we're born„ÄÇ

 What we get is an input sensory input of image sensory input right now„ÄÇ All of us„ÄÇ

 most of us are seeing„ÄÇHearing„ÄÇFeeling with touch„ÄÇ And that's the only input we get„ÄÇ We know nothing„ÄÇ

 And with that inputÔºå we have to learn something„ÄÇNobody is pre teaching us stuff„ÄÇ

 And this is an example of thatÔºå a trivial example„ÄÇ

 But one of the first examples where this is truly working„ÄÇ I sorry to linger on this„ÄÇ

 but it's a fundamental fact„ÄÇThe fact that we have systems that and now outperform human beings in these simple arcade games is incredible„ÄÇ

 This is the research side of things„ÄÇüòäÔºåBut let me step back„ÄÇ These againÔºå the takeaways„ÄÇ

That previous slide is why I think machine learning is limitless„ÄÇIn the future„ÄÇCurrently„ÄÇ

 it's limited„ÄÇAgainÔºå the representation of the data matters„ÄÇAnd if you want to have impact„ÄÇ

We currently can only tackle the small problems„ÄÇWhat are those problemsÔºüImage recognition„ÄÇ

 we can classify given the entire image of a leopard of a boat„ÄÇOf a might„ÄÇWith pretty good accuracy„ÄÇ

Of what's in that image„ÄÇ That's image classification„ÄÇWhat elseÔºü

We can find exactly where in that image each individual object is„ÄÇ That's called image segmentation„ÄÇ

AgainÔºå the process is the same„ÄÇThe learning system in the middleÔºå a neural network„ÄÇ

As long as you give it a set of numbers as input„ÄÇAnd the correct set of labels is output„ÄÇ

 it learns to do that for data hasn't seen the best„ÄÇ

Let me pause a second and maybe if you have any questions„ÄÇ

 does anyone have any questions about the techniques of neural networksÔºüYes„ÄÇÂØπÁöÑ„ÄÇM the two„ÄÇÂÖ≥„ÄÇSo„ÄÇ

That's a great question„ÄÇ And in a couple of slidesÔºå I'll get to it exactly„ÄÇ

 So the data representation„ÄÇI'll elaborate in a little bitÔºå but loosely„ÄÇ

 the data representation is for a neural network„ÄÇIs in the weights„ÄÇOf„ÄÇ

Each of those arrows that connect the neurons„ÄÇ That's where the representation is„ÄÇSo Ill„ÄÇ

 I'll show to really clarify that example of„ÄÇWhat that means„ÄÇ

The Cartesian versus polar coordinates is just a visual very simple„ÄÇViization of the concept„ÄÇ

But you want to be able to represent the data in an arbitrary way„ÄÇ

Where there's no limits to their representationÔºå it can be highly nonlinearÔºå highly complex„ÄÇ

Any other questions„ÄÇS agree„ÄÇGenerally speaking„ÄÇIt' simply„ÄÇ

Statistical models that are able to recognize training„ÄÇ

Things of that nature where they're not necessarily thinking„ÄÇBut simply recognize„ÄÇ

And so I'm a little confused about„ÄÇThe current„ÄÇSystem differs from„ÄÇAnd whether you think that„ÄÇ

I is the possibility of transitionÔºüSo'm actually thinking„ÄÇ

So I have a couple of slides almost asking this question because there's no good answers„ÄÇ

 but one could argue„ÄÇ And I think somebody in last class broughted up thatÔºå you know„ÄÇ

 is machine learning just pattern recognition„ÄÇÂëÉ„ÄÇIt's possible that reasoningÔºå thinking„ÄÇÂïä„ÄÇIs just„ÄÇ

Pattern recognition„ÄÇAnd I'll describe„ÄÇSort of an intuition behind that„ÄÇ

So we tend to respect thinking a lot„ÄÇBecause we've recentlyÔºå as human beings learned to do it„ÄÇ

In our evolutionary time„ÄÇWe think that it's somehow special fromÔºå for exampleÔºå perception„ÄÇ

 We've had visual perception for several orders of magnitude longer in our evolution in evolution as„ÄÇ

 as a living species„ÄÇWe've started to learn to reasonÔºå I thinkÔºå about 100000 years ago„ÄÇ

So we think it's somehow special from the same kind of mechanism we use for seeing things„ÄÇ

Perhaps it's exactly the same thing so perception is pattern recognition„ÄÇ

 perhaps reasoning is just a few more layers of that„ÄÇThat's the hope„ÄÇ but it's an open question„ÄÇYes„ÄÇ

„Ç≥„É≥„Çª„É≥„Éà„ÅÆ„Éã„É•„Éº„Éã„É•„Éº„Ç¢„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÄÇ„Åù„ÅØ„ÄÇ‰∏Ä ÏûàÏñ¥Ïïº„ÇÑÂ∫ó„Å´„ÄÇÂ§â„Åã„Ç§„Éé„Éô„Éº„Ç∑„Éß„É≥„ÄÇjust aÔºüThe result„ÄÇYesÔºå that's a great question„ÄÇ

There's been very few breakthroughs in neural networks since through the AI winters that we've discussed„ÄÇ

Through a lot of excitement„ÄÇIn spurtsÔºå and even recently there's been a very few algorithmic innovations„ÄÇ

The big gains came from computeÔºå some improvements in GPU and better faster computers„ÄÇ

You can't underestimate the power of community„ÄÇ So the ability to share code and the Internet„ÄÇ

Ability to communicate together through the internet and work on code together and then digitization of data„ÄÇ

 so like ability to have large data sets easily accessible and downloadable„ÄÇ

All of those little things„ÄÇ But I think itÔºå in terms of the future of deep learning and machine learning„ÄÇ

 itÔºå it all rides on computeÔºå I thinkÔºå meaning continuedÔºå bigger and faster computers„ÄÇ

That doesn't necessarily mean Moore's law in making small and smaller chips„ÄÇ

 It means getting clever in different directionsÔºå massive parallelization coming up with ways to do super efficient power efficient implementations in neural networks and so on„ÄÇ

SoÔºå let me if„ÄÇFly through a few examples of what we can do with machine learning just to give you a flavor I think in future lectures as possible„ÄÇ

 we'll discuss different speakersÔºå different specific applications really dig into those so we can as opposed to working with just images you can work with videos and segment those I mentioned image segmentation„ÄÇ

 we do video segmentationÔºå though through video segment„ÄÇ

 the different parts of a scene that's useful to a particular application here and drive you can segment the road from cars and vegetation„ÄÇ

And lane markingsÔºå you can also„ÄÇThis is a subtle but important point yesÔºå go back that one slide„ÄÇ

How do you see the light„ÄÇ I mean that's such a critical piece ofÔºå you know„ÄÇ

 the more I listen to you and read your stuff„ÄÇ It seems like this critical these„ÄÇ

 these very small piece of information that we justÔºå we know are important like there is a red light„ÄÇ

well the light I have to stopÔºå I have to slow downÔºå how does it filter that out and pick out thatÔºü

So this„ÄÇüòÄ„ÄÇOhÔºå hard questionÔºå so„ÄÇÂëÉÂëÉ„ÄÇThe question wasÔºå how do you detect the traffic lightÔºüAnd lights„ÄÇ

So how do we do as human beingsÔºüFirst of allÔºå let's start there„ÄÇ The way we do it is by„ÄÇ

The knowledge were bring through the table„ÄÇSo we know what it means to be on the road„ÄÇ

 there's a lot of the huge network of knowledge that you come with„ÄÇ

 and so that makes the perception problem much easier„ÄÇ This is pure perception„ÄÇ

 You take an image and you separate different parts based purely on tiny patterns of pixels„ÄÇ

So first defines all the edges„ÄÇAnd it learns that traffic lights have certain kinds of edges around them and then zoom out a little bit„ÄÇ

 they have a certain collection of edges that make up this black rectangle type shape so it's all about shapes it kind of build up knowing this shape structure of things„ÄÇ

 but it's a purely perception problem and one of the things I argue is that if it's purely a perception approach and you bring no knowledge to the table about the physics of the world„ÄÇ

 the three dimensionmenional physics and the temporal dynamics that youre not going to be able to successfully achieve„ÄÇ

Near 100% accuracy on some of these systems„ÄÇSo that's exactly the right question„ÄÇ

You for all of these thingsÔºå think about how you as a human being would solve these problems and what is lacking in the machine learning approach„ÄÇ

 what data is lacking in the machine learning approach in order to achieve the same kind of results„ÄÇ

The same kind of reason it required that you were used as a human„ÄÇSo there is also image detection„ÄÇ

Iage detectionÔºå which means it's a subtle but important point„ÄÇ

 the stuff I mentioned before image classification is given a image of a cat you find the cat sorry you don't find the cat„ÄÇ

 you say this image is of a cat or notÔºå and then detection or localization is when you actually find where in the image that is„ÄÇ

 That problem is much harder but also doable with machine learning„ÄÇ

With with deep neural networks nowÔºå as I saidÔºå inputsÔºå outputs can be anything„ÄÇ

 the input can be a videoÔºå the output can be video„ÄÇ

 and you can do anything you want with these videos„ÄÇ you can colorize the video„ÄÇ

 You can add take an old black and white film and produce color images„ÄÇAgain„ÄÇ

 in terms of having an impact in the world using these applicationsÔºå you have to think„ÄÇ

This is a cool demonstrationÔºå but how well does it actually work in the real world„ÄÇTranslation„ÄÇ

 whether that's from text to text or image to imageÔºå you can translate hereÔºå dark chocolate„ÄÇ

From one language to another„ÄÇIt's class global business of artificial intelligence„ÄÇ

 There's a reference below there„ÄÇ You can go and generate your own text„ÄÇ

 You can generate the writing of the act of generating handwriting„ÄÇ

 So you can type in some text and given different styles that it learns from other handwriting samples„ÄÇ

 It can generate any kind of text using handwriting again„ÄÇThe input is language„ÄÇ

 the output is a sequence of writing„ÄÇOf pen movements on the screen„ÄÇ You can complete sentences„ÄÇ

This is kind of a fun oneÔºå where if you start„ÄÇSo you can generate language and you can generate a language where you start„ÄÇ

 you feed the system some input firstÔºå so in black there says life is„ÄÇ

And then have the neural network complete those sentences„ÄÇLife is about kids„ÄÇ

 Life about life is about the weather„ÄÇ There's a lot of knowledge here„ÄÇ I think being conveyed„ÄÇ

 And you can start the sense what the meaning of life is„ÄÇThe meaning of life is literary recognition„ÄÇ

True for usÔºå academics or the meaning of life is the tradition of ancient human production„ÄÇAlso true„ÄÇ

But these are all generated by a computer„ÄÇ You can also caption„ÄÇ

 This has been become very popular recently is caption generation„ÄÇ given us input is an image„ÄÇ

 The output is a set of text„ÄÇ that captions the content of the image„ÄÇ

 you find the different objects in the in the imageÔºå that's a perception problem„ÄÇ

 And once you find the different objects„ÄÇ You stitch them together in a sentence that makes sense„ÄÇ

 You generate a bunch of sentences and classify which sentence is the most likely to fit this this image„ÄÇ

And you can so certainly in the„ÄÇI try to avoid mentioning too driving too much because it is my field„ÄÇ

 That is what I'm excited aboutÔºå but„ÄÇThen the moment I started talking about driving„ÄÇ

 it'll all be about driving„ÄÇ SoÔºå but I should mentionÔºå of course„ÄÇ

 that deep learning is critical to driving applications for the both the perception and what is really exciting to us now is the end to end„ÄÇ

 the end to end approach„ÄÇ So whenever you say end to end in any applicationÔºå what that means„ÄÇ

Is you start from the very raw inputs that the system gets and you produce the very final output that's expected of the system„ÄÇ

 So as opposed to in the cell driving car caseÔºå as opposed to breaking a car down into each individual components of perception„ÄÇ

 localizationÔºå mappingÔºå control planning and just taking the whole stack and just ignoring all the„ÄÇ

Super complex problems in the middleÔºå just taking the external scene as input and as output produce steering and acceleration and breaking commands„ÄÇ

 And so in this wayÔºå taking this input is the image of the external world„ÄÇ In this caseÔºå in a Tesla„ÄÇ

 we can generate steering commands for the car„ÄÇ Again„ÄÇ

 input a bunch of numbers that that's just imagesÔºå output„ÄÇ

A single number that gives you the steering of the„ÄÇOf the car„ÄÇOkay„ÄÇ

 so let's step back for a second and think about what can't we do with machine learning„ÄÇ We talked„ÄÇ

 we talked aboutÔºå you can map numbers to numbers„ÄÇ Let's think about what we can't do This at the core of artificial intelligence in terms of making an impact on this world is robotics„ÄÇ

So what can't we solve in robotics and artificial intelligence with a machine learning approach„ÄÇ

And let's break down what artificial intelligence means„ÄÇ

 here's a stack starting at the very top is the environmentÔºå the world that you operate in„ÄÇ

 there's sensors that sense that worldÔºå there is feature extraction and learning from that data and there's some reasoning„ÄÇ

 planning and effectors are the ways you manipulate the world„ÄÇWhat can't we learn in this wayÔºü

So we've had a lot of success as Jonathan talked about in the history of AI with formal tasks„ÄÇ

 playing gamesÔºå solving puzzlesÔºå recently we're having a lot of breakthroughs with medical diagnosis„ÄÇ

We're still„ÄÇSorry„ÄÇWe're still„ÄÇStrugglingÔºå but are very excited about in the robotic space with more mundane tasks of walking„ÄÇ

 of basic perception of natural languageÔºå written and spoken„ÄÇAnd then there is the human tasks„ÄÇ

Which are perhaps completely out of reach of this pipeline at the moment„ÄÇIs„ÄÇCognition„ÄÇImagination„ÄÇ

SjectÔºå subjective experience„ÄÇ So high level reasoningÔºå not just common senseÔºå but high level„ÄÇ

Human level reasoning„ÄÇSo let's fly through this pipeline„ÄÇ There's sensorsÔºå camerasÔºå Lidar„ÄÇAudio„ÄÇ

There's communication„ÄÇThat flies the air or wired or wireless or wired„ÄÇ

 I am you measuring the movement of things„ÄÇSo that's the way you think about it„ÄÇ

 That's the way as human beings„ÄÇ And as any kind of system that you designÔºå you measure the world„ÄÇ

 You don't just get an API to the world„ÄÇ You need to somehow measure aspects of this world„ÄÇ

So that's how you get the data„ÄÇ So that's how you convert the world into data you can play with„ÄÇ

 And once you have the dataÔºå this is the representation side„ÄÇ

 you have to convert that raw data of raw pixelsÔºå a raw audioÔºå raw LiDarR data„ÄÇ

 you have to convert that into data that's useful for the intelligence system for the learning system to use the discriminate between one thing and another„ÄÇ

For visionÔºå that's finding edgesÔºå cornersÔºå object parts and entire objects„ÄÇ

 And there's the machine learning that I' talk that I've talked about„ÄÇ

There's different kinds of mapping of the representation that you've learned to an actual outputs„ÄÇ

There is once you have this„ÄÇ So you have this idea of„ÄÇ

 and this goes to maybe a little bit of Simon's question is reasoning„ÄÇ

 This is something that's out of reach and machine learning at the moment„ÄÇ

 This is going to your question„ÄÇThen we canÔºå we can build a world class machine learning system for taking an image and classifying that it's a duck„ÄÇ

I wonderder if this will work„ÄÇÂïäÂóØÂóØÂïä„ÄÇWake you up„ÄÇSo we could takeÔºå this is well studied„ÄÇ

 exceptionally well studied problem„ÄÇ We could take audio sample„ÄÇOf a duck and tell that it's a duck„ÄÇ

In factÔºå what species of bird„ÄÇIt's incredible how much research there is in bird species classification„ÄÇ

 And we can look at videoÔºå and we could tell that we can do actual recognition that it's swimming„ÄÇüòä„ÄÇ

But we can't do with learning now is reason„ÄÇThat if it looks like a duck„ÄÇ

 it swims like a duck and quacks like a duckÔºå it's very likely to be a duck„ÄÇ

This is the reasoning problem„ÄÇ This is the task that I personally am obsessed with and that I hope that machine learning can close„ÄÇ

And then there is the planning action and the effectors„ÄÇSo this is another place where„ÄÇ

Machine learning has not had many stridesÔºå there's mechanical issues here that are incredibly difficult„ÄÇ

 the degrees of freedom with all the auators involved with all the just the ability to localize every party yourself in this dynamic space„ÄÇ

Where things are constantly changing when there's degrees of uncertaintyÔºå when there's noise„ÄÇ

 just that basic problem is exceptionally difficult„ÄÇSo let me just pose this question„ÄÇ

 We talked about how machineÔºå what machine learning can do with the cats and the duck„ÄÇ

We could do that„ÄÇ given a representationÔºå it could predict what's in the image„ÄÇ

But one of the open questions is„ÄÇAnd deep learning has been able to do the feature extraction„ÄÇ

 the representation learning„ÄÇ This is the big breakthrough that everybody' is excited about„ÄÇ

But can it also reasonÔºüThese are the open questions„ÄÇ Can a reason„ÄÇCan it do the planning and action„ÄÇ

And as human beings doÔºå can you close the loop entirely„ÄÇFrom sensors to effectors„ÄÇ

 So learn not only the brain„ÄÇBut„ÄÇThe way you sense the world„ÄÇAnd the way you affect the world„ÄÇP game„ÄÇ

 so essentially does a real network„ÄÇSo the question was about the pawn gameÔºå thank you„ÄÇ

talk to it for a little longer„ÄÇIt it doesn't get punished when it doesn't detect the ball„ÄÇ

 This is the beautiful thing„ÄÇIt gets punished only at the very end of the game for losing the game and gets rewarded for winning the game„ÄÇ

 So it knows nothing about that ball„ÄÇAnd it learns about that ball„ÄÇ

That's something you really sit and think about„ÄÇBecause like how do as human beings„ÄÇ

 imagine if you're playing with a physical ballÔºå how do you learn what a ball is„ÄÇYou„ÄÇ

 you get hurt by it„ÄÇ You like squeeze itÔºå you throw itÔºå You feel the dynamics of it„ÄÇ

 the physics of itÔºå and„ÄÇNobody tells you about what a ball is„ÄÇ

 You're just using the raw sensory input„ÄÇ We take it for granted„ÄÇ And maybe this is what I can end„ÄÇ

On„ÄÇIsÔºå this is what something Jonathan brought up„ÄÇAs we take the simplicity of this task for granted„ÄÇ

Because we've been„ÄÇWe've had eyes„ÄÇWe broadly speaking as living species on planet Earth„ÄÇ

 these eyes have been evolved for 540 million years„ÄÇ So we have 540 million years of data„ÄÇ

 We've been walking for close to that„ÄÇBippedo mammals„ÄÇWe have been thinking only very recently„ÄÇ

 So 100000 years versus 100 million years„ÄÇAnd„ÄÇThat's why we can't some of these problems that we're trying to solve„ÄÇ

 You can't take for granted how actually difficult they are„ÄÇ SoÔºå for example„ÄÇ

This is the Marvex paradox„ÄÇ that Jonathan Bart up is that the easy problems are hard„ÄÇ

 The things would think are easyÔºå actually really hard„ÄÇ This is state of the art robot on the right„ÄÇ

 playing soccer„ÄÇAnd that was a state of the art human on the leftÔºå playing soccer„ÄÇAnd„ÄÇYeah„ÄÇüòä„ÄÇ

I'll give it a second„ÄÇThe question wasÔºå you knowÔºå there's a fundamental difference between the way we' trained neural networks and the way we've trained biological neural networks to revolution by discarding through natural selection„ÄÇ

 a bunch of„ÄÇThe neural networks that didn't work so well„ÄÇThat'sÔºå so first of all„ÄÇ

 the process of evolution is„ÄÇI thinkÔºå not well understood„ÄÇmeaning sorryÔºå the role I careful here„ÄÇ

 the role of evolution in the evolution of our cognition„ÄÇOf our intelligence„ÄÇI don't know if that's„ÄÇ

 So this is an open question„ÄÇ So maybe clarify this point is neural networks„ÄÇ

Artificial neural networks are fixedÔºå for the most partÔºå In size„ÄÇ This is exactly right„ÄÇ

 It's like a single human being that gets to learn„ÄÇ We don't have mechanisms of„ÄÇ

Of modifying or revolving those neural networks yet„ÄÇ

Although you could think of researchers as doing exactly that„ÄÇ

 you have grad students working on different neural networks and the ones that don't do a good job„ÄÇ

 don't get promoted and get a good„ÄÇ You knowÔºå there is a natural selection there„ÄÇ

 But other than thatÔºå it'sÔºå it's an open question„ÄÇ It's a fascinating oneÔºå y„ÄÇ

So Lea is going to come backÔºå It's not not available next week„ÄÇ

 but he's going to come back the week after„ÄÇ so we can pick up many of these points here„ÄÇ

 many of points can continue„ÄÇ Is there any last final„ÄÇTakeaway you want„ÄÇ

Stay tuned and keep your head up because the futureÔºå I believeÔºå is really promising„ÄÇ

And the slides will be„ÄÇmade available for sure„ÄÇ so we' take five minute break„ÄÇ

I think a lot of the explorations of what it means to build an intelligent machine has been in Scifi movies„ÄÇ

 we're not beginning to actually make it a reality„ÄÇ

 this is space Odyssey to keep with that theme in the previous lecture that we had„ÄÇThis is„ÄÇ

 as opposed to the dreamlike monolith viewÔºå when the astronaut is gazing out into the open sky at the stars„ÄÇ

 we're going to look at the practice of AI today„ÄÇAnd how we goÔºå if you're familiar with the movie„ÄÇ

 when this new technology appeared before our eyesÔºå and we're full of excitement„ÄÇ

 how we transfer that into actualÔºåPractical impact on our lives„ÄÇ

To quickly review what we talked about last time„ÄÇI presented the technology and asked the question of whether this technology merely serves a special purpose to answer specific tasks that can be formalized or whether it can be through„ÄÇ

Through the process of transferring the knowledge learned on one domain„ÄÇ

 be generalizable to where an intelligent system that's trained in a small domain can be used to achieve general intelligent tasks like we do as human beings„ÄÇ

 this is kind of the stack of artificial intelligence of going from all the way up into the top of the environment„ÄÇ

 the worldÔºå the sensors sets of dataÔºå the intelligence systemÔºå the way it perceives this world„ÄÇ

 then once you have you convert the world into some numbers„ÄÇ

 you able to extract some representation of that world„ÄÇ

 And this is where machine learning starts to come into play„ÄÇ

 And then there's the part where I will raise it again today is can machine learning be doing the following steps too that we can do very well as human beings is the reasoning step„ÄÇ

 you know you can tell the difference in a cat and a dog„ÄÇ

 but can you now start to reason about what it means to be alive„ÄÇ

 what it means to be a cat with living creature and what it means to be this kind of physical object or this kind of physical object and take„ÄÇ

It's called common sense things we take for granted start to construct models of the world through reasoning„ÄÇ

DescartesÔºå I think therefore I amÔºå we want our neural networks to come up with that on their own„ÄÇ

And once you do that„ÄÇActionÔºå you'll go right back into the world and you start acting in that world„ÄÇ

 So the question isÔºå can machine learningÔºå can this be learned from data or does do experts need to encode the knowledge of reasoning the knowledge of actions„ÄÇ

 the set of actionsÔºå That's kind of the questionÔºå the open questions I raise„ÄÇ

 It continues throughout the talk today and„ÄÇSo as we start to think about how artificial intelligence„ÄÇ

 especially machine learning as it re itself through roboticsÔºå gets to impact the world„ÄÇ

 we start thinking about what are the easy problems and what are the hard problems„ÄÇ

 and it seems to us that„ÄÇvision and movementÔºå walking is easy because we've been doing it for millions of years„ÄÇ

 hundreds of millions of years and thinking is hardÔºå reasoning is hard„ÄÇ

 I propose to you that is perhaps because we've only been doing it for a short time and so think we're quite special because we're able to think so we have to kind of question of what is easy and what is hard because when we start to develop some of these systems„ÄÇ

And what you start to realize all of these problems are equally hard„ÄÇ

 So the problem of walking that we take for grantedÔºå the actuation and the physical„ÄÇ

The ability to recognize where you are in the physical space to sense the world around you to deal„ÄÇ

Deal with the uncertainty of the perception problem„ÄÇ And then so all of these robotsÔºå by the way„ÄÇ

 this is for the most recent DARPA challengeÔºå which Mi T was also part of„ÄÇ

And so what are these robots doingÔºüThey they don't have any„ÄÇ

 they only have sparse communication with human beings on the periphery„ÄÇ

 So most of the stuff they have to do autonomouslyÔºå like get inside a car„ÄÇ This is an MIT robot„ÄÇ

 unfortunately„ÄÇThey have to get in the car and the hardest taskÔºå they have to get out of the car„ÄÇ

That's walking„ÄÇ So this kind of raises to you very real„ÄÇAspect here„ÄÇ

 you want to build applications that actually work in the real world„ÄÇ

 and that's the first challenge and opportunity here„ÄÇThe many of the technologies as we talked about„ÄÇ

CurrentlyÔºå crumble under theÔºå the reality„ÄÇOf„ÄÇOur world„ÄÇ

When we transfer them from a small data set in the lab to the real world„ÄÇ

 for the computer vision is perhaps one of the best illustrations of this„ÄÇ

Computer vision is the task because we talked about of interpreting images„ÄÇ And so when you„ÄÇ

 there's been a lot of great accomplishments on interpreting imagesÔºå Cats search as dogs„ÄÇNow„ÄÇ

 when you try to create a system„ÄÇLike the Tesla vehicle that I've often that we work with and I always talk about is it's a vision-based robot as radar for basic obstacle avoidance„ÄÇ

 but most of the understanding of the world comes from a single monocular camera now they've expanded a number of cameras„ÄÇ

 but for the most time there's been 100Ôºå000 vehicles driving on the roads today with a single„ÄÇ

 essentially a single webcam„ÄÇSo when you start to do that„ÄÇ

 you have to perform all of these extraction of textureÔºå color„ÄÇ

 optical flows so the movement through timeÔºå temporal dynamics of the images„ÄÇ

 you have to construct these patternsÔºå construct the understanding of objects and entities and how they interact and from that you have to act in this world„ÄÇ

 and that's all based on this computer vision system so it's no longer cats versus dogs„ÄÇIt's„ÄÇ

It's huge detection of pedestriansÔºå where the wrong„ÄÇClassification„ÄÇ

 the wrong detection is the difference in life and death„ÄÇ

So let's look at cats where things is a little more comfortable„ÄÇSo computer vision„ÄÇ

 and I would like to illustrate to you why this is such a hard task„ÄÇ we talked about„ÄÇ

 we've been doing it for 500 million years„ÄÇ so we think it's easy„ÄÇ

Computer vision is actually incredible„ÄÇ So all you're getting with your human eyes„ÄÇ

 is you're getting essentially pixels inÔºå there's light coming into your eyes and all you're getting is the reflection from the different surfaces in here of light„ÄÇ

 And there's perceptionÔºå there's sensors inside your eyes converting that into numbers„ÄÇ

 It's really very similar to this„ÄÇüòäÔºåNumbers in the case of what we use with computers„ÄÇ

 RGB images were the individual pixels are numbers from0 to 255„ÄÇ

 so 256 possible numbers and there're just a bunch of them„ÄÇ and that's all we get„ÄÇ

 We get a collection of numbers where they're spatially connected ones that are close together are part of the same object„ÄÇ

 So cat pixels are all connected together„ÄÇ That's the only thing we have to help us„ÄÇ

 but the rest of it is just numbersÔºå intensity numbers„ÄÇ

 and we have to use those numbers to classify what's in the image„ÄÇAnd if you really think about it„ÄÇ

 this is a really difficult task„ÄÇ All you get is these numbers„ÄÇ

 How the hack are you supposed to form a model of the world with which you can„ÄÇ

Detect pedestrians with really 99„ÄÇ99999% accuracyÔºå because these pedestrians or these cars„ÄÇ

 a cyclist in the car context or any kind of applications you're looking at„ÄÇ

Even if your job is in the factory floor to detect the defective gummy bears„ÄÇ

 they are flying past at like 100 miles an hourÔºå your task is you don't want that bad gummy bear to get by that your product and the brand will be damaged„ÄÇ

 however serious or not serious your application is„ÄÇWhat you have to be„ÄÇ

 you have to have a computer vision system„ÄÇThat deals with„ÄÇAll of these aspectsÔºå viewpoint variation„ÄÇ

 scale variationÔºå no matter the size of the object is still the same object„ÄÇ

 no matter the viewpoint from which the area you look at that object is still the same object„ÄÇ

 The lighting that movesÔºå we have lighting consistently here because we're indoors„ÄÇ

 when you're outdoors or you're movingÔºå the scene is movingÔºå the lighting„ÄÇ

 the complexity of the lighting variations is incredible„ÄÇüòä„ÄÇ

From the illumination to just the movement of the different„ÄÇObjects in the scene„ÄÇ

Now we've had these conversationsÔºå I think about this every time I drive„ÄÇ

 I think about you and this point and how hard it this to see these things and particularly when I'm driving at night„ÄÇ

 and particularly when it's twilight and the light is changing„ÄÇI think„ÄÇ

 you almost every time I drive is one or two things that I see that are really that I'm drawing on like 200 million years in order to be able to figure out it's it's a guy who's open his car door and I can't see him„ÄÇ

 but I can just see the light doesn't look quite right on that side of the road and I somehow know in my mind it's a person„ÄÇ

But it seems like an almost impossible problem for the machines to get right with sufficient accuracy„ÄÇ

 I will argue that the pure perception task is too hard„ÄÇ

That you come to the table as human beings with all this huge amount of knowledge„ÄÇ

That you're not actually interpreting all the complex lighting variations that you're seeing„ÄÇ

 You actually know enough about the worldÔºå enough about your commute home„ÄÇ

 enough about the way the kinds of things you would see in this world about Boston about the way pedestrians move the certain light of day„ÄÇ

 you bring all that to the table that makes the perception task doable„ÄÇ

 And that's one of the big missing pieces in the technology as I'll talk about„ÄÇ

 that's the open problem of machine learning is how to bring all that knowledgeÔºå first of all„ÄÇ

 build that knowledge and then bring that knowledge to the table„ÄÇ

 as opposed to starting from scratch every time„ÄÇAnd so„ÄÇCatsÔºå I promise cats„ÄÇ OkayÔºå so theÔºå to me„ÄÇ

 occlusion„ÄÇFor most of the computer vision community„ÄÇ

 this is one of the biggest challenges and it really highlights„ÄÇ

How far we are from being able to reason about this worldÔºå Icclusions are whenÔºå what an occlusion is„ÄÇ

 is when the objectsÔºå you're trying to detect something about classify the objectÔºå De the object„ÄÇ

 The object is„ÄÇBlocked partially by another object in front of them„ÄÇ

This is something that you think is trivial perhaps you don't even really think about it because we reason in a threediional way„ÄÇ

 but the occlusion aspect is makes perception incredibly difficult so we have to design think about this so this image is converted into numbers and we for the task of detecting is there a cat in this image yes or no„ÄÇ

 you have to be able to reason about this image with that object in the scene most of us are able to very easily detect that there's a cat in this image„ÄÇ

We're able to detect that there is a cat in this image„ÄÇ NowÔºå think about this„ÄÇ

 there's a single eye and there's an ear„ÄÇSo you have to think about what is it part of our brain that allows us to understand to suppose that with some high degree of accuracy that there's a cat here in this picture„ÄÇ

I meanÔºå the degree of occlusion here is immense„ÄÇAnd so I promise„ÄÇSo this is for most of you„ÄÇÂëÉ„ÄÇ

Some of you will think this isÔºå in factÔºå a monkey eating a banana„ÄÇ

 but I would venture to say that most of us are able to tell it's nevertheless a cat„ÄÇ

You watch this for hours„ÄÇAnd so let me give you another„ÄÇ

 this is kind of a paper that's often cited or a set of papers„ÄÇ

To illustrate how difficult computer vision isÔºå how thin the line that we're walking with all of these impressive results that we've been able to show recently in the machine learning community„ÄÇ

In this case„ÄÇFor deep neural networks are easily fooledÔºå paper„ÄÇ

 the seminal paper at this point shows that when you apply„ÄÇNetwork trained on imagenets„ÄÇ

 so basically on detecting cats versus dogs or different categories inside images„ÄÇ

If you you can find an arbitrary number of images that look like noise up in the top row„ÄÇ

Where the algorithm„ÄÇUsed to classify those images in an image net of cat versus dog is able to confidently say with 99„ÄÇ

6% accuracy or above that it's seeing a robin or a cheetah or an armadillo or a panda in that noise„ÄÇ

So it's confidently saying given this noise that that's obviously a robin„ÄÇ

So you have to realize that„ÄÇThe kind of„ÄÇThis is patterns„ÄÇ

 the kind of processes it's using to understand what's containing the image is purely a collection of patterns that it has been able to extract from other images that has been human annotated by humans„ÄÇ

And that perhaps is very limiting to trying to create a system that's able to operate in the real world„ÄÇ

 This is a very sort of this is very clean illustration of that concept and the same you can confidently predict in those images below where there's strong patterns„ÄÇ

 it's not even noiseÔºå strong patterns that have nothing to do with the entities being detected again„ÄÇ

 confidently that same algorithm is able to see a penguin a starfish or baseball and a guitar in that noise„ÄÇ

And more serious„ÄÇFor people designing robots like myself in on the sensor sideÔºå you can flip that„ÄÇ

And sayÔºå I can take„ÄÇA imageÔºå and I can distort it with some very little amount of noise„ÄÇAnd if that„ÄÇ

If that noise is applied to the imageÔºå I can completely change the confident prediction about what's in that image„ÄÇ

 So to explain what's being shown„ÄÇ So on the left and the column in the left„ÄÇAnd againÔºå here„ÄÇ

the same kind of neural network is able to predict accurately confidently that there is a dog in that image„ÄÇ

 but if we apply just a little bit of noise to that image to produce that image imperceptible to our human eyes the difference between those two„ÄÇ

 the same algorithm is saying that there is confidently an ostrich in that image„ÄÇ

So another thing to really think about that noise can have such a significant impact on the prediction of these algorithms„ÄÇ

 This is really„ÄÇReallyÔºå quite honestlyÔºå out of all the things I'll say today„ÄÇ

 and I'm aware of one of the biggest challenges of„ÄÇ

Machine learning being applied in the real world is robustness„ÄÇ

 How much noise can you add into the system before everything falls apartÔºü

So how do you validate sensorsÔºå so say a car company has to produce a vehicle and it has sensors in that vehicle„ÄÇ

 how do you know that those sensors will not start generating slight noise due to interference of various kinds and because of that noise instead of seeing a pedestrian it will see nothing or the opposite you'll see pedestrians everywhere so of course the most dangerous is when it will not see an object and collide with it in the case of cars„ÄÇ

There's also spoofingÔºå which a lot of people as always with security„ÄÇ

 people are really concerned about„ÄÇAnd perhaps people here are really concerned about this issue„ÄÇ

 I think this is a really important issueÔºå but because you can apply noise and convince the system that you're seeing an ostrich when there's in fact no ostrich„ÄÇ

You can do the same thing in a„ÄÇIn an attacking way„ÄÇ

 So you can attack the sensors of a car and make it believeÔºå like with Lidar spoofing„ÄÇ

 So spoof Lidar or radar or ultrasonic sensors to believe that you're seeing pedestrians when they're not there and the opposite to hide pedestrians make pedestrians invisible to the sensor when they're„ÄÇ

 in fact there„ÄÇSo whenever you have intelligent systems operating in this world„ÄÇ

They become susceptible to the fact that everything„ÄÇ

 so much of the work is done in software and based on sensors„ÄÇ So at any point in the chain„ÄÇ

 if there's a failure„ÄÇYou have to be able to detect that failure„ÄÇ And right now„ÄÇ

 we have no mechanisms for automatically detecting that failure„ÄÇ So on the data side„ÄÇ

 So one challenge is that we're constantly dealing with„ÄÇIs„ÄÇThat we„ÄÇ

Are the algorithms and machine learning algorithms that we're using„ÄÇOur need labeled data„ÄÇ

And we have very little label data„ÄÇ Laed dataÔºå againÔºå is when you have pairs of„ÄÇ

Iput data and the ground truthÔºå the true label annotation class that that image belongs to or concept„ÄÇ

And it doesn't have to be an image you could be any source of data„ÄÇ

 It's a really costly process to do„ÄÇSo„ÄÇBecause it's so costly„ÄÇWe„ÄÇ

Rely every breakthrough we've had so far relies on that label data„ÄÇAnd because of its cost„ÄÇ

 we don't have much of it„ÄÇSo all the problems that come from data can either be solved by having a lot more of this data„ÄÇ

 which I believe is most people believe is too challenging„ÄÇ

 it's too challenging to have human beings annotate huge amounts of data„ÄÇ

Or we have to develop algorithms that are able to do something with the unlabeled data„ÄÇ

It's the unsupervisedÔºå semiupervisedÔºå sparsely supervised reinforcement learning„ÄÇ

 as we talked about last time I'll mention again here„ÄÇ

So one way you understand something about data when you don't have labels is your reason about it„ÄÇ

 All you're given is a few factsÔºå when you're a baby„ÄÇ

 your parents give you a few facts and you go into this world with those facts„ÄÇ

 and you grow your knowledge graphÔºå your knowledge base„ÄÇ

 your understanding of the world from those few facts„ÄÇ

 We don't have a good method of doing that an automated unrestricted way„ÄÇ

The inefficiency of our learnersÔºå the machine learning algorithms haveve talked about the neural networks need a lot of examples of every single concept that they're given in order to learn anything about them„ÄÇ

 thousandshouandÔºå tens of thousands of cats are needed to understand what the spatial patterns at every level„ÄÇ

 the representation of a catÔºå the visual representation of a cat„ÄÇWe don't„ÄÇ

 We can't do anything with a single example„ÄÇ There's a few approachesÔºå but nothing quite„ÄÇRobustÔºå yet„ÄÇ

And„ÄÇWe haven't come up with a way this is also possible„ÄÇTo make annotationÔºå this labeling process„ÄÇ

SomehowÔºå be very cheap„ÄÇSo leveragingÔºå this is something being called human computation„ÄÇ

 that term has fallen out of favor a little bitÔºå one of my big passions is human computation is using something about our behavior„ÄÇ

 something about what we do in this world online or in the real world„ÄÇTo annotate data automatically„ÄÇ

SoÔºå for exampleÔºå as you driveÔºå which is what we do„ÄÇ

 Everybody has to drive and we can collect data about you driving in order to train self driving vehicles to to„ÄÇ

To driveÔºå and that's a free annotation„ÄÇSo here are the annotated data sets we have„ÄÇ

 the supervised learning data sets„ÄÇThere's manyÔºå but these are some of the more famous ones from the Toy dataset sets of MNIS to the large broad arbitrary categories of images„ÄÇ

 data sets and which is what imagenet is and there's in healthcareÔºå there's an audio„ÄÇ

 there's in video know there's a huge number of data sets now„ÄÇ

 but each one of them is usually in the scale of hundreds of thousandsÔºå millionsÔºå tens of millions„ÄÇ

 not billions of trillionsÔºå which is what we need to create systems that operate in the real world„ÄÇ

 and againÔºå these are the kinds of machine learning algorithms we have„ÄÇ There's five listed here„ÄÇ

The teachers on the left is what is„ÄÇWhat is the input to the system that requires to train itÔºü

From the supervised learning at the very top is what we have all of our successes and everything else is where the promise lies„ÄÇ

 the semisupervisedÔºå the reinforcement or the fully unsupervised learning„ÄÇ

 where the input from the human is very minimal„ÄÇ and another way to think about this„ÄÇ

So whenever you think about machine learning todayÔºå whenever somebody talks about machine learning„ÄÇ

 what they're talking about is systemsmize that memorize patterns„ÄÇ

And so this is one of the big criticisms of the current machine learning approaches„ÄÇ

 where all they're doing is you're providing they're only as good as the human annotated data that they're provided„ÄÇ

We don't have mechanisms for actually understanding„ÄÇ

You can pause and think about this in order to create an intelligent system„ÄÇ

 it shouldn't just memorize„ÄÇ it should understand the representations inside that data in order to operate in that world„ÄÇ

And that's the open question„ÄÇOne of them„ÄÇ and one of the challenges and opportunities for machine learning researchers today is„ÄÇ

To extend machine learning from memorization to understandingÔºå this is that duck„ÄÇThe reasoning„ÄÇ

If you get information from the perception systems that it looks like a duck„ÄÇ

 from the audio processingÔºå that it quacks like a duckÔºå and then from video classification„ÄÇ

 that the activity recognition that it swims like a duck„ÄÇ

 the reasoning step is how to connect those facts to then say that it isÔºå in fact a duck„ÄÇOkay„ÄÇ

 so that's on the algorithm side and the data side„ÄÇNow„ÄÇ

 this is one of the reasons compute computational power„ÄÇ

 computational hardware that is at the core of the success of machine learning„ÄÇ

So our algorithms have been the same since the '60s since the 80sÔºå '90s„ÄÇ

 depending on how you're counting„ÄÇThe big breakthroughs came in compute„ÄÇSo there's Moore's law„ÄÇ

Most of you know„ÄÇThe way our the CPU side of our computers works for a single CPU is that it's„ÄÇ

For the most partÔºå executing a single action at a time in a sequence„ÄÇSo sequential„ÄÇ

Very different from our brainÔºå which is massively paralleled system„ÄÇSo because it's sequential„ÄÇ

 the clock speed matters because that's how fast essentially„ÄÇ

 those instructions are able to be executed„ÄÇ And so wherere„ÄÇWe're leveling off physics„ÄÇ

Is stopping us from continuing Moore's lawÔºå so Intel AMD are aggressively pushing this Moore's law forward„ÄÇ

But„ÄÇAnd there's some promise that it'll actually continue for another 10 or 15 years„ÄÇ

Then there's another form of parallelismÔºå massive parallelismÔºå is the GPU„ÄÇ

 and this is essential for neural networks„ÄÇThis is essential to the success„ÄÇ

 recent success of neural networks is the ability to utilize these„ÄÇ

Inherently parallel architectures of graphicsÔºå processing unitsÔºå GPUs„ÄÇ

 the same thing used for video games„ÄÇ this is the reason N V stock is doing extremely well„ÄÇIs„ÄÇ

 is GPs„ÄÇ So it's parallelism of basic computational processes that make machine learning work on the GPU„ÄÇ

One of the limitations of GPUsÔºå one of the challenges is in bringing them to in scaling and bringing them into real world applications is power usage„ÄÇ

It's power consumption„ÄÇAnd so there is a lot of specialized chips„ÄÇ

 specialized just from the neural network architectures coming out from Google with a tensor processing unit from IBM„ÄÇ

 Intel and so on„ÄÇ It's unclear how far this goes„ÄÇ So this is sort of the direction of trying to design an electronic brain„ÄÇ

 so it has the efficiency„ÄÇ Our human brain is exceptionally efficient at running the neural networks in our heads„ÄÇ

Or is of magnitude more efficient than our computers are„ÄÇ

 and this is trying to design systems that are able to go towards that efficiency„ÄÇ

Why do you care about efficiencyÔºüFor several reasonsÔºå oneÔºå of course„ÄÇ

 as I'm sure we'll talk about throughout this classÔºå is about the thing in our smartphones„ÄÇ

 battery usage„ÄÇAnd this is the big one communityÔºå I think„ÄÇ

I think it could be attributed to the big breakthroughs in machine learning recently in the last decade is the„ÄÇ

 you knowÔºå compute is important„ÄÇ Alm development is important„ÄÇBut it's the community of nerds„ÄÇ

 global„ÄÇ This is global artificial intelligence„ÄÇ And I will show in several ways why global is essential here is„ÄÇ

 is tens of„ÄÇüòäÔºåHundreds of thousandsÔºå millions of programmersÔºå mechanical engineers„ÄÇBuilding robots„ÄÇ

 building intelligence systemsÔºå building machine learning algorithms„ÄÇ

 the exciting nature of the growth of the community perhaps is the key for the future to unlocking the power of machine learning„ÄÇ

 So this is just one example„ÄÇ Github is a repository for code„ÄÇ

 And this is showing on the Y axis at the bottom is 2008 when GiHub first opened this is going up to 2012 quick„ÄÇ

 near exponential growth of the number of users participating and the number of repositories„ÄÇ

 So these are standaloneÔºå unique projects that are being hosted on Github„ÄÇ

So this is one example I'll show you about this competition that we're recently running„ÄÇ

 and then I'll challenge people here to participate in this competition if you dare„ÄÇ

 so this is a chance for you to build a neural network in your browser so you can do this on your phone later tonight„ÄÇ

 of course„ÄÇOn your phoneÔºå you can specify various parameters of the neural network„ÄÇ

 specify different numbers of layers and the depthÔºå the depth of the network„ÄÇ

 the number of neurons in the networkÔºå the type of layers„ÄÇ and it'sÔºå it's pretty self explanatory„ÄÇ

 super easy„ÄÇIn terms of just tweaking little things and remember„ÄÇ

 machine learning to a large part is an art at this point„ÄÇ

 it's more perhaps than even more than a well understood theoretically bounded science„ÄÇ

 which is one of the challengesÔºå but it's also an opportunity„ÄÇDeep traffic is a chance„ÄÇ

 so we've all been stuck in traffic„ÄÇ there you goÔºå Americans spend 8 billion hours stuck in traffic every year„ÄÇ

 that's our pitch for this competition„ÄÇSo a deep neural network can help and so you have a neural network that drives that little car with an MIT logo„ÄÇ

 red one on this highway and tries to weave in and out of traffic to get to his destination„ÄÇ

And trying to achieve a speed of 80 miles an hourÔºå which is the speed limit„ÄÇ

 which is this physical speed limit of the car„ÄÇ Of course„ÄÇ

 the actual speed limit of the road is 65 miles an hourÔºå but we don't care about that„ÄÇ

 We just want to get to work as quickly as possible at home„ÄÇ So what„ÄÇ

The basic structure this game is„ÄÇ And I want to explain this game a little bit and then tell you how incredibly popular it's gotten and how incredibly„ÄÇ

PowerfulÔºå the networks that people have built from all all over the world„ÄÇ

 the community that's built on this over a single month is incredible„ÄÇ

 And this happens for thousands of projects out there now„ÄÇAnother challenging opportunity„ÄÇOkay„ÄÇ

 so you may have seen this„ÄÇ This is kind of ethics„ÄÇ

 most engineers most I personally don't like I love love philosophy„ÄÇ

 but this kind of construction of ethics that's often presented here„ÄÇ

 is one that is not usually concerned to engineering„ÄÇ

 So what is this question know when you have a car and you have a bunch of pedestrians do you hit the larger group of pedestrians or the smaller group of pedestrians do you avoid the group of pedestrians put yourself into danger„ÄÇ

 these kinds of ethical questions of an intelligence system„ÄÇ

 It's a very interesting question it's one that we can debate and there's really no good answer quite honestly„ÄÇ

 but it's a problem that both humans and machines struggle with„ÄÇ

 And so it's not interesting on the engineering side„ÄÇ

 We're interested with problems that we can solve on the engineering side„ÄÇ

 So the kind of problem that I'm obsessed with and very interested in is the real worldorl problem of controlling a vehicle through this space So it happens in a few seconds here„ÄÇ

 So is„ÄÇA ManhattanÔºå New York intersectionÔºå rightÔºüThis is pedestrians walking perfectly legally„ÄÇ

 I think they have a green light„ÄÇ Of course there's a lot of jawalking too as well„ÄÇ Well„ÄÇ

 this car just flat it's not part of the pointÔºå but yesÔºå exactly there's an ambulance„ÄÇ

 And so there's another car that starts making a left turn in a little bit„ÄÇ

Me have missed it hopefully not„ÄÇ SoÔºå yeahÔºå And then there's another car after thatÔºå too„ÄÇ

 that just illustrates when you design an algorithm that's supposed to move through the space„ÄÇ

 like watch this carÔºå the aggression it shows„ÄÇ now„ÄÇ

 this isn't a trivial example for those that try to build robots„ÄÇ This isÔºå this is the real question„ÄÇ

 is how do you design a system„ÄÇThat's able„ÄÇ So you have„ÄÇ

 you have to think you have to put reward functionsÔºå objective functions„ÄÇ

 utility functions under which it performs the planning„ÄÇ So a car like that has„ÄÇ

Several thousand candidate trajectories you can take through that intersection„ÄÇ

 It can take a trajectory where it speeds up to 60 miles an hour and doesn't stop and just swves and hits everything„ÄÇ

 OkayÔºå that's a bad trajectoryÔºå right Then there's a trajectory„ÄÇ

 which most companies take which most the Google sell driving car and every company that's is concerned about PR is whenever there's any kind of obstacle any kind of risk that's at all reasonable that you can maybe even touch an obstacle„ÄÇ

 then you're not going to take that trajectory„ÄÇ So if that means is you're going to navigate through this intersection at 10 miles an hour and you let people abuse you but youre walking in front of you because they know you're not going to stop And so in the middle there is hundreds„ÄÇ

 thousands of trajectories that are ethically questionable in the sense that you're putting other human beings at risk in order to safely and successfully navigate through intersection and the design of those objective functions is the kind of question you have to ask for intelligence systems for cars„ÄÇ

 there's no grandma„ÄÇAnd a few children you have to choose who gets to dieÔºå very difficult problems„ÄÇ

 of courseÔºå but the problem of what I'm very interested in in streets of Boston„ÄÇ

 streets of New York is how to gently nudge yourself through a crowd of pedestrians in the way we all actually do when we drive in New York„ÄÇ

In order to be able to safely navigate these environments and these questions come up in healthcare„ÄÇ

 these questions come up in factoryÔºå in robots in armed and humanoid robots that operate with other human beings„ÄÇ

And that's one of the big challenges„ÄÇAnother sort of fun illustration„ÄÇ

That folks that open the eye use often to illustrateÔºå wellÔºå let me just pause for a second„ÄÇ

 the gamified version of thisÔºå there's a game called Co runners and you're racing against other boats along this track and your job is there's your score here at the bottom left„ÄÇ

 number of lapsÔºå your time and you're trying to get to the destination as quickly as possible while also collecting funky little things like these green„ÄÇ

These green little things along the way„ÄÇOkayÔºå so what they've done is the build end systemÔºå the one„ÄÇ

 the general purpose one that we talked about last time that learns oops„ÄÇ

 that learns how to navigate successfully through the space„ÄÇSo you're trying to maximize the reward„ÄÇ

And what this boat learns to do is instead of finishing the race„ÄÇIt learns to find„ÄÇ

A loop where it can keep going around and aroundÔºå collecting those green dots„ÄÇ

And it learns the fact that they regenerate with time„ÄÇSo it learns to maximize this score„ÄÇ

By going around and around„ÄÇNow these are the kinds of things„ÄÇ

 this is the big challenge of reward functions of designing systems„ÄÇ

 of designing what you want your system to achieve is not only is it difficult to the ethical questions are difficult„ÄÇ

 but just avoiding the pitfalls of local Opima of it figuring out something really good that happens in the short term„ÄÇ

 the greedyÔºå whether those psychology experiments of the kid eat the marshmallow and can't wait for you can't delay gratification„ÄÇ

 this kind of the idea of delay gratification in the case of designing intelligence systems is a huge actual serious problem and this is a good illustration of that„ÄÇ

So„ÄÇWe flew through a few concepts here„ÄÇ is there any is there any questions about some of the compute and the algorithm side we talked about today So the question was„ÄÇ

 yeah you highlighted some of the limitations of machine computer vision algorithm„ÄÇ

 machine learning algorithmsÔºå but you haven't highlighted some of the limitations of human beings and if you put those in a column and you compare those is our machines doing better overall„ÄÇ

 or is there any kind of way to compare those I mean there is actually interesting work on imagenet„ÄÇ

 So imagenet is this categorization to ask of what you have to classify images and you can ask the question when I present you images of cats and dogs where are machines better than humans and when are they not so you can compare when machines do better„ÄÇ

 what are the fail points and what are the fail points for humans and there's a lot of interesting visual perception questions there„ÄÇ

 But I think overallÔºå it's certainly true that machines fail differently than human beings but in order to„ÄÇ

Make an artificial intelligence system that's usable and could make you a lot of money„ÄÇ

And people would want to useÔºå it has to be better for that particular task in every single way„ÄÇ

In orderÔºå in order for you to want to use the systemÔºå it has to be„ÄÇ

 it has to be superior to human performance and usually far superior to human performance„ÄÇ

 So so it's on the philosophical levelÔºå It's an interesting thing to compare„ÄÇ What are we good at„ÄÇ

 what or not„ÄÇ But if you're using„ÄÇAmazon EchoÔºå your voice recognition or any kind of natural language chatbots or a car„ÄÇ

 you're not going to beÔºå wellÔºå this car is not so good with pedestrians„ÄÇ

 but I appreciate the fact they can stay in the lane„ÄÇFortunately„ÄÇ

 you have a very high standard for every single thing that you're good at and it has to be superior to that„ÄÇ

 I think maybe that's unfair to the robots„ÄÇI'm more of the nerd that makes the technology happen„ÄÇ

 but it's certainly on the self driving car aspect„ÄÇPolicy is probably the biggest challenge„ÄÇ

And I don't think there's good answers there„ÄÇSome of those ethical questions that come up where it feels like so we work a lot with Tesla so I'm driving a Tesla around every day and we're playing around with it and studying human behavior inside Teslas and it seems like there's so much hunger amongst the media to jump on something and it feels like a very shaky PR terrain„ÄÇ

 a very shaky policy terrain„ÄÇ we're all walking because we have no idea how„ÄÇ

How we coexist with intelligence systems„ÄÇ And soÔºå and thenÔºå of course„ÄÇ

 government is nervous because how do we regulate„ÄÇThis shaky terrain„ÄÇ

 and everybody's nervous and excited„ÄÇSo I'm not sure there's no„ÄÇ

 that's a perfect transition if that's okay„ÄÇ same kind of question to Jason in a moment„ÄÇ

 Thanks a lotÔºå Le for another great session„ÄÇ