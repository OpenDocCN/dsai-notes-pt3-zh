# „ÄêËã±ËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëMIT 6.S094 ÔΩú Ê∑±Â∫¶Â≠¶‰π†‰∏éËá™Âä®È©æÈ©∂(2018¬∑ÂÆåÊï¥Áâà) - P8ÔºöL8- Âæ™ÁéØÁ•ûÁªèÁΩëÁªú‰∏éÊó∂Â∫èÈ©æÈ©∂ÊìçÁ∫µ - ShowMeAI - BV1Y34y1i7vC

All rightÔºå so we've talked about„ÄÇRegular neural networksÔºå fully connected neural networks„ÄÇ

 we've talked about convolutional neural networks that work with images„ÄÇ

 we've talked about reinforcementÔºå deeper reinforcement learning„ÄÇ

 where we plug in a neural network into a reinforcement learning algorithm„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_1.png)

When an agentÔºå when a system has to not only perceive the world„ÄÇ

 but also act in it and collect reward„ÄÇ And todayÔºå we'll talk about„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_3.png)

Perhaps the least understoodÔºå but the most exciting neural network out there„ÄÇ

Blaor of neural network is recurring neural networks„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_5.png)

So firstÔºå administrative stuff„ÄÇThere's a websiteÔºå I don't know if you heard carss„ÄÇmt„ÄÇedu„ÄÇ

 where you should create an account if you're a registered studentÔºå that's one of the requirements„ÄÇ

 you need to have an account if you want to get credit for this„ÄÇ

You need to submit code for Deep traffic JS and deep Tesla JS and for deep traffic„ÄÇ

You have to have a neural network that drives faster than 65 m an hour„ÄÇ

 If you need help to achieve that speedÔºå please email us„ÄÇWe can dropÔºå we can give you some hints„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_7.png)

For those of you who are old school S&L fansÔºå there's the deep thoughts section now in the profile page where we encourage you to talk about the kinds of things youve tried in deep traffic or any of the other deep Tesla or any of the work you've done as part of this class for deep learning„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_9.png)

Okay„ÄÇWe've talked about the the vanilla neural networks on the left„ÄÇ

 The vanilla neural network is the one where it's computing„ÄÇ

 It's approximating a function that maps from one input„ÄÇTo one output„ÄÇ

 an example is mapping images to the number that's shown in the image for imagenet„ÄÇ

 it's mapping an image to what's the object in the image„ÄÇIt could be anything„ÄÇ nowÔºå in fact„ÄÇ

Convolution neural networks can operate on audio„ÄÇ You could give it a chunk of audio„ÄÇ

5 second audio clip„ÄÇ That still counts as one input because it's fixed size„ÄÇ

 as long as the size of the input is fixedÔºå That's one„ÄÇChunk of input„ÄÇ

And as long as you have ground truth that maps that chunk of input to some outputÔºå ground truth„ÄÇ

That's a vanilla neural networkÔºå whether it's a fully connected neural network or a convolutional neural network„ÄÇ

TodayÔºå we'll talk about the amazing„ÄÇThe mysterious recurring neural networks„ÄÇ

They compute functions from one to many„ÄÇFrom many to oneÔºå from many to many„ÄÇAlsoÔºå bidirectional„ÄÇ

What does that meanÔºå they take his input sequences„ÄÇTime seriesÔºå audio„ÄÇVideo„ÄÇ

 whenever there's a sequence of data and that temporal dynamics that connects the data is more important than the spatial„ÄÇ

Content of each individual frame„ÄÇSo when there's a lot of information being conveyed in the sequence„ÄÇ

In in the temporal change of whatever that type of data is„ÄÇ

 that's when you want to use current neural networks„ÄÇLike speechÔºå natural language„ÄÇAudio„ÄÇ

 and the power of this is that for many of them of a current neural network„ÄÇ

 where they really shine is when the size of the input„ÄÇIs variable„ÄÇ So„ÄÇ

 you don't have a fixed chunk of data that you're putting in„ÄÇ It'sÔºå it's variable input„ÄÇ

 and the same goes for the output„ÄÇSo you could give it a sequence of speech„ÄÇ

Several seconds of speech„ÄÇAnd then the output is„ÄÇA single label of whether the speaker is male or female„ÄÇ

That's many to one„ÄÇYou can also do many to many„ÄÇTranslation„ÄÇ

You can have natural language put into the network„ÄÇIn Spanish and the output is in English„ÄÇ

Machine translation„ÄÇ That's many to many„ÄÇAnd that many to many doesn't have to be mapped directly into same size sequences„ÄÇ

So for videoÔºå the sequence size might be the same„ÄÇ You're labeling every single frame„ÄÇ you put in a„ÄÇ

A5 second clip„ÄÇOf somebody playing basketball„ÄÇ and you can label every single frame„ÄÇ

 counting the number of people in every single frame„ÄÇ

 That's many to many when the size of the input sizeÔºå the output is the same„ÄÇYesÔºå question„ÄÇ

The question wasÔºå are there any models where there's feedback from output and input„ÄÇ

 and that's exactly what recurrent neural networks areÔºå is it it produces outputÔºü

And it copies that output and loops it back in„ÄÇThat's exactly„ÄÇ

 that's exactly almost the definition of our current neural network„ÄÇ

 There's a loop in there that produces the output and also takes that output as input once again„ÄÇ

And so there'sÔºå there's also many to many where the sequences don't align like machine translation„ÄÇ

 theÔºå the the size of the output sequence might be totally different than the input sequence„ÄÇ

 We'll look at a lot of cool applicationsÔºå like„ÄÇYou can„ÄÇStart a song„ÄÇ

 so learn on the audio of a particular song and have the re you'll network continue that song after a certain period of time„ÄÇ

 so you can learn to generate sequences of audio of natural language of video„ÄÇO„ÄÇ

I know I promise them many equationsÔºå but this is„ÄÇSo beautifully simple that we have to cover back propagation„ÄÇ

It's also the thing that if you're a little bit lazy and you go on the Internet and start using the basic tutorials for Tensorflow„ÄÇ

 you ignore how back propagation work at your peril„ÄÇYou kind of assume it just works„ÄÇ

 I give us some inputÔºå some outputs„ÄÇ It it's like Lego pieces„ÄÇ that can assemble them„ÄÇ

 like you might have done with deep trafficÔºå a bunch of layersÔºå put them together„ÄÇ and then just„ÄÇ

Press train and back propagation is the mechanism that neural networks currently the best mechanism we know of that is used for training„ÄÇ

 So we need to understand„ÄÇSimple power of back propagationÔºå but also the dangers„ÄÇSummary„ÄÇ

Say I'll put the top of the slideÔºå there's an input to the network as an image„ÄÇ

 there's a bunch of neuronsÔºå all with differentiableÔºå smooth activation functions on each neuron„ÄÇ

And then„ÄÇAs you pass through those activation functions„ÄÇTaking the input„ÄÇ

 pass it through the net of differentiable compute nodes„ÄÇ You produce an output„ÄÇ and that output„ÄÇ

You also have a ground truth that correct the truth„ÄÇThat you hope„ÄÇ

 but you expect the network to produce„ÄÇ And then you can look at the difference between what the network actually produced and what you hope to will produce„ÄÇ

 And that's an error„ÄÇ And then you back or propagate that errorÔºå punishing or rewarding the„ÄÇThe„ÄÇ

 the weightsÔºå the parameters of the network that resulted to in that output„ÄÇ

Let's start with a really simple example„ÄÇThere's a function„ÄÇThat takes his input„ÄÇUp on top„ÄÇ

3 variablesÔºå XÔºå YÔºå and Z„ÄÇThe function does two things„ÄÇ It adds x and Y„ÄÇ

 and then it multiplies that sum by Z„ÄÇAnd then we can formulate that as a circuit„ÄÇCircuit of gates„ÄÇ

Where there's a plus gate and a multiplication gate„ÄÇAnd let's take some inputs shown in blue„ÄÇ

 Let's say x is negative 2„ÄÇ Y is 5„ÄÇ Z is negative 4„ÄÇ

And let's do a forward pass through this circuit to produce the output„ÄÇSo negative 2 plus 5 equals 3„ÄÇ

Q is that intermediate value„ÄÇ3„ÄÇThis is so simple„ÄÇAnd so important to understand that I just want to take my time through this because everything else about neural networks just builds on these concepts„ÄÇ

 right„ÄÇOkayÔºå so the the ad gate produces Q in this case is 3„ÄÇ and then three times negative 4 is 12„ÄÇ

 That's the output„ÄÇ The output of the circuit of this„ÄÇNetworkÔºå if you think of it as such„ÄÇ

 is negative 12„ÄÇAnd so the forward pass is shown in blue„ÄÇ

 The backward pass will be shown in red in a second here„ÄÇ

 So what we want to do is what would make us happy„ÄÇ

 What would make F happy is for the output to be as high as possible„ÄÇüòäÔºåNegative 12 is so„ÄÇ

 so we could do better„ÄÇ So how do we teach it„ÄÇHow do we adjust XÔºå YÔºå and ZÔºü

So said it produces a higher„ÄÇF„ÄÇMakes us happier„ÄÇ OkayÔºå let'sÔºå let's start backward„ÄÇThe backward pass„ÄÇ

We make the gradient on the output oneÔºå meaning we want this to increase„ÄÇ we want F to increase„ÄÇ

 That's how we encode our happiness is we want it to go up by one„ÄÇAnd in order to then propagate„ÄÇ

That function that that fact that we want the F to go up by one„ÄÇ

 we have to look at the gradient on each one of the gates„ÄÇWhat's a gradientÔºüIt's a„ÄÇ

Partial derivative„ÄÇWith respect to its inputs„ÄÇTheÔºå the partial derivative of the output of a gate with respect to its inputs„ÄÇ

If you don't know what that meansÔºå it's just„ÄÇHow much does the output changeÔºü

When I change the inputs a little bitÔºå what is the slope of that change„ÄÇ

 If I increase x for the first function of addition„ÄÇF of xÔºå y equals x plus y„ÄÇ

 if I increase x by a little bitÔºå what happens to FÔºå if I increase y by a little bit„ÄÇ

 what happens to F„ÄÇSo taking a partial derivative of those with respect to X and Y„ÄÇ

 you just get a slope of one„ÄÇ So when you increaseÔºå XÔºå F increases linearlyÔºå same with y„ÄÇ

Mulplication is a little trickier„ÄÇWhen you increase x„ÄÇF increases by y„ÄÇ

So the partial derivative of F„ÄÇWith respect to x is y„ÄÇ

 The partial derivative of F with respect to Y is x„ÄÇSo if you think about itÔºå what happens is„ÄÇ

The gradientsÔºå when you change x„ÄÇThe gradient of change doesn't care about X„ÄÇIt cares about why„ÄÇ

So it's flipped„ÄÇSo we can back propagate that oneÔºå the indication of what makes us happy„ÄÇBackwards„ÄÇ

And thatÔºå that's done by computing the local gradient„ÄÇFor Q„ÄÇ

So the partial derivative F with respect to QÔºå that intermediate value„ÄÇ

That gradient will be negative4„ÄÇ It will take the value of Z„ÄÇ As I saidÔºå it's a multiplication gate„ÄÇ

 It will take the value of Z„ÄÇAnd assign it to the gradient„ÄÇ

And the same for the partial derivative of F with respect to ZÔºå it'll assign that to Q„ÄÇ

 the value of the forward pass from the Q„ÄÇ So there's a 3 and the negative 4 in the forward pass in blue„ÄÇ

 And then that's flippedÔºå negative 4 and 3„ÄÇOn the backward passÔºå that's the gradient„ÄÇ

And then we continue in the same exact process„ÄÇButÔºå wait„ÄÇSo what makes all of this work„ÄÇIs„ÄÇ

 is the chain rule„ÄÇIt's magical„ÄÇSo what it allows us to do is to compute the gradient„ÄÇOkay„ÄÇ

The gradient of an F with respect to the inputsÔºå XÔºå YÔºå ZÔºå we don't need to construct the„ÄÇ

 the giant function„ÄÇ that is the„ÄÇThe partial derivative of F with respect to X and Y and Z„ÄÇ

AlyticallyÔºå we can do it step by stepÔºå back propagating the gradients„ÄÇ

 We can multiply the gradients together as opposed to doing partial derivative of F with respect to X„ÄÇ

 We have just the intermediateÔºå the local gradient of F with respect to Q and of Q with respect to X and multiply them together„ÄÇ

So instead of computing the gradient of the that giant function x plus y equals time Z„ÄÇ In this case„ÄÇ

 it's not that giantÔºå but it gets pretty giant when neural networksÔºå we just go step by step„ÄÇ

 look at the first functionÔºå simple additionÔºå Q equals x plus y„ÄÇ and the second function„ÄÇ

 multiplicationÔºå F equals Q times Z„ÄÇSo„ÄÇThe gradient on x„ÄÇAnd why„ÄÇThe partial derivative„ÄÇ

Of F with respect to X and Y is computed by multiplying the gradient on the outputÔºå negative 4„ÄÇ

Times the gradient and the inputsÔºå whichÔºå as we talked about when it's„ÄÇ

 when the operation is additionÔºå that's just one„ÄÇ So it's negative four times 1„ÄÇThat means„ÄÇ

What does that meanÔºå Let's interpret those numbers„ÄÇYou now have gradients on XÔºå YÔºå and Z„ÄÇ

The gradient of the partial derivative of F with respect to XÔºå YÔºå Z„ÄÇ That means the So for X and Y„ÄÇ

 it's negative 4 for ZÔºå it's 3„ÄÇ That means in order to make F happy„ÄÇWe have to decrease„ÄÇ

They are inputs that have a negative gradient„ÄÇAnd increase the the inputs that have a positive gradient„ÄÇ

 The negative ones are X and Y„ÄÇ The the positive is z„ÄÇHopefully„ÄÇ

 I don't say the word beautiful too many times in this presentation„ÄÇ but this is very simple„ÄÇ

 beautifully simple„ÄÇÂëÉ„ÄÇBecause this gradient is a local worker„ÄÇItÔºå it propagates for you„ÄÇ

 has no It has no knowledge of the broader„ÄÇHappiness of F„ÄÇ

It just propagates the it computes the gradient between the output and the input„ÄÇ

 and you can propagate this gradient„ÄÇBased on in this caseÔºå F a gradient of1„ÄÇ

 but also just the error instead of one we could have on the output„ÄÇ

 the error is the measure of happinessÔºå and then we could propagate that error backwards„ÄÇ

 These gates are important because you can break down almost every operation we could think of that we work with in neural networks into one of several gates like this and„ÄÇ

The most popular are threeÔºå which is addition multiplication and the the max operation„ÄÇ

 So for additionÔºå what you do is you ignore theÔºå SoÔºå okay„ÄÇ

 the process is you take a forward path the network„ÄÇSo we have a value on every single gate„ÄÇ

And then you take a backward pass„ÄÇAnd through the back pathÔºå you compute those gradients„ÄÇ

For an ad gateÔºå you equally distribute the gradients on the output to the input„ÄÇ

 So when the the gradient on the output is negative 4Ôºå you equally distribute it to negative„ÄÇ

 to negative 4„ÄÇAnd you ignore the forward pass value„ÄÇ

So that three is ignored when you back propagate it„ÄÇOn the multiplication gateÔºå on the multiply gate„ÄÇ

It's trickier„ÄÇYou switch the forward Pass values„ÄÇSo if you look at FÔºå that's„ÄÇMultiply gate„ÄÇ

The forward pass values are switched„ÄÇAnd multiplied by the value of the gradient in the output„ÄÇ

If it's confusingÔºå go through the slides slowly„ÄÇItllÔºå it'll make a lot more sense„ÄÇHopefully„ÄÇ

One more gateÔºå there's the MA gateÔºå which takes the inputs and produces its output„ÄÇ

The value that is larger„ÄÇAnd when computing the gradient of the max gate„ÄÇIt„ÄÇDistributes the gradient„ÄÇ

Similar to the adgate„ÄÇBut to only one„ÄÇToÔºå toÔºå to only one of the inputs„ÄÇThe largest one„ÄÇ So it„ÄÇ

 unlike the ad gateÔºå pays attention to the inputÔºå the the input values on the forward pass„ÄÇAll right„ÄÇ

Lots of numbers„ÄÇ But the whole point here is it's likeÔºå it's really simple„ÄÇ

What a neural network is just a simple collection of these gates„ÄÇAnd thereÔºå you take a forward pass„ÄÇ

You calculate some kind of function on the endÔºå a gradient at the very end„ÄÇ

 and you propagate that back„ÄÇSo usually from neural networksÔºå that's an error function„ÄÇ

A loss functionÔºå Ob function„ÄÇCost functionÔºå all the sameÔºå all the same word„ÄÇSo that's the„ÄÇ

 that's the sigmoid function there„ÄÇ F whenÔºå when you have three weightsÔºå W 0Ôºå W 1„ÄÇ

 W2 and x 2 inputs x 0 x x 0 x 1Ôºå that's gonna be the sigmoid function„ÄÇ

 That's how you compute the output„ÄÇOf„ÄÇÂïä„ÄÇOf the neuron„ÄÇ But then you could decompose that neuron„ÄÇ

 You could separate it all into just a set of gates like this„ÄÇ additionÔºå multiplication„ÄÇ

There's exponential in there in the division„ÄÇ they're all very similar„ÄÇ

 And you repeat the exact same process if theÔºå the„ÄÇThere's five inputs„ÄÇ

 There's three weights and two inputsÔºå x 0 x1„ÄÇYou take a forward path„ÄÇThrough this circuit„ÄÇ

In this caseÔºå againÔºå you want it to increase so that the the gradient on the output is one„ÄÇ

 and you back propagate that gradient of one to the inputs„ÄÇNow with neural networks„ÄÇ

 there's a bunch of parameters that you're trying to through this process modify„ÄÇ

And you don't get to modify the inputs„ÄÇYou get to modify the weights along the way and the biases„ÄÇ

 The inputs are fixedÔºå The outputs are fixed„ÄÇ the outputs that you hope the network will produce„ÄÇ

 What you're modifying is the weights„ÄÇ So I get to try to adjust those weights and such that in the direction of the gradient„ÄÇ

That's the task of back propagation„ÄÇThe main way that neural networks learn„ÄÇ

As we update the weights and the biases„ÄÇTo decrease the loss function„ÄÇThe lower the loss function„ÄÇ

 the better„ÄÇSo in this caseÔºå you have„ÄÇ3 inputs on the top leftÔºå the simple networkÔºå three inputs„ÄÇ

3 weights on each of the inputs„ÄÇ There's a bias on the node„ÄÇBÔºå and it produces an output„ÄÇËØ∂„ÄÇ

And that little symbol„ÄÇThis is indicating a sigmoid function„ÄÇAnd loss„ÄÇ

Is computed as y minus a squared„ÄÇDivided by2„ÄÇWhere why is the ground truth„ÄÇ

 the output that you want to be the network to produce„ÄÇ

And that loss function is back propagated in exactly the same way that we described before„ÄÇAlright„ÄÇ

 so the subtasks that involved in this update of weights and biases„ÄÇ

Is that the forward pass computes the network output at every neuron„ÄÇ And thenÔºå the finally„ÄÇ

 the output layer„ÄÇComputes the error„ÄÇ The difference between A and B„ÄÇAnd then„ÄÇ

Backward propagates the gradients„ÄÇInstead of one on the outputÔºå itll be the error on the output„ÄÇ

 and you back propagate it„ÄÇAnd then once you know the gradient„ÄÇ

 you adjust the weights and the biases in the direction of the gradient„ÄÇ

Are actually the opposite of the direction of the gradient because you want the loss to decrease„ÄÇ

And the amount by which you make that adjustment„ÄÇIt's called the learning rate„ÄÇ

The learning rate could be the same across the entire network„ÄÇ

 or it could be individual to every weight„ÄÇAnd the process„ÄÇOf adjusting the weights and biases„ÄÇ

 is just optimization„ÄÇIt's learning is an optimization problem„ÄÇ You have an objective function„ÄÇ

 and you're trying to minimize it„ÄÇ And your variables are the parametersÔºå the weights and biases„ÄÇAnd„ÄÇ

 you knowÔºå neural nodes just happened to have tensÔºå hundreds of thousands„ÄÇ

 millions of those parameters„ÄÇSo the spaceÔºå the function that you're trying to minimize is highly nonlinear„ÄÇ

But it boils down to something like thisÔºå y„ÄÇ2 weights„ÄÇHere are two plots„ÄÇOr actually one weight„ÄÇ

 sorryÔºå one weight„ÄÇAnd then as you adjust itÔºå the cost„ÄÇ

You adjust in such a way that minimizes the output cost„ÄÇ

And there's a bunch of optimization methods for doing this„ÄÇ You can„ÄÇThis this is a convex function„ÄÇ

 so you can find the minimum„ÄÇ the local minimumÔºå if you know about these kind of terminologies„ÄÇ

 the local minimum is the same as the global minimum„ÄÇ So there's not„ÄÇ

 it's not a weirdly hilly terrain where you can get stuck in in So your goal is to get to the bottom of this thing„ÄÇ

 And if it's really complex terrainÔºå it'll be hard to get to the bottom of it„ÄÇ

So there is a lot of differentÔºå this general approach is gradient descent„ÄÇ

And there's a lot of different ways to do grade descent„ÄÇ

 some adding in various ways of adding randomness into the process„ÄÇ

 So you don't get stuck into the weird crevices of the terrain„ÄÇAlrightÔºå but it's messy„ÄÇ

You have to be really careful„ÄÇ This is the part you have to be aware of„ÄÇ

When you're designing a network for deep traffic and nothing is happening„ÄÇ

This might be what's happening„ÄÇAvananish ingredients„ÄÇOr explode gradients„ÄÇ

TheWhen the partial derivative is small„ÄÇ So if you take it a sigmoid function„ÄÇYou know„ÄÇ

 the most popular„ÄÇFor a while activation functionÔºå the derivative is 0 at the tails„ÄÇ

 So when the input to thisÔºå the sigmoid function is really high or really low„ÄÇ

That derivative is going to be 0„ÄÇ So the gradient„ÄÇThat you computeÔºå you know„ÄÇ

 gradient tells you how much I want to adjust the weights„ÄÇ The gradient might be 0„ÄÇ

And so you back propagate that 0Ôºå a very low number„ÄÇ and it gets less and less as you back propagate„ÄÇ

 And so yourÔºå the result is that you don't„ÄÇYou think that you don't need to adjust weights at all„ÄÇ

 and when a large fraction of the network thinks that weights don't need to be adjusted„ÄÇ

Then they don't adjust the weights„ÄÇ And you're not doing any learning„ÄÇ

 That's so the learning is slow„ÄÇThere's some fixes to this„ÄÇThere's different types of functions„ÄÇ

 Here's a piece wise„ÄÇTheÔºå the ra functionÔºå which is the most popular activation function„ÄÇBut again„ÄÇ

 it suffers„ÄÇIfÔºå if it's an initialÔºå if the neurons aret initialized poorly„ÄÇIt might not this„ÄÇ

 this function might not„ÄÇ It might be zero gradient for the entire data set„ÄÇ

Nothing that you nothing that you produce as input„ÄÇ you know„ÄÇ

 you run all your thousands of images of cats and none of them fire at all„ÄÇSo that's the danger here„ÄÇ

So you have to pick these„ÄÇBoth theÔºå the optimization„ÄÇEine„ÄÇ

 the solver that you use and the activation functions carefully„ÄÇ

 You can't just play plug and play likeÔºå like their Legoos„ÄÇ You have to be aware ofÔºå of the function„ÄÇ

SGDÔºå stochastic gradient descent„ÄÇIs the„ÄÇIs theÔºå that's the vanilla optimization algorithm„ÄÇ

For gradient descentÔºå for„ÄÇFor optimizing loss function over the gradients„ÄÇ

And so what's visualized here isÔºå againÔºå if you're if you've done any numerical optimization or not nonlinear optimization„ÄÇ

 there's the famous saddle point„ÄÇThat's tricky for these algorithms to deal with„ÄÇ

What what happens is it's easy for them to oscillate„ÄÇ

 get stuck in that saddle and oscillate back and forth„ÄÇAs opposed to what they want to do„ÄÇ

 which is go down intoÔºå you knowÔºå you get soÔºå so happy that you found this like„ÄÇüòäÔºåLow point„ÄÇ

That you forget that there's a much lower point„ÄÇ And so you get stuck with the gradient„ÄÇ

 The momentum of the gradient keeps rocking you back and forth without you going„ÄÇ

To a much greater global minimum„ÄÇ And there's a bunch of clever ways of solving that„ÄÇ

The atom optimizer is one of those„ÄÇBut in this caseÔºå as long as the gradients don't vanish„ÄÇSGD„ÄÇ

 the stochastic gradient descentÔºå one of these algorithms will get you there„ÄÇ

 They might take a little whileÔºå but they'll get you there„ÄÇAnd that's the main yes question„ÄÇ

The question was„ÄÇYou're dealing with a function that's not non convex„ÄÇ

 And how do we ensure anything about it converging to anything that's reasonably good„ÄÇ

 The local optimum converges to itÔºå And the the answer is„ÄÇYou can't„ÄÇ

This isn't only a nonlinear function„ÄÇIt's a highly nonlinear function„ÄÇ

The power and the beauty of neural networks„ÄÇIs that it can represent„ÄÇTheseÔºå like„ÄÇ

Arbitrarily complex functions„ÄÇIt's it's incredibleÔºå right„ÄÇ

 And you can learn those functions from data„ÄÇBut„ÄÇThe the reason you„ÄÇ

 people refer to neural networks' training is art„ÄÇI you're trying to play with parameters that don't get stuck in these local optima for stupid reasons and for clever reasons„ÄÇ

 question„ÄÇSo the question yeahÔºå so continue on the same thread„ÄÇSo the thing is„ÄÇ

 we're dealing with functions where we don't know what the global optimal is„ÄÇ

 That's sort of the crux of it„ÄÇEverything we talk about„ÄÇInterpreting textÔºå interpreting video„ÄÇ

You knowÔºå even drivingÔºå like what is the optimal for drivingÔºüNever crashing„ÄÇYou know„ÄÇ

It sounds easier to say thatÔºå but you actually have to formulate the world under which you define all of those things„ÄÇ

 and that becomes really non nonlinear objective function for which you don't know what the optimalimum is„ÄÇ

It's just„ÄÇThat's why you just keep trying and get impressed every time it gets better„ÄÇ

 Its essentially the process„ÄÇAndÔºå you knowÔºå and you can also compareÔºå you know„ÄÇ

 you can compare to human level performance„ÄÇ So for Iagenet„ÄÇ

 we can tell the difference in cats and dogs in top  five categories and 90„ÄÇShoot 96% of the time„ÄÇ

 whatever accuracy„ÄÇ And then you get impressed when a machine can do better than that„ÄÇ

 but you don't know what the best is„ÄÇThese videos could be watched for hours„ÄÇ

 I won't play it until I explain the slide„ÄÇSo let's pause to reflect on back propagation before I go on to recurrenial networks„ÄÇ

 yes question„ÄÇAs a practical matterÔºå how can you tell when you're actually training a net„ÄÇ

 whether you're facing the vanishished in problem orÔºü

You need to change your optimizer or you need toÔºå I meanÔºå like you've reached some local minimum„ÄÇ

The question wasÔºå how do you practically know when you've hit the vanishing gradient problemÔºü

So the vanishing gradient could be„ÄÇSo that that„ÄÇThe derivative being0 and the gradient„ÄÇ

Happens when the activation is explodingÔºå so like really high values and really low values„ÄÇ

 The really high values is easy because they're like your network is just going crazy„ÄÇ

produce very large values„ÄÇ And you can fix a lot of those things by just capping„ÄÇThe activations„ÄÇ

The value is being really low„ÄÇResulting in vanishing gradient are really hard to detect„ÄÇThis is„ÄÇ

 I meanÔºå there's a lot of research in trying to figure out how to„ÄÇHow to detect these things„ÄÇ

 But it's if you're not carefulÔºå it's oftentimes you can„ÄÇYouÔºå you can find that„ÄÇ

And this isn't hard to do where like 40Ôºå50% of the network of the neurons are„ÄÇ

 are dead where they're called like for Ra you„ÄÇ They're dead Ra you knows„ÄÇ

 they're not They're not firing at all„ÄÇ How do you detect that„ÄÇThat's part of learning„ÄÇ

 So if they never fireÔºå you can detect that by running it through the entire training set„ÄÇ I mean„ÄÇ

 there's a lot of tricksÔºå but it's that's the problem is„ÄÇYou try to learn„ÄÇ

 and then the you look at the loss functionÔºå and it's not„ÄÇConverging to anything reasonable„ÄÇ

 You either' going all over the place or just converging very slowly„ÄÇ

 And that's an indication of something is wrong„ÄÇThat something could be the loss function is bad„ÄÇ

 That something could be that you've already found the optimal or that something could be the vanish ingredient„ÄÇ

And againÔºå that's why it's an art„ÄÇButÔºå certainlyÔºå some„ÄÇ

At at least some fraction of the neurons need to be firing„ÄÇOtherwise„ÄÇ

 the initialization is really poorly done„ÄÇOkayÔºå so to reflect on the simplicity of back propagation„ÄÇ

And the power of it„ÄÇ So this is„ÄÇThis kind of step of back propagating the loss function to the gradients and locally„ÄÇ

Is the way neural networks learn„ÄÇ We don't have„ÄÇ It's really the only way that we've effectively been able to„ÄÇ

 to train„ÄÇA neural network to learn a functionÔºå to adjusting the weights of the biases„ÄÇ

 the huge number of weights and biasesÔºå the parameters„ÄÇIs just through this optimization„ÄÇ

 is back propagating the error„ÄÇWhere you have the supervised ground truth„ÄÇ

So the question is whether this process is just like fitting„ÄÇAdjusting the parameters„ÄÇ

Of a highly nonlinear function„ÄÇTo minimize a single objective„ÄÇIs the way you achieve intelligence„ÄÇ

 human level intelligence„ÄÇ And that's something to think about„ÄÇ

You have to think about for driving purposesÔºå what is the limitation of this approachÔºü

So what's not happeningÔºå The neural network designÔºå The architecture is not being adjusted„ÄÇ

 You're not evolving the any of the edgesÔºå the layersÔºå nothing is being evolved„ÄÇ

And so there are other optimization approaches„ÄÇThat I think are more„ÄÇ

Interesting and inspiring and effective„ÄÇ SoÔºå for exampleÔºå this is„ÄÇUsing soft cubes to robot„ÄÇ

 So this this is falling out of the field of evolutionary computation evolutionary robotics„ÄÇ

 where you evolve the dynamics of a robot using genetic algorithms„ÄÇAnd that's„ÄÇÂóØ„ÄÇSoÔºå you can think of„ÄÇ

So what these robots are being taught to„ÄÇIn simulationÔºå obviouslyÔºå toÔºå to walk and to swim„ÄÇ

 So that one is swimming„ÄÇBut you could theÔºå the nice thing here is the dynamics that highly nonlinear space as well„ÄÇ

 that controls the dynamics of this weird shape robot„ÄÇWith a lot of degrees of freedom„ÄÇ

 it's the same kind of thing as the neural network„ÄÇ and in fact„ÄÇ

 people have applied genetic algorithms and colony optimization„ÄÇ

 all kinds of sort of nature inspired algorithms for optimizing the weights in the biases„ÄÇ

 but they don't seem to currently work that wellÔºå but it's kind of it's a cool idea to be using nature type evolutionary algorithms to evolve something that's already nature inspired„ÄÇ

 which is neural networks„ÄÇBut it's something to think about„ÄÇIsÔºå you know„ÄÇThe back propagation„ÄÇ

 while really simple isÔºå is's kind of dumb„ÄÇ And the question is whether general intelligence reasoning can be achieved with this process„ÄÇ

All rightÔºå recurring neural networks„ÄÇSo on the left thereÔºå there's an input X„ÄÇ

With weights on the inputÔºå UÔºå there's a hidden stateÔºå hidden layerÔºå S„ÄÇWith weights on the„ÄÇ

On the edgeÔºå connecting the hidden states to each other„ÄÇAnd then more weights V on the outputÔºå oh„ÄÇ

It's a really simple network„ÄÇ There's inputs„ÄÇ There is hidden states„ÄÇThe memory of this network„ÄÇ

And there's outputs„ÄÇBut theÔºå theÔºå the fact that there is this„ÄÇLoop„ÄÇ

Where the hidden states are connected to each other„ÄÇ

Means that as opposed to producing a single input„ÄÇThe network takes arbitrary number of inputs„ÄÇ

 It just keeps taking X1 at a time„ÄÇAnd produces a sequence of x's„ÄÇThrough time„ÄÇ

And so depending on the duration of the sequences you're interested in„ÄÇ

 you can think of this network in its unrolled state„ÄÇ

So you can unroll this neural network where the inputs are in the bottomÔºå X T-1Ôºå XÔºå TÔºå X T plus1„ÄÇ

same with the outputsÔºå0„ÄÇ OhÔºå sorryÔºå O T-1Ôºå O TÔºå O T plus1„ÄÇ

And it becomes like a regular neural network unrolled some arbitrary number of times„ÄÇThe parameters„ÄÇ

 againÔºå there's weightsÔºå there's biases„ÄÇ It's similar to CNNs„ÄÇ

 convolusution neural networks in that it just like conusution and neural networks make certain spatial consistency assumptions„ÄÇ

The recurial networks assume temporal consistency amongst the parameters„ÄÇ

 So it shares the parameters that that WÔºå that UÔºå that V is the same for every single time step„ÄÇ

 So you're learning„ÄÇThe same parameterÔºå no matter the duration of the sequence„ÄÇ

And that allows you to look at arbitrarily long sequences„ÄÇWithout having an explosion of parameters„ÄÇ

And this process is the same exact process that's repeated based on the different variants that we talked about before in terms of inputs and outputs„ÄÇ

 one to manyÔºå many to oneÔºå many to many„ÄÇAnd the back back propagation process is exactly the same as for regular neural networks„ÄÇ

Has a fancy name of background propagation through time„ÄÇB PTÔºå TÔºå T„ÄÇ

 But it's just back propagation through an unrolled„ÄÇ

Unrolled recurring neural network where the errors are on the computer and the outputs„ÄÇ

The gradients are computed„ÄÇPropaate back propagated„ÄÇAnd computed on the inputs„ÄÇAgain„ÄÇ

 suffering from the same exact problem„ÄÇ NowÔºå I vanish ingredients„ÄÇ Now„ÄÇ

 the problem is that the depth of these networks can be arbitrary longÔºå rightÔºå so„ÄÇIf„ÄÇ

 if at any pointÔºå the gradient hits a low numberÔºå0„ÄÇIt becomes that neuron becomes saturated„ÄÇ

 that gradientÔºå let's call it saturated„ÄÇ That gradient gets„ÄÇDrives all the earlier layers to zero„ÄÇ

So it's easier to run to a problem where you're really ignoring majority of the sequence„ÄÇ

This is just another Python way„ÄÇTo pseudocode way to look at it„ÄÇIs you have the same W„ÄÇ Remember„ÄÇ

 you're sharing the weights and all the parameters from time to time„ÄÇSo if the weights are such„ÄÇW„ÄÇ

 H A HÔºå HÔºå if the weights are such that they produceÔºå they have either„ÄÇ

They they have a negative value that results„ÄÇIn a gradient that goes to 0„ÄÇ

That propagates through the rest„ÄÇ So this that's the pseudo code for back propagation„ÄÇ

 The backward pass through the R and N„ÄÇThat WÔºå H H„ÄÇPropaates back„ÄÇ

And so you get these things with exploding vanish ingredients where„ÄÇThis isÔºå for example„ÄÇ

 a error surface for a single hidden unit R N„ÄÇ So these visualizing the gradient„ÄÇ

 the value of the weightÔºå the value of the bias and the error„ÄÇ

 So the error could be really flat or could explode„ÄÇAnd both are going to lead„ÄÇ

To you not making the either making steps that are too gradual or too big„ÄÇ

It's the geometric interpretation„ÄÇ OkayÔºå what other variants that we look at a little bit„ÄÇ

Are there for R NNs„ÄÇ It doesn't have to be only one way„ÄÇ It can be bidirectional„ÄÇ

 so there could be edges going forward and edges going back„ÄÇWhat that's needed for is things like„ÄÇ

Fillling inÔºå missing whatever the data isÔºå filling in missing elements of that data„ÄÇ

 whether that's images or words or audio„ÄÇAnd generallyÔºå as alwaysÔºå is the case in neural networks„ÄÇ

 the deeper you goÔºå the better„ÄÇ So this is that deep referring to the number of layers in a single temporal instance„ÄÇ

SoÔºå on the right of the slide isÔºå is we're stacking in theÔºå not in the temporal domain„ÄÇ

Each of those layers has its own set of weights and its own sets of biases„ÄÇThese things are awesome„ÄÇ

 but they need a lot of data when youÔºå when you„ÄÇüòäÔºåWhen you make„ÄÇ

When you add extra layers in this way„ÄÇOkayÔºå so the problem is while recurrenial networks in theory are supposed to be able to learn any kind of sequence„ÄÇ

The reality isÔºå they're not really good at remembering what happened a while ago„ÄÇ

 The long term dependency„ÄÇ So here's a silly example„ÄÇ Let's think of a„ÄÇA story about Bob„ÄÇ

Bob is eating an apple„ÄÇSo the Apple part is generated by their currential network„ÄÇRight„ÄÇ

Thecur neural networks can learn to generate apple because they've seen a lot of sentences with Bob and eating„ÄÇ

 and they can generate the word apple„ÄÇFor a longer sentenceÔºå like Bob likes apples„ÄÇ

 He's hungry and decided to have a snack„ÄÇ So now he's eating an apple„ÄÇ

You have to maintain the state that we're talking about Bob and we're talking about apples„ÄÇ

Through several discretereetÔºå semantic„ÄÇSentences„ÄÇAnd that kind of long term memory is not„ÄÇ

Because of the because of different effectsÔºå but vanished ingredients„ÄÇ

It's difficult to propagate the important stuff that happened a while ago in order to maintain that context in generating Apple or classifying some concept that happened„ÄÇ

Way down the line„ÄÇSoÔºå when people talk about„ÄÇRecurrent neural networks these days„ÄÇ

They're talking about LSTMsÔºå long shirtÔºå short term memory networks„ÄÇ

So all the impressive results on time series and audio and videoÔºå all of that that requires LSTMs„ÄÇ

 And soÔºå againÔºå vanilla R N Ns up on top of the slide„ÄÇis the each cell is simple„ÄÇ

There' are some hidden units„ÄÇThere's an inputÔºå and there's an output„ÄÇ

Here we'll use 10 H as the activation function„ÄÇIt's„ÄÇ

 it's just another popular sigmoid type activation function„ÄÇLSTMs are more complicated„ÄÇ

Where they look more complicatedÔºå but„ÄÇIn some waysÔºå they're more intuitive for us to understand„ÄÇ

There's a bunch of gates in each cell„ÄÇWe'll go through those in yellow or different neural network layers„ÄÇ

It was sigma and 10H„ÄÇAre just are different types of activation functions„ÄÇ

10 H is an activation function that that squishes the input into the range of negative one to one„ÄÇ

 sigmoid function squishes it between 0 and 1„ÄÇ and that serves different purposes„ÄÇ

There is some pointwise operationsÔºå addition„ÄÇMulplication„ÄÇAnd there is„ÄÇConnections„ÄÇ

So data being passed from layer to layerÔºå shown by the arrows„ÄÇThere's concatenation„ÄÇ

 and there's a copy operation on the output„ÄÇ So we copy„ÄÇ

The output of each cell is copied to the next cell and to the output„ÄÇOkay„ÄÇ

 let me try to make it clarify„ÄÇClarify a little bit„ÄÇ

So there's this conveyor belt going through inside each individual's cell„ÄÇ and they all have„ÄÇ

 there's really three steps in the conveyor belt„ÄÇThe first is there is a sigmoid function that's responsible for deciding„ÄÇ

What to forget and what to ignore„ÄÇ So it'sÔºå it's responsible for„ÄÇTaking in the input„ÄÇThe new input„ÄÇ

 X T„ÄÇTaking in theÔºå the„ÄÇThe state of the previous„ÄÇThe output of the previous cell„ÄÇ

 previous time step„ÄÇAnd decidingÔºå do I want to keep that in my memory or not„ÄÇ

 And do I want to integrate the new input into my memory or not„ÄÇ

So this allows you to be selective about the information of which you learn„ÄÇSoÔºå for example„ÄÇ

 the sentence Bob and Alice are having lunch„ÄÇ Bob likes apples„ÄÇAlice likes oranges„ÄÇ

 she's eating an orange„ÄÇSo„ÄÇThe way„ÄÇSo Bob and Alice are having lunch„ÄÇ Bob likes apples right now„ÄÇ

 if you say you had a hidden state keeping track of the gender of the person we're talking about„ÄÇSo„ÄÇ

You might say that there's both genders in the first sentence„ÄÇ There's male in the second sentence„ÄÇ

 female in in the third sentence„ÄÇAnd that wayÔºå when you have to generate a sentence about who's eating what„ÄÇ

 you'll know the you'll keep the gender information„ÄÇ

In order to make an accurate generation of text corresponding toÔºå to the proper person„ÄÇ

So you have to forget certain things„ÄÇ LikeÔºå forget that Bob existed at that moment„ÄÇ

And you have to forgetÔºå Bob likes apples„ÄÇ We have to remember„ÄÇThe Alice likes oranges„ÄÇ

So you have to selectively remember and forget certain things„ÄÇ That's LSTM in a nutshell„ÄÇ

So you decide what to forgetÔºå decide what to remember„ÄÇAnd decide what to output at that cell„ÄÇ

All right„ÄÇZoom in a little bit because this is pretty cool„ÄÇThere is a state running through the cell„ÄÇ

This convey„ÄÇPrevious stateÔºå like whatÔºå you knowÔºå the gender„ÄÇThat we're currently talking about that„ÄÇ

That's the state that you're keeping track of„ÄÇ And that's running through the cell„ÄÇ

And then there is three sigmoid layers„ÄÇOutputting a oneÔºå you knowÔºå a number between 0 and 1„ÄÇ

 but it's one when you want that information to go through„ÄÇAnd 0„ÄÇ

 when you don't want it to go through„ÄÇThe conveyor belt that maintains the state„ÄÇ

And so first sigmoid function is we decide what to forget and what to ignore„ÄÇThat's the first one„ÄÇ

 You take the inputs from the previous time stepÔºå the input to the network from the current time step and decide„ÄÇ

 do I want to forgetÔºå Do I want to ignore„ÄÇThose„ÄÇThen„ÄÇWe decide which part of the state to update„ÄÇ

 What part of our memory do we update with this information and what values to insert that update„ÄÇ

Third step is we perform the actual update„ÄÇAnd perform the actual forgetting„ÄÇ

So that's where you have the sigmoid function is you just multiply it„ÄÇWhen it's 0Ôºå it's forgetting„ÄÇ

 when it's oneÔºå that information passes through„ÄÇAnd finallyÔºå we produce an output from the cell„ÄÇSo„ÄÇ

 if it's translationÔºå it's producing an output in the English language where the input was in the Spanish language„ÄÇ

And then that same output is copied to the next cell„ÄÇOkay„ÄÇ

 so what can we get done with this kind of approach„ÄÇWe can look at machine translation„ÄÇ

 And guess what I'm trying to this question„ÄÇWhat is a representation of the state„ÄÇ

 is it like a floating point or is it like a vectorÔºüÊàëÁöÑÊòØ„ÄÇThe the state is the„ÄÇThe activation„ÄÇMultiply„ÄÇ

 by the way„ÄÇ So it's the outputs of the sigmoid or the 10 H activations„ÄÇThere's a bunch of neurons„ÄÇ

 and they're firing a number between negative1 and1 or between 0 and 1„ÄÇ

 And that's that holds a state„ÄÇ It's just calling it state is sort of simplifying„ÄÇ

 But the point is that there's a bunch of numbers being constantly modified by the weights„ÄÇ

And the biases„ÄÇAnd those numbers hold the state„ÄÇAnd the modification of those numbers is controlled by the weights„ÄÇ

And then once all that is doneÔºå the resulting output of the recurrent neural network is compared to the desired output„ÄÇ

 and the air is then back propagated through the weights„ÄÇHopefullyÔºå that makes sense„ÄÇ

So machine translation is one popular application„ÄÇAnd all of it is the same„ÄÇ

All of these networks that I'll talk aboutÔºå they're really similar constructs„ÄÇYou have some inputs„ÄÇ

Whatever language that is again„ÄÇGermanÔºå maybeÔºå I think everything is German„ÄÇAnd the output„ÄÇ

 so the inputs are in one languageÔºå a set of characters that compose a word in one language„ÄÇ

There's a state being propagated„ÄÇAnd once that sentence is over„ÄÇ

You start as opposed to collecting inputsÔºå you start producing outputs„ÄÇ

 and you can output in the English language„ÄÇThat's there's a ton of great work on machine translation„ÄÇ

 It's what Google is mostly using for their translator„ÄÇSame thing„ÄÇI showed this previously„ÄÇ

But now you know how it worksÔºå same exact thingÔºå LSTMs„ÄÇGenerating handwritten characters„ÄÇ

 So handwriting and arbitrary styles„ÄÇ So controlling the drawing„ÄÇ

Where the input is text and the output is handwriting„ÄÇAnd it'sÔºå againÔºå the same kind of„ÄÇNetwork„ÄÇ

Was some depth here„ÄÇThe inputs is the text„ÄÇ The output is the control of the writing„ÄÇ

Character level text generation„ÄÇThis is the„ÄÇThe thing that told us about life„ÄÇThe„ÄÇ

 the meaning of lifeÔºå literary recognition and the tradition of ancient human reproduction„ÄÇThat's„ÄÇ

 againÔºå the same process„ÄÇInput one character at a time„ÄÇ

Where you see there is an encoding of the characters on the input layer„ÄÇThere's a hidden state„ÄÇ

Hidden layer„ÄÇ that's keeping track of those activationsÔºå the outputs of the„ÄÇ

Of the activation functions„ÄÇAnd every single„ÄÇTimeÔºå it's outputting its best prediction of the next character that follows„ÄÇ

Now in a lot of these applications„ÄÇYou want to ignore the output until the sentences„ÄÇ

 the input sentence is over„ÄÇAnd then you start listening to the output„ÄÇ

 but the point is it just keeps generating textÔºå whether it's given input or not„ÄÇ

So you producing input is just addingÔºå steering the recurrent neural network„ÄÇ

You can answer questions„ÄÇAbout an image„ÄÇSo the input hit there„ÄÇ

 So you could almost arbitrarily stack things together„ÄÇ

 So you take image as an input bottom left there„ÄÇPut it into convolution neural network„ÄÇAnd„ÄÇ

Take the question„ÄÇThere's something called word embeddings is„ÄÇ

 is to broaden the representative meaning of the words„ÄÇ So how manyÔºå how many books is the question„ÄÇ

 So you want to take the word embeddings and the image„ÄÇ

And produce in your best estimate of the answer„ÄÇ So for a question of what color is the cat„ÄÇ

It could be gray or black„ÄÇ There's the different LSTM flavors producing that answer„ÄÇ

 same with counting chairs„ÄÇ You can give an image of a chair„ÄÇAnd ask the question„ÄÇ

 how many chairs are thereÔºå And it can produce an answer of„ÄÇ3„ÄÇ

So this so I should say that this is really hardÔºå right„ÄÇ

 And it's an arbitrary question ask of an arbitrary image„ÄÇ So you're both interpreting„ÄÇ

 you're doing natural language processing and you're doing computer vision all in one network„ÄÇ

Same thing with image caption generation„ÄÇYou can detect the different objects in the scene„ÄÇ

Generate those words„ÄÇStitch him together in in syntactically correct sentences and rera the sentences„ÄÇ

 All of those are LSTMs with the theÔºå the second and the third step„ÄÇ

 The first is computer vision detecting the objectsÔºå segmenting the image and detecting the objects„ÄÇ

 And that wayÔºå you can generate a caption that says a man is sitting in a chair with a dog in his lap„ÄÇ

AgainÔºå LSTMs for video„ÄÇCaption generation for video„ÄÇ

The input at every frame is an image that goes into the LSTM„ÄÇ The input is an image„ÄÇ

And the output is a set of characters„ÄÇ FirstÔºå you load in the video„ÄÇ In this case„ÄÇ

 the output is on top„ÄÇSoÔºå you encode„ÄÇThe video into a representation and inside the network„ÄÇ

 And then you start generating words about that video„ÄÇ So first comes the inputÔºå the encoding stage„ÄÇ

 then the decoding stage„ÄÇTake in the videoÔºå say a man is takingÔºå talkingÔºå whatever„ÄÇ

And because the input and the output is arbitraryÔºå there also has to be indicators of the beginnings and the ends of a sentence„ÄÇ

 So in this caseÔºå end of sentence„ÄÇSo you want to know when you stop„ÄÇ

In order to generate syntactically correct sentencesÔºå you want to be able to generate a period„ÄÇ

That indicates the end of a sentence„ÄÇSo you can alsoÔºå againÔºå recurring neural networks„ÄÇLSTMs here„ÄÇ

 controlling the steering„ÄÇOf a sliding window on an image„ÄÇ

That's used to classify what's contained in that image„ÄÇ So here„ÄÇ

 a CNN being steered by acurrenial network„ÄÇIn order to convert this image into the number that's associated with the house number„ÄÇ

It's called visual attention„ÄÇ And that visual attention can be used to steer for the perception side„ÄÇ

 and it can be used to steer network for the generation„ÄÇ On the rightÔºå we can generate an image„ÄÇ

As so the output of the netÔºå it's a LSTM or the output at every time step„ÄÇIs visual„ÄÇIn this way„ÄÇ

 you can draw numbers„ÄÇHere„ÄÇI mentioned this before„ÄÇIs taking in as an inputÔºå silent video„ÄÇ

 sequence of images„ÄÇAnd producing audio„ÄÇSo this is„ÄÇAn LTM that takes convolutional„ÄÇ

 that has convolution layers for every single frame„ÄÇItTakes imagesÔºå as input„ÄÇAnd produces„ÄÇ

A spectrogramÔºå audioud is output„ÄÇIt's„ÄÇThe training set is a person hitting an object to a drumstick and your task is to generate„ÄÇ

 given a silent videoÔºå generate„ÄÇThe sound that a drumstick could make when in contact with that„ÄÇ

With that object„ÄÇOkayÔºå there medical diagnosis„ÄÇThat's actually„ÄÇ

 So I've listed some places where it's been really successful and pretty cool„ÄÇ

 but it's also beginning to be applied inÔºå inÔºå in places where„ÄÇüòäÔºåCan actually„ÄÇReally help„ÄÇ

CivilizationÔºå rightÔºå in the medical applications„ÄÇ So for medical diagnosis„ÄÇThere is highly sparse„ÄÇ

 and„ÄÇAVariable lengths„ÄÇSequence of information in the form ofÔºå for example„ÄÇ

 patient electronic health records„ÄÇSo every time you visit a doctor„ÄÇ

 there's some test being done and that information is there and you can look at it as a sequence over a period of time„ÄÇ

 and then given that dataÔºå that's the input„ÄÇThe output is a diagnosis„ÄÇA medical diagnosis„ÄÇ

 So in thisÔºå in this caseÔºå we can look at predicting diabetes„ÄÇSolliosisÔºå asthmaÔºå so on„ÄÇ

It was pretty good accuracy„ÄÇThere's something that„ÄÇAll of us wish we could do„ÄÇ

Is stock market prediction„ÄÇSo you can inputÔºå for exampleÔºå WellÔºå first of all„ÄÇ

 you can input the raw stock dataÔºå rightÔºå the order books andÔºå and so onÔºå financial data„ÄÇ

 But you can also look at news articles from all over the Web„ÄÇ

And take those as input as's shown here on the X axis is time„ÄÇ So articles some different days„ÄÇLSTM„ÄÇ

 once again„ÄÇAnd produce an output of your predictionÔºå binaryary prediction„ÄÇ

 whether the stock will go up or down„ÄÇAnd nobody's been able to really successfully do this„ÄÇ

 But there is a bunch of results and„ÄÇTrying to perform above random„ÄÇWhich is how you make money„ÄÇ

 right„ÄÇSignificantly above random on the prediction of it going up or down so you could buy or sell„ÄÇ

And especially when there in the cases when there was crashesÔºå it's easier to predict„ÄÇ

So you can predict an encroaching crash„ÄÇThese are shown in the table„ÄÇ

 the error rates for different stocks„ÄÇ

![](img/f6bbe96f7d85d836630eba16e2ef3316_11.png)

Automotive stocks„ÄÇYou can also generate audio„ÄÇ this exact same process„ÄÇ You generate language„ÄÇ

 You could generate audio„ÄÇ Here's trained on„ÄÇA single speakerÔºå of a few our epics of them speaking„ÄÇ

 And you just learn that's raw audio of the speaker„ÄÇAnd„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_13.png)

It's learning slowly to generate„ÄÇ„ÅÇ„ÅÆ„ÄÇ1Ôºå2Ôºå3„ÄÇI one to desire to the one„ÄÇS for to sayÔºå67Ôºå3Ôºå5Ôºå9Ôºå46Ôºå4 T2„ÄÇ

 I5„ÄÇ

![](img/f6bbe96f7d85d836630eba16e2ef3316_15.png)

PeopleObviouslyÔºå they were reading numbersÔºå but that„ÄÇThe theÔºå their mights„ÄÇThis is incredible„ÄÇ

 This is trained on theÔºå on a compressed spectrogram of the audioÔºå raw audio„ÄÇüòä„ÄÇ

And it's producing something that„ÄÇOver just a few epics is producing something that sounds like words that could do this lecture for me„ÄÇ

 I wish„ÄÇ

![](img/f6bbe96f7d85d836630eba16e2ef3316_17.png)

9„ÄÇ

![](img/f6bbe96f7d85d836630eba16e2ef3316_19.png)

I don't knowÔºå this is amazing„ÄÇ

![](img/f6bbe96f7d85d836630eba16e2ef3316_21.png)

This is raw input„ÄÇRraw outputÔºå all againÔºå LSTMs„ÄÇAnd there is a lot of work and voice recognition and audio recognition„ÄÇ

 you mapping„ÄÇLetYou turn it upÔºå but you're mapping any kind of audio to a classification„ÄÇ

So you can take the audio of the road„ÄÇAnd that's the spectroogram on the bottom there being shown„ÄÇ

And you could detect whether the road is wet or the road is dry„ÄÇAnd you could do the same thing for„ÄÇ

Recognizing the gender of the speaker„ÄÇOr recognizing many the many map of the actual words being spoken„ÄÇ

 speech recognition„ÄÇBut thisÔºå this is about driving„ÄÇ

 So let's see where recurrenial networks apply and driving„ÄÇWe talked about„ÄÇThe NviD approach„ÄÇ

 the thing that actually powers deep TeslaÔºå JS„ÄÇIs a simple convolution in neural network„ÄÇ

There's five convolution layers„ÄÇIn their approachÔºå three fully connected layers„ÄÇ

 you can add as many layers as you want in deep Tesla„ÄÇSo that's youÔºå a quarter million„ÄÇ

Parameterters to optimize„ÄÇ And all you're taking is a single image„ÄÇNo time for information„ÄÇ

 single image and producing the steering angle„ÄÇ That's the approach„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_23.png)

That's the deep tusle way„ÄÇSo take it a single image„ÄÇAnd learning of regression of a steering angle„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_25.png)

NowÔºå so one of the„ÄÇPrizees for the competition is the Uuddacity cell driving car engineer„ÄÇ

 nano degreeree„ÄÇFor free„ÄÇThis thing is awesome„ÄÇ I encourage everyone to check it out„ÄÇ

 but they did a competition„ÄÇÂëÉ„ÄÇThat's very similar to ours„ÄÇ

But they have a very large group of obsessed people„ÄÇ So theyÔºå they were very clever„ÄÇ

 They went beyond just convolution neural networks of predicting steering„ÄÇ

 So taking a sequence of images and predicting steering„ÄÇWhat they did is the winners„ÄÇ

 at least the firstÔºå and I'll talk about the second place winner tomorrow„ÄÇ

On 3D commution neural networks„ÄÇ But the first and the third place winners used R N Ns„ÄÇ

 used LSTMs orcur neural networks„ÄÇAnd mapped a sequence of images to a sequence of steering angles„ÄÇ

for anyone„ÄÇStatistically speaking„ÄÇAnybody here who's not a computer vision person„ÄÇ

 most likely what you want to use for whatever application you're interested in„ÄÇIs RNNs„ÄÇ

Just the world is full of time series data„ÄÇVery few of us are working on„ÄÇData„ÄÇ

 that's not time series data„ÄÇ In factÔºå whenever it's just snapshots„ÄÇ

 you're really just reducing the problem to the size that you can handle„ÄÇ

 But most data the world is time series data„ÄÇ So this is the approach you end up using if„ÄÇ

 if you want to apply it in your own research„ÄÇSo this isÔºå this is this this„ÄÇR NNs is the way to go„ÄÇ

So„ÄÇAgainÔºå whats what are they doingÔºå WhatÔºå how do you„ÄÇPut images into a recur neural network„ÄÇ

It's the same thing„ÄÇYou take„ÄÇYou have to convert an image into numbers in some kind of way„ÄÇ

A powerful way of doing that is convolutionary neural networks„ÄÇSoÔºå you can take„ÄÇ

Either 3D convolutional neural networks or 2D convolutional neural networks„ÄÇ

 ones that take time into considerationÔºå why not„ÄÇSo process that image to extract a representation of that image„ÄÇ

And that becomes the input to the LSTM„ÄÇ And the output at every single cell at every single time step is the predicted steering angle„ÄÇ

 the speed of the vehicle on the torque„ÄÇ That's what the first place winner did„ÄÇ

 They didn't just do steering angle„ÄÇ They also did the speed in the torque„ÄÇ

And the sequence length that they were using„ÄÇSo for training and for testing„ÄÇ

For the input and the output is a sequence length of 10„ÄÇThe question was„ÄÇ

 do they use supervised learningÔºå YepÔºå so they were given the same thing as in deep Tesla„ÄÇ

 a sequence of frames where they have a sequence of steering angleÔºå speed and torque„ÄÇ

 I think there's other information too„ÄÇAvailable„ÄÇ So yeahÔºå there's no„ÄÇ

 there's no reinforcement learning here„ÄÇ question„ÄÇ To get a sense for how how much information is being passed„ÄÇ

 How many L gates„ÄÇSomething this problem„ÄÇSo so the question was„ÄÇ

 how many LSTM gates are there in this problemÔºüSoÔºå this network„ÄÇIt„ÄÇ

s it's true that these diagrams kind of hide the number of parameters here„ÄÇ'sÔºå but it's arbitrary„ÄÇ

 just like convolutional neural networks are arbitraryÔºå so„ÄÇThe size of the input is arbitrary„ÄÇ

 the size of the sigmoid function and the 10 h is arbitraryÔºå so you can make it as large as you want„ÄÇ

 as deep as you wantÔºå and the deeper and larger the better„ÄÇWhat these folks actually use„ÄÇ

 So the way these competitions work and„ÄÇIf you I encourage you finished your machine learning to participate in Kego„ÄÇ

 CagoÔºå I don't know how to pronounce it competitions„ÄÇ

Whereas basically everyone's doing the same thingÔºå you're using LSTMsÔºå or if it's one to one mapping„ÄÇ

 you're using convolutionary neural networks to fully connected networks with some clever preprocessing„ÄÇ

 And the whole job is that takes months„ÄÇ and you probably if you're a researcher„ÄÇ

 that's what you'll be doing your own researchÔºå it's playing with parameters„ÄÇ

Playing with preprocesing of the dataÔºå playing with the different parameters the control„ÄÇ

 the size of the networkÔºå the learning rateÔºå I mentionedÔºå this type of optimizer„ÄÇ

 all these kinds of things„ÄÇ That's what you're playing with„ÄÇUsing your own human intuition„ÄÇ

 and you're using your„ÄÇWhatever probing you can do in monitoring the performance of the network„ÄÇ

Through time„ÄÇYes„ÄÇÂñÇ„ÄÇThe question was„ÄÇYou said that there is a memory of 10 in this LCM„ÄÇ

 and I thought R NNs are supposed to be arbitrary or whatever„ÄÇSo it'sÔºå it has to do„ÄÇ

With the training„ÄÇThe how the network is trained„ÄÇ So it's trained with sequences of 10„ÄÇ

 The structure is still the same„ÄÇ You only have one cell that's looping onto each other„ÄÇ

 But the question isÔºå whatÔºå in what chunks„ÄÇOf what is the size of the sequence of which you're doing the training and then the testing„ÄÇ

You don't have to„ÄÇ It can be arbitrary length„ÄÇ It's just usually better to be consistent and have a fixed length„ÄÇ

But itsÔºå there's noÔºå you're not stacking 110 cells together„ÄÇ It's just a single cell still„ÄÇ

So the third place winner„ÄÇTeam chauffeur„ÄÇUse something called transfer learning„ÄÇ

 And it's something I don't think I mentioned„ÄÇBut it's kind of implied„ÄÇ

The amazing power of neural networks„ÄÇüòäÔºåSo firstÔºå you need a lot of data to do anything„ÄÇ

So that's a cost„ÄÇ That's the limitation in neural networks„ÄÇ But what you could do isÔºå so there's„ÄÇ

 there's„ÄÇNeural networks that have been trained on very large data sets on INe„ÄÇThere's a VDGnet„ÄÇ

 AlexnetÔºå ResnetÔºå all these networks to train in huge amounts of data„ÄÇBut that those„ÄÇ

 those networks were trained to tell the difference between a cat and a dog or whatever or specific object recognition and single images„ÄÇ

How do I then take that network and apply it to my problem„ÄÇ

 say of driving of lane detection or classifying a medical diagnosis or cancer or notÔºü

The beauty of neural networks is you don't„ÄÇMeÔºå it dependsÔºå but transferÔºå the„ÄÇ

 the promise of transfer learning„ÄÇIs that you can just take that networkÔºüChop off the final layer„ÄÇ

The fully connected layer that maps from all those cool„ÄÇ

 high dimensional features that you've learned about the visual space„ÄÇ

And as opposed to predicting cat versus dogÔºå you teach you to predict cancer or no cancer„ÄÇ

You teach you to predict lane or no laneÔºå truck or no truck„ÄÇ

And so as long as the visual space under which the networks operate is similar or the data space„ÄÇ

 like if it's audio or whateverÔºå if it's similarÔºå if the features are useful that you learned in studying the problem of Caverse's dog deeply„ÄÇ

 you have learned actuallyÔºå how to see the world„ÄÇ And so you can apply that visual knowledge„ÄÇ

 You can transfer that learning to another domain„ÄÇ and that's that's the beautiful power of neural networks„ÄÇ

 is they're transferable„ÄÇAsÔºå you knowÔºå and so what they did here is they took„ÄÇ

I didn't spend enough time looking through the code„ÄÇ

 So I'm not sure which of the giant networks they tookÔºå but they took a giant con neural network„ÄÇ

They prun it down to„ÄÇ they chopped off„ÄÇThe end layerÔºå which produced 3000 features„ÄÇ

 and they took those 3000 features at every single image frame„ÄÇ

 And that's the X T that And they gave that as the input to LSTM„ÄÇ

 and the sequence length in that case was 50„ÄÇSo thisÔºå this process is pretty„ÄÇ

It's pretty similar across domains„ÄÇ that's the beauty of it„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_27.png)

And the art of neural networks„ÄÇIs in the„ÄÇThat's a good sign„ÄÇI guess I should wrap it up„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_29.png)

ÂñÇÂñÇ„ÄÇI don't think I need much timeÔºå but„ÄÇTheÔºå the art of neural networks is in the hyperparameter tuning„ÄÇ

 and that's the tricky part„ÄÇ And that's the part you can be taught„ÄÇ That's experience„ÄÇSadly enough„ÄÇ

 That's why they called„ÄÇ I talked about„ÄÇSttochastic gradient descentÔºå SGD„ÄÇ

 that's why whoever was Jeffrey Hinton refers to it as stochastic graduate student descent„ÄÇ

Meaning you just keep higher graduate students to play with the hyperparameter until the problem is solved„ÄÇ

So„ÄÇI have„ÄÇI have about 100 plus slides on driver stateÔºå which is the thing that I'm„ÄÇ

Most passionate aboutÔºå and I think we'll save the best for lastÔºå right„ÄÇ

 andll talk about that tomorrow„ÄÇ We have a guest speaker„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_31.png)

From the White HouseÔºå you talk about the future of artificial intelligence„ÄÇ

 from the perspective of policy„ÄÇAnd„ÄÇWhat I'd like you to doÔºå first of all„ÄÇ

 if you registered students submit the two tutorialsÔºå assignments and pick up„ÄÇ



![](img/f6bbe96f7d85d836630eba16e2ef3316_33.png)

Can we just set up boxes right here or somethingÔºü YeahÔºå just stop byÔºå pick up a shirt„ÄÇ

And give us a card on the way„ÄÇAll rightÔºå thanks guys„ÄÇ

