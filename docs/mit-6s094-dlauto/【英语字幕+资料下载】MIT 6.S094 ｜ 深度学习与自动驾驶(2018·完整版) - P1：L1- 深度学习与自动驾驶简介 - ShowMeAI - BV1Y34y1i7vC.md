# „ÄêËã±ËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëMIT 6.S094 ÔΩú Ê∑±Â∫¶Â≠¶‰π†‰∏éËá™Âä®È©æÈ©∂(2018¬∑ÂÆåÊï¥Áâà) - P1ÔºöL1- Ê∑±Â∫¶Â≠¶‰π†‰∏éËá™Âä®È©æÈ©∂ÁÆÄ‰ªã - ShowMeAI - BV1Y34y1i7vC

All rightÔºå hello everybody„ÄÇHopefully you can hear me wellÔºå yesÔºå yesÔºå great„ÄÇSo welcome to Cose 6 S0Ôºå9„ÄÇ

4„ÄÇ

![](img/419efdb516c630bd47e1579b4956df18_1.png)

Deep learning for self driving cars„ÄÇWe will introduce to you the methods of deep learning„ÄÇ

 of deep neural networksÔºå using the guiding case study of building cell driving cars„ÄÇ

My name is Lex Friedman„ÄÇYou get to listen to me for a majority of these lectures„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_3.png)

And I am part of an amazing team with some brilliant TAsÔºå would you say brilliantÔºüDan„ÄÇDan Brown„ÄÇ

You guys want to stand up„ÄÇ okayÔºå they're in front rowÔºå Spencer„ÄÇWilliam AngelÔºå Spencer Dot„ÄÇ

 and all the way in the backÔºå the smartest and the tallest person I knowÔºå Benedict Jenk„ÄÇ

So what you see there on the left of the slide is a visualization of one of the two projects that„ÄÇ

One of the two simulationsÔºå games„ÄÇThat will get to go through„ÄÇ

We use it as a way to teach you about deeper reinforcement learningÔºå but also as a way to excite you„ÄÇ

By challenging you to compete against othersÔºå if you wish to win a special prize„ÄÇYet to be announced„ÄÇ

 Super secret prize„ÄÇSo you can reach me and the TAs at Deep Cars at MIT atEDU if you have any questions about the tutorials„ÄÇ

 about the lectureÔºå about anything at all„ÄÇThe website„ÄÇ

 Car that MITU has the lecture content code tutorials againÔºå like today„ÄÇ

 the lecture slides for today are already up in P form the slides themselves„ÄÇ

 if you want to see them just email meÔºå but they're over a gigabyte in size because they're very heavy in videos„ÄÇ

 so I'm just posting the P„ÄÇAnd there will be lecture videos available„ÄÇ

A few days after the lecture is given so speaking of which there is a camera in the back„ÄÇ

 this is being videotaped and recordedÔºå but for the most part the camera is just on the speaker so you shouldn't have to worry if that kind of thing worries you„ÄÇ

 then you could sit on the periphery of the classroom or maybe I suggest„ÄÇSunglasses and a mustache„ÄÇ

 fake mustache„ÄÇ That would be a good idea„ÄÇ There is a competition for the game that you see on the left„ÄÇ

 I'll describe exactly what's involved„ÄÇIn order to get credit for the courseÔºå you have to„ÄÇ

Design and neural network that drives the car just above the speed limitÔºå65 m an hour„ÄÇ

 But if you want to winÔºå you need to go a little faster than that„ÄÇSo who this class is for„ÄÇ

You may be new to programmingÔºå new to machine learningÔºå new to robotics„ÄÇ

 or you're an experts in those fieldsÔºå but want to go back to the basics„ÄÇ

So what you will learn is an overview of deep reinforcement learning„ÄÇ

A combinationvolution neural networks„ÄÇRecurring neural networks„ÄÇ

And how these methods can help improve each of the components of autonomous drivingÔºå perception„ÄÇ

 visual perceptionÔºå localizationÔºå mappingÔºå control planningÔºå and the detection of driver state„ÄÇOkay„ÄÇ

 two projectsÔºå code nameÔºå deep traffic is the first one„ÄÇThere is„ÄÇ

 in this particular formulation of itÔºå there is seven lanes„ÄÇIt's a top viewÔºå it looks like a game„ÄÇ

 but I assure you it's very serious„ÄÇIt is the agent in red„ÄÇ

The car in red is being controlled by a neural network„ÄÇ

 and we'll explain how you can control and design the various aspects of the various parameters of this neural network„ÄÇ

 this neural network„ÄÇAnd it learns in the browser„ÄÇüò°ÔºåSo this we're using Comnet JS„ÄÇ

 which is a library that is programmed by Andre Carary in JavaScript„ÄÇ So amazingly„ÄÇ

 we live in a world where you can train in a matter of minutesÔºå a neural network in your browser„ÄÇ

And we'll talk about how to do that„ÄÇ The reason we did this is so that there is very few requirements for get you up and started when neural networks„ÄÇ

 So in order to complete this project for the course„ÄÇ

You don't need any requirements except to have a Chrome browser„ÄÇAnd to win the competition„ÄÇ

 you don't need anything except the Chrome browser„ÄÇThe second projectÔºå code named deep Tesla„ÄÇ

Or Tesla„ÄÇIs using data from a Tesla vehicle„ÄÇOf the forward roadway and using N end learning„ÄÇ

 taking the image and putting it into convolution neural networks that directly maps a agressor that maps to a steering angle„ÄÇ

So all it takes is a single imageÔºå and it predicts a steering angle for the car„ÄÇ And you„ÄÇ

 we have data for the car itself„ÄÇ and you get to build a neural network that„ÄÇTries to do better„ÄÇ

 tries to steer betterÔºå or at least as good as the car„ÄÇOkay„ÄÇLet's get started with the question„ÄÇ

With the thing that we understand so poorly at this timeÔºå because it's so shed in mystery„ÄÇ

 but it fascinates many of us„ÄÇAnd that's the question of what is intelligence„ÄÇThis is from a 1996„ÄÇ

March 1996Ôºå Time magazine„ÄÇAnd the question„ÄÇKem machines think is answered below with they already do„ÄÇ

So what if anything is special about the human mindÔºü



![](img/419efdb516c630bd47e1579b4956df18_5.png)

It's a good question for 1996Ôºå a good question for 2016Ôºå17Ôºå now„ÄÇAnd the future„ÄÇ

And there's two ways to ask that question„ÄÇ One is the special purpose version„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_7.png)

Can an artificialÔºå can an artificial intelligence system achieve a well defined„ÄÇSpecifically„ÄÇ

 formally definedÔºå finite set of goals„ÄÇAnd this little diagram from a book that got me into artificial intelligence is a bright eyeed high school student„ÄÇ

The artificial intelligence is a modern approach„ÄÇThis is a beautifully simple„ÄÇ

Diagram of an of a system„ÄÇ It exists in an environment„ÄÇ It has a set of„ÄÇ

Sensors that do the perception„ÄÇIt takes those sensors inÔºå does something magical„ÄÇ

 There's a question mark there„ÄÇ And with a set of effectors„ÄÇ

 acts in the world manipulates objects in that world„ÄÇüòäÔºåAnd so„ÄÇSpecial purpose„ÄÇ we can„ÄÇ

Under this formulationÔºå as long as the environment is formally definedÔºå well defined„ÄÇ

 as long as the set of goals are well definedÔºå as long as the set of actionsÔºå sensors and the„ÄÇ

Ways that the perception carries itself out is well defined„ÄÇ

 We have good algorithms of which we'll talk about that can optimize for those goals„ÄÇ

 The question isÔºå if we inch along this path„ÄÇWill we get closer to the general formulation„ÄÇ

 to the general purpose„ÄÇVersion of what artificial intelligence is„ÄÇCan it achieveÔºüPoorly defined„ÄÇ

 unconstrained set of goals with an unconstrainedÔºå poorly defined set of actions„ÄÇAn unconstrained„ÄÇ

 poorly defined„ÄÇUtility functions„ÄÇRewards„ÄÇThis is what human life is about„ÄÇ

 This is what we do pretty wellÔºå most days„ÄÇExist in a„ÄÇUndefinedÔºå full of uncertainty world„ÄÇSoÔºå okay„ÄÇ

 we can separate tasks into different three different categoriesÔºå formal tasks„ÄÇ This is the easiest„ÄÇ

It doesn't seem soÔºå it didn't seem so at the birth of artificial intelligence„ÄÇ

 but that's in fact true if you think about itÔºå the easiest is the formal tasksÔºå playing board games„ÄÇ

 the improving„ÄÇAll the kind of mathematical logic problems that can be formal formally defined„ÄÇ

Then there's the expert tasks„ÄÇSo this isÔºå this is where a lot of the exciting breakthroughs have been happening„ÄÇ

 where machine learning methodsÔºå data driven methods can help aid„ÄÇüòä„ÄÇ

Or improve on the performance of our human experts„ÄÇThis means medical diagnosisÔºå hardware design„ÄÇ

 scheduling„ÄÇAnd then there is the thing that we take for grantedÔºå the trivial thingÔºå the thing that„ÄÇ

We do so easily every day when we wake up in the morning„ÄÇThe mundane tasks of everyday speech„ÄÇ

 of written languageÔºå of visual perception„ÄÇOf walking„ÄÇ

Which we'll talk about in today's lecture is a fascinatingly difficult task„ÄÇAn object manipulation„ÄÇ

So the question is„ÄÇThat we're asking here before we talk about deep learning„ÄÇ

 before we talk about the specific methodsÔºå we really want to dig in andÔºå and„ÄÇAnd try to see„ÄÇ

 what is it about driving„ÄÇHow difficult is drivingÔºüI is it more like chess„ÄÇ

 which you see on the left there where we can formally define a set of lanes set of actions and formulate it as this„ÄÇ

 you know there's five set of actionsÔºå you can change a laneÔºå you can avoid obstacles„ÄÇ

 you can formally define an obstaclelyÔºå you can formally define the rules of the road„ÄÇ

 or is there something about natural language something similar to everyday conversation about driving that requires a much higher degree of reasoning„ÄÇ

Of communication„ÄÇOf learning„ÄÇOf existing in this under actuated space„ÄÇ

 is it a lot more than just left laneÔºå right laneÔºå speed upÔºå slow down„ÄÇ

So let's look at it as a chess king„ÄÇ Here's the chess pieces„ÄÇ

What is what are the sensors we get to work with in the self of an untonmous vehicle„ÄÇ

And we'll get a lot more in depth on thisÔºå especially with the guest speakers who've built many of these„ÄÇ

There's radar„ÄÇ There's the range sensorsÔºå radarÔºå Lidar that give you information about the obstacles in your environment„ÄÇ

That help localize the obstacles in the environment„ÄÇ

 Theres the visible light camera and stereo vision that gives you texture information that helps you figure out not just where the obstacles are„ÄÇ

 but what they areÔºå helps to classify those„ÄÇHas to understand their subtle movements„ÄÇ

Then there is the information about the vehicle itself„ÄÇ

About the trajectory and the movement of the vehicle that comes from the GPS and I U sensors„ÄÇ

And there is the rich state of the vehicle itselfÔºå what is it doingÔºü

What are all the individual systems doing that comes from the can network„ÄÇ

And there is one of the less studied but fascinating to us on the research side is audio„ÄÇ

The sounds of the road„ÄÇThat provide the rich context„ÄÇOf a wet road„ÄÇ

 the sound of a road that when it stop rainingÔºå but it's still wetÔºå the sound that it makes„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_9.png)

The screeching tire and and honking„ÄÇ These are all fascinating signals as well„ÄÇ

 And the focus of the research in our group„ÄÇüòäÔºåThe thing that's really much„ÄÇ

Under investigated is the internal facing sensorsÔºå the driver„ÄÇSensing theÔºå the state of the driver„ÄÇ

 where are they lookingÔºå are they sleepy„ÄÇThe emotional stateÔºå are they in the seat at all„ÄÇ

And the same with audio„ÄÇThat comes from the visual information and the audio information„ÄÇ

More than that„ÄÇHere's the tasksÔºå if you were to break into modules„ÄÇ

 the task of what it means to build a self driving vehicle„ÄÇFirstÔºå you want to know where you are„ÄÇ

 Where am I localization and mappingÔºå You want to map the external environment„ÄÇ

Figure out where all the different obstacles areÔºå all the entities are„ÄÇ

 and use that estimate of the environment to then figure out where I amÔºå where the robot is„ÄÇ

Then there's scene understanding„ÄÇIs understanding not just the positional aspects of the external environment and the dynamics of it„ÄÇ

 but also what those entities are„ÄÇ Is it a carÔºå I it a pedestrianÔºå Is it a bird„ÄÇ

There's movement planning once you have kind of figured out to the best of your abilities„ÄÇ

Your position and the position of other entities in this world that figuring out a trajectory through that world„ÄÇ

AndÔºå finally„ÄÇOnce you've figured out how to move about safely and effectively through that world„ÄÇ

 it's figuring out what the human that's on board is doing„ÄÇ

Because as I will talk about the path to a self driving vehicle„ÄÇ

 and that is hence our focus on Tesla„ÄÇMay go through semi autotonnomous vehicles„ÄÇWhere there is a„ÄÇ

Where the vehicle must not only drive itselfÔºå but effectively hand over control„ÄÇFrom the car„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_11.png)

To the human and back„ÄÇOkayÔºå quick history„ÄÇWellÔºå there's a lot of fun stuff from the '80s and '90s„ÄÇ

The big breakthroughs came in the second DARPA Grand challengeenge„ÄÇWith Stanford Stanley„ÄÇ

 when they won the competitionÔºå one of five cars that finished„ÄÇ

 this was an incredible accomplishment„ÄÇIn a desert race„ÄÇ

A fully autonomous vehicle was able to complete the race„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_13.png)

In record time„ÄÇThe DARPA Urban challengeenge in 2007„ÄÇ

Where the race was the task was no longer a race to the desert„ÄÇBut through a urban environment„ÄÇ

And CMU's boss„ÄÇWould GM won that raceÔºü

![](img/419efdb516c630bd47e1579b4956df18_15.png)

And a lot of that work LED directly into the„ÄÇAcceptance and„ÄÇ

Large major industry players taken on the challenge of building these vehicles„ÄÇGoogleÔºå nowÔºå Waymo„ÄÇ

 self driving car„ÄÇTesla with its autopilot system and not autopilot2 system„ÄÇ

Uber with its testing in Pittsburgh„ÄÇAnd there's many other companies„ÄÇ

 including one of the speakers for this course of Mutonomy„ÄÇThat are„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_17.png)

Driving theÔºå the wonderful streets of Boston„ÄÇOkayÔºå so let's take a step back„ÄÇWe have„ÄÇ

If we think about the accomplishments in the DARPA challenge„ÄÇ

And if we look at the accomplishments of the Google self driving car„ÄÇ

Which essentially boils the world down into a chess game„ÄÇIt„ÄÇ

Uses incredibly accurate sensors to build a three dimensional map of the world„ÄÇ

 localize itself effective in that world and move about that world„ÄÇüòäÔºåIn a very well defined way„ÄÇNow„ÄÇ

 what if driving„ÄÇThe open question isÔºå if driving is more like a conversation„ÄÇ

Like a natural language conversation„ÄÇHow hard is it to pass the touring testÔºå The touring test„ÄÇ

 as the popular current formulation isÔºå can a computer be mistaken for a human being in more than 30% of the time when a human is talking behind a veil having a conversation with either computer or human„ÄÇ

 can they mistake the other side of that conversation„ÄÇFor being a humanÔºå when it'sÔºå in fact„ÄÇ

 a computer„ÄÇAnd„ÄÇThe way you would in a natural language„ÄÇ

 build a system that has successfully passes the touring test is„ÄÇ

The natural language part processing part to enable it to communicate successfully„ÄÇ

 so generate language and interpret language„ÄÇThen you represent knowledge„ÄÇ

 the state of the conversationÔºå transferred over time„ÄÇAnd the last pieceÔºå and this is the hard piece„ÄÇ

 is the automated reasoning„ÄÇIs reasoning„ÄÇCan we teach„ÄÇMachine learning methods to reason„ÄÇThat's„ÄÇ

 that is something that will propagate through our discussion because„ÄÇ

As I will talk about the various methodsÔºå the various deep learning methodsÔºå neural networks„ÄÇ

Are good at learning from data„ÄÇBut they're not yetÔºå there' is no good mechanism for reasoning„ÄÇNow„ÄÇ

 reasoning could be just something that we tell ourselves we do to feel special„ÄÇ

 better to feel like we're better than machines„ÄÇ reasonasoning may be simply„ÄÇüòä„ÄÇ

Something as simple as learning from data„ÄÇWe just need a larger network„ÄÇ

Or there could be a totally different mechanism required„ÄÇ And we'll talk about„ÄÇ

The possibilities there„ÄÇYes„ÄÇGood„ÄÇWith„Å¶ that„ÄÇNoÔºå its it's very difficult to find these kinds of situations in the United States„ÄÇ

 So the question was for this videoÔºå is it in the United States or notÔºå I believe it's in Tokyo„ÄÇ

 so India„ÄÇThere's a few European countries„ÄÇA much„ÄÇAre much more towards the direction of„ÄÇ

Natural language„ÄÇVersus chess„ÄÇIn the United StatesÔºå generally speaking„ÄÇ

 we follow rules more concretely„ÄÇ The quality of roads is better„ÄÇ The marking on the roads is better„ÄÇ

 so there's less requirements there„ÄÇThese cars are driving the left side„ÄÇÏïÑ I see„ÄÇI justÔºå okayÔºå yeah„ÄÇ

 you're right„ÄÇ It is cause yÔºå yeahÔºå soÔºå but it's certainly not the United States„ÄÇ

 I'm pretty it's spent quite a bit of Googling trying to find the United States„ÄÇ And it's„ÄÇ

 it's difficult„ÄÇSoÔºå let's talk about„ÄÇThe recent breakthroughs in machine learning„ÄÇ

 and what is at the core of those breakthroughsÔºüIs neural networks„ÄÇ

That have been around for a long time„ÄÇ And I will talk about what has changed„ÄÇ

 What are the cool new things and what has hasn't changed and what are its possibilities„ÄÇ But first„ÄÇ

 in neuron„ÄÇCrudely„ÄÇIs a computational building block of the brain„ÄÇ I know there's a few folks here„ÄÇ

 neuroscience folks„ÄÇThis is hardly a model„ÄÇIt is mostly an inspiration„ÄÇAnd so„ÄÇThe the human neuron„ÄÇ

Has inspired the artificial neuron„ÄÇThe computational building block of a neural network„ÄÇ

 of an artificial neural network„ÄÇI to give you some context„ÄÇ

These neurons for both artificial and human brains are interconnected„ÄÇIn the human brain„ÄÇ

 there's about„ÄÇI believe 10Ôºå000 outgoing connections from every neuron„ÄÇOn average„ÄÇ

And they're interconnected to each other„ÄÇthe largest currentÔºå as far as I'm aware„ÄÇ

 artificial neural network has 10 billion of those connectionsÔºå synapses„ÄÇ

Our human brain to the best estimate„ÄÇThat I'm aware of„ÄÇHas„ÄÇ10Ôºå000 times that„ÄÇSo„ÄÇ100 to 1„ÄÇ

000 trillion synapses„ÄÇNowÔºå what is a„ÄÇArtificial neuron„ÄÇThe building block of a neural network„ÄÇ

It takes a set of inputs„ÄÇIt puts a weight on each of those inputs„ÄÇSums them together„ÄÇ

Applies a bias value on each that sits on each neuron„ÄÇ

And using an activation function that takes us input„ÄÇ

That sum bless the bias and squishes it together to produce a zero to1 signal„ÄÇ

And this allows us a single neuron„ÄÇTake a few inputs and produces an output„ÄÇA classification„ÄÇ

 for exampleÔºå a 0Ôºå1„ÄÇAnd as we'll talk aboutÔºå simply„ÄÇIt can„ÄÇServe as a linear classifier„ÄÇ

So it can draw a lineÔºå it can learn to draw a line between like what's seen here between the blue dots„ÄÇ

And the yellow dust„ÄÇ And that's exactly what we'll do in the i Python notebook that I'll talk about„ÄÇ

But the basic algorithm is you initialize the weights on the inputs„ÄÇAnd you compute the output„ÄÇ

You performed this previous operation that I talked about sum up„ÄÇCompute the output„ÄÇ

And if the output„ÄÇDoes not match the ground truth„ÄÇThe expected output„ÄÇ

 the output that it should produce„ÄÇThe weights are punished accordingly„ÄÇ

And we'll talk through a little bit of the math„ÄÇOf that„ÄÇ

And this process is repeated until the perceptron„ÄÇDoes not make any more mistakes„ÄÇNowÔºå here's„ÄÇÂïä„ÄÇ

The amazing thing about neural networksÔºå there's several„ÄÇ and I'll talk about them„ÄÇüòäÔºåÂïä„ÄÇOne„ÄÇ

 on the mathematical side„ÄÇIs the universality of neural networks with just a single layer„ÄÇ

 If we stack them togetherÔºå a single hidden layer„ÄÇThe inputs on the leftÔºå the outputs on the right„ÄÇ

And in the middleÔºå there's a single hidden layer It can„ÄÇClosely approximate any function„ÄÇ

Any function„ÄÇSo this is an incredible property„ÄÇThat with a single layer„ÄÇAny function„ÄÇ

You can think of„ÄÇThat„ÄÇYouÔºåYou can think of driving as a function„ÄÇ It takes input„ÄÇ

The world outside is output„ÄÇTo control the vehicle„ÄÇ

 There exists a neural network out there that can drive„ÄÇPerfectly„ÄÇ

It's a fascinating mathematical fact„ÄÇSo we can think of this then these functions as a special purpose function„ÄÇ

 special purpose intelligence„ÄÇ You can take say as input„ÄÇüòäÔºåThe number of bedroomsÔºå the square feet„ÄÇ

Type of neighborhoodÔºå those are the three inputs„ÄÇIt„ÄÇPasses that value through to the hidden layer„ÄÇ

 And then one more stepÔºå it produces the final price estimate for the house„ÄÇFor the residents„ÄÇ

And we can teach a network to do this pretty well in a supervised way„ÄÇ This is supervised learning„ÄÇ

You provide a lot of examples where you know the number of bedroomsÔºå the square feet„ÄÇ

 the type of neighborhood„ÄÇAnd then you'll also know the final price of the house of the residence„ÄÇ

And thenÔºå you can„ÄÇAs I'll talk about through a process of back propagationÔºå teach these networks„ÄÇ

To make this prediction pretty well„ÄÇNowÔºå some of the exciting breakthroughs recently„ÄÇ

Have been in the general purposeÔºå intelligence„ÄÇThis is from Andre Carpathy„ÄÇWho's now at open AI„ÄÇ

I would like„ÄÇTo take a moment hereÔºå to try to explain how amazing this is„ÄÇüòäÔºåThis is a game of pong„ÄÇ

If you're not familiar with Pong„ÄÇThere's two paddles and you're trying to bounce the ball back„ÄÇ

And in such a way that prevents the other guy from balancing the„ÄÇ

 the wall the ball back at you on the„ÄÇThe the artificial intelligence agent is on the right in green and up top is the score„ÄÇ

8 to 1„ÄÇNowÔºå this takes about three days to train on a regular computerÔºå this network„ÄÇWhat is„ÄÇ

This network doingÔºå it's called the policy network„ÄÇThe input is the raw pixels„ÄÇ

They're slightly processed and also you take the difference between two frames„ÄÇ

 but it's basically the raw pixel information„ÄÇThat's the input„ÄÇThere's a few hidden layers„ÄÇ

 and the output is a single probability of moving up„ÄÇThatÔºå that's it„ÄÇ that'sÔºå that's the whole„ÄÇ

 that'sÔºå that's the whole system„ÄÇAnd what it's doing is„ÄÇIt learns„ÄÇ

Not you don't know at any one moment„ÄÇYou don't know what the right thing to do is„ÄÇ Is it to move up„ÄÇ

 Is it to move downÔºå You only know„ÄÇWhat the right thing to do is by the fact that eventually you win or lose the game„ÄÇ

So this is the amazing thing here is there's no supervised learning about„ÄÇ

 there's no like universal fact about any one state being good or bad and any one action being good or bad in any state„ÄÇ

But if you punish or reward every single action you tookÔºå every single action you took„ÄÇ

For entire gameÔºå based on the result„ÄÇSo no matter what you didÔºå if you won the game„ÄÇ

The end justifies the means„ÄÇIf you won the gameÔºå every action you took and every action state pair gets rewarded„ÄÇ

 if you lost the gameÔºå it gets punished„ÄÇAnd this process with only 200„ÄÇ

000 games where the system just simulates the games„ÄÇIt can learn to beat the computer„ÄÇ

This system knows nothing about pongÔºå nothing about games„ÄÇThis is general intelligence„ÄÇ

Except for the fact„ÄÇThat it's just a game of pong„ÄÇAnd I will„ÄÇTalk about how this can„ÄÇ

Be extended further„ÄÇ Why this is so promising„ÄÇAnd why this is also„ÄÇWe should proceed with caution„ÄÇSo„ÄÇ

 again„ÄÇThere's a set of actions you take up downÔºå up down based on the output of the network„ÄÇ

 there's a thresholdÔºå given the probability of moving up„ÄÇ

 you move upward or down based on the output of the network„ÄÇAnd you have a set of states„ÄÇ

And every single state action pair is reward if there's a win and it's punished if there's a loss„ÄÇ

When you go home„ÄÇThink about how amazing that is„ÄÇ And if you don't understand why that's amazing„ÄÇ

Spend some time on it„ÄÇIt's incredible„ÄÇSureÔºå sure thing„ÄÇ The question was what is supervised learning„ÄÇ

 what is unsupervised learningÔºå what's the differenceÔºå So supervised learning„ÄÇ

Is when people talk about machine learningÔºå they mean supervised learning most of the time„ÄÇ

 Supervised learning is„ÄÇLearning from data„ÄÇIt's learning from example„ÄÇ

 when you have a set of inputs and a set of outputs that you know are correct„ÄÇ

 what are called ground truth„ÄÇSo you need those examples„ÄÇ

 a large amount of them to train any of the machine learning algorithms to learn to then generalize that to future examples„ÄÇ

This is„ÄÇActuallyÔºå there's a third one called reinforcement learning„ÄÇWhere the ground truth„ÄÇIs sparse„ÄÇ

 The information about„ÄÇWhen something is good or not„ÄÇ

 the ground truth only happens every once in a while at the end of the gameÔºå not every single frame„ÄÇ

 and unsupervised learning is when you have no information about the outputs that are correct or incorrect„ÄÇ

And it is the excitement„ÄÇThe deep learning community is unsupervised learning„ÄÇ

But it has achieved no major breakthroughs at this point„ÄÇThis is the„ÄÇ

 I'll talk about what the future of deep learning is and a lot of the people that are working in the field are excited by it„ÄÇ

 But right nowÔºå every any interesting accomplishment has to do with supervised learning„ÄÇ

s the green  oneÔºå rightÔºå and the brown one is„ÄÇJust a touristuristic solution like look at the velocity„ÄÇ

So„ÄÇBasicallyÔºå the reinforcement learning here is learning from„ÄÇSomebody who has certain rules„ÄÇ

And how can thatÔºüBe guaranteed that you would generalize to„ÄÇSomebody else„ÄÇÂÜç‰∏ã„ÄÇ

So the question was thisÔºå the green Paddle learns to play this game successfully against this specific one brown paddle with us operating under specific kinds of rules„ÄÇ

 how do we know it can generalize to other gamesÔºå other thingsÔºå and it can't„ÄÇ

But the mechanism by which it learns generalizes„ÄÇSo as long as you let it play„ÄÇ

As long as you let it play in whatever world you want it to succeed in„ÄÇLong enough„ÄÇ

It will use the same approach to learnÔºå to succeed in that world„ÄÇ The problem is„ÄÇ

This works for worlds you can simulate well„ÄÇUnfortunately„ÄÇ

 one of the big challenges of neural networks is that they're not currently efficient learners„ÄÇ

We need a lot of data to learn anything„ÄÇ Human beings need likeÔºå need one example„ÄÇOftentimes„ÄÇ

 and they learn very efficiently from that one example„ÄÇ So„ÄÇAnd againÔºå I'll talk about that as well„ÄÇ

 It's a good question„ÄÇSo the drawbacks of neural networks„ÄÇ

So if you think about the way a human being would approach this game„ÄÇThis game of pong„ÄÇ

 that would only need a simple set of instructions„ÄÇ You're in control of a paddle„ÄÇ

And you can move it up and down„ÄÇAnd your task is to bounce the ball past the other player„ÄÇCon by AI„ÄÇ

NowÔºå the human being would immediatelyÔºå they may not win the game„ÄÇ

 but they would immediately understand the game and will be able to successfully play it well enough„ÄÇ

To pretty quickly learn to beat the game„ÄÇBut they need to have a concept of control„ÄÇ

 what it means to control a paddle„ÄÇ They need to have a concept of a paddle„ÄÇ

 They need to have a concept of moving up and down and a ball and bouncing„ÄÇ

 they have to know they have to have a at least a loose concept of real world physics that they can then project that real world physics onto the two dimensional world„ÄÇ

 All of these concepts are„ÄÇAre concepts that you come to the table withÔºüThat's knowledge„ÄÇ

And the kind of way you transfer that knowledge from„ÄÇFrom your previous experience„ÄÇ

 from childhood to nowÔºå when you come to this game„ÄÇThat is something is called reasoning„ÄÇ

Whatever reasoning means„ÄÇAnd the question is whether through this same kind of process„ÄÇ

You can see the entire world„ÄÇAs a game of pong„ÄÇAnd reasoning is simply ability to simulate„ÄÇ

That game in your mind„ÄÇAnd learned very efficientlyÔºå much more efficiently than 200000 iterations„ÄÇ

The other challenge of deep neural networks and machine learning broadly is you need big data„ÄÇ

 and efficientient learners I„ÄÇThat data also needs to be supervised data„ÄÇ

 You need to have ground truth„ÄÇWhich is very costly for„ÄÇTo annotation„ÄÇ

A human being looking at a particular imageÔºå for example„ÄÇ

 and labeling that as something as a cat or a dogÔºå whatever objects is in the image„ÄÇ

 that's very costly„ÄÇAnd for particularly for neural networksÔºå there's a lot of„ÄÇParameters to tune„ÄÇ

There's a lot of hyperparameters„ÄÇ You need to figure out„ÄÇThe network structure first„ÄÇ

 how does this network lookÔºå how many layersÔºå how many hidden nodesÔºü

What type of activation functions on each nodeÔºå there's a lot of hyper parameters there„ÄÇ

 and then once you built your network„ÄÇThere is parameters for how you teach that network„ÄÇ

 There's learning rateÔºå loss functionÔºå mini batch sizeÔºå number of training iterations„ÄÇ

 gradient updates smoothing„ÄÇAnd the selecting even the optimizer with which you„ÄÇWith which it is„ÄÇ

Solve the various differential equations involved„ÄÇIt's a topic of many research papers„ÄÇ

 certainly it's rich enough for research papersÔºå but it's also really challenging„ÄÇ

It means that you can't just plop the network down and it will solve the problem generally„ÄÇ

And defining a good„ÄÇ

![](img/419efdb516c630bd47e1579b4956df18_19.png)

Loss function„ÄÇ or in the case of pong or gamesÔºå a good„ÄÇReward function is difficult„ÄÇ

 So here's a game„ÄÇ This is a recent result from open AI„ÄÇ

And teaching a network to play the game of coast runners and the goal of coast runners„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_21.png)

![](img/419efdb516c630bd47e1579b4956df18_22.png)

Is to go you're in a boatÔºå the task is to go around a track„ÄÇ

And successfully complete a race against other people you're racing against„ÄÇ

Now this network is an optimal one„ÄÇAnd what has figured out that actually in the game„ÄÇ

It gets a lot of points for collecting certain objects along the path„ÄÇ

 So what you see is it's figured out to go in a circle and collect those green turbo things„ÄÇ

And what is figured out is you don't need to complete the game to earn the reward„ÄÇüò°ÔºåNow„ÄÇ

 that more sort of„ÄÇand despite being on fire and hitting the wall and going through this whole process„ÄÇ

 it's actually achieved at least a local optimaÔºå given the reward function of maximizing the„ÄÇ

 the number of points„ÄÇAnd so„ÄÇIt's figured out a way to earn a higher award while ignoring the implied bigger picture goal of finishing the race„ÄÇ

 which us as humans„ÄÇUnderstand much better„ÄÇThis raises for self driving cars ethical questions„ÄÇ

Besides other questions„ÄÇYou can watch this for hours„ÄÇAnd it will do that for hours„ÄÇ

 and that's the point is„ÄÇ

![](img/419efdb516c630bd47e1579b4956df18_24.png)

it's hard to teach„ÄÇIt's hard to encode„ÄÇFormerly define a utility function under which an intelligence system needs to operate„ÄÇ

 And that's made obviousÔºå even in a simple game„ÄÇAnd so what is yepÔºå questionÔºü„Åä„Å≥„ÄÇSo the question was„ÄÇ

 what's an example of a local optimum that an autonomous car so similar to the coast race so what would be the example in the real world for an autonomous vehicleÔºü

And„ÄÇIt's a touchy subject„ÄÇBut it would certainly have to be involved„ÄÇ

The choices we make under near crashes and crashesÔºå the choices a car makes want to avoid„ÄÇ

 for exampleÔºå if there's a crash imminent and there's no way you can stop„ÄÇJust prevent the crash„ÄÇ

 do you keep the driver safe or do you keep the other people safeÔºüAnd„ÄÇThere has to be„ÄÇSome„ÄÇ

EvenEven if you don't choose to acknowledge it„ÄÇEven if it's only in the data and the learning that you do„ÄÇ

 there is an implied reward function there„ÄÇAnd we need to be aware of that award function is because it may It may find something until you actually see it„ÄÇ

 we won't know it„ÄÇ Once we see itÔºå we'll realize thatÔºå oh„ÄÇThat was a bad design„ÄÇ

 And that's a scary thing„ÄÇ It's hard to know ahead of time what that is„ÄÇ

So the recent breakthroughs from deep learning„ÄÇCame„ÄÇSeveral factors„ÄÇ First is the compute„ÄÇ

Moore's lawÔºå CPUs are getting fasterÔºå100 times faster every decade„ÄÇThen there's GPUs„ÄÇAlso„ÄÇ

 the ability to train neural networks and GPUs„ÄÇAnd nowÔºå a6„ÄÇ

Has has created a lot of capabilities in terms of energy efficiency and being able to train larger networks more efficiently„ÄÇ

There is larger„ÄÇ WellÔºå first of allÔºå in theÔºå in the 21st centuryÔºå there's digitized data„ÄÇ

There's larger data sets of digital data„ÄÇAnd now there is that data is becoming more organized„ÄÇ

 not just vaguely available data out there on the Internet„ÄÇ

 It's actual organized data sets like InetÔºå certainly for natural language there's large data sets„ÄÇ

There is the algorithm innovations„ÄÇBack back propagationÔºå conution neural networksÔºå LSTMs„ÄÇ

 all these different architectures for dealing with specific types of domains and tasks„ÄÇ

There's the huge one„ÄÇIs infrastructure is on the software and the hardware side„ÄÇ

 there's Git ability to share an open source way software„ÄÇThere is pieces of software that„ÄÇ

That make robotics and make machine learning easier„ÄÇ RossÔºå Tensorflow„ÄÇ

 Theres an Amazon mechanical Turk„ÄÇWhich allows for efficient„ÄÇ

 cheap annotation of large scale data sets„ÄÇIt's AWS in the cloud hosting machine learning„ÄÇ

 hosting the data and the compute„ÄÇAnd then there's a financial backing of large companiesÔºå Google„ÄÇ

 FacebookÔºå Amazon„ÄÇButÔºå really„ÄÇNothing has changedÔºå there really has not been any significant breakthroughs we're using the accomplished neural networks have been around since the '90s„ÄÇ

 neural networks have been around since the 60s„ÄÇThere's been a few improvements„ÄÇBut the hope is„ÄÇ

 that's in terms of methodology„ÄÇThe compute has really been the workhorse„ÄÇ

The ability to do the hundred fold improvement every decade„ÄÇholdss promise„ÄÇ

 And the question is whether that reasoning thing I talked about„ÄÇAll you need is a larger network„ÄÇ

 that is the open question„ÄÇSo some terms„ÄÇFor deep learning„ÄÇFirst of all„ÄÇDeep learning is a PR term„ÄÇ

For neural networks„ÄÇIt is a term for utilizing„ÄÇ its for„ÄÇFor deep neural networks„ÄÇ

 for neural networks that have many layers„ÄÇIt a symbolic term for the newly gained capabilities that compute has brought us„ÄÇ

ThatÔºå that training on GPUus brought us„ÄÇSo deep learning is a subset of machine learning„ÄÇ

 There's many other methods that are still effective„ÄÇThe terms that they'll come up in this class„ÄÇ

First of allÔºå multi layerer perceptronÔºå deep neural networksÔºå recurring neural networksÔºå LSTM„ÄÇ

 long short term memory networksÔºå CNN or convnetsÔºå convolutional neural networks„ÄÇ

Deep belief networks„ÄÇ And the operation thatll come up as convolutionÔºå pooling„ÄÇ

 activation functions and back propagation„ÄÇ

![](img/419efdb516c630bd47e1579b4956df18_26.png)

![](img/419efdb516c630bd47e1579b4956df18_27.png)

Ôºå good question„ÄÇSo the question wasÔºå what is the purpose of the different layers in your neural network„ÄÇ

 what does it mean to have one configuration versus anotherÔºüSo a neural network„ÄÇ

So having several layers„ÄÇIt's the only thing you have an understanding of is the inputs and the outputs„ÄÇ

You don't have a good understanding about what each layer does„ÄÇ

There are mysterious things neural networks„ÄÇSo I'll talk about how with every layer„ÄÇ

 it forms a higher level„ÄÇA higher order representation of the input„ÄÇ

 so it's not like the first layer does localizationÔºå the second layer does path planning„ÄÇ

 the third layer does navigationÔºå how you get from here to Florida„ÄÇOr maybe it does„ÄÇ

But we don't know„ÄÇSo we know we're beginning to visualize neural networks„ÄÇFor simple tasks„ÄÇ

 like for imagenet classifying cats versus dogs„ÄÇ we can tell what is the thing that the first layer does„ÄÇ

 the second layerÔºå the third layer„ÄÇ And we'll look at that„ÄÇ But for drivingÔºå when you„ÄÇ

 as the input provide just the images and the outputÔºå the steering„ÄÇIt's still unclear what you learn„ÄÇ

Partially because we don't have neural networks that drive successfully yet„ÄÇYeah„ÄÇ

The neuro network fillsÔºå or does it eventually generate theÔºüSo this this is the question wasÔºåDo you„ÄÇ

Does a neural network generate layers over timeÔºå like does it growÔºü

that's one of the challenges is that a neural network is predefined the architectures„ÄÇ

 the number of nodesÔºå the number of layersÔºå that's all fixed„ÄÇ

Unlike the human brain where neurons die and are born all the time„ÄÇneural network is prespecified„ÄÇ

 That's it„ÄÇ That's all you get„ÄÇ And if you want to change that„ÄÇ

 you have to change that and then retrain everything„ÄÇSoÔºå it's fixed„ÄÇ

So what I encourage you is to proceed with cautionÔºå because there's this feeling when you first„ÄÇ

Teach a network with very little effort how to do some amazing tasksÔºå like classify a face„ÄÇ

Versus non face or your face versus other faces or cats versus dogs„ÄÇ it's an incredible feeling„ÄÇ

And then youÔºå there'sÔºå there's definitely this feeling that I'm an expert„ÄÇBut what you realize is„ÄÇ

ItIt's„ÄÇYou don't actually understand how it works„ÄÇAnd getting it to perform well for more generalized tasks„ÄÇ

 for larger scale data setsÔºå for more useful applications requires a lot of hyperparameter tuning„ÄÇ

 figuring out how to tweak little things here and thereÔºå and still in the end„ÄÇ

 you don't understand why it works so damn well„ÄÇSoÔºå deep learning„ÄÇ

These deep neural network architectures is representation learning„ÄÇ

This is the difference between traditional machine learning methods„ÄÇWhere„ÄÇFor example„ÄÇ

 for the task of„ÄÇHaving an image here is the inputÔºå the input to the networks here is on the bottom„ÄÇ

 the output is up at top„ÄÇ and the input is a single image„ÄÇOf a person in this case„ÄÇAnd so„ÄÇThe input„ÄÇ

 specifically„ÄÇIs all of the pixels in that imageÔºå RGB„ÄÇ

 the different colors of the pixels in the image„ÄÇAnd over time„ÄÇ

What what a network does is build multireal representation of this data„ÄÇThe first layer„ÄÇBuilds„ÄÇ

 learns the concept of edgesÔºå for example„ÄÇThe second layer starts to learn composition of those edges„ÄÇ

 cornersÔºå contours„ÄÇThen it starts to learn about object parts„ÄÇAnd finally„ÄÇ

 actually provide a label for the entities that are in the input„ÄÇ

And this is the difference between traditional machine learning methods„ÄÇ

 where the concepts like edges and corners and contours are manually prespecified by human„ÄÇ

By human beingsÔºå human experts for this particular domain„ÄÇAnd representation matters„ÄÇBecause„ÄÇ

Figuring out a line for the Cartesian coordinates of this particular data„ÄÇ

Where you want to design a machine learning system that tells the difference between green triangles and blue circles„ÄÇ

Is difficult„ÄÇThere's no line that separates them cleanly„ÄÇAnd if you were to ask a human being„ÄÇ

 a human expert in the field to try to draw that line„ÄÇThey would probably do a PhD on it„ÄÇ

And still not succeed„ÄÇBut„ÄÇA neural network can automatically figure out„ÄÇTo remap that input„ÄÇ

Into polar coordinatesÔºå where the representation is such that it's an easily linearly separable data set„ÄÇ

And so deep learning is a subset of representation learningÔºå is a subset of machine learning„ÄÇ

 and a key subset of artificial intelligence„ÄÇNowÔºå because of this„ÄÇ

Because of its ability to compute an arbitrary number of features at the core of the representation„ÄÇ

 So you're not if you're trying to detect a cat in an image„ÄÇ

You're not specifying 215 specific features of cas and whiskers and so on that a human expert would specify„ÄÇ

You allow a neural network to discover tens of thousands of such features„ÄÇWhich maybe for cats„ÄÇ

 you are an expert„ÄÇ But for a lot of objectsÔºå you may never be able to sufficiently provide the„ÄÇ

The features which successfully would be used for identifying the object„ÄÇ

And so this kind of representation learningÔºå one is easy in the sense that all you have to provide is inputs and outputs„ÄÇ

 all you need to provide is a data set that you care about without hand engineering features„ÄÇAnd two„ÄÇ

 because of the„ÄÇIts ability to construct arbitrarily sized representations„ÄÇ

Jeep neural networks are hungry for data„ÄÇ The more data we give them„ÄÇ

 the more they're able to learn about this particular data set„ÄÇSoÔºå let's look at some„ÄÇApplications„ÄÇ

First„ÄÇSome cool things that deep neural networkss have been able to accomplish up to this point„ÄÇ

 Let me go through them„ÄÇFirstÔºå the basic one„ÄÇAlex Ne„ÄÇI for Iagenet is a famous„ÄÇData set„ÄÇ

 and it's a competition of classification and localization where the task is given an image„ÄÇ

 identify what are the five most likely things in that image and what is the most likely and you have to do so correctly„ÄÇ

 So on the rightÔºå there's an image of a leopard and you have to correctly classify that that is in fact„ÄÇ

 a leopard„ÄÇSo they're able to do this pretty well„ÄÇGiven a specific image„ÄÇDetermine that„ÄÇ

 it's a leopard„ÄÇAnd„ÄÇWe started what's shown here on the X axis is years on the Y axis is error in classification„ÄÇ

So starting from 2012 on the left with Alex Ne„ÄÇAnd today„ÄÇThe error is decreased„ÄÇFrom 16%„ÄÇ

And 40% before thenÔºå with traditional methods have decreased to below 4%„ÄÇ So human level performance„ÄÇ

 if I were to give you„ÄÇThis picture of a leopard is a 44% for 4% of those pictures of leopards„ÄÇ

 you would not say it's a leopard„ÄÇ That's human level of performance„ÄÇ So for the first time in 2015„ÄÇ

 convolution neural networks outperform human beings„ÄÇ That in itself is an incredible„ÄÇ

 That's something that seemed impossible„ÄÇ And now is because it's done„ÄÇIts not as impressive„ÄÇ

But I just want to get to why that's so impressive because„ÄÇ

Computer vision is hard that we as human beings have evolved visual perception over millions of years„ÄÇ

 hundreds of millions of years„ÄÇSo we take it for grantedÔºå but computer vision is really hard„ÄÇ

 Vis perception is really hard„ÄÇ There is illumination variability„ÄÇ So it's the same object„ÄÇ

The only way we tell anything is from the shade the reflection of light from that surface„ÄÇ

It it could be the same object drastically in terms of pixelsÔºå drastically different looking shapes„ÄÇ

And we still know it's the same object„ÄÇThere is pose variability and occlusions„ÄÇ

Probably my favorite caption for an image for a figure in a academic paper is deformable and truncated cat„ÄÇ

These are pictures„ÄÇ You knowÔºå cats are famously„ÄÇAre deformable„ÄÇ

 they can take a lot of different shapes„ÄÇIt arbitrary poses are„ÄÇAre possible„ÄÇ

 So you have to have computer vision used to know still the same object„ÄÇ

 still the same class of objectsÔºå given all the variability in the post and occlusions iss a huge problem„ÄÇ

 We still know it's an object„ÄÇWe still know it's a cat„ÄÇ

 even when parts of it are not visible and sometimes large parts of it are not visible„ÄÇ

And then there's all the intra class variability„ÄÇIn interclass„ÄÇ

 all of these on the top two rows are catsÔºå many of them look drastically different„ÄÇ

 and the top bottom two rows are dogs also look drastically different„ÄÇAnd yet„ÄÇ

 some of the dogs look like catsÔºå some of the cats look like dogs„ÄÇ

 And as human beings we' pretty good at telling a difference„ÄÇ

 and we want computer vision to do better than that„ÄÇIt's hard„ÄÇSo how is this done„ÄÇ

 This is done with convolution neural networksÔºå The input to which is a raw image„ÄÇ

 Here is an input on the left„ÄÇOf number 3„ÄÇAnd I'll talk about through convolutional layers„ÄÇ

That image is processed passed throughÔºå convolutional layersÔºå maintain spatialal information„ÄÇ

On the outputÔºå they in this case predicts which of the imagesÔºå what number is shown in the imageÔºå 0„ÄÇ

1Ôºå2 through 9„ÄÇAnd so these networksÔºå this is exactly everybody is using the same kind of network to determine exactly that input is an image„ÄÇ

 output is a number„ÄÇAnd in the case of probability that it's a leopardÔºå what is that numberÔºü

Then there's segmentation built on top of these convolution neural networks where you chop off the end„ÄÇ

And convolutionize the networkÔºå you chop off the end where the output is a heat map„ÄÇ

So you can have instead of a detector for a catÔºå you can do a cat heat map„ÄÇWhere its„ÄÇ

The part of the imageÔºå the output heat map gets excited„ÄÇ

 the neurons on that output get excited and the spatially excited in the parts of the image that contain a tabbyca„ÄÇ

And this kind of process can be used to segment the image into different objectsÔºå a horse„ÄÇ

 so the original input on the left is a woman on a horse„ÄÇ

 and the output is a fully segmented image of knowing where's the womanÔºå where's the horse„ÄÇ

And this kind of process can be used for object detection„ÄÇ

 which is the task of detecting an object in an image„ÄÇNow„ÄÇ

 the traditional methods accomplish neural networks and in general in computer vision is the sliding window approach„ÄÇ

 where you have a detector like the leopard detector that you slide through the image to find where in that image is a leopard„ÄÇ

The segmenting approachÔºå the RCNN approach„ÄÇIs efficiently segment the image in such a way that it can propose different parts of the image that are likely to have a leopard or in this case„ÄÇ

 a cowboy„ÄÇAnd that drastically reduces the computational requirements of the object detection task„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_29.png)

And soÔºå these networksÔºå this is the currently one of the best networks for the imagenet task of localization is the deep deep residual networks„ÄÇ

They're deep„ÄÇSoÔºå VD G 19„ÄÇIts one of the famous ones„ÄÇ V G G nu„ÄÇYou starting to get above 20 layers„ÄÇ

 in many casesÔºå 34 layers is the renet one„ÄÇSo the lesson there is the deeper you go„ÄÇ

 the more representational power you haveÔºå the higher accuracy„ÄÇBut you need more data„ÄÇ

Other applicationsÔºå colorization of images„ÄÇSoÔºå thisÔºå again„ÄÇInput is a single image„ÄÇ

 and an output is a single image„ÄÇSo you can take a black and white video from a film„ÄÇ

From an old film and recolor it„ÄÇAnd all you need to do to train that network in a supervised way is provide modern films„ÄÇ

And convert them to gray scale„ÄÇ So now you have arbitrarily sized data sets„ÄÇ

That are able to data sets of gray scale to color„ÄÇAnd you're able to with very„ÄÇ

With very little effort on top of it to successfullyÔºå wellÔºå somewhat successfully recolor images„ÄÇ

AgainÔºå Google Translate does image translation in this way„ÄÇImage to image„ÄÇ

It first perceives here in GermanÔºå I believe„ÄÇFamous GermanÔºå correct me if I'm wrong„ÄÇ

 dark chocolate written a German on a box so this can take this imageÔºå detect the different letters„ÄÇ

 convert them to textÔºå translate the textÔºå and then using the image to image mapping„ÄÇMap the letters„ÄÇ

 the translated letters back onto the boxÔºå and you can do this in real time„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_31.png)

On video„ÄÇSo what we've talked about up to this point on the left are vanilla neural networks„ÄÇ

 common neural networks„ÄÇThat map a single input to a single outputÔºå a single image to a number„ÄÇ

 single image to another image„ÄÇThen there is our current neural networksÔºå the map„ÄÇ

 this is the more general formulationÔºå the map a sequence of images or a sequence of words or a sequence of any kind to another sequence„ÄÇ

And these networks are able to do incredible things with natural language„ÄÇWith with video„ÄÇ

And anytime series dataÔºå for exampleÔºå we can convert text to handwritten digits„ÄÇ

With handwritten text„ÄÇHere we type in„ÄÇAnd you can do this online„ÄÇ

 type in deep learning for self driving carsÔºå and it will use an arbitrary handwriting style to generate the words deep learning for self driving cars„ÄÇ

This is done using recur on neural networks„ÄÇWe can also take car R N Ns„ÄÇ

 They're called It character level recurren neural networks that train on a data„ÄÇ

At an arbitrary text dataset set„ÄÇAnd learn to generate„ÄÇTextÔºå one character at a time„ÄÇ

So there is no preconceivedÔºå syntacticalÔºå semantic structure that's provided to the network„ÄÇ

 It learns that structure„ÄÇSoÔºå for exampleÔºå you can train it on Wikipedia articlesÔºå like in this case„ÄÇ

And it's able to generate successfully„ÄÇNot only text that makes„ÄÇSome kind of grammatical sense„ÄÇ

 at least„ÄÇBut alsoÔºå keep perfect syntactic structure for WikipediaÔºå for markdown„ÄÇ

Eiting for latex editingÔºå and so on„ÄÇThis text says naturalism a decision for the majority of Arab countries„ÄÇ

 CapitalizedÔºå whatever that means was grounded by the Irish language by John Clare and so on„ÄÇ

 These are sentences„ÄÇ If you didn't know better that might sound correct„ÄÇ And it does so„ÄÇ

 let me pause one character at a time„ÄÇSo there isÔºå these aren't words being generated„ÄÇ

 This is one character„ÄÇ You start with the beginning three lettersÔºå not„ÄÇYou generate you completely„ÄÇ

Without knowing of the word naturalism„ÄÇThis is incredible„ÄÇYou can do this„ÄÇ

To start a sentence and let the neural know will complete that sentence„ÄÇSoÔºå for example„ÄÇ

 if you start the sentence with life is„ÄÇOr life is aboutÔºå actually„ÄÇ

It will complete it with a lot of fun things„ÄÇ The weatherÔºå life is about kids„ÄÇ

Life is about the true love of Mr„ÄÇ mom„ÄÇIs about the truth now„ÄÇAnd this is from Jeffrey Hidden„ÄÇ

 the last two„ÄÇ If you start with the meaning of life„ÄÇ

It can complete that with the meaning of life is literary recognition„ÄÇ

 maybe true for some of us here„ÄÇPublish a parish„ÄÇAnd the meaning of life is the tradition of ancient human reproduction„ÄÇ

Also true for some of us hereÔºå I'm sure„ÄÇOkayÔºå so what else can you do„ÄÇ

 You can This has been very exciting recently is image caption recognition„ÄÇ generationÔºå I'm sorry„ÄÇüòä„ÄÇ

Image caption generation is important for„ÄÇFor large data sets of images where we want to be able to determine what's going on inside those images„ÄÇ

 especially for searchÔºå if you want to find a man sitting in a couch with a dog„ÄÇ

 you type it into Google and it's able to find that„ÄÇSo here shown in in black text„ÄÇ

 a man sitting on a couch with a dog is generated by the system„ÄÇ

 A man sitting in a chair with a dog in his lap is generated by a human observer„ÄÇAnd again„ÄÇ

 these annotations are done by detecting the different obstaclesÔºå the different objects in the scene„ÄÇ

 So segmenting the sceneÔºå detecting on the rightÔºå there's a womanÔºå a crowdÔºå a catÔºå a cameraÔºå holding„ÄÇ

 you knowÔºå purple„ÄÇ All of these words are being detected„ÄÇ

Then a syntactically correct sentence is generated a lot of them„ÄÇ

 and then you order which sentence is the most likely„ÄÇ And in this way„ÄÇ

 you can generate very accurate labeling of the images„ÄÇCaptions for the images„ÄÇ

 And you could do the same kind of process for„ÄÇImage question answering„ÄÇ

You can ask how many- so quantityÔºå how many chairs are thereÔºüYou can ask about location„ÄÇ

 where are the right bananasÔºüYou can ask the ball the type of object„ÄÇ

 what is the object on the chairÔºå it's a pillow„ÄÇAnd these areÔºå again„ÄÇ

 using the recurrent neural networks„ÄÇYou could do the same thing with video caption generation„ÄÇ

 video caption description generation„ÄÇ So looking at a sequence of images as opposed to just a single image„ÄÇ

What is the action going on in thisÔºå in this situationÔºå This is the difficult task„ÄÇ

 There's a lot of work in it in this area„ÄÇ Now on the left is correct description„ÄÇ

 of a man is doing stunts on his bikeÔºå a herd of zebras They're walking in the field„ÄÇ

 And on the rightÔºå there's a small bus running into a building„ÄÇYou knowÔºå it's talking about„ÄÇ

Relevant entitiesÔºå but just doing an incorrect description„ÄÇ A man is cutting a piece of„ÄÇ

A piece of a pair of a paper„ÄÇIt's cutting a piece of a pair of a paper„ÄÇ So the words are correct„ÄÇ

PerhapsÔºå but so you're close„ÄÇBut„ÄÇNo cigar„ÄÇ So one of the interesting things„ÄÇ

You can do with the recurrent neural networks is if you think about the way we look at images„ÄÇ

 human beings look at images isÔºå is we only have a small fovea with which we focus onÔºå in the scene„ÄÇ

 So right nowÔºå your periphery is very distorted„ÄÇ The only thing if you're looking at the slides„ÄÇ

 Are you're looking at me„ÄÇ That's the only thing that's in focus„ÄÇ

Majority of everything else is out of focus„ÄÇ So we can use the same kind of concept to try to teach a neural network to steer around the image„ÄÇ

 both for perception and generation of those images„ÄÇ This is important first„ÄÇ

 on the general artificial intelligence point of it being just fascinating„ÄÇ

That we can selectively steer our attention„ÄÇ But also„ÄÇ

 it's important for things like drones that have to fly at high speeds in an environment where at 300 plus frames of second„ÄÇ

 you have to make decisions So you can't possibly localize yourself or perceive the world around yourself successfully„ÄÇ

If you have to interpret the entire scene„ÄÇ So what you can do is you can steerÔºå for example„ÄÇ

 here shown is„ÄÇReading reading house numbers„ÄÇBy steering around an image„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_33.png)

You could do the same task for reading and for writing„ÄÇ

 So reading numbers here on the Ms data set on the left is reading numbers„ÄÇ

 but you can also selectively steer a„ÄÇThe steer network around an image to generate that image„ÄÇ

 starting with a blurred image first and then getting more and more„ÄÇ

Higher resolution as the steering goes on„ÄÇWork here at MI T is able to„ÄÇMap„ÄÇVideo to audio„ÄÇ

So head stuff with the drumstick„ÄÇSilent video and able to generate the sound„ÄÇ

That would drumtick hitting that particular object makes„ÄÇSo you can get texture information„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_35.png)

From that impact„ÄÇSo here's a video of a human soccer player playing soccer and a„ÄÇStated of the art„ÄÇ

Machine playing soccer„ÄÇAnd wellÔºå let me give them some time„ÄÇTo build up„ÄÇOkayÔºå so soccer„ÄÇ

 this is we take this for grantedÔºå but walking is hard„ÄÇObject manipulation is hard„ÄÇ

 Soccer is harder than chess for us to do much harder„ÄÇOn your phone nowÔºå you haveÔºå you„ÄÇ

 you can have a chess engine that beats the best players in the world„ÄÇ

And you have to internalize that„ÄÇ

![](img/419efdb516c630bd47e1579b4956df18_37.png)

Because the question isÔºå this is a painful video„ÄÇ But the question is„ÄÇWhere does driving fall„ÄÇ

 Is it closer to chess or is it closer to soccer„ÄÇFor those incredible„ÄÇ

 brilliant engineers that worked on the most recent DARPA challenge„ÄÇ

 this will be a very painful video to watchÔºå I apologize„ÄÇThis is a video from the DARPA Challenge„ÄÇ

Of robots struggling„ÄÇWith the basic object manipulation and walking tasks„ÄÇSoÔºå it's„ÄÇ

It's mostly a fully autonomous navigation task„ÄÇMaybe I'll just let this play a for a few moments„ÄÇ

To let it internalize how difficult this task is„ÄÇOf balancing„ÄÇ

Of planning in an under actuated way where you don't have full control of everything when„ÄÇ

 when there is a delta between your perception of what you think the world is and what the reality is„ÄÇ

So thereÔºå a robot was trying to turn„ÄÇAn object„ÄÇThat wasn't there„ÄÇ

And this is an M T entry that actually successfullyÔºå I believeÔºå gotten points for this because it„ÄÇ

Got into that area„ÄÇBut as a lot of the teams talked about the hardest part„ÄÇ

 so one of the things the robot had to do is get into a car and drive it„ÄÇAnd get out of the car„ÄÇ

 And there's a few other manipulation tasks where to walk in on on steady ground„ÄÇ

 it had to drill a hole through a wallÔºå all of these tasks„ÄÇ

 And what a lot of teams said is the hardest part„ÄÇ the hardest task of all of them is getting out of the car„ÄÇ

So it's not getting into the car„ÄÇ It's this very task that you saw now is is is a robot getting out of the car„ÄÇ

 These are things we take for granted„ÄÇSo in our evaluation of what is difficult about driving„ÄÇ

 we have to remember„ÄÇThat some of those things we may take for granted in the same kind of way that we take walking for granted„ÄÇ

This is this is more of X„ÄÇParadox„ÄÇWith Hans Moreak from CMU„ÄÇ

Let me just quickly read that quote and quod the large„ÄÇ

 highly evolved sensory and motor portions of the human brain is billions of years of experience about the nature of the world and how to survive in it„ÄÇ

 So this is data„ÄÇ This is big data„ÄÇBillions of years„ÄÇAn abstract thoughtÔºå which is reasoning„ÄÇ

The stuff we think is intelligence„ÄÇIs perhaps less than 100000 years„ÄÇOf dataÔºå old„ÄÇ

We haven't yet mastered it„ÄÇSorryÔºå I'm inserting my own statements in the middle of a quote„ÄÇ

WeItt it's been very recent that we've learned how to think„ÄÇAnd so we respected perhaps more„ÄÇ

Then the things we take for grantedÔºå like walking a visual perception and so on„ÄÇ

 But those may be strictly a matter of data„ÄÇData and training time„ÄÇAnd network size„ÄÇ

So walking is hard„ÄÇThe question isÔºå how hard is drivingÔºü

And that's an important question because the margin of error is small„ÄÇOneÔºåThere's one fatality„ÄÇ

Per100 million milesÔºå that's the number of people that die in car crashes every year„ÄÇ

One fatality per 100 million miles„ÄÇThat's a 0000Ôºå001% margin of error„ÄÇ

 That's through all the time you spent on the roadÔºå That is the error you get„ÄÇ

 We're impressed with INe being able to classify a leopard a cat or a dog„ÄÇAnd close to„ÄÇ

At above human level performanceÔºå but this is the margin of error we get withre driving„ÄÇ

And we have to be able to deal with snowÔºå with heavy rainÔºå with big open parking lots„ÄÇ

 with parking garagesÔºå any pedestrians that behave irresponsibly as rarely as that happens„ÄÇ

Or just unpredictablyÔºå againÔºå especially in Boston„ÄÇReflections„ÄÇThe ones„ÄÇ

 especially this is one of some of the things you don't think about„ÄÇ

 the lighting variations that blind the cameras„ÄÇThe question was if that number changes„ÄÇ

 if you look at just crashesÔºå so fatalities per crash„ÄÇCashes per„ÄÇYeah„ÄÇ

 so one of the big things is cars have gotten really good at crashing and not hurting the anybody„ÄÇ

So the number of crashes is muchÔºå much larger than the number of fatalities„ÄÇ

 which is a great thing we've built safer cars„ÄÇBut stillÔºå even one fatality is too many„ÄÇSo this is„ÄÇ

OneÔºå oneÔºå the Google self driving car team„ÄÇIs quite open about„ÄÇ

Their performance since hitting public roads„ÄÇ This is from a report that shows the number of times„ÄÇ

The driver disengaged the car„ÄÇGives up control„ÄÇThat it asks the driver to take control back or the driver takes control back by force„ÄÇ

 meaning that they're unhappy with the decision that the car was making or it was putting the car or other pedestrians or other cars in unsafe situations and so if you see over time that there's been a total from 2014 to 2015„ÄÇ

There's been a total of 341 times on beautiful San Francisco roads„ÄÇ

 And I say that seriously because the weather conditions are great there„ÄÇ

341 times that the driver had to elect to take control back„ÄÇSo it's a work in progress„ÄÇ

AndLet me give you something to think about here„ÄÇThis with neural networks is„ÄÇA big open question„ÄÇ

 the question of robustness„ÄÇSo this is an amazing paper„ÄÇ I encourage people to read it„ÄÇ There's„ÄÇ

 there's a couple papers around this topic„ÄÇ Deep neural networks are easily fooled„ÄÇüòäÔºåSo„ÄÇ

Here are eight images„ÄÇWhere if given to a neural network as input„ÄÇ

 a convolutional neural network is input„ÄÇThe network with higher than 99„ÄÇ6% confidence„ÄÇ

Says that the imageÔºå for exampleÔºå on the top left is a robin„ÄÇNext to is a cheetahÔºå then an armadillo„ÄÇ

 a pandaÔºå an electric guitarÔºå a baseballÔºå a starfishÔºå a king penguin„ÄÇ

All of these things are obviously not in the imagesÔºå so networks can be fooled with noise„ÄÇ

More importantlyÔºå more„ÄÇPractically for the real world„ÄÇAdding just a little bit of distortion„ÄÇ

 a little bit of noise distortion to the image„ÄÇCan„ÄÇ

Forcce the network to produce a totally wrong prediction„ÄÇ So here is an example„ÄÇ

 there's three columnsÔºå correctect image classification„ÄÇThis slight addition of distortion„ÄÇ

And the resulting prediction of an ostrich for all three images on the left„ÄÇ

And a prediction of an ostrich for all three images on the right„ÄÇ

This ability to fool networks easily„ÄÇBrings up an important point„ÄÇAnd that point is that„ÄÇ

That there has been„ÄÇA lot of„ÄÇExcitement„ÄÇAbouttan neural networks throughout their history„ÄÇ

 There's been a lot of excitement about artificial intelligence throughout its history„ÄÇAnd„ÄÇ

Not coupling that excitementÔºå not grounding that excitement in the reality„ÄÇ

The real challenges around that„ÄÇHas resulted in„ÄÇIn crashes„ÄÇIn AI winters„ÄÇ

When funding dried out and people became hopeless in terms of the possibilities of artificial intelligence„ÄÇ

 So here' is the 1958 New York Times article that said the Navy revealed the embryo of an electronic computer today„ÄÇ

 This is when the firstcept perceptron that I talked about was implemented in hardware by Frank Rosenblt„ÄÇ

It took 400 pixel image input„ÄÇAnd it provided a single output„ÄÇWeights were encoded in hardware„ÄÇ

 potentoomesÔºå and weights were updated with electric motors„ÄÇNowÔºå New York Times wrote„ÄÇ

 the Navy revealed the embryo of an electronic computer today„ÄÇThat expects we'll be able to walk„ÄÇ

 talkÔºå seeÔºå writeÔºå reproduce itself„ÄÇAnd be conscious of its existence„ÄÇDr„ÄÇ Frank Rosenblatt„ÄÇ

 a research psychologist at the Cornell Aeronautical Laboratory Buffalo„ÄÇ

 said perceptrons might be fired to the planets as mechanical space explorers„ÄÇ

This might seem ridiculousÔºå but this was the general opinion of the time„ÄÇAnd as we know now„ÄÇ

 perceptrons„ÄÇCannot even separate a nonlinear function„ÄÇThey're just linear classifiers„ÄÇ

And so this led to two major AI winters in the '70s and in the late '80s and early '90s„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_39.png)

The light Hill report„ÄÇIn 1973„ÄÇBy the UK government said that no part of the field of discoveries made so far produced the major impact that was promised„ÄÇ

So if the hype builds„ÄÇBeyond the capabilities of our research„ÄÇReports like this will come„ÄÇ

And they have„ÄÇThe possibility of creating another AI winter„ÄÇ So I want to pair the optimism„ÄÇ

 Some of the cool things we'll talk about in this class„ÄÇ

With the reality of the challenges ahead of us„ÄÇThe focus of the research community„ÄÇ

 this is some of the key players in deep learning„ÄÇWhat are the things that are next for deep learning„ÄÇ

 the five year visionÔºü

![](img/419efdb516c630bd47e1579b4956df18_41.png)

We want to run on smallerÔºå cheaper mobile devices„ÄÇWe want to explore more in the space of unsupervised learning„ÄÇ

 as I mentionedÔºå and reinforcement learning„ÄÇWe want to do things that„ÄÇ

Explore the space of videos moreÔºå the recurringcur neural networks„ÄÇ

 like being able to summarize videos or generate short videos„ÄÇüòäÔºåOne of the big efforts„ÄÇ

 especially in the companies with deal with large dataÔºå is multimodal learning„ÄÇ

 learning from multiple data sets with multiple sources of data„ÄÇAnd lastlyÔºå making money„ÄÇ

From these technologiesÔºå there's a lot of„ÄÇThisDespite the excitement„ÄÇThere has been an inability„ÄÇ

 for the most partÔºå to make serious money„ÄÇFrom some of the„ÄÇMore interesting parts of deep learning„ÄÇ

And while I„ÄÇGod madeÔºå madeÔºå made fun of by the T S for including this„ÄÇ

Slide because it's shown in so many sort of business type lectures„ÄÇ

 but it is true that we're at the peak of a hype cycleÔºå and we have to make sure„ÄÇ

given the large amount of hype and excitement there isÔºå we proceed with caution„ÄÇ1„ÄÇExample of that„ÄÇ

Let me mention„ÄÇIs we already talked about spoofing the cameras„ÄÇ

 spoofing the cameras with a little bit of noise„ÄÇ So if you think about it„ÄÇ

Self driving vehicles operate with a set of sensors„ÄÇ

And they rely on those sensors to convey to accurately capture that information„ÄÇ

Now what happens not only when the world itself produces noisy visual information„ÄÇ

 but what if somebody actively tries to poof that data„ÄÇ

One of the fascinating things that been recently done is spoofing of Lidar„ÄÇ

So these LiDars is a range sensor that gives a 3D point cloud of the objects in the external environment„ÄÇ

And you're able to successfully„ÄÇDo a replay attack where you have the car see people and other cars around it when there's actually nothing around it„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_43.png)

In the same way that you can spoof a camera to see things that are not there„ÄÇA neural network„ÄÇ

So let me run through some of the libraries that we'll work with and that are out there that you might work with if you proceed with deep learning„ÄÇ

TensorFÔºå that is the most popular one„ÄÇThese daysÔºå it's heavily backed and developed by Google„ÄÇ

It has primarily a Python interface„ÄÇAnd is„ÄÇVery good at operating on multiple GPUs„ÄÇThere's CAS„ÄÇ

 and also TFLearn and TF SMÔºå which are libraries that operate on top of TensorFlow that make it slightly easier„ÄÇ

 slightly more user friendly interfaces to get up and running„ÄÇTorch„ÄÇ

If you're interested to get in at the lower level tweaking of the different parameters of neural networks„ÄÇ

 creating your own architecturesÔºå Torch is excellent for that with its own LuA interface„ÄÇ

 LuA is a programming language„ÄÇAnd heavily backed by Facebook„ÄÇThere's the old school the„ÄÇ

 just what I started on„ÄÇ a lot of people early on in deep learning started on„ÄÇ

It's one of the first libraries that supported had came with GPU support„ÄÇ

It definitely encourages lower level tinkering„ÄÇAnd as a Python interface„ÄÇAnd many of these„ÄÇ

 if not allÔºå rely on invidious„ÄÇAnd Vdia's library for„ÄÇ

For doing some of the low level computations involved with training these neural networks„ÄÇ

On Nvidia GPUs„ÄÇMXNetÔºå heavily supported by Amazon„ÄÇAnd they've officially recently announced that they're going to be„ÄÇ

 their AWS going to be all in on M Xnet„ÄÇNeon recently bought by Intel„ÄÇ

 started out as a manufacturer of neural network chipsÔºå which is really exciting„ÄÇ

And it performs exceptionally well„ÄÇNow here are good things„ÄÇ

 Cafe start in Berkeley also was very popular in Google before TensorFlow came out„ÄÇ

Is primarily designed for computer vision with convnetsÔºå but is now expanded to all the„ÄÇ

All other domains„ÄÇThere is CTKÔºå as he used to be known and now called the Microsoft Cognitive Tookit„ÄÇ

 Nobody calls it that still I'm aware of„ÄÇIt says multi GPPU support has its own brain script„ÄÇ

 custom language„ÄÇAs well as other interfaces„ÄÇAnd what we'll get to play around in this class is amazingly deep learning in the browser„ÄÇ

 rightÔºüOur favorite is Kana JSÔºå what you'll use built by Andrea Carpathy from Stanford now Open AI„ÄÇ

It's good for explaining the basic concept of neural networks„ÄÇ

 it's fun to play around with all you need is a browserÔºå so very few requirements„ÄÇ

 it can't leverage GPUs unfortunately„ÄÇBut for a lot of things that we're doingÔºå you don't need GPs„ÄÇ

 You'll be able to train a network with very little„ÄÇAnd relatively efficiently„ÄÇ

 without the need of GPUsÔºå it has full support for CNNNs„ÄÇ

 R NNs and even deeper reinforcement learning„ÄÇKaras Js„ÄÇ

Which seems incredible we tried to use for this class„ÄÇDidn't didnn't happen to It has GPU support„ÄÇ

 So it runs in the browser with GPU support with open GLÔºå or however it works magically„ÄÇ

 But we're able to accomplish a lot of things we need without the use of GPs„ÄÇ

 So I it's incredible to live in a day and age when„ÄÇüòäÔºåIt literallyÔºå as I'll show in the tutorials„ÄÇ

 it takes just a few minutes to get started with building your own neural network that classifies images„ÄÇ

And a lot of these libraries are friendly in that way„ÄÇSo all the references mentioned in this„ÄÇ

Presentation are available at this linkÔºå and the slides are available there as well„ÄÇ



![](img/419efdb516c630bd47e1579b4956df18_45.png)

So I think in the interest of timeÔºå let me wrap upÔºå thank you so much for coming in today„ÄÇ

 and tomorrow I'll explain the deep reinforcement learning game and the actual competition and how you can win it„ÄÇ

Thanks very much guys„ÄÇ