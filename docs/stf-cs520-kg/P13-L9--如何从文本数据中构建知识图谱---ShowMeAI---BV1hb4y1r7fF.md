# P13ÔºöL9- Â¶Ç‰Ωï‰ªéÊñáÊú¨Êï∞ÊçÆ‰∏≠ÊûÑÂª∫Áü•ËØÜÂõæË∞± - ShowMeAI - BV1hb4y1r7fF

![](img/608d70c57fd7ddd5c8f2f9fd20e9b000_0.png)

Welcome to the Knowledge Cloud Seminar„ÄÇToday we are in the week five of the course and in the course until now we've talked about what is the knowledge graph we have defined the knowledge graph„ÄÇ

 its data model and some query languages„ÄÇAnd for the last couple of weeks„ÄÇ

 we've been talking about how to create a knowledge class„ÄÇ

And in that process we talked about how to design the schema of a knowledge graph last week we talked about how we can create a knowledge graph from structured data and the focus for this week is going to be how we can create a knowledge graph from text and images„ÄÇ

Today's lecture is going to primarily focus on how we create the knowledge graph from text„ÄÇ

But in the lecture on ThursdayÔºå we would also hear about how we can create knowledge graphs from images„ÄÇ

Okay„ÄÇFor today's lectureÔºå I have structured it into two parts„ÄÇ

 the first part is going to focus on the methodsÔºå which is going to be focusing on the techniques for creating knowledge graphs from text„ÄÇ

Mostly in abstract and in the second part of the lecture I will talk about a very concrete application where we can take those methods and try to apply to a real world problem so that you can see how the techniques„ÄÇ

Work and practice„ÄÇOkay so we start with the first part„ÄÇ

 we will talk about the methods for creating a knowledge graph from text I will start by giving a little overview of the problem then we will talk about a general technique called a language models which can be used both for entity extraction and relation extraction tasks and then I'll conclude this segment with a summary„ÄÇ

As we all know a lot of useful information is available in unstructured text this can include things like SEC filings„ÄÇ

 Wall Street general journal and financial news if there is a way for us to automatically process this information and construct a knowledge graph we can do a lot of interesting analytics on that and an obvious technique for doing this kind of processing comes from the field of natural language processing and in particular from information extraction but at the outset I want to make it clear that today's lecture is not a lecture on NLP and it's not going to be any in- depth discussion on NLP„ÄÇ

Our coreÔºå our focus and the focus of this course is on knowledge graphsÔºå like how do we construct„ÄÇ

Structured human understandable representations of a certain part of the world on which we can do inference and on which we can do analytics„ÄÇ

And for the purpose of this lecture and for this course„ÄÇ

 we are resuming that we can use NLP as a black box„ÄÇ

 it's like a tool that is available to us that we can apply to a given problem towards the goal of creating a knowledge graph„ÄÇ

And I cannot stress this point enough because NLP and the techniques that I'm using„ÄÇ

 they are covered in a full length course somewhere else in the curriculum and I'm not trying to reproduce or redo that I'm just trying to leverage but is available to us in the context of the primary goal of this course„ÄÇ

In the first lectureÔºå I had shown this slide where„ÄÇWe talked about how we can„ÄÇ

Extract information from sentences and represent them in a knowledge draft„ÄÇSo for example„ÄÇ

 given this sentenceÔºå Albert Einstein was a German born theoretical physicist who developed a theory of relativity„ÄÇ

 we will extract entities such as Albert EinsteinÔºå GermanyÔºå theoretical physicists etc„ÄÇ

 and then we will extract relationsÔºå such as born in occupationÔºå and developed„ÄÇ

And we can connect them using this directed graph representation„ÄÇ

 and once we have the directed graph representation„ÄÇ

 we can do additional inferences using that information such as theory of relatities„ÄÇ

 a branch of physics and theoretical physicist is a kind of physicistÔºå etc„ÄÇOkayÔºå now„ÄÇ

 but in the overall scope of extracting information from text„ÄÇ

 we have the problem of entity extraction and relation extraction like I just described„ÄÇ

But there' is also the problem of entity resolution„ÄÇAnd by entity resolution„ÄÇ

 what we mean is that the same entity can be referenced in a text in many different ways„ÄÇ

 for exampleÔºå we may have a person John Smith and in a text we may refer to it by he or the company president or there may be other ways to refer to the same real world entity„ÄÇ

I'm not going to cover entity resolution in this lecture„ÄÇ

 partly because I want to limit the scope and partly what I found in my personal experience is that right now the entity extraction and relation extraction tasks are hard enough to do very well on complicated problems that„ÄÇ

The focus is not yet on entity resolutionÔºå we are still trying to do well on these two primitive tasks„ÄÇ

And for both of these tasksÔºå the current fashionable or current trend is to use techniques called language models so I'll start by describing at a very high level what a language model is and then when I describe the techniques for entity extraction and relation extraction„ÄÇ

 I will discuss how language models are currently being used in that process„ÄÇ

So the overall concept behind a language model is that it's a tool or it's a model that predicts what word should come in the text in a sequence of words so for example„ÄÇ

 if you are given a text fragments students open their do dot„ÄÇ

The task for long language model is to fill in the do dot as to what could be the next word„ÄÇ

 for exampleÔºå in this sentence fragmentÔºå we could have students open their books or laptops or exams„ÄÇ

Or whatever else„ÄÇAnd with each predicted wordÔºå it is going to associate a probability of likelihood with which that word might come next„ÄÇ

So more formallyÔºå a language model can be also viewed as a probability distribution„ÄÇ

 such that given a set of words x1 through xn minus1Ôºå we want to predict the next word Xn„ÄÇ

Given that we've already seen x1 through x and minus1 in our input okay now language models are used all over the place„ÄÇ

 they have lots of applications we go and type in query in the search engine and it gives us likely completions so underneath it is basically using a language model to perform the task„ÄÇ

SimilarlyÔºå when we are on iPhone and we are typing a message„ÄÇ

At the bottom or just above the keyboard it is suggesting the likely next words„ÄÇ

 so it's a pretty straightforward application of the language model that we see on a daily basis„ÄÇ

Okay„ÄÇThese language models these days are created using deep learning models and recurrent neural networks is a popular approach for creating those language models„ÄÇ

There are several variations of these pretrained language models that are available and those variations that depend based on what data you use for training„ÄÇ

 whether it's a single direction versus bidirect model„ÄÇ

 which particular neural network architecture you're using„ÄÇAnd as I have noted previously„ÄÇ

 I'm assuming for this course that a language model is available to us off the shelves and we can adapt it for the task that we have at our hand„ÄÇ

 which is the task is to create a knowledge graphÔºå rightÔºüNo„ÄÇ

It may be interesting to actually say a little bit more about the difference between a single direction versus a bidirectional language model„ÄÇ

 the example that I gave was of a single directionional language model in which we are given a sequence of words and we are predicting the next word in a bidirectional model we are given a complete sentence in which one particular word is omitted and now we have information both through the left and the right of the word and we are predicting the word in the middle„ÄÇ

So it's useful to understand this at a very high level in terms of what these models do and what they have been trained to do„ÄÇ

A popular language model which has gained a lot of attention in the last few years is known as BRT„ÄÇ

 this was originally developed at Google and more recently there has been a lot of press and news about a new language model called GPT3„ÄÇ

OkayÔºå now let's now„ÄÇPut our heads down and we focus on the specific problem of entity extraction„ÄÇ

I will start by giving a running example for this problem and then I will outline various approaches for doing entity extraction and then discuss the challenges that arise in using automated entity extraction„ÄÇ

So take this sentenceÔºå Cecilia LoveÔºå 52Ôºå a retired police investigator who lives in Massachusetts„ÄÇ

 said she paid around $370 a ticket with tax for nonstop United Airlines flight to Sacramento„ÄÇ

From Boston for her niece's high school graduation in June 2020 Okay so we are given this sentence and from this sentence„ÄÇ

We want to extract named entities which are defined as things like places„ÄÇ

 companies and people and the definition of entities here is generally broadened to include things like dates times and numerical expression so for example here $370 it's a number that would be considered an entity June 2020 would also be considered in entity it's a time„ÄÇ

So given the sentence above we the task is to produce an annotated version of the sentence of the type shown here„ÄÇ

 so here Cecilia love we have labeled„ÄÇBy personÔºå New Jersey we have labeled as location„ÄÇ

 $370 we've labeled as moneyÔºå United AirlinesÔºå we've labeled as organization and so on okay so the task is to go from this input sentence shown as above to the label version which is shown below„ÄÇ

And typically we use we define a set of tags to mark the entities in a sentence because entities can be more than one word„ÄÇ

 there are these five tags which are defined to mark the boundaries where B denotes the first word in the entity E denotes the last word in the entity E I denotes the internal word in the entity„ÄÇ

O is a word nodding the entity and s is the single word entity„ÄÇ

So given the sentence that we were looking at previouslyÔºå for Cecilia love„ÄÇ

 Cecilia would be marked by B and love would be marked by E„ÄÇ

 and the rest of the words we can see that they would be tagged in an identical manner„ÄÇNow„ÄÇ

 in terms of broad approachesÔºå there are three broad approaches for extracting entities„ÄÇ

There is sequence labeling the neural models but neural models actually just mean language models and the rule list approaches and I'll give a quick overview of each of these approaches„ÄÇ

In the sequence labeling approachÔºå we take a standard machine learning type algorithm„ÄÇ

 such as conditional random field„ÄÇAnd we„ÄÇGive it training data which uses features such as part of speech„ÄÇ

 so for exampleÔºå we may give it an input sentence and we might identify part of speech for every input sentence and say that okay„ÄÇ

 if it is a nounÔºå then it must be a named entity„ÄÇThe training could also be based on whether a particular phrase is present in a mastered list of named entities„ÄÇ

Word embeddingsÔºå which we discussed in the first lecture could also be used as a training feature„ÄÇ

 the prefix of a wordÔºå and whether something appears in an all CAPS notation„ÄÇSo as you can tell„ÄÇ

 if you're going to use any kind of machine learning approach in this case„ÄÇ

A significant feature engineering is required because it's not clear which features we should put in„ÄÇ

 but there is a lot of wisdom and a lot of practice available using which we can choose what features we should be using in an entity extractor„ÄÇ

Now„ÄÇIn the let's now talk about the use of neural models for entity extraction„ÄÇ

 so here we are going to take an off the shell language model such as BRT and we are going to apply it to our problem at hand„ÄÇ

And there are two kinds of steps that are involved in doing that first is task independent training and the second is the task dependent training„ÄÇ

So these language models that we are going to get from off the shelf„ÄÇ

They are trained on very broad corpusÔºå so maybe all the news or some very general purpose corpus such as Wikipedia„ÄÇ

But in generalÔºå we are always interested in a particular domain or solving a particular problem„ÄÇ

 so if we are interested in extracting entities from financial documents or legal documents„ÄÇ

The step of task independent training is to retrain the model that we have on the domain that we are interested in okay„ÄÇ

So that it understands the peculiarities or the vocabulary or the words that appear in that particular domain„ÄÇ

So that's the first step and the second step is the task dependent training so in this case the task is entity extraction„ÄÇ

 so the next thing we are going to have to do is to train our model on the task of entity extraction„ÄÇ

And the way this is done is we will take our sentence and in our sentence„ÄÇ

 we will introduce special markers„ÄÇSo the sentence we were previously working with here we have a marker called CLS„ÄÇ

 which denotes the beginning of the entity and SAPÔºå which denotes the ending of the entity„ÄÇ

These labels are pretty arbitraryÔºå we could have put any marker here„ÄÇ

 but CLS here is I think short form for classification and SP is the short form for separator„ÄÇNow„ÄÇ

When we train a language model in which the sentences have these markers„ÄÇÂëÉ„ÄÇ

What it will learn is how to predict these markersÔºå okayÔºü

We can repurpose the language model to this entity extraction task by now asking it to predict whether the next token is going to be CLS or whether the next token is going to be SP„ÄÇ

 rightÔºüAnd if„ÄÇWe get it to predict these distinguished tokens„ÄÇ

 we know where the entity boundaries are and we can use that information to mark where the entities are in our sentence„ÄÇ

So it's a pretty clever way of just taking a very general purpose language model technology and repurposing it to entry extraction task„ÄÇ

OkayÔºå let's now talk about the rule based entity extraction„ÄÇ

 the basic idea here is that we are going to write a set of rules which will tell us how we should extract the entities„ÄÇ

And these rules can be based on either something very simple as regular expressions or it could be looking up things in a dictionary or it could be invoking custom extractors okay„ÄÇ

 but the bottom line is„ÄÇAgainÔºå just like in feature engineering we have to come up with features here we have to do rule engineering we have to„ÄÇ

Have enough understanding of our domain to figure out what the entities are and we have to be able to specify the relevant rules which will help extract the entities„ÄÇ

OkayÔºå so that was sort of my quick overview of the methods one can use the difficulties that arise in doing entity extraction well are one obviously is ambiguity we can have entities such as Louis Vuitton which can either refer to a company or to a person or to a product so in cases like this it's difficult to figure out what should be the appropriate label for that end„ÄÇ

Training data„ÄÇOr future engineeringÔºå you knowÔºå I meanÔºå rural engineering„ÄÇ

 all of that is the bottleneck in doing this process well„ÄÇ

There are domains where there are variations which are very peculiar to that domainÔºå so for example„ÄÇ

 if you are doing extraction in biology you may have entities such as duplication of cell by efficient„ÄÇ

I meanÔºå which is like a long phraseÔºå which is very different from the kind of things we were seeing in the example where we were primarily limited to company and organization and location„ÄÇ

 etc„ÄÇAnd in some domainsÔºå you have to extract very general„ÄÇ

Terms as entities like attach or bind or synthesis„ÄÇAnd„ÄÇüòäÔºåThere againÔºå it becomes a challenge how you„ÄÇ

Define your rules and training„ÄÇTo do„ÄÇExtraction for those very general entities„ÄÇAnd finally„ÄÇ

 entities have multiple formsÔºå so these forms may include singular versus plural„ÄÇ

 you may have abbreviations for an entityÔºå you may have morphological variations of an entity„ÄÇ

All of those things are going to appear in the text and„ÄÇ

We won't be able to figure out that they are all referring to the same entity unless we have a lot of lexical knowledge„ÄÇ

And if you really wanted very high performance on the entity extractor„ÄÇ

 we also need a very good lexicon for the domain so that we can accurately distinguish whether different variations of a entity are actually referring to the same thing„ÄÇ

ÊòØ„ÄÇAll rightÔºå so that was my quick overview of term extraction and now I'm going to move on to methods for relation extraction„ÄÇ

And here againÔºå I'm going to begin by giving a few„ÄÇ

giving one example of the extraction task we want to perform„ÄÇ

 then I'll give a broad picture for various techniques for doing relation extraction and then talk about what's hard„ÄÇ

 what is difficult about doing relation extraction„ÄÇ

So the example is the same sentence that we considered for entity extraction„ÄÇ

 and now we want to extract information such as Cecilia Love lives in Massachusetts that lives in is the relationship United Airline flies from Boston„ÄÇ

 United Airline flies to BostonÔºå so those we want to extract those relations from this sentence„ÄÇÂëÉ„ÄÇ

OkayÔºå so„ÄÇActuallyÔºå I have multiple examplesÔºå not just one example„ÄÇVery popular task that people„ÄÇ

A lot of people focus on is to extract information from Wikipedia because it's very useful for enhancing the search results„ÄÇ

Lot of the fact extraction from Wikipedia is straightforwardÔºå but there are a lot of corner cases„ÄÇ

 so if you look at the Wikipedia page for for Larry King he has been married multiple times six or seven times and for each of his marriages there is time duration right and„ÄÇ

If a person is married only a single timeÔºå then it's pretty straightforward to extract the spouse relationship„ÄÇ

 but now the person is married multiple times and there is time and sometimes he was married to the same person twice right so it becomes very complicated very soon to associate appropriate temporal„ÄÇ

Information with the fact that you are extracting„ÄÇI mentioned domain specific extraction in the when I was talking about entities„ÄÇ

 but the same thing arises for relations also there are„ÄÇDomamain specific extraction systems„ÄÇ

 for exampleÔºå for the medical domainÔºå where they are primarily interested in information such as what things cause what disease„ÄÇ

 what drug can treat what symptomsÔºå what kind of enzyme or chemical disruptsÔºå what kind of process„ÄÇ

 and thats those meanings and the way they are defined is very specific and peculiar to the biology domain„ÄÇ

 and that by itself becomes a whole subfeed within relation extraction„ÄÇEven for relation extraction„ÄÇ

 there are three broad approachesÔºå there is a rule based approach„ÄÇ

 there is a supervised learning approachÔºå and then there is open information extraction„ÄÇ

Even within supervised learningÔºå people make a lot of subdistinctions„ÄÇ

 whether it is semiupervised or fully supervised or„ÄÇ

 but as long as the approach is supervised for the purpose of my discussion„ÄÇ

 I have kept everything under the same heading of supervised approaches„ÄÇ

The open information extraction„ÄÇApproach is a way of extracting information where they don't give any„ÄÇ

Specific attention to the meaning of the labelsÔºå they just extract triples out of text„ÄÇSo„ÄÇüòä„ÄÇ

So just as an exampleÔºå if you're given a sentenceÔºå Dante passed away in Dvana„ÄÇ

The open information extraction approach will simply take this text fragment and they will turn this into a triple which is shown here to the left„ÄÇ

 Dante passed away in Uvana„ÄÇAs opposed to„ÄÇTaking this text and populating a knowledge graph in which we have a vocabulary of relations which have very defined semantics so on the right I'm showing a little property graph there we have a person node and there is a city node and there is a relation called death place which probably has some domain and range constraints defined for it it has some rules and constraints on what values it can or cannot take„ÄÇ

And whenever we are going to talk about where a person diedÔºå we would use the same relation okay„ÄÇ

 so there is that careful knowledge engineering and knowledge representation that has happened„ÄÇ

Which would be„ÄÇNot done in the case of in open information extraction„ÄÇ

 in open information extractionÔºå you just process text in a completely unsupervised way„ÄÇIt's a„ÄÇ

Popular and very compelling story for certain kinds of problems„ÄÇ

 but it becomes very difficult to do the inference and analytics using the information we will extract in open information extraction way so for the purpose of my lecture here I have decided to keep that outside the scope because we are primarily focused on knowledge graphs and we are interested in techniques which will help us popular in knowledge graph where we have well defined meanings for the nodes and labels in our representation„ÄÇ

So for the rest of my discussionÔºå I'm going to primarily discuss information„ÄÇ

 extraction or relation extraction based on syn patterns and supervised learning„ÄÇOkay„ÄÇ

 so synthetic patternsÔºå they were originally introduced by Martyhurst and in her honor„ÄÇ

 they are also referred to as heararrst patterns„ÄÇAnd I illustrate that using an example that I took from the original paper on this topic„ÄÇ

 so let's take this sentenceÔºå the bolu such as bambbaran d is plucked and has an individual curved neck for each string„ÄÇ

Now„ÄÇI've never seen a bullutÔºå I don't know what bombbara and Dang is„ÄÇ

 these are the words I may be encountering for the first time„ÄÇBut„ÄÇ

We can just from the syntactic structure of the sentenceÔºå we can say that wellÔºå you know„ÄÇ

 the marin D must be a kind of boat loopÔºå assuming kind of or superclass is one relationship that we are interested in„ÄÇ

So this was the key insight that Mardihurst had and she said that while you know„ÄÇ

 we can define such syntactic patterns which based on the way a sentence is structured could give us very strong indication for what might be the relationship between them and she had in her original paper she had several examples„ÄÇ

 so for exampleÔºå if we have a sentence such as work by authors such as Ericrick Goldsmith and blah„ÄÇ

 blahÔºå blahÔºå we know that Herrick and Goldsmith they authors right„ÄÇAnd then if you have a sentence„ÄÇ

 bruise bruisesÔºå woundsÔºå broken bones or other injuries„ÄÇThen we know that in this sentence„ÄÇ

 bruises and wounds must be kind of injuries and so on and so forth„ÄÇ

 you can follow the rest of the examples in the same day„ÄÇNow„ÄÇ

 when this idea was originally introducedÔºå you know people thoughtÔºå oh wow„ÄÇ

 this is really cool and if you can do the extraction like this„ÄÇ

 wouldn't this be really a very scalable way of doing itÔºü

But it turns out it's not that easy to generalize„ÄÇAnd so even in the original paperÔºå you know„ÄÇ

 there was this section onÔºå okayÔºå how do you generalize it to relations that you have not seenÔºü

And the general methodology that was suggested was thatÔºå well„ÄÇ

 if you want to extract a certain relationÔºå what you do is you collect lots and lots of examples of sentences where that relation is described„ÄÇ

And from there you try to figure out what are the general patternsÔºü

And then for those general patternsÔºå you define this syntctic„ÄÇNow„ÄÇ

 if you take some relationships such as Ha partÔºå it's been very difficult to find very general patterns about how you would extract it from the text and I will actually give you more examples of this in the second part of my lecture„ÄÇ

ü§ßSome people have„ÄÇSome people have undertaken research to see if they could„ÄÇ

Auttoomatically learn these patternsÔºå instead of having to manually engineer these patterns using examples and working backwards from example instances of these relations and sentences can be somehow automatically learn them„ÄÇ

And that also has limited successÔºå I mean there is some success in limited domains„ÄÇ

 but not in a sort of very general purpose manner„ÄÇO„ÄÇ

Now let's switch to the supervised learning approach for relation extraction and first and foremost„ÄÇ

 you know it requires a huge amount of training data„ÄÇ

 you know you may not be required to define patterns for the example occurrence of in a sentence„ÄÇ

 but you still have to find those sentences where those relations occur„ÄÇËØ∂„ÄÇAnd some people„ÄÇ

 what they do is they would„ÄÇUse the Mardiher style syntactic patterns„ÄÇ

 and they will use those patterns to generate lots and lots of training data„ÄÇ

In the opposite direction„ÄÇGiven that these training dataÔºå these sattactic patterns„ÄÇ

 they are not very general and they don't always work„ÄÇ

There is this recent idea called approximate labeling and this is something which Chris Ray in in our department here has pioneered and the basic idea there is that while you know we can't come up with„ÄÇ

Clear way to figure out whether a particular relation exists in a sentence or not„ÄÇ

 so we are going to have lots and lots of different syntactic patternsÔºå which might suggest„ÄÇ

That this relationship might exist in a sentence„ÄÇAnd then we are going to use all of them and then through a training process„ÄÇ

 we are going to learn how good each of these is and we are going to combine combine„ÄÇ

The the input or the signal that they give us into what we are going to feed into our into our learning algorithm„ÄÇ

 so as a concrete exampleÔºå let's say we are we have a relationship has part we want to learn this from the syntax structure of the of the sentence now if our weak labeling function could be that if in a sentence we have„ÄÇ

A has B or A have B„ÄÇThen we could say thatÔºå ohÔºå you knowÔºå this might be suggesting that a has part B„ÄÇ

And we know this is not correctÔºå this is not all this correctÔºå in some casesÔºå this is correct„ÄÇ

But that is a labeling functionÔºå a weak labeling function that we can use in our training algorithm„ÄÇ

Which eventually„ÄÇBased on experienceÔºå we get better„ÄÇOkay„ÄÇÂïä„ÄÇNext„ÄÇ

 let's talk about how we can adapt a language model for the task of relation extraction„ÄÇ

And the basic idea here is not very different from the kind of trick we used for entity extraction„ÄÇ

So essentially what we do is„ÄÇWe take our input sentences and we put these special markers in our sentence which denote the beginning and end of each term„ÄÇ

 so term one start and term one end that denotes the first entity and term to start and term to end„ÄÇ

ÂóØ„ÄÇDeotes the second entity„ÄÇAnd in our training data„ÄÇ

 what we are going to train our language model to do is that when the language model encounters a sentence like this„ÄÇ

 its output should be lives inÔºå which is the relationship that we are trying to predict„ÄÇSo again„ÄÇ

 you knowÔºå the basic idea„ÄÇIt remains the same„ÄÇEnhance your input data to add markers which correspond to the task you're trying to perform„ÄÇ

Throw lots and lots of data at the model and get it to learn„ÄÇThe output you are trying to produce„ÄÇ

The challenges you can expect in this case are the first and foremost is the training data like how do you get lots and lots of examples of the„ÄÇ

Relations of the training dataÔºå which are required for this any of these techniques to work„ÄÇ

And given that all of these techniques are„ÄÇApproximate mean they are not going to work in all the cases„ÄÇ

 we still need human verification at the end if the end goal is to come up with a highly accurate knowledge graph„ÄÇ

 you have to have a human in the loop„ÄÇAnd„ÄÇI primarily here talked about relation extraction for entities„ÄÇ

 but there are„ÄÇSpecialized methods when you are trying to extract relationships for events or when you're trying to extract temporal information about entities„ÄÇ

I have not covered them in this lectureÔºå but I just wanted people to be aware that you know„ÄÇ

 there is more to it than what I've just covered here„ÄÇOkay„ÄÇ

 so that sort of brings me to the summary of the first part or the methods part of what I was going to say„ÄÇ

 and that is entity extraction and relation extraction are fundamental problems if we want to create knowledge graphs from text„ÄÇ

And the overall landscape of methods is that people still prefer to use learning based approaches for doing so„ÄÇ

 but the rule based approaches and syntactic patternsÔºå they are very powerful paradigms„ÄÇ

And people are leveraging them to„ÄÇCreate or bootstrap the training data that they need for their learning algorithm„ÄÇ

We are still trying the state of the art is still such that we are still trying to do well on entity extraction and relation extraction and entity resolution I mean that's an extremely difficult problem again I kept that out of this lecture just to sort of„ÄÇ

Keep the scope„ÄÇBut eventuallyÔºå I think once the entity extraction and relation extraction becomes well tackled„ÄÇ

 entity resolution is going to be increasingly important„ÄÇOkay„ÄÇNo„ÄÇ

I would like now to move to the a second part of the lecture„ÄÇ

 which is going to focus on a concrete application where„ÄÇ

I can illustrate how these methods actually worked in a particular project that I was involved in„ÄÇ

I'll take a quick scan at the questions just to see whether there is anything I should address now versus addressing at the„ÄÇ

End of the„ÄÇEnd of the lecture„ÄÇOkayÔºå yeahÔºå I think I we take these questions at the end of the lecture as we get into the discussion part„ÄÇ

Okay„ÄÇOkayÔºå so in the discussionÔºå I'm going to talk about an application called intelligent textbook where we are trying to create a knowledge graph from textbook textbooks and I will„ÄÇ

Show how some of the techniques that I talked about we were able to apply and how well they worked for our project„ÄÇ

So I'll start off by discussing what is an intelligent textbook„ÄÇ

 what kind of knowledge of do we actually need for an intelligent textbook and then how do we extract entities„ÄÇ

 how do we extract relations and then sort of„ÄÇTell you about what were the experiences„ÄÇ

 how much did we succeed and„ÄÇAnd what I think is the way forward for using automatic extraction methods in surveys of knowledge graph construction„ÄÇ

So I like to define an intelligent textbook as a traditional textbook„ÄÇ

 which is enhanced by a knowledge graph of concepts and relations which are found in the book„ÄÇ

Once we combine this traditional book with the knowledge graph„ÄÇ

 I'm calling that an intelligent textbook„ÄÇNow there could be other definitions for an intelligent textbook„ÄÇ

 but that's sort of how I've defined it for the purpose of this lecture„ÄÇNow„ÄÇ

 the first question that arises here is who needs it„ÄÇ

 why should you even care and what problem are we solving in creating an intelligent textbookÔºü

So I think„ÄÇIntelent textbook of the sort we have been thinking about is useful for making it easy for students to learn complex new concepts„ÄÇ

And an example student for„ÄÇwho has such a problem is a first year student in a college level biology„ÄÇ

 and if you talk to these students who have aspirations to become doctors someday„ÄÇ

And when they walk into their biology classroomsÔºå we hand them these thick textbooks and they have to master those books if they are going to progress with their education and the sentiment which is shared by these students is that biology is very complex„ÄÇ

 it has huge amounts of new words and they feel lost to help students like this„ÄÇ

 we think an intelligent textbook could be a powerful technology and we have built a concrete prototype of what such a textbook might look like„ÄÇ

 and I'm going to give you a demonstration of this book so that you can see for yourself concretely what I'm talking about„ÄÇ

OkayÔºå so in a it has five different capabilities that help students„ÄÇ

 the first is that for any difficult words that appear such as proteins„ÄÇ

 polysaccharides and nucleic acidsÔºå students can get a quick definition by simply clicking on it„ÄÇ

SecondÔºå it helps crosslink content coming from different parts of the bookÔºå including diagrams„ÄÇ

 regardless of which chapter those diagrams might be defined in„ÄÇThirdÔºå it gives a visualization„ÄÇ

 knowledge graph visualization for every single concept in the book„ÄÇ

 and the student can interactively explore this visualization to ensure that they've learned what they were studying„ÄÇ

FourthÔºå as the student is reading a book and they highlight a passageÔºå it asks the student questions„ÄÇ

And for exampleÔºå in this caseÔºå the student kind of remembers that hemoglobins carry oxygen„ÄÇ

 but they're not sure„ÄÇSo they decide to touch on that question and by comparing their answer with the answer returned by the book„ÄÇ

 they have this renewed confidence that they actually understood the material„ÄÇ

 so it's a great self testing device„ÄÇAnd finallyÔºå they can ask questions from the book„ÄÇ

 for example hereÔºå the student is asking compare protein with a polysaccharide„ÄÇ

And in response to such a questionÔºå the book will systematically compare these two concepts and present the results in a nicely organized table okay„ÄÇ

So using these five new capabilities which are powered by a knowledge graph„ÄÇ

 the student is able to more effectively interact and engage with this complicated body of knowledge„ÄÇ

OkayÔºå so that was the demonstration just to make it concrete for you how the knowledge graph is actually being used in the context of a textbook„ÄÇ

We it's actually not just a demoÔºå it's actually a working prototype and we have tested it out in multiple classrooms at some community colleges at a college campus in Sweden and also at Harvard University and we found that„ÄÇ

These features that I just showed in the demonstration they are uniformly liked by students„ÄÇ

 they also lead to better„ÄÇLearning outcomes and also it also helps students underperforming students„ÄÇ

So„ÄÇüòäÔºåThe real challenge in creating intelligent textbooks like this is to actually build the graph„ÄÇ

 how do we actually build the graph in a scalable manner for lots and lots of books„ÄÇNow„ÄÇ

The next thing one could ask here is okayÔºå but what kind of knowledge graph is actually neededÔºü

What is it that we areÔºüTrying to createÔºå which would enable the kind of demonstration that I just showed„ÄÇ

So let's now look at it a little bit more carefully because this example is different more different from the Cecilia love example„ÄÇ

 which I was considering in the first part of the lecture„ÄÇ

So let's take this sentence such as on the outer surface of the plasma membrane„ÄÇ

 carbohydrate side chains are found attached to proteins in lipid„ÄÇ

so that's the sentence and from this we want to construct a graph of the sort shown to the right where we do have things like plasma membrane„ÄÇ

 carbohydrate c chainÔºå those things appear in the graph„ÄÇ

 but the protein and lipids instead of appearing as protein and lipids„ÄÇ

 they appear as glycoprotes and glyco lipididsÔºå which are more special kinds of proteins„ÄÇNow„ÄÇ

 those proteins were not„ÄÇExplicitly mentioned in this sentence right they were probably mentioned in some other part of the textbook where they were talking about these more special kind of proteins„ÄÇ

But when we extract information and we want to construct this knowledge graph„ÄÇ

 we want to construct this sort of cohesive global knowledge graph and in this case„ÄÇ

To build something like thisÔºå we would also have to resolve this lipid entity with the glycolipid entity which already is there in the graph„ÄÇ

 similarly protein entity with a glycoprotein entity„ÄÇNo„ÄÇ

TheI think the other thing which needs to be pointed out here is what is the actual meaning of this graph mean short you know this is a directly labeled graph of the sort that we've defined in this course„ÄÇ

 but what exactly is this graph sayingÔºüNow„ÄÇIf I was reading the logical meaning of this goff„ÄÇ

 it's kind of saying that for every plasma membrane there is a glycoprotein„ÄÇ

 there is a carbohydrate side chain such that that side chain is a part of glycorotein so I'm reading this leftmost part of the path that you are seeing on the screen„ÄÇ

Now the first thing you would notice here is that the nodes that we have in the knowledge graph here are genetics right they are not things like Cecilia Love or Boston or United Airlines„ÄÇ

 these are the kind of things that we saw in the first part of the talkÔºå but here we have„ÄÇ

Classes of objects like plasma membranesÔºå gcoroteinsÔºå consÔºå etter„ÄÇ

So the the actual meaning and what we want to do with this graph„ÄÇ

 strictly speaking is much more than„ÄÇWhat a knowledge graph between real world entities is because there is some quantification and some more background inference which goes with it„ÄÇ

And now„ÄÇWe know that„ÄÇGetting all that meaning is„ÄÇEven more difficult and I think when we were looking at this problem„ÄÇ

 we saidÔºå okay„ÄÇWhy don't we see if we can just ignore that all that complicated background quants and those meetings„ÄÇ

 why let's see if we can even just„ÄÇExtract these relations„ÄÇBetween them„ÄÇ

 let's just extract these isolated relations„ÄÇOkay„ÄÇüòä„ÄÇ

So that we're still within the sort of narrow version of a knowledge graph and we're not trying to do„ÄÇ

More difficult or much harder portion of assembling a coherent graph from the book„ÄÇ

 let's just see if we can get these isolated micro fragments of a knowledge graph„ÄÇ

Now the other part of the problem is the semantic meanings right so we are using here relations such as has part and has function and and„ÄÇ

AgainÔºå you knowÔºå they these are not as„ÄÇCleanly defined as United Airlines is flying from Boston to Sacramento„ÄÇ

 you know there the definitions are very clear but here„ÄÇGetting formal definitions„ÄÇ

 it's it's a challenge in itself it's a problem in itself and it turns out that„ÄÇ

At least for this projectÔºå the biologists we were working with„ÄÇ

 they're not used to doing formal definitionsÔºå they've never even thought about coming up with formal definitions for these concepts„ÄÇ

NowÔºå just to sort of make it more concrete for you on„ÄÇThe problem and the challenge that we faced„ÄÇ

Is let's see you know how biologists define has part and has function„ÄÇ

 they actually like to refer to it as structure and function right and if if you talk to biologists you know you get a definition like this„ÄÇ

Structure and function are correlated at all levels of biological organization„ÄÇ

 the form fits functionÔºå and they would say that while you know the birds have these wings which are aerodynamically shaped and they help them fly„ÄÇ

And that's how sort of we think about structure and function or if you are if you have bones„ÄÇ

 bones have honeycomb structure and this honeycomb structure gives the bones strength„ÄÇ

 but it also keeps them light right and so that's sort of what you get that's sort what we got when we were talking to biologists about okay„ÄÇ

 give us the meaning of structure and function„ÄÇSo this by itselfÔºå you knowÔºå was not„ÄÇ

 we didn't think it was very useful from a computational point of viewÔºå so we saidÔºå okayÔºå well„ÄÇ

 is there a way we can approach this problem from a computational point of viewÔºüAnd„ÄÇüòä„ÄÇ

I think the way we like to think about this in the context of the designer knowledge graphs is to think in terms of competency questions„ÄÇ

 rightÔºå can we come up with a set of questions that our knowledge graph should be able to answerÔºü

And could we work backwards from there to definedÔºå what should be the meaning of the nodes and edgesÔºü

And so we came up with two broad categories of questions„ÄÇ

 diagnostic questions and educationally useful questions„ÄÇ

 and I'll give you examples of each of these categories of questions„ÄÇ

So diagnostic questions are questions which basically test whether the system has the knowledge„ÄÇ

 the basic knowledgeÔºå so if you ask the system questions such as what is the structure of and what is the function effects the system must be able to answer it right if the system cannot answer that then„ÄÇ

Âïä„ÄÇYou knowÔºå it doesn't even know what a structure and function is then what else can you expect it to do right„ÄÇ

 but you can answer these questions also a string lookup rightÔºü

So we wanted to go beyond that right that the question should not be simply a string lookup„ÄÇ

And in the definition of educationally useful questionsÔºå we said wellÔºå you know„ÄÇ

The question has to be pedagogically useful and it has to be Google hardÔºå Google hard in the sense„ÄÇ

 it's not a string lookupÔºå you have to do more calculationÔºå more computation to answer this question„ÄÇ

And it should not also be too hard rightÔºå because answering any question about the biology of„ÄÇ

 you knowÔºå mythsÔºå it's a open ended research problem„ÄÇ

 but it should be such that we should be able to solve it in a short amount of time„ÄÇ

So we came up with these five categories of educationally useful questionsÔºå and in this case„ÄÇ

 we here means teachers and students from a focus group that we had convened„ÄÇAnd„ÄÇThey gave us 100„ÄÇ

 200 or so questionsÔºå and then we sort of sat down and we categorize them into these five different categories„ÄÇ

How do you relate structure to functionÔºå how do you perform qualitative comparisons„ÄÇ

 how do you do similarity reasoningÔºå how do you understand the impact of changing the structure of something on its functionÔºü

And we can sort of look at some examplesÔºå so for exampleÔºå if the loop of Heley gets longer„ÄÇ

 how will its function be backÔºüSo let's say we want to answer that question„ÄÇAll right„ÄÇ

 so this was sort of a set of requirements working from this set of requirements„ÄÇCame up with„ÄÇ

A vocabulary or a set of relation definitions which should be present in our knowledge graph and we make made this list and from this you can see some of them are„ÄÇ

Purely meeroic in nature where we are modeling the structure of things„ÄÇ

 there are some relations which are spatialÔºå there are some relations which are about properties and„ÄÇ

We had a similar set of relationships for functionsÔºå but just for to keep the talk scope„ÄÇ

 I'm going to primarily focus on the structure relations because that is enough to give you„ÄÇ

The sense for„ÄÇThe complexity of the problem and the challenge that one faces in doing radiation extraction„ÄÇ

So then we spend a lot of time trying to come up with definitions for what these actually mean and this„ÄÇ

Set of definition which I also sometimes like to call it like a flow chart„ÄÇ

 may seem a little esotericÔºå but there is a lot of thought and a lot of literature behind this based on which we came up with„ÄÇ

And„ÄÇAnd the interesting connection between this sort of piece of ontology research with„ÄÇ

Information extraction is that„ÄÇThis is the source for our weak labeling functions right and when we do the relation extraction in a few slides„ÄÇ

And when we are looking for what should be in our weak labeling functionsÔºü

This this is one place where you could get them from„ÄÇOkay„ÄÇ

 so let me sort of quickly walk you through this through this logic„ÄÇ

 we have five relations has part element material possesses and has region right„ÄÇAnd„ÄÇüòäÔºåÁ¨¨„ÄÇüòä„ÄÇ

We can have any of these five relationships„ÄÇBetween two entities„ÄÇ

 if it makes sense to say x has y in EnglishÔºå right„ÄÇ

 if it doesn't make sense to say x has y in EnglishÔºå then„ÄÇ

None of these relationships quite likely would apply„ÄÇ

We would say x has region y if y is a regional space defined in relation to x„ÄÇ

And it does not make sense to associate why with properties such as mass or density okay„ÄÇ

 and everyday example of this would be let's say„ÄÇYou have a table and you want to say define the relationship between tabletop and table right and tabletop is a regional space which is defined in relation to a table and tabletop by itself doesn't have mass or density table does have mass in density but tabletop„ÄÇ

n't it's just a region of space„ÄÇWe say x as material y if y is tangible and is's pervasive in x„ÄÇ

Now continuing with the table example„ÄÇWood would be material for table because wood is a table is could be made of wood„ÄÇ

X has element y if x is a set of entities of the same type or sibling types that y is an instance of„ÄÇ

ÂóØ„ÄÇNowÔºå here the„ÄÇMore common example would be like if you have a DNA strand where DNAN strand is made of a set of nucleotides or you in more common sense well you have a necklace and you have a set of beads which constitute a necklace„ÄÇ

 so there the relationship between the necklace and the beads is the elementary relationship„ÄÇ

X possesses y only if y is energy bond or gradient„ÄÇNow you may sayÔºå oh„ÄÇ

 this is sort of very strange way of defining itÔºå but this is actually an example of example application of what Martyhurst„ÄÇ

Argues right so we had this possessed relationship and we went into the book and we see where they were using the possesses relationship and we tried to look for a generic pattern that we could specify when X possesses Y and at least for the biology book„ÄÇ

 this is the best we could come up with„ÄÇüòäÔºåThat they were using the word possesses whenever you know the entities happen to be energy bond or as and if none of these relations applies then the likely candidate is the has part relationship okay so I think this is the sort of semantic work semantic definition work which really distinguishes„ÄÇ

The knowledge graph relation extraction from open information extraction where in open information extraction you don't do this kind of work„ÄÇ

 you know you just see what's in the text and that becomes your relation okay„ÄÇAnd but here we are„ÄÇ

Trying to pay attention to what these relations meanÔºå how they are actually used„ÄÇ

 and how we might be able to aximatize themÔºå how we might be able to draw conclusions from them„ÄÇOkay„ÄÇ

 so having set up that framework and the problem definitionÔºå let's now talk about entity extraction„ÄÇ

And how we can take entity extraction techniques from the first part of the lecture to solve the problem we have here„ÄÇ

So we go back to our sentence and given this sentence„ÄÇ

 we want to extract plasma membrane carbohydrate side chain proteins and lipids that's what we want to get out of this„ÄÇ

Then the first question you would obviously ask isÔºå wellÔºå you knowÔºü

Where are we going to get the training data fromÔºüAnd our answer wasÔºå wellÔºå you knowÔºå textbooks have„ÄÇ

Glosies at the backÔºå you knowÔºå the author has already gone through the pain of figuring out what the key entities are and they have made a list that's our training data„ÄÇ

Now that's actually not a bad idea and actually a good idea„ÄÇ

 the only problem is that the glossies that tend to be not very complete they don't have everything that you want to extract from these sentences for your knowledge graph but hey you know it's available for free you don't have to do any work so„ÄÇ

Why not use it so that's what we did so what we did was we found about half a dozen different open source textbooks we processed them and we extracted the glossaries and then we we fed them into a language model' BRT we were using BRT we first trained BRT on these books„ÄÇ

 we we did a domain task independent training of Bt on these books„ÄÇ

And then we fed these glossaries into the language model„ÄÇ

And then we obviously had a dev set and the test set right in the development set„ÄÇ

 we had these about less than a dozen or so books on different topicsÔºå physicsÔºå psychology„ÄÇ

 microbiologyÔºå chemistryÔºå etctera„ÄÇAnd then we had a test depth set and the test setÔºå and in the test„ÄÇ

 you know we were feeding it sentences such as the one you see above here„ÄÇ

 all cells have cell membranesÔºå but only some have cell walls and we were expecting it to give us the sentence of the kind you see at the bottom„ÄÇ

 where it has to tell us the entitiesÔºå cellsÔºå cell membrane and cell walls because that's going to be a first step that we are going to need to build our knowledge graph„ÄÇ

So we tested this out and we found that the precision on this was not bad meaning it was 0„ÄÇ

67 you knowÔºå I'm saying not bad because„ÄÇIt's it's not 0„ÄÇ2 or 0„ÄÇ1Ôºå but it's certainly not 0„ÄÇ

99 of the kind that we would like to have in the book and the recall was even lower it was 0„ÄÇ

51 so I mean it was missing out on a lot of things you would want to extract but the beautiful thing about this was that okay this is all automatic you know you can do this you know once you have the code you know you could you could do this right away„ÄÇ

And at this pointÔºå you would askÔºå okay„ÄÇWhy why is it not be having better and if you wanted to make it better„ÄÇ

 how would we go about making it betterÔºüSo one sort of challenge that we„ÄÇ

Saw and we I mentioned in the previous part of the lecture was that there are multiple ways to refer to entities right so you could have DNA and then DNA is also same as the oxiv nu right and„ÄÇ

You have to somehow you either have to have a language model that tells you synonyms„ÄÇRight„ÄÇ

 if you don't have that and if you just have entity extraction„ÄÇ

 then entity extractor will think that these are two separate entities„ÄÇAnd similarlyÔºå you know„ÄÇ

 you may have situations like in a sentence where they are using membrane in another sentence where they're using cell membrane„ÄÇ

 but they're talking about the same thing„ÄÇAnd then you have to be able to disembegate between the two„ÄÇ

In biologyÔºå there are also a lot of unusual plurals„ÄÇ

 so you have things like mitochondria versus mitochondria„ÄÇ

 So we mitochondria is a plural form of mitochondriaÔºå but it's a kind of„ÄÇUnusual pluural„ÄÇ

And unless language model knows thatÔºå or unless you train your language model for pural detection„ÄÇ

 it's going to treat these as two separate entitiesÔºå rightÔºü

So I think one big lesson that we learned in this whole exercise was that a good lexicon is actually essential if you're going to do very high fidelity term extraction„ÄÇ

If you don't have this lexical knowledge or you train your language model to actually learn the lexicon also unless you do that„ÄÇ

The fidelity of information you're going to get through these language models is not going to be very satisfying to the domain actually„ÄÇ

OkayÔºå the main experts of the sort who are writing a bookÔºå OkayÔºå I should sort„ÄÇMake that yet„ÄÇ

And I think the other thing you would have observed by now is that„ÄÇ

This relation extraction problem is very different from the relation extraction problem I talked about in the first segment where we had basically people„ÄÇ

 placesÔºå companiesÔºå datesÔºå you know there are four or five classes of entities that we were trying to extract„ÄÇ

And hereÔºå the entities are much more varied„ÄÇAnd just even the definition of what counts as an entity is„ÄÇ

So little very different from what we tend to see in the conventional relation extraction task„ÄÇ

So for exampleÔºå the biologist would consider a 40 tumor suppressor„ÄÇ

Gene as as an entity and then the question is„ÄÇReallyÔºå is that an entity and this kind of entity„ÄÇ

 it's unlikely to exist in a very general language modelÔºå it's very peculiar to biology„ÄÇ

And then something like control of blood flow to skin„ÄÇ

 which is a very reasonable function that you may want to have in your knowledge graph„ÄÇ

But this is a phrase which is six words long and and doing it using language models its„ÄÇ

Currently outside the reach of the current language models„ÄÇ

And I had briefly mentioned these very general words like attack and synthesis„ÄÇ

 which you want to identify as nodes in your knowledge graphÔºå which„ÄÇ‰Ω†„ÄÇ

Current systems they won't obviously do„ÄÇAll right„ÄÇSo given that„ÄÇ

 let's now move on to the task of relation extraction„ÄÇ

 assuming you know we can do these entities and maybe we can do the correctionÔºå let's see if„ÄÇ

We can extract some of the relations we are interested in through these automatic methods„ÄÇ

Now let's go back to the sentence we were working withÔºå we have the entities as shown at the top„ÄÇ

 we have relations as shown at the„ÄÇBottom we've identified here that you know plasma membrane has part car side chain and because they are connected then they must be abuing each other so we are using one meeromic and one spatial relationship„ÄÇ

Now the first question that obviously arises here is where do we get the training data from now in this case we had some training data we could get from the existing knowledge base because we had a knowledge base we had hand built and there is this distance supervision technique using which you can„ÄÇ

If you already know some relationsÔºå you can map them to the textbook sentences„ÄÇAnd in addition„ÄÇ

 we use the weak supervision technique of Chris Ray style based on the semantic definitions of these relationships that I had alluded to earlier„ÄÇ

 so essentially the way the weak supervision works is we define a set of label functions„ÄÇ

We apply each of these label functions to every training instance that we have in our input and then we aggregate the input that these labels labeling functions are giving giving us into„ÄÇ

ÂóØ„ÄÇHard levelss and soft levelsÔºå hard levels are obtained based on the majority labels„ÄÇ

And soft labelsÔºå they are labels calculated by some probabilistic combination of how much we trust each of these labeling functions„ÄÇ

And then we have a very similar pipeline where we have the entities from our entity extraction step„ÄÇ

 we enumerate all pairs of entitiesÔºå and then we input them into our model„ÄÇ

 we train that model based on our pre-existing knowledge based and the weak labeling functions and the task of the model is to tell us what might be the likely relationship between the two entities that appear in a sense„ÄÇ

OkayÔºå so that was that was the process„ÄÇAgainÔºå the precision turned out to be in the range of 0„ÄÇ

65 and recall was in the range of 0„ÄÇ54 mean it misses out a lot of things„ÄÇ

 but a lot of things that it„ÄÇIt finds theyre not too badÔºå it's not like 10% or 20% accuracy„ÄÇ

 but it's also not 100% or 99%„ÄÇNow„ÄÇAt this pointÔºå the vision that„ÄÇ

 you know a lot of people get very excited is that whileÔºå you know„ÄÇ

You want to feed these books into these learning models and then get the entities and then feed those entities into second language model and then you get the relations and thenvoaha you'll get these knowledge graphs at the other end„ÄÇ

You knowÔºå people get excited about that„ÄÇBut because the precision and recall is not quite there this rosy picture doesn't quite pan out in in practice I don't think it's going to pan out anytime soon so the picture that I sort of„ÄÇ

Think how these technologies can be used for knowledge graph„ÄÇ

 highly accurate knowledge graph construction is to introduce a human review step„ÄÇ

 so you do some automatic term extraction and then you have a human actually look at what the model did and then you feed that into relation extraction then you have a human look at it and then there is this still undefined task of how do you take these triple level information and you sort of synthesize and fuse them or integrate them into a coherent knowledge graph„ÄÇ

You could also ask this questionÔºå you knowÔºå who is going to do the human review and the vision and the picture that I've been arguing for a while is that well„ÄÇ

 you know this should actually be done by a textbook author and it should just become part of the process of writing a book that you as you write the book you part process it through these tools and it gives you some useful information which will also help you improve the book„ÄÇ

And„ÄÇAnd yeahÔºå I meanÔºå againÔºå I think the people are sort of receptive to that ideaÔºå but I think then„ÄÇ

Ting that I try to do is to see well you know we need some kind of a futuristic glossary editor and a diagram editor and this glossary editor gives you way to bootstrap your glossary at the back of the book in a very comprehensive and text rooted manner and this diagram editor lets you visualize every single concept in the book and then people start saying that well you know author is never going to do this and well maybe there needs to be an author assistant a new kind of professional who works with the author and who is in charge of doing this kind of processing„ÄÇ

ËØ∂„ÄÇWhether somebody is going to buy into this kind of vision„ÄÇ

 you know that's still open to open to discussionÔºå but but this is sort of how I think these automated extraction technologies can potentially enable the authoring of highly accurate knowledge graphs„ÄÇ

So to summarizeÔºå what I've tried to argue in this lecture is that„ÄÇ

Enity extraction and relation extraction„ÄÇ They are sort of fundamental building blocks for„ÄÇ

Creating knowledge graphs from text„ÄÇÂëÉ„ÄÇAt least in sort of my version of the problem„ÄÇ

 the rule based methods or methods which start from the semantics of the relation„ÄÇ

And their potential aximatic definitionsÔºå that's really the place where we start from and we can use them for generating some training data and we can feed them into automatic methods and that I think is already popular paradigm„ÄÇ

 but sort of my own personal take on this is to bring in sort of more semantic definition from the from the ontology research and knowledge graph side of things so that what we are actually learning„ÄÇ

Are things that we can do principle inference with„ÄÇAnd finally„ÄÇ

 just to acknowledge entity linking and entity resolution„ÄÇ

 they eventually will play a big role in our ability to create these knowledge graphs„ÄÇ

As we're still struggling with doing well on the more primitive tasks of entity extraction and relation extraction„ÄÇ

I'm expecting that entity resolution in a few years might become„ÄÇAn equally important building block„ÄÇ

 eventually we will get thereÔºå but with the current state of the art„ÄÇ

 I don't think we are quite there yet„ÄÇWith thatÔºå I'd like to conclude my lecture here and we still have seven minutes left for any questions„ÄÇ

Co so sorryÔºå I joined itÔºå but I can I can see a few questions here„ÄÇOn the Q and A tab Okay„ÄÇ

 good so first question is could you mention again the author of approximate labeling function„ÄÇ

 please Yes do you in any specific paper„ÄÇ

![](img/608d70c57fd7ddd5c8f2f9fd20e9b000_2.png)

To read about the labeling for knowledge graphs using MLl Okay so the specific author is Chris Ray and Chris Ray„ÄÇ

 he gave a lecture in our seminar„ÄÇLast yearÔºå so if you see our series from last year„ÄÇ

 I think it was a second session where he talked about snorkel and his weak labeling approach„ÄÇ

So that's the technology we were using for this project„ÄÇOkayÔºå thank you„ÄÇSo the next question„ÄÇ

 could we have a link to the codeÔºå maybe in Gitthub or somewhere to try the labeling processÔºüYeah„ÄÇ

 so I think snorkel has become a commercial product now„ÄÇËØ∂ËØ∂„ÄÇI think they yeah„ÄÇ

 so and I think if you send me emailÔºå I can„ÄÇSend you a link to the code that we developed„ÄÇ

 which is in public open source„ÄÇ So just send me an email I can I can„ÄÇProvide reference„ÄÇYeah„ÄÇ

 so I have come across several open source projects in Github„ÄÇ Okay so search for search for„ÄÇ

NLP labeling and there are a couple of projects actually in that„ÄÇ

There's an open source project called Spacey„ÄÇAnd they have a new tool called Prodigy„ÄÇ

Which helps you label stuff alsoÔºå so that also works quite wellÔºå so there are quite a few examples„ÄÇ

And the last question here„ÄÇThat I see is are you using predicates such as has part has functionÔºüAnd„ÄÇ

Function from already published ontologiesÔºå or are you defining them internal to your systemÔºü

So I'd say a little bit of bothÔºå so we actually ourselves have a paper on the semantics of structure and function which we authored with the partnership with biologists„ÄÇ

 but as part of that paper we relate our definitions to whats„ÄÇ

In the broader ontology research literature„ÄÇSo we're not that different from what people are talking about in the literature there is certainly some adaptation like you might remember there was one slide in which I explained a flowchar of how you choose between these five relations right so that actually is based it's an adaptation of a piece of work that was done by Maria Ket she is one„ÄÇ

One of the researchers in the anthology research community„ÄÇ

 so we basically took her her framework and then we adapted it because she was not addressing all the nuances that we were seeing seeing in the book so so I think the short answer is yes what we're doing is compatible but I think we've also made some novel contribution to extending what is„ÄÇ

Already known about how to define the semantics of these structure and functional relationships„ÄÇCool„ÄÇ

 thank you„ÄÇ and one question just popped up in the last few seconds„ÄÇ

So this is a question about KG validation should it be done manually or by done by experts do you know of any systematic and automatic ways for doing that so I think Kg validation I view this as a research problem I don't think it is solved„ÄÇ

ÂëÉ„ÄÇI meanÔºå againÔºå I think the„ÄÇDoing it in a manual way is a starting point„ÄÇ

 but I think the way I think about this problem„ÄÇIn the context of the intelligent book that we were building was that once you have the KG„ÄÇ

 then you ought to be able to pose lots and lots of questions to the KG and you ought to be able to show the answers to an expert„ÄÇ

And expert should be able to validate those answers„ÄÇThat's sort of how we were doing the process„ÄÇ

But I think once you have that framework in placeÔºå there's no reason why you could not put it on a crowdsourcing platform where„ÄÇ

You have multiple students reading the answer or multiple teachers rating the answers„ÄÇSoÔºå that„ÄÇ

The cost of actually doing the validation is not part of your project you can somehow sort of form it out the to the crowd platform right but it's it's I don't think it has been worked out„ÄÇ

And it's open research OkayÔºå and on a related question related topic„ÄÇ

 I have a question in your projectÔºå did you use any implicit„ÄÇ

Feedback mechanisms for validation like Google will collect your clicks and then validate a lot of their algorithm„ÄÇ

 anything you did on the students„ÄÇLike measure what they clicked on or something like that yeah we we don't have that we did not know that yet so you do not capture did you capture the clicks and English you have the capture of the clicks„ÄÇ

 but we have not utilized it okay„ÄÇSo yeahÔºå I think that's it„ÄÇOn the questions here„ÄÇ

 there was something in the chat in the chat„ÄÇDo you use a draft DbÔºå which draft D is recommendedÔºüËØ∂„ÄÇ

While we were using at the time what you can call it a logic programming system„ÄÇ

 that's sort of what we have in the guts of the current prototype and if you were to ever rebuild it„ÄÇ

 it would be some version of that„ÄÇÂóØ„ÄÇIn terms of which graph D you recommend„ÄÇ

Nine has been planning a lecture towards the end of the series where he will give us a sort of survey of the tools available„ÄÇ

And what people should consider looking atÔºå so I think we should def that question to that lecture„ÄÇ

Sounds good„ÄÇ I will keep this in mind„ÄÇ This question in mind when I„ÄÇ‰∏ç that„ÄÇCo„ÄÇ

 I think we are done OkayÔºå MikeÔºå do you have anything to addÔºüÂóØ„ÄÇ

I don't think so unless you want to have a long long drawn out argument about rule base versus machine learning or intelligent textbooks„ÄÇ

 but exactly they areÔºå but I'm just impressed with how much how cool the tool that you built is„ÄÇ

I would like it to see it go fartherÔºå but I'm happy to see that it's gotten as far as it has„ÄÇ

All rightÔºå wellÔºå that's a great„ÄÇGreat closing statement„ÄÇ

 thank you Mike for your support and inspiration„ÄÇAnd I will conclude and we will continue our series on Thursday on Thursday we have two fantastic speakers„ÄÇ

 Adier KanurÔºå who worked on the team that had built the jeopardy system at IBM„ÄÇ

 he will be talking about his current work on creating causal graphs for understanding natural language and we will have a second speaker Ranja Krishna„ÄÇ

 who defended his PhD thesis on FridayÔºå he will be talking about how he has been using scene graphs for image understanding„ÄÇ

So we will see you on ThursdayÔºå thank you very much„ÄÇÊãúÊãú„ÄÇ

