# P27ï¼šL10.1- çŸ©é˜µä¹˜æ³• - ShowMeAI - BV17h411W7bk

![](img/cc9141875dbcc8c4f438d1c801c2d53e_0.png)

This is chapter 10 on matrix multiplication so far we've seen well a couple of different kinds of multiplication if you like you can think of the inner product as a multiplication of two vectors we've seen matrix vector multiplication and now we're going to step it up one and look at matrix matrix multiplication you can multiply two matrices we're going to see that has a lot of usesã€‚



![](img/cc9141875dbcc8c4f438d1c801c2d53e_2.png)

okã€‚So if I have an M by P matrix and a P by n matrix the first one is a and the second one is B and note that the matrix A has a number of columns that's P which is equal to the number of rows of B that is critical okay I can multiply A and B to get another matrixã€‚

 which I'll call C and we're simply going to write it as A Bã€‚

 so we're heavily overloading multiplication notation the ordinary ordinary multiplication notation is by simply you put two things together right so next to each other so if I say something like you know just put them together we do that with matrix vector multiplication but here it's matrix matrix okay manã€‚

Here to say what C isï¼Œ I have to tell you what its entries are and so it IJ entry is a sum of products of entries of a and entries of B and here's what they are I sum over AIK that's walking across the Ih row of A and I'm multiply those by BKJ now here J is fixed and so K is changing in my sum and I'm walking down the J column of Bã€‚

ðŸ¤§And I can write it out that way if you don't like the sum notation Okay and so very roughly speakingã€‚

 here's how you get the Ij entry of the product matrix you move along the if row of a and you move down the J column of B and you roughly speaking take the inner product or the you know basically you take the sum of the products of the corresponding numbers Okay so let's do an example and by the wayã€‚

 you may have seen this in a previous course as well so I just want to make sure everyone's on the same page Okayã€‚

 so for exampleï¼Œ here is a two by three matrix and here is a three by two matrix and the thing we have to check is that the intermediary dimensionã€‚

Is the sameï¼Œ So the number of columns of the first matrixã€‚

Is equal to the number of rows of the second and indeed it is three is equal to three and the result is actually two by two okayã€‚

 so before you ever multipied two matricesï¼Œ you must do perform this syntax check just to make sure if it's a valid product okayã€‚

 so this is validã€‚Wouldn't be an example on the slides if it weren'tï¼Œ but okay all rightã€‚

 then let's actually figure out how to do thisã€‚ Wellã€‚

 the first entry that's gonna be C11 and that's obtained by going across the first column here and down the first sorry across the first row here and down the first column here and indeed it's minus1ã€‚

5 plus3 times 0 which is0 plus2 and you should get this so that should be your number it's right so okay allrightã€‚

 let let's audit another entryã€‚ How about let's try this one Okay so to get the22 entry of C we would go along the second row of a and down the second column and let's just check it get one times minus1 Okay that's minus1 plus minus1 times minus2 is2 So we're up to1 and then 0 times  zero So we're one and it's correct Okay so by the wayã€‚

 at this pointã€‚Qualplication this is like the rules of chess it should have no interest there's there's no reason you should have any interest in this yet so you have to take me on my word that this is actually going to be super useful and super important but for the moment it's just these are just the rules this is how you do it okayã€‚

So there are we've already seen various types of multiplication and they're all actually special cases of matrix multiplication So here's one we saw the scalar vector product and we would write it as alpha X where alpha is a scalar and x is a vector now it turns out that's not a special case of matrix multiplication has got the wrong the sizes are wrong alpha is like one by one and let's say x is n by one right so you could see the intermediary dimensions don't line up so in factã€‚

 howeverï¼Œ if you do scalar multiplication with a scalar on the rightã€‚

 it actually works and it's exactly the same now for some I guess this is just the quirks of mathematical notation people don't write a vector with a scalar on the right although I think what this shows you is they should but nevertheless they I mean if someone doesã€‚

no one would think I mean they would think it's weirdã€‚

 but they would fully understand what you're saying you could even explain this and then they go oh cool that's evenã€‚

Good for you okay so so just mathematical notation convention is we don't write a scalar rec multi usually with a scalar on the right almost always it's in the front and that's just that's a tradition that goes back probably a couple hundred years by now so that's how we do it all rightã€‚

Inner product is actually nowã€‚It's a perfect example of this right so this says you have two n vectors A and Bã€‚

 and it says you form the transpose and so a a is n by one a transpose is1 by nã€‚B is n by oneã€‚

 Sure enoughï¼Œ the intermediary dimensions are the sameï¼Œ and so you can multiply themã€‚

 and the result' is gonna to be a one by one by one matrixã€‚

 which we interpret as a scalar okay or a number and it is exactly the inner product matrix vector multiplicationã€‚

 That's oneã€‚ So here a is M by n let's say and x is n by one and sure enoughã€‚

 you can multiply them you can think of x as a sorry as a matrix and then perform matrix vector matrix matrix multiplication and it's the same as matrix vector multiplication okayã€‚

A we can now tell you about something called the outer product of two vectorsã€‚ so two vectorsã€‚

 by the wayï¼Œ of any of any sizeï¼Œ it doesn't because it always worksã€‚

 So if I have an M vector A and an n vector B I can form a B transpoposedse now toã€‚

Figure out what this means A is an M vectorï¼Œ so it is M by1 and B is n by1 B transpose is1 by nã€‚

And sure enoughï¼Œ the intermediary dimension is oneã€‚And when when you work out what it isã€‚

 it creates a matrix which is M by n and the entries are all products of all possible entries of a with B Okayã€‚

 so that's called the outer product you've seen the inner product and you can see it's they're very close in terms of this notation right one is a transpose B that gives you a scalar and A B transpose that gives you a matrix it's called the outer product Well we'll encounter that a couple of times promptã€‚

Okay now matrix multiification is a bunch of properties that hold I'm actually not going to show them I mean somebody has to or should you could trust me that's an option I suppose at this point or you can audit one or two of these yourself so but I'll go over them and say kind of what they mean it's super important that you stay on your toes with this notation to make sure everything here works so here I have three matrices oh and the imã€‚

 the assumption generally is this is that when I write down products of matrices like AB the assumption is that that's a valid product right and oh so some people would say that they are compatible or something like that or it just means the intermediary dimension is is correct right so when I'm writing down here whenever you see things like that the assumption is that that everything is correct right if I then later tell you a has this dimensionã€‚

B has its C has then you raise a big alarm and you goï¼Œ heyã€‚

 you can't multiply A B makes no sense or something like that so okayã€‚

This has multiply the two matrices A and B first and then multipied by C on the rightã€‚

Then it turns out that's the same as if I multipied the matrices B and C and then multiplied by a on the leftã€‚

And so what that means is we can write both as the triple product ABC right because what it says is that when you write down the product of three matricesã€‚

 it doesn't matter whether you multiply A and B first and then C or B and C first and then A so that's an important thing okay it distributes so A matrix times B plus C is equal to A B plus A now you have to be super duper on your toes here in this equation first of allã€‚

 it must be that that B and C have the same size otherwise you can you have no right to add them dont have the right it just means nothing if they are not the same size so presumably in this line B and C have the same size and this is the plus that's the addition of matrices so it says add the matrices B and C multipied by A on the left over here it's different this says multiply first A by Bã€‚

hen a by C and then add them so this is also matrix additionã€‚

 but it it's possibly a different size matrix right so okayã€‚Here's oneã€‚

A B quantity transpose is is B transpose A transposeã€‚ So roughly speakingã€‚

 the product transpose is theã€‚The product in reverse order of the matrices themselves transposedã€‚

And honestly it's easier just to look at the equation okay so it like it looks like this right very important rule so and you might not think that right because for example aestheticallyã€‚

You might say yeahï¼Œ I don't know this looks reasonable right it looks reasonable It is very and deeply wrong for many reasonsã€‚

 I mean first of allï¼Œ it's just falseï¼Œ but the other thing is it's a lot of times doesn't make any sense right that depending on the dimensions of A and B A transpose and B transpose always make sense but you can't multiply them necessarily So this is just wrong Okay here's one a times the identity is a if I multiply on the right by an identity matrixã€‚

 I get a if I multiply on the left by an identity matrix I get a and by the wayã€‚

 these two eyes are of different sizes if a is M by N this I is N by n that identity matrix and this I is M by M so here you just get things from you get the dimensions which are ambiguous because I didn't say what size I is in the two equations you get it from the syntax of the equations okayã€‚

æœ‰ã€‚Here's something superï¼Œ duper importantï¼Œ it's very importantã€‚The planet A Bã€‚

Is not necessarily equal to product B actually it's worse than that even if you can multiply A Bã€‚

 theres no reason to believe that you can multiply B it may be incompatible Okay but even when it does make sense it's even when A B and B are both valid products they are not they need not be equal to each other nowã€‚

 of course in some cases they are argument example you know A times I equals I times a and a has let's make a yeahã€‚

 but just leave it this way A is squared in this case right so the two I are the same matrix at the same sizeã€‚

That's trueï¼Œ by the wayï¼Œ when two matricesï¼Œ when you multiply them together and you get the same resultã€‚

 they have to be square if you get the same resultã€‚No matter which order you multiply them inã€‚

 that's called commutativeï¼Œ they commuteï¼Œ it means you can kind of put them in you can multiply them in either orderã€‚

 okayï¼Œ but in general that doesn't holdï¼Œ that's a very important factã€‚Okayã€‚

 now block matrices will work with matrix multiplicationï¼Œ so for exampleï¼Œ hereï¼Œ first of allã€‚

 this would simply be the formula for if ABCï¼Œ Dï¼Œ E FGH were numbersã€‚

 this would be a two by two matrix two by two matrix and that's a two by two matrix and this is indeed the correct formula for what happens when you multiply two two by two matricesã€‚

Howeverï¼Œ what cool here is that here these could be blocks so that's a block two by two matrix that these are block matrices so ABC and D can themselves be matrices as can EFG and H now for all of this to make senseã€‚

Everything has toï¼Œ you know any matrix I write down here when I'm multiplying has to have the right I mean things have to have the right dimensions or otherwise this is all well it's meaningless right but if these are valid products then this this identity holds so it says that we can do matrix multiplication by blocks which is actually kind of cool one very important thing and that goes back to this factã€‚

Is you when you're messing with matrices and run down equationsã€‚

You have to be very careful with the order of them so A B is not B A so don't do don't do anything that depends on A Bã€‚

 B B Aï¼Œ which you're used to because that's true for numbers the product of two and3 is the product of three and 2 but the product of two matrices in reverse order when it makes sense need not be the same as the other oneã€‚

 So just be super careful about keeping the order right So for exampleã€‚

 in this formula up here if A B C Dï¼Œ E FGH were numbers I could remove that and write Eã€‚

It would be trueï¼Œ it would still be correct becauseã€‚

EA and AE are the same provided that they're scrs right if however theirre matricesã€‚

 they're not the same and then this what I've written down here is just wrong Okay so you just have to be very careful its order mattersã€‚

Okayï¼Œ now we'll give a couple of interpretations and we'll be using all of these basically throughout this SQL the rest of the courseã€‚

 so if you denoteã€‚Let's first write out B in the product A B as a columns Okayã€‚

 so it's B1 B2 up to B N right so and remember that B is going to be P by N and A is going to be M by Pã€‚

 this is A and this is B Okay so it's going to look like that and if I work out what A B is actually I can do this by block matrix multiplication So I simply write B as a block matrix where the blocks are the columnsã€‚

And then I just multiply out as if these were numbers or whatever and I get being very careful with the order and I get A B1 and then A B2 and each of these is a column and so now what you can see is one interpretation of a matrix A times a matrix B is it is simply it works column by column it just says take the matrix B multiply every column of B by a and then rearrange them into a matrix so you could think of it as some people think of aB as a batch multiply of a times all the columns of B so that's one way people think of itã€‚

As an exampleï¼Œ we can represent multiple sets of linear equations with a very compact notationã€‚

 so remember that a system of linear equations looks like Ax equals Bã€‚

 that's a system of linear equationsã€‚If this is if there's if a is M by n this is M equations in the n variablesã€‚

 which is x B has size M here have dimension n M okayã€‚

 but now suppose we have multiple linear equationsï¼Œ but with the same coefficient matrix Aã€‚

 but with different righthand sides B I well we can write that in super compact notation this wayã€‚

 and now I have basically a system of linear equationsã€‚

X is a matrix and it literally means that its columns are different are the different x's and b's of a different B so so that's by the wayã€‚

 this is going to be important later in the course but this is kind of the idea so it's super compact notation if you write stuff out this wayã€‚

Okayï¼Œ another very useful interpretation for us is going to be the inner product interpretationã€‚

 So as you knowï¼Œ to calculate an entry of the productï¼Œ you go along the row of a if it's a times Bã€‚

 you go along a certain row of a and down a certain column of Bã€‚

 very roughly speaking you're taking the inner product of a row of a and a column of Bã€‚ Wellã€‚

 we can write it out this wayã€‚ we can say that A B is the following matrix is it's the first row of a times I should say the first column of B that's a1 transpose times B1 and so onã€‚

 And so what it is is you could think of this as a matrix product gives you all the inner products of the rows of aã€‚

 and the columns of B and then arranged into a matrixã€‚

 So that's a perfectly good way to think about matrix multiplicationsã€‚

 It's useful actually all these different waysã€‚ They're not very hard to work out they're all related and they're all useful in different settingsã€‚

So here's a matrix that's going to come up pretty often in the sequelï¼Œ it's called the Gm matrixã€‚

 that's the gram is the name of a mathematician from the 19th centuryã€‚

 so let's let a be an M by N matrix and its columns are A1 through AN and each of those is an M vectorã€‚

Okayï¼Œ wellï¼Œ the gra matrix is simply this boyã€‚ it's a very compact notationã€‚

 It's G equals a transpose Aã€‚ A transpose Aã€‚ That's something you're going to be seeing a lot ofã€‚

 to be honestã€‚ So get used to itã€‚ but it's got a beautiful interpretationã€‚

 So the entries of a transpose A are exactly the followingã€‚ They areã€‚

 The first entry is a1 transpose a1ã€‚ but you know what that isã€‚

 That's actually the norm squared of a1ã€‚ðŸ˜Šï¼ŒOkayï¼Œ so the one two entry is the inner product of the first and second columnã€‚

Okay by the wayï¼Œ the two1 entry is the product of it's the inner product of the second column of the firstã€‚

 but you know that inner product does commute so these are the same number and what that says is the matrix G is a symmetric matrix right which means that if you transpose itã€‚

 you get back the same matrixã€‚It means that it's IJ entry and its J I entry are the same Okay so anyway this is the gram matrix it says super useful we can also use super fancy we can use matrixã€‚

Mattrix arguments to showã€‚The G is symmetricã€‚ So if I say that if I want to know what is G transposeã€‚

 wellï¼Œ that's a transpose a transposeï¼Œ Okayï¼Œ but that's the product of two matrices and then transpoposedã€‚

 But we know what that isã€‚ That's simply the transpose of the second matrix and then times the transpose of the first matrixã€‚

 So this is equal to a transpose times a transpose transposeã€‚

But wait a minute a transpose transpose is a if I transpose a matrix twice I get back the matrixã€‚

 so this is actually a transpose a heyï¼Œ but that's G and this string of equality says that G transpose is G that means G is symmetric okay so here's something you can do with the gram matrix that it gives you a very compact way to describe a concept that we already have it's a transpose a equals Iã€‚

Super interestingï¼Œ It means that if you look at thisï¼Œ if you look at this matrix hereã€‚

 it's ones on the diagonal and zero offã€‚ Let's see what that meansã€‚ Wellã€‚

 if a transpo if a1 transpose a1 is1ï¼Œ that means the length of the norm of a1 is1 same for a2ã€‚

 And so what it says is the diagonal of the gram matrix is equal to they're all onesã€‚

Provided all of the columns of a have the same normï¼Œ which is oneã€‚ Okayï¼Œ so that's normalizedã€‚

 but now let's look at off diagon entryã€‚ Ifï¼Œ if this is Iï¼Œ it means the off diagon entries are0ã€‚

 So that says that a1 transpose a2 is0ã€‚ That means that a1 and A2 are orthogonalã€‚

 but so are a1 and A3 and a1 and A4 and so onã€‚ And so basically the super compact equationã€‚

 a transpose a equals Iã€‚Is a way to say that the columns of a are orthoormalã€‚

 they each have norm one and different columns are orthogonalã€‚

 they have an inner product of zero Okayï¼Œ so this is the gram matrixã€‚

Let say a little bit about the complexity of multiplying two matrices actually this is a super interesting topicã€‚

 I might say a little bit about it in a minuteï¼Œ but so the basic way is here is a is M by P and then B is P by N okay so now to get an entry and every entry of Cã€‚

Is basically an inner product so and what I'm going to do is you know that the number of flops to calculate a p long inner product is actually 2 p minus1ã€‚

 but we skip the minus1 and no one pays any attention it's just2 p and so C you have to get all the entries of C C is going to end up being M by N So I have to do for all the entries I have to calculate inner product and I get two m and p flops So basically the total number of flops required to multiply two matricesã€‚

Is the product of their dimensions well the intermediary dimensions which have to match on the two matrices have to be the same and so it's the product of the three numbers that's it so for exampleã€‚

 if I were to multiply 2000 by00 matrices that requires two billion fluxps right soã€‚By the wayã€‚

 that this is a lotï¼Œ rightï¼Œ I mean these are bigï¼Œ I mean if you think about itï¼Œ these are very bigã€‚

 like if someone says what's a00 by a0 matrixï¼Œ you'd sayï¼Œ ohã€‚

 it's a rectangular array of 1 million numbersã€‚It's a lot at least to a person it's a whole lot right and then you multiply the two together and you say that would require two billion floating point operations so if you had to do this by hand or with a you know or with a slide rule or an abacus it's going to take you a long timeã€‚

So on my laptopï¼Œ which is way old nowï¼Œ I can do this in about 01 secondsã€‚That'sã€‚

Crazy what I just said and actually it's a very importantï¼Œ you knowã€‚

 all the math we're doing was just as true and just as interesting in 1830 or 1880 or something like that or 1950ã€‚

This is what you didn't have in 1950 was the ability to actually do these do the calculations that we're talking about in this course at truly stunning speeds I meanã€‚

 so this is just stunning so I guarantee on your homework you will one of your homework problems will be to multiply 2000 by000 matrices and then have a moment of quiet to sit there and appreciate how like awesome that is that the little processor in your laptop or whatever you're doing this on for that minuteã€‚

 you get it is on a phone but the point is to sit there and have a moment of silence to just recognize how awesome it is that two billion floating point operations were' just carried out for you in about a tenth0 of a secondã€‚



![](img/cc9141875dbcc8c4f438d1c801c2d53e_4.png)

![](img/cc9141875dbcc8c4f438d1c801c2d53e_5.png)