# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÊñØÂù¶Á¶èENGR108 ÔΩú Áü©ÈòµËÆ∫‰∏éÂ∫îÁî®Á∫øÊÄß‰ª£Êï∞(2020¬∑ÂÆåÊï¥Áâà) - P24ÔºöL8.2- Á∫øÊÄßÂáΩÊï∞Ê®°Âûã - ShowMeAI - BV17h411W7bk

![](img/ca4fd7b9cd781730b6609d082efedcc0_0.png)

So in many applicationsÔºå relations between an in vectoror and an in vectoror either are approximated sometimes the approximation is very good as linear or aline right so sometimes the approximation is really good and holds over like you know holds out at the you know fifth and sixth decimal place or something and example of that would be electromagnetics or for example acoustics there are many cases where it's just like that function is basically linear now sometimes it is the approximation is just it's pretty good over smaller ranges so for example aircraft dynamics right if I take an airplane and I ask what are the forces and torques that are put on the airplane you know as a function of its speed and sort of the angle of it the angle of attack and the control surface deflections that's approximately„ÄÇ



![](img/ca4fd7b9cd781730b6609d082efedcc0_2.png)

fineine for you know reasonable rangesÔºå certainly for most of the ranges that you would be comfortable flying an airplane in„ÄÇ

 but it doesn't hold when when you you know the airplane is like falling out of the sky or upside down or something like that„ÄÇ

 okay„ÄÇNow in other cases still the approximation is quite approximate like its plusmin is 50% or worse but it's still super useful so that's for example in econometric models right so I mean just to put something on this„ÄÇ

 you know my colleagues in electrical engineering when they're doing E&M you know their models they can predict things to three significant figures quite easily right so that's good my friends who work at hedge funds they basically put it this way„ÄÇ

 they say we're happy if we get the sign right okay so but nevertheless it's still useful„ÄÇOkay„ÄÇ

 so our first example is from economics„ÄÇSo here we have end goods or services„ÄÇ

 I'll just imagine them to be end goods and we have the prices for those goods„ÄÇ

 the market prices are given by an Nveor P here so P3 is the current price of item or good3 and we have demand and that's given as an nveor D So D4 is the demand„ÄÇ

 the number of units of good4 okay and then what you do is what we're going to do is we're gonna imagine changing the prices and so what we do is we take the new price that's Pi new that's the new price for item or good I minus Pi so if that's positive it's a price increase if it's negative it's a decrease and we divide by pi or the prices I should say are all positive and that has a beautiful interpretation is the fractional change in prices and we're going to call that deelta price sub„ÄÇ

Right so if that is equal to plus 0„ÄÇ1 that means basically you just increase the price of that item by 10% right if it's minus 0„ÄÇ

05Ôºå that means you just decrease the price on that item by 5% Okay so highly interpretable so that's what the deelta vector gives you delta price vector it tells you the fractional changes in the prices for those goods„ÄÇ

Okay now we do the same with demand right we have the fractional change in demand right so if we subtract from the new demand„ÄÇ

 we subtract the current demand or something like that we divide by the current demand„ÄÇ

And demand alsoÔºå by the wayÔºå is positive„ÄÇ And so this is the fractional change in the demands right so that that's how that that's the idea„ÄÇ

 SoÔºå for exampleÔºå if deelta Dm sub2 is minus 0„ÄÇ1 that says that the change in demand for good or item two went down 10%„ÄÇ

 So highly interpretable okay now clearly there's some relation between the prices and demands„ÄÇ

 we all know that if you have a single thing and you increase the price„ÄÇ

 the demand goes down okay and what relates them is called elasticity the elasticityÔºå in fact„ÄÇ

 that's called the price demand elasticity and for multiple goods„ÄÇ

 there's a very common model and it looks like this It says that the vector of demands is a matrix E called the elasticity matrix times„ÄÇ

The relative changes in pricesÔºå Delta priceÔºå okayÔºüNow that's super interesting A is an E is an n by N matrix„ÄÇ

 it's called the elasticity matrixÔºå and it's highly interpretable and it's very important to understand like what it means so for example„ÄÇ

 E11 is minus 0„ÄÇ3„ÄÇWhat does that meanÔºå WellÔºå E11 tells you how much does the price of the first entry tells you sorry„ÄÇ

 how much is the demand that's the firstÔºå the first one„ÄÇ So we say one„ÄÇ

 How much is the demand for item one„ÄÇChange per fractional change in the price of item 1„ÄÇ

 And this is -„ÄÇ3„ÄÇ And so hereÔºå here's a specific„ÄÇ This is a very specific conclusion„ÄÇ

 This says if you increaseÔºå if you increase the price by 10 by let'ssÔºå let's make it lessÔºå like„ÄÇ

 let's increase it by 1%Ôºå rightÔºå if we increase the price for item 1 or good one by 10%„ÄÇOur model„ÄÇ

 that price demand elasticity model predicts that the demand will go down by 03%„ÄÇ Okay„ÄÇ

 so that's what it says„ÄÇ OhÔºå you can ask another question„ÄÇ

 does your profit go up or down and that depends on how much it costs you to manufacture all that sort of stuff So we' here we're just predicting how the demand is going to change Of course„ÄÇ

People are interested in how the demand is going to change for two reasons number one for supply chain you want to make sure you can you can actually have that amount of that good on hand and the other thing is you want to find out what happens your profit does it go up or down okay so all right„ÄÇ

E12 equals plus 0„ÄÇ1„ÄÇSuper interestingÔºå let's see what it says that says that under the price demand elasticity model„ÄÇ

 if you increase the price„ÄÇOf„ÄÇGood2 byÔºå let's sayÔºå1%„ÄÇ This says you can„ÄÇ

 you can expect the demand for good number one to go up by 01%„ÄÇ

So increasing the price of the second good increases the demand of the first good now„ÄÇ

That comes up all the time and what people call in economics„ÄÇ

 these are referred to as substitutes right that you know when that somehow if people say oh„ÄÇ

 that's more expensiveÔºå I'm not I'm buying less of it right so that would be E22 you know is minus you know 02 or something right so if you increase the price it says that the demand for good2 the demand for good2 goes down but demand for good1 goes up because there's somehow you know you know their substitutes right so thats that's the idea here's one E23 was minus 0„ÄÇ

05 that tells you that if if you increase the price of good 5 it says that the demand for good2 goes down„ÄÇ

And sorryÔºå if you sorryÔºå if you increase the price for good3„ÄÇ

 then the demand for good2 goes down and it's quite specific about how much it goes down„ÄÇ

 it's not much rightÔºå but so what that usually says that you know I mean the typical thing would be if you increase the price for shoes„ÄÇ

 you know of course the demand for shoes goes down„ÄÇ

 but also the demand for socks goes down or something like that„ÄÇ

 I mean okay so and there's a name for that in economicsÔºå which I've forgotten but this is the idea„ÄÇ

 but it's a very very common modelÔºå of course it's only accurate for small changes right if I double or triple the price„ÄÇ

 I would hardly expect this thingÔºå this simple modelÔºå the simple linear model to hold„ÄÇ

 but first small changes it's actually pretty good so it's a pretty good way to predict stuff„ÄÇOkay„ÄÇ

The next one is another source of aine models is directly from well differential calculusÔºå in fact„ÄÇ

 you can even say the differential calculus is nothing more than an organized way to come up with an aine approximation of a function a function given by a formula so you can whatever do all your derivatives and stuff okay so here the setting is suppose we have a function from Rn to RM and it's a differentiable okay and the first order Tayloror expansion of F hat is called F hat of F near Z is equal to this it is equal to„ÄÇ

NowÔºå to tell you what my approximation is I have to tell you what each of its component is„ÄÇ

 so I'm telling you what the I component isÔºå it's f hat I of X is equal to F of Z„ÄÇ

 that's the value of F at Z plus and then I have a whole bunch of little terms hereÔºå each tells you„ÄÇ

About how much you've changed x from Z and then you multipied by the associated partial derivative so that's just the Taylor expansion and you've seen that before and that we write out this way„ÄÇ

 in fact we've seen this in previous lectures it's an interpretation of the inner product so it says that Fi had of X is Fi out of z plus the gradient of Fi at z inner product with X minus z which is an x minus z is interpreted as the deviation of X from Z okay and in compact notation people write that this way„ÄÇ

F hat of x equals F of Z plus Df of Z times x minus Z„ÄÇ Okay now Df is an M by N„ÄÇ

 It's called a derivative matrixÔºå Jacobian matrix„ÄÇ It's got other names depending on the field„ÄÇ

 right And in some casesÔºå it's very specificÔºå rightÔºå It's about„ÄÇ

 I mean it's got all sorts of names like anywayÔºå depending on the field for specific applications„ÄÇ

 But here it's called the derivative or the Jacobian matrix„ÄÇ And it's a very simpleÔºå you know„ÄÇ

 thing it looks like that„ÄÇ It says that roughly speaking„ÄÇ

 it says your approximation is the value at at Z„ÄÇ NowÔºå these are all M vectors„ÄÇ

 It's the value at Z plus an M by n matrix times your deviation from Z on your input right„ÄÇ

 So that's kind of the idea„ÄÇ And this thing you can think of it„ÄÇ this way„ÄÇ

 this derivative matrix has rowsÔºå which are the transposes of the gradients„ÄÇ

Of the entries of F or you could think about this that this is a matrix and to get its Ij entry„ÄÇ

 you take the partial derivative of Fi with respect to Xj and that's what it is so it's so another way to say it is Df of X is the matrix actually this should be a Z sorry about that it says that it is the matrix of partial derivatives is what this matrix is okay„ÄÇ

And the idea is that that is a very good approximation of x for x Ne z and it's an aine function„ÄÇ

 so I mean it's not clear it's an aine functionÔºå well I think it is we could write it this way you could write as DF„ÄÇ

Of Z times X„ÄÇ That's sort of like the A X„ÄÇ And then the B term looks like this„ÄÇ I'll put it together„ÄÇ

 It's F of Z minus„ÄÇD F of Z transpose Z like that„ÄÇ OkayÔºå so this is sort of like a„ÄÇ

 And this thing here is sort of like B in the in in the way you write an aine function out„ÄÇ Okay„ÄÇ

 so this is this isÔºå so thisÔºå this is a giant source„ÄÇOf aine functions„ÄÇ

 it's simply you do a first order Taylor series expansion of your function„ÄÇ

 and that's going to give you an aine function„ÄÇAnother one where it comes up is in statistics„ÄÇ

 machine learning„ÄÇAnd prediction so and it's called a regression model you've already seen this before„ÄÇ

 but it's it's worth here we can actually stack it into some vectors and I'll explain how that works Okay„ÄÇ

 so the regression model remember looks like this it's it's Y hat equals x transpose beta or the inner product of x and beta plus V okay now here x is an n vector of features or regressiongressors depends you know so these could be attributes of a patient or anything else attributes of a person or a customer or of an email or something like that it doesn't matter„ÄÇ

So's that's what x is beta is an n vector of model parameters and v is the so-called offset parameter and then this produces a scalar a scalar y hat and that's our prediction remember that a hat on top of something is not universal but common mathematical it' certainly an applied math it hints that it's an approximation of something and in this case it's an approximation of y y we assume is what the actual observed value was„ÄÇ

ü§ßNow suppose that we have a so called data set and a data set is going to be we have a set of we have capital n samples and x1 up to XN those are vectors right and then I have the associated responses and those are y1 through YN okay now„ÄÇ

This is just these are just like some observedÔºå it's a data setÔºå it's observed data„ÄÇ

Now we can also for each of the x1 through XNÔºå for each of our data our observed or data sample features„ÄÇ

 we can actually calculate what the prediction isÔºå y hat I is this now„ÄÇI mean„ÄÇ

 it's clear a super good predicting what we really wantÔºå of courseÔºå is this we want why„ÄÇI„ÄÇ

 to be approximately equal to why„ÄÇOf I like that so that that's what we've want if they're close that we'd say that that your model does a very good job predicting why that's that's that's the idea„ÄÇ

OkayÔºå so what we'll do is we're going to stack„ÄÇWe're going to stack our data set we're going to form a matrix and a vector out of it so what I'll do is I'll form a vector Y hat D D is for data and it's simply stacks the observed Ys on top of each other it's a capital n vector and I'll make a feature matrix with the columns X1 up to Xn by the way it's also very common in in fact honestly it's more common in statistics to work with the transpose of x but you just have to figure that out„ÄÇ

When you go to your internship and someone saysÔºå here's the data matrix„ÄÇ

 you have to figure out are they talking about other columnsÔºå the features or other rows and„ÄÇ

While in this bookÔºå we make the columns the features„ÄÇ

 it's probably more common on the streets for people to give a data matrix with the bros„ÄÇ

 but that's fine and I'll show you why that is in a minute„ÄÇ

So the reason is when you write that on a matrix vector notation„ÄÇ

 you write this that the vector of predictions is the data matrix transpose times beta that's a vector plus v times the vector of ones okay so now you can see why people often work with the data matrix being having the rows as the beach is because then you don't have this transpose here before the matrix vector multiplication but it's fine that's the idea And so for example„ÄÇ

 the prediction error and it's a vector is this is y d minus y hat it's what it's what actually happened minus and then your prediction of it and that's going to be equal to this thing and so for example if I take the RMS value of the prediction error and it's0„ÄÇ

1 I could say on that data set my regression model made predictions that we about you plus or minus 0„ÄÇ

1 I mean that's what it means to have an RMS value of about 0„ÄÇ1 sos's„ÄÇ

Regression model we're going to see a whole lot more about that later in the class so so far we haven't told you„ÄÇ

How do you find beta or V we'll see that later in the class it's a very important thing„ÄÇ

 but for now there's note that we can certainly interpret and look at a regression model before you know how to fit one fitting one is going to come later„ÄÇ



![](img/ca4fd7b9cd781730b6609d082efedcc0_4.png)

![](img/ca4fd7b9cd781730b6609d082efedcc0_5.png)