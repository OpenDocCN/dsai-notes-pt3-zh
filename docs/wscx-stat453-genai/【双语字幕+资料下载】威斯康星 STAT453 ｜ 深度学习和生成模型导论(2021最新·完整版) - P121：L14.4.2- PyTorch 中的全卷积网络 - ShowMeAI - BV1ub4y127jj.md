# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P121ï¼šL14.4.2- PyTorch ä¸­çš„å…¨å·ç§¯ç½‘ç»œ - ShowMeAI - BV1ub4y127jj

All rightï¼Œ let me now show you how we can implement this all convolutional network that I discussed in the previous videoã€‚



![](img/01aeb81254f41e05749e6dc46c33a23a_1.png)

So here I have a code notebook I will of course share as usual and also as usual I won run this because it took like 45 minutes to run this whole notebookã€‚

 and yeahï¼Œ there was actually an interesting question on Piazza regarding the runtime of the homeworkã€‚

So a student was asking whether it's normal that it takes like 8 minutes to run the notebookã€‚ Yeahã€‚

 that is totally normal in deep learningã€‚ It's actually pretty fast eatenã€‚ So yeahï¼Œ deep learning isã€‚

 of courseï¼Œ a little bit different than traditional statistics where we usually work with small data setsã€‚

 like little tables of dataã€‚ So here we have really large data sets and complicated models with manyã€‚

 manyï¼Œ many parametersã€‚ So yeahï¼Œ it takes usually a long timeã€‚ So some peopleã€‚

Actually use hundreds or thousands of GPUus for multiple weeks to train these cutting edgeã€‚

 vision and language modelsã€‚ So you can actually get good performance also with efficient models that only run a few hoursã€‚

 But honestlyï¼Œ if you have a real world dataã€‚ Sometimes hereï¼Œ you have to be patientã€‚

 Sometimes it takes a few days or soã€‚ So this model here is relatively simpleã€‚

 we have the Cypher 10 data setã€‚ So luckilyï¼Œ it only takes 45 minutesã€‚ But yeahã€‚

 that is still a long timeã€‚ and we probably want don't want to wait 45 minutes here during the video until it finishes trainingã€‚

 So I'm not going to rerun thisã€‚ but yeahï¼Œ I will share the resultsã€‚

So everything here is exactly the same as in the VG G 16 notebookã€‚

 so I don't have to recap all of thatã€‚ The only new part is really hereã€‚

 this code of the all convolutional network can make this maybe a little bit biggerã€‚



![](img/01aeb81254f41e05749e6dc46c33a23a_3.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_4.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_5.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_6.png)

Yeahï¼Œ I'm seeingã€‚ I was writing this very ver bothã€‚ So you actuallyã€‚

 if you have the same height and widthï¼Œ just a small common hereã€‚

 if you have the same height and width for kernel size in strideã€‚

 you can also replace this by just the threeã€‚ and this just by by oneï¼Œ for exampleã€‚ So hereã€‚

 the first value always stands for the heightã€‚ And this is for the widthã€‚

 And this is also for the height and for the widthã€‚So yeahã€‚

 because it's all about simplifying convolution networks here you will only see convolutional layers and re layers and the beome layerã€‚

 no max pooling and no fully connected layer soã€‚You can furtherï¼Œ of courseã€‚

 simplify it by not using batchchomeã€‚ I think batchchnom was not even around not even invented or around when this architecture was proposedã€‚

 but I didn't get really good results without batchchomeã€‚ So I just added itã€‚

And the rest is just like the paper that I showed you this striving for a simplicity paperã€‚But yeahã€‚

 except that I added a patch normã€‚ Yeahï¼Œ and all I can tell you here is that we have convolutions andã€‚

Here we have always like one convolution that increases the number of channelsã€‚

 but it keeps the input in the output size the sameã€‚

 So this is like the same convolution that we talked aboutã€‚ I used a patting of one to achieve thatã€‚

 So if the input is 70 pixelsï¼Œ the output will also be 70 pixelsã€‚

And then so here there' is always a con that increases the channelsã€‚

Because each channel can be thought of a feature map from a different kernel or feature extractorã€‚

That is how the network yeah learns to extract different featuresã€‚

And then there is always a convolution that keeps the same number of channelsã€‚

And this one has the stride of2ã€‚ And this isï¼Œ these are the equivalents of the max pooling with kernel size of2 by2 and stride of 2ã€‚

 So this is hereã€‚ This is the one for reducing the height and widthã€‚



![](img/01aeb81254f41e05749e6dc46c33a23a_8.png)

And then we haveï¼Œ againï¼Œ one that increases the channelsã€‚With a straight of oneã€‚

 So it keeps the input and output heightã€‚ And then we haveï¼Œ againã€‚

 one that here with a Str of2 just reduces the height and width by a factor of 2ã€‚

And we keep doing that a couple of timesã€‚ And then in the endï¼Œ we have 10 classesã€‚

 right in Cypher 10ã€‚We have 10 classesï¼Œ so in my last convolution layerã€‚

 I have now the number of output channels equal to the number of classesã€‚Andã€‚In Pytjï¼Œ there isã€‚

 for some reasonï¼Œ no global average poolingï¼Œ global average pooling is essentially just computing the mean over the channelsã€‚

 So so for each height and width for each channel you would compute the meanã€‚

 you could technically implement that very in a very simple wayã€‚

 So that's probably why they didn't have a global average pooling layer in Pytorchã€‚

 but you can also just implementing averaging layerã€‚

 you can also use this adaptive average pooling 2 D with an input of one It has the exact same effect as this global average poolingã€‚

So adaptive average pullingdding is a layer that is quite versatileã€‚

 So what it can do is it will produce the size that you desireã€‚ So if you put a two hereã€‚

It will produce  two by two outputsã€‚ If you put a one hereï¼Œ it willï¼Œ produce the one by one outputsã€‚

 If I go back to my lecture hereã€‚

![](img/01aeb81254f41e05749e6dc46c33a23a_10.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_11.png)

Soã€‚This global average pullingdding will be the same as this adaptive average pullingddingsã€‚

 It will take the whole feature mapï¼Œ produce the size of one hereã€‚ So that is what we are doing nowã€‚

 So we are reducing this one to a size of oneã€‚ I actually don't even knowã€‚



![](img/01aeb81254f41e05749e6dc46c33a23a_13.png)

I probably should have prepared thisï¼Œ but I don't know what the size before this isã€‚ It's probablyã€‚

 I don't knowï¼Œ maybe 8 by 8 or something like thatã€‚You can actually double check that byã€‚

Removing this partã€‚And thenï¼Œ just doing aã€‚Print exc sizeã€‚

 and then you can find it out if you don't want to do the mathã€‚

But I'm not doing that now because then it will crash the output hereï¼Œ soã€‚

But that is how you can find out at homeã€‚ You canï¼Œ I can just make a copyï¼Œ to be honestã€‚

 Let's do thatã€‚ Why notã€‚

![](img/01aeb81254f41e05749e6dc46c33a23a_15.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_16.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_17.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_18.png)

Soï¼Œ it's 8 by 8ï¼Œ like I thoughtã€‚ So it was actually a pretty good guessã€‚ Alrightã€‚

 so back to the code hereã€‚ So yeahï¼Œ so we have now this global average pooling or here called adaptive average pooling instead of the fully connected layer that we had in VG G16ã€‚

 And then yeah I'm training the network using very simple setup the same as for VG G16ã€‚

 It's trainingã€‚ It's a very simple networkã€‚ So it doesn't really train that longã€‚

 It doesn't have so many parametersã€‚

![](img/01aeb81254f41e05749e6dc46c33a23a_20.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_21.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_22.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_23.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_24.png)

I meanï¼Œ not as long as the VDG16ã€‚ So the VD G16ï¼Œ I couple check hereã€‚It was probably long timeã€‚ğŸ˜”ã€‚

90 minutesã€‚Soï¼Œ this only tookã€‚

![](img/01aeb81254f41e05749e6dc46c33a23a_26.png)

Half the timeï¼Œ thenã€‚41 minutesã€‚ It doesn't get the same good performanceã€‚ It has 80%ã€‚

 I think this one has 84ï¼Œ85%ã€‚ So it's not as goodï¼Œ but twice as efficientã€‚ Alrightï¼Œ so yeahã€‚

 this is how our all convolution network works without max pooling and without fully connected layerã€‚

 in the next videoï¼Œ I will show you how we can alternatively replace fully connected layers by convolutional layersã€‚

 So here we learned how to replace it by averageã€‚

![](img/01aeb81254f41e05749e6dc46c33a23a_28.png)

![](img/01aeb81254f41e05749e6dc46c33a23a_29.png)

Pulingï¼Œ but average pool doesn't have any parametersã€‚Replacing the fully connected layerã€‚

 but it's not equivalentã€‚ It'sï¼Œ of courseï¼Œ different because now we replace it by a version without permitsã€‚

 in The next videoï¼Œ I will show you how we couldï¼Œ technicallyã€‚

 if we wanted to replace the fully connected layerã€‚



![](img/01aeb81254f41e05749e6dc46c33a23a_31.png)