# P68ÔºöL9.4- ËøáÊãüÂêàÂíåÊ¨†ÊãüÂêà - ShowMeAI - BV1ub4y127jj

YeahÔºå now we have seen simple models like logistic regression and more complicated models like multi layerer perceptrons„ÄÇ

 So I think that's a great time now to talk about topics like overfitting and underfitting„ÄÇ

 So in particular problems with models that are too simple like logistic regression and problems with models that fit the data too well„ÄÇ

 maybe multilay perceptrons„ÄÇ So the big problem with models that are too simple is that yeah„ÄÇ

 we don't get a good performance all of them„ÄÇ for example„ÄÇ

 when we used logistic regression on Ms we got a 93% whereas when we used„ÄÇüòäÔºåYeah„ÄÇ

 now that we have seen a selection of models like logistic regression as a simple model and multilayer perception as a„ÄÇ

 I would say more complicated modelÔºå it's I think a good time to talk about overfitting and underfitting in particular„ÄÇ

 problems that arise with models that are too simple like logistic regression apply to am listeded data and models that fit data too well„ÄÇ

 for exampleÔºå multilayer perceptioncepts with too many features„ÄÇSo yeahÔºå with that„ÄÇ

 let's talk about some of these topics„ÄÇ but I also wanted to start this video with a small„ÄÇ

 let's sayÔºå quiz„ÄÇ So here I'm showing you some images from the Amnes data„ÄÇ And yeahÔºå the question is„ÄÇ

 what image or what number do you think this is„ÄÇÊâÄË¶ÅÂëÉ„ÄÇTrue label is actually an8„ÄÇ

 The model predicts a4„ÄÇ I can kind of see how it predicts a4Ôºå though„ÄÇ It meanÔºå if you look at it„ÄÇ

 it could be almost like„ÄÇSomething like thisÔºå rightÔºå so„ÄÇSomething like this„ÄÇ So it's actually an aid„ÄÇ

 but it doesn't look that far away from a forÔºå to be honestÔºå it's actually a pretty tricky case„ÄÇ

 Or take a look at this one„ÄÇ What would you think this image is„ÄÇSo yeahÔºå as you may have thought„ÄÇ

 it's a2Ôºå but also it's actually not too far away from a 7 rightÔºå if you think of a 7 like this„ÄÇ

 it's actually not too far away„ÄÇ And in factÔºå that the model predicts a7 here„ÄÇOr thisÔºå this one here„ÄÇ

 What would you think this number here represents„ÄÇSo according to the labelsÔºå this is actually a5„ÄÇ

 but I also can see how this might be a three almost rightÔºå So in that wayÔºå another ambiguous case„ÄÇ

Last oneÔºå so what do you think this one representsÔºüYepÔºå it's a 6„ÄÇ but yeahÔºå also„ÄÇ

 it could be very well be a zero„ÄÇ So like like thisÔºå maybe maybe someone„ÄÇWas writing the0 like this„ÄÇ

 So you can see it's not always very obvious what this number represents„ÄÇ And that way„ÄÇ

 it's probably even impossible to get a 100% prediction accuracy on that data set„ÄÇOops„ÄÇ

 I have one more example here„ÄÇ So yeahÔºå can you think what„ÄÇ

Well can you guess what these numbers here are in terms of the true labels and the predicted labelsÔºü

So on the left hand sideÔºå we have a true label 2 on the right hand sideÔºå also a true label2„ÄÇ

 so both these numbers„ÄÇRepresent the digit2„ÄÇ but you can see they look very different from each other„ÄÇ

 And also yet a model in the left hand side the left hand side predicts0 on the right hand side predicts a 7„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_1.png)

YeahÔºå so here's an overview of some of the failure cases of a multi layerer perceptron trained on Mnesist„ÄÇ

 So here I was yeah using a not so good model it was like a logistic„ÄÇ

Sigmoid activation and output layer„ÄÇAnd I used the M E squared arrow„ÄÇ So I only got 93% accuracy„ÄÇ

 But that is reallyÔºå besides the point„ÄÇ So the point here is reallyÔºå it's useful„ÄÇ

To visualize some of the failure cases„ÄÇ So if you train a network on a dataset set it's always good to look at the wrong prediction because sometimes you may also find there' is just a mislabelling issue in the data that you may want to fix„ÄÇ

 So in that wayÔºå sometimes yeah you get additional insights about your data like issues with your data by just looking at it„ÄÇ

So yeah here it's just interesting to see what the model here predictsÔºå for example„ÄÇ

 like I mentioned in Germany we write the7 like this in the US it's common to write a 7 like this in Germany it's common to write the one like this in the US it's common to write the one like this so I can see a model may confuse„ÄÇ

American 7 with a German oneÔºå for example„ÄÇI can't see this issue here in this dataset set„ÄÇ

 but what I can see is that for exampleÔºå this7 here is mistaken by a3 because a3 also has this thingy here in the middle„ÄÇ

 this little yeah I would what would we call itÔºå I don't know„ÄÇ

 but you can see this is maybe confusing the model thinking it's a three while in truthÔºå it's a 7„ÄÇ

So hereÔºå just the bottom line is it's useful sometimes to take a look at your training data and the wrong predictions„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_3.png)

So talking now about overfitting and underfittingÔºå so overfitting refers to the issue when the model memorizes details in the training set that are only very specific to the training set but don't generalize to the test set„ÄÇ

So„ÄÇHereÔºå for exampleÔºå what I'm showing you is a plot where I have thearrow on the Y axis„ÄÇ

And the model capacity on the x axis„ÄÇ So what do we mean by model capacityÔºå So with model capacity„ÄÇ

 I mean in a way the number of parameters or complexity of the model think of it for yeah for simple or for simplicity„ÄÇ

As the number„ÄÇOf parameterss„ÄÇOr the ability of the model to fit a complex data set„ÄÇ

 So a model with more hidden layers compared to a model with fewer layers„ÄÇ

 a model with more hidden layers as a larger capacity or a model with wider layers also as a larger capacity to a model compared to a model with fewer or smaller hidden layers„ÄÇ

 So usually the more layers you have or the wider the layers are the higher your model capacity„ÄÇ

AlrightÔºå so what I'm showing you here now is the training error first„ÄÇ

 So let's focus on the training arrow in orange„ÄÇ So the error usually goes down as the model capacity increases„ÄÇ

So that means if we have more layers orÔºå I meanÔºå this is likeÔºå of course„ÄÇ

 not generally true because then we have issues like vanishing and exploding gradient„ÄÇ

 So let's say if we have a wider layer„ÄÇ So if we haveÔºå let's say„ÄÇum„ÄÇMti hyperperceptron„ÄÇ

Where this represents a arm„ÄÇHidden there„ÄÇIf we make this hidden layer wider„ÄÇLike this„ÄÇ

 doubling the sizeÔºå for exampleÔºå we increase the capacity of that model to fit a complex data set„ÄÇ

So usually for the training setÔºå the larger the capacityÔºå the smaller the error„ÄÇ

For the tests at though„ÄÇWhat we usually observe is firstÔºå if we have„ÄÇ

 so let's say we start with a very simple model here on the left hand side„ÄÇ

 like only one hidden unit or something in the hidden there„ÄÇ

 then the model is too simple to capture the trends or patterns in the training data„ÄÇ

 So we start with a large  error„ÄÇ But then as we make„ÄÇThe hidden layer wider„ÄÇ

 we see that the arrow goes down„ÄÇBut then let's sayÔºå we make the„ÄÇWe are too large„ÄÇ

 too many parameters to learn what we often observe is that the test that a goes up again because you know the model has so many parameters that it's not memorizing certain patterns in the training set that don't generalize to the training set so for example„ÄÇ

 in terms of pattern like's say individual positions of pixels that instead of more general shape it would pay too much attention to a particular pixel or something like that„ÄÇ

And with generalization errorÔºå this isÔºå I meanÔºå this is like the performance on„ÄÇNew data„ÄÇFor example„ÄÇ

 as measured„ÄÇOftenÔºå it's measured„ÄÇW„ÄÇüòîÔºåAt test set an independent„ÄÇTest set„ÄÇ

 So usually we use the test set to estimate the generalization error„ÄÇYeah„ÄÇ

 one more thing under fitting„ÄÇUnderfitting usually means if the model is not complex enough to capture the trends in the data„ÄÇ

 so here in this regionÔºå we can maybe say that this is underfitting„ÄÇ

And here on the right hand side this would be overfitting so overfitting is usually if you how you would quantify this usually by looking at the gap between training and test set performance„ÄÇ

 that is usually one way to assess the degree of overfitting„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_5.png)

YeahÔºå in practiceÔºå you will sometimes also hear people saying a model has high bias or a model has high variance„ÄÇ

 So I want to briefly go over yeahÔºå the concept of the bias variance decomposition and how it relates to overfitting and underfitting„ÄÇ

 HoweverÔºå this is just a very brief rundown„ÄÇ It's not„ÄÇ

 I would say the most important thing here in this course„ÄÇ So this course about deep learning„ÄÇ

 And because we have only so much time we won't to talk about„ÄÇ

 let's say model evaluation techniques in too much detail„ÄÇ

 There is a simple technique that most people useÔºå I will„ÄÇ

Talk about this a little bit after these slides and also we'll show you how that works inÔºå yeah„ÄÇ

 in code examples„ÄÇ So but just let's just focus on biasvariancy composition„ÄÇ

 If you' are interested in more model evaluation aspects„ÄÇ

 I cover more of this in the 451 introduction to machine learning course„ÄÇ

 which I usually teach in fall semester„ÄÇ SoÔºå but here because like I said„ÄÇ

 we only have so much time in deep learning„ÄÇI don't want to cover this in too much detail here„ÄÇ

 but I think it's useful to have a basic understanding of what bias and variance means in that context„ÄÇ

 because you will probably read about this in a paper at some point in your careerÔºå so„ÄÇ

Let's say we have a model for regression because it's simpler in this context„ÄÇ

 Let's say we have a regression„ÄÇModelÔºå and this is some value for a given data point that we want to estimate„ÄÇ

 Let's sayÔºå call that value or prediction theta„ÄÇ Let'sÔºå let's say this is aÔºå the true„ÄÇTrue value„ÄÇ

 And we want to estimate this„ÄÇ Let's sayÔºå by predicting its value using a a regression„ÄÇModel„ÄÇ

 and the regression model produces this theta head here„ÄÇ So theta head is the„ÄÇPrediction„ÄÇAnd„ÄÇNow„ÄÇ

 so think of everything here in the context of the squared„ÄÇScrd„ÄÇüòîÔºåArrow„ÄÇ

So here we talk about the bias varianceancy composition of the squared as„ÄÇAnd nowÔºå think of„ÄÇ

Having like a large number of training setsÔºå why we have this large number of training sets is a weird interesting question„ÄÇ

 It's like a weird scenarioÔºå usually in practiceÔºå we only have one training set„ÄÇ

 but just assume for the sake of this example that we have a very large number of training sets„ÄÇ

 Let's say we have1 million training sets„ÄÇSo every time we train a regression model on a training set„ÄÇ

 we get a slightly different model because the training sets are not identical„ÄÇ

So now think of training one„ÄÇMillion„ÄÇMods„ÄÇAnd each model makes the prediction on the same data point„ÄÇ

Let's call this So the data point corresponding to the theta here„ÄÇ Let's call this data point I„ÄÇ

 There's a prediction for the data point I„ÄÇAnd then we average over them„ÄÇ

 So we average over this prediction for that data point„ÄÇ So here„ÄÇ

 the expectation is over the training sets„ÄÇ So we are predicting„ÄÇThe yeah„ÄÇ

 data point for these well using these different modelsÔºå so„ÄÇThen we get this average value here„ÄÇ

 this expectation and the difference between this expected value„ÄÇ

Of this expectation of the theta head here of the estimated parameter„ÄÇ

 the difference between those two„ÄÇ This is our bias„ÄÇ This is how on average„ÄÇ

 how far are we off from the true value„ÄÇIn contrastÔºå so the variances„ÄÇ

 you are just two different ways of writing the variances„ÄÇ

 You've probably seen that in other statistics course„ÄÇ But„ÄÇ

 the main point is the variance is defined a little bit differently's„ÄÇ

How spread out these predictions are„ÄÇ So if you have a prediction by a particular model„ÄÇ

And then you take the average prediction„ÄÇ So this is really like here„ÄÇV„ÄÇüòîÔºåAverage„ÄÇPrediction„ÄÇ

How far or how spread are they how far are these apart squared so there's no positive or negative value So how far are they apart and then taking the expectation so how far oh how scattered our predictions on average basically so because this is like very weird to think about conceptually I find it easier to have some drawing so I took this actually from 451 so students will have taken 451 have seen my little drawing here so that's a person with a bow and arrow and„ÄÇ

Let's say the person wants to hit some target here„ÄÇThere's also usually some noise around the target„ÄÇ

 so in the dataÔºå so here for simplicityÔºå maybe ignore the noise„ÄÇ

And the goal is for this person here to hit the target with an arrow„ÄÇÂóØ„ÄÇIf„ÄÇ

 so you can see all the arrows fly short here„ÄÇ So the difference between„ÄÇSo this party„ÄÇ

 let's say the average hereÔºå this would be the expectation in the middle if you take the average of all these„ÄÇ

A rows hereÔºå this would be the expectation„ÄÇ You can see the difference between this one and this one„ÄÇ

 This would be the bias„ÄÇAnd„ÄÇHow scattered or how spread these arrow are that would be the variance„ÄÇ

So why why am I explaining this So usually people relate bias and variance to overfitting and underfitting personally I find it easier to think just of overfitting and underfitting„ÄÇ

 but yes some people like to talk about models in terms of bias and variance so a model with a high variance if you would train that model with different training sets„ÄÇ

 this would mean that a large variety of these predictions of the models a model with high variance is also more likely to overfit„ÄÇ

And a model with high bias means that it's kind of far off from the target„ÄÇ So in that way„ÄÇ

 a model with high bias is usuallyÔºå yeah notÔºå not complex enough„ÄÇ So it's usually underfitting„ÄÇ

 So high bias is usually underfitting and high variance is usually overfitting„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_7.png)

So I try to summarize that here in this plot„ÄÇ So againÔºå we have our error and the model capacity„ÄÇ

 So the training error and generalization error is what I've shown you before on the left hand side„ÄÇ

 when we have a high error for both training and test data or high„ÄÇLet's say„ÄÇÁ≥ª„ÄÇüòîÔºåArrowÔºå oops„ÄÇ

Surprisingly difficult to talk and write at the same time for me„ÄÇ I don't know why„ÄÇ Hi error for„ÄÇ

Both„ÄÇüòîÔºåTraining„ÄÇAnd generalization„ÄÇLet's say on both higher training and generalization„ÄÇ

It should be in let's sayÔºå in terms of in„ÄÇBoth string and translation arrow„ÄÇ

 So if we have a high arrowÔºå this is usually underfitting and„ÄÇIf we have a high generalization error„ÄÇ

 but a low training errorÔºå then this is usually the difference between„ÄÇThe green one here„ÄÇ

 the orange oops on the orange one„ÄÇThis is usually overfitting„ÄÇ

And variance and biasers relates to that„ÄÇ if we have a very simple modelÔºå low model capacity„ÄÇ

 it usually has a low variance„ÄÇ So even if I fit the model on different training sets„ÄÇ

 the results are usually quite stable because it doesn't memorize the data too closely„ÄÇ

 and then the variance„ÄÇGoes up„ÄÇAs we increase the model capacity„ÄÇ So in that way„ÄÇ

 the variance increasesÔºå and this is usually also correlated to increasing degrees of overfitting„ÄÇ

Similarly„ÄÇWith a biasÔºå so model that is too simple has usually a high„ÄÇBas„ÄÇ

 because it can't fit the data too well„ÄÇ It will always„ÄÇ

 let's say provide do very simple predictions that are always very similar„ÄÇ It's not yeah„ÄÇ

Complex enough to fit the data„ÄÇ And you can seeÔºå thoughÔºå as you increase„ÄÇ

 the capacity bias goes down„ÄÇ So a high„ÄÇBas model is usually relatedd to underfitting„ÄÇ So again„ÄÇ

 for more detailsÔºå I cover this in 4Ôºå51„ÄÇ but yeah„ÄÇMore more detail„ÄÇ

 you don't really have to know for this course for the focus here on deep learning„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_9.png)

So„ÄÇYeahÔºå like I saidÔºå a more detailed understanding is not mandatory for this class„ÄÇ

 I won't ask you make any more detailsÔºå let's say in quizzes or exams than we just covered„ÄÇ

 So it's just like a briefly a brief overview In practice„ÄÇ

 there are different ways we can evaluate models„ÄÇ there are like in 451 there are„ÄÇ

Cross validation testsÔºå we used bootstrapping and all types of different approaches„ÄÇ

Deep learning when we have very large data setsÔºå we usually use the hold odd method where we have three data sets„ÄÇ

 a trainingÔºå a validation and a test set„ÄÇ So that is usually sufficient because yeah we usually a very large test set So estimating the performance on a test set should be quite robust„ÄÇ

 given that we don't reuse our test set multiple times„ÄÇ

 So the focus is here really that our test set remains independent„ÄÇ

 So by that what I mean is usually we have a validation set„ÄÇThat we look at when we tune the model„ÄÇ

 So what we do is usually we„ÄÇFit the model on the training data„ÄÇ Then during training„ÄÇ

 we look at the validation performance„ÄÇ and then once we are finished we get the final performance estimate on the test set that's the usual approach„ÄÇ

 YeahÔºå and that is something we will also be using in in the code examples„ÄÇ

 So there's nothing really you have to pay particular attention to right now in this class„ÄÇ

 So for this classÔºå we use this threefold holdout method„ÄÇ

 which is also common in the context of deep learning If you look at literature„ÄÇHowever„ÄÇ

 if you are interested in more details about model evaluation and best practicesÔºå well„ÄÇ

 we cover this in 451Ôºå which you probably either have taken or not taken„ÄÇ

 you don't have to know any of this for this class„ÄÇ

 but if you are interested I have put up an article here on archive summarizing basically my lecture notes this is like different„ÄÇ

Here different techniquesÔºå statistical testsÔºå cross validationÔºå KÔºå cross validation„ÄÇ

 Woodt estimates and so forth„ÄÇ So yeahÔºå you are welcome to check out this article if you are interested„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_11.png)

YeahÔºå one aspect also about deep learning is that deep learning works best with large data sets„ÄÇ

So here I have drawn another conceptual plot related to the generalization error and here the training data set size„ÄÇ

 So if we have„ÄÇThe comparison between traditional machine learningÔºå for exampleÔºå decision trees„ÄÇ

 random forests support vector machines things like that compared to deep learning„ÄÇ

 usually if we have a small data set„ÄÇYeahÔºå traditional machine learning will perform better„ÄÇ

 so the gization error for traditional machine learning will be lower„ÄÇHowever„ÄÇ

 as the data set size increasesÔºå usually we will find that alsoÔºå yeah„ÄÇ

 traditional methods will perform betterÔºå but„ÄÇYeahÔºå for deep learning there's actuallyÔºå yeah„ÄÇ

 a really steep„ÄÇ yeahÔºå steep decline of the error with increasing data set sizes compared to traditional machine learning„ÄÇ

 so„ÄÇEspecially deep learning works well with and really even requires large data sets to perform well because yeah we have large models„ÄÇ

 there are a lot of parameterss and to fit to parameterize the model wellÔºå we need sufficient data„ÄÇ

YeahÔºå so this is the traditional viewÔºå usually the more data we haveÔºå the better„ÄÇAnd also„ÄÇ

 this is something if you find that your model doesn't perform well„ÄÇ

You may end up tuning some hyperparmeters„ÄÇ You might may find that hyperparmeter tuning helps with improving the performance a little bit„ÄÇ

 but there will be probably a point where you can't even make any difference no matter how many hyperparmetertor values you explore„ÄÇ

 and that might be a point where more data could be helpful„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_13.png)

SoÔºå but yeahÔºå interestinglyÔºå I recently saw the paper on double descent„ÄÇ

 so there was the paper on double descent that came out in December 2019„ÄÇ

 So that's an observation that is quite interesting and it's quite different from the common belief„ÄÇ

 So here„ÄÇWhat the researchers did is they looked at CNN architectureÔºå standard and renets„ÄÇ

 so standard CNNs and residual networksÔºå both are things we will cover later in this course and transformers which will also cover at the end of the course so I'm not sure if that the insights here generalized to other models like recurrent neural networks and multilayer perceptionceptrons because they haven't looked at those„ÄÇ

 but at least this was very interesting in the context of CNNs„ÄÇ

So all the models were also trained with cross entropys here„ÄÇYeah„ÄÇ

 there is this phenomenon of the double descent„ÄÇ So what does that mean„ÄÇ

 What does a double descent means I meanÔºå So hereÔºå what you can see is„ÄÇLike expected„ÄÇ

Training error goes down as the model complexity increases„ÄÇ So here you can think of„ÄÇX X S model„ÄÇ

CapacityÔºå which we have looked at before„ÄÇ so that is expected at some pointÔºå though„ÄÇ

 if we make the model too largeÔºå we will see that the error goes up„ÄÇ

 So here the solid line is a test error trained error goes still down„ÄÇBut the test  error goes up„ÄÇ

 So this is what we talked about„ÄÇ This is the overfitting„ÄÇNowÔºå the surprise is that it goes up„ÄÇ

 but at some point it goes down again„ÄÇ So what's going on here„ÄÇ

 actually people don't know quite know yet why this happens„ÄÇSo there are some theories„ÄÇ

 I will share one of them in a later slide„ÄÇ But yeah„ÄÇ

 so what is interesting here is this double descent that it first goes down„ÄÇ

 But it's the first descent„ÄÇ and then it goes down again after going up„ÄÇ This is the double descent„ÄÇ

 So they observe it with four different model capac„ÄÇ So if you make the model larger„ÄÇ

 you can observe this double descent„ÄÇ

![](img/9534ee1cc8e8407eb6113b0c37f1a72c_15.png)

And you can also observe it if you train for more epochs„ÄÇ So here again„ÄÇ

 is a test error they have here on the left hand sideÔºå three modelsÔºå a small model„ÄÇ

 an intermediate model and a large model„ÄÇ you can see when you train a small model for more epochs„ÄÇ

You don't have thisÔºå you go basically downÔºå the generalization error goes down„ÄÇ

 so the model is improvingÔºå the more epochs we train it„ÄÇFor the intermediate model„ÄÇ

 you can see it it goes down„ÄÇBut then at some pointÔºå it goes up again„ÄÇ

So here the model performs actually worse when we train it longerÔºå so in this case„ÄÇ

 for this intermediate model it would be good actually to stop the training early to stop let's say training here and in the next lecture I will also yeah talk more about early stopping as a way of regular regularizing the model like improving the performance preventing overfitting„ÄÇ

And for the large model you observe it goes downÔºå then it goes up similar to the intermediate model„ÄÇ

 but then it goes down againÔºå so that's also this double descent here„ÄÇSo that's quite interesting„ÄÇ

YeahÔºå on the right hand side is the same„ÄÇ visualize it or the same thing just visualize differently for„ÄÇ

The model parameter size on the X axis and the number of epos on the Y axis„ÄÇ

 So there are a couple of yeah thoughts about that from the paper or theoriesÔºå so„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_17.png)

At that„ÄÇCritical regions„ÄÇ So with critical regionÔºå they mean„ÄÇThis region here in the red region„ÄÇ

 the reason why we might may find that it goes up here is„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_19.png)

That„ÄÇThey think its only one of the models fits the data well and is very sensitive to noise so with one model imagine you have a residual neural network and when you train it there are many„ÄÇ

 many different hyperparmeter model weights that you can define to fit the data well so there are multiple possibilities and there's only one that fits the data well there's a particular combination of weights that fits the data well„ÄÇ

But it's very sensitive to noise„ÄÇ So if you have small perturbations in a training set as you train„ÄÇ

 it's very sensitive„ÄÇ It's not guaranteed to find it„ÄÇ

 And also it's really sensitive to the inputs So if there's a slight perturbation and the inputs the model may make the right prediction of wrong prediction in that way it's not so good in terms of generalizing but if you have an overproempterized model if a model is very large„ÄÇ

 there are many ways you can fit the data well So you have a lot of weights„ÄÇ

 and you only let's say maybe need a subset of those to perform well„ÄÇ

 and there are many different ways you can find a good subset of the weights„ÄÇ and they„ÄÇ

Theorize that satorcchastic gradient in descent finds one of these weight combinations„ÄÇ

That fits the training set wellÔºå but also performs well on the test set„ÄÇ So in that way„ÄÇ

 oops if I go backÔºå so the„ÄÇ

![](img/9534ee1cc8e8407eb6113b0c37f1a72c_21.png)

Claim is basically that here the model that is learned is very sensitive to noiseÔºå whereas„ÄÇ

In this region hereÔºå yeahÔºå we found a model that performs well on the training set„ÄÇ

 but also on the test set„ÄÇThere are more experiments in that paper also experimenting with different degrees of noise„ÄÇ

 So if you are interested in thatÔºå yeah I recommend reading the paper here„ÄÇ

 I only yeah took a very small number of figures to just illustrate this double descent phenomenon„ÄÇ

 So there's also„ÄÇ

![](img/9534ee1cc8e8407eb6113b0c37f1a72c_23.png)

Yes's the same as I saw„ÄÇ Oh yeahÔºå this is also an interesting figure„ÄÇ

 It shows both the number of epochs and the width„ÄÇ So there's essentially a model wise double descent and epochwise double descent„ÄÇ

 So there are these double descent curves for both different sizes of the model„ÄÇ

 So if you have more parameters and also for longer training„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_25.png)

LastlyÔºå there's alsoÔºå yeah something they observed with„ÄÇThe number of training examples„ÄÇ

 So if you increase the data set sizeÔºå there are also someÔºå yeah little surprises„ÄÇ

 But I wouldn't sayÔºå so they describe them in the paper as surprises„ÄÇ

 but I wouldn't say it's a big surprise„ÄÇ The general trend is„ÄÇSo if you have hereÔºå the error„ÄÇ

From lowest to highest„ÄÇ so you have the lowest error in this region here where you have a large model and a lot of data or a small model and a large model of data data„ÄÇ

 But what is weird is here in between if you have an intermediate model„ÄÇ

 more training set or larger training sets are actually worse„ÄÇ

Compared or these models are worse compared to the small models and big models„ÄÇ And also„ÄÇ

 when you look at this closely„ÄÇLet's say hereÔºå for exampleÔºå you can see that„ÄÇ

Increasing the number of training examples from here to here improves the generalization error„ÄÇ

 But then from here to hereÔºå it becomes worse again„ÄÇ and then it becomes better again„ÄÇ

 So if you would plot thatÔºå you have a„ÄÇIt's a high generalization or„ÄÇ it drops„ÄÇ

 and then it becomes worse again„ÄÇ So that is also a little bit weird here„ÄÇ That's some surprise„ÄÇ

 But in generalÔºå you can see more training„ÄÇData helps and also more larger models perform better„ÄÇ

 So a good combination is large training set and a large model„ÄÇ SoÔºå yeahÔºå againÔºå so this isÔºå yeah„ÄÇ

 just interesting„ÄÇ If you're interestedÔºå you can read about this moreÔºå Why the double decent„ÄÇ

Phenomeeno happensÔºå I think that is not quite clear„ÄÇ Some peopleÔºå let's say so in some forum„ÄÇ

 even debate that this might be just some buck in the code or things like that so„ÄÇMany people„ÄÇ

 thoughÔºå I can sayÔºå have observed this independentlyÔºå so it's probably a real thing„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_27.png)

But why this happens yeahÔºå it's not quite clear yet„ÄÇ So but yeah moving on„ÄÇ

 So this was just a very brief video actually it was longer than I expected„ÄÇ

 but still a very brief video in the grand scheme of things like on overfitting and underfitting and in the next video I will show you how we can use multilay perceptrons with custom datasets because so far we only have worked with MNs but yeah chances are for your class project you will want to work with your own dataset So that and the next video I will show you how we can do that„ÄÇ



![](img/9534ee1cc8e8407eb6113b0c37f1a72c_29.png)