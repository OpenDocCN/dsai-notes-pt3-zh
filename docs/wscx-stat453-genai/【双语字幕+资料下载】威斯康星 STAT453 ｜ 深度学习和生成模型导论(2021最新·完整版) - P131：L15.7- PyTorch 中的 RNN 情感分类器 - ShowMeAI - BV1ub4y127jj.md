# P131ï¼šL15.7- PyTorch ä¸­çš„ RNN æƒ…æ„Ÿåˆ†ç±»å™¨ - ShowMeAI - BV1ub4y127jj

Alrightï¼Œ so this is going to be the last video in this lecture on recurrent neural networksã€‚

 so we are now talking about implementing an R andR class R classifier in Pythtorã€‚

 so the many to one word R andN that we just talked about in the previous video so it will be essentially this whole process from going from a text to building a vocabulary then this integer representation and then using an embedding to get this input to the R and N which will be when you recall this one many to one R andN where we have one sentence as an input and one classable as the outputã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_1.png)

![](img/49104266c97f1f4f9793724450b9f7d0_2.png)

![](img/49104266c97f1f4f9793724450b9f7d0_3.png)

![](img/49104266c97f1f4f9793724450b9f7d0_4.png)

So I have actually two codes hereã€‚ One is an LCSDM and one is a packed LSDMã€‚

 The packed LCTM is just a more implement more efficient implementationã€‚ So let's just talk aboutã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_6.png)

MeI justã€‚ let's talk about the regular LDM firstï¼Œ the regular approachã€‚ So it took yeahã€‚

 a couple of minutes to run thisã€‚ So I I'm not going rerun thisã€‚

 We are just taking a look at the resultsï¼Œ and I will upload thisã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_8.png)

![](img/49104266c97f1f4f9793724450b9f7d0_9.png)

![](img/49104266c97f1f4f9793724450b9f7d0_10.png)

To githubï¼Œ if you want to play around with thatã€‚ So we are going to useã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_12.png)

Torch or pyrch and torch textã€‚So in particularï¼Œ any version of Torch text that is 0ã€‚9 or higherã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_14.png)

Also notice I don't have any helper files here because yeah this is like a tricky concept to explainã€‚

 I wanted to keep everything in this notebook to make it a little bit more yeah easy to explain by walking you through this instead of visiting different filesã€‚

 but yeah you could technically also use these helper files when code becomes largerã€‚

 So here the training function will be very simpleã€‚

 I don't have any fancy training function this timeã€‚

 just to keep things simple because I think an RnN is already complicated enoughã€‚

 So compared to a convolutional networkï¼Œ these R ends are actually really tricky to implement at least in my opinionã€‚

 I actually very much prefer working with convolutional networksã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_16.png)

Soã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_18.png)

Here are some general settingsï¼Œ so we are going to use the vocabulary size capped at 20000ã€‚

The learning rateï¼Œ batch sizeï¼Œ number of epoes is something familiar to youã€‚

 The embedding dimension that we will use is 1 or 28ã€‚ The hidden dimension will be 256ã€‚

 This is like onã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_20.png)

After thatã€‚And then the number of classes is 2ã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_22.png)

So firstï¼Œ we are going to download the datasetï¼Œ the IMDB movie review datasetã€‚ So hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_24.png)

In thisï¼Œ I in this partï¼Œ we are downloading it from my book becauseï¼Œ yeahï¼Œ just for simplicityã€‚

 because this will save us some pre processing stepsã€‚

 There is actually an I M D B dataset set implemented in torch textã€‚But hereï¼Œ I'm alsoã€‚

Explaining to you how you can use an LSDM on your own datasetã€‚ So it's basically two steps in oneã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_26.png)

And we are using this because it's a CV format that is alreadyã€‚

 I would say easy to use so we can skip all the pre processingsing steps of this particular dataset set so that we can more focus on how torch text worksã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_28.png)

So this is just on downloading itã€‚From the St repositoriumã€‚Then this is unziping itã€‚

And then this is loading it into upã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_30.png)

Panda's data frameï¼Œ because it's just a little simplerã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_32.png)

Thenhan using anything elseã€‚ So this is a CV fileã€‚ So we are using pandas to take a look at itã€‚

 So it hasï¼Œ I think 50000 entriesã€‚ So yeahï¼Œ these are the first fiveã€‚ The review is the textã€‚

 the input text and the sentiment is the class labelã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_34.png)

![](img/49104266c97f1f4f9793724450b9f7d0_35.png)

It's kind of to personallyï¼Œ to meï¼Œ a common gotcha to have the wrong names later in the codeã€‚

So here I'm using something called a text column name and label column name as the name for theseã€‚

 becauseã€‚You will see that laterã€‚You have to provideã€‚

Kind of like attribute access to these features in the training loop and the same for the labelsï¼Œ soã€‚

Depending on the names of your columns in the pans data frameã€‚

 your training loop might look differentã€‚ You have to rewrite itï¼Œ and I find this very tediousã€‚

 so I would give my panda data frame if I have different data sets always these names just to keep it simpleã€‚

 it could be something elseï¼Œ but I find it also capital lettersã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_37.png)

![](img/49104266c97f1f4f9793724450b9f7d0_38.png)

Usefulã€‚ So it reminds me what this means or what this isã€‚

 it's just easier to see it that screams outã€‚ Okayï¼Œ this is a column name hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_40.png)

And this is importantã€‚ Alrightï¼Œ so I'm just giving it the generic nameã€‚

 text column name and the generic nameï¼Œ label column name hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_42.png)

Alrightï¼Œ and then I'm deleting this againã€‚ So here I was just essentially loading itã€‚

 renaming it and saving it againã€‚ And then here this is just for taking a look at it again that it looks okay and then I'm deleting it because I'm not using it here anymoreã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_44.png)

![](img/49104266c97f1f4f9793724450b9f7d0_45.png)

![](img/49104266c97f1f4f9793724450b9f7d0_46.png)

Then we are going now to prepare this data set with torch text as input to the R and Nã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_48.png)

For thatï¼Œ we are going to use a library that is called Spaceyã€‚

 Spacey is a very popular natural language processing library for Pythonã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_50.png)

And in particularï¼Œ we are using the tokenizerã€‚So by defaultã€‚

 it would use tokenizer splitting on white spacesï¼Œ but I heard from people working with real world datas that sometimes these are not very robust toã€‚

 let's say weird charactersã€‚ So also HL characters and things like thatã€‚

 And this tokenizer also gets rid of certain formatting things you find in HL like these onã€‚

These symbols here and so forthã€‚ So it's like a little bit more sophisticated than just splitting on white spaceã€‚

 So what this is doing is it's splitting yeahï¼Œ a textã€‚Into white space so that one token is one wordã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_52.png)

And we are using here thisã€‚English languageã€‚ it'sï¼Œ I think it's stands for English coreã€‚

 web and somethingã€‚ I'm not this is not for somethingã€‚ I'm just saying somethingã€‚

 I forgot what this meansï¼Œ but this is essentially a library or not a library dictionary for English words and web things encountered onã€‚

 and on websites and stuff like thatã€‚ So this is usually usefulã€‚ If youï¼Œ yeahã€‚

 just work with a data like scrape from somewhere on the Internetã€‚If you are just running thisã€‚

 it may be that you encounter will encounter an errorã€‚ So you have to run this one firstï¼Œ which willã€‚

 you have to run this on the command I this will download thisã€‚Yeahï¼Œ dictionary hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_54.png)

And yetï¼Œ to install a space hereï¼Œ I recommend Condaï¼Œ but you can also lose Pipã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_56.png)

Pip installã€‚Nowï¼Œ like I said before in the previous videoï¼Œ things have changed in Torch textã€‚

 so we are going to use the old way called Torch textã€‚t legacyã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_58.png)

![](img/49104266c97f1f4f9793724450b9f7d0_59.png)

But if you want to convert this to the new oneï¼Œ I actually spent a lot of time yesterdayã€‚

 and then it was not working very wellã€‚ So Iã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_61.png)

![](img/49104266c97f1f4f9793724450b9f7d0_62.png)

We use the old way againã€‚ but if you are interested hereï¼Œ there's a tutorial for migrationã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_64.png)

On the slidesã€‚So to migrate to them newer way that it doesn't use this legacy thingã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_66.png)

Alrightï¼Œ so we are now defining a field for the textã€‚ So this will be our featuresï¼Œ our tokensã€‚

 So thisï¼Œ this will beã€‚ So if we haveï¼Œ for instance onã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_68.png)

Oopsï¼Œ if we have this text hereï¼Œ this will be something like a list containing ofã€‚

Containing these consisting of these wordsã€‚Split byã€‚Approximately something like the white spaceã€‚

 but a little bit fancier than thatã€‚ But each entry in the list will be one wordï¼Œ essentiallyã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_70.png)

Using this tokenizerã€‚Al rightã€‚ The second one is the labelã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_72.png)

So this is for designating this labelã€‚Which will be a integerã€‚ Longï¼Œ long is just a 604 bit integerã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_74.png)

Here we are providing these fieldsã€‚Andã€‚This isã€‚So we are providing these fields which are the text that we have defined here and the label that we have defined hereã€‚

 and we are using a tabular data set which will read our CV file and then parsing out these thingsã€‚

So that we will can then load them as a data loadã€‚ So hereï¼Œ this is why it's so hereã€‚

 this is importantã€‚ This name has to beã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_76.png)

![](img/49104266c97f1f4f9793724450b9f7d0_77.png)

The name that is actually hereã€‚ And personallyï¼Œ it'sï¼Œ that is why I always make mistakesã€‚ So Iã€‚

 let's sayï¼Œ don't rename itã€‚ If I don't rename itï¼Œ I would have to put in likeã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_79.png)

Oopsã€‚I would have to put in review hereã€‚And then sentiment hereã€‚ And then laterã€‚

 I have to also use these wordsã€‚ And if I have a predefined training loopã€‚

 I would have to rewrite certain thingsï¼Œ depending on what data set I useã€‚

 This is why at the beginningï¼Œ I rename the columnã€‚

 So I can always leave it like it is right here nowã€‚ The only thingã€‚I have to changesï¼Œ of courseã€‚

 the path to my datasetã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_81.png)

Alrightï¼Œ And in this caseï¼Œ it doesn't have a headerã€‚ So you also have to check in this caseã€‚

 there is no header rowã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_83.png)

![](img/49104266c97f1f4f9793724450b9f7d0_84.png)

There are only the colour namesï¼Œ but there's noï¼Œ no particular header ruleã€‚ Ohï¼Œ waitï¼Œ Sorryã€‚

 there is skip headerã€‚ There's no header ruleã€‚ It's skipping the headerï¼Œ okayã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_86.png)

![](img/49104266c97f1f4f9793724450b9f7d0_87.png)

So it's skippingï¼Œ skipping theseã€‚ Sorryï¼Œ what I meant is it has a headerã€‚ It has these column namesã€‚

 and it's skipping thoseã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_89.png)

Okayã€‚So this is now the way we process our CV file into a data setã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_91.png)

Nextã€‚We want to have a training and a test dataset setã€‚ So I'm using this split functionã€‚

 I'm splitting this dataset set into two a training and a test dataset setã€‚ Actuallyã€‚

 I try to split it into 3 directlyã€‚ It should technically support thatã€‚ So I had something likeã€‚7ã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_93.png)

Pot1 andã€‚2ã€‚ But it gave me some very weird resultsã€‚ I think it's a bugã€‚

 So because what happened was I had a validationation set like thisã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_95.png)

Train dataï¼Œ validation data and test dataã€‚ For some reasonã€‚

 I don't know why the validation data was much bigger than a test dataï¼Œ which should be the oppositeã€‚

 And I tried many thingsã€‚ It seems to be a bugã€‚ So I do it in two stepsã€‚ First step isã€‚Im splittingã€‚

The training data or the data center for training dataï¼Œ 80% and 20% test dataã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_97.png)

So I'm double checking hereï¼Œ so the dataset consists of 50000 data pointsï¼Œ40000 will be for trainingã€‚

10000 will be for testingã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_99.png)

And then I split the training data further into a training data set again and validation dataã€‚

 So in totalï¼Œ what I will have is 34000 training examplesã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_101.png)

6000 validation examples and 10000 test examplesã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_103.png)

Just to make sure everything looks okayï¼Œ we are now taking a look at the first training exampleã€‚

 So 0 index0 is the first training exampleã€‚ and this is how it looks likeã€‚Soã€‚

 text column name that isã€‚The tokenizedã€‚ So this is using the tokenizerã€‚

 This is the tokenized review textã€‚ You can see it keeps punctuationã€‚ It keeps numbersã€‚

So for some unknown reasonï¼Œa seven years agoï¼Œ I watched blah blahï¼Œ blahï¼Œ So you can seeï¼Œ yeahã€‚

 this is now the tokenized textã€‚ This is from using the spacey tokenizerã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_105.png)

And alsoï¼Œ there's the can name hereã€‚ This is like theã€‚This should be the class labelã€‚

Cre you not sure why this isã€‚Not an integerã€‚ Laterï¼Œ actuallyï¼Œ doesn't cause any problemsã€‚

 So it seems to be okayï¼Œ but feel like this should be without quotation marksï¼Œ but anywaysã€‚Allrightã€‚

 soã€‚Nowï¼Œ we have theã€‚Data sets the training dataï¼Œ validation setï¼Œ data and the test dataã€‚

What we are now doing is we are building the vocabularyã€‚So hereï¼Œ build vocabã€‚

I' am setting a maximum size for the vocabulary because we are to prevent overfittingã€‚

 So we are only using the most used wordsï¼Œ the 20000 most frequent wordsã€‚

 So I define the vocabulary size here or somewhere at at the top can play around with thatã€‚

 can use 10002500ï¼Œ30000 depends a little bit on how big the training set isã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_107.png)

![](img/49104266c97f1f4f9793724450b9f7d0_108.png)

And howï¼Œ yeahï¼Œ how diverse the data points the texts areï¼Œ how long the texts areã€‚

 But 20000 is a good number to start withã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_110.png)

Soï¼Œ we are buildingã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_112.png)

This nowã€‚And for some reasonï¼Œ it's also called build wall cap hereã€‚ I think I'm doing it rightã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_114.png)

So vocabulary sizeï¼Œ what we all find is its 20ã€‚Thousand and2ï¼Œ not 20000ã€‚

 And this is because we have the unknown wordã€‚Tokenã€‚

 So if we encounter an unknown word that it will not crash and then answer the ones for pattingã€‚

 And we have two classesï¼Œ0 and 1ã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_116.png)

![](img/49104266c97f1f4f9793724450b9f7d0_117.png)

Here I'm now showing the just to look at whether it makes senseã€‚ Actuallyã€‚

 I can see there is something that I feel like shouldn't be thereã€‚ as is this break character hereã€‚

I thoughtï¼Œ to be honestï¼Œ the spacey tokenizer would be a bit more robust that it would not have these types of thingsã€‚

 but oh wellã€‚Happensã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_119.png)

It's probably not perfectã€‚è¯´ã€‚Here we are looking at the  trend0 most frequently encounteredã€‚

Words or or tokensã€‚ So the is very frequentã€‚ comm frequent point punctuation and so forthã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_121.png)

But yeahï¼Œ this kind of bothers meã€‚ This shouldn't be hereã€‚ So we would in an real world applicationã€‚

 probably have to deal with that using a different tokenizer or maybe just stripping it out before we pass it to the tokenizer or something like thatã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_123.png)

![](img/49104266c97f1f4f9793724450b9f7d0_124.png)

Alrightï¼Œ next tokens corresponding to the first 10 indices just to look at thoseã€‚

 So we have a vocabulary that is of size 2000ã€‚ If I go back to myã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_126.png)

![](img/49104266c97f1f4f9793724450b9f7d0_127.png)

My slidesã€‚ So we have this vocabularyã€‚And we are now looking 1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ã€‚

 The different integer the strings correspond toã€‚ So the first entry in my vocabulary is this unknown  oneã€‚

Second one is the paddingï¼Œ and then the command point and A Oï¼Œ F and so forthã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_129.png)

And just for I just making sure things work technicallyã€‚

 so we will use that data for making predictionsã€‚ But later generallyï¼Œ we can also just take thisã€‚

Vocabulary for the text field and convert any word into this interteject corresponding to the dictionaryã€‚

The the according to this vocabularyï¼Œ the word the is at index position 2ï¼Œ So 0ï¼Œ1ï¼Œ2ã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_131.png)

So here we are putting it in and get the number 2ã€‚ So this is all we are here currentlyã€‚

 this is not necessaryã€‚ We are just investigating what's going on just to make sure things look okayã€‚

 Ohï¼Œ yeahï¼Œ I seeã€‚ Soï¼Œ yeahï¼Œ we have now this class label vocabularyã€‚ And I mentioned earlierã€‚

 that shouldn't be stringsã€‚ I meanï¼Œ this is probably becauseã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_133.png)

![](img/49104266c97f1f4f9793724450b9f7d0_134.png)

Yeahï¼Œ we could haveã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_136.png)

Here we could have put the word pause or neck for positive or negativeã€‚

 This is what's original in the movie reviewã€‚Databaseã€‚ So here I inï¼Œ in my bookã€‚

 I converted it to 1 and 0 already andã€‚The code thinks these are yeahï¼Œ stringsã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_138.png)

Kind of funnyã€‚ So it's mapping 1 to 0 and 0 to 1ã€‚ So we would have to keep that in mind when we later do the predictionã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_140.png)

So we could have just used words like pause and negative and stuff like thatã€‚ We could alsoã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_142.png)

Yeahï¼Œ we could also change that if we wanted toã€‚ it's justï¼Œ yeahï¼Œ it's justï¼Œ I thinkã€‚

 alphabetical order or something like thatã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_144.png)

Well it can't be alphabeticalï¼Œ I think it's justã€‚What it has encountered first or somethingã€‚

 Or maybe it's even randomã€‚Just have to remember that theã€‚

String  one in our label column corresponds to the class label 0 and and in the tensor laterã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_146.png)

Then here is frequency count of the vocabularyã€‚ sorry of the training data pointsã€‚

So we have approximately 60000 corresponding to 0ï¼Œ and this one is actually negativeã€‚0 is negativeã€‚

 and one is positive and 70000 positive onesã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_148.png)

Onã€‚One more thing I wanted to say is let'sï¼Œ yeah hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_150.png)

I am building the vocabulary only on the training dataï¼Œ not on the whole dataï¼Œ because as usualã€‚

 we pretend that the validation and test data are unseen that there are new data setsã€‚

 That's what we use for evaluating our model during trainingã€‚ we pretend we don't know theseã€‚

 It's like independent dataã€‚ So we are only buildingã€‚The voculary based on the known dataã€‚

 the training dataã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_152.png)

Alrightï¼Œ so you can see it's really complicated to implement an R and are lots of steps involvedã€‚

 it's way more complicated than a convolutional networkã€‚

 So if you don't really understand everything the first time it's totally normalï¼Œ it's justã€‚

 it is very complicatedã€‚ People study this for many months to before they become comfortable using those thingsã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_154.png)

Now we are implementing the training validation and test loadã€‚

 we use something called the bucket iteratorï¼Œ which is a special iterator in Pytorrch torch textã€‚

 which will groupã€‚The batches such that the sentences haveã€‚Similar lengthã€‚

 And that reduces the number of pedding that is requiredã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_156.png)

Okayï¼Œ here now we are testing whether those workã€‚ Actuallyï¼Œ these data load us and youã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_158.png)

Can see what I'm just doing is I'm like before in my other code examplesã€‚

 I'm just doing for batch and train orderã€‚ and then Iã€‚Print theseã€‚ and then I do a breakã€‚

 So it only shows the first batchã€‚ I just want to see ifï¼Œ if it runsï¼Œ okayã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_160.png)

So you can see for the first batchï¼Œ it's actually pretty largeï¼Œ I should sayã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_162.png)

The first value here is the sentence lengthã€‚And the second one is the batch sizeã€‚

 So this is a little bit different from the conversion networksï¼Œ where we had the batch size firstã€‚

This is what makes I feel like everything also a bit complicated to understandã€‚

 It's like that the sentence length here isã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_164.png)

Firstã€‚And the sentence length isã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_166.png)

These integers hereï¼Œ this hereã€‚So I a better one hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_168.png)

Yeahï¼Œ thisï¼Œ this is basically the sentenceã€‚ Wellï¼Œ this is for one wordï¼Œ sorryã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_170.png)

å—¯ã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_172.png)

Yeahï¼Œ I don't have a good one here in the lecture notesï¼Œ butã€‚So if you concatenate these togetherã€‚

 this would be the sentence lengthã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_174.png)

And then this is the batch sizeã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_176.png)

I think yeahã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_178.png)

![](img/49104266c97f1f4f9793724450b9f7d0_179.png)

Alrightã€‚ so now the R and N hereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_181.png)

Soï¼Œ the R and Nã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_183.png)

Okayï¼Œ sorryï¼Œ let's just have toã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_185.png)

Because a bit bigger hereã€‚ So the R and Nã€‚Looks like as followsï¼Œ we're actually using an LTMã€‚

 So there areã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_187.png)

Several things nowã€‚ we are using this embedding that provides the input to the LSDMã€‚

Then the EsteM itselfã€‚And then theã€‚Output layerã€‚Hidden thereã€‚ sorryï¼Œ the output layerã€‚

 it's not a hidden thereã€‚Thisï¼Œ you can think of of the LSDMã€‚ you can think of as the hidden layerã€‚

Whereasï¼Œ yeahï¼Œ okayï¼Œ the embedding comes before thatã€‚ it's like preparing the inputã€‚For the hiddenã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_189.png)

Actuallyï¼Œ in the slidesï¼Œ I said it's this oneï¼Œ but then there would be another matrixã€‚

 So it's technically a little bit confusingã€‚ I should have actually not done thatã€‚

 I should have showed youã€‚It is a embedding that comes before that that prepares these xsã€‚ And thisã€‚

 this W technically belongs to the R and N hidden layerã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_191.png)

If we would implement this one hereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_193.png)

And the SDDM has a more complicated setupï¼Œ as you recall from last timeã€‚

 So it has all these different types of hidden layers hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_195.png)

![](img/49104266c97f1f4f9793724450b9f7d0_196.png)

Okayã€‚å—¯ã€‚Noã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_198.png)

What we have here is the embedding that convertsã€‚The word into the real value vectorã€‚

 If I go back to my slides againï¼Œ this is giving us this matrix hereã€‚ So this goes from textã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_200.png)

![](img/49104266c97f1f4f9793724450b9f7d0_201.png)

To this interteger vectorï¼Œ through these embeddingsã€‚

And then the LSDM takes in this embeddings and produces the hidden activationsã€‚

And then this is just like a classification layerï¼Œ like in a multi layer perception or the last layer of a convolutional layerã€‚

 This goes from the hidden dimensionã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_203.png)

To the class labelsï¼Œ the output dim is the number of class labelsã€‚Nowï¼Œ these are defined hereã€‚

 We can't use easily a sequential like we did beforeã€‚

 because there's a little bit the output looks a little bit differentã€‚So I'm alsoã€‚

 maybe I should say you can technical use an R and N instead of the LSDMã€‚

 but you will find the performance is relatively poorã€‚ So youã€‚Probably want to use an SDDMã€‚

 but if you want to do some experimentsï¼Œ you can actually use the R and N instead of the LSTMã€‚

 The LSTM is essentiallyï¼Œ yeahï¼Œ what I showed you before in the last2ï¼Œ two videos agoã€‚

 the LSDM hidden layerã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_205.png)

Okayã€‚The forward pass gets a textã€‚ So this gets ready the textã€‚ This goes through the embeddingã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_207.png)

![](img/49104266c97f1f4f9793724450b9f7d0_208.png)

And then the embedding is the input to the LSDMã€‚ So I call it R nï¼Œ but's the LSDMã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_210.png)

And it outputsã€‚The outputï¼Œ the hidden and the cell stateã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_212.png)

Soã€‚å—¯ã€‚mJust looking for a good slide hereã€‚ So we have this many21 hereã€‚Andã€‚Theã€‚

Should probably focus on manyï¼Œ one too many or many too manyã€‚ Okayï¼Œ so let'sã€‚

 let's consider this many too many hereã€‚ When I call the LSDMï¼Œ it will outputã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_214.png)

![](img/49104266c97f1f4f9793724450b9f7d0_215.png)

So the orange  one you can think of asï¼Œ as the LCDMï¼Œ it will outputã€‚

Something that goes to the outputã€‚ I think Id a better slide somewhere hereï¼Œ Yeahï¼Œ hereã€‚

 So it will output the yã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_217.png)

And it will output the hidden state for the next hidden layerã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_219.png)

So this is the output is the yã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_221.png)

This is the yã€‚Hidden is what goes here in this arrowã€‚ What goes to the next oneã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_223.png)

And cell state is specific to the LSDMã€‚ That's this LSTM stateã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_225.png)

Okayã€‚Soã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_227.png)

å—¯ã€‚We scroll hereã€‚Soï¼Œ we haveã€‚Cell state that is output hereã€‚ rightï¼Ÿ So this one hereï¼Œ Then we haveã€‚

 this is the y here to next layer where it says to next layerï¼Œ this would be the yã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_229.png)

This would beã€‚The outputã€‚And H Tï¼Œ this would be the hiddenã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_231.png)

And sellï¼Œ this would be the Cã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_233.png)

It is complicatedã€‚ So if that does make sense immediatelyï¼Œ it is a complicated conceptã€‚Soã€‚

 since we haveã€‚Let me find a better representation yet againã€‚Since we have many to oneã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_235.png)

We are not going to use these hereã€‚ So we are not going to use this one and this oneï¼Œ soã€‚This oneã€‚

 we are not going to useã€‚ This one is notã€‚ we are not going to useã€‚

 and this one is kind of also included in this outputã€‚So to make things simplerï¼Œ we are going to useã€‚

 actuallyã€‚Let me run arrowã€‚ So what we are going to use here is we are going to use the hidden output from the last oneã€‚

 which is this hidden hereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_237.png)

![](img/49104266c97f1f4f9793724450b9f7d0_238.png)

And thenï¼Œ we will provideã€‚Or own hidden thereã€‚Of our own output hereã€‚ instead of using this green 1ã€‚

 we will have our ownã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_240.png)

![](img/49104266c97f1f4f9793724450b9f7d0_241.png)

Fooully connected here or fully connected thereï¼Œ this isã€‚What we are doing hereã€‚

 So we are computing our own outputã€‚ We areã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_243.png)

Removing thisï¼Œ it'sï¼Œ let's say too complicatedã€‚ We don't want to use allï¼Œ all these green onesã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_245.png)

We are going to only useã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_247.png)

The hidden oneï¼Œ which is the output of this orange here of the last orangeã€‚

 and then have our own fully connected layer to get this output hereã€‚ This is what's going on hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_249.png)

Alrightï¼Œ I hope this makes somewhat senseã€‚Soã€‚If we look at theã€‚

Sizes we go from sentence length to batch sizeã€‚ This is like what we had beforeã€‚

 sentence length and batch sizeï¼Œ the matrix of our inputã€‚Then this goes into the embedding layerã€‚

 which produces a sentence lengthï¼Œ batch sizeï¼Œ embedding dimensionã€‚ This is ourã€‚

 I don't know why it is arranged like thatï¼Œ but it is ourã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_251.png)

Let me delete thisã€‚ So weï¼Œ so I don't save it later when I export it for youã€‚ yeahã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_253.png)

So this will beï¼Œ this is the this is the embeddingã€‚This is the embedding matrixã€‚

 This is the embedding for one training exampleã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_255.png)

We have someã€‚ we have multiple because we have a batch size and the batch size dimensions between the embedding and the sentence lengthã€‚

 So the sentence length length would be the rows hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_257.png)

![](img/49104266c97f1f4f9793724450b9f7d0_258.png)

Hereï¼Œ it's also the rowsã€‚ and the columns is hereï¼Œ not the embedding dimensionsã€‚ It's the batch sizeã€‚

 So we have sent in flks batch size and embeddingã€‚ So you have to think there would be an additional dimension hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_260.png)

![](img/49104266c97f1f4f9793724450b9f7d0_261.png)

![](img/49104266c97f1f4f9793724450b9f7d0_262.png)

And then this goes sentence lengthï¼Œ batch sizeï¼Œ hidden dimensionã€‚ This isã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_264.png)

The dimensionity of a hidden thereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_266.png)

We choseï¼Œ I think 256ã€‚ and then weã€‚What we output get isï¼Œ there's only oneã€‚

So hidden is one because it's the last oneï¼Œ only the last oneã€‚

The dimension is batch size and hidden dimensionã€‚ This is usually what would go into the next hidden layerã€‚

And we want to give it to our weï¼Œ like I saidï¼Œ before we make our own output layerã€‚

 Thiss a fully connected layerï¼Œ this oneã€‚So we are removing here with squeezeã€‚

 We are removing this oneã€‚ So we make this a batch size times hidden dimensionã€‚

 And this is something you have seen before all the time when we use the multilay perceptron and a convol networkã€‚

This squeeze is justï¼Œ we are saying remove the first dimensionã€‚

 the one here so that it is compatible with our linear layer hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_268.png)

Againï¼Œ this is complicated stuffã€‚ So if that doesn't make senseã€‚

 you don't have to memorize any of thisï¼Œ I can totally understand if this is complicatedã€‚

 to be honestï¼Œ I also spent several hours just implementing thisã€‚ it's it's not easyã€‚

 it's complicated andã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_270.png)

![](img/49104266c97f1f4f9793724450b9f7d0_271.png)

If you really want to work with textï¼Œ of courseï¼Œ watching this one lecture gives you just the introductionã€‚

 It's normal to spend weeks or months or professionals spend years really doing all these things There are manyã€‚

 many aspects to working with textã€‚ this is just the introduction so don't feel bad if this looks a little bit complicated to youã€‚

 it naturally takes time to work with this and you to get a better grasp of what's going on hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_273.png)

Oï¼Œ but moving onï¼Œ as saw weã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_275.png)

Iitialize now our recurrent neural networkã€‚ the input dimension is equal to our vocabulary size is a 20002ã€‚

 So we use that here in hour to create our embedding matrixã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_277.png)

![](img/49104266c97f1f4f9793724450b9f7d0_278.png)

![](img/49104266c97f1f4f9793724450b9f7d0_279.png)

Then the embedding dimensionï¼Œ we had something like 1 of28ã€‚And the hidden dimension is 256ã€‚

 and number of classes we haveã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_281.png)

2ï¼Œ we set it to twoã€‚ So if I scroll up to the topã€‚We set it toã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_283.png)

Two hereï¼Œ we in a dimension 256 embedding 128ã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_285.png)

We could technically use just one class and then use logistic sigmoid instead of softm functionã€‚

 and then we could use the binary cross entrobus instead of the regular cross entropios in Pytorchã€‚

 I did that at firstï¼Œ but then I was thinking maybe you would like to use this code here as a template for some other classification problemã€‚

 That is not a binary oneã€‚ And then you would have to rewrite everythingã€‚ So Iã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_287.png)

![](img/49104266c97f1f4f9793724450b9f7d0_288.png)

![](img/49104266c97f1f4f9793724450b9f7d0_289.png)

![](img/49104266c97f1f4f9793724450b9f7d0_290.png)

![](img/49104266c97f1f4f9793724450b9f7d0_291.png)

Implemented it here with two output notesï¼Œ although it's redundantã€‚

 I implemented it so that you can adopt it to your own dataset setã€‚

 So I thought it's more useful in this wayï¼Œ so you don't have to rewrite any code if you want to use that for your projectã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_293.png)

![](img/49104266c97f1f4f9793724450b9f7d0_294.png)

Alrightï¼Œ so nowã€‚Let's getã€‚ So this is initializing the modelã€‚ I'm just using Adamomã€‚ Nowã€‚

 let's get to the partã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_296.png)

Wellï¼Œ we have the trainingã€‚ So here's the accuracy function for computing the accuracy soã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_298.png)

![](img/49104266c97f1f4f9793724450b9f7d0_299.png)

Yeahï¼Œ so yeah we are just computing the accuracyã€‚ And here that's the trainingã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_301.png)

![](img/49104266c97f1f4f9793724450b9f7d0_302.png)

Interestingï¼Œ I should haveã€‚ yeahï¼Œ I could have also done it like thatã€‚ But so to be clear hereã€‚

 how this works isã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_304.png)

I have batch index and batch dataã€‚ So here I did it a little bit differentlyã€‚ So yeahã€‚

 already you unrolled thisï¼Œ it seemed to workã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_306.png)

![](img/49104266c97f1f4f9793724450b9f7d0_307.png)

But yesï¼Œ so here I have batch index and batch dataã€‚ So it's the training loopã€‚

 I iterating over the eposï¼Œ setting my model to train modeã€‚

 and then I'm iterating over the data loadï¼Œ and it gives me two things the textã€‚

 which is batch data dot text column nameã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_309.png)

And labels which dispatched data dot label column nameã€‚This is why I earlier renamed the columnsã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_311.png)

Then I'm providing either logictsã€‚ This is the output from the modelã€‚

 So we give the text to the modelï¼Œ and it will do the embedding for usã€‚

And then run it through the SDDMã€‚And ought come the logicitsã€‚

 which is just like the logicits in the multi layer perceptron or the convol network that we have seen beforeã€‚

 And we have the labels hereã€‚ The labels is all sentimentã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_313.png)

And this is exactly how we've seen that beforeã€‚ There's nothing new hereã€‚ And yeahï¼Œ it trainsã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_315.png)

Actuallyï¼Œ I was training itï¼Œ and I noticedï¼Œ okayï¼Œ it's not really workingï¼Œ rightã€‚

 you can see it doesn't really workã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_317.png)

![](img/49104266c97f1f4f9793724450b9f7d0_318.png)

And I was like really frustrated because I spent many hours implementing thisã€‚

 and then it didn't workã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_320.png)

But then for some reasonï¼Œ it picked up training hereã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_322.png)

And the performance got really goodã€‚ So at the endï¼Œ I had a test accuracy of 84%ã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_324.png)

Then also to make sure I should have used the same dictionaryã€‚ I don't know why I didn't do that forã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_326.png)

Yeahï¼Œ the tokenise anywayã€‚ So here is just an exampleã€‚ This I took actually modified it slightlyã€‚

 This is based onã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_328.png)

Based on the tutorial hereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_330.png)

Took it from hereã€‚ So modified it a little bit for this codeã€‚

 This is just like an example of the things we have to do in order to put something into our textã€‚

 If we have new textã€‚ So let's say I have my model and I have a new text like this is such an awesome movieã€‚

 I really love itã€‚ðŸ˜Šã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_332.png)

![](img/49104266c97f1f4f9793724450b9f7d0_333.png)

And I want to know whether it what the probability that this is a positive review isã€‚

It turns out it's 98% positiveï¼Œ which is what we would expectã€‚So what did I do hereã€‚

 I put the model in evaluation modeã€‚ I tokenized the textï¼Œ soã€‚Yeahã€‚

 so I'm tokenizing a text using this LP tokenizerã€‚ I should have maybe used the same as above this web dictionaryã€‚

 but it worked just fineã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_335.png)

Thenï¼Œ I'm getting theã€‚Interjoã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_337.png)

Representationã€‚The length I don't need hereã€‚ I need it for my other modelã€‚

 This is why I think I've just left it in hereã€‚ Then I'm converting it to a long ten tensor and put it onto the GPUã€‚

 It's where my model isã€‚ If it was on the GPUï¼Œ otherwiseï¼Œ it will be on the CPUï¼Œ if device is CPUã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_339.png)

Just an optional step if you' trained on the GPUã€‚Yeahï¼Œ so this' is the index tensorã€‚

And this index sensorsor will go to the embeddingã€‚ So the embedding will not do the text intoã€‚

The embedding it will be two stepsï¼Œ so we have to prepare the indicesã€‚Yeahï¼Œ and thenã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_341.png)

That's the softm because we don't have any softm in our model ourselvesã€‚And yeahã€‚

 this is just this predict sentiment function forã€‚Putting in arbitrary textã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_343.png)

And here is the same phoneã€‚ the computingï¼Œ the probability that something is negativeã€‚ It's just myã€‚

1 minus thisï¼Œ rightã€‚So hereï¼Œ I really hate this movieã€‚ It is a really bad movie on sucksã€‚

 and you can seeã€‚Model also detects that this is indeed a negative oneã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_345.png)

Alrightï¼Œ so this is how it essentially worksã€‚ So this is the LSTMï¼Œ the regular LSTMã€‚

 It's pretty complicatedï¼Œ as you have seenã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_347.png)

![](img/49104266c97f1f4f9793724450b9f7d0_348.png)

You can actually make it even co more complicated using this packed approachã€‚

 So if you're interested in thatï¼Œ there is imp very good explanation hereã€‚ So essentiallyã€‚

 it's aboutã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_350.png)

Orderingã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_352.png)

The sentences and the batches to minimize the number of computationsã€‚

 because we have to do a paddingï¼Œ rightï¼Ÿ And if you just shuffle your data setã€‚

 there will be randomly long and short sentences togetherï¼Œ butã€‚

It is inefficient because for some batchesï¼Œ you have to pad a lotã€‚

 just because there are one or two long sentencesã€‚ So this packed approachã€‚

 what we we will do is it will look at the whole training set and organizeise it such that it minimizes the number of padding requiredã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_354.png)

So there are a few changes that you have to make for thatã€‚Soã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_356.png)

I highlighted them hereã€‚ so you have to include the length in the tokenizer and so forthã€‚

 So some changesã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_358.png)

![](img/49104266c97f1f4f9793724450b9f7d0_359.png)

I think here weã€‚The someã€‚Sting within the batches also requiredã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_361.png)

![](img/49104266c97f1f4f9793724450b9f7d0_362.png)

Yeahï¼Œ and then here that was what take took me a long time to figure outï¼Œ you have toã€‚

Use this R N dot pe dot padded sequences and then provide also the text lengthã€‚

 took me literally hours to figure that outã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_364.png)

![](img/49104266c97f1f4f9793724450b9f7d0_365.png)

Was kind of frustratingï¼Œ butã€‚Anywaysï¼Œ okayï¼Œ soã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_367.png)

And then I had to modify this a little bit in the accuracy functionã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_369.png)

In any caseï¼Œ long story shortï¼Œ it trainedã€‚ It trained actually very wellã€‚

 I didn't expect it to train that wellã€‚ I'm not sure if there's a buckã€‚

 but it trained so good actually or so well that it gotã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_371.png)

![](img/49104266c97f1f4f9793724450b9f7d0_372.png)

![](img/49104266c97f1f4f9793724450b9f7d0_373.png)

99% test accuracyã€‚ So essentiallyï¼Œ this should be just the same as this oneã€‚

 but more efficient because it putsã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_375.png)

Or organize it so that we minimize the peddingã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_377.png)

And it is also faster because of thatï¼Œ you can see if I go here for one epo takes only 0ã€‚33 minutesã€‚

 whereas hereã€‚

![](img/49104266c97f1f4f9793724450b9f7d0_379.png)

![](img/49104266c97f1f4f9793724450b9f7d0_380.png)

It takes almost more than two times as muchã€‚And yeah you can see it gets 99% test accuracyã€‚

 I took a look at thisã€‚ I can't find any mistake or bugã€‚

 I think it's just a great model here that trains wellã€‚

 It could be that there's a bug somewhere because this is a bit suspiciously goodã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_382.png)

![](img/49104266c97f1f4f9793724450b9f7d0_383.png)

![](img/49104266c97f1f4f9793724450b9f7d0_384.png)

But yeah well I take it 99% doesn't sound too bad So yeahã€‚

 so here you have two templates and based on what I've seen actually I think this one looked really good so here you will have some additional resources if you are really interested in working with text but again this is a very complicated topic and I don't blame you if this looks all complicated to you so you are just learning about it probably for the first timeã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_386.png)

![](img/49104266c97f1f4f9793724450b9f7d0_387.png)

People who work with natural language processing spend manyï¼Œ manyã€‚Yeah daysï¼Œ weeksã€‚

 months learning these types of thingsã€‚ So here I gave you the overviewã€‚ I hope it's it's usefulã€‚

 Next lectureï¼Œ we will now then finally get to the generative modelling partã€‚

 So now I gave you the introduction to the general machine learning and deep learning concepts in the next lectureã€‚

 we will take a look at deep learning models forï¼Œ yeahï¼Œ generating new dataï¼Œ auto encodesã€‚

 variational auto encodes generative adversarial networksã€‚ðŸ˜Šï¼ŒAnd if we have timeã€‚

 maybe also transform usã€‚ All rightï¼Œ then see you on Thursdayã€‚



![](img/49104266c97f1f4f9793724450b9f7d0_389.png)