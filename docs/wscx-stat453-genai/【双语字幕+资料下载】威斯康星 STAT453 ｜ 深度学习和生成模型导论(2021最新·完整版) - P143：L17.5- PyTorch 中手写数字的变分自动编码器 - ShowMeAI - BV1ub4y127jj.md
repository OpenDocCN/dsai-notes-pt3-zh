# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÂ®ÅÊñØÂ∫∑Êòü STAT453 ÔΩú Ê∑±Â∫¶Â≠¶‰π†ÂíåÁîüÊàêÊ®°ÂûãÂØºËÆ∫(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P143ÔºöL17.5- PyTorch ‰∏≠ÊâãÂÜôÊï∞Â≠óÁöÑÂèòÂàÜËá™Âä®ÁºñÁ†ÅÂô® - ShowMeAI - BV1ub4y127jj

Al rightÔºå let us begin by looking at a variational auto encoder for handwritten digits in Pythtor„ÄÇ

 So this is our Mnines dataset set„ÄÇ starting simple„ÄÇ I have a bunch of code examples„ÄÇ

 I will show you one at a timeÔºå So starting with the simplest one„ÄÇ

 This is our variation out encoder for Mnes„ÄÇ And I implemented it as a convolutional variational auto encoder„ÄÇ

 Of courseÔºå you can also implement it with fully connected layers„ÄÇ

 But since Mnis is an image dataset„ÄÇ Why not using convolutional layers„ÄÇ And alsoÔºå yeah„ÄÇ

 the structure will be similar to the autoer encoder that I implemented in the previous lecture„ÄÇ

 exceptÔºå of courseÔºå that we have the differences with using this mean and log bar vector„ÄÇ

 And then also having the K divergence term„ÄÇ instead of just a reconstruction loss„ÄÇ All right„ÄÇ

 one thing at a time„ÄÇ So as usualÔºå I have helper function So that the notebook is not too crammed„ÄÇüòä„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_1.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_2.png)

ActuallyÔºå in the last couple of days I received a few questions from students regarding these helper functions„ÄÇ

 whether it's okay to use them in the class project and yesÔºå of course it's okay to use them„ÄÇ I mean„ÄÇ

 I actually wrote them for this class to keep things more organized because I'm reusing most of them from week to week and instead of copy and pasting the contents always in that notebook here„ÄÇ

 I thought it's more organized to have this as separate functions„ÄÇ

 for instance in my helper train function I have still the classifier function that we used before the autoenr„ÄÇ

 the regular autoenr then the variation autoenr and so forth„ÄÇ

 I feel like instead of copying all that into the main notebook for all the five autoenrs here„ÄÇ

 having it one time here and importing it as kind of cleaner and more organized and you are of course welcome to reuse everything that you can find here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_4.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_5.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_6.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_7.png)

Also with any kind of code you find on GiHubÔºå chances are that you are free to reuse it„ÄÇ

 usually especially in educational contextsÔºå you just have to cite the source so that it's clear that it's not your code that it is not plagiarized if you make clear where you have the code from„ÄÇ

 but if you show where you have the code fromÔºå then it's usually fine to reuse the code„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_9.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_10.png)

Of courseÔºå there may be certain types of code that have a license that don't permit that„ÄÇ

 but unless it's stated explicitly for educational purposesÔºå it's of course okay to reuse that„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_12.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_13.png)

And yet my code is writtenÔºå Ive wrote this especially for educational purposes„ÄÇ

 so please feel free to use any of that for your class projects„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_15.png)

But yeahÔºå moving on„ÄÇ So I have my helper functions when the time comes in the code„ÄÇ

 I will explain what they are doing„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_17.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_18.png)

ÂóØ„ÄÇHereÔºå this is like usual we have our boiler plate„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_20.png)

Bge size1 56Ôºå small learning rateÔºå50 epochs„ÄÇ We don't need classes„ÄÇ Actually„ÄÇ

 I don't know why I headed there„ÄÇ Probably copy and paste  errors„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_22.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_23.png)

And we are using the M data set„ÄÇ we don't need validation data hereÔºå because yeah„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_25.png)

We are only uÔºå I meanÔºå variation auto decors are unsupervised„ÄÇ We are only using the images„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_27.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_28.png)

ÂóØ„ÄÇYeahÔºå here I am just checking that the dataset set works„ÄÇ AgainÔºå we don't need the labels„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_30.png)

And here it's the main model where it gets interesting„ÄÇ So similar to the regular autoer encoder„ÄÇ

 I set it up using an encoder„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_32.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_33.png)

And a decoder„ÄÇBoth cases using sequential here„ÄÇ So this is„ÄÇSeveral convolutional layers„ÄÇ

And I should say the latent space is size 2„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_35.png)

So what I'm doing here is I' am compressing it„ÄÇAnd then here I am reconstructing it into the original space„ÄÇ

 So Emnes is 28 by 28„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_37.png)

Here I am having a fully connected layer followed by convolutional transpose layers or transpose convolution layers„ÄÇ

And then I have this trim functionÔºå the same one that I used in the regular autoenr because it happens that it will be 29 by 29„ÄÇ

 and the original images were 28 by 28„ÄÇ I'm just trimming the last pixel here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_39.png)

OkayÔºå so there's one thing I have not talked about that is kind of the essence of this variational auto encoder„ÄÇ

 what makes makes it different from the regular auto encoder„ÄÇ So for the regular auto encoder„ÄÇ

 we may have had something let me put it like here„ÄÇWe may have had something„ÄÇLike this„ÄÇ

Where we had30„ÄÇ1 out 36 up to2 if I want to have a two dimensional latent embedding„ÄÇ

 I would have it like this for my encoder„ÄÇHoweverÔºå since this is not a regular auto encoder„ÄÇ

 it's a variational auto encoderÔºå we are going to work with this„ÄÇMean vectorÔºå the mu„ÄÇ

And the lobar vector„ÄÇSo both I use for both fully connected layers to compress whatever this is into a two dimensional one„ÄÇ

And the same thing here„ÄÇ So they are separateÔºå separate modelsÔºå because if I would use the same one„ÄÇ

 wellÔºå then the mean in the log variance would be the same if I use the same linear layers„ÄÇ

 I have to have two linear layers„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_41.png)

And now let me show you how I actually use them„ÄÇ I think it makes more sense then so„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_43.png)

Let's take a look at the forward method first„ÄÇ Then I will explain you why I have this method„ÄÇ

So in the forward methodÔºå firstÔºå like in the regular auto encodeÔºå I'm calling the encoder first„ÄÇ

 So this is encoding„ÄÇMy image into the two dimensional space„ÄÇSo let me bring up„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_45.png)

Maybe on„ÄÇSlides here„ÄÇËØ¥ÁöÑ‰∫ãÂÆû„ÄÇEncoding into my two dimensional space„ÄÇBut we are not quite here yet„ÄÇ

 We are somewhere here now in that orange partÔºå and then„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_47.png)

What we want to do is we want to get this mean vector and the logvariant vector„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_49.png)

And then we call this„ÄÇReparmeterization function„ÄÇ So here we will have two vectorsÔºå so„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_51.png)

It's maybe a little bit unfortunate that I'm showing it as oneÔºå but it would be actually two vectors„ÄÇ

 mean and the lo variances„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_53.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_54.png)

And then we call the self do repar rise here on these two vectors„ÄÇ

 And what is going on here is that I' am sampling this epsilon from random normal distributionÔºå so„ÄÇ

HereÔºå this is equal to the input size„ÄÇ So if we yeah if we have a batch size of 256„ÄÇ

 it will sample 256 of those„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_56.png)

Okay„ÄÇSee„ÄÇSo this is where we are hereÔºå this epsilon„ÄÇ So we are sampling now the epsilon„ÄÇHere„ÄÇLet's„ÄÇüòî„ÄÇ

This one„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_58.png)

And then we are doing the rippermeterization hereÔºå the mean vector„ÄÇPlusÔºå the epsilon times„ÄÇ

 the standardner deviation„ÄÇ So this is the standardner deviation„ÄÇ

 Why is that the standard deviation that is„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_60.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_61.png)

The lock bar trickÔºå where did I have it„ÄÇHere„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_63.png)

So this was the lock qua trick because this allows us to have„ÄÇFor this one„ÄÇ

 positive and negative valuesÔºå instead of just positive valuesÔºå it is better for back propagation„ÄÇ

And this is essentiallyÔºå yesÔºå So this whole step is„ÄÇIs the step here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_65.png)

RightÔºå so then we are returning Z„ÄÇ And this Z here is„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_67.png)

Is this Z here in the center that I'm showing you„ÄÇ So I'm not showing you the mean and lock bar vector„ÄÇ

 I'm only showing you the Z here that„ÄÇIt comes out of here„ÄÇOkayÔºå so„ÄÇReparmeterized„ÄÇThen returns O Z„ÄÇ

 I called it here and it„ÄÇ I could have also called it Z„ÄÇAnd then„ÄÇ

We are decoding using our deco and our decoder takes this Z back to the 33136 and then runs through the convolutional transpose layers and reconstructs our input here I have the s mite„ÄÇ

 So the pixels are in the01 range and„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_69.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_70.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_71.png)

And where is it„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_73.png)

IÔºå I have to go up„ÄÇ I think now it's in a data load and a data loader„ÄÇ I should probably show you„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_75.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_76.png)

And the data orderer that we are that I' am not using any particular train transform and test transform and by default„ÄÇ

 how I implemented this at Cypher 10Ôºå sorry„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_78.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_79.png)

Where is MistÔºå US Mist„ÄÇSame thing I have this torch to tensor it will automatically convert images to 01 range if we use a normalized function that such that let's say the pixels are between minus1 and 1 that would also work„ÄÇ

 but then we have to make sure that we use a 10 h here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_81.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_82.png)

Because we want the pixel ranges between the input and the output to be on the same range because we want to have the MSE„ÄÇ

 rightÔºü So if the input pixels are between 0 and 1„ÄÇ

 then the reconstructed pixels should also be between 0 and 1Ôºå so„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_84.png)

Going on here„ÄÇAgainÔºå the forward method„ÄÇI'm calling the encoder„ÄÇDo the repromanorization„ÄÇ

To get my latent spaceÔºå this includes this epsilon from the random normal distribution„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_86.png)

Then I'm calling my decoder and I'm returning a bunch of things here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_88.png)

That's what I need for my„ÄÇB proagationÔºå I will show you in the trainingÔºå I need all four of those„ÄÇ

LaterÔºå I will„ÄÇDo some investigation and some experiments„ÄÇ

I will show you some interesting experiments later for which I implemented also this encoding function„ÄÇ

 So this encoding function is maybe overkill to implement that I yeah„ÄÇI meanÔºå why not„ÄÇ

 So I in this wayÔºå I don't have to run the decoder every time„ÄÇ

 So the encoding function just re returns Z„ÄÇ So it's basically just it's this part„ÄÇ

 if you take a look at this„ÄÇIf I just copy it below hereÔºå you can see that's the same„ÄÇ

Same thing hereÔºå right„ÄÇ So I just decoupled it for some reason„ÄÇ I could have actually„ÄÇ

Could have called it„ÄÇHere on„ÄÇAn xÔºå for example„ÄÇLike this should of also work„ÄÇ

 except that I want these two for the loss function„ÄÇ

 I think that's why I have it as a separate functionÔºå instead of doing„ÄÇdoing„ÄÇThisÔºå but yeah„ÄÇ

Just a minor implementation detail„ÄÇ So I have this also separately if we want to do some investigation later with some functions I've wrote„ÄÇ

 So yeah for here for this notebookÔºå you can actually ignore that it doesn't do anything here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_90.png)

OkayÔºå so explain to you the thought path„ÄÇ so which is now encoder„ÄÇThe repermatization„ÄÇ

Oh should probably„ÄÇReprimeterization„ÄÇ and then the decoding„ÄÇ

 and then we returning these things in the regular out quarterÔºå we only had„ÄÇThisÔºå essentially„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_92.png)

This was our regular„ÄÇAlder corner„ÄÇNowÔºå we have„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_94.png)

Oops„ÄÇAlsoÔºå this reprimeterizationÔºå mainly in these two vectors„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_96.png)

OkayÔºå let's initialize everything here and then we run the training„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_98.png)

NowÔºå let's take a look at the training function„ÄÇI actually here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_100.png)

So it's my training function here„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_102.png)

We have actually two losses nowÔºå so by default amusing them as e loss„ÄÇ

 we discussed this briefly in the video why we don't use the binary cross entropy here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_104.png)

The rest is boiler plate like before„ÄÇ So this is just„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_106.png)

What we used every time I just used this one hereÔºå the underscoreco„ÄÇ

 instead of usually we had something like labels or targets here„ÄÇ

 where we don't need labels or targets because it's an unsubervised model„ÄÇ

 So I just replace it by underscoreco„ÄÇ underscoreco and Python is a convention that we use if we don't use the variable„ÄÇ

 But weÔºå but the variable is there„ÄÇ we just use an underscoreco„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_108.png)

OkayÔºå so we have the features here from our data and then„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_110.png)

HereÔºå I'm calling model„ÄÇ So model will call„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_112.png)

Execute forward„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_114.png)

Gives us these four vectors hereÔºå which this return from here„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_116.png)

And then I'm computing now firstÔºå the k KL divergence term„ÄÇ So this term hereÔºå that's computed is„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_118.png)

I had it somewhere„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_120.png)

HereÔºå so is this this term here that I discussed in the video„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_122.png)

And notice that I'm usingÔºå I'm summing here over the latent dimensionÔºå so„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_124.png)

The sum here is over the latent dimension„ÄÇ I forgot to have the index under the sum„ÄÇ

 but this is for the latent dimension„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_126.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_127.png)

Not for the batch size„ÄÇWe have then if we want to compute the average k divergence over the batch size„ÄÇ

 we call them the mean here„ÄÇ So if I would„ÄÇNot have x's here„ÄÇ

You will probably get really bad results because it will sum over everything„ÄÇI mean„ÄÇ

 sure why not but„ÄÇYou should first sum over the latent dimension„ÄÇ

 and then you can average over over the batches„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_129.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_130.png)

Okay„ÄÇÂóØ„ÄÇYeahÔºå and then we compute the pixel wise mass„ÄÇ So this is our reconstruction mouse„ÄÇ

Here it's calling loss FNÔºå which is just loss function„ÄÇ And by default„ÄÇ

 if I don't specify it at my functionÔºå it uses the means called error loss„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_132.png)

And the means square error loss is„ÄÇBetween the decoded ones„ÄÇSo the reconstructed ones„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_134.png)

And the inputs„ÄÇ So this part here is reallyÔºå yeahÔºå the reconstruction is here„ÄÇ

 This is what you see at the top here„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_136.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_137.png)

I'm reshaping it„ÄÇSo that it's the batch size and the vector„ÄÇ So instead of having a tensor„ÄÇ

 it's now a matrix„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_139.png)

A tableÔºå if you will„ÄÇ And then we first sum over the pixels„ÄÇ It's„ÄÇ

 this is equivalent to summing here over the latent dimension„ÄÇ

 So we are summing first the square arrow over the pixels„ÄÇ So this is essentiallyÔºå yeah this„ÄÇ

 this sum here„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_141.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_142.png)

I haven't done a reduction„ÄÇ OkayÔºå I could have I forgot kind of think it should do it means square„ÄÇ

 I forgot the the square rootÔºå but doesn't really matter„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_144.png)

SoÔºå I don't have a„ÄÇThere shouldn't be a square rootÔºå to be honest„ÄÇBecause it's the square here„ÄÇ

Me change that„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_146.png)

ÂïäÔºåÁü•ÈÅì„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_148.png)

When you can have a square rootÔºå doesn't really matter„ÄÇOkay„ÄÇ

 so that's not the Euc clan distance anymoreÔºå but the square Euclidean distance„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_150.png)

It doesn't really matter here„ÄÇAnyways„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_152.png)

OkayÔºå so we have no pixel wise here„ÄÇ with sum over the pixels„ÄÇ

 and then we average over the batch dimension„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_154.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_155.png)

That's where our mean comes from„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_157.png)

OkayÔºå then we compute the overall loss and the overall loss consists of two parts„ÄÇ

 the reconstruction„ÄÇ Oh sorryÔºå the pixel wise loss and the k divergence term„ÄÇ

 And here I have an additional„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_159.png)

Pramat„ÄÇ So I should probably also have that in the code„ÄÇSoÔºå let's call that„ÄÇ

L 1 is the reconstruction„ÄÇ Let's call it alpha„ÄÇBecause it can give us a weight because„ÄÇ

It may not be clear„ÄÇMeanÔºå they may not be in the same scale really depends on the images„ÄÇ

 So it's kind of a hyperparmetera„ÄÇ It's like saying how much should the model focus on the reconstruction us and how much should it focus on the KL divergence term„ÄÇ

 if we don't use alpha if we if we set alpha to oneÔºå then there will be equal weight„ÄÇ

 but might not work well in practice all the timeÔºå So it's another hyperparametera„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_161.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_162.png)

OkayÔºå yeahÔºå and this is essentially„ÄÇ And then we can run our big propagation as usual„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_164.png)

So just to recapÔºå compute the Cal divergence termÔºå we compute the pixelwise term„ÄÇ

 and then we add both together„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_166.png)

And we are training itÔºå this is just a logging like usualÔºå nothing new here„ÄÇ

 So let us take a look now how it trains„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_168.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_169.png)

You can see it starts with a high lossÔºå and it goes downÔºå which is nice„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_171.png)

Because going more slowly„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_173.png)

YeahÔºå so I actually have two plots here„ÄÇ I have this plot training loss function that I used before„ÄÇ

 now I'm doing it with a reconstruction loss per batch„ÄÇ

 the train the k divergence loss and then the combined loss so you can see first is the reconstruction loss it goes down„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_175.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_176.png)

The ks„ÄÇGoes downÔºå But then goes up„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_178.png)

Well„ÄÇAnd the combined loss„ÄÇIt's kind of a trade offÔºå rightÔºå But the combined loss„ÄÇGo down„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_180.png)

YeahÔºå so overallÔºå it goes down„ÄÇ And what we can see is the auto encoder is able to„ÄÇ

Generate realistic looking images„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_182.png)

I meanÔºå kind of„ÄÇ So againÔºå we have the same problem„ÄÇ It's only two dimensional„ÄÇ

 which is kind of extreme„ÄÇ So you can see sort of top row here is„ÄÇ

Original images in the bottom row is reconstructed images„ÄÇAnd you can seeÔºå okay„ÄÇ

 it confuses four with a9Ôºå but most of the time it looks kind of okayÔºå okayÔºå it's blurry too„ÄÇ

 here have5 and3Ôºå it gets confusedÔºå but this is really because the space is so cramped„ÄÇ

 So let's take a look at the latent space here„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_184.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_185.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_186.png)

So I'm also showing the class labels here„ÄÇ you can seeÔºå okay„ÄÇ

 it's a bit cramped because it's two dimensional„ÄÇI don't like this overlap that thinks overlap„ÄÇ

 but well's„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_188.png)

what happens hereÔºå but it looks slightly better than for the regular auto code„ÄÇ unfortunately„ÄÇ

 I don't have it here for reference„ÄÇBut what you can see also now is that it's centered at 0„ÄÇRight„ÄÇ

 the distribution centre at 0 and it looks like Ga seeian mixture at some point„ÄÇ I meanÔºå kind of„ÄÇ

 I meanÔºå we can't go by class tables because it doesn't use the class tables„ÄÇ

 We would have to go by dimensions„ÄÇIt's hard to see hereÔºå but I have actually„ÄÇ

 for a high dimension one„ÄÇHistograms looking at the distributions per dimensions„ÄÇ it„ÄÇ

 it can be like it's hard to see becauseÔºå yeahÔºå we can„ÄÇ it's too much going on here„ÄÇ It's to dense„ÄÇ

 but it could probably be a„ÄÇMultivari standard goes in at some point„ÄÇ I meanÔºå here we have some„ÄÇ

Lets so„ÄÇNice„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_190.png)

ShapeÔºå but yeah„ÄÇWith a little bit of squintingÔºå it looks quietÔºå okay„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_192.png)

YeahÔºå and then we can sample from that distribution so we could just take arbitrary points from a standard normal distribution and then sample„ÄÇ

 So here I'm just taking one point„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_194.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_195.png)

The center„ÄÇShould be„ÄÇ0„ÄÇ03 somewhere here„ÄÇ and it reconstruct an 8„ÄÇ So 8 is actually under this 9„ÄÇ

 It's kind of unfortunate„ÄÇ So it's reconstructing the 8„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_197.png)

And here we are sampling now„ÄÇ So hereÔºå I'm just sampling from random normal distribution„ÄÇ Let me„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_199.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_200.png)

Show you that plotting„ÄÇÂì¶„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_202.png)

What was this function called plot images sampled from the A E„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_204.png)

It took me a lot of time to implement all that„ÄÇÂóØ„ÄÇMikeÔºå ohÔºå I should be in„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_206.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_207.png)

YeahÔºå the button„ÄÇSo yeahÔºå here what I'm doing is I'm„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_209.png)

Sampling from a random normal distribution„ÄÇ So R n is a random normal distribution„ÄÇÂóØ„ÄÇ

Sampling a given number of images here 10„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_211.png)

L in size„ÄÇ I'm sending it to2„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_213.png)

HereÔºå because that's how I trained my autoenr„ÄÇThen„ÄÇNotice that I'm not using the encodeder here„ÄÇ

 I'm only using the decoder here„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_215.png)

It's all amusing„ÄÇYeahÔºå and then I'm plotting„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_217.png)

So heres is some follow loop„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_219.png)

To do the plottingÔºå this is very similar to the regular auto encoder code„ÄÇ

 I just copy and pasted it and made a small modificationÔºå but essentially„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_221.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_222.png)

This is just plotting these imagesÔºå and these are just sampled from a random normal distribution„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_224.png)

You can see they look mostly reasonable„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_226.png)

Not all of them„ÄÇ This is garbage„ÄÇ thisÔºå thisÔºå but the ones look O„ÄÇ the sevenths look O„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_228.png)

![](img/571a6f32a80cb0c70d0d2b425fa84956_229.png)

It's look okay„ÄÇ I think many of these problems are that„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_231.png)

YeahÔºå in our caseÔºå we only have a two dimensional spaceÔºå so things don't look great„ÄÇ

 but it doesn't look terrible either„ÄÇ So if you make the a latent space a little bit bigger„ÄÇ

 it will look betterÔºå but yeah„ÄÇ

![](img/571a6f32a80cb0c70d0d2b425fa84956_233.png)

OkayÔºå so this is our variational auto encoder here and„ÄÇ

I will stop this video and then I will show you more interesting oneworth face images„ÄÇ



![](img/571a6f32a80cb0c70d0d2b425fa84956_235.png)