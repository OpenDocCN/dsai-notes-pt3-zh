# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÂ®ÅÊñØÂ∫∑Êòü STAT453 ÔΩú Ê∑±Â∫¶Â≠¶‰π†ÂíåÁîüÊàêÊ®°ÂûãÂØºËÆ∫(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P9ÔºöL1.4- ÁõëÁù£Â≠¶‰π†Â∑•‰ΩúÊµÅÁ®ã - ShowMeAI - BV1ub4y127jj

YeahÔºå hi and welcome backÔºå everyone„ÄÇ I hope it a nice first lecture day„ÄÇ Yeah„ÄÇ

 and remember when I mentioned that snow is awesome„ÄÇ if you look outside„ÄÇ

 there's a whole lot of new snow outside„ÄÇ But anyway„ÄÇ

 so today I'm going to talk about the supervised learning workflow in a little bit more detail„ÄÇ

 Last lecture day I talked about machine learning and the three categories of machine learning„ÄÇ

 Now I want to provide some more details about the supervised learning workflow„ÄÇ

 and then I will also cover some of the necessary notation and jargon regarding machine learning that we will be needing for the remainder of this course„ÄÇ

 So just laying some groundworkÔºå how we define a training set and what mathematical symbols we use and some terms that we will be using„ÄÇ

HoweverÔºå I'm trying to keep things a little bit short this time because yeah„ÄÇ

 as you've seen in the previous lecture dayÔºå there are lots of topics I want to cover the semester„ÄÇ

 So I don't want to go into too much technical details that are not very interesting for each topics„ÄÇ

 I try to keep things a little short„ÄÇ and then with that„ÄÇ

 I hope we will be able to tackle all the projects that we are topics that I have in mind for this cause„ÄÇ

 So with that without wasting too much more time„ÄÇ let me get started with the supervised dining workflow„ÄÇ

AlrightÔºå now let me talk a little bit more about the supervised learning workflow and yeah we will be using supervised learning a lot in the next couple of weeks„ÄÇ

 so just to briefly outline how supervised learning works„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_1.png)

So supervis learning is like you remember from the previous videos the process of regression or classification„ÄÇ

 so there are essentially two stepsÔºå one is the training step so we train a machine learning model and the second step is the inference step but before we get to the inference step let me talk about the training step first So imagine you have a training data set and your task is in this case„ÄÇ

 let's say classification you want to„ÄÇClassify something„ÄÇ

 Lets maybe pick a simple example of classifying different flowers„ÄÇ So let's say you have„ÄÇÂóØ„ÄÇ

Different„ÄÇFlowers„ÄÇAnd there might be different flower speciesÔºå maybe some flowers more like this„ÄÇ

And so forth and you are interested here in classifying how what type of flower it is based on an image„ÄÇ

 So you collected multiple flower images that's your training data setÔºå and you also have an expert„ÄÇ

 you consulted an expert to provide you with the labels so it could beÔºå for example„ÄÇ

Let me think that'sÔºå let's say this is an iris flower„ÄÇ This is a rose„ÄÇ And yeah„ÄÇ

 the third one would beÔºå let's say a sunflower or something like that„ÄÇÂóØ„ÄÇSo you have these labels„ÄÇ

 These are your„ÄÇLabels that you want to predict and the flowersÔºå the pictures„ÄÇ

 the pictures of the flowers„ÄÇ These are your„ÄÇObservations„ÄÇ

So you're collected maybe thousands of those„ÄÇ This is your training data set„ÄÇ

And in traditional machine learningÔºå what you would do is you would extract some features„ÄÇ

 So usually traditional machine learning algorithms don't work very well on image data„ÄÇ

 So you would yeah extract some features in here again„ÄÇYou would need a domain expert„ÄÇ

And having someoneÔºå someone's opinionÔºå like what could be a good featureÔºå you can think about it„ÄÇ

 But alsoÔºå usually it's good to consult an expert who knows a lot about for us„ÄÇ

 And it also helps like understanding the data set a little bit„ÄÇ So one might thinkÔºå okayÔºå yeah„ÄÇ

 what could be a potential feature„ÄÇ It could be maybe„ÄÇ

Maybe the color of the flower and maybe the height„ÄÇOf the flower and yeahÔºå other aspects„ÄÇThe number„ÄÇ

Of leaves„ÄÇAnd so forthÔºå so there might be different features you have to think about what could be a good feature and also what would be a feature that you can obtain from„ÄÇ

 let's sayÔºå the image data easily„ÄÇSo if you have that„ÄÇ

 if you have these features and also the labelsÔºå you can then train an algorithm„ÄÇ

 a machine learning algorithm to make predictions„ÄÇ So after yeah training the model„ÄÇ So in this step„ÄÇ

So we say trainingÔºå we can also say„ÄÇFitting„ÄÇüòîÔºåThe model or parameter raising„ÄÇ

The model depends on what a model we are talking about„ÄÇ Some models are non parametric models„ÄÇ

 so we don't really yeah update weight parameters in the model„ÄÇ So in that case„ÄÇ

 parameterizing would be not a good fit„ÄÇBut yeahÔºå these terms„ÄÇTraining„ÄÇ

 fitting and priorizing are kind of synonymous in the context of the deep learning„ÄÇNow„ÄÇ

 let's say we have our model that is our model that was learned from the data or parameterized based on the training data set„ÄÇ

 then yeah the goal is to make predictions on new flow because yeah the whole goal about developing the model is to use it in some prediction tasks So for example„ÄÇ

 if let's say you have a website you have developed the website where people can upload pictures of flowers and then your pipeline can predict what type of flow it is so„ÄÇ

You would have new flowersÔºå new images that would be a feature extraction step for these flowers„ÄÇ

 So here the feature extraction step is exactly the same as during training because your model has learned to work yeah with this data that it has seen during training so you have to have the same feature extraction steps here„ÄÇ

Then yeahÔºå you have your modelÔºå and then you can use it to yeah predict new labels„ÄÇ

 And this is nowadays called„ÄÇInferenceÔºå as shown here„ÄÇ So yeahÔºå inference„ÄÇ

 why inference is's a little bit different fromÔºå yeahÔºå statistical inference„ÄÇ It's„ÄÇ

 it just happens to be called inference„ÄÇ But yeahÔºå it's really like you can think of it as„ÄÇ

As prediction„ÄÇOn new data or something like that„ÄÇAll right„ÄÇ

So this is the typical superve learning workflow training a model and then using it„ÄÇ however„ÄÇ

 somewhere in this process we also want to evaluate how good our model is before we employ in the real world so how do we evaluate the performance of a model„ÄÇ

 So this is relatively similar to the inference step I have shown you in the previous slide„ÄÇ

 However we use a test set for that„ÄÇ

![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_3.png)

SoÔºå the test sent„ÄÇHere it looks like the training set„ÄÇ

 but it is usually independent from the training set„ÄÇ So if you have a large data set„ÄÇ

So let's say you have a large data set„ÄÇ What you usually do is you shuffle the data and then randomly divide it into a large portion for training„ÄÇ

 let's sayÔºå 70% and a smaller portion„ÄÇFor testingÔºå let's say 30%Ôºå usually theres a thought split„ÄÇ

Let me write this down„ÄÇ So this is training„ÄÇ but this is also only an approximate number„ÄÇ

A 30% for testing„ÄÇ you can maybe alsoÔºå it depends really on the data set size„ÄÇ

 We will talk more about thatÔºå but you can also just„ÄÇThis's a little bit smallerÔºå let's sayÔºå 20%„ÄÇ

And then make thisÔºå maybeÔºå I don't know„ÄÇ Let's sayÔºå let's keep it at 70%„ÄÇ And then there could be„ÄÇ

Third data set here„ÄÇThat's 10%„ÄÇAnd that is the validation set„ÄÇThat we use for tuning a model„ÄÇ

But yeahÔºå we will talk more about that later when we also see our first code examples„ÄÇ

 So for now consider this test set and this test set yeah looks very similar to the training set„ÄÇ

 We have observations and labels„ÄÇAnd now what we do though is„ÄÇSo we have this step here„ÄÇ

 which is like the inference step„ÄÇI showed you in the previous slide„ÄÇSo what's going on hereÔºü



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_5.png)

It's the same as I have here on the right sideÔºå the inference stepÔºå the same same step„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_7.png)

But yeahÔºå what we do now is we have„ÄÇThese known labels„ÄÇ

 So we separate from the tested observations and labels„ÄÇ We keep them separatelyÔºå so we„ÄÇ

Use our labels„ÄÇHereÔºå we withhold them from the model because there is no training right now„ÄÇ

 And then we use the observations as we treat them as new observations„ÄÇ We pretend they are new„ÄÇ

 so we„ÄÇPretend these unused labelsÔºå then we do our feature extraction step„ÄÇ

Give the data to the model„ÄÇ and the model makes the predictions„ÄÇ So we have nowÔºå yeah„ÄÇ

 two sets of labels„ÄÇ One are the known labels„ÄÇ We know them becauseÔºå yeah„ÄÇ

 we had them in the test set„ÄÇ They are sometimes also called„ÄÇOn ground„ÄÇTruth data„ÄÇ

 So that is also sometimes they are called ground truth data„ÄÇ

 And we compare these known labels to the predicted labels„ÄÇ And then we can„ÄÇ

 yeah count the number of times how often our model makes a correct prediction„ÄÇ And then we can„ÄÇ

 for exampleÔºå compute the accuracy„ÄÇ if we count the number of„ÄÇCorrect predictions over the number of„ÄÇ

Total„ÄÇData points in the tester that gives us the„ÄÇEcrey„ÄÇOn similarly„ÄÇ

 we can compute the error by one minus the accuracy„ÄÇ

 So it's like the basic yeah workflow of a supervised„ÄÇLearning model„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_9.png)

YeahÔºå regarding the data regarding the flowers so„ÄÇI also wanted to briefly discuss the difference between„ÄÇ

Structured and unstructured dataÔºå so„ÄÇStudents who have taken statistics 451Ôºå the introduction„ÄÇ

To machine learning„ÄÇIn this class we mainly worked with structured data„ÄÇ

 so in this class we won't be working with structured data except for some basic examples„ÄÇ

 so a structured data set is you can think of it as a tabular„ÄÇData set or a data set that„ÄÇ yeah„ÄÇ

 it looks like a table essentially„ÄÇ and this is something where yeah you have the data organized„ÄÇ

As follows by the„ÄÇColumns are your features„ÄÇAnd„ÄÇThe rose eye you are„ÄÇObservations„ÄÇ

So let me go back a step„ÄÇ So this is a table you may get„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_11.png)

During this feature extraction stepÔºå so this is something a human has to do or you can also automate it in certain points„ÄÇ

 but imagine the original data would look like an image so the original data is the flower so you can observe it either in the real world or you can take a picture of the flower and then as a human you can yeah use a ruler and then make the measurements about these petal and zipal„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_13.png)

LevesÔºå so Cal and pital are these leaves here„ÄÇAnd then you can measure how yeah„ÄÇ

 how long they are and how wide they are„ÄÇSo here I have a table of the Sepal lengthÔºå Sepal width„ÄÇ

 petal length and petal widthÔºå eitherÔºå yeah from an imageÔºå I mean„ÄÇ

 from image would be a little bit hard because it's not three dimensional„ÄÇ

 Well let's say an observation in the real world„ÄÇ So this could be then„ÄÇYour tabular data set here„ÄÇ

 These would be your four features„ÄÇ So you have„ÄÇFor features here on the right hand side„ÄÇ

 this is the the label that we want to predict included it here in the same table„ÄÇ

This would be an example of a structured dataset„ÄÇIn contrast„ÄÇAn unstructured data set would beÔºå yeah„ÄÇ

 the raw data„ÄÇ for exampleÔºå this image here„ÄÇ So this would be an unstructured data set„ÄÇ

 So let me write this down unstructured„ÄÇSometimes we also just call it the raw data„ÄÇ

So you can actually extract this structured data from the unstructured dataset„ÄÇ

 but yeah it's not always very simple because for example„ÄÇ

 sometimes you can automate it here it might be harder to automate it„ÄÇ

 you some have to have some human helping with that like maybe even taking the flower taking a ruler and making measurements„ÄÇ

Strucd data is something where we use„ÄÇTraditional„ÄÇMachine learning and unstructured data is something where we can use„ÄÇ

Deep learning„ÄÇBecause deep learning has internally a feature extraction step„ÄÇ

 it's implicitly doing feature extraction for us„ÄÇThe downside is of course we need much more data„ÄÇ

 for exampleÔºå hereÔºå this IRS data only has 150 flower examples„ÄÇ

 and this is sufficient for regular machine learning algorithms for traditional machine learning algorithms such as random forests„ÄÇ

 you can easily get something like a 99% accuracy with a random forest on this data„ÄÇ

 If you want to get 99% performance with deep learning on a flower„ÄÇSpecies prediction task„ÄÇ

 you would at least I would say there are some papers I can maybe link later„ÄÇ

 but I would say at least„ÄÇ10000 images of these lowest to get„ÄÇ let's sayÔºå within the 90% accuracy„ÄÇ

 So this is a three class„ÄÇPrediction problem„ÄÇ so it would be requiring much more data and not in every scenario you have such a large data set„ÄÇ

So I'm currently also working on a collaboration where we analyze videos„ÄÇ

 So we classify different videos„ÄÇ And yeahÔºå one limitation is that we only have a thousand videos„ÄÇ

 So the videos are actually from YouTube„ÄÇ But the problem is the labels„ÄÇ

 The labels is here but what's kind of costly because you would have to have a human„ÄÇ

Looking at these video videos to provide the labels„ÄÇ

 so it's not always possible to find people to watch long videos to provide these annotations that would be very intensive so sometimes you have to make the trade off okay I can use deep learning but I need a large dataset so if you have lot of labels available then it's feasible but sometimes you don't and then using a structured data is maybe not a bad idea„ÄÇ

Becauseuse it's simplerÔºå in a sense„ÄÇ

![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_15.png)

OkayÔºå so here's a nice also summary I found in this book„ÄÇ

 it's a nice cartoon illustrating the difference between the structured and unstructured workflow where you have traditional machine learning where there's deep learning so here on the left hand side„ÄÇ

This is the workflow for yeah for deep learning essentially where you have the data and then you throw it into the network„ÄÇ

 It's like a black box and then yeah the output is some prediction„ÄÇ

 So yeah if you get the reference here 42 if you know„ÄÇThe joke maybe post in piazza is's actually„ÄÇ

 I'm just curious how many people nowadays„ÄÇnow what the number 42 refers to it's kind of a insider joke„ÄÇ

 anyways„ÄÇ So yeah on the right hand sideÔºå this is yeah the traditional workflow where you have a human extracting the feature from the data„ÄÇ

 so you have these handcrafted features that you then provide to the machine learning system and then do the prediction„ÄÇ

 So it's essentially highlighting the difference between the unstructured„ÄÇAnd structured workflow„ÄÇ

OrDa sets„ÄÇSo the structure data would be this one here in the center where you have the handcrafted features„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_17.png)

YeahÔºå just to overlay it with the exampleÔºå I've just shown you with the flowers„ÄÇ

 So on the left hand side for the deep learning context„ÄÇ

 you would just give the model the raw images„ÄÇAnd the model will figure outÔºå yeah„ÄÇ

 what features to use„ÄÇ So it will learn certain feature extract us„ÄÇ

 We will talk more about this when we talk about convolutional„ÄÇNeer networks later„ÄÇ

They would implicitly learn how to extract features and in contrast„ÄÇ

 the machine learning workflow with a handcrafted features here on the right hand side where you have these handcrafted features such as taking these measurements here„ÄÇ

AlrightÔºå so yeah that is just a brief overview of the supervised learning workflow and how machine learning is different from deep learning Next I want to introduce some of the necessary notation and jargon and then I will also show you a little bit how what type of tools we are using in this class„ÄÇ



![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_19.png)

![](img/9bb1a86e7c4ebfe7bfa5aabdfff0d80b_20.png)