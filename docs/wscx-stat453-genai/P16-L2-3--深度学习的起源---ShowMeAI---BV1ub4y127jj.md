# P16ÔºöL2.3- Ê∑±Â∫¶Â≠¶‰π†ÁöÑËµ∑Ê∫ê - ShowMeAI - BV1ub4y127jj

Yeah now moving on from the multilayer networks like the multilayer perceptrons to deep learning so we are going to talk about the origins of deep learning in this video So coincidentally I just submitted a paper today with collaborators where we used multilayer perceptrons and we were debating whether we should call it deep learning or whether we should avoid the word The reason is deep learning is a relatively new word like that was invented„ÄÇ

 I would say like 1015 years ago„ÄÇBut multi layerer perceptrons have been around for at least like 3040 years„ÄÇ

 right like I talked about in the previous videoÔºå So is this really deep learning„ÄÇ So yeah„ÄÇ

 that is kind of debatable So technically when the term deep learning„ÄÇ

 yeah first occurred when it was first used what people referred to was the representation learning with advanced architectures with many layers„ÄÇ

 So having„ÄÇMultiple layers is not really what makes yeah„ÄÇ

 the difference between a multi layer perceptor and deep learning„ÄÇ

 It's more like the representation learning capabilities„ÄÇ that is usuallyÔºå yeahÔºå what deep learning„ÄÇ

Is all about„ÄÇ So nowadaysÔºå thoughÔºå if you read papers„ÄÇ

 newer papers where people use multilay perceptionceptronsÔºå they call them deep learning too„ÄÇ

 So I think nowadays it's okay to also call it deep learning to make it maybe less confusing for people because everything nowadays that is a neural network is also automatically deep learning„ÄÇ

 but let's dive a little bit more into the representation learning aspects that I just mentioned„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_1.png)

So that goes back to yeah also the approximately 1990s„ÄÇ

 So also in that way it's a thing that was discovered or invented before deep learning was a thing the word deep learning and it is convolutional neural networks So this is kind of on top of yeah the multilayer perceptrons it's like can think of it as a specialized version where you have locality so here it's about making training more efficient and also extracting local features which then better capture feature dependency So recall in multilayer perceptrons we had like the feature independence„ÄÇ

 so it would work with tabular data now with convolutional network we can leverage some prior knowledge of this relational inductive bias so it's specifically for image recognition for image data So how multilayer perceptron works is yeah you have these independent„ÄÇ

and features and the convolution network captures dependency„ÄÇ on the right hand side„ÄÇ

 I'm showing you this original line architecture from Yan Leon and Cos„ÄÇ

There was applied to hand written zip code recognition„ÄÇ

And we will have a dedicated lecture just to convolutional networks later„ÄÇ

 But here just a brief overview is that it consists of two parts„ÄÇ

 So there is one part that is the convolutional„ÄÇPartÔºå so here you have convolutional layers„ÄÇ

 They have a trick or a concept called weight sharing„ÄÇ And there is also pooling involved„ÄÇ

 And that makes theÔºå yeah train more efficient„ÄÇ We will discuss this in more detail later„ÄÇ

 But you can think of it roughly as„ÄÇNo„ÄÇFeture learning„ÄÇ

Layers where these layers are able to extract the abstract features from the data„ÄÇ

 and these features are then„ÄÇPassed on to„ÄÇFully connected„ÄÇSet of layers„ÄÇ

 So these are fully connected layers„ÄÇ And these are essentially a multi layer„ÄÇPerceptron„ÄÇ

And you can think of it as a classifier here„ÄÇSo if you think of it as a task„ÄÇ

 let me also use red here„ÄÇSo here we have this partÔºå the lower part here for feature learning„ÄÇ

 and this upper part is for„ÄÇClassifying the features that have been extracted by these earlier layers„ÄÇ

 So this is making the hand crafting of the features obsolete„ÄÇ NowÔºå the network learns the features„ÄÇ

 and it learns that in a way such that it is optimal for the classifier„ÄÇ

 because everything here is connected„ÄÇ So it's learning togetherÔºå which is one advantage that makes„ÄÇ

 yeah that makes neural networks for image data specifically very efficient„ÄÇSo this isÔºå again„ÄÇ

 this is from the 1990sÔºå back then the term deep learning didn't existÔºå but I would say nowadays„ÄÇ

 con neural networks are really like the most popular form of deep learning because there are„ÄÇ

 I meanÔºå manyÔºå many advances that followed this earlier architectures„ÄÇ

And made yeah deep learninging what it is nowadays„ÄÇ Of course„ÄÇ

 there is also a separate branch of recurrent neural networks that is also very popular in deep learninging„ÄÇ

 So recurrent neural networks also areÔºå I would say an advanced version of the multilayer perceptron„ÄÇ

 So here what's new is that there is a recurrence„ÄÇ So so you can think of this as a multilayer perceptron„ÄÇ

 but a multilayer perceptron is a feet forward network„ÄÇ Now you have this recurrence„ÄÇ

 So you are revisiting earlier things„ÄÇ So againÔºå this will be covered in way more detail in a dedicated lecture later on in this course„ÄÇ

 but the key idea is basically that we have a modified version of backproagation„ÄÇ

 which is called back propagation through time because there's a time component„ÄÇ

 and this is especially useful for„ÄÇ

![](img/35175ee54acba63d3413d749ca5256cb_3.png)

Sequence data where there's aÔºå yeah sequential dependency in the data among across the features„ÄÇSo„ÄÇ

 but the problem with that is nowÔºå when we train neural networks with many layers„ÄÇ

 especially if a recurrence over a long sequenceÔºå theres this problem of vanishing and exploding gradients„ÄÇ

 So that is like a big challenge„ÄÇ HoweverÔºå it was alsoÔºå I meanÔºå there are many„ÄÇ

Potential solutions to that„ÄÇ one of them that isÔºå yeah„ÄÇ

 one of the ones that is still commonly used is LSTMs that stands for longÔºå shorter term memory„ÄÇ

 So also this one was like overcome„ÄÇ And this is also one popular form of deep learning„ÄÇ

 like using these neural networks„ÄÇ But againÔºå this is something that has been around for a long time„ÄÇ

 ActuallyÔºå I don't know exactly when recurrent neural networks were invented first„ÄÇ

 it was like also in the 1980s sometime after„ÄÇBack propagation was invented becauseÔºå yeah„ÄÇ

 this is an advancement of back propagation„ÄÇ It was someone sometime in the 1980s„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_5.png)

YeahÔºå just to summarize what originally the term deep learning meant„ÄÇ

 he has a nice section or sentence from the deep learning review by Laon Benjo and Hinton So Hinton was the person working on the back propagation algorithm Lacooon was the one who came up with the convolal neural network and Benjo is yeah doing a lot of work also across deep learning„ÄÇ

 mainly also focusing on yeah the current neural networksÔºå but also basically everything„ÄÇ

 So in this review„ÄÇThe sentence goes like like this„ÄÇ

 representationpresentation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification„ÄÇ

 Deep learning methods are representation learning methods with multiple levels of representation can also say abstraction„ÄÇ

YeahÔºå and so here the focus is really like the implicit feature extraction that deep learning does„ÄÇ

 That is something that traditional machine learning is not capable of like we talked about last week„ÄÇ

 where we have the handcrafted features versus the automatic feature extraction„ÄÇ

 So here the focus is really on on the automatic part„ÄÇ

 But nowadays its really deep learning yeah means„ÄÇThe same as yeahÔºå using neural networks„ÄÇ

 So deep learning nowadays„ÄÇIt's really the same as using„ÄÇNurong„ÄÇüòîÔºåNetworks„ÄÇ

 maybe we should be a little bit more specific and say„ÄÇÁõÆÁöÑ„ÄÇüòî„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_7.png)

Laer„ÄÇYeahÔºå but going from these architectures I showed you that were invented in the 90s towards the modern era of deep learning research„ÄÇ

 There was unfortunately in between another AI winter in the late 1990s and early2 thousandss and I think that was probably due to the popularity of support vector machines and random forests because back then yeah neural networks were capable but they were very expensive to train so you needed like enormous computer hardware to train them efficiently and even then you had to wait a long time to train them„ÄÇ

 so they were not easy to train compared to let's say support vector machines and random forests of course support vector machines come with their own set of problems like the inefficiency of RBf cor machines on high dimensionmenional data Also random forests require a lot of trees so but still compared to deep neural networks„ÄÇ

 these were easier to train and worked quite well„ÄÇSo yeahÔºå but then at some point„ÄÇ

 people figured out how to use GPUus to make the training of neural networks more efficient„ÄÇ

 And that is really what helped yeah making neural networks really popular and feasible„ÄÇ

 So when I looked at literature what I could find it goes already back to 2004 So GPU implementations of neural networks have been around for quite some time„ÄÇ

 but really when it became popular was in 2012 where Khrushevsky Sutkiver and hintton worked on imagenet classification„ÄÇ

 the very common benchmark data like millions of images where they used yeah deep neural networks trained on GPUus to outperform traditional computer vision approaches„ÄÇ

 So a few more words about that in the next couple of slides„ÄÇ So yeah here's a table„ÄÇ

From my 2017 bookÔºå I actually updated this last year„ÄÇ so I don't know why I have the old one here„ÄÇ

 maybe I should swap it„ÄÇ but again the bottom line here is more that the difference between traditional CPU for example here in Intel CPU and an NviDdia graphics card or in general graphics card„ÄÇ

 maybe think of it as the difference between a CPU and a GP and GPus are particularly good at linear algebra operations like vector and matrix operations„ÄÇ

 So even though GPUus have a smaller clock frequency„ÄÇ

 one advantage is really like the parallel courseÔºå each core is slower than a CPU core of course„ÄÇ

 but you have more of them and that helps you parallelizing computation so„ÄÇParallel„ÄÇYeah„ÄÇ

 computing of dot products and„ÄÇMatrix modifications it's really what makes GPUus very useful for deep learning„ÄÇ

 So you really get a higher way higher memory bandwidth also so the GPU memory GPUus come with their own memory which is closer to where things are computed so it's also faster in that way if you have the data on the GPU however you have to get the data to the GPU which is sometimes a little bit slow So there are some tricks also to make this efficient in terms of data loading„ÄÇ

 but this is something we will talk about when we actually use Pytorch for deep learning I will also show you how you can use GPUus for this class you won't need a GPU I will later on talk about some free online resources where you can get one GPU for free which can help with some homeworks and also the project but yeah you don't need to buy your own GPU or something like that„ÄÇ

So yeahÔºå and moving on yeah„ÄÇ So really you can see the number of floating point calculation of float is yeah you can think of it as a decimal number in the computer„ÄÇ

 can see it has a way higher number of floating point calculations and it's also cheaper at least compared to this high end in CPU but of course they are also yeah things with GPUs that make certain things inconvenient because they have their own memory which is not very large„ÄÇ

 I mean there are nowadays more expensive cards that have larger memory„ÄÇ

 but usually indeed deep learning GPU memory the bottleneck at least for me„ÄÇ

 but again that is topic for another day„ÄÇ

![](img/35175ee54acba63d3413d749ca5256cb_9.png)

YesÔºå so here's another fun quote from the architects of InÔºå like an interview with Joe Finton„ÄÇ

So it is about when„ÄÇYesÔºå so regarding the questionÔºå when did deep learning become really popular„ÄÇ

 So here againÔºå is a fun quote from orqu excerpt from interview from the book Architects of Intelligence„ÄÇ

And yeahÔºå this refers to the 2012 Inet competition„ÄÇ

 So there was a famous computer vision competition on a dataset set called„ÄÇIage net„ÄÇ

 and it was essentially about a benchmark„ÄÇ and people submittedÔºå yeah„ÄÇ

 computer vision methods and papers„ÄÇ and it was about having the best system each year who could do the best classification on this image dataset set„ÄÇ

 It's like a yeah image dataset set consisting of up to 14 million images of they used only a subset of at that time as far as I remember„ÄÇ

 But yeah it was a millions of images„ÄÇ And„ÄÇBack then really the conferences were dominated by traditional computer vision approaches like manual feature engineering and so forth„ÄÇ

 no deep learning really And here in this interview and I't want to read everything here„ÄÇ

 maybe you can pause the video and read through it if you are curious but it is essentially about that deep learning methods were usually rejected so here is like something underlined the referees thought that it was the way way sorry the referees thought it was the wrong way to do things referring to the neural network architectures here So people really didn't like deep neural networks back then I mean people who were using traditional computer vision systems however„ÄÇ

Yeah the network that was submitted that year in 2012Ôºå the Alexnet„ÄÇ

 which was by Alex Khushevsky Sozscapeer and Jofinton„ÄÇ

 was really outperforming traditional computer vision methods by a large margin so they achieved a 15„ÄÇ

4% error in 2012 on top 5 classification I will in the next slide explain what top 5 accuracy or error means so forget about top5 for now so they achieved a 15„ÄÇ

4% classification error and the second best method only achieved 26„ÄÇ

2% error so their method was about twice as good as any traditional computer visionion system so by the way as a side note nowadays you can even get down to 3% error on imagenet so even like since 2012 things improved quite a lot„ÄÇ

ButÔºå yeah„ÄÇI just briefly here the last thing„ÄÇ So people were really surprised about how well deep learning worked„ÄÇ

 And then also like he saysÔºå within two yearsÔºå they all switched„ÄÇ

 So for things like object classificationÔºå nobody would dream of trying to do it without using neural network now„ÄÇ

 So this was really like 2012 was really like the breakthrough moment for deep learning because yeah it it performed really well on on image classification„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_11.png)

YeahÔºå and here's also just a quick overview of the benchmark dataset sets„ÄÇ

 Nowadays there are other even bigger data setsÔºå but these are still common data sets when you develop con networks or object classification methods„ÄÇ

 So there's the traditional Mnes data from 9098„ÄÇ60000 examples„ÄÇ

10 classes and very low resolution images„ÄÇ So these are the handwritten digits„ÄÇ

 So this is still a great dataset set for debugging on your network„ÄÇ

 It's like when you want to yeah try a network get the code written and see whether it works because it's really fast to train a network on that in practice if you write a conference paper testing your method on Mnes may not be enough anymore„ÄÇ

 but yeah it's still a good way to start more I would say advanced data is Cypher 10 and Cpher 100 So there are 60000 examples of either 10 classes which is for Cypher 10 or 100 classes in cpher 100 again„ÄÇ

 very low resolution 32 by 32 now though we have color images so we have three color channels and yeah we have different object here to classify„ÄÇ

 there's usually only one object in each image„ÄÇA more challenging dataset set is the imagenet dataset set„ÄÇ

 which consists of 14 million images„ÄÇ So they have full resolution„ÄÇ

 and but what is a little bit yeah more challenging about that too is that there can be multiple objects in an image I talked about in the stuff in the news section where people were relabelling imagenet„ÄÇ

 But yeah so what can happen is that there could be multiple objects sometimes So or it can be kind of ambuous„ÄÇ

 So usually what people do is they measure the top five accuracy or error„ÄÇ So for example„ÄÇ

When you have predictionÔºå you check„ÄÇWhether it's so whether your top five labels are matching with the image label because a network is strained you to return a probability or a confidence score for each possible class and then you look at the top five most confident labels and you look whether one of the five labels matches with a label in the image for example„ÄÇ

 it's a little bit smallÔºå I can't really read this hereÔºåYeahÔºå let me see„ÄÇ but let me pick an example„ÄÇ

 So hereÔºå for exampleÔºå we have actually also two things„ÄÇ We have a cherry and a dock„ÄÇ

 So it's also you can see this is like a challenging example where your network may predict a dock„ÄÇ

 but since the data point here is labeled with cherry„ÄÇ

 it would actually count as an arrow which is kind of unfortunate„ÄÇ

 So you would look whether yeah your prediction is kind of within a top 5 or here in this case„ÄÇ

 your algorithm may predict car or grill like the grill of a car both would be correct right So in that way you look whether a grill is under your top5 for example„ÄÇ

 So in that wayÔºå it's a little bit harder to evaluate on imagenet compared to Cypher 10„ÄÇ

 I think in Cypher 10 it's a little bit more obviousÔºå not not more that more obvious„ÄÇ

 but here you have classes where it's at least a little bit less ambiguous„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_13.png)

AlrightÔºå but yeah moving onÔºå I don't want to make this brief overview lecture like too long because we will dive into these little concepts in way more detail later throughout this course„ÄÇ

 So like a last thing here of course there have been many advances since 2012„ÄÇ

 So okay this is 2010 but for example advances that are making deep neural networks work way better so common ones are popular ones are re units rectified linear units which are activation functions very simple but very effective batch normalization dropout adversy networks and these are all covered in this course and many more so there have been a lot of advances also in the last decade and these are already like six„ÄÇ

7 years old and so there are way more of these and they are all contributing together to make deep learning work better„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_15.png)

So in the next videoÔºå I want to briefly just very briefly talk a little about hardware and software landscape„ÄÇ

 what has changed in the few last few years and then„ÄÇ

Briefly going over some current research trends and then really wrapping up yeah„ÄÇ

 these series of videos here for lecture 2Ôºå and then that we can go into our yeah more detailed lesson on perceptrons„ÄÇ



![](img/35175ee54acba63d3413d749ca5256cb_17.png)