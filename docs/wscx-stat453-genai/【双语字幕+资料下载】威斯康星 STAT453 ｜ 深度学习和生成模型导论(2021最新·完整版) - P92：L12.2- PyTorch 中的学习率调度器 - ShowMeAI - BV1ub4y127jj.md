# P92ï¼šL12.2- PyTorch ä¸­çš„å­¦ä¹ çŽ‡è°ƒåº¦å™¨ - ShowMeAI - BV1ub4y127jj

Yesï¼Œ in the previous video we discussed what learning rate decay is and why it might be usefulã€‚

 Let's now see how we can do this in practice in Pytorchã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_1.png)

So firstï¼Œ the manual wayï¼Œ the tedious wayï¼Œ we can define our own function to do learning rate decay in pyrã€‚

 So here I defined a function called adjust learning rateã€‚

 and this is implementing the exponential decay that we talked about in the last video So what it is doing is it's every 10th epoch So this line may read a little bit counter intuitivetuitively becauseã€‚

This modulus operator is essentially doing a division and then returning the remainder of that division soã€‚

If I have a number that is not divisible by 10ï¼Œ it will return the remainderã€‚

And here it's essentially saying if there' is no remainderï¼Œ then do thisã€‚

 So it's essentially doing something every 10 epochsã€‚So if the number is divisible by 10ï¼Œ do thisã€‚

 And what I'm doing here is I'm essentially implementing togetherã€‚Exponential decayã€‚

 And I'm applying it to the learning rateï¼Œ soã€‚I implemented this in a way here that looks a little bit complicatedã€‚

 that is because there are different optimizers and some optimizers have yet different learning rates for different parameter groups and so forthã€‚

 so this will essentially take care of updating all the learning rates that are relevantã€‚Alrightã€‚

 so this would be the tedious wayã€‚ And then you can call this function after every epochã€‚

 So if you have a follow so far epochã€‚Inã€‚Ringeã€‚Apoch or something like thatã€‚And then for eachã€‚

 I'm not writing it allï¼Œ but for each mini batchï¼Œ essentiallyã€‚

Then you do your training and you would have this functionã€‚For each epochï¼Œ but not for each miniã€‚

 So would you would put itã€‚Essentiallyï¼Œ hereï¼Œ like come adjustã€‚Learning rate and so forthã€‚

 I can't write down here because I have my color bar hereã€‚

 but you would put essentially the the function here adjust learning rate with the optimizers inputã€‚

 the epoch numberï¼Œ the initial learning rate and the decay rate and then it will update every 10th epochã€‚

 Howeverï¼Œ this is just the the manual wayã€‚ So you can see how you could implement it yourselfã€‚

 if you have an idea for a new learning rateã€‚ But in practiceï¼Œ if you want to just use an existingã€‚

Common way of doing learning grade decayã€‚ You can use one of the build in functions in Pythtorchã€‚

 So for thatï¼Œ I recommend going to this websiteã€‚ They have a selection of differentã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_3.png)

Learning rate schedulers here' is just an exampleã€‚ that is a very generic oneã€‚

 So here I chose a screenshot of this particular example because it came with a practical exampleã€‚

 so I didn't have to retype itã€‚So how this works is essentially that you initialize the schedulerã€‚

 So here it's this a Lada learning rate schedulerã€‚ you give it the optimizer and then these valuesã€‚

And then you iterate over the epochs and then for each epoch you call this dot step essentiallyã€‚

 and then you have your train function and radiation function that we usually use in this class tooã€‚

 So essentially you there are two steps only one step is initializing itã€‚

 and the second step is yeah essentially using it and that's itã€‚

And you can do that with any type of scheduler they have on that websiteã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_5.png)

So here I'm showing you now how that works with the exponential learning grade scheduleã€‚

So here I have first an initialization of a modelã€‚Then I initialize my optimizer hereã€‚

 I'm using a stochastic gradient decent optimizerï¼Œ and then I'm initializing my schedulerã€‚ So hereã€‚

 notice I'm giving itã€‚The optimizer as inputã€‚

![](img/16a73732b5dc404fdee7ea2860473d02_7.png)

And then I have my main training loopã€‚ So 5 epochs set my model into training modeã€‚

 and then I iterate over the mini batchesã€‚ And this is ourã€‚Typlicical model trainingï¼Œ soã€‚

We call the modelï¼Œ compute the lossï¼Œ set the gradients to 0ï¼Œ do back propagationã€‚

Yeah do the gradient So here this is the applying the gradientã€‚ So backwardã€‚

 we'll compute the gradients here we are doing the gradient updateã€‚ Here's some loggingã€‚

 And then notice after the epoch that's where we call the scheduler stepã€‚

 but you can also actually put it up here if you want toã€‚ so it doesn't really matterã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_9.png)

Alrightï¼Œ let's now talk about my favorite way of learning rate decay so I'm not using learning rate decay that often because I usually find that Adam an optimizer that we will be discussing later works pretty well out of the box but yeah sometimes I compare it to SGD and learning rate decay and I find it actually yeah this method works actually best compared to other methods I've tried and yeah I got this from a paper in 2016 on deep residual learning which is the paper that originally proposed the Renet which we will be talking about also yeah next week it's among the most popular convolutional in your networks hereã€‚

But yeah here I'm not sure if they proposed this learning rate decay method for the first timeã€‚

 but yeah that's at least I got the inspiration for that So what they do is they use regular SGD with a mini batch size of 256 and then they start with a learning rate of 0ã€‚

1 which is actually quite large for SGD but yeah they start with 0ã€‚

1 and then divide by 10 every time then when the error plateaus so essentially if they do the training and notice that the loss doesn't further go down I mean of course there's some wiggle room soã€‚

If it staysï¼Œ let's sayï¼Œ within a certain marginï¼Œ then they divide the learning rate by 10ã€‚So yeahã€‚

 that's the whole trickã€‚ And they also actually useã€‚Weight decay of 0ã€‚0001ã€‚

 So weight decay we discussed this in the previous lecture that's essentially L2 regularization and they use a momentum of 0ã€‚

9 and momentum I will explain in the next videoã€‚

![](img/16a73732b5dc404fdee7ea2860473d02_11.png)

But let me show you how this works in practice in Pythtorchï¼Œ so I prepared a code exampleã€‚

 so I put it here as scheduler I as an iyth or Jupiter notebook and I will share that on the repository like always so I will include a linkã€‚

Another videoã€‚ And yeahï¼Œ so what I'm doing here is I'm initializing the multi layer perception from last week where we used batch norm and dropout and I'm now using a S GD with a learning rate of 0ã€‚

1ã€‚ And here this is theã€‚Learning rate scheduler from Pyrage that can be used similar to what they proposed on in the previous slideã€‚

 where they have basically theã€‚

![](img/16a73732b5dc404fdee7ea2860473d02_13.png)

Monitoring of the plateauing error and the divide by 10 every time the error plateauusã€‚

 So this is essentially this learning rate scheduler hereï¼Œ soã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_15.png)

I am providing it with the optimizer and the factor is essentially by how much we divide itï¼Œ so 0ã€‚

1 means times 0ã€‚1 and times 0ã€‚1 is essentially dividing by 10 like they described in the paperã€‚

 but yeah you can of course change that it's another hyperparmeterã€‚Then theres a modeã€‚

 So the mode it really depends on where or what you apply this toã€‚

 So you can apply this to anything you like during trainingï¼Œ soã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_17.png)

Hereï¼Œ they sayã€‚Erorï¼Œ it's not quite clear what they mean by errorã€‚

 It could be either the loss or the classification errorã€‚ personallyallyï¼Œ I tried different thingsã€‚

 and I find it usually works best if I do this on the error on the validation set or accuracy on the validation setã€‚

 so I usually like to work with accuracy instead of error because I don't know it's more positiveã€‚

 It sounds better like having a high accuracy sounds better than having a low error for some reason I don't know I like accuracyã€‚

 It's maybe also because in the context of psychic learnã€‚

 everything is an accuracy and I really like psychic learnã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_19.png)

It's for those who haven't taken 451ï¼Œ it's a package for traditional machine learningã€‚

 which has a very nice API anyways soã€‚Here I have a modified version of my train model function that we used in previous lecturesã€‚

 I will show you the relevant parts in the next slideã€‚Andã€‚ðŸ˜”ï¼ŒI'm applying this reduce L orã€‚

L R on plateau method scheduler to the validation set accuracy andã€‚Essentiallyã€‚

 I'm saying I want to maximize the validation at accuracyã€‚ So every time it plateausã€‚

 I want to divide the learning rate by 10ã€‚ So I'mï¼Œ I'm saying maxï¼Œ because for accuracyã€‚

 the higher the betterã€‚ if I use the mini batchche lawsï¼Œ I would putã€‚Min hereã€‚Rightï¼Œ soã€‚Essentiallyã€‚

I tried it with many different thingsã€‚Training set lossï¼Œ that training set accuracyã€‚

 the validation set accuracyï¼Œ the validation set lossã€‚

 and from all my experience I find that using it with a validation accuracy happens for me at least to work bestã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_21.png)

Alrightï¼Œ so and here are the relevant parts from thisã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_23.png)

Ohã€‚

![](img/16a73732b5dc404fdee7ea2860473d02_25.png)

Train model functionã€‚ So here I zoomed inã€‚ againï¼Œ you can find it next to this notebook in the Github repositoryã€‚

 I will include the link at the bottomã€‚Andã€‚Yeahï¼Œ essentiallyï¼Œ we haveã€‚The loop over the epooxã€‚

 then the loop over the mini batches here Iã€‚Just left out all the code because it would be too long otherwiseã€‚

 And then I'm just saying if we use it schedule so this can is by default noneã€‚ but we canã€‚

 of courseï¼Œ like I showed on the previous slideã€‚Pviide here theã€‚Schedullerã€‚

 So if we have a scheduler and it's set to validation accuracyã€‚

 it will essentially just do this step based onã€‚The validation accuracy which we collect during training so I have a validation accuracy I keep track of during training I do this for logging purposes so I can do a plot later on and so here I do it on the latest validations set accuracy if it hasn't improved substantially compared to the previous iterations so I think it's for over three iterations then it will divide the learning rate by a factor of 10 but you can also setã€‚

A numberã€‚To includeï¼Œ likeï¼Œ how often doesï¼Œ does it have to stagnate before you divide by 10ã€‚

 So there are a lot of options that you may also want to chooseã€‚

 But I found just this works well for meã€‚

![](img/16a73732b5dc404fdee7ea2860473d02_27.png)

Yeahï¼Œ related to learning rate schedulers and optimize usã€‚

 I also wanted to say something about saving models in Pytchã€‚

 We haven't talked about saving models in Pytch yetã€‚ but yeahã€‚

 it's kind of an important topic right So if you train a modelã€‚

 let's say for a certain number of iterations and you want to use it another day for making predictions it's of course yeah important to save that model so you don't have to retrain it from scratch every time right but also sometimes you just want to train it longerã€‚

 let's say you train it for 100 epochs and you find the loss has not quite converged yet let me train it longer So instead of just rerunning the training from scratch you can in that case then just let's say lot your model from let's say a previous round and then continue running itã€‚

So saving a model in Pytrch is actually quite simpleï¼Œ so there are two ways of doing itã€‚

 but I will only show you the recommended way of doing itã€‚

 so the recommended way is using TorchSa on the model state dictionaryã€‚

 so the model state dictionary contains all the model settings and also all the model parametersã€‚

However then also if you use an optimizer that has a stateï¼Œ for exampleã€‚

 if you use SGD and change the learning rateï¼Œ the learning rate would be a state essentiallyã€‚

 so you can also save that so here you can do optimizer do state di and then it will also save that it will all be saved as I think they are actually pickle files but I'm actually not sure I think they could be Yal files I honestly forgot I just call them do P files pytorch filesã€‚

And yeahï¼Œ these contain the settings for your modelï¼Œ essentiallyã€‚

And then if you want to load your modelï¼Œ you can useã€‚Also you have to do into stepsã€‚

 you have to first initialize your modelã€‚Because here really you are onlyã€‚

 youre only saving the parameters of the modelï¼Œ like the weights and everything andã€‚

Here you can or here youï¼Œ for instanceï¼Œ initialize your modelã€‚

 It has to be the same model that you savedã€‚ And then what you do is youã€‚

Have like this load state dictã€‚ So it's easy to remember because this is called state dict hereã€‚

 And this is essentially just load state diã€‚ And thenï¼Œ but you have to do an inner torch load hereã€‚

 which is loading this pytorrch fileã€‚ So if you do thatï¼Œ it will load the modelã€‚Andã€‚ðŸ˜”ã€‚

It will essentially load the weightsã€‚ So in this static the weightsã€‚

 it will load the weights into that model hereã€‚And that's all there is to itï¼Œ essentiallyã€‚

If you have an optimizerï¼Œ thoughï¼Œ that you saved and you want to reuseã€‚

 you do the same thing here for the optimizerã€‚ For instanceï¼Œ you just initialize a blank optimizerã€‚

 Let's say S GD optimizer with a model parameters and thenã€‚You load the state tickã€‚

 so if you had used a learning rate scheduler that changed the learning rateã€‚

 it will then update the learning rate so you don't have to remember or check manuallyã€‚

And then yeah also for the schedulerï¼Œ if you use the exponentialã€‚Schedulularï¼Œ it willï¼Œ of courseã€‚

 yeah change over timeï¼Œ rightï¼Œ So in that wayã€‚You can alsoï¼Œ thenã€‚Yetã€‚

 Lordless scheduler with its parameterssã€‚Alrightï¼Œ so and that is essentially how you save and load models in Pythtorchã€‚



![](img/16a73732b5dc404fdee7ea2860473d02_29.png)