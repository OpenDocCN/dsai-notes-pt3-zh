# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P42ï¼šL6.0- PyTorch ä¸­çš„è‡ªåŠ¨å¾®åˆ†ã€è¯¾ç¨‹æ¦‚è¿°ã€‘ - ShowMeAI - BV1ub4y127jj

Yeahï¼Œ hiï¼Œ everyoneã€‚ I hope you had a nice weekendã€‚ So last weekã€‚

 we talked about gradient descent and topics and calculus to understand how we can compute the partial derivative of a loss function with respect to the weights of the model so that we can optimize the model to do good predictionsã€‚

 So this isï¼Œ I thinkï¼Œ still very important to understand from a bottom up perspectiveã€‚

 like understanding why we compute gradients and how we compute gradientsã€‚ Howeverï¼Œ in practiceã€‚

 especially when we work with these big neural networksã€‚

 It will be very tedious to implement these gradients by hand by deriving the loss function manually by let's say pen and paper and then coding it up in python Python code and things like thatã€‚

 So we will use pythwa actuallyã€‚ğŸ˜Šï¼ŒTo make our life easierã€‚ So in Pytorarchã€‚

 there is a sub moduleule called Autogradï¼Œ which is a module for automatic differentiationã€‚

 And as the name automatic impliesï¼Œ it will automatically derive the loss function with respect to the weights for usã€‚

 So in that wayï¼Œ we don't have to worry about it ourselvesã€‚ And in this lectureã€‚

 I will show you essentially how this worksã€‚ And we will be then also using it later in this courseã€‚

 when we work with more complicated networks like convol networks or recurrent neural networksã€‚

 So with thatï¼Œ let us get started thenã€‚Yeahï¼Œ like I mentionedã€‚

 the focus of today's lecture will be on computing partial derivatives more easily and automatically using Pytorchã€‚



![](img/55a51dbe162cad4fead61affda2ad39b_1.png)

And I structured this lecture into five partsï¼Œ so the first part will be really just on yeah Pytor resources so where you can find information about Pythtor and more reading material if you need itã€‚

 where you can find useful tutorialsã€‚ So in addition to this classã€‚

 I think this is just also useful for you to know where to find more information and keep up to date with yeah the Pytorch development in terms of new version releases and so forthã€‚

So then I will introduce the concept of computation graphsã€‚

 so this is basically how we think of a series of computations in the computer like this yeah computation graph that we can use to visualize a computation like a prediction in a neural network and then using the analogy or the concept of a computation graph I will explain how automatic differentiation works in Pytorchã€‚

 so Pytch is under the hood building such a computation graph and then based on this computation graph it backts the computation to compute the gradientsã€‚

We will then see how that applies to Adeline so last lecture we trained the Adeline manually so we computed the derivatives by hand in lecture slides and then I showed you a code implementation of that so today we will see how we can do this automatically using Pytorch so in Pytorch there is a so-called backward function which can do things automatically that we have done tediously by hand last weekã€‚

And yeahï¼Œ lastlyï¼Œ I want to end this lecture today by taking a closer look at the Pytorch APIã€‚

 So there are two main subapisï¼Œ object oriented and a functional API which are both usefulã€‚

 So I will also yeah explain to you how the API works in a bigger picture sense and we will be using these concepts than later when we talk about implementing yeah multilayer new networksã€‚

 So with that I think this lecture maybe one of the longer once againã€‚

 So it could be that is a little bit above the 75 minutesã€‚ Howeverã€‚

 on Thursday there will be a shorter lecture where I will go over just optional concepts like how we can run code on the GPU using free cloud resourcesã€‚

 So Thursday lecture will be I think relatively short or more like optional So you will have also plenty of time to catch up this week if this lecture ends up a little bit longer but with that let me not yeah spend too much time here and get started with part1ã€‚



![](img/55a51dbe162cad4fead61affda2ad39b_3.png)

Pytage resourcesã€‚