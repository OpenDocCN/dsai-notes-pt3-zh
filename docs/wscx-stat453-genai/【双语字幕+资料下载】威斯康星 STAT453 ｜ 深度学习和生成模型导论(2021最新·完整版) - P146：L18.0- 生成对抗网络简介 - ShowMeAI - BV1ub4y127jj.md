# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P146ï¼šL18.0- ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç®€ä»‹ - ShowMeAI - BV1ub4y127jj

Yeahï¼Œ hiï¼Œ everyoneã€‚ Todayï¼Œ we have a pretty exciting topicï¼Œ generative adversarial networksã€‚

 even if you have maybe not had any background in deep learning before you took this classã€‚

 I'm pretty sure you probably heard about generative adversarial networksã€‚

 They are a very popular model in deep learningã€‚ and they are essentially used for generating new dataã€‚

 Nowadaysï¼Œ there are hundredsï¼Œ if not thousands of different generative adversarial networks around thereã€‚

 but yeahï¼Œ we have to start somewhereã€‚ So we are starting with the introduction discussing the original GNã€‚

 and then also implementing a deep convolutional G GNsï¼Œ like I saidï¼Œ a pretty exciting topicã€‚

 but I find they are also notoriously hard to trainã€‚

 So we will also look at some tips and tricks for training GNsã€‚ And with thatï¼Œ yeahã€‚

's let's get startedã€‚ğŸ˜Šï¼ŒYeahï¼Œ so in this lecture we are mainly going to focus on the traditional generative adversarial networks approach which was published back in 2014 by Goodfe and alumni and yeah it became really popular around 2016 I would say when there was a famous Europe's workshop where near the generative adversarial networks were discussed and presented extensively so since then there have been literally hundreds if not thousands of different generative adversarial networks so there was actually a GiHub repository listing different types of generative adversarial networks and back then like three years ago there were approximately 150 different types of generative adversarial networksã€‚

And yeah it was not updated since thenï¼Œ unfortunatelyã€‚

 but I bet there are nowadays probably up to1 thousand different generative adversary networksã€‚

 but yeah we have to start somewhere and today we are going to focus on the original GNã€‚

 the original generative adversary networks modelã€‚And alsoï¼Œ I will show you a flavor of that laterã€‚

 which is called Dganã€‚ So Dgan stands for deepã€‚Convolutionalã€‚Againï¼Œ so the originalï¼Œ againã€‚

 the original generative adversary networks here was implemented with fully connected layers andã€‚

Approximately a year later or so there was an implementation with convolutional layersã€‚

 So it was called DCcgan nowadays when you hear the wordganã€‚

 it usually implies that there are convolutions to be used So when people say again usually most of the time people actually mean a type of D G Allright so but to give you some ideas of what we can do with GNs before I give you the lecture overview So here's like a fun overview of different applications of G like these are more like joke or fun applications So there are these different websitesã€‚



![](img/7d0d7bf31be16f6a7c2f950f1753f901_1.png)

For exampleï¼Œ this cat does not exist and every time you refresh the websiteã€‚

 you will see a new cat and this cat is yeah generated by adversarial networksã€‚

 generative adversarial networksï¼Œ and they don't exist in real lifeã€‚

 These are generated cats as of courseï¼Œ also one for face imagesã€‚ This person does not existã€‚

Theres also a fun oneã€‚ this pony does not exist and then there's also a recent oneã€‚

 this startup does not existã€‚ So these are all yeah fun applications of GNsã€‚ but of courseï¼Œ yeahã€‚

 there are manyï¼Œ many different things you can do with GNs in this lecture we will focus on the fundamentals and we will see an exampleã€‚

For handwritten digits and also face imagesã€‚I must say personally thoughã€‚

 working with GANs can be both fun but also veryï¼Œ veryï¼Œ very frustratingã€‚ personallyã€‚

 I think GANs are among the trickiest things in deep learning to train because you will see there are now two neural networks that we have to train and we have to make sure they really well tuned with respect to each other So before we had to tune only one networkã€‚

 now we have to tune two networks and they have to be tuned in context to each otherã€‚

 So it's actually really hard personally I think to train a G model but I will also show you some tips for that So the lecture overview for today is as followsã€‚

 I will first give you the big picture behind GNs then we will talk a little bit about the objective So the loss functionã€‚



![](img/7d0d7bf31be16f6a7c2f950f1753f901_3.png)

Like it was presented in the original paper and then we will talk about a little modification that makes it a little bit more practical so when we are training it regarding the gradientsã€‚

And then I will show you an example how we canï¼Œ yeah train on neural network or fully connected G for hand of written digitsã€‚

And then I will go over some tips and tricks for yeahï¼Œ makinggans work becauseganNs are reallyã€‚

 really trickyã€‚ And even with these tricks and tipsï¼Œ it's still hard to traingansã€‚

And then I will show you a DC C G for generating face imagesã€‚

 which I spent a lot of hours on because yeahï¼Œ like I saidï¼Œ GNs can be fun but also trickyã€‚

 So these are our topics for todayï¼Œ starting in the next video with the main ideaã€‚



![](img/7d0d7bf31be16f6a7c2f950f1753f901_5.png)