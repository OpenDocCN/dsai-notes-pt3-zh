# P89ï¼šæ·±åº¦å­¦ä¹ æ–°é—» #7 2021å¹´3æœˆ13æ—¥ - ShowMeAI - BV1ub4y127jj

Yeahï¼Œ hi everyoneã€‚ againï¼Œ lots of exciting things to talk about todayã€‚

 So you may have noticed in the past that I have been covering a lot of these big projects from companies like Facebook AI research and Google AI researchã€‚

 I wanted to emphasize I'm not affiliated with any of these companies or projectsã€‚

 It's just like these are big projects and are very catchy and also that makes them sometimes very interestingã€‚

 which is why I kind of try to keep up with what other people are doingã€‚

 and these are usually the ones that kind of stick outã€‚

 but I will also try in the upcoming weeks to be more selective or also let's say more diverse in terms of covering both little and big projects that are interestingã€‚

 So today I don't have a particular theme I just selected some things that came to mind that I stumbled uponã€‚

 So little projectsï¼Œ big projects a little bit of bothã€‚

 So because there are lots of things to talk about todayã€‚

 let me not waste too much time on this introduction and get startedã€‚Yesã€‚

 so the first project I want to talk about today is this text box G I saw on GitHub this week as far as I am concerned and as far as the author is concernedã€‚

 this is also the first application of a G to generating new text boxes so here are oops here are some examples of how they might look like so why are we interested in that Well maybe you can use that to design a new poster or something like thatã€‚

 but essentially I think it's just like a nice and simple application of a G for generating some new dataã€‚

So later in this courseï¼Œ we will also be talking aboutï¼Œ yeahï¼Œ Gs in more detailã€‚

 So here it's just like an example of how a G might look likeã€‚ And alsoã€‚

 the S repository contains a really nice description of how this worksã€‚ And it's reallyï¼Œ yeahã€‚

 just a nice example project hereã€‚ So what is going on hereã€‚

 Maybe just to briefly walk you through thisã€‚So againã€‚

 usually consists of two parts there as a generator and a discriminatorã€‚

 So the generator is essentially trying to generate new dataã€‚

That mimics the data in the training setã€‚ and the discriinator is the task of the discriinator is to tell apart whether the generator yeah generated fake dataã€‚

 like data that is different from the training set distribution or data that is similar to the training set distributionã€‚

 So essentiallyï¼Œ the generator will learn or tries to learn to fool the discriinator such that the discriinator cannot distinguish betweenã€‚

Genrated and real imagesã€‚ And in that senseï¼Œ you can think of the generator as learning the training dataset set distributionã€‚

Soã€‚Hereï¼Œ there is like a slight modificationã€‚ I meanï¼Œ a again is usually a little bit simplerã€‚

 So hereï¼Œ in addition to thatã€‚ So there are two things going onã€‚

 a normal G usually gets some noises inputã€‚ So the noise gets encode is basically an a vector that goes into the network and the network then generates the new dataã€‚

 So why the noiseï¼Œ it's such that otherwiseï¼Œ I meanï¼Œ you need the noise otherwiseã€‚

 the generator will always produce the same outputï¼Œ rightï¼Œ If you think of it as a functionã€‚

 So that wayï¼Œ the noise is such that it will create different outputsã€‚And hereï¼Œ in addition to thatã€‚

 there is also the word encoderï¼Œ which takes as input a wordã€‚

 So this word will be then included in this output imageã€‚Soï¼Œ and yeahã€‚

 to ensure that this word is indeed included in this output imageï¼Œ there is also this O CR moduleã€‚

 which will judge whetherï¼Œ yeahï¼Œ this text here resembles the text that was put inã€‚Soï¼Œ yeahã€‚

 this is also why you can't use this module here for generatingã€‚

 let's say image capchas because then like these capchas that I used for verifying whether you are human when you log into a websiteã€‚

 I meanï¼Œ hereï¼Œ this wouldn't be useful because I would say it's too easy to solve because the OR is able to tell which word it is rightã€‚

 So in that wayï¼Œ you can simply design a robot to full but to fool this capturecha and generatorã€‚

 But yeahï¼Œ anywaysã€‚This is actually a quite yeah useful technique to just add an additional constraint hereã€‚

 For instanceï¼Œ a couple of years agoï¼Œ we also yeah worked on face privacyã€‚

 where we wanted to hide certain phase attributesã€‚ And we also an a project calledã€‚Privacyã€‚

Pririv sceneã€‚Pivacyã€‚Net we also designed again that yeah hides face information while still maintaining face matching accuracy or the same face matching accuracy So that generated images are still useful in practiceã€‚

 But then so the goal was essentially to having face images still being useful for let's say passport verification purposesã€‚

 but then if someone captures images on a security cameraã€‚

 it should the person shouldn't be able to do some data mining on let's say the gender of the person and so forthã€‚

 So here then we use face matching in a similar mannerã€‚ Anywaysï¼Œ so hereã€‚

 then the discriminator judges whether yeahï¼Œ the generated images fake or notã€‚

 and essentially this whole network will then learn how to generate new text boxesã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_1.png)

Yeahï¼Œ so here's a slightly larger projectã€‚ I already wanted to cover it like one week agoã€‚

 but the episode was already too longã€‚ So I moved it into this week's episodeã€‚

 But I think that is something worth talking about onã€‚So this is like a largeï¼Œ really large modelã€‚

 It's called M6ï¼Œ a Chinese multimodal pretrainerã€‚ And this was a collaboration between Alibaba and the Jinhua Universityã€‚

 So here what they did is they trainedï¼Œ I think they used the megaron from NviDdiaï¼Œ They trained 1ã€‚

9 ters of images or they trained on 1ã€‚9ter of images andã€‚292 GB of textã€‚

 So it's a really large effort hereã€‚ And what's yeahã€‚

 essentially new and interesting here is that it is in Chinese and not Englishã€‚

 So it's kind of interesting to see that these language models also perform pretty well on other languages that are not English languages because in Chinese hereã€‚

 also you probably know this better than I doï¼Œ but you have all these different types of charactersã€‚

 So English textsï¼Œ I would say much simpler because you only have 24 characters hereã€‚

 That's a little bit more challengingã€‚ So it's kind of an interesting case study as wellï¼Œ I thinkã€‚

So they trained actually two models at 10ã€‚Billion and a 100 billion parametermeter transformerã€‚

And so this was done with yeah self-supvised pretrain and then the pretrain model can actually be used for many different tasks downstreamã€‚

 For instanceï¼Œ the model can be used for generating descriptionsã€‚

 doing image search for Q and A or poem generationï¼Œ and yeahï¼Œ manyï¼Œ many different thingsã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_3.png)

So Justin and Natchaï¼Œ I don't want to go into too much detailï¼Œ but how did they accomplish thatã€‚

 How can they use the model on so many different downstream tasksã€‚

 So essentially how they achieve that is by maskingã€‚ So they have the same modelã€‚

 They call it here unified encodeta decoderã€‚ I'm not an expert in these large language modelsã€‚

 but I think this is based on Nvidia megatron I've seen something similar beforeã€‚ in any caseã€‚

 so here they have like these different masking strategiesã€‚So for instanceã€‚

 when they want to use the model for text denoizingï¼Œ they would mask out all the gray parts hereã€‚

 which is the I Pã€‚ they call it I P and D Tã€‚Mostlyï¼Œ so but they maintain some dutiesã€‚ So what isã€‚IPã€‚

 Eï¼Œ Tï¼Œ and D Tã€‚ So I P are image patchesï¼Œ Eï¼Œ Tï¼Œ I encoder tokens andã€‚The DTR decoder tokensã€‚

 So encodeder isï¼Œ can think of it as the input tokensã€‚

 Let's say text input tokens and decoder are more like the output tokensã€‚So for text denoisingã€‚

 the model gets yeah decoder and encodeder tokens and let's say for language modelingã€‚

 there's only the decoder tokens and for image captioning they useï¼Œ of courseã€‚

 the image patches together with the decoder tokens and so forthã€‚

 So in this way based on the task they use different types of input so they have like this masking strategyã€‚

 So with that they are able to train one single model essentiallyã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_5.png)

Yetï¼Œ totally unrelated to the previous projectã€‚ I saw a very interesting project on archive this weekã€‚

 So this project essentially highlights how fragile deep learning can still be in practice and that we have to be a little bit careful about certain things when we are using itã€‚

ðŸ˜Šï¼ŒSo the project I'm talking about is actually not the project on this slideï¼Œ but on the next slideã€‚

 but it reminded me of this one that I saw about approximately almost a year agoã€‚So hereã€‚

 just to describe you what's going on hereã€‚ So here the authors try to fool Tesla's autopilot systemã€‚

 So if you haven't heard of Tesla's autopilotï¼Œ it's essentially a self driving car program inside the Tesla carã€‚

 which canã€‚To some extentï¼Œ automatically control the Tesla car like steering it on the highwayã€‚

 I don't have a Teslaã€‚ I only vaguely familiar with itï¼Œ but based on what I hear from peopleã€‚

 it's it's somewhat okayï¼Œ but it'sï¼Œ of courseï¼Œ not something that you want to blindly rely onã€‚

 And this paper also highlights some of the issues of that systemã€‚

 I'm not sure if this is already fixedï¼Œ butã€‚In any caseï¼Œ So what's going on here is that the authorsã€‚

 yeahï¼Œ they try to fool the autopilot systemã€‚ So what they did is they projectedï¼Œ let's sayã€‚

 street signs into treesã€‚ and that yeah was essentially fooling the system thinking that this is actually a real street signã€‚

 And you can think ifï¼Œ I meanï¼Œ of a real world application if there's some malicious actorã€‚

 they could maybe essentially project certain things and then cause crashes and stuff like thatã€‚

 or hereï¼Œ for instanceï¼Œ they projected a silhouette of Elon Musk onto the streetã€‚

And the car was then thinking there's a person on the street and was breaking pretty hard and things like thatã€‚

Soï¼Œ yeahï¼Œ what I saw in an archive was essentially an update of thatã€‚

 or I think these are different authorsï¼Œ rightã€‚

![](img/e03a4dc809a337167ac8b7e9e1635992_7.png)

Yeahï¼Œ but it was essentially a pretty interesting project where they did something similar with laser beamsã€‚

 So here they essentiallyã€‚Projected laser beams into the imageã€‚ And by thatã€‚

 they could also fool the cars essentiallyã€‚ So I thinkã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_9.png)

This one here definitely takes more effortã€‚ if youï¼Œ let's sayï¼Œ a malicious actor andã€‚Yeahã€‚

 you want toï¼Œ for some reasonï¼Œ fool the carã€‚ I think having something that can project a street signã€‚

 you need a projectorã€‚ essentiallyï¼Œ it's a little bit more effort to do thatã€‚

 but something like a laser beam having something like thatã€‚ that might be more concerning becauseã€‚

 yeahï¼Œ these laser beams they are moreï¼Œ I would sayï¼Œ easier to carry around and things like thatã€‚

 So yeahï¼Œ that essentially highlights are still a long way to go for making self drivingiv cars safeã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_11.png)

![](img/e03a4dc809a337167ac8b7e9e1635992_12.png)

Yeahï¼Œ related to the topic of safetyï¼Œ there's also another important topicï¼Œ fairnessã€‚

 So how do we design fair machine learning and deep learning systemsï¼Ÿ Yeahã€‚

 Facebook had a blog post on that topic this week called on the ground applying algorithmgic fairness approaches to complex production systemsã€‚

 and yeah in this blog postï¼Œ there was also a link to a research paperã€‚

 it's a very a relatively long paperï¼Œ but yeah a recommended read I think it's an important topicã€‚

 So in this paper they outline yeahï¼Œ the challenges and approaches they take to making machine learning and deep learning fairã€‚

So it's actually a pretty tricky problem that they have thereã€‚ So I'm not an expert in this areaã€‚

 but it seems like it's yeah it's not so easy to solveã€‚ but yeahã€‚

 one thing I wanted to highlight from that is regarding label fairness because in practice we usually assume that the labels that we have for a given data that they are correct or that they are the definite ground truth labelsã€‚

 but yeah in a real worldï¼Œ it's not always so obvious or not always so clear whether these labels are correct or whether we should take them literally or whether we should take them with a grain of saltã€‚

So for instanceï¼Œ as they say hereï¼Œ things like when you haveã€‚

Websites so you can perfectly measure whether users click on a given buttonã€‚

 So if you want to measure or predict website clicksã€‚

 website clicks themselves are labels that are yeah pretty yeah I meanã€‚

 pretty confident or you are pretty sure if someone clicks on that you can measure this pretty confidently a click or not but other thingsã€‚

 for instanceï¼Œ if you deal with topics like identifying bullyingã€‚

 So the labels that you may use for thatã€‚They are usuallyï¼Œ for instanceã€‚

 generated by a human who is labeling certain postsï¼Œ whether they are related to bullying or notã€‚

 And because that's based on human judgmentï¼Œ it may also embed human biasesã€‚ So in certain casesã€‚

 yeahï¼Œ whether a label is correct or notã€‚ it'sï¼Œ it's reallyï¼Œ it's moreï¼Œ I would say subtleã€‚ it'sã€‚

 that's also a grey zone and things like that soã€‚Alsoï¼Œ like they say hereã€‚

 there's usually a policy written down to identify bullying and it's also important like to have a good policy for the label us to apply And then but different peopleã€‚

 yeah apply the policy maybe differently and there are like these implicit and explicit biases that label us haveã€‚

 So that way in certain in certain contexts it's actually not so simpleã€‚

 we cannot always believe that these labels are the definite ground truth so that kind of make certain topicsã€‚

Application for machine learning and deep learning a little more challenging than othersã€‚

But yeah related to that what I wanted to mention for your class projectã€‚

 what might be also an interesting thing to do is to take a sample of your datasetã€‚

 So if you are working on a classification problemã€‚

 let's say you have a data set of 100 images or let's sayï¼Œ let's say 100000 imagesï¼Œ sorryï¼Œ takeã€‚

 let's say 100 images and then look at these 100 images andã€‚Without looking at the labelsã€‚

 try to predict what class table it isï¼Œ and then you count the numbers of times you were correct and then divide that number by 100 and then you get a feeling for what the human accuracy is on that dataset or how the human predictions relate to the labels that are actually the ones contained in your dataset it gives you a feeling of the difficulty of the task too So for instance if you have the Mnes dataã€‚

 take maybe 100 Mnes digits and try to predict which number is is and let's see whether you get 100% accuracy or notã€‚

So it gives you also yeah an idea of whether the labels are even correct in the dataã€‚

 but also how difficult the task isã€‚

![](img/e03a4dc809a337167ac8b7e9e1635992_14.png)

Yesï¼Œ since we talked about improving generalization performance this week and we will continue to talk about this topic this weekã€‚

 there was an interesting research article on the understanding generalization in deep learning from the perspective of online and offline learningã€‚

 So the title of the article is good online learners are good offline generalizersã€‚

So here they had two scenariosï¼Œ a real world scenarioã€‚

 So the real world scenario is essentially what we have also always considered in classã€‚

 So we have given training set and we train a model on end training samples from that yeahã€‚Data setã€‚

 where we have mini batch stochastic gradient descentã€‚And we run that for multiple epochsã€‚

 So essentiallyï¼Œ this thing is just describing what we are doing when we are working with a training set where we haveã€‚

 yeahï¼Œ where we do stochastic gradient incent with mini batches and we repeat that for multiple epochsã€‚

But then they have another scenario they call that the ideal worldã€‚

 So here instead of yeah doing mini batch gradient in descent on the training setã€‚

 instead of having a fixed sized training set they have infinite data so they are drawing every time a new mini batchch from the distribution of new data so they have an infinite pool of new data and they don't have epochs because yeah the data never repeatsã€‚

 they always draw new dataã€‚And here what they are doing is they are comparing how the real world compares to the ideal worldã€‚

 So here this is essentially illustrating that we once we complete one epochï¼Œ we start from scratchã€‚

 I meanï¼Œ we do another round in another roundã€‚ So we reuse the same training set for training in an ideal worldã€‚

 we always move forward and have new samplesã€‚ What they found was pretty interestingï¼Œ actuallyã€‚

 that there is actually no difference whether we have the ideal world or the real world case in terms of the generalization performanceã€‚

 So both theã€‚Ideal world and a real world setting result in models that have the same performance on the test setã€‚

 So they have a test set where they measure the performance thenã€‚ And hereã€‚

 this is the number of iterationsã€‚So it's hard to seeï¼Œ but you can see there are two lines hereã€‚

 a red line and a blue lineï¼Œ and blue corresponds to the real world scenario and red to the ideal world and you can see there's virtually no differenceã€‚

So there's one caveatï¼Œ thoughï¼Œ with that studyã€‚ So one is how they generate or generated the new data for the ideal world scenarioã€‚

 So here they used the model to do thatã€‚ So they usedã€‚A model thatã€‚

Draw or constructed 6 million synthetic Cypher 10 like images by sampling from a certain generative modelã€‚

 And how did they then get the labels for thatï¼Œ They used another model that was used then to label these images hereã€‚

 they had an model with 98ã€‚5% accuracyã€‚ So yeahï¼Œ I meanï¼Œ this is an okay approach Because yeahï¼Œ wellã€‚

 where should you get all the data from otherwiseï¼Œ rightï¼Œ But yeahã€‚

 this is also a little caveat because these are not real imagesã€‚

 They are generated images that look like real images using a generative modelã€‚In caseã€‚

 it's still an interesting study Yeahï¼Œ and another or another little thing I want to mention is it's actually not the test set errorã€‚

 it's something called test soft errorï¼Œ so it's not a test accuracy but the soft errorã€‚

 I wasn't bit confused by thatã€‚ I haven't seen that beforeï¼Œ so they had a paragraph on thatã€‚

So here it's essentially what they call a soft accuracy of classifiers defined as a softm probability on the correct labelã€‚

 So instead of using the arc max on the softmã€‚Where in the softmax recall we have pro class membership probabilitiesã€‚

 they use the highest probability score in computer near the accuracy that way as a soft accuracyã€‚

 Honestlyï¼Œ I'm not exactly sure why they are doing thatã€‚

 why they are not reporting the regular tests at accuracyã€‚ but yeahã€‚

 that's that's an interesting point hereã€‚

![](img/e03a4dc809a337167ac8b7e9e1635992_16.png)

Yeahï¼Œ and to ensure that this observation was not just an artifactã€‚

 particular to this resonnet model that they usedï¼Œ they also tried it with different models and saw the same effectã€‚

Yeahï¼Œ one more visualization from that paperã€‚ so here they also looked at pre trainingã€‚

 so what they did is hereã€‚They had a model for the ideal and real world scenario and with and without pretrainã€‚

 So the one without pretrainï¼Œ this is like the random weight initialtization and pretrain is essentially pretrain hereã€‚

 the model on imagenet and then using the weights and training it further on that Cypher 10 dataset setã€‚

 So what they found here isã€‚If you look atï¼Œ so the dotted line is ideal worldã€‚

 in the real world is the solid lineã€‚ And in redï¼Œ that is the randomã€‚

 It's a little bit hard to read this graphï¼Œ to be honestï¼Œ or not hardã€‚

 but you have to think a little bit about itã€‚ So this is the randomã€‚In itï¼Œ and the blue ones areã€‚

Pre trainingã€‚And thenã€‚What you can see here is the dotted one isï¼Œ againï¼Œ the idealã€‚

And the solid one is the real worldã€‚ And you can see for the random initialization like we've seen beforeã€‚

 theres no difference really whether we use the real world or ideal world scenario and the same is true for the pretrain model there is also no but notã€‚

 not much differenceã€‚However what is interesting here though is yeah of course that pretraining really helps so this is the again test soft error and you can see that the pretrain model has an error that goes down muchã€‚

 muchï¼Œ much quicker than the one for the random tested so it highlights that pre-training a model on a larger data set first instead of doing a random weight initialertization its actually really good for getting good performance faster Also what's also interesting is that final performance is also a huge gap so it's not only training faster but it also results in a better model hereã€‚

Yeahï¼Œ and related to pretrainingã€‚ So there was another interesting project called SER Well CR stands for self-svisedã€‚

 So pretraining is essentially very similar to self-servised learning So self-svised learning is a form of pretraining in that senseã€‚

 So on the previous slide I showed you that they pretrained a model on imagenetã€‚

 but there they just used the labels that were contained in imagenet Sesupervised learning is basically yeahã€‚

 it's like pretrainingï¼Œ but you use the data set that is unlabeled and then you generate the labels for that based on some information on the dataã€‚

 for exampleï¼Œ you can mask certain things in an image or you can cluster the images and things like thatã€‚

So we talked a little bit about selfsvised learning beforeã€‚

 It's a little bit beyond the scope of this classã€‚ So I mentioned forï¼Œ yeahã€‚

 some class project feedbacks that it might be something interesting for you to look intoã€‚

 but you don't have toï¼Œ of courseï¼Œ because it would be more something more advancedã€‚ but in any caseã€‚

 this was an interesting projectã€‚ So what they did here is they trained a billion parametermeter model using self supervised learningã€‚

And they used enabled data from Instagramã€‚So doing thatã€‚

 they were able to reach a new state of the art performance for self supervis learningï¼Œ getting 84ã€‚

2% top1 accuracy on INeã€‚How did they do thatï¼Œ Yeahï¼Œ they usedã€‚Online clustering algorithmã€‚

 which is actually a pretty efficient oneã€‚ It's called Swfã€‚

 And this one doesn't rely on pairwise image comparisonsã€‚ But yeahï¼Œ againã€‚

 since this is a already very long blog postï¼Œ not blog post story videoã€‚

 I don't want to go into too much detailã€‚ I will probably end thisã€‚Weeks stuff in the news sectionã€‚

 There's only one more thing I wanted to mention in connection to this project hereã€‚

 There is another interestingã€‚

![](img/e03a4dc809a337167ac8b7e9e1635992_18.png)

A library or module I would call it library that came outã€‚

 It's for yeah selfsvised learning benchmarksã€‚ So it's a library for for state of the artã€‚

 selfsvised learningï¼Œ supporting Pythtor and it's essentially a library that provides benchmarks and pretrained models that you can compare with let's say your modelsã€‚

 So it's essentially a benchmark library that provides pretrained selfsvised modelsã€‚

 it's I think a nice thing if you are interested in selfsvised learningã€‚

 let's say for your class project an interesting thing to check outã€‚



![](img/e03a4dc809a337167ac8b7e9e1635992_20.png)