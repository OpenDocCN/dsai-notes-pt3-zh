# P12ï¼šæ·±åº¦å­¦ä¹ æ–°é—» #1ï¼Œ2021 å¹´ 1 æœˆ 27 æ—¥ - ShowMeAI - BV1ub4y127jj

Yeahï¼Œ hi everyoneã€‚ I decided to make a short bonus video stuff in the newsã€‚

 interesting things related to deep learningã€‚ So here I'm just briefly talking about cool things I discovered in the news this week related to deep learningã€‚

 And I think it's just fun to yeah talk about the recent developments in deep learning just to stay up to date with thingsã€‚

 So I'm planning to release such a video every week if I have timeã€‚

 So it's also on the optional So you don't have to watch them So it's something just watch it if you're interested in if not don't worry about itã€‚

 It's just like some fun additional video content for this classã€‚ So then yeahã€‚

 let me get started and let me tell you what happened in the world of deep learning this weekã€‚Yeahã€‚

 let's start with a cool application of deep learning for CoVD 19 resource needsã€‚

 predictions from a series of x raysã€‚So this was a project by Facebook AI research in collaboration with medical doctors at NY Uã€‚

 And it's always cool to involveï¼Œ yeahï¼Œ domain expertsã€‚ I think that's super importantã€‚

 as I mentioned in theã€‚ðŸ˜Šï¼ŒLectsï¼Œ it's always a good idea to consult people who actually have some expertise in the data that you're working withã€‚

 especially if it's an important applicationï¼Œ like a medical applicationã€‚ So in this caseã€‚

 the researchers trained three models to predictï¼Œ yeahã€‚

 patient deterioration and to help predict the resource requirements like oxygenï¼Œ soã€‚

Here in the first modelï¼Œ they predicted the deterioration of the patient from only one x ray image that did the same thingã€‚

 the same prediction task now from also a series of x raysã€‚

And the third model was predicting the oxygen supply neededã€‚ Yeahã€‚

 for helping a patient that was also based on a single x rayã€‚ So of courseaã€‚

 it's usually helpful to have multiple x rays that can also then yeah boost the performance if you have a sequence of x rays and you can yeahã€‚

Tickle this as a time serious problemã€‚ Howeverï¼Œ these models also work if only one single x ray is availableã€‚

So how they approached this modeling task was that they pretrained the deep neural network on a large noncoviId chest X- ray databaseã€‚

 so they used a general Xray databaseï¼Œ Why did they do thatã€‚

 That's because they had a larger dataset available this wayã€‚

 Because there are only limited numbers of X rays from COVID patients at this pointã€‚

So here they used selfsupvised learningã€‚ remember from the lecture selfsvised learning is this new trend where you pretrain a model on a socalled pretext task and then you find unit to your targeted data setã€‚

 So here they did the fine tuning based on a smaller CoVID-19 x- ray data set where they had 27000 xrays from 5000 patientsã€‚

And what was interesting is that yeahï¼Œ these methods they developed outperformed human experts on some of the measuresã€‚

 So of course it's yeah not a good idea probably to replace humansã€‚

 but I think developing these systems can be really useful to help humans because yeahã€‚

 everyone is stretched very thin these daysï¼Œ especially do the large amount of patients at hospitals right nowã€‚

 So maybeã€‚Yeahï¼Œ the doctor's task can be done more effectively in the combination with deep learningã€‚

 especially for exampleï¼Œ if you think of medical staff that is maybe a little bit tired having a deep learning system taking also yeah a second look at these images X race could maybe help yeah avoid making mistakesã€‚

So you can find the full paper here on archive and they also uploaded the pretrain models on GitHub if someone is interestedã€‚



![](img/a232ad23b114e800c7d0b426557a7565_1.png)

Yeahï¼Œ regarding CoVd 19 researchï¼Œ so on archiveï¼Œ which is a preprint setupã€‚

There's a large amount of thousands of papers or manuscriptsï¼Œ preprints uploaded regarding Covid-19ã€‚

 So this is a general preprint server for machine learning we have a lot of papers on this serverã€‚

 so I help moderating the machine learning categories and every day there are about 140 new papers about yeah deep learning and machine learning so it's like a huge amount of papers I think there are now in total like 140 million papers across different research domainsã€‚

In any caseï¼Œ you can use the search function to also search forã€‚Yeah has specific researchã€‚

 And here Iã€‚Yeah try to search a keyword combination to also yeah bring up more Covid-19 related research with deep learning So what I showed you here in the previous sni was pretty cool but of course it's not the only approach using deep learning for CoVID prediction from chest x-rays So here using these search terms you can find many more works in this areaã€‚

 but yeah also you have to take this a little bit with a grain of salt because not of all of these papers have undergone peer reviewã€‚

 So some of the findings maybe spurious or maybe less rigorousã€‚

 so always take archive papers with a grain of saltã€‚

 I will post a link so you can access these papers if you are interested in thatï¼Œ for exampleã€‚

 for the context of your class projectsã€‚

![](img/a232ad23b114e800c7d0b426557a7565_3.png)

![](img/a232ad23b114e800c7d0b426557a7565_4.png)

![](img/a232ad23b114e800c7d0b426557a7565_5.png)

Yeahï¼Œ there was another interesting research project related to Covid 19 was the learning of the language of viral evolution and escapeã€‚

 So this was an article where the researchers described the training of a bidirectional LSTMã€‚

 So an LS LSTM stands forã€‚Longã€‚ðŸ˜”ï¼ŒShort term memoryã€‚It's a recurrent neural network of flavorã€‚

 and it's a particularï¼Œ yeahï¼Œ you can think of it as a particular version of the R and Nã€‚

 and we will talk also about that more later in this courseã€‚

So here they trained a bidirectional LSDM bidirectional just means that they process a sequence from both ends from beginning to end and from the end to the beginningã€‚

 and it's a language modelã€‚ So here they treat the amino acid sequence corresponding to a virusã€‚

They treat this as a language model like textï¼Œ for exampleã€‚

 and they also draw some analogies from language modelingï¼Œ for exampleã€‚

 they consider the context of being grammatically correct as the biologically being correctã€‚

 like is this like a correct sequenceï¼Œ a correct aminosic sequenceï¼Œ is it a plausible oneã€‚

And then also considering its semantic meaningï¼Œ so here in context of a languageã€‚

 the semantic meaning would be at the meaning of the sentence here it's whether yeah the sequence causes immune responses or notã€‚

And yeahï¼Œ they got a pretty good performanceã€‚ They have a point85 A Uã€‚ A U C stands forã€‚A areã€‚

Another curveã€‚Which is rather ambiguous because what curve do we mean hereã€‚

 if there's no context if you see something like Auc see in a paperã€‚

 it usually means receiver a operating characteristic area under the curveã€‚ So R Oã€‚

 It's a measure of false positive and true positive ratesã€‚ if you shift the prediction thresholdã€‚

 but it's maybe too much detail at this pointã€‚ So what's important is that a 0ã€‚5 is randomã€‚ So 0ã€‚

5 is a random prediction and 1ã€‚0 is a perfect modelã€‚

 So in this way they are yeah closer to a really good model than to a random or bad predictorã€‚

 So yeahï¼Œ that is another interesting Covid-19 paper moving on to the more like business side of AI or deep learning there was also something I found really interesting that interestingã€‚

 but it was like quite a headlineã€‚ So there's like a project called human AIã€‚



![](img/a232ad23b114e800c7d0b426557a7565_7.png)

That just got a 3ã€‚2 million of funding to build a personal intelligence platformã€‚

 So here that sounds very interestingã€‚ So what it is about is that they are building an individual personalI that is secured by a blockchain to retain and recall informationã€‚

 so you have two buzzwords in hereã€‚ So you have the eye and blockchainã€‚

So this is building a knowledge base in a way it sounds like itã€‚

 but based on an individual's informationã€‚ so you can maybe also think of it as a second brain zoneã€‚

They say it's made possible through a convergence of neuroscienceã€‚

 natural language processing and blockchain to deliver seamless in the momentã€‚

 recall G3 is built on the memories of the public Internetï¼Œ While Lutherã€‚

 thats their system is built on the memories of your private selfã€‚

 So it sounds like yeah they are attempting to build a second brain orã€‚

Digital copy of your brain that it kind of also reminded me ofã€‚

Of this movie seen here or actually TV show sceneï¼Œ it might be also fun to let me know if you know what the name of the TV show is as a little side quiz hereã€‚



![](img/a232ad23b114e800c7d0b426557a7565_9.png)

Anywaysï¼Œ moving on so regarding yeah access to data to make a transition hereã€‚

 there is also a cool initiative by Twitterã€‚ So Twitter is opening up its full tweet archive to academic researchers for freeã€‚

 So they have been yeah projects before academic projects by people used Twitter dataã€‚

 but as I as far as I know it was a little bit tediousã€‚

To access the data through the API because there were some limitations now yeah they say they want to make this easier and to give more access so they say for exampleã€‚

 they are giving applicants approved applicants a higher monthly tweet volume cap of 10 million tweets so per month which is 20 times higher than what it was beforeã€‚

And yeahï¼Œ they also a allow more precise filtering to help researchers pinpoint tweets and other relevantã€‚

Data to what they are studyingï¼Œ basicallyã€‚ So in that wayã€‚

 of making research based on Twitter a little bit more convenientã€‚ So what can you doã€‚

 what what is Twitter data useful forï¼Œ Why isï¼Œ Why is that actually coolï¼Ÿ

 So they are actually quite some projects involving social media data that are quite useful beyond just their simple sentiment analysisã€‚

 So here I saw another news article where they are using a artificial intelligence to manage extreme weather eventsã€‚

 So in this researchã€‚

![](img/a232ad23b114e800c7d0b426557a7565_11.png)

They use social media contributionsï¼Œ for exampleï¼Œ tweets to more usefully manage crisesã€‚

 so they developed a noise reductionã€‚Mechanism to filter for valuable information from social media to better SS trouble spots where there areã€‚

 for exampleï¼Œ floods or snowstorms and so forthã€‚Soã€‚Yeahï¼Œ that was another interestingã€‚

Application of deep learning where information can be efficiently accessed toï¼Œ yeahã€‚

Help certain areas where there are problemsã€‚

![](img/a232ad23b114e800c7d0b426557a7565_13.png)

Okayï¼Œ talking about data setsï¼Œ large data setsã€‚ So one data set that is very common in the deep learning community very commonly used as a benchmark is the imagenet data setã€‚

 I think it's alreadyï¼Œ yeahã€‚16ï¼Œ16ï¼Œ15 years oldã€‚ It has been released around 2005ï¼Œ2006ã€‚

 It's still very popularã€‚ It's a very large data setï¼Œ about 14 million imagesã€‚

And it's usually used for evaluating the classification performance of image models like convolutional neural networks or now also visual transformersã€‚

So the problemï¼Œ thoughï¼Œ is thatï¼Œ yeahï¼Œ the image data set is kind of notorious for mistakesã€‚

 and there are also incomplete labelsã€‚ So sometimes you have multiple object in an objects in an imageã€‚

 for exampleã€‚As shown in hereï¼Œ you have a cow here and then a barn andã€‚Someï¼Œ yeahï¼Œ I don't knowã€‚

 maybe also sky in the backgroundã€‚ So there are multiple things going onã€‚ or actuallyã€‚

 they call it an oxã€‚ So they areã€‚OhActuallyï¼Œ noï¼Œ it's it's the fenceã€‚ I just see it hereã€‚

 It's the fence hereã€‚ So there are multiple objects in this imageã€‚ And if you train a classifierã€‚

 a regular classifierï¼Œ usually it only gives you the most confident class label as the predictionã€‚

 So if you have a classifier that predicts barn it may be wrong because the image was just labeled with ox hereã€‚

and in that wayï¼Œ thatã€‚The classifier may be correctï¼Œ but you are counting it as a misclassificationã€‚

 So here in this projectï¼Œ the researchers are relabelling imagenetã€‚

 So they are adding multiple labels to the image hereã€‚ So they are usingã€‚

Also machine learning to do that because yeah would take a lot of people or resources to look at these 14 million images and yeah to assign the correct labels so they make their life easier by also using deep learning for that so it's kind of like a chicken egg problemã€‚

What comes firstï¼Œ the data or the model the model can then be used for labeling the dataset here what they do is they use a different dataã€‚

 They use 1 billion images from Instagram and they train a model called efficient net for for training this model to become a machine annotator to annotate the 14 million images in image netã€‚

 they use crop regions for that So they are cropping different regions of the image So for example as shown here they are cropping the image into smaller regions and then apply a classifier to each of these smaller regions to obtain the class label and then have this multilabel context for each image that is also something I found actually useful and interestingã€‚



![](img/a232ad23b114e800c7d0b426557a7565_15.png)

Yeahï¼Œ another project from Facebook AI research hereã€‚

 I also also thought that might be a cool application of machine learning and deep learning that has someã€‚

 yeahï¼Œ use forã€‚The real worldï¼Œ so hereã€‚So what Facebook did is they used AI to improve photo descriptions for people who are blind or visually impairedã€‚

 So they developed a smartphone appã€‚That yeahï¼Œ where you can take a picture and that app can then describe what can be seen in that pictureã€‚

 like an audioã€‚Message so this system has been aroundï¼Œ I thinkï¼Œ for a couple of yearsã€‚

 but they are just improved to make it more accurateã€‚ So here they trained a resnt model on 3ã€‚

5 billion Instagram photos and the corresponding hashtags and they also are combined with a fast R C andN object detector to describe different aspects of this imageã€‚

 So for exampleï¼Œ here in this example the description is it may be an image of one person standing on or at Machu Piccuã€‚



![](img/a232ad23b114e800c7d0b426557a7565_17.png)

So going back hereï¼Œ this is kind of similar to these crop regions where people have these different crops of the same image and then assign a label hereã€‚

 it's a similar approach that you haveï¼Œ for exampleï¼Œ personï¼Œ Machu Piccu and so forthã€‚

 but yeah the addition here is that there's also a text describing this or putting this into contextã€‚



![](img/a232ad23b114e800c7d0b426557a7565_19.png)

![](img/a232ad23b114e800c7d0b426557a7565_20.png)