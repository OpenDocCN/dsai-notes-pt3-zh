# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P108ï¼šL13.9.2- åœ¨ PyTorch ä¸­ä¿å­˜å’ŒåŠ è½½æ¨¡å‹ - ShowMeAI - BV1ub4y127jj

All rightï¼Œ so at the end of the previous videoï¼Œ I promised you to show you Alexnet nowã€‚

 But before we do thatï¼Œ let me show you one more thingï¼Œ how we save and lot modelsã€‚

 And then in the next videoï¼Œ I will show you Alexnetã€‚

 So I explained to you how that works in an earlier lectureã€‚ But yeahã€‚

 it's really good to just recap that because I think it might be very useful for your class projectsã€‚

ğŸ˜Šï¼ŒSoã€‚Here I have a subfolderã€‚ I just called it Sa and lotã€‚ So all of that is on Githubã€‚

 I will add the linksã€‚ So this save and lot subfolderã€‚ And let's do the Alex that first withã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_1.png)

Only training it for like one or two epochsã€‚ So here I'm showing you how we can save a modelï¼Œ soã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_3.png)

Same thing as beforeã€‚ noticed that I am having now this Su path dot insert dot dotã€‚

 That's because all my helpaler files are one level higher than this folder where I'm executing this notebookã€‚

 So it's basically going back one folderã€‚ And this is where my helper files isã€‚

 So this is essentially just adding this pathã€‚ So that Python knows where to find these helpaler filesã€‚

 Of courseï¼Œ you can also make this a python a Python packageã€‚ and thenã€‚

Import this as a package by yeah different by a setup fileï¼Œ maybe evenã€‚

 but this might be over color hereã€‚ So here for experimental purposesã€‚

 it's just sufficient to just add the path and it will find this and run thisã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_5.png)

Or importm everythingã€‚ So everything here is the same as beforeã€‚ So now let'sã€‚

 let's train only for three epochs or something or twoã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_7.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_8.png)

Andã€‚It's all the same stuffã€‚ so I don't have to explain all of that againã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_10.png)

So this is essentially now training for two epochs instead of fiveã€‚

SoLet's briefly wait until this finishesã€‚ It shouldn't take that longï¼Œ maybeã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_12.png)

A minute or somethingã€‚Half a minuteã€‚

![](img/5a3e0422b6af2773919fc4e6fa067d70_14.png)

Alrightã€‚So yeahï¼Œ maybe we might thinkï¼Œ okayï¼Œ it might be good to train a bit longerã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_16.png)

So actuallyï¼Œ I also added an anotherã€‚ So I have the show example functionã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_18.png)

So hereï¼Œ everything looks correct orã€‚

![](img/5a3e0422b6af2773919fc4e6fa067d70_20.png)

Looks fineï¼Œ but I also added another functionï¼Œ a confusion matrixã€‚ Students who took 4ã€‚

51 last semester may know what the confusion matrix isã€‚ But yeahï¼Œ essentiallyã€‚

 for those who are not familiar with thatï¼Œ it's essentially a matrix showingã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_22.png)

The predicted labels versus the true labelsã€‚ So how manyï¼Œ let's say how manyã€‚9s were predicted as 0ã€‚

 rightã€‚Soã€‚Can see where the model makes the most mistakesã€‚ What you want is you wantã€‚

The highest number here in the diagonalï¼Œ you can seeï¼Œ for instanceã€‚

 the model mistakes a lot of the9s as a 5 or mistakes a lot of Can we see here twos as a 7ã€‚ I meanã€‚

 they are quite similarï¼Œ rightï¼Œ the2 into 7 are not that differentã€‚

 So it's kind of interesting to look at that and see where the model makes the most mistakesã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_24.png)

But this is just as a site noteã€‚ So the main part I wanted to talk about is the model saving hereã€‚

 So here what we do is we save the model parametersã€‚ That's the state ditã€‚

 So take a dictionary consisting of the stateï¼Œ all the weights and everythingï¼Œ all the parametersã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_26.png)

And we are saving it to a file called model dot P Tã€‚ So P T just for Pytorchï¼Œ but you can choose anyã€‚

Name that you preferã€‚ you can also spell it outã€‚Py torchï¼Œ oopsã€‚Doesn't really matterã€‚Okayã€‚

 and then let's do thatã€‚ So then it will what we also do is we save the optimizer state because we useã€‚

SD with momentumã€‚ So there's also a momentum state that we save if we want to continue using that optimizer and we also have the schedulerã€‚

 So we also save the scheduler state I meanï¼Œ you don't have to do thatã€‚

 you can start from scratch with a new optimizer and schedulerã€‚

 but if we really wanted to just continue training like if the run here got interruptedï¼Œ for exampleã€‚

 then this would be the proper way to do it in ways that we save all of them and then load all of these statesã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_28.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_29.png)

Soï¼Œ nowã€‚We have these hereã€‚And thisã€‚Safe and G folderã€‚Andã€‚Can we see thisã€‚

 I'm not sure we can see that The file size is also quite interestingã€‚

 Sometimes these are pretty large the model because there are lots of weights anywaysã€‚Nowã€‚

 assume we have saved the modelã€‚ Let's now load the modelã€‚ So you have prepared another notebookã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_31.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_32.png)

Actuallyï¼Œ it's all the same stuffã€‚So everything is the sameã€‚

 It's kind of required because what we do is we firstã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_34.png)

Have to initialize the modelã€‚

![](img/5a3e0422b6af2773919fc4e6fa067d70_36.png)

So that is what creates the class and then once we have initialized itã€‚

 this is really only the new partï¼Œ that's how we load the modelã€‚

 So now we have Torch load load and then the model do P file the same thing for the optimize and scheduler and then we are loading this state dicator into the model but notice that we have to initialize the model as before that's the same thing as before but we have to do thatã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_38.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_39.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_40.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_41.png)

cause otherwiseï¼Œ it wouldn't know whereï¼Œ yet where to put the parameters in itã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_43.png)

So okayï¼Œ if we have done thatï¼Œ we can thenã€‚Train the model furtherã€‚ Yeahã€‚

 for 10 epos it might take quite a whileã€‚ but yeahï¼Œ we would then continue training that modelã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_45.png)

![](img/5a3e0422b6af2773919fc4e6fa067d70_46.png)

So that's how you save and lot models next in the next videoã€‚ Nowï¼Œ let's get finally to the Alexnetã€‚



![](img/5a3e0422b6af2773919fc4e6fa067d70_48.png)