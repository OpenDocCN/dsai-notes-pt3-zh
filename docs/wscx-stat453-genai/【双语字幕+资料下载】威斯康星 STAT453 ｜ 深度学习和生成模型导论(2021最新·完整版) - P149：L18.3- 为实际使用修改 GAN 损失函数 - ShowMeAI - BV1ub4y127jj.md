# P149ÔºöL18.3- ‰∏∫ÂÆûÈôÖ‰ΩøÁî®‰øÆÊîπ GAN ÊçüÂ§±ÂáΩÊï∞ - ShowMeAI - BV1ub4y127jj

So in this videoÔºå I want to talk about a small modification that we can make to improve the G training„ÄÇ

 in particularÔºå we are looking at improving stochastic gradientding descent for the generator„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_1.png)

But hereÔºå before we get to thatÔºå let me highlight or just list some of the problems with G training In a future video„ÄÇ

 I will show you some tricks and tips for yeah addressing some of the problems„ÄÇ

 or at least for improving G training„ÄÇ But hereÔºå let's just take a look at this list of problems„ÄÇ

 So one problem is„ÄÇThe constant oscillation between the generator and discriminness„ÄÇ

 So things never convergeÔºå things might just keep oscillating„ÄÇ

Another very common problem is mode collapseÔºå which essentially means that the generator will learn how to generate a particular type of data that is particularly good at fooling the discriinator„ÄÇ

So that is also one problem usually when you see that the generator is only producing one kind of image„ÄÇ

 then this is usually due to this type of mode collapse where the generator just exploits a weakness in the discriminator just producing a particular type of image„ÄÇ

One common problem with a traditional or conventional gtering that I showed you before or that we discussed when we had this minm setup is that the discriminator would be too strong usually or what can happen is that the discriminator is too strong which is a common problem because classification is simpler than generating data so it can easily be that the discriminator is too strong and if this happens in the very beginning that the discriminator starts out very strong and using the loss gradient that I showed you earlier what happens is that the gradient for the generator will vanish it will be too small and the generator can't keep up with a discriminator and then yeah things won't train at all„ÄÇ

Another problem could be that the riskco is too weak and the generator produces non realistic images that fool it too easily„ÄÇ

The difference here between one is that the disc is too strong and here it's too weak and practice it's usually that the disc is too strong because the classification is easier than data generation so„ÄÇ

There is a little trick that we can apply to at least address„ÄÇThis problemÔºå to some extent„ÄÇ

 and that is something I will explain in the next couple of slides„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_3.png)

OkayÔºå let's now focus in on the problem related to the discriminator being too strong„ÄÇ

 such that the gradient for the generator vanishes and the generator can't keep up„ÄÇ

Which can be fixedÔºå or at least mitigated as follows„ÄÇ So hereÔºå what I have is the original„ÄÇ

G formulation that I showed you from the paper earlierÔºå from the algorithm one screenshot„ÄÇ

And what we had is hereÔºå the update for the generator„ÄÇ

 So this is the gradient of the loss with respect to the generator weights„ÄÇ And yeahÔºå if you recall„ÄÇ

 the generator once„ÄÇThe discriinator to output something close to one for these generated images„ÄÇ

 So hereÔºå these are the generated images„ÄÇ And then once the discgrainator to think they are„ÄÇ

 they are real„ÄÇAnd then if we have something close to oneÔºå then where we lock„ÄÇ1-1„ÄÇ

 which really minus infinity„ÄÇAnd„ÄÇThis is where we then maximize„ÄÇSorryÔºå minimize this loss function„ÄÇ

 and it is maximizeimd if this is somewhat close to 0Ôºå because then we have lock 1-0Ôºå which is„ÄÇ0„ÄÇ

 right„ÄÇ So in this case„ÄÇWhat we want is something close to one„ÄÇBut it might happen in the beginning„ÄÇ

 especially that„ÄÇIn the beginning that the output of the discriminator is close to 0„ÄÇ

 because in the beginningÔºå it is kind of hard to generate new images from scratch if the generator hasn't learned anything yet So in the first few iterations„ÄÇ

 So in the beginningÔºå it will be very easy for the discriminator to tell apart real and fake„ÄÇ

 So in the beginningÔºå it will output something close to 0„ÄÇ

This will maximize this loss and we want to minimize it„ÄÇ so that's actually good„ÄÇ

 But the problem is that the gradient signal will be relatively small and it will be kind of hard this way for the generator to learn efficiently„ÄÇ

 I meanÔºå it will be able to learnÔºå but not very efficiently„ÄÇ

Because the gradient will be relatively smallÔºå and it can be improvedÔºå like shown at the bottom„ÄÇ

 So but yeahÔºå let me maybe outline the problem first with a gradient here„ÄÇ

 So what we have is lock 1 minus something„ÄÇ let's call this„ÄÇGrated image„ÄÇWhen not generate image„ÄÇ

 the inside is a generated image„ÄÇ but let's just call this whole thing X prime„ÄÇOr maybe„ÄÇ

 maybe something like„ÄÇWhyÔºå why hatÔºå let's call it way hat„ÄÇSo what we have is„ÄÇLook„ÄÇ

1 minus my head here„ÄÇWhat is the derivative of thatÔºüSo for thatÔºå we would need the chain rule„ÄÇ

 So you know that the derivative of„ÄÇSomething like log X would be„ÄÇ1 over„ÄÇX„ÄÇ

So here we have to use the chain ruleÔºå the autota times the inner derivative„ÄÇ So what we have is for„ÄÇ

 let's do the inner derivative first„ÄÇ So it's one minus y hat„ÄÇ

 so we are looking at the derivative with respect to Y hatÔºå of course„ÄÇ

So the inner derivative here would be1 minus„ÄÇ So the derivative of1 minus y hat would be-1Ôºå right„ÄÇ

Because with respect to my hat„ÄÇAnd this vanishes„ÄÇ And this becomes a one„ÄÇ So we have„ÄÇ-1„ÄÇ

Times the outer derivativeÔºå like I said beforeÔºå the outer derivative isÔºå as follows„ÄÇ So if of log X„ÄÇ

 it would be one over x„ÄÇ So here the outer derivative would be one over1 minus y hatÔºå rightÔºü

 So that derivative then is„ÄÇ-1„ÄÇlet's write it like this„ÄÇ-1„ÄÇ1 or1„ÄÇüòîÔºåW he ohÔºå way„ÄÇAnd„ÄÇDoing premier„ÄÇ

 But I meanÔºå hintÔºå of course„ÄÇOkayÔºå so this is our derivative„ÄÇ So if something is close to a 0 here„ÄÇ

 our derivative will be around„ÄÇ-1Ôºå ifÔºå if this is„ÄÇClose to 0„ÄÇAnd I meanÔºå this is okay„ÄÇ

 but it's not like the strongest„ÄÇderivative„ÄÇ So it won't be the bestÔºå let's say„ÄÇ

 for learning the generator in the beginning„ÄÇ So a trick is to„ÄÇ

Turn this gradient asscent problem into the following gradient ascent problem„ÄÇ

 So now what I'm doing here is I'm dropping this one minus here„ÄÇSo„ÄÇ

Then if the discriminator outputs 0 here„ÄÇThe loss would be„ÄÇInfinitine„ÄÇAnd if the generator outputs„ÄÇ

SorryÔºå if the discriminator outputs are  oneÔºå which is what we wantÔºå the loss would be 0„ÄÇ

 So now we have the loss between 0 and„ÄÇInfinityÔºå and before we headed between minus infinity and„ÄÇ0„ÄÇ

 so before we wanted to minimize it„ÄÇ So before we wanted to„ÄÇMinimise the loss„ÄÇNowÔºå it' grain essence„ÄÇ

 We want to maximize this term„ÄÇAnd this will give us here a stronger gradient if the initial prediction of the discriminator is that it can detect the generated images„ÄÇ

 So if in the worst case scenarioÔºå what we have is that the discriminator outputs something close to a0 right„ÄÇ

 And now if you look at this term here in the whole term„ÄÇ

 it's log x term and the derivative log x is„ÄÇIs one over xÔºå rightÔºü So in the worst case now„ÄÇ

 we have something close to 0„ÄÇ And let's say we have one over a very small„ÄÇNumber„ÄÇ

Then what will happen is that the gradient„ÄÇWill be„ÄÇ

Well the the derivative will be much larger here for„ÄÇ

A discriminator that can successfully detect the generated images„ÄÇ

 So here using this formulation at the bottomÔºå the generator will burn more effectively in the beginning„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_5.png)

YeahÔºå so by nowÔºå we have seen a lot of gradient ascent and descent and flipping between the two and so forth„ÄÇ

 So it might look super complicatedÔºå but in practiceÔºå actually„ÄÇ

 it's not as complicated as you might think„ÄÇ It's actually pretty straightforward to implement thegan must function with ir regularular gradient descent„ÄÇ

So we will be using regular gradient descent for both the discriminator and the generator„ÄÇ

 and it will probably be more clear when you see that implemented in code in the next video„ÄÇ

 But yeahÔºå let me briefly„ÄÇJust finish the section on this trick or just in general„ÄÇ

 how we can turn everything into a gradient decent problem„ÄÇ

 So in an earlier video on the original againÔºå we have seen in the paper that they mentioned gradient accentcent for training the discriinator„ÄÇ

So previously in the paperÔºå they mentioned that they are maximizing the prediction probability of classifying real is real and fake is fake for the discriminator„ÄÇ

 but as you remember from the logistic regression lectureÔºå long time agoÔºå lecture 8Ôºå I think„ÄÇ

What we said is that maximizing the lock likelihood is the same as minimizing the negative lock likelihood„ÄÇ

 So the negative lock likelihoodÔºå we can also think of it as the„ÄÇCross entropy„ÄÇ So in that way„ÄÇ

 we can actually yeah just use our regular cross entropy binary cross entropy and Pytorch to optimize the discriinator„ÄÇ

 we don't have to do gradient in Ecent„ÄÇSo the same for the generatorÔºå so for the generator„ÄÇ

 we first in the original paperÔºå they first said it's about minimizing the likelihood of the discreteator making correct predictions„ÄÇ

And„ÄÇMinimizing the likelihood is the same as maximizing the cross entropy in that sense„ÄÇ

 It's similar to„ÄÇHereÔºå maximizing the cross look likelihood and minimizing the cross entropy„ÄÇ

 here had now flippedÔºå minimizing likelihood and maximizing cross entropy„ÄÇ

 But we just talked in the previous slide„ÄÇThat this is actually not ideal because the gradient small gradient issues„ÄÇ

 So we said that it doesn't work well in practice because of these small gradient issues„ÄÇ

 So what we did is we flipped or we didn't flipÔºå but we modified the loss first so that we can use gradient accent„ÄÇ

But in practiceÔºå it's even better to just flip the labels and minimize the cross entropy„ÄÇ

So what we are doing is we are forcing the discriminator to output high probabilities„ÄÇ

For a real image„ÄÇIf an image is fakeÔºå so a higher probability„ÄÇFor the real label„ÄÇ

 given that the image is fake„ÄÇIf this all is very dense and complicated here on this slide is a lot of information here„ÄÇ

 let me go through the next couple of slides where I will yeah disentangle this a little bit„ÄÇ

 only two more slidesÔºå and then we will see a code example in the code example you will see it's actually pretty straightforward„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_7.png)

Okay so now I will just step by step illustrate how everything relates back to our binary cross entropy or minimizing the negative look likelihood So here this is the gradientes step from the original paper from the G paper So again this is for the discriminator and we want the discriminator for the real images to output something close to one here„ÄÇ

And on the right hand sideÔºå for the fake imagesÔºå we want to output something close to 0„ÄÇ

 So this is the original„ÄÇAgain„ÄÇObjective for the discriminator and„ÄÇ

It's with a gradient in essencecent described in the paper„ÄÇ

 but we can turn this into a great and decent problem by„ÄÇ

 yeah just using our negative look likelihood function„ÄÇ

 the loss function that we have seen from the logistic regression lecture„ÄÇSo here„ÄÇ

This whole thing is I just used it from the logistic regression lecture„ÄÇ

 This is our loss function we used there„ÄÇ And here I'm just highlighting how the G objective maps to this loss function„ÄÇ

So„ÄÇAgainÔºå we had these two parts„ÄÇ We had a minus yÔºå and then we had1 minus y„ÄÇ

 So let's just focus on the y here„ÄÇ So if the true label is oneÔºå then we use this turnÔºå right„ÄÇ

 And if the true label is one here AlsoÔºå then this will become 0„ÄÇ

 So we don't do anything with this one„ÄÇ So if the true label is one„ÄÇ

 we don't do anything with the right hand side„ÄÇ We only do something with the left hand side„ÄÇ

If the true labelÔºå if the class label is0Ôºå then the whole thing will become 0„ÄÇ

 so we don't use this one and this one becomes 0„ÄÇ So 1 minus-0„ÄÇ This one becomes1„ÄÇ

 So we are using only this right part„ÄÇIf the class table is 0„ÄÇ

So there are these two parts to the loss function„ÄÇ This is yeah just from the logistic regression lecture„ÄÇ

So now let's focus on this part here„ÄÇRightÔºå so we want this to be close to one„ÄÇ

 And this is for the real images„ÄÇ And we set for the real images„ÄÇWe have class table 1„ÄÇ

 So for the real imagesÔºå we are looking atÔºå at this part here„ÄÇ

And we want the prediction also be close to one„ÄÇSoÔºå that is„ÄÇHowÔºå yeah„ÄÇ

 how objective maps here to a gradient decentcent problem„ÄÇ

 because here we have also the minus for the negative log likelihood„ÄÇ

 This is a negative log likelihood„ÄÇ We have minus and minus„ÄÇ

 so we are minimizing trying to minimize this termÔºå right„ÄÇAnd for fake images„ÄÇ

 we are looking now at the right hand sideÔºå rightÔºå because for fake imagesÔºå we have the label„ÄÇ0„ÄÇ

 so this will become 0 cancel„ÄÇ So the whole thing will cancel„ÄÇ

 We only look at the right hand side here„ÄÇSo then this one will be one„ÄÇ

And then we look at lock 1 minus y hat„ÄÇSo againÔºå we have a negative look likelihood„ÄÇ

 It's the minimization here„ÄÇSoÔºå we want to„ÄÇWhen we do the gradient descentÔºå what happensÔºå we will„ÄÇ

Learn how to output a white head here„ÄÇ This is the ideal case„ÄÇ This is what minimizes our„ÄÇLast year„ÄÇ

RightÔºå because otherwiseÔºå minusÔºå if this would be a oneÔºå then the whole thing will be oops„ÄÇ

The whole thing will become 0Ôºå and minus„ÄÇLock of 0 will be minus minus infinity„ÄÇ It will be infinity„ÄÇ

 rightÔºå So this is highlighting how„ÄÇThis oneÔºå the gradient essenceÔºå becomes a gradient„ÄÇ

Descent in practice when we use our negative lock likelihood„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_9.png)

YeahÔºå let's now look at the generator objective„ÄÇ So at the topÔºå this is from the original paper„ÄÇ

 the gradient decent part of the original G paper and„ÄÇ

We can also yeah transfer this to our negative likelihood context so because now we are having the fake images from the generator„ÄÇ

 so we have the fake labels which are0„ÄÇ So this part is0 so this whole thing cancels we can ignore this part only focusing on the right hand part„ÄÇ

 but if we use a regular negative likelihood if we optimize this„ÄÇ

 but will happen it will wants to optimize the prediction to0 right„ÄÇHowever„ÄÇ

 we want the opposite we want to fool„ÄÇThe discriminatorÔºå right„ÄÇ

 we don't want to encourage it to detect the fake images„ÄÇ

 We want to fool it so that it thinks these are real„ÄÇ So how can we do that„ÄÇ

 We can flip this sign here„ÄÇTo a positive sign„ÄÇ So then instead of this being maximized to y hat 0„ÄÇ

 it will be maximized to y hat equals 1„ÄÇ

![](img/0afe481a373a75548df7c0b7c13634cc_11.png)

OkayÔºå so but we said„ÄÇActuallyÔºå this is bad bad because flipping the sign„ÄÇ Okay„ÄÇ

 it will correctly achieve our objectiveÔºå but the gradients will be very small if our discriminator is successful in predicting„ÄÇ

That the generated images are generated„ÄÇ So we saidÔºå okayÔºå this is actually not a good idea„ÄÇ

 We want to modify this loss function where we don't have the one minus hereÔºå rightÔºü

So that is what we spend a couple of minutes about talking in the previous slides„ÄÇ

 so what we can do instead instead of modifying this label sorry instead of modifying this sign here to a plus sign instead of doing that we can just flip the labels so flipping the labels so instead of doing the gradient descent before so before we had this gradient descent here with this1 minus and we said this is bad so we are removing the one minus here„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_13.png)

![](img/0afe481a373a75548df7c0b7c13634cc_14.png)

![](img/0afe481a373a75548df7c0b7c13634cc_15.png)

![](img/0afe481a373a75548df7c0b7c13634cc_16.png)

![](img/0afe481a373a75548df7c0b7c13634cc_17.png)

We do a great inescent„ÄÇAnd we can just flip the labels to turn this into a grain and decent problem„ÄÇ

OkayÔºå so the modified loss function isÔºå or what we are doing is we have usually for the fake images„ÄÇ

 we have the label 0Ôºå right„ÄÇNow we are flipping this„ÄÇ NowÔºå instead of using label 0„ÄÇ

 we are using label one for the fake images„ÄÇ This is for the generator„ÄÇ

 and then we can use this part of the loss function because yeahÔºå this one will be one„ÄÇ

 This one will be one here„ÄÇSo this whole thing cancels„ÄÇAnd we are looking at this one„ÄÇ

 And then what will happen is if we have a oneÔºå it will also„ÄÇ

Try the prediction to make it similar to the one„ÄÇAnd then„ÄÇBecause„ÄÇWe provide it as one„ÄÇ

 but in realityÔºå it's actually still the 0„ÄÇ I meanÔºå it's a fake image„ÄÇ

 What will happen is that it screeninator will be trained to make the wrong prediction„ÄÇ

 So the generator trains„ÄÇTo fool the discriminatorÔºå to make wrong predictions„ÄÇOkay„ÄÇ

 so this was probably super complicated„ÄÇ Lots of stuff happening„ÄÇ So in the„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_19.png)

Next video I will show you a code example and you will see we are just using regular binary cross entropy for everything and you the regular stochastic gradient descent or Adamom Opr and it will be pretty clear then afterwards I hope„ÄÇ



![](img/0afe481a373a75548df7c0b7c13634cc_21.png)