# P150ÔºöL18.4- Âú® PyTorch ‰∏≠ÁîüÊàêÊâãÂÜôÊï∞Â≠óÁöÑ GAN - ShowMeAI - BV1ub4y127jj

All rightÔºå let's now implement a again in Ptorch„ÄÇ So here we will start with a simple G with fully connected layers trained to generate handwritten digits„ÄÇ

And I hope this will make these types of things clear that I tried to explain in the previous video it's very„ÄÇ

 it's a lot of mathematical notationÔºå it's maybe a little bit overwhelming„ÄÇ

 but you will see in the code example is actually quite straightforward„ÄÇI implemented several GNs„ÄÇ

 honestly it took me quite some time to get a good GN working and they're also not great„ÄÇ

 so theyre just simplegans so they are not that great„ÄÇ

 but even then it took me quite some time because training GNs is quite challenging„ÄÇ

So I will in the next video go over some tips and tricks for that„ÄÇ

 but even if you consider these tips and tricksÔºå it can still be hard compared to let's say„ÄÇ

 just training a classifier„ÄÇSo one of the reasons isÔºå so here„ÄÇ

 let's say go over our regular imports and everything„ÄÇ

 But one of the reason is that we have now two neural networks that we have to train„ÄÇ

 So before we only hadÔºå for instanceÔºå one learning rate for training a classifier„ÄÇ now we have„ÄÇ

2 models„ÄÇ So we need also two learning rates and can also be hard to find the goodÔºå a good kind of„ÄÇ

I would say ratio between the learning grades„ÄÇLet me make this a little bit bigger here„ÄÇ

Before we only had to tune1Ôºå now we have to tune2Ôºå the generator learning rate and the discriminator learning rate„ÄÇ

 and also we have to find the right relationship„ÄÇ for instance„ÄÇ

 it could be that this has to be much larger than this one or other way around„ÄÇ So again„ÄÇ

 this is something that has to be tuned and that just yeah increases the complexity„ÄÇAlright„ÄÇ

 so this is just a general setup beside having now two learning rates„ÄÇ So here we have the data set„ÄÇ

 againÔºå nothing special„ÄÇ I'm using the endless data set and here„ÄÇ

I'm normalizing the images between -1 and1„ÄÇWorked a little bit better than 0Ôºå1„ÄÇ

And we are only using the training set here„ÄÇ we are not using the test set for M because GANs are also unsupervised algorithms„ÄÇ

 so we only need we don't need labels or something like that„ÄÇ

 You could technically merge training and test data into one single data set so you have more data„ÄÇ

 but I was lazy hereÔºå so I'm just using the training set„ÄÇFor simplicity„ÄÇ

Just checking that everything loads correctly„ÄÇ Now I'm using this torch vision U dot make grid function„ÄÇ

 which is a pretty nice function to make visualization quickly so„ÄÇOkay„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_1.png)

Here it's„ÄÇPloottting 64 images in an 8 by 8 gridit pretty conveniently„ÄÇ It's justÔºå yeah„ÄÇ

 basically oneÔºå two lines of codeÔºå or three lines of code„ÄÇ So here„ÄÇ

 this is a function I will also use later to visualize the results„ÄÇ

 It's a quite useful function for just making visualizations quickly„ÄÇ

 So here's just how some of these headwritten digits look like„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_3.png)

![](img/5049c02cf602d62e3419b206a736cae4_4.png)

![](img/5049c02cf602d62e3419b206a736cae4_5.png)

OkayÔºå so here's the interesting partÔºå the model„ÄÇSoÔºå we have„ÄÇNow a generator enter a discriminator„ÄÇ

 so I implement this as photosÔºå I use the sequential API for the generator and also the sequential API for the discriminator„ÄÇ

So this is a fully connected can„ÄÇ So I have a linear layer„ÄÇ Here have a leakquire and a dropout„ÄÇ

 I tried different types of dropout with and without„ÄÇ it worked better with with with dropout„ÄÇ

 But while it's another thing to tune„ÄÇ It's kind of tricky„ÄÇÂóØ„ÄÇYeahÔºå and„ÄÇLike I said„ÄÇ

 we are using fully connected layers and because I normalized my input images to be on the -11 range„ÄÇ

 we have also a 10 h here so that the pixel outputs are also in the  -1 in one range that they are comparable to the input range„ÄÇ

 So this is the output from our generator„ÄÇ So the output here are our generated images essentially„ÄÇ

The discriminator is just a classifierÔºå so„ÄÇIt receives an input image„ÄÇ

 We just flatten it so that it goes into our fully connected layer„ÄÇWhich has the sizeÔºå image„ÄÇ

 hide image width and cut channels„ÄÇ the number of features„ÄÇ if we flatten an image„ÄÇ

Has been a long time ago but this is something you probably remember from the multi layerer perceptron class„ÄÇ

And then we have a leaky re hereÔºå dropboard and output layer with one output node because we are using the binary cross entropy„ÄÇ

 We have a binary classification problem here„ÄÇ We could have two output nodes and use the multi category cross entropy„ÄÇ

But hereÔºå for hereÔºå I for simplicityÔºå I'm using the binary crossenttropy„ÄÇ

Which is essentially like a regular logistic regression„ÄÇOkayÔºå so„ÄÇFor each„ÄÇ

 for both the generator and for the discriminatorÔºå I have a forward function„ÄÇ

 I have the generator forward here and the discriminator forward„ÄÇ So the generator forward„ÄÇ

The generator will receive an input image from noise„ÄÇ So the way I implemented my training function„ÄÇ

 because I implemented it with con auto generators in mind„ÄÇI have in the training function„ÄÇ

 something that creates a noise vector that is in the shape„ÄÇColor channelsÔºå height width„ÄÇ

So I'm just flattening it here„ÄÇ That is just a vector„ÄÇAnd then this noise vector„ÄÇ

 This is a noise vector from a random normal distribution„ÄÇIt goes into the generator„ÄÇ

 So this part is executing„ÄÇThis yearÔºå this pipelineÔºå which will produce a new image generated image„ÄÇ

 And since the last day is a fully connected layerÔºå I'm just reshaping it that it outputs„ÄÇAlso„ÄÇ

 the dimensions colour channelsÔºå image height and image width„ÄÇ

 So what goes into here is also colour channels height and width„ÄÇ

 which is why I'm flattening this here„ÄÇSo let me put this maybe here„ÄÇZ has„ÄÇI mentioned„ÄÇCÔºå H W„ÄÇ

And the output also has the dimension CÔºå HW across also the batch size„ÄÇ

 so we can maybe also add that here„ÄÇSo NÔºå NÔºå CÔºå HÔºå W„ÄÇOkay„ÄÇ

 and the discriminmat is a little bit simpler here„ÄÇ it's just receiving the input image„ÄÇ

 which has the flattening here and then returns the logicits for the predictions that this is a real image„ÄÇ

OkayÔºå so then we initialize so this is our model„ÄÇ I will show you the training loop in a few moments„ÄÇ

 then one more thing is yeah we are initializing our model and then here we are initializing our optimizers„ÄÇ

Here is one important aspect„ÄÇSo first I'm using Adam for both„ÄÇ

 Some people recommend using S GD for I think the generatorÔºå I tried different things„ÄÇ

 This happened to be„ÄÇThe best working version that I could get„ÄÇ

 So you may find better settings in the next video I will go over some tricks„ÄÇ

 but this happened to work well for me„ÄÇ took me a long time to find anything that worked at all„ÄÇ

 anywaysÔºå so one important thing here is that of course„ÄÇ

 we use the generator learning rate for the generator and the discriator learning rate for the discriinator„ÄÇ

 but the more important thing is that we also use the right parameters here„ÄÇ

So we have an optimizer for the generator that should only update the generator parameters„ÄÇ

And the disc it„ÄÇHere„ÄÇShould only update the discriator parameters if we had something like this„ÄÇWell„ÄÇ

 this would not work well in practiceÔºå because then it would„ÄÇWhen we take a step„ÄÇ

Here for the optimizerÔºå it would update both the discriator and the disc generator„ÄÇ

 And this is not what we want„ÄÇ So because„ÄÇIf I go back to my slides a long time ago„ÄÇ

 but in the first videoÔºå I think talked about this„ÄÇMight be the second video„ÄÇ So we train„ÄÇ

Let us screen it up first„ÄÇWhile we keep the generator frozen whenÔºå when it gets there„ÄÇFake images„ÄÇ

 So we only train the discriatorÔºå and then we freeze the discriator and only to train the generator„ÄÇ

 So in order to achieve that„ÄÇWe have these two different optimizers where we for one optimizer„ÄÇ

 only train the generator where here the discriator remains frozen and here we only train the discriator where the generator remains frozen„ÄÇ

And then we have the training function hereÔºå so I have this in a helper file because then I can reuse it across my different notebooks„ÄÇ

 Let me open this here„ÄÇSo should probably at the bottom because it was the last thing I implemented„ÄÇ

 So here this is my training„ÄÇ So this is a training I'm using here„ÄÇ

 So let me now explain how the training looks like„ÄÇ First of all„ÄÇ

 we are using binary cross entropy with logics„ÄÇ Why it's because we have„ÄÇ

The output here is the logics„ÄÇAnd„ÄÇThenÔºå we are sampling„ÄÇSo we are sampling in each„ÄÇSo for sorry„ÄÇ

 we are generating here a fixed noise vector„ÄÇ I'm calling it fixed noise because we are reusing that one to monitor the progress during training„ÄÇ

 This will become clear after the epochs„ÄÇ So for nowÔºå maybe ignore this part„ÄÇ

 let's focus here on the epochcateeration during the training„ÄÇ

 So for each epoch and the number of epochs we want to train„ÄÇThis is the same as before„ÄÇ

 like in any neural network we trained before„ÄÇ Now here we just get the batch size as a variable so it will be easier to read and„ÄÇ

HereÔºå we are only concerned with the real images„ÄÇ We don't need the labels„ÄÇ Usually„ÄÇ

 we had something like the labels hereÔºå but we are not using them„ÄÇ So I'm just using an underscore„ÄÇ

 in Python„ÄÇ The underscore is just like a indicator that this variable is not used„ÄÇ

So here we have the real images„ÄÇ and now we create our real labels„ÄÇ So the real labels are once„ÄÇ

 So here real„ÄÇReal is equal to one„ÄÇAnd fake is equal to 0„ÄÇSo we create our real labels here„ÄÇ

Now we also generate fake images„ÄÇ This is for the discriminator training„ÄÇ

So we create them from noiseÔºå rightÔºå so here I have a random normal distribution„ÄÇ

I have my batch size„ÄÇ So if I haveÔºå let's sayÔºå64 real images I'm creating now 64 fake images as well„ÄÇ

And these are from a noise vector„ÄÇ That's the latent dimension here„ÄÇ So if I go back to my slides„ÄÇ

 this is this noise„ÄÇSorryÔºå this noise vector here sampled„ÄÇFrom a„ÄÇRandom normal distribution„ÄÇ

 You can also use a random uniform distributionÔºå but practically in practice random normal„ÄÇ

 is that Gaussian works better„ÄÇ So this isÔºå let's say if we have a 100 dimensional embedding„ÄÇ

 this would be a 100 dimensional vector„ÄÇ So by defaultÔºå I said it„ÄÇTo 100Ôºå I thinkÔºå here„ÄÇ

I didn't set it hereÔºå let me see„ÄÇÂì¶„ÄÇYeahÔºå set the latent dimension to 100 here„ÄÇ

This will create a 100 dimensional vector„ÄÇ And here I'm reshaping it to an image format„ÄÇ

 So it's format„ÄÇAnd„ÄÇSo this is sorry„ÄÇ I was actually here„ÄÇ

 but the fixed size vector is created the same way„ÄÇ So it's a format N color channels H W„ÄÇ

Where what's the other one„ÄÇHere„ÄÇSoÊàë„ÄÇWe are sampling from this random normal distribution with 100 latent size„ÄÇ

 This is our color channels because I implemented that with the convolutional autoenr generator first„ÄÇ

 and then I did the fully connected one„ÄÇBut this one gets reshaped„ÄÇThis gets reshaped„ÄÇHere„ÄÇ

 so that it will also work with a fully connected layer„ÄÇ So you don't have to worry about this„ÄÇ Okay„ÄÇ

 now we are generating these fake images from our noise vector„ÄÇWe are calling generator forward„ÄÇ

 This will generate our fake images„ÄÇAnd then we will create our fake labelsÔºå which are0„ÄÇSo„ÄÇ

 fake relas„ÄÇNbel is one„ÄÇAnd fake labelÔºå this label is 0Ôºå right„ÄÇThis is our fake label„ÄÇ

 and we will also create our flipped fake labels„ÄÇ So this is our trick that we discussed„ÄÇ

Where was itÔºå we discussed that„ÄÇHereÔºå where we had our flipped„ÄÇLabels„ÄÇSo the flipped labels„ÄÇ

 flipped fake labels are the real labelsÔºå so„ÄÇHere„ÄÇüòîÔºåÂïä„ÄÇOkayÔºå let's do this real„ÄÇÂèØ‰ª•‰∏ç„ÄÇüòî„ÄÇ

Faith label here„ÄÇThink label is one„ÄÇThis is that we use for fooling the discriinator when we train the generator„ÄÇ

NowÔºå we are training the discriminator here„ÄÇFirst„ÄÇLike alwaysÔºå we0 the previous gradients of the„ÄÇ

Model of the discriminator„ÄÇThis will only do that for the discreteator ones„ÄÇAnd hereÔºå so hereÔºå again„ÄÇ

 we generated the data for training„ÄÇ And here we carry out the actual training„ÄÇ

 So what we do is we now„ÄÇGet the predictions„ÄÇ These are the lots„ÄÇ

And the logicits would be in the form„ÄÇN times„ÄÇÂóØ„ÄÇSometimes oneÔºå right„ÄÇ So we convert that just to n„ÄÇ

Instead of having n times 1Ôºå we just convert to nÔºå it will be just a vector„ÄÇ

Instead of an end by one matrixÔºå just easier to handle„ÄÇ We are just removing the last image„ÄÇ

 I could have also done a squeeze here„ÄÇIt's maybe easier„ÄÇüòîÔºåIt doesn't matter„ÄÇOkay„ÄÇThen hereÔºå we have„ÄÇ

The loss„ÄÇThe loss for the real images„ÄÇ So we want the disc screenator to predict real„ÄÇ

 So how we compute the loss is as the loss function again is if we don't specify anything„ÄÇ

 it's the binary cross entropy with logics„ÄÇ So we have„ÄÇ

Prediction logics that's from the discriminator„ÄÇ And this is the real labeled„ÄÇ So these are the ones„ÄÇ

 So weÔºå these are the labelsÔºå the ones„ÄÇ And we want this also to become one„ÄÇ So this is the loss„ÄÇ

To predict oneÔºå given that the labels are one„ÄÇSo the real images„ÄÇAnd then we do the fake images here„ÄÇ

 it's the same„ÄÇAs beforeÔºå except„ÄÇNowÔºå that„ÄÇWe have„ÄÇ

The predictions for the fake images they were obtained on the fake images here„ÄÇ

 And here I have the detaach because otherwise it will influence the generator gradient„ÄÇ

 It's complaining about that„ÄÇ So I'm just detaching it from the generator graph„ÄÇ

 because I could have„ÄÇProbablyÔºå yeahÔºå noÔºå it's fine„ÄÇSo yeahÔºå it's fake images„ÄÇ

Retaching it from the graph„ÄÇ So I'm not optimizing the generator hereÔºå right„ÄÇ

 The generator is frozen„ÄÇAnd then I'm computing the loss here„ÄÇ

The fake prediction with the fake labels„ÄÇAnd„ÄÇThese are so fake labels are0„ÄÇ

 and we want to make them 02„ÄÇSo againÔºå we are just using binary cross entropy between labels„ÄÇ

 we just want to„ÄÇMake these labels similar to these labelsÔºå the ones„ÄÇ

 and we want to make the fake prediction similar to the fake labelsÔºå which are the zeros„ÄÇThen„ÄÇ

 I meanÔºå we could technically back propagate here and here„ÄÇ

 But instead of calling backwardwater twiceÔºå it's more efficient to just„ÄÇ

Add them together here and then call back what once„ÄÇ

So I'm just combining the loss on the real labels and the fake labels„ÄÇ

 So I'm combining that from here and hereÔºå adding it up„ÄÇ It's actually not necessary to have the 0„ÄÇ5„ÄÇ

 but why not And then call the backward„ÄÇ and then we update the discriminator„ÄÇ

 So this whole thing is training the discriminator„ÄÇNowÔºå we are training the generator„ÄÇ

So we are now using the flipped labels„ÄÇSo„ÄÇHere we obtain now the predictions on the fake images„ÄÇ

RightÔºå same as before„ÄÇ So this is the same„ÄÇAs before„ÄÇ But now we are using the the gradients„ÄÇ

For the generator„ÄÇWe want to keep the gradientsÔºå so I'm not detaching anything here„ÄÇ

And then I'm computing the loss between the fake predictions and the flipped fake labels„ÄÇ

 So the flipped fake labels are oneÔºå rightÔºå If I go up againÔºå they are one„ÄÇAnd here„ÄÇThe prediction„ÄÇ

So the discreator will output if it's a good discreminator will output to 0„ÄÇBut we want to fool it„ÄÇ

 so we wanted to output a one„ÄÇBut we are not training the discriminator here„ÄÇ

 We are training the generator here only„ÄÇ That's why we are using optimize the generator hereÔºå right„ÄÇ

And this is also why I'm not detaching anything here„ÄÇ It's the disclaimer here remains frozen„ÄÇ

 We are only updating the generatorÔºå because when I go back„ÄÇHere„ÄÇ

We have only the generator parameters in our optimizer for the generator„ÄÇ

 so we are only updating the generator hereÔºå not the discriminator and the generator will be updated such that in the next iteration it will be better at fooling the discriminator here to output onces because the ones will be then similar to these ones here„ÄÇ

 So it's trying to make these similar„ÄÇAlrightÔºå so this is essentially how things work„ÄÇ

And then the rest is just logging purposes„ÄÇJust printing some resultsÔºå saving some results„ÄÇ Oh„ÄÇ

 maybe one more thing I wanted to mention is„ÄÇI mentioned earlier I had this fixed noise hereÔºå rightÔºü

 So why am I using the fixed noiseÔºå I'm actually using that in each epoch„ÄÇ So if I scroll down again„ÄÇ

 So in each epoch hereÔºå I am using my fixed noise„ÄÇAnd make a prediction„ÄÇ

And then I'm saving my image gridit to just the lists I have„ÄÇList here„ÄÇ

 just I call this images from noise per epoch„ÄÇ and I'm appending to this list„ÄÇ

 and then we can take a look at the generated images during training„ÄÇOkayÔºå so let me go to my„ÄÇ

Training here„ÄÇ So this is training„ÄÇSo you can see the generator discriminator losses here„ÄÇ

 so they start out pretty balanced and they keep kind of balanced„ÄÇ

 but honestly looking at this is not very informative except that you don't want to have one going to0 and one going really high„ÄÇ

 but other than that it's really hard to tell just by looking at these numbers whether it's training well or not you want them to be not going crazy„ÄÇ

 you don't want to like I said going them going to really infinitely high or become zero„ÄÇ

 but except that usually there's not that much information you can gain from looking at this okay trained for 100po„ÄÇ

And then yeahÔºå here's a loss function„ÄÇ So sorryÔºå loss plot„ÄÇ

 I saved everything in this locked dictionary„ÄÇ and then we have the is greaterator loss per batch and generate loss per batch„ÄÇ

 which I'm showing you here„ÄÇ So kind of„ÄÇThey are pretty stable hereÔºå actuallyÔºå that's actually good„ÄÇ

ÂóØ„ÄÇOs somehowÂ•ΩËØ∂„ÄÇÂïä„ÄÇI don't think I can fix it here because I didn't run it„ÄÇ

 but it should have been epoch„ÄÇ so that's why it's not showing„ÄÇThis year was 100 epochsÔºå anyways„ÄÇÂóØ„ÄÇ

And then the visualizationÔºå iss the more interesting part„ÄÇ

 So here I'm visualizing these generated images per epoch„ÄÇ and then the last one„ÄÇ

I'm not sure if this is necessary„ÄÇüòîÔºåCould have„ÄÇüòîÔºåAdd it X row„ÄÇPlusÔºå5 here„ÄÇAnyways„ÄÇWass just lazy„ÄÇ

 just copy and pasting„ÄÇ So this is just train So plotting from the fixed noise„ÄÇ these images„ÄÇ

 So you can see the generated images at epoch 0„ÄÇ So at the beginning„ÄÇ

 the generator is not able to produce anything useful„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_7.png)

![](img/5049c02cf602d62e3419b206a736cae4_8.png)

You see that here„ÄÇThen after Epoch 5Ôºå things look a a little bit better„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_10.png)

U book 10„ÄÇ15„ÄÇüòî„ÄÇ

![](img/5049c02cf602d62e3419b206a736cae4_12.png)

20 so forth„ÄÇ you can see it becomes better and better„ÄÇ Now you can even see these7s„ÄÇ This is a9„ÄÇ

 So actually things look very good„ÄÇ So let's scroll down to the bottom„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_14.png)

![](img/5049c02cf602d62e3419b206a736cae4_15.png)

Okay this is last epoch„ÄÇ

![](img/5049c02cf602d62e3419b206a736cae4_17.png)

So you can see I didn't really improve that much„ÄÇ You have now issues like here and here„ÄÇ

 So training it for longer might not„ÄÇ

![](img/5049c02cf602d62e3419b206a736cae4_19.png)

ImproveÔºå but it's actually given that this is a very simpleÔºå fully connected G„ÄÇ

Images look quite reasonable„ÄÇ So not all of them look greatÔºå of courseÔºå but„ÄÇWellÔºå it's not terrible„ÄÇ

 I meanÔºå itÔºå it's learning somethingÔºå rightÔºå if you compare to the first„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_21.png)

Apochs„ÄÇ

![](img/5049c02cf602d62e3419b206a736cae4_23.png)

HereÔºå it is learning somethingÔºå rightÔºü

![](img/5049c02cf602d62e3419b206a736cae4_25.png)

So yeahÔºå this is our first G and training Gs is tricky to be honest„ÄÇ

 so in the next video I will go over some tips and tricks for training GNs„ÄÇ



![](img/5049c02cf602d62e3419b206a736cae4_27.png)