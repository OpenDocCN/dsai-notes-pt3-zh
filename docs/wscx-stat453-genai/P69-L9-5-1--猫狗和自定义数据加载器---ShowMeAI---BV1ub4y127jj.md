# P69ÔºöL9.5.1- Áå´ÁãóÂíåËá™ÂÆö‰πâÊï∞ÊçÆÂä†ËΩΩÂô® - ShowMeAI - BV1ub4y127jj

YeahÔºå let's now talk about cats and dogs and custom data loaders„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_1.png)

I should say I just edit cats and dogs to make this a little bit more interesting because I can imagine if you just read data loads or custom data la„ÄÇ

 it doesn't sound so exciting by itself„ÄÇSo I was like using that just to get you attention„ÄÇ

 But in any case„ÄÇ So here what I'm showing you is indeed cats and dogscs classifier„ÄÇ

 I trained from a Keaggel dataÔºå So he had trained a VG G16 convolutional network that we will be discussing later in the convolutional network section or lecture„ÄÇ

 So here this is yeahÔºå think of it as just a neural network for the sake of having a model here that performs yeah„ÄÇ

 reasonably well on a more complicated data„ÄÇAnd then in order to fit this model„ÄÇ

 I downloaded this data set from Keegel containing cats and Docs images„ÄÇ

 but I needed to yeah create a custom data loader for that and in this video I will show you how you can create a custom data loader I will be using a simpler data though because then you don't have to download such a large cats and Docs data„ÄÇ

You will be or you can actually get this though and download it so I have the code link here and if you're interested you can download it from here„ÄÇ

 or here I at least have the instructions how to download it and I also have this model there„ÄÇ

But yeah I wanted to before I show you the custom data loadÔºå I wanted to make a few more points„ÄÇ

 So here I'm showing you the training loss and accuracy„ÄÇ So actually this should be„ÄÇ

The accuracy here on this axis„ÄÇDon't want to hide the 90 here„ÄÇ

 And let's focus on the left hand side first on the cross entropy so you can see„ÄÇ

During training that the training loss goes down as expectedÔºå This is something you want to see„ÄÇ

 but you can see„ÄÇI'm using a validation set and for the validation set„ÄÇ

For each epoch I evaluate on the validation set and you can see that here the yeah the loss does not go down„ÄÇ

 So at first it goes downÔºå but then it stagnateates„ÄÇ So in this case„ÄÇ

 we don't make any further improvement on the validation set while„ÄÇ

It continues to improve on the training set„ÄÇ So here we can see there is overfitting„ÄÇGoing on„ÄÇ

 So even if I train longerÔºå I may still not be able to improve the model„ÄÇOn the right hand side„ÄÇ

 that's the same for accuracy„ÄÇ but yeahÔºå the accuracy is usually you can think of it as the cross entropy as inverse surrogate for the accuracy„ÄÇ

 So it behaves similarly here„ÄÇ So you can see the accuracy goes up continues to go up let's maybe even yeah I say maybe„ÄÇ

Let's sayÔºå 97% even„ÄÇBut you can see for the validation set„ÄÇ

 it goes up and then it tends to stagn it maybe year at„ÄÇI'll just say somewhere here„ÄÇüòî„ÄÇ

Let's say maybe 88 perÔºå something like that„ÄÇI then also evaluated the performance on an independent test set after the training has completed on that training a test set I also get 88%„ÄÇ

 so maybe approximately like the validation setÔºå which is kind of expected„ÄÇSo„ÄÇYeah„ÄÇ

 what we can see here is extensive overfitting and„ÄÇHere„ÄÇ

 the validation set gives us orient indicator of that„ÄÇ

 so we don't have to use our final test set necessarily„ÄÇ

 We can already see based on the validation set that is's overfitting„ÄÇ

 So the test set should only be used ideally one time in the endÔºå it should be kept independent„ÄÇ

 So if you want to tune your model„ÄÇYou can do this entirely on the training validation set if you tune your model a lot„ÄÇ

 if you change a lot of hyperparmeters and do a lot of tweaking„ÄÇ

 you may find that the validation set performance is actually a little bit better on the training set and or sorry during training so when you evaluate it but then„ÄÇ

It's not as good it's better actually sorry it's better than the test set because you will see that if you tune your model a lot„ÄÇ

 you will also slightly overfit to this validation set„ÄÇ

 Of course you don't use your validation set for model training right so you don't fit the model on that data you only use it to evaluate it during model training„ÄÇ

 howeverÔºå just by chance you may end up picking a model that just performs well on the validation set due to chance and then you have this effect of overfitting so„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_3.png)

In any case the procedure I outlined using training set validation set and a test set for the final evaluation is near the common approach in deep learning in regular machine learning we tend to use Kfold cross validation„ÄÇ

 but it's a little bit too expensive for deep neural networks„ÄÇ

And also because we have large data set sizesÔºå like usually large validation and test sets„ÄÇ

 that's also usually okay„ÄÇYeahÔºå what is a good ratio when we use the training validation and„ÄÇ

testest setÔºå I thinkÔºå I meanÔºå it's relatively important to have a relatively large test set to get a reliable performance estimate„ÄÇ

AlsoÔºå it's useful to have a lot of data because we've seen in the previous video the more data usually the better„ÄÇ

 So in that way I would say make the validation set the smallest„ÄÇ

 It's still important because it gives you an idea of the model performance during training„ÄÇ

 but it's not as important as let's say the test set or the training set„ÄÇ So personally for example„ÄÇ

 I would do something like 80% training data 5% validation data and 15% test data„ÄÇ

 but you can of course also change it„ÄÇ you can make it 85Ôºå5 and 10 or something like that„ÄÇ

 So it really kind of depends also„ÄÇThere's no real correct way of doing that„ÄÇ

 It's usually something approximately around these values„ÄÇSo yeah„ÄÇ

 just to summarize the training set is used for training„ÄÇ

 and it is not necessary to plot the training accuracy during trainingÔºå but it can be useful„ÄÇ

 So you don't have to do the plots during trainingÔºå rightÔºå But I find it useful to look at it„ÄÇ

Because then I can see based on the validation and training accuracy curves„ÄÇ

 how much I'm overfitting„ÄÇSo the validation set yeah provides a rough estimate of the generalization performance„ÄÇ

 It's kind of like the test set„ÄÇ but because we use the validation set a lot and we choose hyperparameter such that the model performs well on the validation set„ÄÇ

 it's it's not truly independent anymore„ÄÇ and we have an optimistic bias here„ÄÇ

 So from the validation set on the validation set would usually report a model performance that is slightly better„ÄÇ

Then the model would perform on„ÄÇTruly unseen data„ÄÇYeahÔºå and like I said„ÄÇ

 the tester should only be used once to get an unbiased estimate of the generalization performance„ÄÇ

 So this is like really in model evaluation in a nutshell in like a minute„ÄÇ

 So like I recommend in the previous video if you want to know more details„ÄÇ I recommend the article„ÄÇ

 I link thereÔºå I will also link it again on canvas„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_5.png)

So yeah here's how it looks like you don't have to make plots also usually when I train a model„ÄÇ

 especially if I do that on a serverÔºå I just print„ÄÇ

These values like the training accuracy and the validation accuracy„ÄÇ

 and let to train and then after training I would print the test accuracy„ÄÇ

There are multiple tools that can help you to monitor„ÄÇModel training during yeah during training„ÄÇ

 So to take a look at these curves in real time it yeah it requires some setup because yeah„ÄÇ

 we have so many important topics to cover in this class I won't go into too much detail because it's like I would say more like an engineering thing like like a software engineering thing„ÄÇ

 So after you understood the basics of deep learning and are familiar with Pythhor„ÄÇ

 you can yeah add more tools to your tool belt and explore additional tools„ÄÇ

 I don't want to cram too many tools into your tool belt right now„ÄÇ

 you can but if you're interested you can explore them on your own like after class or for your projects„ÄÇ

 So some tools are for example„ÄÇThere are nice R M L flow„ÄÇ and there are others„ÄÇ And yeah„ÄÇ

 these allow you also to plot yeah performance values during training in a plot interactively„ÄÇ

 There's also„ÄÇTs are bought„ÄÇAnd Tensor board is originally for TensorFlow but it's also compatible now with Pyth and also a lot of people use Tensor board so you can maybe look at these two tools but of course there are more„ÄÇ

 these are really only the two that spontaneously come to mind but if you are interested I can also share a list of more of those tools„ÄÇ

In any caseÔºå so now just before we get to the code in the next video„ÄÇ

 just a few more things to mention there are„ÄÇParameters and hyperparmeter„ÄÇ So just to recap„ÄÇ

Parameter are parameters like the weights and the biases in the model that are trained or learned from the training data„ÄÇ

 So that's what the model learns via back propagation„ÄÇHoweverÔºå there are hyperparmeters„ÄÇ

 and I haven't used this work yet„ÄÇ SoÔºå ohÔºå I havet used this wordÔºå but I haven't explained it yet„ÄÇ

 I think so hyperpars you can think of them as„ÄÇTuning„ÄÇPerrameters„ÄÇ

So students who have taken 451 have encountered this in the context of k nearest neighbors as the number of neighbors and so forth here we have different hyperparmeter„ÄÇ

 So here these tuning parameterss areÔºå for exampleÔºå the mini batch size way we normalize the data„ÄÇ

 for exampleÔºå I mean mix scaling standardization just dividing it by a constant and many different ways we can normalize data and hyperparmeters are really parameters you as the person who sets up the model you have to choose them yourself and you have to try them out and practice and see what performs better„ÄÇ

 there's no way let's say we can use back propagation to learn these„ÄÇ I mean„ÄÇ

 there are maybe some tricks or something but usually this is something„ÄÇ

That is set up by the person who yeah implements the neural networks„ÄÇ For example„ÄÇ

 the number of epochs can also be considered as a hyperparmeter or the number of hidden layers„ÄÇ

 The number of hidden unitsÔºå everything really that affects the performance of the final model the learning rate to some extent also the random seat„ÄÇ

 So the random seat is something you probably shouldn't tune„ÄÇ

 but there are sometimes random seats that don't produce are good models because the initial starting weights are really bad„ÄÇ

 So sometimes so usually I recommend„ÄÇIf you want to report the final performance of a model you present a model„ÄÇ

 I would recommend to run your model at least three or five times with different random seats and then average over the results„ÄÇ

And then you can also assure the standard deviation or even confidence interval„ÄÇ

We have the loss functions the hyperparmeter„ÄÇHere various weights in terms of weighting terms you can weight certain examples more heavily than others in the loss function„ÄÇ

 the activation function like syigmoidÔºå a logistic syigmoid 10 H or Relu and so forth„ÄÇ

 regularization schemes We will talk about that in the next lecture weight initialerialization schemes and optimization algorithms„ÄÇ

 These are all things we will cover in the next three lectures„ÄÇ

So here there are really no good ways to choose these„ÄÇ yeahÔºå I would say„ÄÇ

Maybe there are some ways nowÔºå but I would so based on meta learning„ÄÇ

 you can train your model on different dataset sets and you can see what performs well how how you set up your model so that it performs well on different data sets„ÄÇ

 but in the grand scheme of thingsÔºå it's something you still have to experiment with so„ÄÇ

But I'm saying it there's no kind of scientific explanation for why or no no theory or theorem„ÄÇ

 why certain parametersÔºå Hys should work better than others„ÄÇ

 So what we have to do is we have to try many things„ÄÇThere's this jokeÔºå probably like„ÄÇ

Because of gradient descentÔºå people call this graduate student descent because graduate students usually„ÄÇ

 yeah unfortunately have to spend a lot of time tweaking these things„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_7.png)

These hyporoas„ÄÇ AllrightÔºå so here has actually a nice visualization of Pytorch data order„ÄÇ

 how it works conceptually„ÄÇ I just saw it the other day„ÄÇ

 and I thought it might be fun to include it in the video because it's really a nice summary of how things work„ÄÇ

 So I saw this here on TwitterÔºå original link„ÄÇ But yeahÔºå let's just play the video here„ÄÇüòä„ÄÇ

So you can see„ÄÇOhÔºå sorryÔºå let me stop it first„ÄÇ let me explain first„ÄÇ And then I start the video„ÄÇ

 So on the left hand sideÔºå you are shown the inputs and the labels in the data set„ÄÇ

 So this is your dataset set„ÄÇ Then are certain transformation methods„ÄÇ

 We will cover this in detail when I show you the data lot in action„ÄÇ

And there is a sampler and the batch sampler„ÄÇ So the sampler sample one pair of inputs and labels at a time„ÄÇ

 The batch sampler yeah samples them for a batchÔºå and then the collate function combines them to a mini batch that we can use in the model„ÄÇ

 So let's play this again„ÄÇSo you can see the inputs enableds go through the transform and through the sampler and get collected in this batch sampler„ÄÇ

 Once we have a batch readyÔºå it goes to the col function and it produces the batch of inputs and batch of labels„ÄÇ

 And then yeahÔºå it does the next batch and you can see„ÄÇHere it's sampled without repetition„ÄÇ

 So each sample is used exactly once also each pair of inputs and labels„ÄÇ

 And then yeah once we are finishedÔºå we finished the epoch and then there will be another epoch„ÄÇ

 So you can see there are also chosen randomly here„ÄÇSo it's basic equivalent to shuffling„ÄÇ

So then the last batch here„ÄÇAlrightÔºå yeahÔºå so and then you would do the whole thing again„ÄÇ

 But of courseÔºå yeahÔºå you would choose them in a different order if you haveÔºå there's a parameter„ÄÇ

 It's called shuffle„ÄÇ If you have shuffle enabledÔºå it will choose them in a different order then„ÄÇ

YeahÔºå this is conceptually how the Pytch loadout works„ÄÇ So here's how it looks like in code„ÄÇ

 and yeah I actually I think I should make a separate video and walk you through this in the Jupyter notebook it will be a little bit better to explain compared to walking you through it here on the screenshot„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_9.png)

So just to wrap up the slides before we go to the last video of this lecture to the code example„ÄÇ

 So we have now the good news that we can solve London nonlinear problems„ÄÇ That's great„ÄÇ

 right howeverÔºå now we have the bad news that is that our multilayer neural networks now have a lot of parameters„ÄÇ

 And yeahÔºå it's easy to overfit the data„ÄÇ So in the next„ÄÇüòä„ÄÇ

Next year we will talk about techniques like regularization techniques to help prevent overfitting„ÄÇ

 so here's a simplified example of how that might look like„ÄÇ So if we have„ÄÇ

 for example a model in the center here that is maybe too complicated and doesn't generalize well to new data then here on the right hand side there is a model that is slightly simpler we can make it even more simple like just as linear decision boundary„ÄÇ

 but this is not sufficient here to distinguish between these crosses and circles„ÄÇ

 so there is usually„ÄÇA good compromise between a model that is„ÄÇ

 let's say overfitting It has high variances or a model that is underfitting that has high bias„ÄÇ

 So regularization helps to simplify decision boundaries in a certain way„ÄÇ

 if you think of it as if you think about it visually but yeah„ÄÇ

 we will talk more about that in the next lecture„ÄÇ So in the last video or the next video„ÄÇ

 I will show you the custom data order and practice„ÄÇ



![](img/fac9c108eb4e9b18697c04e5ef2d6249_11.png)