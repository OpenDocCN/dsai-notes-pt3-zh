# P70ÔºöL9.5.2- PyTorch ‰∏≠ÁöÑËá™ÂÆö‰πâÊï∞ÊçÆÂä†ËΩΩÂô®(‰ª£Á†ÅÁ§∫‰æã) - ShowMeAI - BV1ub4y127jj

YeahÔºå let's not talk about Pytor custom data loader„ÄÇ

 So the data loader is a class and Pythtorch that lets usÔºå yeah„ÄÇ

 a lot of data more conveniently compared to doing it manually„ÄÇ I will show you two notebooks„ÄÇ

 One is yeah just the data loader itself with a simple example„ÄÇ

 and then I will show you how we can use it in a yeah model training context„ÄÇ

So yeah what I should say is I'm actually using MNIS here and you may wonder why MN because there is already MNT data set and data lot are implemented in Torch Viion which we could technically import which is what we have done in the yeah last couple of videos so the reason is MNIS is relatively small and yeah in this way I can upload it to GitHub so I can upload this without let's say taking too much space in that repository and it's also for you faster to download and just convenient„ÄÇ

Because you are already familiar with itÔºå but of course here Mnes this represents a more general data„ÄÇ

 so think of it as an arbitrary data consisting of P andG files„ÄÇ

So what I've done is I yeah divided Mnest„ÄÇAnd do three partsÔºå a training set„ÄÇ

 a validation set and a test set„ÄÇSo I put them here into yeah PN G filesÔºå just in each folder„ÄÇ

 there's a set of PN G filesÔºå as you can see here„ÄÇAnd„ÄÇI have also corresponding on CV file„ÄÇ

 So here in the CV fileÔºå I have the class tables„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_1.png)

And the file name„ÄÇOf courseÔºå you can alsoÔºå if you likeÔºå you can have only one„ÄÇ

Folder with P And G files and then have a column with validation train and test index so you can also specify it like this„ÄÇ

 I meanÔºå how you set it up is up to you„ÄÇ I sometimes find it convenient to do it like this„ÄÇ

 Sometimes I only have one gigantic P And G file folder and keep track of what is training what is validation with this test„ÄÇ

 I keep track of it with columns in the C file„ÄÇ But this is really optional„ÄÇ I mean„ÄÇ

 how you want to set up is up to you„ÄÇ You can set it upÔºå however you like„ÄÇ

 and I will show you how we can then handle that with Pyhar data class„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_3.png)

So back to this notebook I showed you nowÔºå I have these files so focus now only on these three folders and these these V files„ÄÇ

 the help a functionÔºå I will use them later in this train model notebook„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_5.png)

So yeahÔºå let's get started„ÄÇ So usually when I have a new dataset what I do first is I inspect this dataset„ÄÇ

 So I sometimes use I use image IO„ÄÇ Sometimes I just use the Python image library I'm not very consistent„ÄÇ

 It doesn't really matter the are multiple libraries and Python that lets you open a P and G file or JpeEC file in Python itself„ÄÇ

 and then you can take a look at it„ÄÇ So here I'm using P it's the Python imaging library„ÄÇ

 If you have to install it„ÄÇ I think you have to do install„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_7.png)

Hello„ÄÇWhy pillow and not wipe„ÄÇPill or PL„ÄÇ That is because the Python imaging library„ÄÇ

 I think it got abandoned at some point„ÄÇ And then some people forked it on Gitthub to further maintain it„ÄÇ

 And this fork is called pillow„ÄÇ But even if you install it as pillow the import is identical„ÄÇ

 you use this one to import it„ÄÇ or here in particular„ÄÇ

 we are only implementing the importing this image class„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_9.png)

So here I'm just looking at the image„ÄÇ So here„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_11.png)

I'm loading one data point or one image from this Mest train folder„ÄÇ why C map binary„ÄÇ Yeah„ÄÇ

 because colour maps by default is this verus colour mapÔºå which is kind of useful for heat maps„ÄÇ

 But yeah here maybe it looks a bit goofy if we have these colors for Ms„ÄÇ

 So here we use just this version„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_13.png)

![](img/363ca9888bed55788c258cb6b3103f4e_14.png)

AlrightÔºå yeahÔºå alsoÔºå I find it helpful to just take a look at the image dimension„ÄÇ

 So here it's 28 by 28„ÄÇ There is no colour channel„ÄÇ And you can see the values„ÄÇ

 the pixel values are between 0 and„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_16.png)

![](img/363ca9888bed55788c258cb6b3103f4e_17.png)

![](img/363ca9888bed55788c258cb6b3103f4e_18.png)

255„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_20.png)

ItCould be 254„ÄÇ I'm not actually not quite sure here actually I see the the highest one is 253„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_22.png)

AlrightÔºå so then looksÔºå okay„ÄÇ So we nowÔºå know what we are working with„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_24.png)

![](img/363ca9888bed55788c258cb6b3103f4e_25.png)

Let's know„ÄÇlot the CV files„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_27.png)

padasÔºå and then I'm loading my CV files„ÄÇ So these are only the first five rows with this head command„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_29.png)

![](img/363ca9888bed55788c258cb6b3103f4e_30.png)

YeahÔºå and I can also show youÔºå ohÔºå you can see it right here„ÄÇThe dataset is„ÄÇ

 yeah only made it artificially small„ÄÇ There are only 256 images in each dataset set„ÄÇ Mnes is„ÄÇ

 of courseÔºå much bigger„ÄÇ It's usually I think 50000 in the training set and 10000 a test set here„ÄÇ

 I just made it smaller because I'm going to upload this to Github so you can download it„ÄÇ

 And in this way it's not like too much taking up too much space there„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_32.png)

![](img/363ca9888bed55788c258cb6b3103f4e_33.png)

OtherwiseÔºå I don't want to upload 50000 small filess and stuffÔºå you knowÔºå AlrightÔºå so here„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_35.png)

Here's our interesting part now„ÄÇ that's the data set class and Pythtorch„ÄÇ

 and so in order to do to use the data la we need a data set so there are two parts„ÄÇ

 one is the data and one is the data laÔºå So let's talk about the data first because that's what we need for making the data la„ÄÇ

 So here the data is really how we read the data„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_37.png)

![](img/363ca9888bed55788c258cb6b3103f4e_38.png)

So this is something you yeah have to set up yourself or a new dataset„ÄÇ

 So here this is from Pytorch Torch U data„ÄÇ This is yeah something a class from Pytorch„ÄÇ

 and here this is called class inheritance in Python„ÄÇ

 So we are inheriting certain features from dataset so that they are available in all our dataset„ÄÇ

 So it's called class inheritance„ÄÇ It's like a not a PytorchÔºå but a Python concept„ÄÇSo„ÄÇ

 and then we are defining our own dataset setÔºå I'm just calling it my dataset set„ÄÇ

 but you can call it whatever you like„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_40.png)

And then like in every classÔºå we have an init method„ÄÇ And again„ÄÇ

 in this constructor and this init methodÔºå I'm specifying certain things„ÄÇIt's basically by the way„ÄÇ

 arbitrary what I put hereÔºå it's not required to put anything here„ÄÇ

 but on what we need here because we have CV files and we have foldersÔºå I put both the CV path„ÄÇ

 the path to the CV fileÔºå let's say the training CV and the image directoryÔºå for exampleÔºå here„ÄÇ

 this directory„ÄÇAnd there's also a transform for doing a custom image transformation„ÄÇ

 I will show you just a very basic transformation„ÄÇ ActuallyÔºå we' are not doing any transformation„ÄÇ

 I will talk about this in the next lecture„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_42.png)

YeahÔºå so what's going on here is in the in„ÄÇ in the unit„ÄÇ

 we are loading the CCV file and keep it attached to the data loaddown„ÄÇNotÔºå no„ÄÇ

 we don't need it attached We one secondÔºå so„ÄÇWe lot the CV file„ÄÇ

 We save the image directory to the self dot image dear attribute so we can use it later„ÄÇ

 and then we save the image names as self do image names„ÄÇ

 And this comes from the CV file from the file name column„ÄÇ So if I scroll up again„ÄÇ

 this is this column we just save this column here„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_44.png)

![](img/363ca9888bed55788c258cb6b3103f4e_45.png)

And then we also save the class label column itself dot y„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_47.png)

These sell class labels„ÄÇ And then we just store whatever we provide a transform here„ÄÇ

 So this is a setup for the data set when it's created„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_49.png)

And hereÔºå this is how a data point gets loaded„ÄÇ a single data point„ÄÇ

 Remember that this one was in short you the animation loading a pair of„ÄÇ

Or a data point with its training labelÔºå basicallyÔºå So one image and one label„ÄÇ

 So that's what we are what's loaded with us get item here„ÄÇ

Here you have to have this index here I in there other waysÔºå but I find it convenient with the index„ÄÇ

And then we have to specify„ÄÇ So what we do is here we specify how we obtain one image and one corresponding label„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_51.png)

So how do we open the imageÔºå So image that open So this is similar to what I used„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_53.png)

Up here„ÄÇThe mentioned stood open„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_55.png)

And then I'm giving it the path„ÄÇ So the path is„ÄÇBased on the image directory that I provide here„ÄÇ

 and then„ÄÇThe image name„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_57.png)

So the image name is in this columnÔºå rightÔºå so„ÄÇHere what I M G is„ÄÇ It will beÔºå for example„ÄÇ

 something like Emest„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_59.png)

Train„ÄÇLet's sayÔºå one dot P And G„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_61.png)

So hereÔºå index will select a random once it could be either 1 or3 or 5Ôºå1Ôºå2„ÄÇ123Ôºå whateverÔºå so„ÄÇ

This is chosen randomly„ÄÇ so this is how this data set is basically shuffled by always picking the ind season in random order„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_63.png)

And then there is an optional transformation that we can apply to the imagesÔºå for example„ÄÇ

 normalizationÔºå rotation and things like that„ÄÇ and I will show you how that works in the next lecture„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_65.png)

And then we also obtain the corresponding class label„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_67.png)

So if index isÔºå let's say one„ÄÇThen we willÔºå or let's say indexes yeah here 1„ÄÇ

 then we would obtain image 513 to PN G and the corresponding label 0„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_69.png)

And then it returns both the image and the label„ÄÇAnd that's essentially it„ÄÇ

 There's one more method here„ÄÇ That's the length„ÄÇ And this one is the length of the data set„ÄÇ

 So that is how this data set knows when one epoch is finished„ÄÇ

 So here we can simply compute the length by„ÄÇGetting the shape of this y„ÄÇ

 which is the class label columnÔºå so„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_71.png)

Essentially„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_73.png)

OhÔºå I have not imported anything here„ÄÇüòî„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_75.png)

I actually should have„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_77.png)

D it's not differentÔºåhu„ÄÇOhÔºå IÔºå sorry„ÄÇ I call a dift train„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_79.png)

![](img/363ca9888bed55788c258cb6b3103f4e_80.png)

Okay„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_82.png)

So this is our data set„ÄÇ So this is really specifying how we lot a data set or images from the data„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_84.png)

And now this is the data laer that is also loading data points„ÄÇ

 but this is really for making our mini batches„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_86.png)

![](img/363ca9888bed55788c258cb6b3103f4e_87.png)

So„ÄÇFor doing thatÔºå we need„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_89.png)

The data set„ÄÇSo„ÄÇHere what I'm doing is I'm setting up the training dataset set„ÄÇ

 So the training dataset set has the CB file Min MnesT underscore train dot CB and the folder Mnes train„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_91.png)

![](img/363ca9888bed55788c258cb6b3103f4e_92.png)

This is this folder here and this C file„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_94.png)

Let me before I explain this in more detailÔºå also show you the validation data set„ÄÇ

 so here's the same thing for the validation setÔºå but notice that the folder names are different and the C file names are different and here is the same for the test set„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_96.png)

![](img/363ca9888bed55788c258cb6b3103f4e_97.png)

![](img/363ca9888bed55788c258cb6b3103f4e_98.png)

Now„ÄÇSeeÔºå there is another thing going on Trans„ÄÇ and this is our custom transformation„ÄÇ

 We don't do anything here except converting the image to a Pytorch tensor„ÄÇ

 So there is the Torch vision libraryÔºå which has this transforms package or sub library„ÄÇ

 and there are different„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_100.png)

Methods for augmenting and transforming images here„ÄÇ I'm using something called2 tensor„ÄÇ

 and this one will convert an image to a Pyth tensor„ÄÇ

 but it will also normalize the images by dividing them by 255 automatically„ÄÇI actually find this„ÄÇ

 I don't know„ÄÇ I would like if it wouldn't do this automatically because it's maybe something we don't want to do„ÄÇ

 but in any caseÔºå yeah it does that so what I mean is it would be cool to have the choice whether we do it or not„ÄÇ

 Maybe there's a new function that has or give you gives you the choice„ÄÇ

 but it's actually not a bad idea to normalize images„ÄÇ So in that way„ÄÇ

 it's maybe good so people avoid making mistakes because yeah„ÄÇ

 training a network on unnmalized images is usually a bad idea„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_102.png)

Okay„ÄÇYesÔºå so this is how we then set up along„ÄÇTraining data„ÄÇ Now we have created a dataset„ÄÇ

 a training dataset using our my dataset class that we defined here„ÄÇ

 So here this is just defining the class and here we are actually using it„ÄÇ

 And now we are setting up the data la„ÄÇ So that's the main part„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_104.png)

![](img/363ca9888bed55788c258cb6b3103f4e_105.png)

![](img/363ca9888bed55788c258cb6b3103f4e_106.png)

Which„ÄÇTakes in this training dataset„ÄÇ And here we also specify the batch size„ÄÇ

We specify whether we shuffle or not after each epoch„ÄÇ

 this is shuffling or essentially before each epoch„ÄÇ and there is also a parameter nu workers„ÄÇSo„ÄÇ

It would be great to have a whiteboard here or something„ÄÇ I don't have one„ÄÇBut think about it„ÄÇ

As this„ÄÇ So if we Python is single threadedÔºå usually„ÄÇ So there's one mainy Python process„ÄÇ

 one process running„ÄÇ So there's usuallyÔºå let's say data processing„ÄÇAnd then there's our model„ÄÇ

 And thisÔºå let's say„ÄÇWe give our data to the GPU„ÄÇ and then on the GPU„ÄÇ

 there happens the model trainingÔºå and then„ÄÇÂóØ„ÄÇIt then it goes back to„ÄÇData processing again„ÄÇAnd then„ÄÇ

It's basically a repeating loop„ÄÇ So we are going from data processing to the GPU where we do the model training and then data processing„ÄÇ

 GPU model training„ÄÇ And this would also be true for CPU„ÄÇ

 The main point is that this is sequential because Python is usually one single process„ÄÇ

 one main processÔºå however„ÄÇData processing„ÄÇCan be slow„ÄÇ I meanÔºå it can takeÔºå let's say„ÄÇ

10 seconds or 5 seconds to load the images„ÄÇSo„ÄÇIt would be more efficient if we have the data processing decoupled„ÄÇ

From giving the data to the GPU and the model trainingÔºå if those happen like in parallelÔºå right„ÄÇ

 So we could have actually multiple„ÄÇCPUusÔºå via multiple CPUUus„ÄÇ We can do the data processing„ÄÇ

 and then the data is already ready in the memory„ÄÇ and the GPU just has to read it and do the model training„ÄÇ

 It has neverÔºå never has to wait until the next batch is processed„ÄÇSo in that sense„ÄÇ

 we can use multi processing of our CPU to prepare the next batch of images for the GPU„ÄÇ

 so the GPU doesn't have to wait„ÄÇFor thatÔºå we can use the number of workers greater than0 if we have0 then only one main python process is used for both for everything for the whole pipeline„ÄÇ

 if we set it to oneÔºå then it will create one sub process to load the data which makes it more efficient and two is even better„ÄÇ

I noticed when I run it hereÔºå actuallyÔºå I get problems recently with recent versions„ÄÇ

 I think this is because Mnes is so fast to load that it will just load too many things at once„ÄÇ

 And then it has too many open files waiting for the GPU to be processed„ÄÇ

 So I get nowadays an error when I run it on Mnes„ÄÇ But if I have any other data set other than Mnes that is usually not the problem„ÄÇ

 because Mnes is really just too simple„ÄÇ I think that's the problem„ÄÇ So I set it to0„ÄÇ

 But in your projectsÔºå you may want to set it to a higher number„ÄÇ And for example„ÄÇ

 in my research projectsÔºå I usually use two3 without problems„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_108.png)

ÂóØYeah„ÄÇOr I should also explain what drop last means„ÄÇ

So if you have a number that is let's say not divisible by 32„ÄÇ

 then there will be a last batch that is smaller than 32 right And if drop last is true„ÄÇ

 it will be dropped you don't have to do this I mean you don't have to drop this„ÄÇ

 but I noticed sometimes in my research code that if I haveÔºå let's say batch sizes of 512„ÄÇ

 and then the last batch is only 11 examples„ÄÇ this last batch can be extremely noisy and sometimes harm the model performance as a bad update at the end of the epoch„ÄÇ

 So personally in my projects I found usually dropping the last mini batch„ÄÇIf it's smaller„ÄÇ

 then the batch size is sometimes good„ÄÇAlrightÔºå let's take a look now„ÄÇ

 So here we are initializing all the data load for the training setÔºå for the br set and the test set„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_110.png)

![](img/363ca9888bed55788c258cb6b3103f4e_111.png)

![](img/363ca9888bed55788c258cb6b3103f4e_112.png)

And here I'm justÔºå yeahÔºå I'm iterating through it to just make sure that it works„ÄÇ

 So here I'm simulating how we would train a model„ÄÇ So we haveÔºå let's say„ÄÇ

 just two epochs and then we iterate through the batches here„ÄÇFor our training order„ÄÇ

 this is actually what you have seen before„ÄÇ We have used the built in endless data set„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_114.png)

I am transferring it to the device„ÄÇ So the deviceÔºå if you have a GPUÔºå it will be the first GPU„ÄÇ

 OtherwiseÔºå it will be the CPU„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_116.png)

So yeahÔºå it will just iterate sea„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_118.png)

So just give the batch size„ÄÇ so it will create„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_120.png)

1Ôºå2Ôºå3Ôºå4Ôºå5Ôºå6Ôºå7Ôºå8 mini batches„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_122.png)

And that is it let me change this to one and see what happens I„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_124.png)

Don't always get this errorÔºå but with amness„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_126.png)

YeahepÔºå seeÔºå I get something„ÄÇCalled„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_128.png)

Like this„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_130.png)

I think this is because there are too many open files„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_132.png)

Doesn't say so explicitly„ÄÇBecause the weird thing is„ÄÇ

 I don't get this error when I run this on data sets that are not Mnes„ÄÇ There's something about Mnes„ÄÇ

 I think it's„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_134.png)

![](img/363ca9888bed55788c258cb6b3103f4e_135.png)

And this is just as simple„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_137.png)

It's a little bit weirdÔºå to be honest„ÄÇAlsoÔºå I can't remember in the past getting this error about you anyways„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_139.png)

Could also be my computer because I compiled Pythr from scratch„ÄÇ

 but I also get this error on my other machineÔºå so„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_141.png)

![](img/363ca9888bed55788c258cb6b3103f4e_142.png)

Anyways„ÄÇSo„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_144.png)

Let's go back to this one Yeah„ÄÇ and here we can also just print the shape of one of the batches here„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_146.png)

So the shape is 32„ÄÇ Then the color channel is only one color channel„ÄÇ

 So because it's black and white and then 28 pixels highÔºå28 pixels white„ÄÇ

 here's just printing it as a vector if we reshape it„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_148.png)

32 times 784„ÄÇ So this is what our multilayer perceptron needs as an input„ÄÇ

 so convolal networks can work with this input directly„ÄÇ multilayer perceptrons cannot„ÄÇ

 They can only work with this„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_150.png)

Just just for reference how it looks like the torch tensor„ÄÇ can see it's normalized„ÄÇ

 We should be able„ÄÇ maybe we can't„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_152.png)

It's just see if it's„ÄÇCause it's abbreviating it„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_154.png)

If we get printed it„ÄÇHere you can see the highest value „ÄÇ999 because it's 253 divided by 255„ÄÇAlright„ÄÇ

 so this is how the data load works„ÄÇ Let me now show you the model training code here„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_156.png)

Using the custom data model„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_158.png)

So here I'm now using a hybrid of what I showed you two videos ago when I use helper functions„ÄÇ

 helper scripts and a Jupyter notebook„ÄÇSo here I have set up several helper files that I may reuse in different projects„ÄÇ

 and this helps me keeping the notebook kind of small„ÄÇ So if I make a new notebook„ÄÇ

 let's say I call it notebook„ÄÇ2Ôºå I can make some changes to this notebookÔºå for example„ÄÇ

 some settingsÔºå but I don't have to copy and paste all the code„ÄÇ It's in that wayÔºå easier to read„ÄÇ

 especially if you want toÔºå let's say modify some function as a bug in the accuracy function„ÄÇ

 Then you don't have to go back to every file here and change the code„ÄÇ

 You only have to change it in one of the files and the P files„ÄÇ So I can just maybe open them„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_160.png)

Show you what I mean„ÄÇSo„ÄÇüòî„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_162.png)

ExampÔºå help I evaluate„ÄÇ I have this set all seats Demin compute accuracy„ÄÇ So if there's a bug„ÄÇ

 for exampleÔºå I only have to change it here once I don't have to go back to all my notebooks„ÄÇ

 I find this very helpful if I have a project with multiple model training and model notebook scripts or notebooks and scripts„ÄÇ

 alright„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_164.png)

![](img/363ca9888bed55788c258cb6b3103f4e_165.png)

Me closes again„ÄÇ We can take a look at individual ones„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_167.png)

So„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_169.png)

Yeah yeah importing certain functions from this„ÄÇAll from these helpalpa files„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_171.png)

Then here are my settings„ÄÇ You can alsoÔºå like I explained before have a separate settings file here„ÄÇ

 I have the notebook itselfÔºå random seatÔºå batch size and number of epochs„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_173.png)

And thenÔºå I'm using these„ÄÇTo make that deterministic„ÄÇ And he has just„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_175.png)

So yeahÔºå I have a get data load function that actually uses the data load from the previous notebook that I showed you„ÄÇ

 I just put it into„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_177.png)

![](img/363ca9888bed55788c258cb6b3103f4e_178.png)

This script here„ÄÇ Now I have my data set hereÔºå and I have written a get data orderÔºå which will„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_180.png)

Set it up for me automatically„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_182.png)

So that it's basically just a slightly modified version of what I've showed you in the previous notebook where I just have arbitrary paths and stuff„ÄÇ

 and it will return the training orderÔºå validation order and test order„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_184.png)

![](img/363ca9888bed55788c258cb6b3103f4e_185.png)

And here I'm just testing that they actually work„ÄÇ So just getting some statistics„ÄÇ and you can see„ÄÇ

 So if I run this againÔºå you can see that the shuffling works because you can see that these numbers change„ÄÇ

 So these are the first 10 labels„ÄÇSo you can see this„ÄÇ So every time it will start from scratch„ÄÇ

 because I break here„ÄÇSo you can see these numbers change„ÄÇHoweverÔºå if I set my random seat„ÄÇ

I always get the same orderÔºå see„ÄÇCan run this again„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_187.png)

Always get the same order because of the random seedÔºå the the random seed„ÄÇYeahÔºå makes the„ÄÇÂóØ„ÄÇ

Makes it consistent„ÄÇ Its soÔºå for exampleÔºå if you run this code„ÄÇ

 you will get the same model and same accuracy I got because you use the same random seat„ÄÇ

 This is usefulÔºå for exampleÔºå if you do research and you develop some code and want to share it with someone else and the other person wants to reproduce your code„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_189.png)

ÂóØ„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_191.png)

So yeahÔºå here is the multi perceptionceptron„ÄÇ I yeah simplified this a little bit„ÄÇ

 So I'm using sequential„ÄÇ Now„ÄÇ I meanÔºå simplified compared to two videos ago here I'm actually using flattened„ÄÇ

 This is actually new„ÄÇ I like this a lot„ÄÇ So this way we don't have to reshape„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_193.png)

Our feature vector„ÄÇ So it will essentially reshape the 28 by 28 to 784 for us„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_195.png)

So we don't have to do it manually somewhere down here„ÄÇYeahÔºå and this is it„ÄÇ

 So here I'm using sequential„ÄÇ so I don't have to do anything in the forward„ÄÇ

 It will automatically return the logicits„ÄÇ So here this is a multilay perception with only one hidden layer„ÄÇ

 So this is the first hidden layer„ÄÇ Then we have a sigmoid activation„ÄÇ

 and then we have the output layer„ÄÇAnd then we would technically have a softm„ÄÇ

 but we don't need to have the soft max because the functional cross entropy loss in Pythtch computes the softm for us„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_197.png)

![](img/363ca9888bed55788c258cb6b3103f4e_198.png)

AlrightÔºå so this is how it works„ÄÇ So don't need to set another seat herecause I've done it above„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_200.png)

So here the seat would be for„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_202.png)

For the initial random weightsÔºå we'll also talk about this in a in„ÄÇ2 lectures„ÄÇ

 So not the next lectureÔºå but the lecture„ÄÇ after that„ÄÇ

 we will talk about these different ways we can initialize weights„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_204.png)

Mse stochasticÔºå great incent„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_206.png)

And hereÔºå I alsoÔºå yeah just brought a function for training The model is essentially what you have seen before„ÄÇ

 I just put it into a separate file here„ÄÇ So if I go to help train Pi„ÄÇ

 I have all the code I have had previously in here„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_208.png)

![](img/363ca9888bed55788c258cb6b3103f4e_209.png)

![](img/363ca9888bed55788c258cb6b3103f4e_210.png)

Because it's essentially always the same codeÔºå so you can use that in other projects as well„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_212.png)

You can justÔºå yeahÔºå copy and paste that„ÄÇ It just keeps the notebook more readable in that way„ÄÇ

 It's not such a long notebook anymore„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_214.png)

OopsÔºå what do we got hereÔºå YepÔºå that's what I always forgetÔºå defining things„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_216.png)

![](img/363ca9888bed55788c258cb6b3103f4e_217.png)

AlrightÔºå so trains„ÄÇ It will train very fastÔºå actually„ÄÇ

 because we only have 256 data points in each data set„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_219.png)

YepÔºå it is training fast„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_221.png)

YeahÔºå we get actually pretty high accuracy„ÄÇ I meanÔºå given that we only have 256 images„ÄÇ

 it's also Ba overfitting„ÄÇ It's actually not yeahÔºå you can see it's 91% and 73„ÄÇ It's actually„ÄÇ

 it is overfitting„ÄÇBut yeahÔºå the validationÔºå accuracy and test accuracy are almost identical„ÄÇ

 The difference hereÔºå Why is the difference is's usually just a small random effectÔºå right„ÄÇ

 because it's a small data set 156„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_223.png)

ÂóØ„ÄÇYeahÔºå and then I also have functions for plotting the training loss and the accuracys also helpful„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_225.png)

So yeahÔºå I have the version with a running average„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_227.png)

And„ÄÇüòîÔºåCan see the loss goes down„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_229.png)

We get train for one our epochs„ÄÇ And here the accuracy goes up„ÄÇ But then at some point„ÄÇ

 there's more and more overfitting„ÄÇSo I put these plotting functions in help plotting if you ever need them„ÄÇ

 I think I will also personally reuse them in future lectures because then I don't have to make these long notebooks because this code is really always the same„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_231.png)

![](img/363ca9888bed55788c258cb6b3103f4e_232.png)

![](img/363ca9888bed55788c258cb6b3103f4e_233.png)

So I have it some time defined find here and then I can reuse that„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_235.png)

You don't have to honestly memorize any of that or„ÄÇ

It's good maybe to understand it if you want to change it„ÄÇ

 but you don't even technically have to understand any of these details„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_237.png)

![](img/363ca9888bed55788c258cb6b3103f4e_238.png)

So it's also something I wrote one time„ÄÇ and if I ever need it againÔºå I'll just copy and paste it„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_240.png)

Because there are too many other things to worry about„ÄÇ It's rewriting this is it took me some time„ÄÇ

 I had to there were some bugs and things didn't work and„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_242.png)

In that wayÔºå you write it once so that it works and then you can just reuse it„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_244.png)

AlrightÔºå so last as a show examples function I wrote„ÄÇ So it shows some of the images so you can see„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_246.png)

P means predicted and T means true label or target label„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_248.png)

So these are all correct„ÄÇYeahÔºå so here this is a„ÄÇPredicted as2Ôºå but the target is 6„ÄÇ I see„ÄÇ

 I think I made an arrow here that can't be right„ÄÇMaybe it is rightÔºå but let me double check„ÄÇ

I haven't plant this„ÄÇ It's very spontaneous„ÄÇ so good that we look at it„ÄÇ I think is yeahÔºå I sorry„ÄÇ

 it's my mistake„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_250.png)

NowÔºå I just wrote this codeÔºå actuallyÔºå for this lecture„ÄÇSo„ÄÇMade a mistake„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_252.png)

AndLet's„ÄÇDo this again„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_254.png)

![](img/363ca9888bed55788c258cb6b3103f4e_255.png)

![](img/363ca9888bed55788c258cb6b3103f4e_256.png)

Hoops should have been targets„ÄÇYeahÔºå one it disadvantage is because I have the import at the top of this notebook„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_258.png)

I have to run the whole notebook„ÄÇüòî„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_260.png)

![](img/363ca9888bed55788c258cb6b3103f4e_261.png)

But it's faster run„ÄÇ

![](img/363ca9888bed55788c258cb6b3103f4e_263.png)

AlrightÔºå so that looks better Now„ÄÇ predicted 6Ôºå target 2 predicted 5 well„ÄÇTarget 0„ÄÇ

Some other mistake here you can see the model makes some mistakes„ÄÇ

 but I think these are just mistakes because the model hasnt haven't hasn't seen enough numbers because these should be easy to distinguish„ÄÇ

 I think they are clearly number twos„ÄÇOkayÔºå so yeahÔºå this is the custom nilota„ÄÇ

 So that's it then for this lecture„ÄÇ next weekÔºå we will talk about„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_265.png)

RegularizationÔºå like preventing„ÄÇOverfitting„ÄÇ All right„ÄÇ Have a good weekend„ÄÇ



![](img/363ca9888bed55788c258cb6b3103f4e_267.png)