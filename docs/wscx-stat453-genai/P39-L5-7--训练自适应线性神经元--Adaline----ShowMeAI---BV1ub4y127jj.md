# P39ÔºöL5.7- ËÆ≠ÁªÉËá™ÈÄÇÂ∫îÁ∫øÊÄßÁ•ûÁªèÂÖÉ (Adaline) - ShowMeAI - BV1ub4y127jj

YeahÔºå so the last couple of videos included a lot of mathematical details„ÄÇ

 which may not be super exciting„ÄÇ So let's now take a look at the more hands on example and do something„ÄÇ

 yeah more hands on training and adaptive linear neuron and Python„ÄÇ

 So here I will just give you the overview of how things relate to the Aline„ÄÇ So recall the Aline„ÄÇüòä„ÄÇ



![](img/9196609a4baf3856bac9916a9102ebf3_1.png)

That is what we covered briefly in the history of deep learning lecture„ÄÇ

 that is a model by Wirow and Hf in developed in 90 and around the 1960s„ÄÇ

 So actually whats the physical deviceÔºå but you can of course also nowadays implemented in software and this is a nicely differentiable neuro model so the perceptron model that we talked about before is not differentiable because of this threshold function„ÄÇ

 So this Analine you can think of it as an advancement of this perceptron that is now also converging even if the data is not linearly separable„ÄÇ



![](img/9196609a4baf3856bac9916a9102ebf3_3.png)

SoÔºå yeahÔºå just for comparisons„ÄÇ So how the perception looked like„ÄÇ So recall in the perception„ÄÇ

 you we compute the net input firstÔºå and then we pass the net input through a threshold function„ÄÇ

 and then threshold function produces our output„ÄÇ So the output is„ÄÇThe predicted class table„ÄÇ

 which can be either0 or one„ÄÇAnd if„ÄÇThe prediction„ÄÇ

Matches the actual label for that given training example„ÄÇ Then we don't do anythingÔºå but„ÄÇIf it„ÄÇ

Doesn't match if it's different„ÄÇThen we have this error term that we computed„ÄÇ

 So yeah the difference between the two and we use that to update the weights„ÄÇ

 so we update the weightsÔºå which then will change the decision boundary to make the prediction correct„ÄÇ

So that is how the perceptron worksÔºå but a threshold function is not differentiable„ÄÇ

 so here we couldn't use calculus„ÄÇ There was just this rule that was developed by I would say„ÄÇ

 thinking hard about this problemÔºå so it was more like an empirical update rule now we can actually improve that by using calculus„ÄÇ

So at the bottom is the adeline„ÄÇ So here you can think of this part here as the„ÄÇMaybe base model„ÄÇ

 And this isÔºå yeahÔºå like linear regression works„ÄÇ So again„ÄÇ

 we also compute the net input similar to the perceptron„ÄÇ Now we have as an activation function„ÄÇ

 We have this identity functionÔºå which is„ÄÇNot doing anything„ÄÇ So if it's not doing anything„ÄÇ

 If my activation function is just the identity functionÔºå why do I write it down in the first place„ÄÇ

 That's because yeahÔºå next week or the week after that„ÄÇ

 we will be talking about non linear activation functions„ÄÇ We will be talking about„ÄÇ

Our functions that areÔºå for exampleÔºå a sigoidal functionÔºå likeÔºå like„ÄÇThis oneÔºå for example„ÄÇ

 so we will be covering other types of activation functions„ÄÇ

 and we will need them to develop multilayer networks because this will help our multilayer network to„ÄÇ

 yeah produce nonlinear decision boundaries for solving complex problems because if we would be using linear activation functions in a multi layerer neural network„ÄÇ

 then„ÄÇThe multilayer network would be just a combination of linear functions and the sum of linear functions is also just the linear functions so we wouldn't gain anything so later on we will be talking about nonlinear activation functions and here you can think of it as a place that we will replace that later I'm just including it here in the notation because it's a more general notation that would apply to also nonlinear activation functions okay„ÄÇ

Now consider this linear regression base in order to turn this linear regression model into an adaptive linear neuron into the Adeline model„ÄÇ

 all we have to do is now adding a threshold function because the adeline model is a classifier„ÄÇ

Classifier for classifying data points similar to the perception„ÄÇ HoweverÔºå note the difference here„ÄÇ

 really between the perception and the airlineline is„ÄÇWhere we compute the error so„ÄÇ

For the perceptionceptronÔºå we compute the error after the threshold function and in the add line„ÄÇ

 we compute the error before the threshold function„ÄÇ

 So here we don't have the problem that things are not differentiable because we compute it before the threshold function„ÄÇ

 The threshold function still is not differentiable„ÄÇBut we don't„ÄÇ

 yeah worry about that because we compute the gradients before that„ÄÇ

 So in that way it's not a hindrance and it will become more clear when I show you the code example„ÄÇ



![](img/9196609a4baf3856bac9916a9102ebf3_5.png)

So here's just conceptually how it looks like when we fit an adeline model„ÄÇ

 So here what I'm just doing is I'm showing you the class label on the y axiss„ÄÇ So for binary„ÄÇ

ClassificationÔºå where we have two„ÄÇClasification where we have two class tables of 1 and 0„ÄÇ

 I have plotted them hereÔºå so the class as can be either one or0„ÄÇ

 And then we have only one feature value for simplicity here„ÄÇAnd yeah„ÄÇ

 we want to predict that and the linear neuron is a linear model„ÄÇ

 so essentially what it will learn will fit a linear line similar to linear regression„ÄÇ

 so this would be very similar to linear regression right„ÄÇ

 except now the difference is really that in linear regression we usually have continuous values„ÄÇ

 not only zeros and ones and we don't have the threshold function„ÄÇ

So in the headdeline after fitting this modelÔºå we apply this threshold function let's say at 0„ÄÇ

5 between 0 and 1„ÄÇ and we say„ÄÇThenÔºå if something„ÄÇIf something is bigger than a certain value„ÄÇ

 So if the„ÄÇIt's maybe a little bit unfortunate that I wrote class table here because this is this threshold„ÄÇ

 if the predictionÔºå let's say„ÄÇPrediction„ÄÇIf the prediction is greater than 05Ôºå produce glass table 1„ÄÇ

And„ÄÇüòîÔºåOtherwise„ÄÇProduce class label 0„ÄÇ So in that way„ÄÇ

 we turn the continuous prediction into a class label„ÄÇ again„ÄÇ

 this will become clear when I show you the code example„ÄÇSo I prepared some code examples„ÄÇ

 let me pause this video and do this in a fresh video„ÄÇ

 so there will be another video where I will go over these code examples„ÄÇ



![](img/9196609a4baf3856bac9916a9102ebf3_7.png)