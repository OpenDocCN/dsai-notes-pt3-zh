# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P148ï¼šL18.2- GAN ç›®æ ‡ - ShowMeAI - BV1ub4y127jj

All rightï¼Œ let's now talk about the again objectiveï¼Œ essentially how the loss function looks likeã€‚



![](img/e633c4715e18b9915b05386427cb77cb_1.png)

Before we get to that thoughï¼Œ just againï¼Œ the big picture overview and the important questionã€‚

 when does again converge because yeahï¼Œ the answer might not be so obviousã€‚

 so we have the discriminator which is trained to distinguish between real and generated images so essentially the discriminator wants to become better at detecting these generated images while at the same time the generator wants to become better at fooling the discriminatorã€‚

Rightï¼Œ so in that wayï¼Œ this like this fine interplay or this back and forth between the generatorã€‚

Wanting to be better at fooling the discriminatorã€‚ So it kind of wants the discriminator to make wrong predictions and the discriminator wants to make correct predictionã€‚

 So when does it actually converge if it goes back and forthã€‚

 So if you train this and everything is set up properlyã€‚ It should at some pointã€‚

 reach some point of equilibriumã€‚ So in the context of game theoryã€‚

 there what you call the Nsh equilibriumã€‚ So there will be some sweet spot between the twoã€‚

 where both are somewhat happyã€‚

![](img/e633c4715e18b9915b05386427cb77cb_3.png)

So the loss function for the G overall would look like thisã€‚ It's essentially a min Max gameã€‚

 So some people call it mini Maxã€‚å“¦ã€‚0ã€‚ğŸ˜”ï¼Œä¸‰ gameã€‚And we have two parts hereã€‚

 So we want to minimize some G here where G corresponds toï¼Œ let's say the generatorã€‚

Permeters and the D corresponds toã€‚The discriniatorã€‚And you can see there areã€‚Two broad parts hereã€‚

 One part is hereã€‚And the other part is this one hereã€‚And in this left partï¼Œ what we can see hereã€‚

 that'sã€‚D for the discriminatorã€‚è¿™æ˜¯ä¸Šã€‚ğŸ˜”ï¼ŒOutput or prediction of the discriatorã€‚

And this on the right hand sideã€‚Mis the output of the generatorã€‚ So this is our in input imageã€‚

 Let's call it the generated image X primeï¼Œ whereasã€‚Here that access the real imageã€‚Soï¼Œ Dã€‚On x primeã€‚

 this is like the prediction of the generated imagesã€‚ So looking at thisï¼Œ we have two termsã€‚

 One is prediction on theã€‚Real imagesã€‚And one is the prediction of the discer on theã€‚Generate itã€‚

Imagesã€‚So let's now in the next couple of slidesï¼Œ walk through this step by stepã€‚

 looking at the discriminator part first and then going to the generator part because sort of things going onã€‚

 let's look at it one at a timeã€‚

![](img/e633c4715e18b9915b05386427cb77cb_5.png)

Okayï¼Œ so there are lots of things going on now at the topã€‚

 I just copied over the equation from the previous slideã€‚And now in this slideã€‚

 we are going to focus only on disc screenator partï¼Œ So theã€‚Maximization party of the deepã€‚

And since it's a maximization problemï¼Œ we are going to use or assume we are using gradient ascent before in thesã€‚

 we used gradient descent because we wanted to minimize somethingã€‚Nowã€‚

 because it's a maximization problem hereï¼Œ we are going to maximize somethingã€‚

 which is why we call this gradient ascentï¼Œ not descentã€‚But yeahï¼Œ this is just a minor detailã€‚Okayã€‚

 so we are going to maximize something hereã€‚ So going toï¼Œ for instanceï¼Œ maximize this partã€‚

In this part for the discriminatorã€‚ So here at the bottomã€‚

 showing you the gradient of the loss with respect to the discriminator parametersã€‚

 So W is just the weights of the discriminatorã€‚And yeahï¼Œ this is yeahï¼Œ the lossã€‚

And this is something we want to maximizeï¼Œ thoughï¼Œ becauseï¼Œ like I saidï¼Œ it's a maximization problemã€‚

 Ohï¼Œ and by the wayã€‚We have a sum here instead of the expectationï¼Œ becauseã€‚

In the form here at the topï¼Œ this is assuming the data generating distributionã€‚

 but in practice we never really have access to thatã€‚ We only have a fixed size training setã€‚

 so this becomes more like an empirical lossã€‚So this is why we use the sum here where the sum is over the end trainingã€‚

So it's an number of training examplesã€‚Just a minor detailã€‚å—¯ã€‚Yeahã€‚

 the interesting part is now we are going to focusã€‚ let's say we are focusing only onã€‚This part hereã€‚

 and then I will have a new slideï¼Œ exactly a duplicate of that slide where we are going to discuss the right hand side hereã€‚

 I want to discuss this in two slides because I can imagine it will become very crowded hereã€‚Okayã€‚

 focusing on what I highlighted here in purpleã€‚At the bottom hereï¼Œ essentially this partã€‚

 the discriinator for the real imagesã€‚ what we want the discriinator is to predict well on the real imagesã€‚

 rightï¼Œ So we want this probabilityã€‚To be close to oneã€‚So there is screen data hereã€‚

Which colorlo I use withï¼Œ So the discgraator here is outputting a scoreã€‚Betweenã€‚0 and1ã€‚

 representing the probabilityã€‚That an image isã€‚Realã€‚

So it's outputting this probability here between 0 and1ã€‚Andã€‚Ideallyã€‚

The best possible score for the discï¼Œ because it's an maximization problem hereï¼Œ is this to be oneã€‚

 rightï¼Œ becauseã€‚If we plug in some valuesï¼Œ so there's a lock hereã€‚Soã€‚Lock of one isã€‚Like thisã€‚

Lock of one is 0ï¼Œ and lockã€‚0ï¼Œ that would be the worst case would be minus infinityï¼Œ rightã€‚

The worst case would be when we predict the0 for the real imagesã€‚

 in the best case would be to break the oneã€‚That's how we maximize this termã€‚Okayï¼Œ so the next slideã€‚

 let me show you the second term hereã€‚Allrightï¼Œ let's do this againã€‚

 but now we are going to focus on the right partï¼Œ so we are going to focus on this one hereã€‚

And we are still talking about the discriminatorã€‚ So we're still talking about gradient ascentã€‚

 maximizing somethingã€‚ We're still talking about maximizing somethingã€‚

And now we are exactly here where weã€‚Consider generated dataã€‚ So on G here is the generatorã€‚Andã€‚

It receives some noise input Zï¼Œ and it will output X prime the generatedã€‚Imageã€‚

 if we look at this termï¼Œ it's actuallyã€‚Very similar to what we have on the left hand sideã€‚

 So there's also a D and the D still outputs the value between 0 and 1ã€‚But nowï¼Œ of courseã€‚

 based on the generated image instead of the original imageï¼Œ and now we have this one minus hereã€‚

So as a consequenceï¼Œ what happens if our discriator is very confident that this image is a real imageã€‚

 if it thinks this is realï¼Œ it will put out a value close to oneï¼Œ rightï¼Ÿ

So in this case for let's go over here to the left hand sideï¼Œ soã€‚Lookã€‚1 minus-1ã€‚

 This is if it thinks it'sã€‚Realã€‚ğŸ˜”ï¼ŒSo this would beã€‚Lock 0ï¼Œ which is minus infinityã€‚ would be a veryã€‚

Yeahï¼Œ badï¼Œ very bad loss becauseã€‚The biggerï¼Œ the betterã€‚

 because we are still here talking about maximizingã€‚

 So the worst case scenario is that our the screen thinks that the generated image is realã€‚

 We' are talking about optimizing the disc screenã€‚ So we want to actually avoid that to maximize this termã€‚

We would put in or the discriminator would predict a0ï¼Œ rightï¼Œ so because then we have lockã€‚1-0ã€‚

Which isã€‚ğŸ˜”ï¼ŒLook 1ï¼Œ which is 0ã€‚ So this would be our best case scenario for predictingã€‚Gen itã€‚

So here I meanï¼Œ with a value of 0ï¼Œ this is a low probability for realã€‚ If we set the cutoff at 0ã€‚5ã€‚

 this would be essentially predicting generatedã€‚Okayï¼Œ soã€‚Putting these two points togetherã€‚

 what we want for the discriminator when we are training the discriminator here is we want that it outputs a probability close to one for real imagesã€‚

And we want here it to output a probability close to 0 for these fake or generated imagesã€‚

 So this is the discriator part In the next slideï¼Œ we will then focusã€‚Here onã€‚The generator aspectã€‚



![](img/e633c4715e18b9915b05386427cb77cb_7.png)

All rightã€‚ So finallyï¼Œ we are now finished with a discriminatorï¼Œ and we can now focus onã€‚

The generator updateã€‚Okayï¼Œ soã€‚Now we are talking about a minimization problemï¼Œ soã€‚

We can use gradient descent for training the generatorã€‚

We are focusing again on exactly the same part as beforeï¼Œ howeverã€‚

 before we updated the weights of the discriminatorã€‚

 now we keep the discriminator as fixed and update the weights of the generatorã€‚

It incorporates the prediction of the discriminatorï¼Œ which is why I circled this whole thing hereã€‚

So looking at the equation aboveã€‚If we want to know what we have to update for Gã€‚ So the left termã€‚

If you think also calculus of the sum ruleï¼Œ this would be kind of cancelled because there is no G hereã€‚

 rightï¼Œ So this is not relevant in the lossã€‚ So we can actually ignore this for nowã€‚

 So this has nothing to do with a generatorã€‚On the right hand sideã€‚We see the generator hereã€‚

So let's bring this down hereã€‚ This isï¼Œ againï¼Œ the empirical losssonã€‚On the training setã€‚

 And this is exactly the same I showed you before in the previous slideã€‚

 except now we are talking about G instead of Dã€‚And we are talking about minimizingã€‚

 instead of maximizingã€‚But againï¼Œ this partã€‚Is stillã€‚The generated or fake imageã€‚

And the disc screenator hereã€‚Predicts on this fake imageã€‚

 and the output range is still between 0 and 1ã€‚Where one or where this represents the probability for realã€‚

Okayï¼Œ so in the previous slideï¼Œ when we talked about the discinatorï¼Œ we wanted to maximize thisã€‚

 so we wanted to maximizeã€‚The probabilityã€‚That the discriator predicts real on real imagesã€‚

And predictsã€‚Fake on these generated imagesã€‚Soã€‚Let me write this partã€‚

 lock 1 minus So in order to maximize this in the previousã€‚Slideã€‚

What we had is or we wanted the discriminator to outputã€‚Wanted to output a0 hereã€‚

Because then we have lockã€‚1ï¼Œ which isã€‚0ï¼Œ was our best case scenario for maximizing the discriatorã€‚Noã€‚

Since we talk about a minimization problemã€‚We want actuallyï¼Œ the disd output of one hereã€‚

Because then we have 1 minus-1ï¼Œ which is 0ã€‚Which gives us minus infinity hereã€‚Minus infinity isã€‚

 yes you can imagine the most the lowest possible valueï¼Œ rightã€‚

 because we talk about minimizing this lost termï¼Œ gradient descent minimizingã€‚

 So we have minimization hereã€‚ And this is minimized if we have a lock 0ã€‚ So if theã€‚

The crriminator outputsã€‚A low probability here sorryï¼Œ high probability here for realã€‚Soã€‚

The discriator hereï¼Œ this is Pã€‚The probabilityã€‚The image is realã€‚Some range between 0 and 1ã€‚

It is a generated imageï¼Œ so it is not realï¼Œ but we want the discriminator to think it is realã€‚

 So we want it to output a high score1 because then we have 1 minus-1ã€‚Block 0ã€‚

 which is minus infinityã€‚ And that is how we minimize the generatorã€‚

 So the generator wants the discriminator to outputã€‚The prediction that something is realã€‚

 although in reality it's not realã€‚And yeahï¼Œ this is then now the different partsã€‚

 we we covered the maximization of the screenator and we talked about minimizing the generatorã€‚

 So the next couple of slidesï¼Œ I will just add a few more things from the paperã€‚



![](img/e633c4715e18b9915b05386427cb77cb_9.png)

So this here is a screenshot from the original G paper so this is the training process of what we've discussed in the previous slidesã€‚

 just summarizing it into this training procedureï¼Œ they call this the mini batch stochastic gradient descent training of generative adversarial netsã€‚

 of course also gradient ascent as involved as you have seen in the previous slides for training the discriminatorã€‚

In factï¼Œ in the next videoï¼Œ I will show you a trick that we can turn this ascent problem into a descent problemã€‚

 It's also recommended in practiceï¼Œ but for nowï¼Œ let's stick to this original outline of the algorithm hereã€‚

 So let'sï¼Œ yeah discuss this step by stepã€‚There is a follow loop hereã€‚ Let me stick with green hereã€‚

 There's a follow up here for the number of training iterationsã€‚

 You can think of it also as yeah follow loop over the number of epochsã€‚And thenï¼Œ there areã€‚

The discriminator training and the generator training alternatingã€‚

So let me box this in so it will be easier to seeã€‚Soï¼Œ this isã€‚The generatorï¼Œ sorryã€‚

 the discriator trainingã€‚And then here at the bottomã€‚This is the generatorã€‚Trainingã€‚Okayã€‚

 let's take a look at the discrial training firstã€‚ So it says for K stepsã€‚

And the K steps as a hyperparameter and they used k equals 1ã€‚

 so they only essentially train the discriminator onces and then they go to the generator and then they go back to the discriminator and so forthã€‚

 but in practice you could update the discriminator several times before you update the generatorã€‚

 It's another hyperparameter to considerã€‚å—¯ã€‚What we do is when we train the discriminator is we sample a mini bitch of M noise samplesã€‚

Fromï¼Œ let's sayï¼Œ a standard normal distributionã€‚And then we sample a mini batch of M examples from the data generating distribution hereã€‚

 this is essentially you areã€‚our training setã€‚So this is essentially just drawing a mini batchã€‚

There's nothing special about thatï¼Œ it's just obtaining a mini batchã€‚ğŸ˜”ã€‚

And then we update the discriminator by ascending its stochastic gradientã€‚

 so that is what we talked about in the previous slidesï¼Œ that's how we update the discriminatorã€‚

So this is the discriminator part at the bottomï¼Œ we have the generator partã€‚Againã€‚

 here we sample a mini batch of noise examplesã€‚And then we update the generator by descendingã€‚

So here that's the SGD that we had on the previous slideã€‚And yeahï¼Œ for learningã€‚

 So this is it essentiallyï¼Œ and for learningï¼Œ they say they use momentumã€‚Based stochasticã€‚

 gradient descentã€‚Personally I also had good experiences with S GD and momentum and Adamom but I've had seen some comments or people recommended not using momentum because you want the generator and the discriminator to be kind of flexible so the momentum term makes them lag behind a little bitã€‚

 so sometimes people recommend not using momentumï¼Œ but I find that it works just well with momentum as wellã€‚



![](img/e633c4715e18b9915b05386427cb77cb_11.png)

Yeahï¼Œ just to recapgan convergence so when does a G converge like I mentioned briefly beforeã€‚

 it converges when we reach the Nsh equilibriumï¼Œ which is a term game theory and that is essentially when we we have an equilibrium betweenã€‚

Maximizing the loss for the discriminator and minimizing the loss for the generatorã€‚

So in the game theory jargonï¼Œ it is basically reached when the actions of one player won't change depending on the opponent's actionsã€‚

And here and concretelyï¼Œ this means that the G produces realistic imagesã€‚

So the generator is able to produce realistic imagesã€‚

 and the discriminator outputs random predictionsï¼Œ probabilities close to 0ã€‚5ã€‚

So G is able to produce images that are indistinguishable from the training set imagesã€‚ I meanã€‚

 they are still new imagesï¼Œ but they look very realisticã€‚ While the discriminator yeahã€‚

 can't tell them apartã€‚ The discriminator essentially predicts 05ï¼Œ like a ã€‚

5 probability being unsure whether something is real or fakeã€‚



![](img/e633c4715e18b9915b05386427cb77cb_13.png)

Yeahï¼Œ so here's another figure from the original G paperã€‚

 This is a really nice figure illustrating the G training processã€‚

 So when it converges when it reaches the Nsh equilibriumã€‚ So there are four stepsã€‚To this figureï¼Œ Aã€‚

Bï¼ŒC and Dï¼Œ let's talk through this one by oneã€‚ So let's focus on figure a firstã€‚

You can see there are multiple linesã€‚ that's lot of things going onã€‚ So let's annotate this firstã€‚

 soã€‚What they say here is in the green solid line is the generative distributionã€‚

 or essentially the generator dataã€‚ So the outputs of the generatorã€‚Let's say theã€‚Fake imagesã€‚Thenã€‚

 what we have isã€‚Here and blackã€‚ğŸ˜”ï¼ŒThe back dotted lineï¼Œ these are the data generating distributionã€‚

So with thisï¼Œ it means the original training set imagesã€‚ So let's just call thatã€‚Trainingã€‚ğŸ˜”ï¼Œæˆ‘ã€‚Realã€‚ğŸ˜”ã€‚

Imagesã€‚Then we have one more lineï¼Œ the blue lineï¼Œ the blueã€‚Ded line hereã€‚

 And this is the discriminative distributionã€‚ so you can think of it asã€‚Here has this oneã€‚ğŸ˜”ï¼Œå—¯ã€‚

Maybe not idealã€‚ just like hereã€‚Disriminatorã€‚Predictionsã€‚And you knowï¼Œ from the previous slidesã€‚

The range is between  one and 0ï¼Œ where 1ã€‚Or where the the screenator outputs the probability that an image is realã€‚

Okayï¼Œ so now we have these different thingsã€‚ and you can alsoã€‚You can alsoã€‚

 also you can think of the black line here as a probability densityã€‚ And hereï¼Œ this is the xï¼Œ theã€‚

Input images so the range of the input imagesã€‚ Of courseï¼Œ it's only a one dimensional plot hereã€‚

Just for simplicityï¼Œ X are the input imagesï¼Œ and z are the generated imagesã€‚Let's sayï¼Œ realã€‚

And generate itã€‚And what they are trying to show here is where the generatedã€‚Images map 2ã€‚

 And you can see thatï¼Œ let's sayã€‚The training imagesï¼Œ the density is highest in this region hereã€‚

And the generated images at this first stepï¼Œ they are mostly mapping only to a smallã€‚Regionã€‚

Over hereã€‚Soã€‚The highest density for the generated images is hereã€‚Andã€‚They say the step A here isã€‚å—¯ã€‚

Near convergenceã€‚ So it's not quite convergedã€‚ So they are illustrating here the process of converging going from A to B to C and to Dã€‚

 So we setã€‚That the distribution of generated images here is differentã€‚At this pointã€‚

 from the training distributionã€‚ But it's not substantially differentã€‚

The discriminator predictions are very confident here for these imagesï¼Œ like that they are realã€‚

 So here in this whole regionã€‚The generator predictsã€‚Realã€‚Except then when we go down hereã€‚

To the generatorã€‚Images hereã€‚The0ï¼Œ it essentially detects correctly that they are fakeã€‚

So this is a region in general where the discriminator is pretty happyã€‚ It's doing good predictionsã€‚

 but the generator is not very happy because it's not able to fool the discriminator yetã€‚Soã€‚

 next andã€‚Bï¼Œ so as B hereã€‚B in the inner loop of the algorithm D is trained to discriminate samples from dataã€‚

 so now we have a training stepï¼Œ so B is a training step updating the discriminatorã€‚

So you can see after this updateã€‚It will become even more confidentã€‚

 So after this update so instead step Bï¼Œ now it's consistently around one instead of being fluctuating here and you can see also here in this regionã€‚

It's consistently around  zero instead of being fluctuating hereã€‚

 So here this updated the discriminatorã€‚After the discriminator update comes the generator updateã€‚

 rightï¼Œ so nowã€‚We have a training step of the generator here in C After this stepã€‚

 what you can see is that the generator learns how to make the distributionã€‚

Of the generated data in green hereï¼Œ closerã€‚To the training dataã€‚

 So they are now more similar to each otherã€‚ And you can see thenã€‚That in this regionã€‚

 the discriminatorã€‚Is somewhere like very confidentã€‚ So it's in this caseã€‚

 the discriminator is not doing so well anymoreã€‚ So hereã€‚

 this is a point in see whether the generator is more happyã€‚ And in Bã€‚

 the discriminator is more happyã€‚ But in yeahï¼Œ what we want is we want to find this equilibrium where both are having the sweet spot where both are relatively happyã€‚

 So this is reached in Dï¼Œ when you do many stepsã€‚So in Dï¼Œ after several steps of trainingã€‚

 if G and D have enough capacityï¼Œ so if they are networks that are able to learnã€‚

 of course you can have maybe networks that are too weak to learn anything usefulã€‚

 then of course this would not be the caseï¼Œ but if both have the capacity to learnã€‚

 they will reach a point at which both cannot improveã€‚

Because the data generating distribution is the same as the generator distributionã€‚

And the discator will be unable to differentiate between the two distributionsã€‚

 outputting 05 is the predictionã€‚ So this is what we can see hereã€‚

 So here we can see the generator has learned to outputã€‚



![](img/e633c4715e18b9915b05386427cb77cb_15.png)

to recreate the training set distributionã€‚And the discriminator will be unable to differentiate between the twoã€‚

 So here steps Aï¼Œ Bï¼Œ C and D kind of illustrate the process of traininggans at least conceptually in practice it's way more messyã€‚

 it's not so easy to reach step Dï¼Œ but yet this will be more clearã€‚

 I think when we look at the code example howã€‚How difficult it is to train againï¼Œ in any caseã€‚å—¯ã€‚

Now we covered the loss function and the again objectiveã€‚

 the convergence and everything and in the next video I want to briefly tell you about a small modification so that we can use stochastic gradient descent for training both the generator and the discriminator and also how we can improve the gradientã€‚

 the loss gradient for the generatorã€‚

![](img/e633c4715e18b9915b05386427cb77cb_17.png)