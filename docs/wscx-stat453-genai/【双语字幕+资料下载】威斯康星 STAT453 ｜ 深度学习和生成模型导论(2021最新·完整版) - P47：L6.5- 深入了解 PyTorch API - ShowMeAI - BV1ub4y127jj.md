# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÂ®ÅÊñØÂ∫∑Êòü STAT453 ÔΩú Ê∑±Â∫¶Â≠¶‰π†ÂíåÁîüÊàêÊ®°ÂûãÂØºËÆ∫(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P47ÔºöL6.5- Ê∑±ÂÖ•‰∫ÜËß£ PyTorch API - ShowMeAI - BV1ub4y127jj

YeahÔºå so in this last video photo todayÔºå I want to go over the Pitorch API in particular„ÄÇ

 discussing the subtle difference between the object oriented and functional APIs because it will become useful in the future lessons„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_1.png)

So here is an overview of a multi layer perceptron„ÄÇ

So we haven't really talked about in detail how it works„ÄÇ

 I only showed you some yeah graphs of how it looks like„ÄÇSo here for this purpose„ÄÇ

 it's really just sufficient to think of it as a multi layerer neural network„ÄÇ

Because we the same concept really applies for all types of networks when we work with Python or almost all types of networks„ÄÇ

 So that's like this general template that you can think of where we have„ÄÇ

Or where we use usually a class to yeah define the model„ÄÇ And then for this class„ÄÇ

 we inherit from this torch dot an n dot module„ÄÇ So this gives us some certain convenience functions automatically„ÄÇ

 So this is usually how we set up a network in Pytorrch„ÄÇAnd then there's this constructor„ÄÇ

 the init constructorÔºå that is something we can define ourselves„ÄÇ

 So there's one line that we use here„ÄÇ This is really just for inheritance„ÄÇ

 So it inherits the init method from a moduleÔºå but then everything else here has something we can define ourselves„ÄÇ

So here I'm setting up a neural network with„ÄÇ1Ôºå2 hidden layersÔºå and one output layer„ÄÇ

And each layer is a torch and n dot linearÔºå a fully connected layer here„ÄÇ

And these are really in the in methodÔºå only the parts that need to be updated like the model parameters„ÄÇ

 So how the network runs like the forward passÔºå that is what we define in a forward method„ÄÇ

So here the input to the forward method is just a data input that will be provided during training„ÄÇ

And then we define really how the computation works„ÄÇ In this case„ÄÇ

 this is a network where we first compute the net input„ÄÇ then we used the relu function„ÄÇ

 We discussed the relu function earlier in this lecture„ÄÇThen we have another„ÄÇFully connected layer„ÄÇ

 net inputÔºå then another re„ÄÇ and then the output„ÄÇ and then we compute also our probabilities for the output„ÄÇ

 We could technically skip this step and only return the loits„ÄÇ

 Let's read just a matter of preference„ÄÇ And we will also discuss what softmax is and what the logicits are later in the upcoming weeks„ÄÇ

So here I really want to emphasize„ÄÇThat in the in methodÔºå we define model parameterss„ÄÇ

And then in the forward methodÔºå we define how and in what order the model parameters are used„ÄÇ

So that is just like the general outline here„ÄÇ And this is also similar what to what we have done in the previous video when we talked about the add line in the last step in the automatic step„ÄÇ

So here consider step one as the setup or module„ÄÇDefinition step„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_3.png)

Gci hereÔºå we are not really running any coded„ÄÇ we are just setting up our Python class„ÄÇSo then step2„ÄÇ

 we actually instantiate or create our model„ÄÇ So here I'm just setting my random seat„ÄÇBecauseuse„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_5.png)

If I go back one slide hereÔºå these like I mentioned in the code examples„ÄÇ

 these will be based on small random weights„ÄÇ PersonalÔºå I like to have my code reproducible„ÄÇ

 So I usually set a random seat„ÄÇ

![](img/80d91185d87ba37f6d819e7249f6c5a1_7.png)

Before I initialize the model„ÄÇ So every time then you run the same code„ÄÇ

 it will use the same random seats if I use the same value for random seat„ÄÇ However„ÄÇ

 in new network trainingÔºå of courseÔºå it requires sometimes to change the random seat because sometimes you can have bad starting weights„ÄÇ

 I will talk us about that more later„ÄÇ So I'm not always using the same random seat„ÄÇ

 But if I want to reproduce these experiments I write down the seats I use„ÄÇ

 and then if I have someone else execute the codeÔºå they can use the same seat„ÄÇAnyway„ÄÇ

 so here we initialize the perceptionceptron model„ÄÇ and then this is an optional step to device„ÄÇ

 This is really veryÔºå very cool if you want to run your code on the GPU„ÄÇ

 So the only line of code you really need to change„ÄÇ I meanÔºå there will be some other lines„ÄÇ

 but the main line you have to change is this one„ÄÇ If you provide GPU setting here„ÄÇ

 it will run all the code on GPU„ÄÇ So it will transfer all that code to the GPU and run automatically on the GPU„ÄÇ

 which is really convenient„ÄÇ

![](img/80d91185d87ba37f6d819e7249f6c5a1_9.png)

![](img/80d91185d87ba37f6d819e7249f6c5a1_10.png)

And then another thing we set up is the optimizer here„ÄÇ So here„ÄÇ

 like I also explained in the previous videoÔºå it gets the model parameterss„ÄÇ In this case„ÄÇ

 if I go back one slideÔºå sorryÔºå we have a lot of model parameterss here„ÄÇ

 All these linear ones contain weights and biases„ÄÇ So here we tell the optimizer what are the model parameterss„ÄÇ

 What needs to be updated during gradient descent„ÄÇ So this is stochastic„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_12.png)

![](img/80d91185d87ba37f6d819e7249f6c5a1_13.png)

Griianient„ÄÇDescent that we discussed also last week„ÄÇ So it's a stochastic rain descent optimizer„ÄÇ

 LaterÔºå we will see there are other types of optimizers like different flavors of stochastic ra descent„ÄÇ

AlrightÔºå so yeahÔºå this is what I described before„ÄÇ so we can provide if we have a co deviceÔºå a GPU„ÄÇ

 we can specify it here„ÄÇ and then the code or the model will be executed on the GPU„ÄÇ

 which can make training much more faster„ÄÇ And then Thursday„ÄÇ

 I will show you some some free platforms where you can use the GPU for free„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_15.png)

AlrightÔºå so step3 is then the training step„ÄÇ So that is also the same concept as I explained in the Adeline code in the previous video„ÄÇ

 So much of itÔºå what I'm showing you here on this slide is really very similar to what I've shown you in the previous video„ÄÇ

 I'm just walking through this a little bit more slowly„ÄÇSoÔºå here„ÄÇI have my loop over the epochx„ÄÇ

 I'll notice that we set model dot train„ÄÇ This is a good practice because later„ÄÇ

 there will be certain functions„ÄÇWhere we have a different behavior during training and evaluation„ÄÇ

 for exampleÔºå there is a concept called batch norm or dropout„ÄÇ

 and it's a good habit in each epoch to set it to dot train„ÄÇ

 And then when we do some logging or evaluation to set it dot to dotev„ÄÇ it's just a good habit„ÄÇ

 So that is something it's always good to do„ÄÇ So I will also make sure my code example that I provide to you that this is indeed specified„ÄÇ

And also noticeÔºå you don't really have to memorize this because in practice„ÄÇ

 when you write a new neural network or implement a neural neural network„ÄÇ

 you would never start from scratch„ÄÇ You would never like start with a blank„ÄÇ

 empty script and write down all these codes„ÄÇ What you would do is you would copy and paste The code here„ÄÇ

You would copy and paste it as existing codeÔºå and then yeahÔºå you would just optimize or modify it„ÄÇ

 so you would never really yeah start from scratch totally„ÄÇSo in that way„ÄÇ

 you don't really need to memorizeÔºå you just have to know where to find this information if you want to„ÄÇ

 yeahÔºå if you want to write some on code you useÔºå usually a template to start with„ÄÇWhere was I„ÄÇ Okay„ÄÇ

 so here we iterate over the epochs here„ÄÇ we iterate over„ÄÇThe batches„ÄÇ

 there will also be a training laer that I will show to you where we batch up our training set in a Pywach data set„ÄÇ

A context that makes also the iteration over the mini batchs a little more convenient„ÄÇHere„ÄÇ

 this is like a requirement because I created this example for MNT„ÄÇAnd M are images 28 by 28„ÄÇ

And my model here is a fully connected network„ÄÇ It needs this long tabular data set„ÄÇ

 this long vector„ÄÇ So I'm just reshaping it„ÄÇ But this is a detail„ÄÇ

 Don't worry about it here at this point„ÄÇ There's one more thing„ÄÇ If my model sits on the GP Also„ÄÇ

 my data has to sit on the GP„ÄÇ So that is something that is like requiredÔºå we can't do a computation„ÄÇ

 let's say a multiplication or matrix multiplication between a matrix sitting on the GP and the CPU„ÄÇ

 They have to be either both„ÄÇOn the CPU or both on the GPU„ÄÇ So personallyÔºå how this can be very„ÄÇ

 very easily handled is by specifying somewhere in your codeÔºå something like„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_17.png)

Oops„ÄÇSomething like device equals to either CPU or GPU„ÄÇ

 So usually there's something you want to you want to use like Torch not„ÄÇDeviceÔºå sorry„ÄÇ

Toch to device„ÄÇAnd then you would either set it to CPU„ÄÇÂì¶„ÄÇLet's say the ka device„ÄÇ

 usually if you have one GPUÔºå you would set it to0„ÄÇ

 if you want to use a second GPU that you have in a computerÔºå you can change into one„ÄÇ

 So this is like really an index here„ÄÇBut I will also talk more about this in the next lecture„ÄÇ

So if you set this somewhere in your codeÔºå then this variable will be used here„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_19.png)

And hereÔºå so you don't have to change in anything so it will just work whatever you have either CPU or GPU„ÄÇ

So then moving onÔºå this is the forward pass„ÄÇ So this is the forward path of your model„ÄÇ Notice that„ÄÇ

We don't actually call forward„ÄÇ We don't do„ÄÇModel dot„ÄÇForward„ÄÇFeatures„ÄÇWe just call model features„ÄÇ

 It's almost the same thing„ÄÇ I actually have a note here to remind you of that„ÄÇ

 It's actually the same thing„ÄÇBut there's one extra step if we don't do forward„ÄÇ So internally„ÄÇ

 PythonÔºå how classes work in PythonÔºå there's someÔºå yeahÔºå something called a call and this one„ÄÇ

We'll actually do some extra stuff and then insideÔºå run forwardÔºå so„ÄÇIf you do it like this„ÄÇ

 there will be another method dot callÔºå basic dot underscore underscore call„ÄÇ

 And this one will do some checkingÔºå just making sure everything looks okay„ÄÇ

 and then run dot model or model dot forward„ÄÇ So in this wayÔºå this is usually„ÄÇYeah„ÄÇ

 how we do the forward pass looks a little bit weird„ÄÇ

 but is this not like how the forward pass works„ÄÇAnd thenÔºå computer loss„ÄÇ

Set the gradients to 0 from the previous epoch„ÄÇ That's something I explained in the code in the last video„ÄÇ

Then we do the backward pass to compute gradients„ÄÇAnd then we update the model parameters„ÄÇ

 So that's that's the major part in the training loop„ÄÇ And like I said„ÄÇ

 you can always copy and paste this code and just adjust it to your new network„ÄÇ

 You never really have to memorize it personallyÔºå I alsoÔºå I mean„ÄÇ

 I've done or looked at this so many times I could probably write this down„ÄÇBut why memorizing this„ÄÇ

 if I can just use existing code and just menu manually adjust it„ÄÇ

 what's really only important that you understand thisÔºå you have to understand what's going on„ÄÇ

 but accept that you don't have to memorize code„ÄÇI don't meanÔºå like I saidÔºå no one doest it„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_21.png)

All right„ÄÇYeahÔºå there's just some more written stuff of what I explained„ÄÇ

 So you can also on the slides read through this more slowly„ÄÇ It's just some annotation„ÄÇ

 So if you want to take a look at it at home in a quiet momentÔºå you have also my annotation here„ÄÇ

Sometimes easier to listen„ÄÇ Sometimes it's easier to read than to listen„ÄÇ

 I think in a way I unnotated everything„ÄÇAll right„ÄÇ

And this is also something I will explain when we talk about logistic regression and multi layer percepts why we use los„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_23.png)

AlrightÔºå so the main point hereÔºå the remaining point and does the video„ÄÇ

Is that there are two types of API in Pyth„ÄÇ There is the object oriented API and the functional API„ÄÇ

And we can actually use both or a mix of both„ÄÇSo with functional„ÄÇ

 I mean functional programming like the concept of functional programming versus object oriented programming„ÄÇ

 So functional usually means that we have something without an internal state„ÄÇ

 So therch end torch that an functional API is an API without an internal state„ÄÇ

So what that means is if you take a look at the left hand side here„ÄÇ

 this is the perceptioncept that I showed you earlier in this video„ÄÇ

 So where we define the parameters and„ÄÇIn the constructor in the in constructor„ÄÇ

 And then we call these things„ÄÇNotice that for certain parts where we have this F„ÄÇ

 So I'm importing torch dot nn dot functional as F just for brevity„ÄÇSo in certain parts„ÄÇ

 I have this F here„ÄÇSo this is all using the functional API„ÄÇSo I could have done it differently„ÄÇ

 I could have„ÄÇDefined Reul as a class„ÄÇSo here I could define it as a class„ÄÇ however„ÄÇ

 this would be a little bit overkill because if you think about itÔºå what re is„ÄÇ

 a re is just function„ÄÇMax„ÄÇLet's say x0„ÄÇ It just returns„ÄÇWhatever value is higherÔºå rightÔºü

 So it's like this piece of vice function„ÄÇ It doesn't have any weight itself or any bias unit or weight parameter or something like that„ÄÇ

 It's just a function„ÄÇ So by that it's kind of overkiled to implement it as a class because classes usually create objects„ÄÇ

 and then this object„ÄÇI meanÔºå it doesn't have any parameters„ÄÇ So it's kind of overkill„ÄÇ

 We can just use a regular python function for that„ÄÇ

So this is like the difference between using an object oriented and a functional API and where does it matter„ÄÇ

 So like I showed you before on the left hand side is again the implementation I showed you where I created these weights here„ÄÇ

 the layersÔºå the weight layersÔºå and then I'm using them in the forward pass„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_25.png)

HoweverÔºå there is something that is more convenientÔºå It's the so called sequential„ÄÇClass here„ÄÇ

 So the sequential class executes things„ÄÇIn order„ÄÇ So you can see here my forward method on the right hand side is much shorter than on the left hand side„ÄÇ

So what's going on here„ÄÇ So here on the right hand sideÔºå I'm using sequential„ÄÇ

' it's essentially like a Python list and everything that is inside essential gets executed yeah linearly„ÄÇ

So one by one„ÄÇ So firstÔºå it will execute linearÔºå reluÔºå linearÔºå reluÔºå linear„ÄÇBut it won't„ÄÇ

 So how can I say that it will define it firstÔºå So it will define it in the sequential thing„ÄÇ

 And then we can use it and forward„ÄÇSo I really like this because it's very compact„ÄÇ

 but it's using this object oriented API here„ÄÇBut it's still compactÔºå because„ÄÇ

Here we define the parametersÔºå and then we have to memorize them in what order we use them„ÄÇ

 And then here we call them see that as„ÄÇHere I have linear 1Ôºå linear 2„ÄÇ

 which I have here in the same order„ÄÇ And if you have a deep neural networks with I don't know„ÄÇ

20 layers or somethingÔºå it's easy to make aarrow and copy and paste some values and„ÄÇAccidentally„ÄÇ

 copy and paste them out of order and make mistakes with a sequential one„ÄÇHereÔºå you define the order„ÄÇ

When you create a thingÔºå and then let's say I'm assigning it to my network„ÄÇ

 And then here I'm calling it my network„ÄÇ but I don't have to yeah redo all the forward pass„ÄÇ

 It's automatically in the sequential thing„ÄÇ So I like this actually back in the day when I learned Pyto the first time„ÄÇ

Four years agoÔºå I was using mostly this API because I felt likeÔºå okayÔºå this is„ÄÇ

Better because I'm avoiding object or API for things that don't have attributes„ÄÇ

 But then over the yearsÔºå I kind of„ÄÇLearn to prefer„ÄÇThis API„ÄÇ

 because here it's harder to make mistakes„ÄÇ It's easier to define everything in the right order here„ÄÇ

 I find„ÄÇBut sometimesÔºå of courseÔºå we alsoÔºå yeahÔºå we need to be flexible„ÄÇ

 Sometimes it makes more sense to use the API on the left hand side„ÄÇ for example„ÄÇ

 if we have custom research projects where we want to tinker a little bit more with a code„ÄÇ

 because there's one downside„ÄÇ

![](img/80d91185d87ba37f6d819e7249f6c5a1_27.png)

Of the sequential API„ÄÇ So the sequential hereÔºå the sequential class„ÄÇ

 the problem is if you want to get intermediate results„ÄÇ So with thatÔºå I mean„ÄÇ

 if you want to know whatÔºå let's say the size of this one or there's a buck or something„ÄÇ

 and you want to print the output of this one„ÄÇ So if I go back one more slide here„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_29.png)

Anywhere hereÔºå when it means a different color„ÄÇAnyway hereÔºå I can just insert a„ÄÇPrint„ÄÇüòîÔºåOut„ÄÇ

 for exampleÔºå to print the output value of this oneÔºå if I am curious at itÔºå if I want to look at it„ÄÇ

 it's very easy to just insert a print statement on the right hand side„ÄÇ

 you can't just insert a print statement hereÔºå it won't work„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_31.png)

For thatÔºå we have toÔºå yeahÔºå create so called hooks„ÄÇ So we have to computeÔºå for example„ÄÇ

 a forward hook or register forward hook„ÄÇ So that means reallyÔºå we are hooking into this API„ÄÇ

 So you have to kind of first take a look at„ÄÇThe orderÔºå so the indices so here„ÄÇ

After implementing this„ÄÇSequential thing„ÄÇ this should actually be not netÔºå but my„ÄÇNetwork„ÄÇ

So if I print out„ÄÇMy networkÔºå you can see there are these indices 0Ôºå1Ôºå2Ôºå3Ôºå4„ÄÇ

 It's essentially like a Python dictionary almost„ÄÇ And then I can access this„ÄÇ So if I want to have„ÄÇ

Or if I want to see the output after this linear unit hereÔºå I can„ÄÇAccess it here„ÄÇ

 Register this forward hook„ÄÇIt's a little bit weird„ÄÇ But then when I call the model„ÄÇ

 it will print the output here„ÄÇ So it will print out the result„ÄÇThat comes often here„ÄÇ

 It's instead of inserting„ÄÇ

![](img/80d91185d87ba37f6d819e7249f6c5a1_33.png)

Inserting this print statement hereÔºå I have to register the hook and you can see this is actually more work to register this hook„ÄÇ

 So sometimes it can be a little bit more cumbersome to use the sequential API in some ways it might be easier to do it like this where we can just play around with it more„ÄÇ

 howeverÔºå like I said if you have a very large network with like 28 layers„ÄÇ

 it's also more easy to make a mistake here to yeah somehow have some repetition here or„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_35.png)

![](img/80d91185d87ba37f6d819e7249f6c5a1_36.png)

Things like that„ÄÇ And if you have only„ÄÇThis one where you define it in order and it gets executed in the same order„ÄÇ

 you define it„ÄÇ It's hard to make mistakes„ÄÇ So you have to decide for yourself what API you prefer„ÄÇ

 I meanÔºå it's really up to you„ÄÇ there's no right or wrong both work the same way„ÄÇ

 It's just a matter of yeah I would say matter of taste and I will probably switch more to the sequentially API for the code examples I provide to you but you can also yeah for your class project use whatever you like„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_38.png)

But alsoÔºå yeahÔºå if the multi layer perceptron stuff is a little bit too complicated„ÄÇ

 we will talk about multilay perceptance in next week's lecture„ÄÇ

 So that will be also something we'll be revisiting„ÄÇ

 So you don't have to memorize any of that stuff right now„ÄÇ

 You will see that multiple times later in this class again„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_40.png)

One last thing about Pytorch and style and things like that„ÄÇ

 So I found a very cool Github repository recently a couple of months ago where someone wrote down like the best practices for Pyttorch„ÄÇ

 And I thought that might be also something cool to look at„ÄÇ

 There was also interesting section about Jupiter notebooks versus Python script„ÄÇ

 And that's exactly what I wasÔºå yeah also recommending„ÄÇ So the person here recommends also„ÄÇüòä„ÄÇ

To start with a Jupyter notebookÔºå to do some exploration and stuff like that„ÄÇ maybe do some coding„ÄÇ

 basic coding„ÄÇ And then later on move everything to Python scripts and deploy it on a server' like„ÄÇ

YeahÔºå because there are some advantages of using Jupyter notebooks„ÄÇ

 but there are also some advantages of using Python scripts personally for teaching„ÄÇ

 I really like Jupyter notebooks because like you've seen before„ÄÇ

 I can insert figures and show intermediate results and things like thatÔºå which is really cool„ÄÇ

But it's a little bit more inconvenient to run Jupyter notebooks on a serverÔºå so„ÄÇHereÔºå also„ÄÇ

 like the person mentionedÔºå the files can become huge if we have one single Jupyter notebook and because especially if you print the output in the notebook„ÄÇ

 they will become very long„ÄÇAnd„ÄÇYeahÔºå sometimesÔºå I don't know„ÄÇ

 sometimes computation get interrupted in Jupytern notebooks for some reason„ÄÇ So in that way„ÄÇ

 it's also not ideal for long training„ÄÇ And yeahÔºå it's it's easy to make mistakes in Jupitern notebook because I find the debuggs are not that good„ÄÇ

 I meanÔºå they list here debugging as a pro as a pro argument personally„ÄÇ

 I find debugging and Python scripts honestly easier because you have more help of functions or utilities and for example„ÄÇ

 P charm or visual studio code„ÄÇ I most of the time use a visual studio code„ÄÇ

 but also many people use P charmÔºå which is also very nice„ÄÇ So Python scripts have the advantage of„ÄÇ

That they are more robust when you want to run longer computations„ÄÇ

 and it's also easier to track changes if you use Gitthub and want to look at changes„ÄÇ

 although there are some plugins for Jupyter notebooksÔºå but to be honest„ÄÇ

 it's still simpler with Python scripts„ÄÇI find debugging easier with Python scripts„ÄÇ

 however I also like they say it means rerunning the whole script„ÄÇ

 what an advantage of Jupyter is that you can run one computation or one cell at a time„ÄÇ

Ratherither orÔºå I meanÔºå there are pros and cons on both sides as a deep learning practitioner„ÄÇ

 I think you probably want to use a mix of bothÔºå maybe for simple things and analyses using Jupyter analog notebooks and then later on if you have more sophisticated projects using Python scripts in this class I will also use a mix of both I think for teaching Jupipyter notebook is really nice„ÄÇ

 but for the some codes that I will provide later I think Python scripts make more sense„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_42.png)

AlrightÔºå last thing also from this Gitth repository„ÄÇ

 So here also some yeah recommendations regarding the naming conventions„ÄÇ So usually we use lower„ÄÇ

C conventions with these underscore scores for package modulesÔºå constant„ÄÇ

 as not Con for instances of objects„ÄÇMethods and functions and variables„ÄÇ And for constants„ÄÇ

 we use capitals with anosqua is just a common convention„ÄÇ That is also what I'm gonna use for„ÄÇ

The code in this class„ÄÇ It's like a common convention„ÄÇ OkayÔºå but yeahÔºå you can read through this„ÄÇ

 read me sometime Also later during this courseÔºå it's not like super important„ÄÇ

 But if you read through this rather earlier than laterÔºå thenÔºå yeahÔºå you don't learn„ÄÇ

 let's say bad habits that you have to unlearn later„ÄÇ So it doesn't hurt to read this„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_44.png)

ÂóØ„ÄÇYeah and more Pytage features will also be introduced step by step later in this course when we start working with more complex networks„ÄÇ

BecauseÔºå yeahÔºå I don't want to bombard you with too many things right now because you haven't really seen the more complex networks like convolutional networks„ÄÇ

 So there will be many things we will introduce one by one when we need them„ÄÇ

 So this was more like the big picture„ÄÇ I hope that made sense to you and if not„ÄÇ

 we will see this multiple times again in class„ÄÇ So we will be using this general Pytch layout for almost everything„ÄÇ

AlrightÔºå so with thatÔºå yeahÔºå that was the week here or the first part of the week talking about Pyarch„ÄÇ

 it was a little bit long„ÄÇ I think the Thursday lecture would be a little bit shorter„ÄÇ

 I just want to show you how to use some free computer on GPU resources„ÄÇ

And that is because it will probably be shorterÔºå also a good time than to catch up with yeah„ÄÇ

 other things in class„ÄÇAllrightÔºå so see you on Thursday then„ÄÇ



![](img/80d91185d87ba37f6d819e7249f6c5a1_46.png)