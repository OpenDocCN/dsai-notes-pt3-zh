# ã€åŒè¯­å­—å¹•+èµ„æ–™ä¸‹è½½ã€‘å¨æ–¯åº·æ˜Ÿ STAT453 ï½œ æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆæ¨¡å‹å¯¼è®º(2021æœ€æ–°Â·å®Œæ•´ç‰ˆ) - P10ï¼šL1.5- æœºå™¨å­¦ä¹ ç¬¦å·å’Œä¸“æœ‰åè¯ - ShowMeAI - BV1ub4y127jj

Yeahäº†ã€‚Yeah now let me go over some of the necessary machine learning notation and jargonã€‚

 something that we will be using in this class over and over again and that is also commonly used in the machine learning and deep learning communitiesã€‚

So yeahï¼Œ on revisiting the term supervissed learningï¼Œ What is supervissed learningã€‚

 It's about learning a function that maps some input Xã€‚To some output Yã€‚

 where x are the features and y are the targetsã€‚ Soï¼Œ yeahã€‚

 like you remember from the previous videosï¼Œ the featuresï¼Œ or we also call themã€‚Observationsã€‚

They are usually vectors or yeah for exampleï¼Œ the flower dimensionsï¼Œ sal lengthã€‚

 sal width petal length and petal width or pixels of an image and so forthï¼Œ by the wayã€‚

 if I write a vectorï¼Œ I would then if I do or use handwritingã€‚

 use this a little error to denote a vector and I will try to use if I don't forget an underscore and a capital letter to refer to a matrixã€‚

And Xï¼Œ if I don't use any of this would be a scalar valueã€‚ So hereï¼Œ thoughã€‚

 I was just writing x as a scalarï¼Œ but features in practice can be also vectorsã€‚ So anywaysã€‚

 we are getting ahead of ourselves here a little bitã€‚

 So the next term here on this slide is structured dataï¼Œ which we discussed us in the previous videoã€‚

 So the term structured data usually refers to data in the format of yeah tables can also also think of it asã€‚

Tularã€‚ğŸ˜”ï¼ŒData usually comes in the form of databasesï¼Œ like if you know SQL databasesï¼Œ for exampleã€‚

 or if you think of Excel spreadsheets or CSV filesã€‚

 this would be a typical example of a structured dataã€‚Then yeah unstructured dataã€‚

 this is usually what we refer to as the raw dataï¼Œ for exampleï¼Œ imagesï¼Œ the pixels and imageã€‚

 audio signals or text sentences like documentsï¼Œ and this is usually something that yeah deep learning works withã€‚

So and before deep learningï¼Œ we usually needed extensive feature engineeringï¼Œ as I explained beforeã€‚

 where we extracted features from raw data sourcesã€‚So here on the right hand side Iã€‚

Just wanted to show you another example of yeah raw image input versusã€‚

Something that requires feature engineeringã€‚ Soï¼Œ for exampleï¼Œ here you have a portrait of imageã€‚

 And let's say the task isã€‚Face recognition where you want toã€‚Match multiple facesã€‚

 So here I don't have multiple people where we want to compare whether it's the same person or notã€‚

 So we don't have really face recognition matchingã€‚ Howeverã€‚

 what I'm illustrating here is that we can extract features from this imageã€‚

 So here this is a traditional methodã€‚ using like facial key point extractionã€‚

 So or extracting so-called face landmarksã€‚And on this would be a feature engineering step like simplifying the image such that it only now contains these key pointsã€‚

 I think there are around 67 or so key pointsã€‚ So we reduced the complexity of the dataset by having a high dimensional data setã€‚

 So if this isï¼Œ for exampleï¼Œ200 by 200 pixel imageã€‚We would haveã€‚40000 pixels or 40000 featuresã€‚

 including background and everythingã€‚ and we here we just simplified it and only haveã€‚

 I think it's 67 features I could be wrong you would have to double checkã€‚

 so here this is actually a function I implemented based onã€‚Lirry called Deupã€‚

 which implements this face extractionã€‚Here I'm just yeah I implemented a Python Reper function to make it a little bit simpler to use any caseã€‚

 so here this would be an example of manual feature engineeringã€‚

 like reducing the complexity of the problem by extracting a smaller number of features from this raw inputã€‚

Okayï¼Œ so moving on so here on this slide some more terminologyã€‚

 so a training set we usually refer to it as D and a training set comes in pairs of these observations the so-called training examples or features and the target labels and like I said I will be using this error notationã€‚

 if I do handwriting to refer to vectors so in if I don't do handwriting like in the slides using computer font I will make them boldã€‚

And yeahï¼Œ for scalrsï¼Œ I won't useã€‚Bt frontã€‚Then a training data consists of n training examplesã€‚

 so that's the number of examples in a training setã€‚And I will be using the squareã€‚

Brackt notation here as a superscript to refer to the training data points indexã€‚

 So if I write something likeã€‚10ã€‚Then this means that's the 10th yeahï¼Œ training featureã€‚

Feature vector in the training setsï¼Œ I'm referring to the10th training example to the feature vector of the 10th training exampleã€‚

Soã€‚Then in practiceï¼Œ so usually the data setï¼Œ the training data comes from some data generating distributionionã€‚

 something could be a natural physical phenomenon that has created our data and so forthã€‚

 so there exists some unknown function that associates our feature vectors with some labelã€‚

And the goal in machine learning is yeah in supervised learning is to yeah predict the labelsã€‚

 So how we do that is by approximating this unknown functionã€‚ and yeahã€‚

 traditionally this is called the hypothesis nowadays I think the hypothesis term is a little bit dated we can just call that model we don't have to use fancy terms like hypothesis we can just call that a machine learning model So it's like a more common way to refer to itã€‚

 So you can think of the machine learning model as a function that approximate approximates this unknown functionã€‚

 So it willï¼Œ for exampleï¼Œ in the classification example return predicted label So we can write the predicted label as y head for example or we can just call it target target t or output O always maybe a little bit tricky because it almost looks like a zero but yeah these are all equivalent notationsã€‚

 So in this way is age you can think ofã€‚It is the machine learning modelã€‚Yeahã€‚

 and classification againã€‚ So we have the modelï¼Œ which here is a function that maps some M dimensional input vectorã€‚

 So this would be our features mapping thoseã€‚Yeah to some targets hereã€‚

Where the targets in the term in the context of classifications are class tablesã€‚

 so we can have up to k class tablesã€‚ So usually K is larger or larger equal to twoã€‚

 We have at least two classes in the case of the iris dataset set that I've shown you earlierã€‚

 There were actually three possible classes on Cosaã€‚Vsy colorã€‚And oricaï¼Œ for exampleã€‚ But yeahã€‚

 of courseã€‚Really depends on the dataset setã€‚ there is no limit to the number of classes you can haveã€‚

 Alsoï¼Œ yeah in regressionï¼Œ we have a input vector that is m dimensionalã€‚

 and we map that to a continuous to real valued numberã€‚Yeahï¼Œ more about the feature vectorã€‚

 So I said before the feature vector is n dimensionalã€‚ so if you think backã€‚Of the Iis exampleã€‚

 where we had the Sepalã€‚leengthã€‚S Paulã€‚Withã€‚Polã€‚leengthã€‚And pitalã€‚Withï¼Œ so we hadã€‚For featuresã€‚

And thenï¼Œ if I lookã€‚At the training at at the indexã€‚Let's sayã€‚focuscus in on theã€‚Thirdhirã€‚ğŸ˜”ã€‚

Training exampleï¼Œ I would write it down asã€‚th3ã€‚And then it's a vectorã€‚

 So it's a third feature vectorã€‚ So in this caseï¼Œ we have a vector of consisting ofã€‚For valuesã€‚

 So this is what I'm showing you here as the vector representationã€‚So yeahã€‚

 we have an m dimensional vectorï¼Œ and I will use the subscriptã€‚

Notation to refer to the feature indexã€‚ So if I write something likeã€‚3 hereã€‚

 this would refer to the thirdï¼Œ the 123 to the petal length of the thirdã€‚Training exampleã€‚

Now in Python we start zero indexingï¼Œ so if we do Python codingã€‚

 it might be a little bit more complicated because we should we start indexing at0 in contrast to rã€‚

 So in in Python notation this would be actually the fourthã€‚Training example and the fourth featureã€‚

 like petal widthã€‚Yeahï¼Œ moving on and now here I have a feature vector againã€‚

 just as on the previous slideã€‚ Howeverï¼Œ in practiceï¼Œ we usually have multiple feature vectorsã€‚

 So one feature vector per training exampleã€‚ So if you think back of the iris data set where we had up to 150ã€‚

Training examplesã€‚ Let's use the letter N here over the rows to referï¼Œ yeahï¼Œ to the trainingã€‚

Data pointsã€‚ And then for each oneï¼Œ we had a feature that's called it feature 1ï¼Œ feature 2ã€‚

 feature 3 and feature 4ã€‚So we have this table hereã€‚ So you can also useã€‚Let's seeã€‚ğŸ˜”ï¼ŒDot dot dotã€‚

 featureã€‚å—¯ã€‚Soã€‚Then each data pointï¼Œ So eachã€‚Observation is a feature vectorã€‚

 So in linear algebra notationï¼Œ we usually yeah write a vector as a columnã€‚ Howeverã€‚

 we arrange the vector here as like a row vectorã€‚ So a row vector would be referring to one data point as one observationã€‚

 So we use a transpose on that one toã€‚I'll refer to this one here as the firstã€‚Yeahã€‚

 data point in the tableã€‚ It's a little bit confusing the way I've written it hereã€‚

 because now I'm using the subã€‚ This is just because I have the trans post hereã€‚

 And then it's a little bitï¼Œ yeahï¼Œ a little bitã€‚Squiedï¼Œ so actuallyã€‚

 I could have written it as transposeã€‚Oneï¼Œ for exampleã€‚

 it would have been clear or maybe so maybe ignore this notation here on the right hand sideã€‚

 I have the more Yeahï¼Œ extended notation where I'm referringã€‚

With a superscript to the data point indexã€‚So this would be all the first data point in the first rowã€‚

And then the subscript refers to the feature indexã€‚So if I pickï¼Œ for exampleï¼Œ this case hereã€‚

 this would beï¼Œ what is maybeï¼Œ with unfortunateï¼Œ Let me use this one hereã€‚ This is theã€‚

Second feature of the n data pointã€‚ So this would be if I go right hereï¼Œ so would be this one hereã€‚

 So this scalar valueã€‚ So usually machinery will use a design matrix I will use bold letters and if I handr this I will try to use an underscore code to make sure to indicate that this is a matrix because with handwriting it can be unclear if I do an x it's unclear if I don't yeah deote it further whether it's a vector or matrix and so forth So again for vectors I will use this notation and for matrices this notation and I may forgetã€‚

 but I will try not toã€‚Okay yeah just to summarize this is a structured data set how it would look like in machine learning in the first couple of lectures we will actually be using with structured data before we go into working with unstructured data so in the first couple of lectures just as a warm up using simpler deep learning related methods like single layer neural networks and then multilayer neural networks that are fully connectedã€‚

 they will be working with also structured data and then when we talk about convolutional networks and recurrent neural networks which are the real innovations in deep learning then we will be using unstructured dataã€‚

Alrightï¼Œ so yeahï¼Œ just to recap M is theã€‚Petureã€‚å—¯ï¼Œ numberumberã€‚So we have up to M featuresã€‚

 and N is theã€‚Yeahã€‚Numberã€‚Of trainingã€‚Examplesï¼Œ so I think the reason why I left the blank hereã€‚

 I wanted to ask you on that as an exerciseã€‚ So in that wayã€‚I already did the exercise for youã€‚

 So hereï¼Œ the rowã€‚ I think it was what I was referring toã€‚Yeahï¼Œ training examplesã€‚

Where the columns are alongã€‚Featuresã€‚And this is our one class label columnã€‚All rightã€‚

 so it was not very excitingï¼Œ but yeah I was just summarizing how we think of a data set in the context of machine learningã€‚

ğŸ˜Šï¼ŒNowï¼Œ if we have image dataï¼Œ how do we deal with thatã€‚

 How does it fit into our yeah concept of representing dataã€‚

 So images are actually unstructured dataï¼Œ as I mentioned beforeã€‚

 but we can actually convert it into a structured data set and if you think of image like thisã€‚

 this is actually a 28 byã€‚28 imageï¼Œ which should be 700ã€‚84 dimensionalï¼Œ so we have 784 pixelsã€‚

Pixels are usually in the range between 0 and 255ï¼Œ however hereã€‚Assume I normalized the dataã€‚

 we will talk more about why data normalization is usefulã€‚

I normalize it such that the pixel values are in the range between 0 and1ã€‚

 So we have a pixel like several hundredã€‚Of thisã€‚There are 84 of these pixels hereã€‚

 so you can actually allã€‚Can see this actually lower resolution one pixel here and one pixel here and so forthã€‚

 So I thinkï¼Œ yeahï¼Œ you know what I mean by pixelã€‚ So we can actually use that as input to a traditional machine learning method in terms ofã€‚

Thinking of this as a structured data set by concatetnating the rows so we can make a long feature vector out of this image becauseã€‚

 I meanï¼Œ this is a matrixï¼Œ rightï¼Ÿ So it's likeã€‚å—¯ã€‚28 by 28 matrixã€‚

 but we can convert this into a vector by just concatetnatingã€‚ So take the first rowã€‚

Let's see this first row hereã€‚And then we have the second rowã€‚And just add it here to the first rowã€‚

And thenã€‚Third rowã€‚Heading it hereã€‚ So and if I keep doing thatï¼Œ I get a very long vectorï¼Œ in factã€‚

 a 784 dimensional vectorã€‚ and that is what I am showing you here in the centerã€‚

 we're probably already wondering what these numbers areã€‚ and these are the pixel valuesã€‚ So the 0ã€‚

0 refers to a white pixelã€‚ So you can see in the beginning hereã€‚The image is all whiteã€‚

 So we have all the white 0ã€‚0s hereã€‚ and then yeah you have these gray scale and black pixels which are about hereã€‚

 So we kind of converted this unstructured data set into a feature vector that we can then use with traditional methodsã€‚

 and we will also yeah be doing that inã€‚A context of deep learning using simpler methods like multi layerer perceptronsã€‚

 fully connected neural networksï¼Œ so we will start with a simple approach and then build up to it and then later use the unstructured data directlyã€‚

Alrightï¼Œ so yeahï¼Œ like I said before convolutional neural networksã€‚

 which will be a topic yet later on in this courseï¼Œ convolutional neural networksï¼Œ they useã€‚

The image data directly and usually the format for that is also a matrix more precisely it's actually a three or four dimensional tensorã€‚

Here so there are two two common representationsã€‚ one is called NCHWã€‚

 We will talk more about that later when the time comesã€‚

 but maybe if you are curious what it stands forï¼Œ H stands for the heightã€‚

W stands for the width of an imageã€‚ So we have here the H times Wã€‚ So this would be a matrixã€‚

 Howeverï¼Œ there's usually also a color channelã€‚So C stands for color in this caseã€‚

 we don't have color because it's a black and white imageã€‚ So in this case it's so there's a oneã€‚

 So actually I'm showing you here the dimensionsã€‚ So 28 by 28 height times width and then the color channel and then usually in deep learning what we do is we bundle a bunch of images together as input for the neural networkã€‚

 So in we have something called a batch sizeã€‚ So here I have 128 images where each image isã€‚

3D tensorã€‚ So in that wayï¼Œ if I consider all of thatï¼Œ it's a 4D tensorã€‚ So in that wayã€‚

We are representing the data as ten source and this is why we need some basic linear algebra for this course while I mean we won't be using fancy things just simple matrix multiplications and dot products and I will also talk more about that later so right now I don't want to go into too much detail because convolutional networks that is topic far ahead a few weeks ahead and I don't want to talk too much about this hereã€‚

 I have to be honestly a little bit careful with the time because like you noticed I always try I try to avoid it but I always end up going on tangents and talking about things in too much detail too early I think so let me move on thenã€‚

Yeah here lastly machine learning jargon part2ï¼Œ so somewhat terms we will be usingã€‚

 I think this is more like useful as a cheat sheetã€‚

 like something you can maybe refer to later when certain terms are unclear so when we say for example training a modelã€‚

That is the same as sayingï¼Œ for exampleï¼Œ fitting a model or parameterizing a model or learning from dataã€‚

Then he had the word training exampleã€‚ it's synonymous to sayingï¼Œ for exampleã€‚

 training record or training instance or training sampleã€‚Howeverï¼Œ yeahï¼Œ for exampleã€‚

 when I teach other statistics classesï¼Œ I usually use often as staians we use the term sampleã€‚

 but I find sample can be a little ambiguousï¼Œ especially in the context of deep learning because if we say training sample it's not clear really whether we are referring to a single training data point or multiple training data pointsã€‚

 So for example when I was writing my python machine learning book in 2015 in the first editionã€‚

 I used the term training sample as I rememberï¼Œ I mean it has been six years agoã€‚

 but I think I used training sample throughoutï¼Œ and then sometimes I noticed it was a little bit confusing do I mean now a single data point or do I mean the training data as a training sample So I data also went back and changed everything to saying training exampleã€‚

 if I refer to a simple or single training example and then also plural I would say training examplesã€‚

IThink this is a little bit more clearã€‚ And this is also something most people in machine learning and deep learning nowadays useã€‚

 So the term training exampleã€‚Then yeah feature feature is also synonymous to observation or predictorã€‚

 variableï¼Œ independent variableï¼Œ inputï¼Œ attributeï¼Œ Covariateã€‚

 So in other statistics classes we are often using the termï¼Œ for exampleã€‚

 predictor and things like that or even covariate so here in machine learning and deep learning we usually use the term featureã€‚

Then yeah we have the term targetï¼Œ which is synonymous to outcome ground truthã€‚

 output response variableï¼Œ dependent variable in a specific context of classificationã€‚

 We also say class label or yeahï¼Œ just labelã€‚So alsoï¼Œ these are all the same thingã€‚

 And then yeah lastly here output predictionã€‚ And this is what the model producesã€‚ This is differentã€‚

 Yeah from the targetã€‚ So the target is we want to predict the targetã€‚ So this is the groundã€‚

Truth or something that is provided in the data set and the prediction or output is the thing that the model returnsã€‚

 and we want to usually match the targetã€‚Okayï¼Œ so this is it forja jargon and the next video I want to briefly talk about a little bit more about the tools that we will be using in this courseã€‚



![](img/a5f179f50ae9a5cb408d8f689cdbf576_1.png)

![](img/a5f179f50ae9a5cb408d8f689cdbf576_2.png)