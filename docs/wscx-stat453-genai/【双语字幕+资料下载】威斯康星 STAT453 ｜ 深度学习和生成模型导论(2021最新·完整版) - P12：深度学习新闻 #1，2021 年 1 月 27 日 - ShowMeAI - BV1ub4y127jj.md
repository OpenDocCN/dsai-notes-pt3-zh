# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëÂ®ÅÊñØÂ∫∑Êòü STAT453 ÔΩú Ê∑±Â∫¶Â≠¶‰π†ÂíåÁîüÊàêÊ®°ÂûãÂØºËÆ∫(2021ÊúÄÊñ∞¬∑ÂÆåÊï¥Áâà) - P12ÔºöÊ∑±Â∫¶Â≠¶‰π†Êñ∞Èóª #1Ôºå2021 Âπ¥ 1 Êúà 27 Êó• - ShowMeAI - BV1ub4y127jj

YeahÔºå hi everyone„ÄÇ I decided to make a short bonus video stuff in the news„ÄÇ

 interesting things related to deep learning„ÄÇ So here I'm just briefly talking about cool things I discovered in the news this week related to deep learning„ÄÇ

 And I think it's just fun to yeah talk about the recent developments in deep learning just to stay up to date with things„ÄÇ

 So I'm planning to release such a video every week if I have time„ÄÇ

 So it's also on the optional So you don't have to watch them So it's something just watch it if you're interested in if not don't worry about it„ÄÇ

 It's just like some fun additional video content for this class„ÄÇ So then yeah„ÄÇ

 let me get started and let me tell you what happened in the world of deep learning this week„ÄÇYeah„ÄÇ

 let's start with a cool application of deep learning for CoVD 19 resource needs„ÄÇ

 predictions from a series of x rays„ÄÇSo this was a project by Facebook AI research in collaboration with medical doctors at NY U„ÄÇ

 And it's always cool to involveÔºå yeahÔºå domain experts„ÄÇ I think that's super important„ÄÇ

 as I mentioned in the„ÄÇüòäÔºåLectsÔºå it's always a good idea to consult people who actually have some expertise in the data that you're working with„ÄÇ

 especially if it's an important applicationÔºå like a medical application„ÄÇ So in this case„ÄÇ

 the researchers trained three models to predictÔºå yeah„ÄÇ

 patient deterioration and to help predict the resource requirements like oxygenÔºå so„ÄÇ

Here in the first modelÔºå they predicted the deterioration of the patient from only one x ray image that did the same thing„ÄÇ

 the same prediction task now from also a series of x rays„ÄÇ

And the third model was predicting the oxygen supply needed„ÄÇ Yeah„ÄÇ

 for helping a patient that was also based on a single x ray„ÄÇ So of coursea„ÄÇ

 it's usually helpful to have multiple x rays that can also then yeah boost the performance if you have a sequence of x rays and you can yeah„ÄÇ

Tickle this as a time serious problem„ÄÇ HoweverÔºå these models also work if only one single x ray is available„ÄÇ

So how they approached this modeling task was that they pretrained the deep neural network on a large noncoviId chest X- ray database„ÄÇ

 so they used a general Xray databaseÔºå Why did they do that„ÄÇ

 That's because they had a larger dataset available this way„ÄÇ

 Because there are only limited numbers of X rays from COVID patients at this point„ÄÇ

So here they used selfsupvised learning„ÄÇ remember from the lecture selfsvised learning is this new trend where you pretrain a model on a socalled pretext task and then you find unit to your targeted data set„ÄÇ

 So here they did the fine tuning based on a smaller CoVID-19 x- ray data set where they had 27000 xrays from 5000 patients„ÄÇ

And what was interesting is that yeahÔºå these methods they developed outperformed human experts on some of the measures„ÄÇ

 So of course it's yeah not a good idea probably to replace humans„ÄÇ

 but I think developing these systems can be really useful to help humans because yeah„ÄÇ

 everyone is stretched very thin these daysÔºå especially do the large amount of patients at hospitals right now„ÄÇ

 So maybe„ÄÇYeahÔºå the doctor's task can be done more effectively in the combination with deep learning„ÄÇ

 especially for exampleÔºå if you think of medical staff that is maybe a little bit tired having a deep learning system taking also yeah a second look at these images X race could maybe help yeah avoid making mistakes„ÄÇ

So you can find the full paper here on archive and they also uploaded the pretrain models on GitHub if someone is interested„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_1.png)

YeahÔºå regarding CoVd 19 researchÔºå so on archiveÔºå which is a preprint setup„ÄÇ

There's a large amount of thousands of papers or manuscriptsÔºå preprints uploaded regarding Covid-19„ÄÇ

 So this is a general preprint server for machine learning we have a lot of papers on this server„ÄÇ

 so I help moderating the machine learning categories and every day there are about 140 new papers about yeah deep learning and machine learning so it's like a huge amount of papers I think there are now in total like 140 million papers across different research domains„ÄÇ

In any caseÔºå you can use the search function to also search for„ÄÇYeah has specific research„ÄÇ

 And here I„ÄÇYeah try to search a keyword combination to also yeah bring up more Covid-19 related research with deep learning So what I showed you here in the previous sni was pretty cool but of course it's not the only approach using deep learning for CoVID prediction from chest x-rays So here using these search terms you can find many more works in this area„ÄÇ

 but yeah also you have to take this a little bit with a grain of salt because not of all of these papers have undergone peer review„ÄÇ

 So some of the findings maybe spurious or maybe less rigorous„ÄÇ

 so always take archive papers with a grain of salt„ÄÇ

 I will post a link so you can access these papers if you are interested in thatÔºå for example„ÄÇ

 for the context of your class projects„ÄÇ

![](img/a232ad23b114e800c7d0b426557a7565_3.png)

![](img/a232ad23b114e800c7d0b426557a7565_4.png)

![](img/a232ad23b114e800c7d0b426557a7565_5.png)

YeahÔºå there was another interesting research project related to Covid 19 was the learning of the language of viral evolution and escape„ÄÇ

 So this was an article where the researchers described the training of a bidirectional LSTM„ÄÇ

 So an LS LSTM stands for„ÄÇLong„ÄÇüòîÔºåShort term memory„ÄÇIt's a recurrent neural network of flavor„ÄÇ

 and it's a particularÔºå yeahÔºå you can think of it as a particular version of the R and N„ÄÇ

 and we will talk also about that more later in this course„ÄÇ

So here they trained a bidirectional LSDM bidirectional just means that they process a sequence from both ends from beginning to end and from the end to the beginning„ÄÇ

 and it's a language model„ÄÇ So here they treat the amino acid sequence corresponding to a virus„ÄÇ

They treat this as a language model like textÔºå for example„ÄÇ

 and they also draw some analogies from language modelingÔºå for example„ÄÇ

 they consider the context of being grammatically correct as the biologically being correct„ÄÇ

 like is this like a correct sequenceÔºå a correct aminosic sequenceÔºå is it a plausible one„ÄÇ

And then also considering its semantic meaningÔºå so here in context of a language„ÄÇ

 the semantic meaning would be at the meaning of the sentence here it's whether yeah the sequence causes immune responses or not„ÄÇ

And yeahÔºå they got a pretty good performance„ÄÇ They have a point85 A U„ÄÇ A U C stands for„ÄÇA are„ÄÇ

Another curve„ÄÇWhich is rather ambiguous because what curve do we mean here„ÄÇ

 if there's no context if you see something like Auc see in a paper„ÄÇ

 it usually means receiver a operating characteristic area under the curve„ÄÇ So R O„ÄÇ

 It's a measure of false positive and true positive rates„ÄÇ if you shift the prediction threshold„ÄÇ

 but it's maybe too much detail at this point„ÄÇ So what's important is that a 0„ÄÇ5 is random„ÄÇ So 0„ÄÇ

5 is a random prediction and 1„ÄÇ0 is a perfect model„ÄÇ

 So in this way they are yeah closer to a really good model than to a random or bad predictor„ÄÇ

 So yeahÔºå that is another interesting Covid-19 paper moving on to the more like business side of AI or deep learning there was also something I found really interesting that interesting„ÄÇ

 but it was like quite a headline„ÄÇ So there's like a project called human AI„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_7.png)

That just got a 3„ÄÇ2 million of funding to build a personal intelligence platform„ÄÇ

 So here that sounds very interesting„ÄÇ So what it is about is that they are building an individual personalI that is secured by a blockchain to retain and recall information„ÄÇ

 so you have two buzzwords in here„ÄÇ So you have the eye and blockchain„ÄÇ

So this is building a knowledge base in a way it sounds like it„ÄÇ

 but based on an individual's information„ÄÇ so you can maybe also think of it as a second brain zone„ÄÇ

They say it's made possible through a convergence of neuroscience„ÄÇ

 natural language processing and blockchain to deliver seamless in the moment„ÄÇ

 recall G3 is built on the memories of the public InternetÔºå While Luther„ÄÇ

 thats their system is built on the memories of your private self„ÄÇ

 So it sounds like yeah they are attempting to build a second brain or„ÄÇ

Digital copy of your brain that it kind of also reminded me of„ÄÇ

Of this movie seen here or actually TV show sceneÔºå it might be also fun to let me know if you know what the name of the TV show is as a little side quiz here„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_9.png)

AnywaysÔºå moving on so regarding yeah access to data to make a transition here„ÄÇ

 there is also a cool initiative by Twitter„ÄÇ So Twitter is opening up its full tweet archive to academic researchers for free„ÄÇ

 So they have been yeah projects before academic projects by people used Twitter data„ÄÇ

 but as I as far as I know it was a little bit tedious„ÄÇ

To access the data through the API because there were some limitations now yeah they say they want to make this easier and to give more access so they say for example„ÄÇ

 they are giving applicants approved applicants a higher monthly tweet volume cap of 10 million tweets so per month which is 20 times higher than what it was before„ÄÇ

And yeahÔºå they also a allow more precise filtering to help researchers pinpoint tweets and other relevant„ÄÇ

Data to what they are studyingÔºå basically„ÄÇ So in that way„ÄÇ

 of making research based on Twitter a little bit more convenient„ÄÇ So what can you do„ÄÇ

 what what is Twitter data useful forÔºå Why isÔºå Why is that actually coolÔºü

 So they are actually quite some projects involving social media data that are quite useful beyond just their simple sentiment analysis„ÄÇ

 So here I saw another news article where they are using a artificial intelligence to manage extreme weather events„ÄÇ

 So in this research„ÄÇ

![](img/a232ad23b114e800c7d0b426557a7565_11.png)

They use social media contributionsÔºå for exampleÔºå tweets to more usefully manage crises„ÄÇ

 so they developed a noise reduction„ÄÇMechanism to filter for valuable information from social media to better SS trouble spots where there are„ÄÇ

 for exampleÔºå floods or snowstorms and so forth„ÄÇSo„ÄÇYeahÔºå that was another interesting„ÄÇ

Application of deep learning where information can be efficiently accessed toÔºå yeah„ÄÇ

Help certain areas where there are problems„ÄÇ

![](img/a232ad23b114e800c7d0b426557a7565_13.png)

OkayÔºå talking about data setsÔºå large data sets„ÄÇ So one data set that is very common in the deep learning community very commonly used as a benchmark is the imagenet data set„ÄÇ

 I think it's alreadyÔºå yeah„ÄÇ16Ôºå16Ôºå15 years old„ÄÇ It has been released around 2005Ôºå2006„ÄÇ

 It's still very popular„ÄÇ It's a very large data setÔºå about 14 million images„ÄÇ

And it's usually used for evaluating the classification performance of image models like convolutional neural networks or now also visual transformers„ÄÇ

So the problemÔºå thoughÔºå is thatÔºå yeahÔºå the image data set is kind of notorious for mistakes„ÄÇ

 and there are also incomplete labels„ÄÇ So sometimes you have multiple object in an objects in an image„ÄÇ

 for example„ÄÇAs shown in hereÔºå you have a cow here and then a barn and„ÄÇSomeÔºå yeahÔºå I don't know„ÄÇ

 maybe also sky in the background„ÄÇ So there are multiple things going on„ÄÇ or actually„ÄÇ

 they call it an ox„ÄÇ So they are„ÄÇOhActuallyÔºå noÔºå it's it's the fence„ÄÇ I just see it here„ÄÇ

 It's the fence here„ÄÇ So there are multiple objects in this image„ÄÇ And if you train a classifier„ÄÇ

 a regular classifierÔºå usually it only gives you the most confident class label as the prediction„ÄÇ

 So if you have a classifier that predicts barn it may be wrong because the image was just labeled with ox here„ÄÇ

and in that wayÔºå that„ÄÇThe classifier may be correctÔºå but you are counting it as a misclassification„ÄÇ

 So here in this projectÔºå the researchers are relabelling imagenet„ÄÇ

 So they are adding multiple labels to the image here„ÄÇ So they are using„ÄÇ

Also machine learning to do that because yeah would take a lot of people or resources to look at these 14 million images and yeah to assign the correct labels so they make their life easier by also using deep learning for that so it's kind of like a chicken egg problem„ÄÇ

What comes firstÔºå the data or the model the model can then be used for labeling the dataset here what they do is they use a different data„ÄÇ

 They use 1 billion images from Instagram and they train a model called efficient net for for training this model to become a machine annotator to annotate the 14 million images in image net„ÄÇ

 they use crop regions for that So they are cropping different regions of the image So for example as shown here they are cropping the image into smaller regions and then apply a classifier to each of these smaller regions to obtain the class label and then have this multilabel context for each image that is also something I found actually useful and interesting„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_15.png)

YeahÔºå another project from Facebook AI research here„ÄÇ

 I also also thought that might be a cool application of machine learning and deep learning that has some„ÄÇ

 yeahÔºå use for„ÄÇThe real worldÔºå so here„ÄÇSo what Facebook did is they used AI to improve photo descriptions for people who are blind or visually impaired„ÄÇ

 So they developed a smartphone app„ÄÇThat yeahÔºå where you can take a picture and that app can then describe what can be seen in that picture„ÄÇ

 like an audio„ÄÇMessage so this system has been aroundÔºå I thinkÔºå for a couple of years„ÄÇ

 but they are just improved to make it more accurate„ÄÇ So here they trained a resnt model on 3„ÄÇ

5 billion Instagram photos and the corresponding hashtags and they also are combined with a fast R C andN object detector to describe different aspects of this image„ÄÇ

 So for exampleÔºå here in this example the description is it may be an image of one person standing on or at Machu Piccu„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_17.png)

So going back hereÔºå this is kind of similar to these crop regions where people have these different crops of the same image and then assign a label here„ÄÇ

 it's a similar approach that you haveÔºå for exampleÔºå personÔºå Machu Piccu and so forth„ÄÇ

 but yeah the addition here is that there's also a text describing this or putting this into context„ÄÇ



![](img/a232ad23b114e800c7d0b426557a7565_19.png)

![](img/a232ad23b114e800c7d0b426557a7565_20.png)