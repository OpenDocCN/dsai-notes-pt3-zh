# P41ï¼šæ·±åº¦å­¦ä¹ æ–°é—» #3ï¼Œ2021 å¹´ 2 æœˆ 13 æ—¥ - ShowMeAI - BV1ub4y127jj

Yeahï¼Œ hiï¼Œ everyoneã€‚ So all good things come in threesã€‚ and I'm back with stuff in the news number3ã€‚

 Last weekï¼Œ I talked a lot about language models for deep learningã€‚ And this weekã€‚

 my news section will be more focused on computer vision modelsã€‚

 which is also a little bit closer to my research area because there happened a lot of interesting stuff around computer vision this weekã€‚

 there are lots of things to talk aboutã€‚ So let me get started and dive inã€‚ðŸ˜Šï¼ŒYeahã€‚

 let's start with a good old fashioned computer vision application image recognitionã€‚

 So here the title of the paper is high performanceã€‚

 La scale image recognition without normalizationã€‚ So here the researchers has developed a deep neural network that can achieve new image classification state of the art results without batch normã€‚

 So if you encounter this work here Sotaï¼Œ this usually stands forã€‚State ofã€‚

The art and means that you achieve a state of the art performance in terms of the best possible performance or among the best possible performances compared to other cutting edge state of the art modelsã€‚

 So hereï¼Œ what was the noveltyã€‚ So hereï¼Œ the novelty is that they achieved this state of the art performance without batch normalizationã€‚

 So batch normalization is something we will be covering later in this semesterã€‚

 And it's a technique that has been used in the lastï¼Œ I would sayï¼Œ4 or five years to getï¼Œ yeahã€‚

 stable and good performing modelsã€‚It's like a type of data normalization techniqueã€‚

 and we will come this in more detail later in classã€‚

 So here what's new is basically that they achieve the good performance now without batch normalizationã€‚

 Basically making models simple againã€‚ So what did they use hereã€‚

 So here they developed an adaptive gradienting clipping techniqueã€‚

To overcome the instabilities that arise from not using batchomeã€‚

 So there have been also some other models recently in a last couple of months or years that achieved state of the art performance without batchomeã€‚

 but they were usually more unstableã€‚ So more unstable towards little fluctuations in the data set and so forthã€‚

 So here they achieved really good performanceã€‚Without this normalization techniqueã€‚

 so they developed so calledled normalizer free residual networksã€‚

 So restnets or residual networks are also something we will be covering in the semester in the convolal network lectureã€‚

 So we will be likely also revisiting this paper thenã€‚

What is also interesting is how they evaluated the performanceã€‚

 So here I have a screenshot from the paper on the Y axisã€‚ you see the imagenet top one accuracyã€‚

So recall from the introductory lecturesï¼Œ I I mentioned the challenges with Inet where you can have multiple possible labelsã€‚

 So in this way usually people also call or compute the so-called top 5% accuracy because yeah if there is something let's say you have a bus or a car in an image there are multiple possible labelsã€‚

 for exampleï¼Œ it could be a vehicle car automobile and stuff like thatã€‚

 So there are multiple possible ways to yeah have a correct label and sometimes there are also multiple objects in an image here yeahã€‚

 for some reason I mean the researchers yeah use the top1 accuracyã€‚

 I think top five accuracy both are yeah important things to look at in any caseã€‚

 but it's interesting hereã€‚The X axis so here on the X axis the researchers also focused on computational efficiencyã€‚

 so here they call it the training latency as I think it's seconds per step on a TUã€‚

 so this is like the tensa processing unit equivalent to a GPU or similar to a GPU and they looked at a batch size of 32 per device so they used multiple devicesã€‚

 multiple TUus in parallelã€‚Yeahï¼Œ but what is interestingï¼Œ thoughã€‚

 is to think of it as the just like the efficiencyã€‚ So the right hand sideã€‚ So here it's moreã€‚

Expensiveã€‚And this one here on the left hand side would be cheaperã€‚

 make cheaper to train faster to runã€‚So and why is that interesting to look atã€‚

 it's because usually you can also think of it as if you make a model largerã€‚

 you have more parameterssï¼Œ you will likely get a better performanceã€‚But then at the same timeã€‚

 also these networks become more expensiveï¼Œ so depending on your application you are interested also sometimes in smaller models because you cannot run these large modelsã€‚

 for exampleï¼Œ on a cell phone or iPhone or something like that where they have on device machine learning algorithmsã€‚

But then also at the other handï¼Œ you otherwiseï¼Œ still can make the argumentï¼Œ the together the modelã€‚

 the better the performanceã€‚ And you want to also see whether the method just works for yeah smaller modelsã€‚

 So here they have different flavors of the methodã€‚ F 0 to f 5ã€‚

 I think these are just different sizes of the modelã€‚ And you can seeã€‚In terms of accuracyã€‚

 their method is yeah better than all the other methods here and these are actually pretty good methodsã€‚

 it's like efficient methodsï¼Œ but it's called efficient net for exampleï¼Œ Lambdanetã€‚

 I think the stands for data efficient image transformer and so forth so you can see for all types of yeah model sizes their method performs better than these alternatives but again these are different architectures we will talk more about the convolution network architectures later in this course what was interesting really here is that yeah you can also achieve good performance without using batch normalizationã€‚

Yeahï¼Œ here's another interesting thing I found this weekã€‚

 It's not so much a news article but a Reddit discussion from the Reddit machine learning subditã€‚

 which has sometimes really interesting and useful insightful discussionsã€‚

 So here someone asked about deep learning theory like wondering about the recent advances of or in the theory of deep learningã€‚

 like certain understandings how we think of deep learningã€‚ So in the last couple of yearsã€‚

 there were someã€‚Hypotheses that were particularly popularã€‚ For exampleã€‚

 the lottery ticket hypothesisï¼Œ which is essentially aboutï¼Œ yeahï¼Œ saying that just by chanceã€‚

If you train a large overpoorized network with lots of combinationsã€‚

 just by chance there is a high probability that at least one of them will yeah have optimal performance just because you considered so many variations or combinations that just one of them performs well by chanceã€‚

 there's a lot of evidence in favor of this hypothesisã€‚

 but I also recall like a couple of weeks ago or months agoã€‚

 I think what was 2020 there was a paper like giving evidence against this lottery ticket hypothesis And in this way I'm actually not sure in how far this hypothesis is still a valid hypothesis anywaysã€‚

The other one is the double decentscent hypothesisï¼Œ which is also particularly interestingã€‚

 So here at the bottomï¼Œ I have a screenshot of this hypothesis from a different blog post article because it was just a nice imageã€‚

 soã€‚What is shown here is the test and the training errorã€‚ So in contrast to the previous slideã€‚

 the lower is betterã€‚ So in the previous slideï¼Œ we had accuracyã€‚

 so the higher was better here it's the lower is betterã€‚ And here we haveï¼Œ for exampleï¼Œ the viewã€‚

 the expected viewï¼Œ the classical statistics viewpointï¼Œ soã€‚Hereï¼Œ you canã€‚

Think of it in a classical statistics viewpoint that you start with a modelã€‚That has a high errorã€‚

 Why is the error highã€‚ Yeahï¼Œ that is becauseã€‚Usually your model is too simple to capture the complexity in the dataã€‚

 so your model doesn't have enough parameters and then it's too simple and cannot achieve a good classification performance becauseã€‚

 for exampleï¼Œ think you have think of a nonlinear decision boundary that you need to classify the dataã€‚

 but you only have a linear model in this way the model is too simple to captureã€‚

The patterns in the dataã€‚ And as you make your model more and more complexã€‚

 maybe think of adding more layers to a neural networkã€‚

 then your training error will go down and the test error will also go downã€‚

 but at some point the test error will go up again because you have now so many parameters that your model starts overfittingã€‚

 So in this way your model will perform worse with a given sizeã€‚

 So here they use the residual networkã€‚ we will talk about residual networks also later in this classã€‚

Yesï¼Œ so this is the classic yeahï¼Œ statistical viewpoint withã€‚Let's maybeï¼Œ yeahã€‚

 let's consider the modern modern viewã€‚ The modern view is usually the more data you have the larger sorry the the larger the accuracyã€‚

 but also the smaller the errorï¼Œ basically So but the reality is that theres usually this bumpã€‚

 That is what researchers has yeahï¼Œ found outï¼Œ I think in the last couple of yearsã€‚

 So if you look at it in practiceï¼Œ you startã€‚With a high accuracyï¼Œ the accuracyï¼Œ sorryï¼Œ high errorã€‚

 the error goes downã€‚But then yeahï¼Œ it goes up again for some reasonã€‚ Soã€‚

 and then there is this bumpã€‚ and then it goes down againï¼Œ which is a little bit weirdã€‚

 So people call that the double descent hypothesis because you go first downã€‚

 then you go up and then you go down againã€‚ So right nowã€‚

 I think it's also still a discussion whether this is a valid thing or whether this is maybe due to accidentalã€‚

Experimental errors like someoneï¼Œ maybe add some little bug in their code or something like thatã€‚

 But so farï¼Œ all the evidence shows that this is indeed a phenomenon that can be observedã€‚ And yeahã€‚

 that was another interesting hypothesis that is currently still under discussionã€‚

 So if you're interested in more of these types of thingsã€‚Check out this subdã€‚

 there are way more hypotheses listed below there in the thread so people discuss these types of thingsã€‚

 and I think it's just interesting if you are curious about these thingsã€‚Yeahã€‚

 another interesting research article I saw was this one he entitled Reming biased data to I fairness and Eã€‚

 soundss like a relatively straightforward approachã€‚

 like if you have unfair system and this is like also a very important topic due to your data sets sometimes and other reasons machine learning systems can be unfair towards certainã€‚

Subpopulationsï¼Œ for exampleï¼Œ and here the researchers tested the idea that removing biased dataã€‚

 whether this can improve the fairness and maybe even the accuracy of the system and what they found what was quite interesting is that they achieved a low discrimination of almost 0% when they trained the model on the biased data so by just changing the data said they were able to reduce the discrimination of the modelã€‚

But what was also interesting is that they saidã€‚While observed in higher accuracy compared to models trained on the full dataã€‚

 so basically they removed biased data points and not only did they improve the fairness of the machinery modelã€‚

 but they also achieved a higher accuracyã€‚So and according to the authorsï¼Œ for exampleã€‚

 other methods that are being used to make machine learning more fair usually achieve this fairness at the expense of accuracyã€‚

 so usually when people want to make a machine learning model more fairã€‚

 the accuracy goes down and then here they found yeah the opposite you make it more fair and the accuracy goes up which which sounds like a win- win situationã€‚

So here' just a brief overview of what they didï¼Œ so they started with the biased training data and they had a feature extractor generated similar pairsã€‚

 so similar pair in terms of you have a data point from so maybe let me step back take a step back so they evaluated it on eight data sets hereã€‚

where they had multiple attributes and they had also a sensitive attributeï¼Œ for exampleã€‚

 the sex of a person or the race of a person and what they wanted to predict isï¼Œ for exampleã€‚

 different things like incomeï¼Œ credit worthinessï¼Œ exam scores and so forthã€‚And theyï¼Œ for exampleã€‚

 generated similar pairs withï¼Œ for exampleï¼Œ someone who hadã€‚

 or where some instances where the sensitive attributes were differentã€‚

 but everything else was the sameã€‚So they found individuals treated unfairlyã€‚

 and they trained algorithms based on this biased modelï¼Œ they then rank theseã€‚

Instances by influence of how much influence these instances had on the modelã€‚ And then hereã€‚

 they sorted the training dataï¼Œ removed the data points and trainedã€‚

Model on this the biased dataset set measured the discriminationã€‚

 And then if the discrimination decreasedï¼Œ they did another round and removed more data points so they kept going until no improvement could be made and they found by by this simple approach they could yeah improve both the fairness and the accuracyã€‚

 which it sounds like a good ideaã€‚But I'm not an expert in this areaã€‚

 but it sounds like something that yeah should be explored more and maybe also applied to some deep learning modelsã€‚

 so I found this interestingã€‚Related to also the training data influenceã€‚

 I saw this article by the Google AI research teamsï¼Œ so they had a block articleã€‚

 but in the block article is's also a link to the paper to the original paperã€‚

 so they call their method trace inï¼Œ which is the simple method for estimating the training data influenceã€‚

So what they do is during trainingï¼Œ they record the changes in the prediction caused by an individual training exampleã€‚

 so they train a model and then look whether the training performance is yeah how much the training and performance is influenced by this particular data point and this technique is especially then useful for detecting outliersã€‚

And also what you can do with this technique is you can explain predictions so to get some insights into the AI model from the training examples rather than the features so most techniques for interpretability usually focus on the features it's basically about saying okay this and this attribute in the training set is important for making predictions here they look at it from the perspective of training examples like which training examples have a large influence on the model and I can imagine if you think back of the previous slide this model on fairnessã€‚

 I think those two methods might be also interesting to combine in a way that might be a good or interesting thing to look atã€‚

These influential training examples and how they maybe influence the fairnessã€‚

Might be a future research direction anywaysï¼Œ or could be something interesting for your class projectã€‚

 In any caseï¼Œ so here's a figure from this blog postã€‚So here on the X axisã€‚

 they have the updates during trainingï¼Œ so the different model updates on the Y axis is the loss and here they take a look at the class zucchiniã€‚

And they noticeï¼Œ for exampleï¼Œ if they provide a training example that contains zucchinisã€‚

 then the loss goes down as expectedã€‚ So you go down with a lossã€‚ but then for exampleã€‚

 if you encounter a training example seat beltt which has nothing to do with the zucchini then the training loss for zucchini goes upã€‚

 So if you want to improve the zucchini classification then you shouldn't show it seat beltt samples but then of course your problem is probably a multiclass classification problem where you also have seat belts So it's like a tradeoff right should you show the seat beltã€‚

 I mean then you make maybe the seat beltt classification better but then you lose on the zucchini classificationã€‚

 So in this wayã€‚They give it here another seatbeltã€‚ It goes upã€‚Andã€‚

Here goes down me doing some otherï¼Œ I don't think they show every training exampleã€‚

 they only show the most influential onesï¼Œ the proponents and opponents and seatbelã€‚

 it goes up againï¼Œ zucchini it goes down by a lot and so forth and sunlasses it's interesting for sunlasses also the loss goes down on zucchiniã€‚

Yeah and so here they can kind of better understand what influence the data or data example haveã€‚

 for example hereï¼Œ one seat belt has more influence than another seat beltt and this way you may also find interesting weird outliers in a datasetã€‚

Yeahï¼Œ another interesting research article was related to generative generative adversary networksã€‚

 So this is also something we will be covering towards the end of the classã€‚

 and this might be us in generalï¼Œ though on interesting application or idea for your class projectã€‚

 So there were some projects in the past called this person does not exist where people usedã€‚

Genativeã€‚Adverilialã€‚Networks to generate faces of people that don't exist in real lifeã€‚

 So for exampleï¼Œ this person does not exist in real lifeï¼Œ it's made up by the modelã€‚

 And if you go to this website and refresh it every time you will see a different face that does not exist in the real lifeã€‚

And alsoï¼Œ similarlyï¼Œ theres aã€‚Website called this cat does not exist where people did the same thing for cat imagesã€‚

 So yeahï¼Œ you canã€‚Yeahï¼Œ generate cat imagesã€‚ Yeahã€‚ and now researchers applied the same idea to genome researchã€‚

 So he was anã€‚Article linking to a research article that was recently published where the researchers described that in our workã€‚

 we apply a similar concept to genetic data to automatically learn its structure and for the first timeã€‚

 produce high quality realistic genomesã€‚ So why is that important or interestingã€‚

Currently there's a lot of research being done on DNA and genomesã€‚

 but one problem is really like privacy because yeah genome is unique for a given personã€‚

 so if you do research on genomic dataï¼Œ you kind of have to be careful about how you handle the data if you have realistic genomes that are totally realistic but don't belong to a certain person then I can imagine this can make certain types of research easier for exampleã€‚

 if if you train large scale classification models for a different genes and you have a data and your model learns from this dataã€‚

The model will con turn contain some information about the dataã€‚ So it's kind ofï¼Œ yeahã€‚

 a little bit tricky to make this model available for people or to people who might find it useful because maybe someone would be able to extract some personal information from that modelã€‚

 if you train a model on thisã€‚Fake DNAï¼Œ and it works well on real DNA as wellã€‚

 I can imagine this can help with some of these privacy issues around thatã€‚



![](img/f978af83cc38bc20a97a5bfd62e47432_1.png)

Yeahï¼Œ one last thing about computer vision or related to computer visionã€‚

 which might also be useful as inspiration for a class projectã€‚

So I also saw this project where a companyï¼Œ I think it's called Rebackã€‚

 a company trained computer vision model to estimate the price of a handbagã€‚

So here based on the article an interview with a personã€‚

 they trained it on millions of data points and it took like six year to develop six years to develop this appã€‚

 but yeah it sounds like a fun project where you can take a picture of your handbag and then it estimates the price So it's like a simple straightforward computer vision project I think not too complicated but I guess the trick here was to really get a lot of pictures of handbags and make it accurate So that might be also like an inspiration for a class project of course not with handbags but maybe with something elseã€‚

 So yeah these days people maybe sell a lot of cell phones or laptops or something like that So in that way might be also interesting of course it's not only then based on the picture but also some other statistics like processor speed each of the computer and stuff but yeah I think this is also maybe an interesting fun class project to develop a simple computer vision app that can take pictures of something and then yeah estimateã€‚



![](img/f978af83cc38bc20a97a5bfd62e47432_3.png)

The resale valueã€‚ Alrightï¼Œ with thatï¼Œ this is all I have for this news weekã€‚

 and I wanted to also wish you a happy Luna New Yearã€‚ Hope you have a nice weekendã€‚

 and I will see you back in class on Tuesdayã€‚ðŸ˜Šã€‚

![](img/f978af83cc38bc20a97a5bfd62e47432_5.png)